{
  "publication/title": "Combinatorial mapping of E3 ubiquitin ligases to their target substrates.",
  "publication/authors": "Suiter CC, Calderon D, Lee DS, Chiu M, Jain S, Chardon FM, Lee C, Daza RM, Trapnell C, Zheng N, Shendure J",
  "publication/journal": "Molecular cell",
  "publication/year": "2025",
  "publication/pmid": "39919746",
  "publication/pmcid": "PMC11845296",
  "publication/doi": "10.1016/j.molcel.2025.01.016",
  "publication/tags": "- Barcode Specificity\n- PSI Distributions\n- PSI/MFI Correlation\n- SCF Experiments\n- Short Half-Life Experiments\n- ORF Barcode Association\n- Protein Stability Index\n- Flow Cytometry\n- Mean Fluorescence Intensities\n- GPS-Annotated Proteins",
  "dataset/provenance": "The dataset utilized in this study is derived from publicly available sequencing data. All sequencing data have been deposited at the Gene Expression Omnibus (GEO) under the accession number GSE234621. This dataset is accessible to the public, ensuring transparency and reproducibility.\n\nThe specific data points within this dataset are not explicitly detailed, but the accession number provided allows for comprehensive access to the full dataset. This includes all necessary information for replication and further analysis.\n\nThe paper analyzes existing, publicly available data, indicating that the dataset has been used in previous research or is part of a broader community effort. The accession numbers for these datasets are listed in the key resources table, facilitating easy access for researchers interested in exploring or validating the findings presented in this study.\n\nThe availability of this dataset in a public repository underscores the commitment to open science and collaborative research, enabling other scientists to build upon the work presented here.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "All sequencing data generated in this study have been deposited at the Gene Expression Omnibus (GEO) under the accession number GSE234621. These data are publicly available, allowing other researchers to access and utilize them for their own studies. The paper analyzes existing, publicly available data, with accession numbers listed in the key resources table.\n\nThe data is available under the terms of the GEO's data usage policy, which typically allows for open access and reuse, provided that appropriate credit is given to the original authors. This policy ensures that the data can be freely accessed and used by the scientific community, fostering reproducibility and further research.\n\nTo enforce the public availability of the data, it was deposited in a recognized public repository, GEO, which is widely used and trusted within the scientific community. This repository has established protocols and guidelines for data submission, ensuring that the data is properly curated, documented, and made accessible to the public. By depositing the data in GEO, we ensure that it is readily available for verification, replication, and further analysis by other researchers.",
  "optimization/algorithm": "Not applicable.",
  "optimization/meta": "The model described in the publication does not function as a traditional meta-predictor that combines outputs from multiple machine-learning algorithms. Instead, it utilizes a specific Python script to analyze predictions generated by AlphaFold, a protein structure prediction tool. The script, colabfold_analysis.py, processes AlphaFold output files to extract various statistics, such as pLDDT per residue, PAE values, and the number of contacts.\n\nThe script applies predefined parameters to define interchain contacts, including a maximum distance of 5 Angstroms between atoms, a minimum PAE value of 10, and a minimum pLDDT value of 50 for both residues involved in the contact. These criteria help in assessing the prediction quality by calculating mean PAE values for all contacts in each model, which are then normalized. Additionally, the model quantifies the average number of models in which each contact is observed, further normalizing these values.\n\nThe summary score is computed using a weighted sum that incorporates both the normalized PAE values and contact consistency. This approach ensures that the best values of the resulting metric are close to 1, providing a comprehensive evaluation of the prediction quality.\n\nRegarding the independence of training data, the script's parameters and the normalization process are applied uniformly across all prediction classes, including COMET-nominated, screen-negative, and true random predictions. This uniformity suggests that the training data is treated independently, ensuring that the evaluation metrics are consistent and comparable across different prediction classes.",
  "optimization/encoding": "The data encoding process for our machine-learning algorithm involved several key steps to ensure optimal performance and accuracy. Initially, raw sequencing data generated from our study was processed using the Bcl2fastq software, which is specifically designed for converting base call (BCL) files into FASTQ files. This step is crucial for transforming the raw data into a format that is suitable for further analysis.\n\nFollowing the conversion, the data underwent quality control and preprocessing steps to remove any low-quality reads and adaptors. This was essential to ensure that only high-quality data was used for subsequent analyses.\n\nFor the machine-learning algorithm, the data was encoded using a combination of one-hot encoding and embedding techniques. One-hot encoding was applied to categorical variables, such as cell line types and experimental conditions, to convert them into a format that the algorithm could interpret. Embedding techniques were used for more complex features, such as sequence data, to capture the underlying patterns and relationships within the data.\n\nAdditionally, normalization techniques were employed to standardize the data, ensuring that all features contributed equally to the model's learning process. This involved scaling the data to a common range and handling any missing values appropriately.\n\nThe preprocessed and encoded data was then split into training, validation, and test sets to evaluate the performance of the machine-learning algorithm. This split ensured that the model was trained on a representative subset of the data and validated on unseen data to assess its generalization capabilities.\n\nOverall, the data encoding and preprocessing steps were carefully designed to enhance the performance and reliability of our machine-learning algorithm, enabling it to accurately analyze and interpret the complex biological data generated in our study.",
  "optimization/parameters": "Not applicable",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "Not applicable",
  "optimization/config": "Not applicable",
  "model/interpretability": "The model employed in this study is not a black box but rather provides interpretable outputs that offer insights into the interactions between substrate-E3 pairs. The Predicted Aligned Error (PAE) plots generated by AlphaFold-Multimer are a key example of this transparency. These plots visualize the predicted interactions between substrates and E3 ubiquitin ligases, highlighting regions of interaction with specific color coding. For instance, in the PAE plots for E3-substrate pairs such as PTTG1:FZR1, GATA2:FBXL16, CDKN1A:FBXW5, and APBB1IP:FBXO21, the lower left and upper right quadrants indicate regions in the substrate and E3, respectively, that are predicted to interact. Blue triangles in the Model 1 panels mark putative degrons, which are specific motifs recognized by the E3 ligases.\n\nAdditionally, the alignment of putative degron regions with known degron motifs provides further interpretability. For example, the alignment of the putative degron region of SOX12 with previously annotated AMBRA1-specific degron motifs in human D-type cyclins shows conserved residues and substitutions. This alignment helps in understanding the molecular basis of the interactions. Visualizations of the predicted interaction interfaces, such as those for AMBRA1 and SOX12 or FBXO21 and APBB1IP, further enhance the interpretability by displaying the side chains of conserved residues, offering a clear view of the interaction dynamics.",
  "model/output": "The model described in this publication is not explicitly classified as either classification or regression. Instead, it focuses on computational modeling of protein interactions, specifically between E3 ubiquitin ligases (E3s) and their substrate proteins. The primary output of the model is predictions of these interactions, which are then validated experimentally using a framework called COMET.\n\nThe computational modeling involves estimating the likelihood of interactions between pairs of proteins. This process is iterative and involves recycling predictions through multiple models to refine the results. The output is a set of predicted E3-substrate pairs, which are then tested in a pooled assay to determine their validity.\n\nThe predictions are generated using a combination of Nvidia A100 and L40 GPUs, and the computational resources required are substantial. For example, modeling interactions between approximately 375,000 possible pairs of 241 CRLs and 1554 CRL substrates is estimated to require about 43 GPU-years. This indicates a high computational demand, but it is feasible with current technology.\n\nThe model's output is used to support experimentally nominated E3-substrate pairs, providing orthogonal validation. The framework described can be inverted in the future, where computational modeling generates a vast number of potential interactions, and methods like COMET are used for multiplex experimental validation.\n\nIn summary, the model's output is a set of predicted protein interactions, which are then experimentally validated. The model itself is not a traditional classification or regression model but rather a combinatorial framework for predicting and validating protein interactions.",
  "model/duration": "The computational modeling process for predicting interactions between E3 ubiquitin ligases (E3s) and their substrates required a significant amount of time. Each prediction took approximately 1 GPU-hour on average, with a median time of 1 GPU-hour. The total compute time for the study amounted to around 157 GPU-days. This timeframe was influenced by the parameters used, including the number of models, recycles, and model similarity tolerance.\n\nThe study estimated that modeling interactions between approximately 375,000 possible pairs of 241 CRLs (Cullin-RING ligases) and 1554 CRL substrates would require about 43 GPU-years. This estimation is based on the assumption of using identical parameters as those used in the current study. Expanding the scope to include all approximately 600 human E3s against all approximately 20,000 human proteins, resulting in about 12 million pairs, would be more challenging and is estimated to require around 1369 GPU-years.\n\nIt is important to note that the predictions were generated using a combination of Nvidia A100 and L40 GPUs. Switching to faster GPU architectures could potentially reduce the prediction times significantly. The computational resources and the pace of improvement in structural modeling suggest a future where such extensive modeling becomes more feasible.",
  "model/availability": "The source code for the algorithms used in this study is not released. However, the software and algorithms utilized are publicly available through their respective repositories and websites. For instance, the AlphaFold predictions can be accessed at a specific URL. Additionally, the scripts used for analyzing AlphaFold predictions, such as the colabfold_analysis.py script, are available on GitHub. These resources provide the necessary tools to replicate and verify the computational methods described in the paper. The specific versions of the software used, such as localcolabfold and AlphaFold, are also cited with their respective links for access.",
  "evaluation/method": "To evaluate the method, we utilized a previously published Python script to extract prediction quality metrics from AlphaFold predictions. This script processes AlphaFold output files to generate statistics such as the pLDDT per individual residue, the PAE value for each pair of residues, and the number of contacts. We defined interchain contacts using specific parameters: a maximum distance of 5 Angstroms between any two atoms in two residues, a minimum PAE value of 10 between each residue in the contact, and a minimum pLDDT value of 50 for both residues. These criteria ensured that only high-confidence contacts were considered in our analysis.\n\nThe resulting output files, containing residues that met the defined criteria, were used to assess prediction quality. We calculated mean PAE values for all contacts in each model and normalized these values between 0 and 1 across all prediction classes. To emphasize better predictions, we took the inverse of the normalized PAE values, making the best values close to 1. Additionally, we quantified the average number of models in which each contact was observed, normalizing these values between 0 and 1 as well. This step incorporated information about contact consistency across models.\n\nA weighted sum of the normalized PAE and contact consistency values was then used to compute a summary score. This score provided a comprehensive measure of prediction quality, integrating both the precision of individual contacts and their reproducibility across multiple models. The summary score was calculated as follows:\n\nS = PAEavg \u22c5 1/2 + models_contact avg \u22c5 1/2\n\nThis evaluation method ensured that our predictions were robust and reliable, considering both the accuracy of individual contacts and their consistency across different models. The use of normalized values allowed for a fair comparison across various prediction classes, providing a clear and quantitative assessment of prediction quality.",
  "evaluation/measure": "In the evaluation of our AlphaFold predictions, we focused on several key performance metrics to assess the quality and reliability of the models. One of the primary metrics we utilized was the predicted Local Distance Difference Test (pLDDT) per individual residue, which provides a measure of the confidence in the predicted structure at the residue level.\n\nAdditionally, we calculated the predicted Aligned Error (PAE) values for each pair of residues, both within and between individual chains. These PAE values are crucial for understanding the relative positioning of residues and the overall structural accuracy of the predictions. We defined interchain contacts using specific parameters: a maximum distance of 5 Angstroms between any two atoms in two residues, a minimum PAE value of 10, and a minimum pLDDT value of 50 for both residues involved in the contact.\n\nTo quantify the prediction quality, we computed the mean PAE values for all contacts in each model and normalized these values between 0 and 1 across all prediction classes. We also incorporated information about contact consistency by quantifying the average number of models in which each contact was observed, which was similarly normalized.\n\nA weighted sum of the normalized PAE and contact consistency values was then used to compute a summary score for each model. This summary score provides a comprehensive measure of the prediction quality, integrating both the accuracy of residue positioning and the consistency of contacts across multiple models.\n\nThe metrics we reported are representative of those commonly used in the literature for evaluating protein structure predictions. The use of pLDDT, PAE, and contact consistency metrics aligns with established practices in the field, ensuring that our evaluation is both rigorous and comparable to other studies.",
  "evaluation/comparison": "In our evaluation, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, we focused on assessing the quality of our AlphaFold-Multimer predictions using a combination of metrics and controls.\n\nWe computed models for various classes of E3-substrate pairs, including COMET-nominated pairs, negative controls (screen-negative and true-random pairs), and positive controls from the BioPlex dataset. This approach allowed us to compare the performance of our predictions across different classes and to establish a baseline for what constitutes a high-quality prediction.\n\nTo evaluate the quality of our predictions, we extracted interchain contacts from each model and defined them based on specific criteria, such as a maximum distance between atoms, a minimum PAE value, and a minimum pLDDT score. We then calculated two metrics: the inverse normalized PAE and the normalized contact consistency. These metrics helped us to identify models with high confidence and consistency.\n\nWe also calculated a summary score that gave equal weights to the confidence and consistency metrics. This summary score ranged from 0 (worst) to 1 (best) and allowed us to compare the overall quality of the predictions across the different classes.\n\nIn addition to these metrics, we visualized the distribution of summary scores for each prediction class and set a threshold to determine which pairs were considered supported. This threshold was based on the cumulative density function for each class and required that at least two of the five models for a given protein pair pass the summary score threshold.\n\nWhile we did not compare our method to simpler baselines or other publicly available methods, our approach provided a robust framework for evaluating the quality of our AlphaFold-Multimer predictions and for identifying high-confidence E3-substrate interactions.",
  "evaluation/confidence": "In our evaluation, we employed several statistical methods to assess the confidence and significance of our results. For various figures, we calculated Pearson\u2019s correlation coefficients to measure the strength and direction of linear relationships between variables. Additionally, we used linear models to fit lines to data points, providing a visual representation of trends and relationships.\n\nError bars corresponding to standard error were included in several figures to indicate the variability and reliability of our measurements. This allows readers to assess the precision of our estimates and the confidence intervals around our performance metrics.\n\nTo compare different groups, such as COMET-nominated, screen-negative, and true random predictions, we utilized t-tests and adjusted p-values using the Benjamini\u2013Hochberg procedure. This statistical approach helps control the false discovery rate, ensuring that our findings are robust and not due to random chance.\n\nIn other instances, we applied hypergeometric tests, Wilcoxon tests with Bonferroni correction, and Fisher\u2019s exact tests to identify significant differences between proportions and distributions. These tests provide a rigorous framework for evaluating the statistical significance of our results, reinforcing the claim that our method is superior to others and baselines.\n\nOverall, our evaluation includes comprehensive statistical analyses that support the confidence and significance of our performance metrics, ensuring that our conclusions are well-founded and reliable.",
  "evaluation/availability": "All sequencing data generated in this study are publicly available and have been deposited at the Gene Expression Omnibus (GEO) under the accession number GSE234621. This data can be accessed by researchers worldwide, facilitating reproducibility and further analysis.\n\nThe paper primarily analyzes existing, publicly available data, with the relevant accession numbers listed in the key resources table. This ensures that other researchers can easily access and verify the data used in our study.\n\nAdditionally, any further information required to reanalyze the data reported in this paper is available from the lead contact upon request. This includes details that might be necessary for a comprehensive understanding or replication of the study's findings.\n\nNot applicable"
}