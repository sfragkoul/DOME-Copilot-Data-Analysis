{
  "publication/title": "Limited prognostic value of pain duration in non-specific neck pain patients seeking chiropractic care.",
  "publication/authors": "Guill\u00e9n D, Guekos A, Graf N, Humphreys BK, Peterson C, Schweinhardt P",
  "publication/journal": "European journal of pain (London, England)",
  "publication/year": "2022",
  "publication/pmid": "35451179",
  "publication/pmcid": "PMC9324235",
  "publication/doi": "10.1002/ejp.1954",
  "publication/tags": "- Neck pain\n- Chiropractic treatment\n- Pain duration\n- Prognostic factors\n- Treatment outcome\n- Regression analysis\n- Machine learning\n- Patient-reported outcomes\n- Observational study\n- Cohort study",
  "dataset/provenance": "The dataset used in this study was sourced from an observational prospective cohort study of neck pain patients in Switzerland. The data collection involved active members of the Association of Swiss Chiropractors, who were instructed to recruit patients with neck pain. Data were collected between October 2009 and March 2015 in a standardized manner. The study included 851 neck pain patients, of which 720 were used in the analysis after excluding those who missed the primary predictor, pain duration.\n\nThis dataset has been utilized in several previous publications, indicating its relevance and the community's interest in the data. The studies that have used this dataset include those by Humphreys & Peterson (2013), Langenfeld et al. (2015), Nyir\u00f6 et al. (2017), Peterson et al. (2012), Th\u00f6ni et al. (2017), and Wirth et al. (2016). The STROBE guidelines for reporting observational studies were followed to ensure the quality and transparency of the data collection and reporting processes.",
  "dataset/splits": "The dataset was split into two parts: a training set and a test set. The data was randomly divided with a ratio of 3:1, meaning that three-quarters of the data was used for training, and one-quarter was used for testing. This split was done to evaluate the predictive value of pain duration on outcomes in an independent dataset. Specifically, a linear model for linear regression or a generalized linear model for logistic regression was first fitted to the training dataset and then used to make predictions on the test dataset. The training set was used to develop the model, while the test set was used to assess the model's performance and generalization to new, unseen data.",
  "dataset/redundancy": "The dataset was split randomly into a training set and a test set with a ratio of 3:1. This means that 75% of the data was used for training the models, while the remaining 25% was used for testing the models' predictive performance. The training and test sets were independent, ensuring that the model's performance on the test set could be considered an unbiased estimate of its performance on new, unseen data.\n\nTo enforce the independence of the training and test sets, the data was randomly split without any overlap between the two sets. This random splitting was done to ensure that the model did not have access to the test data during the training process, which could lead to overfitting and an overestimation of the model's performance.\n\nThe distribution of the dataset used in this study was compared to previously published machine learning datasets in the context of neck pain. The sample size was notably large compared to previous studies, which enhances the generalizability of the conclusions drawn. However, it is important to note that the dataset showed a striking difference between the mean and the median pain duration, which is a common phenomenon when assessing all patients together without first stratifying them by pain duration. This characteristic is typical in studies that do not stratify patients by pain duration before analysis.\n\nThe dataset included patients with neck pain of any duration, and separate analyses were performed for the full sample and for chronic patients only. This approach allowed for a comprehensive evaluation of how pain duration influences treatment outcomes across different patient groups. The dataset was collected over a period from October 2009 to March 2015, ensuring a robust and diverse sample of neck pain patients receiving chiropractic treatment.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study is a machine learning approach known as random forest. This is a well-established ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe random forest algorithm is not new; it has been extensively used and validated in various fields, including medical research. The decision to use this algorithm was driven by its robustness and ability to handle complex, non-linear relationships within the data. It is particularly useful for identifying potential non-monotonic relationships between predictor variables and outcome measures.\n\nGiven that our primary focus was on investigating the influence of pain duration on treatment outcomes in neck pain patients, the random forest method was chosen for its effectiveness in capturing intricate patterns in the data. The algorithm's capability to manage high-dimensional data and provide feature importance rankings made it a suitable choice for our analytical needs.\n\nThe random forest algorithm has been widely published and discussed in machine learning literature, so there was no need to publish it in a machine-learning journal. Instead, our study concentrated on applying this established method to address specific clinical questions related to pain duration and treatment outcomes.",
  "optimization/meta": "The study does not employ a meta-predictor model. Instead, it utilizes traditional statistical methods and a machine learning approach to analyze the relationship between pain duration and treatment outcomes in neck pain patients.\n\nThe primary methods used include linear and logistic regression to assess the influence of pain duration on outcomes such as percent NRS change and PGIC. Additionally, quadratic and cubic curve fits were employed to test for non-linear relationships. To address potential data skewness, regression analyses were repeated with log-transformed predictor variables.\n\nA random forest machine learning approach was also used to detect any non-monotonic relationships between predictor variables and outcome measures. This method does not rely on data from other machine-learning algorithms as input; rather, it operates independently on the dataset.\n\nFor the secondary aim of assessing the predictive value of pain duration in independent data, out-of-sample prediction was performed. The data were randomly split into training and test sets with a 3:1 ratio. A linear model for linear regression or a generalized linear model for logistic regression was fitted to the training dataset and then used to make predictions on the test dataset. This approach ensures that the training data is independent of the test data, maintaining the integrity of the predictive analysis.\n\nIn summary, the study does not use a meta-predictor but rather employs a combination of traditional statistical methods and a machine learning approach to analyze the data. The training and test datasets are kept independent to validate the predictive value of pain duration.",
  "optimization/encoding": "The data used in our study was initially stored in IBM SPSS 21 and later converted into comma-separated values (CSV) format for analysis. The primary predictor variable of interest was pain duration in weeks at baseline. To ensure completeness, all entries were checked, and patients missing this primary predictor were removed, leaving 720 patients for further analysis.\n\nFor the machine learning approach, we used a random forest method to detect potential non-monotonic relationships between predictor variables and outcome measures. This approach was chosen because it does not require normally distributed data, which was beneficial given the skewness in our dataset.\n\nTo address data skewness, we also performed regression analyses with the log-transformed predictor variable. Although this transformation corresponded to a normal distribution, it did not change the results of the analysis. Additionally, we fitted linear and generalized linear models to the training dataset and used them to make predictions on the test dataset for out-of-sample prediction.\n\nFor the categorical outcome PGIC, we assessed the goodness of fit by comparing the model's accuracy to the no-information rate and calculating the area under the receiver operating characteristics curve. For the continuous outcome percent NRS change, we determined the coefficient of determination, R2.\n\nIn summary, the data was pre-processed by checking for completeness and removing missing values. The primary predictor variable was pain duration in weeks, and various statistical and machine learning techniques were employed to analyze the data, accounting for its skewness and ensuring robust predictions.",
  "optimization/parameters": "In the optimization process, the primary input parameter was the duration of pain, which was used as an independent variable. This parameter was selected based on its potential influence on treatment outcomes. The duration of pain was measured in weeks and was used in both linear and non-linear (quadratic and cubic) forms to test for various relationships with the dependent variables.\n\nTo account for data skewness, a log-transformed version of the pain duration was also used in the regression analyses. However, this transformation did not change the results, indicating that the original scale of pain duration was appropriate for the analysis.\n\nAdditionally, the model considered other predictor variables, although multivariate analyses including these variables did not alter the conclusions drawn from the primary analyses focusing on pain duration.\n\nThe selection of pain duration as a key parameter was driven by the study's aim to investigate its influence on treatment outcomes in patients with chronic neck pain. The use of different forms of pain duration (linear, quadratic, cubic) allowed for a comprehensive examination of its potential relationships with the outcome measures.",
  "optimization/features": "The primary predictor variable used in this study was pain duration in weeks at baseline. This was the main input feature considered for the analyses. The study did not explicitly mention the use of feature selection techniques. However, it is implied that pain duration was chosen based on its relevance to the research questions. The data cleaning process involved removing patients missing the primary predictor, ensuring that pain duration was consistently available for all included patients. The analyses were conducted using this single predictor variable, with no indication of additional features being selected or used. The study focused on the predictive value of pain duration, both in terms of statistical significance and out-of-sample prediction.",
  "optimization/fitting": "The study employed various statistical and machine learning approaches to analyze the relationship between pain duration and treatment outcomes in neck pain patients. The dataset consisted of 720 patients after removing those with missing primary predictor data.\n\nTo address potential overfitting, several strategies were implemented. Firstly, the data were split into training and test sets with a 3:1 ratio. This allowed for the evaluation of the model's performance on an independent dataset, ensuring that the relationships identified were not merely artifacts of the training data. Additionally, the use of logistic and linear regression models, along with quadratic and cubic curve fits, helped to test for non-linear relationships, providing a more robust assessment of the data.\n\nThe study also utilized a machine learning approach, specifically a random forest, to detect potentially non-monotonic relationships between predictor variables and outcome measures. This method is less prone to overfitting compared to more complex models, as it aggregates the results of multiple decision trees.\n\nTo rule out underfitting, the study calculated the coefficients of determination (R2 adjusted for linear regressions and Nagelkerke's pseudo R2 for logistic regressions) to assess how much variance in the outcome was explained by pain duration. This ensured that the models were sufficiently complex to capture the underlying patterns in the data.\n\nFurthermore, the goodness of fit for categorical outcomes was assessed by comparing the model's accuracy to the no-information rate and calculating the area under the receiver operating characteristics curve (AUC). For continuous outcomes, R2 was determined to ensure that the models adequately captured the variability in the data.\n\nIn summary, the study employed a combination of regression analyses, curve fitting, and machine learning techniques to balance the risk of overfitting and underfitting. The use of independent test sets and robust statistical measures ensured that the models were both generalizable and sufficiently complex to capture the relationships in the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. For the regression analyses, we used both linear and logistic regression models. To account for potential non-linear relationships, we also tested quadratic and cubic curve fits. Additionally, we transformed the predictor variable using a log transformation to address data skewness, although this did not change the results.\n\nTo further validate our models, we utilized out-of-sample prediction. The data were randomly split into a training set and a test set with a ratio of 3:1. The models were first fitted to the training dataset and then used to make predictions on the test dataset. This approach helped us assess the true predictive value of pain duration on outcomes.\n\nFor the categorical outcome, the Patient Global Impression of Change (PGIC), we evaluated the goodness of fit by comparing the model's accuracy to the no-information rate and by calculating the area under the receiver operating characteristics curve (AUC). For the continuous outcome, percent change in Numerical Rating Scale (NRS), we determined the coefficient of determination (R2).\n\nMoreover, we employed a random forest machine learning approach to detect any potentially non-monotonic relationships between predictor variables and outcome measures. This method provided an additional layer of validation and helped ensure that our findings were robust and not due to overfitting.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The model employed in this study is not a blackbox. It includes both linear and logistic regression models, which are inherently interpretable. These models provide clear relationships between the predictor variable (pain duration) and the outcome variables (percent NRS change and PGIC). The coefficients from these regressions indicate the direction and magnitude of the influence of pain duration on the outcomes.\n\nAdditionally, quadratic and cubic curve fits were used to test for non-linear relationships, further enhancing the interpretability by showing how changes in pain duration might affect outcomes in a non-linear fashion. The use of random forest machine learning also aids in interpretability by detecting potentially non-monotonic relationships between predictor variables and outcome measures.\n\nThe study also calculated coefficients of determination (R2 adjusted and Nagelkerke's pseudo R2) to quantify how much variance in the outcome is explained by pain duration. This provides a clear measure of the model's explanatory power.\n\nFor categorical outcomes like PGIC, the model's accuracy was compared to the no-information rate, and the area under the receiver operating characteristics curve (AUC) was calculated. For continuous outcomes like percent NRS change, R2 was determined, offering straightforward metrics to assess the model's performance and interpretability.\n\nIn summary, the models used are transparent and provide clear, interpretable results regarding the influence of pain duration on treatment outcomes.",
  "model/output": "The model employed in this study is both classification and regression, depending on the outcome variable being analyzed. For the categorical outcome, Patient Global Impression of Change (PGIC), logistic regression was used, which is a classification technique. This approach was also used to assess the goodness of fit by comparing the model's accuracy to the no-information rate and calculating the area under the receiver operating characteristics curve.\n\nFor the continuous outcome, percent change in Numerical Rating Scale (NRS), linear regression was utilized, which is a regression technique. This method was chosen to determine the coefficient of determination (R\u00b2), indicating the amount of variance in the outcome explained by pain duration.\n\nAdditionally, quadratic and cubic curve fits were tested to explore non-linear, monotonous relationships between pain duration and both outcome measures. These analyses required pain duration to be treated as a continuous variable, so it was measured in days.\n\nTo further investigate potential non-monotonic relationships, a random forest machine learning approach was also employed. This method can detect complex relationships between predictor variables and outcome measures.\n\nLastly, out-of-sample prediction was used to test whether pain duration has true predictive value for outcome. The data were split into training and test sets, and a linear or generalized linear model was fitted to the training dataset and then used to make predictions on the test dataset. This approach was applied to both the continuous outcome (percent NRS change) and the categorical outcome (PGIC).",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not applicable",
  "evaluation/method": "The evaluation method employed in this study was comprehensive and multifaceted, ensuring robust assessment of the influence of pain duration on treatment outcomes. Several statistical techniques were utilized to evaluate the relationships between pain duration and outcome measures.\n\nLinear and logistic regression analyses were conducted to assess the impact of pain duration on percent NRS change and PGIC, respectively. These analyses were complemented by quadratic and cubic curve fits to explore potential non-linear, monotonous relationships. To address data skewness, regression analyses were repeated with log-transformed predictor variables, although this transformation did not alter the results.\n\nAdditionally, a random forest machine learning approach was used to detect any non-monotonic relationships between predictor variables and outcome measures. This method provided a more nuanced understanding of the data, beyond what linear models could offer.\n\nFor illustrative purposes, outcomes in chronic pain patients with short chronicity (between 3 and 6 months) were contrasted with those with chronicity over 4 years. Pearson's \u03c72 test of independence was used for categorical data (PGIC), and Welch's t-test was employed for continuous data (NRS).\n\nTo determine how much variance in outcome is explained by pain duration, coefficients of determination (R2 adjusted for linear regressions and Nagelkerke's pseudo R2 for logistic regressions) were calculated. This provided a quantitative measure of the predictive power of pain duration.\n\nTo test whether pain duration has true predictive value for outcome in independent data, out-of-sample prediction was used. The data were randomly split into a training set (75%) and a test set (25%). A linear model (for linear regression) or a generalized linear model (for logistic regression) was fitted to the training dataset and then used to make predictions on the test dataset. The goodness of fit for the categorical outcome (PGIC) was assessed by comparing the model's accuracy to the no-information rate and calculating the area under the receiver operating characteristics curve (AUC). For the continuous outcome (percent NRS change), R2 was determined.\n\nThis evaluation method ensured a thorough and rigorous assessment of the study's primary and secondary aims, providing a comprehensive understanding of the relationship between pain duration and treatment outcomes.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the predictive power of pain duration on patient outcomes. For the categorical outcome measured by the Patient Global Impression of Change (PGIC), we assessed the model's accuracy by comparing it to the no-information rate. Additionally, we calculated the area under the receiver operating characteristics curve (AUC) for the trained model. These metrics are widely used in the literature for evaluating the performance of classification models.\n\nFor the continuous outcome, which was the percent change in Numerical Rating Scale (NRS) pain intensity, we determined the coefficient of determination (R\u00b2). This metric indicates the proportion of the variance in the dependent variable that is predictable from the independent variable, providing a clear measure of the model's explanatory power.\n\nTo address the primary aim of our study, we performed univariate regression analyses, using logistic regression for the dichotomized PGIC and linear regression for the percent NRS change. We also explored quadratic and cubic relationships to test for non-linear, monotonous relationships between pain duration and the outcomes. Furthermore, we used a random forest machine learning approach to detect potential non-monotonic relationships.\n\nTo test the second secondary aim, which involved out-of-sample prediction, we split the data into training and test sets with a 3:1 ratio. We then fitted a linear model for the linear regression and a generalized linear model for the logistic regression to the training dataset and used these models to make predictions on the test dataset. This approach allowed us to evaluate the true predictive value of pain duration on outcomes.\n\nIn summary, our set of performance metrics is representative of standard practices in the literature, ensuring a comprehensive evaluation of the predictive power of pain duration on patient outcomes.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. However, we did compare the predictive power of pain duration to simpler baselines. Specifically, we used out-of-sample prediction to assess whether pain duration has true predictive value for outcomes. This involved splitting the data into training and test sets, fitting a model to the training data, and then evaluating its performance on the test data. For the categorical outcome (PGIC), we assessed the model's accuracy and the area under the receiver operating characteristics curve (AUC). For the continuous outcome (percent NRS change), we determined the coefficient of determination (R2). This approach allowed us to evaluate the predictive power of pain duration in a manner similar to simpler baseline models, providing a robust assessment of its utility as a prognostic factor.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of the study's results was conducted with a focus on statistical significance and the confidence in the performance metrics. Regression analyses were performed to determine the influence of pain duration on patient outcomes, with significant results indicated by bold typeface. The p-values for these analyses were provided, allowing for an assessment of statistical significance. For instance, at the 1-week follow-up, the p-value for the percent NRS change was less than 0.01, indicating a statistically significant result.\n\nThe study also calculated the amount of variance explained by pain duration using Nagelkerke's pseudo R\u00b2 for dichotomized PGIC and R\u00b2 for percent NRS change. These metrics provided a measure of the confidence in the performance of pain duration as a predictor variable. For example, at the 1-week follow-up, the R\u00b2 value for percent NRS change was 0.05, suggesting that pain duration explained 5% of the variance in this outcome.\n\nAdditionally, out-of-sample prediction was used to test the true predictive value of pain duration. This involved splitting the data into training and test sets and fitting a model to the training data before making predictions on the test data. The goodness of fit for the categorical outcome PGIC was assessed by comparing the model's accuracy to the no-information rate and calculating the area under the receiver operating characteristics curve (AUC). For the continuous outcome percent NRS change, the R\u00b2 value was determined. These steps ensured that the results were not overfitted to the training data and provided a robust evaluation of the model's performance.\n\nThe study also noted that a p-value between 0.05 and 0.1 was considered a statistical trend, indicating that while these results may not be statistically significant, they warrant further investigation. This approach ensured that the evaluation was thorough and considered all potential influences of pain duration on patient outcomes.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The data used in this study were initially stored in IBM SPSS 21 and then converted into comma-separated values (CSV) format for analysis using R 3.4.4 with the 'tidyverse' collection of packages. However, these files were not released publicly. The study involved a dataset of 851 neck pain patients, but only 720 were used for analysis after removing those missing the primary predictor, pain duration. The dataset underwent a preparatory data cleaning process to ensure completeness. The analyses focused on evaluating the influence of pain duration on outcomes, using various statistical methods such as linear and logistic regression, as well as machine learning approaches. The results of these analyses are detailed in the study, but the raw data files themselves are not accessible to the public."
}