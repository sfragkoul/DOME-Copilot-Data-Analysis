{
  "publication/title": "A Model Using Support Vector Machines Recursive Feature Elimination (SVM-RFE) Algorithm to Classify Whether COPD Patients Have Been Continuously Managed According to GOLD Guidelines.",
  "publication/authors": "Xia J, Sun L, Xu S, Xiang Q, Zhao J, Xiong W, Xu Y, Chu S",
  "publication/journal": "International journal of chronic obstructive pulmonary disease",
  "publication/year": "2020",
  "publication/pmid": "33177815",
  "publication/pmcid": "PMC7649211",
  "publication/doi": "10.2147/copd.s271237",
  "publication/tags": "- Chronic Obstructive Pulmonary Disease (COPD)\n- GOLD guidelines\n- Machine Learning\n- Support Vector Machines (SVM)\n- LibSVM\n- COPD assessment\n- Patient management\n- Feature selection\n- Medical data analysis\n- Predictive modeling",
  "dataset/provenance": "The dataset used in this study was sourced from a clinical trial registered with the ClinicalTrials.gov ID NCT03314077. The study involved two groups: the Managed group and the Control group. Initially, there were 16 subjects in the Managed group, but one was excluded, leaving 15 subjects. In the Control group, 217 subjects were retrospectively interviewed, with 23 excluded for being continuously managed for more than a month after leaving the hospital, and 3 lost to follow-up, resulting in 191 subjects.\n\nThe final sample included 15 subjects in the Managed group and 191 in the Control group. For model development, 80% of the subjects in each group were randomly selected as the training sample, and the remaining 20% served as the testing sample. This resulted in 12 patients in the Managed group and 151 in the Control group being used for training, while 3 patients in the Managed group and 40 in the Control group were used for testing.\n\nDue to the imbalance in sample size between the Managed and Control groups, a synthetic minority over-sampling technique (SMOTE) was applied to the training dataset of the Managed group. This procedure up-sampled the Managed group to 60 samples, ensuring a more balanced training dataset. The testing dataset remained unchanged to maintain real-world testing conditions.\n\nThe data used in this study included various demographic characteristics and indicators of COPD assessment based on GOLD guidelines 2017. These features included sex, age, education level, smoking history, BMI before and after 1-year follow-up, moderate and severe AECOPD frequency in the previous 12 months before and after 1-year follow-up, mMRC score after 1-year follow-up, CAT score after 1-year follow-up, and lung function testing results after inhaling a bronchodilator, including FEV1, FEV1% predicted value, FVC, and FEV1/FVC before and after 1-year follow-up.",
  "dataset/splits": "The dataset was divided into two main splits: a training sample and a testing sample. The training sample consisted of 80% of the data, while the testing sample consisted of the remaining 20%.\n\nIn the training sample, there were 12 patients in the Managed group and 151 in the Control group. To address the imbalance between the Managed and Control groups, a synthetic minority over-sampling technique (SMOTE) was applied to the Managed group, resulting in 60 samples in the Managed group training dataset.\n\nThe testing sample included 3 patients in the Managed group and 40 in the Control group. The testing dataset was not up-sampled to maintain a real-world background for evaluating the model's performance.",
  "dataset/redundancy": "The datasets were split into training and testing sets to evaluate the model's performance. Specifically, 80% of the subjects in each group were randomly selected for the training sample, while the remaining 20% constituted the testing sample. This resulted in 12 patients in the Managed group and 151 in the Control group being used for training, with 3 patients in the Managed group and 40 in the Control group reserved for testing.\n\nThe training and test sets are independent. To ensure this independence, the datasets were split randomly, and the same subjects were not included in both the training and testing sets. This random selection process helps to prevent data leakage and ensures that the model's performance on the test set is a true reflection of its generalization capability.\n\nThe imbalance in sample size between the Managed group and the Control group was addressed using the Synthetic Minority Over-sampling Technique (SMOTE). This technique was applied only to the training dataset to balance the class distribution, while the testing dataset remained unchanged. This approach helps to mitigate the bias towards the majority class and improves the model's ability to classify the minority class accurately.\n\nThe distribution of the datasets in this study compares favorably with previously published machine learning datasets in medical research. The use of SMOTE to handle class imbalance is a well-established technique that has been shown to improve model performance in various medical applications. By ensuring that the training and testing sets are independent and representative of real-world scenarios, the study aims to provide a robust evaluation of the model's effectiveness in classifying patients based on their management status.",
  "dataset/availability": "The data used in this study is not publicly available. However, individual deidentified participant data, specific data, and other study documents are available from the corresponding author upon reasonable request. The data has been made available from July 2020 and will remain accessible for 3 years. The ClinicalTrials.gov ID for this study is NCT03314077. This approach ensures that the data is shared responsibly while protecting participant privacy.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Support Vector Machines (SVM). Specifically, we employed LibSVM, a widely-used library for SVM. This algorithm is not new; it has been extensively used in various fields, including medical research, due to its robust performance in classification tasks.\n\nThe choice of SVM was driven by its effectiveness in handling high-dimensional spaces and its ability to perform well with clear margin of separation. The hyperparameters of the SVM model, such as the cost parameter (C) and the kernel type, were optimized using a grid-search technique combined with 10-fold cross-validation. This approach ensured that the model's performance was not overfitted or underfitted, thereby enhancing its generalization capabilities.\n\nThe reason this algorithm was not published in a machine-learning journal is that our focus was on applying established machine-learning techniques to a specific medical problem\u2014identifying whether COPD patients were continuously managed according to GOLD guidelines. The innovation lies in the application and optimization of SVM for this particular healthcare challenge, rather than in the development of a new algorithm. Our study contributes to the field by demonstrating the practical utility of SVM in clinical settings, providing a tool that can be readily adopted by healthcare professionals.",
  "optimization/meta": "The model developed in this study does not use data from other machine-learning algorithms as input. It is not a meta-predictor. Instead, it is a standalone support vector machine (SVM) classifier. The SVM model was built using the LibSVM algorithm and was trained using a dataset that included various features such as smoking history, lung function test results, and other clinical indicators. The training data were standardized using z-score transformation, and the testing data were transformed using the same parameters. The model's performance was assessed using metrics such as positive predictive value (PPV), F1 score, and area under the receiver operating characteristic curve (AUC). The hyperparameters for the SVM were optimized using grid-search and 10-fold cross-validation, ensuring that the model was robust and generalizable. The training and testing datasets were independent, with 80% of the data used for training and 20% reserved for testing. This approach helped in evaluating the model's performance on unseen data, ensuring its reliability and validity.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for optimizing the performance of our machine-learning algorithm. Initially, the training data were standardized using z-score transformation, which ensures that each feature has a mean of zero and a standard deviation of one. This standardization process was also applied to the testing data using the same parameters derived from the training data, maintaining consistency across both datasets.\n\nTo address the imbalance in the sample sizes between the Managed group and the Control group, the Synthetic Minority Over-sampling Technique (SMOTE) was employed. SMOTE generates synthetic data points for the minority class by interpolating between existing minority samples and their nearest neighbors. This approach helps to mitigate the bias towards the majority class and improves the classifier's sensitivity to the minority class.\n\nThe support vector machine recursive feature elimination (SVM-RFE) algorithm was utilized to identify the most relevant features for optimizing the classifier's performance. This process involved a grid-search and 10-fold cross-validation to train and estimate the SVM hyperparameters. The grid-search was conducted over a range of values for the cost parameter (C = 0.01\u201310) and the kernel type (linear or radial basis function (RBF)). The optimal hyperparameters identified were an RBF kernel, a cost parameter of 1, and a gamma value set to scale. These hyperparameters, along with 10-fold cross-validation, were used to train the classifier on the training set.\n\nThe features selected by SVM-RFE included smoking history, post-bronchodilator forced vital capacity (FVC) before management, and several post-1-year follow-up metrics such as body mass index (BMI), frequency of moderate and severe acute exacerbations of chronic obstructive pulmonary disease (AECOPD) in the previous 12 months, modified Medical Research Council (mMRC) score, post-bronchodilator forced expiratory volume in one second (FEV1), FEV1% predicted, post-bronchodilator FVC, and the FEV1/FVC ratio. These features were used to classify whether COPD patients were continuously managed according to the Global Initiative for Chronic Obstructive Lung Disease (GOLD) guidelines.\n\nThe performance of the classifier was evaluated on the testing dataset, which was not used during the training phase. The model demonstrated a positive predictive value (PPV) of 66.7%, an F1 score of 0.978, an area under the receiver operating characteristic curve (AUC) of 0.987, and a kappa value of 0.788. A sensitivity analysis was conducted by reducing the hyperparameter C to observe the robustness of the model, and the results remained consistent, confirming the model's reliability.",
  "optimization/parameters": "In our study, we utilized a Support Vector Machine (SVM) classifier to identify whether COPD patients were continuously managed according to GOLD guidelines. The model was developed using the LibSVM algorithm, and the hyperparameters were trained and estimated using a grid-search method combined with 10-fold cross-validation.\n\nThe selection of features for the model was performed using the Support Vector Machine Recursive Feature Elimination (SVM-RFE) algorithm. This algorithm helped in identifying the most relevant features that optimize the performance of the classifier. Through this process, nine features were selected. These features include smoking history, post-bronchodilator Forced Vital Capacity (FVC) before management, and several post-1-year follow-up measurements such as Body Mass Index (BMI), frequency of moderate and severe Acute Exacerbations of Chronic Obstructive Pulmonary Disease (AECOPD) in the previous 12 months, modified Medical Research Council (mMRC) score, post-bronchodilator Forced Expiratory Volume in one second (FEV1), post-bronchodilator FEV1% predicted, post-bronchodilator FVC, and post-bronchodilator FEV1/FVC ratio.\n\nThe grid-search was conducted over a range of values for the hyperparameters, specifically C (ranging from 0.01 to 10) and the kernel type (linear or radial basis function (RBF)). The optimal hyperparameters identified were an RBF kernel, a cost parameter of 1, and gamma set to scale. These hyperparameters, along with the 10-fold cross-validation, were used to train the classifier using the training set. The performance of the classifier was then assessed on a separate testing dataset, which was not used during the training phase. This approach ensured that the model's generalization ability was evaluated in a real-world scenario.",
  "optimization/features": "In our study, nine features were used as input for the classifier. These features were selected using the Support Vector Machine Recursive Feature Elimination (SVM-RFE) algorithm. This feature selection process was performed using only the training set, ensuring that the testing data remained independent and unbiased. The selected features include smoking history, post-bronchodilator forced vital capacity (FVC) before management, and several post-1-year follow-up metrics such as body mass index (BMI), moderate and severe acute exacerbation of chronic obstructive pulmonary disease (AECOPD) frequency in the previous 12 months, modified Medical Research Council (mMRC) score, post-bronchodilator forced expiratory volume in one second (FEV1), post-bronchodilator FEV1% predicted, post-bronchodilator FVC, and post-bronchodilator FEV1/FVC ratio. These features were chosen to optimize the performance of the classifier in distinguishing between patients who were continuously managed according to the Global Initiative for Chronic Obstructive Lung Disease (GOLD) guidelines and those who were not.",
  "optimization/fitting": "The fitting method employed in our study utilized a Support Vector Machine (SVM) with a radial basis function (RBF) kernel, developed using the LibSVM algorithm. The hyperparameters, including the cost parameter (C) and gamma, were optimized through a grid-search technique combined with 10-fold cross-validation. This approach ensured a comprehensive search over specified parameter values, aiming to find the optimal settings for our classifier.\n\nTo address the potential issue of overfitting, we carefully selected the hyperparameters using the grid-search method. Overfitting was mitigated by evaluating the model's performance on a separate testing dataset that was not used during the training phase. Additionally, a sensitivity analysis was conducted by reducing the C-value to 0.1, which yielded the same testing results as the primary model. This consistency in performance suggested the robustness of our model and indicated that overfitting was not a significant concern.\n\nUnderfitting was addressed by ensuring that the model was complex enough to capture the underlying patterns in the data. The use of the RBF kernel, which is capable of handling non-linear relationships, along with the optimal hyperparameters identified through grid-search, helped in achieving a good balance between bias and variance. The model's performance metrics, such as the positive predictive value (PPV) of 66.7%, F1 score of 0.978, and an area under the receiver operating characteristic curve (AUC) of 0.987, further confirmed that underfitting was not an issue.\n\nThe imbalance in the sample size between the Managed group and the Control group was managed using the Synthetic Minority Over-sampling Technique (SMOTE). This technique was applied only to the training dataset to avoid bias towards the majority class. The testing dataset remained untouched, ensuring that the model's performance was evaluated in a real-world scenario. The SMOTE algorithm helped in creating a balanced training dataset, which improved the model's ability to generalize and reduced the risk of underfitting.\n\nIn summary, the fitting method involved a rigorous optimization process using grid-search and cross-validation, along with techniques to handle class imbalance and ensure model robustness. These steps collectively helped in ruling out both overfitting and underfitting, resulting in a reliable and generalizable classifier.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was grid-search combined with 10-fold cross-validation. This approach allowed us to systematically search for the optimal hyperparameters for our support vector machine (SVM) model, specifically the regularization parameter C and the kernel type. By using cross-validation, we could evaluate the model's performance on different subsets of the data, reducing the risk of overfitting to any single subset.\n\nAdditionally, we conducted a sensitivity analysis by reducing the hyperparameter C to 0.1. The results remained consistent with the primary model, indicating that our model is robust and not overly sensitive to the specific value of C. This further supports the effectiveness of our regularization techniques.\n\nAnother important aspect was the use of the Synthetic Minority Over-sampling Technique (SMOTE) to address the imbalance in our dataset. This technique helps to avoid overfitting by generating synthetic samples for the minority class, thereby ensuring that the model does not become biased towards the majority class. The SMOTE algorithm was applied only to the training dataset, allowing us to test the model on a real-world, imbalanced testing dataset without compromising its generalization ability.\n\nOverall, these methods collectively contributed to the development of a reliable and robust classification model for identifying whether COPD patients were continuously managed according to GOLD guidelines.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in detail within the publication. Specifically, we utilized a grid-search technique combined with 10-fold cross-validation to determine the optimal hyperparameters for our support vector machine (SVM) model. The ranges explored for the hyperparameters included C values from 0.01 to 10 and kernel types of linear or radial basis function (RBF). The best-performing hyperparameters identified were an RBF kernel, a cost parameter of 1, and gamma set to scale.\n\nThe model files and optimization parameters are not directly available in the publication. However, the data used in this study can be accessed upon reasonable request from the corresponding author. The data sharing statement specifies that individual deidentified participant data and study documents will be available from July 2020 for a duration of three years. This ensures that other researchers can replicate and build upon our findings, promoting transparency and reproducibility in scientific research.\n\nThe study was funded by the National Key Technologies R&D Program and the National Natural Science Foundation of China, which supported the development and optimization of the classification model. The protocol and methods adhered to ethical guidelines, including approval by the Institutional Review Board and informed consent from participants. This rigorous approach ensures the reliability and validity of the reported configurations and optimization processes.",
  "model/interpretability": "The model developed in this study is not a black-box model. It is a multivariable classifier that uses a support vector machine (SVM) algorithm, specifically LibSVM, which is known for its interpretability compared to other complex models like deep neural networks.\n\nThe model's transparency is evident in several ways. Firstly, the features selected for the classifier are clearly defined and clinically relevant. These include variables from spirometry, such as post-bronchodilator FEV1, FEV1%pred, FVC, and FEV1/FVC, as well as other health metrics like BMI, moderate and severe AECOPD frequency, and mMRC score. These features are not arbitrary but are chosen based on their significance in assessing COPD patients according to GOLD guidelines.\n\nSecondly, the model's hyperparameters were systematically tuned using grid-search and 10-fold cross-validation, ensuring that the optimal values were found. The best hyperparameters identified were an RBF kernel, a cost parameter of 1, and gamma as scale. These parameters are not hidden but are explicitly stated and can be understood in the context of SVM theory.\n\nMoreover, the model's performance was evaluated using metrics that consider the minority class, such as the F1 score, positive predictive value (PPV), and area under the ROC curve (AUC). These metrics provide a clear understanding of the model's strengths and weaknesses.\n\nThe use of the SMOTE algorithm to handle the imbalance in the dataset is also transparent. The algorithm adds synthetic data to the minority class, which helps in training a more robust model without compromising the testing dataset's real-world applicability.\n\nIn summary, the model is designed to be interpretable, with clear feature selection, hyperparameter tuning, and performance evaluation processes. This transparency makes it a promising tool for clinicians to identify whether COPD patients were continuously managed according to GOLD guidelines.",
  "model/output": "The model developed in our study is a multivariable classifier. It is designed to identify whether COPD patients were continuously managed according to GOLD guidelines in the previous year. The classifier uses variables from spirometry, BMI, and the frequency of moderate and severe AECOPD episodes. These features were selected using the Support Vector Machine Recursive Feature Elimination (SVM-RFE) algorithm, which helps optimize the performance of the classifier.\n\nThe model was built using the LibSVM algorithm and trained with hyperparameters estimated through grid-search and 10-fold cross-validation. The best hyperparameters identified were an RBF kernel, a cost parameter of 1, and gamma as scale. The performance of the classifier was assessed on a testing dataset that was not used during the training step. The model achieved a positive predictive value (PPV) of 66.7%, an F1 score of 0.978, an area under the ROC curve (AUC) of 0.987, and a kappa value of 0.788. These metrics indicate the model's effectiveness in classifying patients between the Managed group and the Control group.\n\nA sensitivity analysis was conducted by reducing the hyperparameter C to 0.1, and the testing results remained the same as those of the primary model, suggesting the robustness of our classifier. Additionally, the Synthetic Minority Over-sampling Technique (SMOTE) was used to address the imbalance in the training dataset, ensuring that the model could generalize well to real-world data. The features selected for the model include smoking history, post-bronchodilator FVC before management, and various post-1-year follow-up metrics such as BMI, AECOPD frequency, mMRC score, and lung function parameters. These features collectively contribute to the model's ability to accurately classify COPD patients based on their management status according to GOLD guidelines.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the classification model developed in this study is not publicly released. The model was built using the LibSVM algorithm and Python 3.5.5 programming language, along with the scikit-learn 20.0 library. However, these tools are widely available and can be accessed by researchers interested in replicating or building upon the work. The specific details of the implementation, including the hyperparameters and feature selection process, are described in the publication, allowing for potential replication or adaptation by other researchers in the field.",
  "evaluation/method": "The evaluation method for our study involved a comprehensive approach to ensure the robustness and generalizability of our model. We utilized a 10-fold cross-validation technique to train and estimate the hyperparameters of our support vector machine (SVM) model. This method helps in preventing overfitting and underfitting by providing a thorough search over specified parameter values.\n\nTo address the imbalance in the dataset, we employed the synthetic minority over-sampling technique (SMOTE) on the training dataset. This technique helps in balancing the class distribution, ensuring that the model does not have a bias towards the majority class. However, the testing dataset remained untouched to maintain a real-world scenario for evaluation.\n\nThe performance of the classifier was assessed using several metrics, including the positive predictive value (PPV), F1 score, area under the receiver operating characteristic curve (AUC), and kappa statistic. These metrics provide a holistic view of the model's performance, especially in handling the minority class.\n\nAdditionally, a sensitivity analysis was conducted by reducing the hyperparameter C to observe the model's robustness. The results remained consistent, suggesting that the model is stable and reliable. This analysis further confirms the optimal values of the hyperparameters used in the model.\n\nThe evaluation process also included assessing the model's ability to classify patients between the Managed group and the Control group in the testing sample. The results showed a good performance, indicating that the model has a good generalization capability.",
  "evaluation/measure": "In our study, we assessed the performance of our classification model using several key metrics to ensure a comprehensive evaluation. The primary metrics reported include the F1 score, Positive Predictive Value (PPV), and the Area Under the Receiver Operating Characteristic Curve (AUC). These metrics were chosen because they provide a balanced view of the model's performance, especially in the context of imbalanced datasets, which is common in medical research.\n\nThe F1 score is particularly useful as it combines precision and recall into a single metric, providing a measure of the model's accuracy that is especially informative when dealing with imbalanced classes. The PPV indicates the proportion of positive identifications that were actually correct, which is crucial for understanding the reliability of the model's positive predictions. The AUC provides a summary of the model's ability to distinguish between the two classes across all possible classification thresholds, offering a comprehensive view of the model's performance.\n\nAdditionally, we reported the kappa statistic, which measures the agreement between the predicted and actual classifications, adjusted for the agreement that could be expected by chance. This metric helps to ensure that the model's performance is not merely due to random guessing.\n\nThese performance metrics are widely recognized and used in the literature, making our evaluation representative and comparable to other studies in the field. The use of multiple metrics ensures that our model's performance is thoroughly assessed from different angles, providing a robust evaluation of its effectiveness in classifying whether COPD patients were continuously managed according to GOLD guidelines.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "The evaluation of our model's performance included several key metrics such as the positive predictive value (PPV), F1 score, and the area under the receiver operating characteristic curve (AUC). These metrics were calculated to assess the model's ability to classify whether COPD patients were continuously managed according to GOLD guidelines.\n\nThe PPV was reported as 66.7%, indicating the proportion of true positive predictions among all positive predictions made by the model. The F1 score, which balances precision and recall, was 0.978, suggesting a high level of accuracy in the model's predictions. The AUC was 0.987, demonstrating the model's strong discriminative ability.\n\nTo ensure the robustness of our results, we conducted a sensitivity analysis by reducing the hyperparameter C to 0.1. The testing results remained consistent with those of the primary model, confirming the model's stability and reliability.\n\nStatistical significance was evaluated using independent-samples t-tests or chi-square tests for patient characteristics, with p-values less than 0.05 considered statistically significant. This rigorous statistical approach ensures that the observed differences are not due to random chance.\n\nWhile specific confidence intervals for the performance metrics were not explicitly mentioned, the use of 10-fold cross-validation and the consistency of results in the sensitivity analysis provide a strong indication of the model's reliability and generalizability. The model's performance metrics, combined with the statistical significance of the results, support the claim that our method is effective and superior to simpler approaches.",
  "evaluation/availability": "The individual deidentified participant data, specific data, and other study documents are available from the corresponding author upon reasonable request. The data has been made available from July 2020, and this availability will last for 3 years. The ClinicalTrials.gov ID for this study is NCT03314077. This ensures that the raw evaluation files are accessible to researchers who wish to verify or build upon the findings presented in the study. The data sharing policy is designed to promote transparency and reproducibility in scientific research."
}