{
  "publication/title": "QUANTITATIVE OPTICAL COHERENCE TOMOGRAPHY ANGIOGRAPHY FEATURES FOR OBJECTIVE CLASSIFICATION AND STAGING OF DIABETIC RETINOPATHY.",
  "publication/authors": "Alam M, Zhang Y, Lim JI, Chan RVP, Yang M, Yao X",
  "publication/journal": "Retina (Philadelphia, Pa.)",
  "publication/year": "2020",
  "publication/pmid": "31972803",
  "publication/pmcid": "PMC6494740",
  "publication/doi": "10.1097/iae.0000000000002373",
  "publication/tags": "- Non-proliferative diabetic retinopathy\n- OCTA\n- Support vector machine\n- Classification\n- Machine learning\n- Image processing\n- Diabetic retinopathy\n- Computer-aided diagnosis\n- Feature extraction\n- ROC curve\n- Sensitivity\n- Specificity\n- Accuracy\n- AUC\n- Cross-validation\n- MATLAB\n- Image data processing\n- SVM classifier\n- Diagnostic prediction\n- Retinal imaging",
  "dataset/provenance": "The dataset used in this study was sourced from the University of Illinois at Chicago (UIC) Retinal Clinic. The study involved a retrospective analysis of consecutive diabetic patients (type II) who underwent OCTA and OCT imaging. The patients were representative of a university population of diabetic patients who required imaging for the management of diabetic macular edema and diabetic retinopathy (DR).\n\nThe dataset consisted of 120 OCTA images from 60 non-proliferative diabetic retinopathy (NPDR) patients and 40 images from 20 control subjects. Initially, there were 65 sets of NPDR patient data and 20 sets of control subjects\u2019 data, but 10 eyes were excluded due to poor OCTA acquisition or the presence of other retinal diseases. Among the NPDR OCTAs, there were 20 sets of mild, moderate, and severe stage data, totaling 40 OCTAs for each stage.\n\nThe OCTA images were acquired using an ANGIOVUE SD-OCT angiography system, which has a 70-KHz A-scan rate, an axial resolution of approximately 5 \u03bcm, and a lateral resolution of approximately 15 \u03bcm. All the OCTA images were macular scans with a field of view (FOV) of 6 mm \u00d7 6 mm. The images were exported from the software ReVue and processed using custom-developed MATLAB code.\n\nThe dataset was used to refine and extend established features for computer-aided classification of NPDR stages. The algorithm measured six OCTA features of control and disease subjects and inputted them into a support vector machine (SVM) model. The SVM classifier was trained with these features to provide a final diagnostic prediction. The classification performance was quantitatively validated using sensitivity, specificity, and accuracy metrics, along with graphical metrics such as the receiver operating characteristic (ROC) curve.\n\nThe dataset was also used in a previous study for the staging of sickle cell retinopathy (SCR) patients with three different classification models. It was observed that combined features showed the best accuracy for identifying SCR stages with an SVM classifier model. The current study builds upon these established features for the classification of NPDR stages.",
  "dataset/splits": "The dataset used in our study consisted of OCTA images from patients with non-proliferative diabetic retinopathy (NPDR) and control subjects. Initially, we had 65 sets of NPDR patient data and 20 sets of control subjects' data. However, we had to exclude 6 eyes due to poor OCTA acquisition and another 4 eyes due to the presence of other retinal diseases. This left us with 120 OCTA images from 60 NPDR patients and 40 images from 20 control subjects.\n\nFor the NPDR OCTAs, we had 20 sets of mild, moderate, and severe stage data, resulting in 40 OCTAs for each stage. The dataset was split into training and testing sets using a 5-fold cross-validation technique. This method involved dividing the data into five subsets, where four subsets were used for training and one subset was used for testing. This process was repeated five times, with each subset serving as the test set once. Additionally, multiple runs with different image data splits were implemented to confirm the robustness and repeatability of the computer-aided classification.\n\nThe distribution of data points in each split was designed to ensure that each fold had a representative sample of the different stages of NPDR and control subjects. This approach helped in controlling overfitting and provided a comprehensive evaluation of the classification model's performance.",
  "dataset/redundancy": "The dataset used in this study consisted of 120 OCTA images from 60 patients with non-proliferative diabetic retinopathy (NPDR) and 40 images from 20 control subjects. Initially, there were 65 sets of NPDR patient data and 20 sets of control subjects\u2019 data, but some were excluded due to poor OCTA acquisition or the presence of other retinal diseases.\n\nTo ensure the robustness and repeatability of the computer-aided classification, multiple runs with image data splits were implemented. A 5-fold cross-validation technique was used to control overfitting. This technique involves splitting the dataset into five subsets, where the model is trained on four subsets and tested on the remaining one. This process is repeated five times, with each subset serving as the test set once. This approach ensures that the training and test sets are independent in each iteration, providing a comprehensive evaluation of the model's performance.\n\nThe distribution of age, sex, and hypertension between the control and NPDR groups was analyzed, and no statistical significance was found. This indicates that the dataset is balanced in terms of these demographic factors, which is crucial for the reliability of the classification model.\n\nThe dataset's distribution compares favorably to previously published machine learning datasets in the field of diabetic retinopathy. The use of a diverse and well-characterized dataset, along with rigorous validation techniques, enhances the generalizability and clinical relevance of the findings.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Support Vector Machine (SVM). This is a well-established and widely used algorithm in the field of machine learning, particularly for classification tasks.\n\nThe SVM algorithm employed in our research is not entirely new, as SVM is a well-known technique in the machine-learning community. However, the specific implementation and application of SVM in our study are tailored to the unique challenges of classifying non-proliferative diabetic retinopathy (NPDR) stages using Optical Coherence Tomography Angiography (OCTA) images.\n\nThe reason this work was not published in a machine-learning journal is that the primary focus of our study is on the medical application and diagnostic performance of the algorithm rather than the development of new machine-learning techniques. Our research aims to demonstrate the effectiveness of SVM in identifying and classifying different stages of NPDR, which is a significant contribution to the field of ophthalmology and medical imaging. The innovation lies in the application of SVM to this specific medical problem, utilizing a combination of six quantitative OCTA features to achieve high accuracy in diagnosis. This approach highlights the potential of machine learning in improving diagnostic tools for retinal diseases, making it more relevant to medical and biomedical engineering journals.",
  "optimization/meta": "The model described in this publication does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The approach involves a Support Vector Machine (SVM) classifier that is trained directly on features extracted from OCTA images. These features include blood vessel tortuosity, blood vessel caliber, vessel perimeter index, blood vessel density, foveal avascular zone area, and foveal avascular zone contour irregularity.\n\nThe SVM classifier is implemented in MATLAB and is used for both binary and multi-class classification tasks. For binary classification, a one-versus-one class decision model is employed. For multi-class classification, a custom-coded SVM function in MATLAB allows for the prediction of multiple classes.\n\nThe classification performance is evaluated using metrics such as sensitivity, specificity, accuracy, and the area under the ROC curve (AUC). The model's robustness and repeatability are confirmed through multiple runs with image data splits and a 5-fold cross-validation technique to control overfitting.\n\nThe training data consists of OCTA images from 60 NPDR patients and 20 control subjects, with a total of 120 OCTA images from NPDR patients and 40 from control subjects. The data is split into training and test sets, and the independence of the training data is maintained through the use of cross-validation techniques. This ensures that the model's performance is evaluated on unseen data, providing a reliable assessment of its diagnostic capabilities.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for ensuring the reliability and performance of our machine-learning algorithm. We began by acquiring OCTA images with a specific field of view and resolution, which were then exported for further analysis. To standardize the images, we performed normalization based on maximum and minimum intensity values. This step was essential to account for variations in light and contrast across different images.\n\nFollowing normalization, we extracted six quantitative features from each OCTA image: BVT, BVC, VPI, BVD, FAZ-A, and FAZ-CI. These features were chosen for their relevance to the diagnosis and staging of non-proliferative diabetic retinopathy (NPDR). The feature extraction process involved detailed procedures to measure each feature accurately. For instance, the segmented foveal avascular zone (FAZ) area was excluded when measuring the blood vessel density (BVD) to improve diagnostic accuracy.\n\nThe extracted features were then compiled and used to train our support vector machine (SVM) classifier. The classifier was implemented in MATLAB and utilized a custom-coded SVM function for multi-class classification. This function allowed for the prediction of multiple classes, which was essential for distinguishing between control subjects and different stages of NPDR.\n\nTo ensure the robustness and repeatability of our classification model, we employed a 5-fold cross-validation technique. This method helped control overfitting and was complemented by multiple runs with different image data splits. The preprocessing and feature extraction steps were designed to enhance the overall reliability of the extracted features, thereby improving the performance of the classifier model in identifying OCTAs of different stages of NPDR.",
  "optimization/parameters": "In our study, we utilized six quantitative OCTA features as input parameters for our model. These parameters were selected based on their ability to reflect various morphological aspects of the diseased retina. The parameters included blood vessel tortuosity (BVT), blood vessel caliber (BVC), vessel perimeter index (VPI), blood vessel density (BVD), foveal avascular zone area (FAZ-A), and foveal avascular zone contour irregularity (FAZ-CI). These features were chosen because they provide a comprehensive quantitative analysis of pathological changes due to retinal diseases, such as non-proliferative diabetic retinopathy (NPDR), and their progression.\n\nThe selection of these parameters was informed by our previous work, where we conducted a comprehensive analysis of OCTA images of sickle cell retinopathy (SCR) patients and established these six parameters as potential OCTA biomarkers. We validated the computer-aided classification of SCR stages using an SVM classifier model with these six features and obtained high accuracy. In the current study, we adapted this strategy for DR OCTA images, demonstrating the importance of quantitative analysis alongside qualitative observation in DR staging.\n\nThe six parameters were chosen because they show low correlation among each other, except for BVD and VPI when compared in a 6 mm field of view (excluding the foveal avascular zone). This low correlation suggests that each parameter reflects different morphological aspects of the diseased retina, making them objective and suitable for combining to yield better classification performance. The combination of these features enhanced the classification performance, achieving high sensitivity, specificity, and accuracy in identifying NPDR from control subjects.",
  "optimization/features": "In our study, we utilized six quantitative features extracted from each OCTA image as input for our classification model. These features are:\n\n* Blood vessel tortuosity (BVT)\n* Blood vessel caliber (BVC)\n* Vessel perimeter index (VPI)\n* Blood vessel density (BVD)\n* Foveal avascular zone area (FAZ-A)\n* Foveal avascular zone contour irregularity (FAZ-CI)\n\nFeature selection was not performed in the traditional sense, as we aimed to leverage the combined power of these six features to enhance classification performance. Instead of selecting a subset of features, we combined all six features together to achieve improved diagnostic accuracy. The segmented FAZ area was excluded when measuring BVD to ensure the reliability of the extracted features.\n\nThe rationale behind each of these features and the detailed procedures for measuring them have been described in our recent publication. The combination of these features allowed our SVM model to achieve high sensitivity, specificity, and accuracy in both control vs. disease and control vs. mild NPDR classifications.",
  "optimization/fitting": "In our study, we employed a Support Vector Machine (SVM) classifier for the identification of Non-Proliferative Diabetic Retinopathy (NPDR) stages. The classification process was divided into two segments: binary classification (control vs. disease) and multi-class classification (control vs. mild, moderate, and severe NPDR).\n\nTo address the potential issue of overfitting, given that the number of parameters could be large relative to the number of training points, we implemented a 5-fold cross-validation technique. This method helps to ensure that the model generalizes well to unseen data by training and validating on different subsets of the data. Additionally, we conducted multiple runs with different image data splits to confirm the robustness and repeatability of the computer-aided classification.\n\nFor the binary classification, we used a one-versus-one class decision model. In the multi-class classification, a custom-coded SVM function in MATLAB was utilized, which allows for the prediction of multiple classes. The average time for processing a single OCTA image and extracting the feature vectors was approximately 5 seconds. The classification process for binary and multi-class predictions took about 3\u20135 seconds and 8\u201310 seconds, respectively.\n\nTo evaluate the performance of the SVM prediction model, we calculated sensitivity, specificity, and accuracy for the control vs. disease and control vs. mild NPDR classifications. For multi-class classification, overall accuracy and error rate were measured. The Receiver Operating Characteristic (ROC) curve was used to evaluate the model's prediction performance, with the Area Under the Curve (AUC) quantifying how well the classifier could identify different classes. An AUC close to 1 indicates high accuracy, while an AUC of 0.5 indicates poor performance.\n\nIn summary, our approach included rigorous validation techniques to mitigate overfitting and ensure the model's reliability and generalizability. The use of cross-validation and multiple data splits provided a comprehensive assessment of the model's performance, confirming its robustness in identifying NPDR stages.",
  "optimization/regularization": "To prevent overfitting in our classification models, we employed a 5-fold cross-validation technique. This method involves dividing the dataset into five subsets, training the model on four of these subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. By averaging the results, we ensure that the model's performance is robust and not dependent on a particular subset of data.\n\nAdditionally, we implemented multiple runs with different image data splits to confirm the robustness and repeatability of our computer-aided classification. This approach helps in validating that the model generalizes well to unseen data and is not merely memorizing the training set. These techniques collectively enhance the reliability and accuracy of our classification model.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the provided information. However, the methodology section describes the use of a support vector machine (SVM) classifier implemented in MATLAB. The SVM model was trained using a feature set compiled from OCTA data, and the classification performance was validated using sensitivity, specificity, and accuracy metrics, along with ROC curves.\n\nThe specific hyper-parameters, such as the kernel type, regularization parameter, and other SVM-specific settings, are not reported. Similarly, the optimization schedule and model files are not mentioned. Therefore, it is not clear whether these details are available for public access or under any specific license.\n\nThe study does mention the use of a 5-fold cross-validation technique to control overfitting and ensure the robustness of the classification model. This technique is a standard practice in machine learning to evaluate the performance of a model and to prevent overfitting to the training data. However, the exact parameters and settings used for cross-validation are not specified.\n\nIn summary, while the general approach and some performance metrics are reported, the specific hyper-parameter configurations, optimization schedule, model files, and optimization parameters are not detailed. Therefore, it is not possible to provide information on their availability or licensing.",
  "model/interpretability": "The model employed in our study is not a black box; it is designed to be interpretable through the use of specific, quantifiable features derived from OCTA images. These features include BVT, BVC, VPI, BVD, FAZ-A, and FAZ-CI, which provide a comprehensive quantitative analysis of pathological changes due to retinal diseases like NPDR.\n\nThe model's transparency is evident in how it utilizes these features. For instance, BVD, which reflects overall density changes in the retina, was found to be the most sensitive single feature for classification. Further analysis showed that the perifoveal region, particularly the temporal region, provided the highest sensitivity in predicting the onset of mild NPDR. This level of detail allows for a clear understanding of which aspects of the OCTA images are most indicative of disease presence and severity.\n\nAdditionally, the use of a support vector machine (SVM) classifier model, which is trained on these compiled features, ensures that the diagnostic predictions are based on objective, measurable criteria. The model's performance was validated using sensitivity, specificity, and accuracy metrics, as well as ROC curves, providing a robust evaluation of its predictive capabilities.\n\nThe interpretability of the model is further enhanced by the low correlation observed among the six quantitative parameters, except for BVD and VPI. This indicates that each feature contributes uniquely to the classification process, making the model's decisions more transparent and less reliant on redundant information.",
  "model/output": "The model employed in our study is a classification model. Specifically, we utilized a support vector machine (SVM) classifier to distinguish between different stages of non-proliferative diabetic retinopathy (NPDR) and control subjects. The classification tasks included both binary classification, where the model identified control versus disease, and multi-class classification, where the model differentiated between control and three stages of NPDR (mild, moderate, and severe). The SVM model was trained using a set of six quantitative OCTA features, including BVT, BVC, VPI, BVD, FAZ-A, and FAZ-CI. These features were extracted from OCTA images and compiled to train the classifier. The performance of the model was evaluated using metrics such as sensitivity, specificity, accuracy, and the area under the ROC curve (AUC). The model demonstrated high accuracy in both binary and multi-class classification tasks, indicating its effectiveness in diagnosing and staging NPDR.",
  "model/duration": "The execution time for our model varied depending on the type of classification task. For feature extraction from a single OCTA image, it took approximately 5 seconds. The binary classification tasks, which included control vs. disease and control vs. mild NPDR, each took between 3 to 5 seconds. For the multi-class classification, which involved distinguishing between control and three stages of NPDR (mild, moderate, and severe), the process took around 8 to 10 seconds. These times were measured on a 4-core desktop computer with a Windows-7 64-bit operating system, equipped with a Core i7\u20134770 CPU at 3.4 GHz and 16 GB of RAM. The classification algorithm was implemented in MATLAB.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed for our study involved a comprehensive approach to ensure the robustness and accuracy of our classification model. We utilized a 5-fold cross-validation technique to mitigate overfitting and to validate the model's performance. This technique involved splitting the dataset into five subsets, where the model was trained on four subsets and tested on the remaining one, repeating this process five times with different subsets.\n\nIn addition to cross-validation, we implemented multiple runs with different image data splits to confirm the repeatability and reliability of our computer-aided classification. This approach helped in assessing the model's consistency across various datasets.\n\nFor the binary classification task, which involved distinguishing between control and disease (NPDR) states, we used a one-versus-one class decision model within the SVM framework. This method allowed for a clear differentiation between the two classes.\n\nIn the multi-class classification scenario, where the goal was to identify control and three stages of NPDR (mild, moderate, and severe), we developed a custom-coded SVM function in MATLAB. This function enabled the prediction of multiple classes, providing a more nuanced diagnostic output.\n\nThe performance of our SVM prediction model was evaluated using several metrics. For the binary classification, we calculated sensitivity, specificity, and accuracy to assess the model's ability to correctly identify cases. Sensitivity and specificity provided insights into the true positive and true negative rates, respectively, while accuracy offered a balanced representation of the model's overall performance.\n\nFor the multi-class classification, we measured overall accuracy and error rate to evaluate the classification performance. These metrics helped in understanding how well the model could distinguish between the different stages of NPDR.\n\nFurthermore, we employed the Receiver Operating Characteristics (ROC) curve to graphically evaluate the model's prediction performance. The ROC curve plotted the true positive rate (sensitivity) against the false positive rate (1-specificity) at various threshold settings. The Area Under the Curve (AUC) was calculated to quantify the model's ability to discriminate between the classes. An AUC close to 1 indicated a highly accurate model, while an AUC of 0.5 suggested a model with no discriminative power.\n\nThe significance of our statistical tests was considered at a P-value of less than 0.05, ensuring that our findings were statistically robust. Overall, our evaluation method combined cross-validation, multiple runs with different data splits, and comprehensive performance metrics to validate the effectiveness and reliability of our classification model.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our classification models. The primary metrics reported are sensitivity, specificity, accuracy, and the area under the receiver operating characteristic curve (AUC). These metrics provide a comprehensive evaluation of the model's performance in distinguishing between different classes.\n\nSensitivity, also known as the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, indicates the proportion of actual negatives that are correctly identified. Accuracy provides an overall measure of the model's performance by calculating the proportion of true results (both true positives and true negatives) among the total number of cases examined.\n\nThe AUC is a crucial metric that quantifies the model's ability to discriminate between classes. It ranges from 0 to 1, where a value of 1 indicates perfect discrimination and a value of 0.5 indicates no discrimination ability. The AUC provides a single scalar value that summarizes the performance of the classifier across all possible classification thresholds.\n\nIn addition to these metrics, we also considered the overall accuracy and error rate for multi-class classification. These metrics help in evaluating the model's performance when dealing with multiple classes simultaneously.\n\nThe set of metrics used in our study is representative of standard practices in the literature. Sensitivity, specificity, accuracy, and AUC are commonly reported metrics in medical diagnostic studies and machine learning evaluations. These metrics provide a balanced and comprehensive representation of the classification performance, ensuring that our results are comparable to other studies in the field.\n\nNot applicable.",
  "evaluation/comparison": "In our study, we focused on evaluating the performance of our Support Vector Machine (SVM) model using various features extracted from Optical Coherence Tomography Angiography (OCTA) images. We did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, our evaluation centered on the effectiveness of different features and their combinations in distinguishing between control subjects and those with Non-Proliferative Diabetic Retinopathy (NPDR), particularly in the mild stage.\n\nWe compared the performance of single features such as Blood Vessel Tortuosity (BVT), Blood Vessel Caliber (BVC), Vessel Perimeter Index (VPI), Blood Vessel Density (BVD), Foveal Avascular Zone Area (FAZ-A), and Foveal Avascular Zone Contour Irregularity (FAZ-CI). Each of these features was assessed individually for its ability to classify control vs. disease and control vs. mild NPDR. The results, presented in a performance comparison table, showed varying levels of sensitivity, specificity, accuracy, and Area Under the Curve (AUC) for each feature.\n\nAdditionally, we combined all six features to observe if the classification performance could be enhanced. The combined-features approach yielded the highest sensitivity, specificity, and accuracy for both control vs. disease and control vs. mild NPDR classifications. This indicates that integrating multiple features provides a more robust and accurate predictive model.\n\nWhile we did not compare our method to simpler baselines or publicly available datasets, our focus was on demonstrating the efficacy of our feature-based approach in identifying NPDR, especially in its early stages. The high AUC values and classification metrics for the combined-features model underscore the potential of our method in clinical settings for early detection and diagnosis of NPDR.",
  "evaluation/confidence": "The evaluation of our model's performance included several key metrics such as sensitivity, specificity, accuracy, and the area under the ROC curve (AUC). These metrics were calculated to assess the model's ability to distinguish between control subjects and those with non-proliferative diabetic retinopathy (NPDR), including the mild stage.\n\nConfidence intervals for these performance metrics were not explicitly provided in the results. However, the use of a 5-fold cross-validation technique and multiple runs with image data splits ensured that the results were robust and repeatable, reducing the likelihood of overfitting and providing a measure of confidence in the model's performance.\n\nStatistical significance was considered for all tests used in the study, with a threshold of P < 0.05. This indicates that the results are statistically significant, supporting the claim that the model performs well in identifying NPDR from control subjects. The high AUC values, exceeding 90% for both control vs. disease and control vs. mild NPDR classifications using combined features, further establish the model's strong predictive capability. The detailed comparison of sensitivity, specificity, and accuracy in Table 3 also highlights the model's superior performance, particularly when combining all six features.",
  "evaluation/availability": "Not enough information is available."
}