{
  "publication/title": "Deep Learning to Optimize Magnetic Resonance Imaging Prediction of Motor Outcomes After Hypoxic-Ischemic Encephalopathy.",
  "publication/authors": "Vesoulis ZA, Trivedi SB, Morris HF, McKinstry RC, Li Y, Mathur AM, Wu YW",
  "publication/journal": "Pediatric neurology",
  "publication/year": "2023",
  "publication/pmid": "37774643",
  "publication/pmcid": "PMC10842950",
  "publication/doi": "10.1016/j.pediatrneurol.2023.09.001",
  "publication/tags": "- Machine Learning\n- Neonatal Hypoxic-Ischemic Encephalopathy\n- Therapeutic Hypothermia\n- MRI\n- Predictive Modeling\n- Deep Learning\n- Logistic Regression\n- Neurodevelopmental Outcomes\n- Pediatric Neurology\n- Feature Selection\n- SHAP Scores\n- Clinical Variables\n- Cross-Validation\n- Model Optimization\n- Infant Outcomes",
  "dataset/provenance": "The dataset used in this study is derived from a secondary analysis of infants enrolled in three existing research cohorts focused on hypoxic-ischemic encephalopathy (HIE). These cohorts include a single-site historical cohort from Washington University School of Medicine (WUSM) and two multicenter randomized clinical trial cohorts: NEAT (NCT00719407) and NEATO (NCT01913340). The study included a total of 117 infants, with 21 from NEAT, 39 from NEATO, and 57 from the WUSM historic cohort.\n\nThe infants in the study met specific inclusion criteria, such as a gestational age of at least 36 weeks, perinatal depression, and moderate or severe neonatal encephalopathy. Exclusion criteria included being small for gestational age, being older than 23.5 hours at the time of recruitment, having severe congenital anomalies, microcephaly, polycythemia, hypertension, or lack of central or peripheral indwelling catheter. Additionally, infants without interpretable MRI scans were excluded.\n\nThe dataset comprises standard clinical variables, including the severity of encephalopathy, Apgar score at 10 minutes, worst arterial cord or infant blood gas pH within one hour of age, erythropoietin dosing, completed weeks of gestation, and birth weight. All infants underwent formal developmental testing between 12 and 24 months using either the Alberta Infant Motor Scale (AIMS) or the Bayley Scales of Infant Development, Third Edition (BSID-III). Adverse motor outcomes were defined as a Bayley-III motor score of less than 85 or an AIMS score below the 10th centile.\n\nMRI images were scored by experienced reviewers using a system that assigns a numeric score indicating the severity of injury in various brain regions across T1, T2, and DWI sequences. The scores were summed and categorized into severity levels: no injury, mild injury, moderate injury, and severe injury.\n\nThe dataset has been used to develop and validate machine learning models aimed at predicting adverse motor outcomes in newborns with HIE treated with therapeutic hypothermia. The models utilized a combination of MRI and clinical variables to achieve high predictive accuracy. The study's findings contribute to the existing literature on HIE and provide a foundation for future research with larger and more diverse datasets.",
  "dataset/splits": "The dataset was split into training and validation cohorts with an 80/20 distribution, respectively. This means that 80% of the data was used for training the models, while the remaining 20% was used for validation. Additionally, five-fold cross-validation was performed. This involved dividing the overall cohort into five equal parts. Each part was used for validation once and for training four times, ensuring that every data point was used for both training and validation. This approach helps in making efficient use of the cohort and reducing the risk of overfitting.",
  "dataset/redundancy": "The dataset used in this study consisted of 117 infants, with minimal missing data. To develop and validate our machine learning models, we employed an 80/20 training-validation split, ensuring that the training and validation cohorts were independent. This split was achieved by randomly sampling infants, which helped to maintain the integrity and independence of the datasets.\n\nFor the deep learning models, we utilized five-fold cross-validation. This process involved dividing the overall cohort into five equal parts. Each part was used for validation once and for training four times, ensuring that every data point was used for both training and validation. This method helped to efficiently use the cohort and reduce the risk of overfitting.\n\nIn the logistic regression models, a similar 80/20 training-validation split was applied. However, due to the limitations of logistic regression in handling missing data, two variables (cord pH and 10-minute Apgar) with missing values were excluded from the analysis. This step was necessary to ensure that the evaluation process at each step required equal row counts, maintaining the independence and comparability of the datasets.\n\nThe distribution of our dataset is comparable to previously published studies on hypoxic-ischemic encephalopathy (HIE) and MRI, which typically range between 53 and 173 subjects. This sample size, while somewhat small for a machine learning investigation, was efficiently utilized through cross-validation techniques. The mean gestational age was 38.6 \u00b1 1.6 weeks, and the mean birth weight was 3291 \u00b1 608 grams, providing a representative sample of the population under study.",
  "dataset/availability": "The dataset used in this study is not publicly available due to privacy restrictions. This decision was made to protect the sensitive information of the infants involved in the study. The data includes detailed clinical and imaging information that could potentially identify individual participants, which is why it has not been released in a public forum.\n\nHowever, the code for the deep learning algorithm developed for this study is available under the GNU General Public License. This code can be accessed at the following GitHub repository: [https://github.com/zvesoulis/ml_mri](https://github.com/zvesoulis/ml_mri). The availability of the code allows other researchers to replicate the study's findings and build upon the work, while ensuring that the privacy of the participants is maintained. The GNU General Public License ensures that the code can be freely used, modified, and distributed, provided that any derivative works are also released under the same license.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is deep learning, specifically implemented through the XGBoost library. XGBoost is a well-established and widely used gradient boosting framework that has proven effective in various predictive modeling tasks.\n\nThe algorithm used is not new; it is a established method in the field of machine learning. XGBoost has been extensively validated and optimized over time, making it a reliable choice for our research. The decision to use XGBoost was driven by its robustness, efficiency, and ability to handle complex datasets, which are crucial for achieving accurate predictions in medical research.\n\nGiven that XGBoost is a mature and widely recognized algorithm, it was not necessary to publish it in a machine-learning journal. Instead, our focus was on applying this algorithm to a specific medical context\u2014predicting adverse motor outcomes in newborns with hypoxic-ischemic encephalopathy (HIE) treated with therapeutic hypothermia. The novelty of our work lies in the application of this algorithm to this particular medical problem, rather than in the development of a new algorithm. This approach allows us to leverage the strengths of existing machine-learning techniques to address important clinical questions.",
  "optimization/meta": "The models developed in this study do not use data from other machine-learning algorithms as input. Instead, they utilize a combination of MRI features and clinical variables to predict adverse motor outcomes in infants with hypoxic-ischemic encephalopathy (HIE) who received therapeutic hypothermia.\n\nThe study employed two primary types of models: deep learning models using the XGBoost library and logistic regression models implemented in R. The deep learning approach involved creating a parsimonious model through feature reduction using SHAP scores, which identify the most important variables for prediction. The logistic regression models included a baseline model using categorical MRI scores, a stepwise regression model, and a LASSO regression model, each aiming to optimize feature selection and model performance.\n\nThe training and validation cohorts were created with an 80/20 split, ensuring that the data used for training and validation were independent. This split was performed randomly, and five-fold cross-validation was used to further ensure that each part of the cohort was used for validation once and training four times, reducing the risk of overfitting.\n\nIn summary, the models are not meta-predictors but rather standalone predictive models that utilize specific machine-learning techniques to identify the most relevant features for predicting adverse motor outcomes in infants with HIE. The training data independence is maintained through random splitting and cross-validation techniques.",
  "optimization/encoding": "For the machine learning models, particularly the deep learning approach using XGBoost, several steps were taken to encode and preprocess the data. Initially, new variables were created by summing specific components, such as the right and left hemispheres, subcortical components, and cortical components. This step helped in examining all possible element combinations.\n\nClinical variables included gestational age, birth weight, the worst degree of encephalopathy in the first six hours, cord blood gas pH, and the 10-minute Apgar score. These variables, along with the MRI scoring components, were used to create a comprehensive set of candidate features.\n\nTo prepare the data for the machine learning models, an 80/20 training-validation split was employed, with infants sampled at random. This split ensured that the model could be trained on a substantial portion of the data while reserving a portion for validation to assess its performance.\n\nFor the deep learning model, the XGBoost library version 1.2.1 was used, implemented in a Python script with the Scikit-learn framework. The optimal values for three key parameters\u2014learning rate, number of estimators, and decision tree size\u2014were determined through grid search. This process involved evaluating various parameter combinations to maximize model performance while minimizing the risk of overfitting.\n\nFeature importance was assessed using SHAP (Shapley Additive Explanation) scores, which quantify the contribution of each feature to the overall prediction. SHAP scores were evaluated across two domains: SHAP value and feature value. Features with high SHAP values and distinct clustering by feature value were considered ideal predictors.\n\nTo further refine the model, feature selection and pruning were performed using SHAP scores. This step involved removing features of low importance to enhance model accuracy. Five-fold cross-validation was conducted to efficiently use the cohort and reduce the risk of overfitting. This involved dividing the overall cohort into five equal parts and performing training and validation steps so that each part was used for validation once and training four times.\n\nFor the logistic regression models, implemented in R version 4.2.0, a similar 80/20 training-validation split was used. Optimal feature selection was achieved using a stepwise algorithm in the backwards direction, maximizing the Akaike information criterion (AIC). This process involved starting with the maximal number of variables and sequentially removing those that did not improve the model's performance.\n\nAdditionally, LASSO regression was employed to handle multicollinearity. Ten-fold cross-validation was performed to identify the lambda value that produced the lowest test mean squared error. Coefficient shrinkage was used to select out poorly predictive factors by setting their coefficients to zero.\n\nIn summary, the data encoding and preprocessing involved creating new variables, using clinical and MRI scoring components, splitting the data for training and validation, optimizing parameters through grid search, assessing feature importance with SHAP scores, and employing cross-validation techniques to ensure robust model performance.",
  "optimization/parameters": "In our study, we utilized a deep learning approach implemented using the XGBoost library. For this model, we focused on optimizing three key parameters: the learning rate, the number of estimators, and the decision tree size. The selection of these parameters was performed through a grid search method. This involved evaluating various combinations of these parameters to identify the optimal values that maximized model performance while minimizing the risk of overfitting. The specific values evaluated during this tuning process can be found in Supplemental Table 2. The optimal parameters were chosen to ensure that the model achieved the best possible accuracy and generalization to new data.",
  "optimization/features": "In our study, we initially considered a comprehensive set of features, including 76 MRI scoring components and several clinical variables. The clinical variables included gestational age, birth weight, the worst degree of encephalopathy in the first six hours, cord blood gas pH, and the 10-minute Apgar score.\n\nFeature selection was indeed performed to identify the most relevant features for predicting adverse motor outcomes. For the deep learning model, we used SHAP (Shapley Additive Explanation) scores to evaluate the importance of each feature. Features with low SHAP scores were pruned to enhance model accuracy and reduce the risk of overfitting. This process was conducted using the training set only, ensuring that the validation set remained unbiased.\n\nFor the logistic regression models, feature selection was accomplished using two different methods: stepwise regression and LASSO regression. The stepwise regression employed a backwards elimination approach, starting with all features and sequentially removing those that did not improve the model's performance as measured by the Akaike Information Criterion (AIC). LASSO regression, on the other hand, used coefficient shrinkage to select the most predictive features by setting the coefficients of poorly predictive factors to zero. Both methods were applied to the training set to ensure that the validation process was not influenced by the feature selection.\n\nThe final models utilized a reduced set of features, demonstrating that a parsimonious combination of salient variables can achieve high predictive accuracy. For instance, the parsimonious deep learning model identified putamen/globus pallidus injury on T1, gestational age, and cord pH as the most important features, achieving an accuracy of 85%.",
  "optimization/fitting": "In our study, we employed both deep learning and logistic regression models to predict adverse motor outcomes in infants with hypoxic-ischemic encephalopathy (HIE). The number of candidate variables, including MRI features and clinical variables, was substantial, potentially larger than the number of training points. To address this, we implemented several strategies to mitigate overfitting and ensure robust model performance.\n\nFor the deep learning model, we used the XGBoost library and performed grid search to optimize three key parameters: learning rate, number of estimators, and decision tree size. This process helped in finding the optimal parameter values that maximized model performance while minimizing the risk of overfitting. Additionally, we utilized five-fold cross-validation, which involved dividing the cohort into five equal parts and performing training and validation steps so that each part was used for validation once and training four times. This technique ensured that the model generalized well to unseen data.\n\nTo further reduce the risk of overfitting, we employed SHAP (Shapley Additive Explanation) scores to evaluate feature importance. Features with low SHAP scores were pruned from the model, resulting in a more parsimonious model that retained only the most predictive variables. This feature selection process not only improved model accuracy but also reduced the complexity of the model, making it more interpretable and less prone to overfitting.\n\nFor the logistic regression models, we used stepwise regression and LASSO (Least Absolute Shrinkage and Selection Operator) regression to handle multicollinearity and perform feature selection. The stepwise regression model started with all variables and sequentially removed those that did not improve the model's performance, as measured by the Akaike Information Criterion (AIC). LASSO regression, on the other hand, performed coefficient shrinkage, setting the coefficients of poorly predictive variables to zero. This approach helped in selecting a subset of relevant features and mitigating the risk of overfitting.\n\nTo rule out underfitting, we compared the performance of different models using metrics such as accuracy, precision, recall, and area under the receiver-operator curve (AUC). The parsimonious deep learning model, which underwent feature reduction by SHAP scores, achieved the highest accuracy and AUC, indicating that it captured the underlying patterns in the data without being too simplistic. Similarly, the stepwise and LASSO logistic regression models demonstrated improved performance compared to the baseline model, suggesting that they effectively captured the relevant information in the data.\n\nIn summary, we employed a combination of parameter tuning, cross-validation, feature selection, and model comparison to address the challenges of overfitting and underfitting in our study. These strategies ensured that our models were robust, generalizable, and capable of accurately predicting adverse motor outcomes in infants with HIE.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our models. For the deep learning approach using XGBoost, we utilized grid search to optimize the model parameters, specifically the learning rate, number of estimators, and decision tree size. This process helped in finding the optimal values that maximize model performance while minimizing the risk of overfitting.\n\nAdditionally, we implemented five-fold cross-validation. This involved dividing the cohort into five equal parts, where each part was used for validation once and for training four times. This method ensures that the model is trained and validated on different subsets of the data, reducing the likelihood of overfitting to any specific part of the dataset.\n\nFor the logistic regression models, we employed stepwise regression and LASSO (Least Absolute Shrinkage and Selection Operator) regression. Stepwise regression helped in selecting the most relevant features by sequentially removing variables that did not improve the model's performance, as measured by the Akaike Information Criterion (AIC). LASSO regression, on the other hand, is robust to multicollinearity and performs feature selection by shrinking the coefficients of less important variables to zero, thereby reducing the model complexity and preventing overfitting.\n\nFurthermore, we calculated SHAP (Shapley Additive Explanation) scores to determine the importance of each feature. Features with low SHAP scores were pruned from the model, ensuring that only the most predictive variables were retained. This feature selection process also aids in reducing overfitting by simplifying the model.\n\nIn summary, our study incorporated grid search, cross-validation, stepwise regression, LASSO regression, and SHAP score-based feature selection to prevent overfitting and enhance the generalizability of our models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in detail. Specifically, for the deep learning model, we utilized the XGBoost library in Python with Scikit-learn. The optimal values for the learning rate, number of estimators, and decision tree size were determined through grid search, and these values are documented in Supplemental Table 2. The model files and optimization parameters are not directly provided in the publication but the code for the deep learning algorithm is available under the GNU General Public License at the following GitHub repository: https://github.com/zvesoulis/ml_mri. This repository contains the scripts and configurations used for training and validating our models, allowing for reproducibility and further exploration.",
  "model/interpretability": "The models developed in this study are not entirely black-box, as efforts were made to enhance their interpretability. To achieve this, SHAP (Shapley Additive Explanation) scores were calculated for each feature in the deep learning model. SHAP scores provide a way to understand the contribution of each feature to the overall prediction, making the model more transparent. These scores are evaluated across two domains: SHAP value and feature value. A high SHAP value indicates a strong association with the outcome, while distinct clustering by feature value suggests that certain feature values are strongly associated with specific outcomes.\n\nFor instance, features like putamen/globus pallidus injury on T1, gestational age, and cord pH were identified as high-performing elements based on their SHAP scores. This means that these features significantly contribute to the model's predictions, and their values can be distinctly linked to the predicted outcomes. By using SHAP scores, it is possible to identify which features are most important and how they influence the model's decisions, thereby reducing the black-box nature of the deep learning model.\n\nIn the logistic regression model, feature selection was performed using a stepwise algorithm in the backwards direction by maximal Akaike information criterion (AIC). This process involved sequentially removing variables to minimize the AIC, which measures model error and quality. The final logistic regression model included specific components such as putamen/globus pallidus DWI left, putamen/globus pallidus T1 left, and gestational age, among others. This approach provides a clear understanding of which variables are most relevant to the model's predictions, enhancing its transparency.\n\nOverall, the use of SHAP scores in the deep learning model and the stepwise feature selection in the logistic regression model ensures that the models are not entirely black-box. These techniques allow for a clearer understanding of how individual features contribute to the predictions, making the models more interpretable.",
  "model/output": "The models developed in this study are primarily classification models. They are designed to predict adverse motor outcomes in infants with hypoxic-ischemic encephalopathy (HIE) who received therapeutic hypothermia. The models use various machine learning and logistic regression techniques to classify infants into categories based on their likelihood of experiencing adverse motor outcomes.\n\nSeveral models were created and compared, including baseline logistic regression (LR) models, stepwise LR models, LASSO regression models, and deep learning (DL) models. The performance of these models was evaluated using metrics such as accuracy, precision, recall, and the area under the receiver-operator curve (AUC). The deep learning models, particularly the parsimonious DL model, showed notable improvements in accuracy and AUC, indicating their effectiveness in classifying outcomes.\n\nThe parsimonious DL model, which underwent feature reduction using SHAP scores, achieved the highest accuracy of 85% and the highest AUC of 0.75. This model used a combination of MRI features and clinical variables to make predictions, demonstrating the potential of machine learning in improving outcome prediction for infants with HIE. The logistic regression models, while also useful, had varying levels of performance, with the baseline LR model showing the lowest accuracy and precision. The stepwise and LASSO regression models performed better, with accuracies of 80% and similar recall values.\n\nIn summary, the models developed are classification models aimed at predicting adverse motor outcomes in infants with HIE. The deep learning models, particularly the parsimonious DL model, showed superior performance compared to the logistic regression models.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the models involved several key steps to ensure robustness and accuracy. For the deep learning models, five-fold cross-validation was employed. This process divided the overall cohort into five equal parts, with each part used for validation once and for training four times. This approach helped to efficiently use the cohort and reduce the risk of overfitting.\n\nFor the logistic regression models, an 80/20 training-validation split was used, with infants selected at random. The performance of all models was assessed using several metrics: accuracy, precision, recall, and the area under the receiver-operator curve (AUC). Accuracy was defined as the ratio of correctly predicted observations to the total observations. Precision was the ratio of correctly predicted positive observations to the total predicted positives. Recall was the ratio of true positives to the sum of false positives and false negatives. The AUC provided a measure of the model's ability to distinguish between positive and negative classes.\n\nThe deep learning models were evaluated using three different approaches. The first used the categorical severity score of the MRI as originally published. The second utilized all MRI scoring components and clinical variables. The third employed feature reduction by SHAP scores to create a more parsimonious model.\n\nThe logistic regression models included a baseline model using the categorical severity score of the MRI, a stepwise model that used a backwards selection algorithm to minimize the Akaike information criterion (AIC), and a LASSO regression model that employed coefficient shrinkage to handle multicollinearity and select the most predictive features.\n\nIn summary, the evaluation methods ensured a comprehensive assessment of model performance, utilizing cross-validation, multiple performance metrics, and various model configurations to identify the most accurate and efficient predictors of adverse motor outcomes in newborns with hypoxic-ischemic encephalopathy treated with therapeutic hypothermia.",
  "evaluation/measure": "The performance of the models was evaluated using several key metrics to ensure a comprehensive assessment. These metrics included accuracy, precision, recall, and the area under the receiver-operator curve (AUC). Accuracy measures the ratio of correctly predicted observations to the total number of observations, providing an overall sense of the model's correctness. Precision, on the other hand, focuses on the ratio of correctly predicted positive observations to the total predicted positives, which is crucial for understanding the reliability of positive predictions. Recall, also known as sensitivity, assesses the ratio of true positives to the sum of true positives and false negatives, highlighting the model's ability to identify all relevant instances. The AUC provides a single scalar value that represents the ability of the model to distinguish between classes, with higher values indicating better performance.\n\nThese metrics are widely used in the literature and are considered representative for evaluating the performance of predictive models, especially in medical and machine learning contexts. The choice of these metrics ensures that the models are assessed not only on their overall correctness but also on their ability to correctly identify positive cases and their discriminative power. This set of metrics allows for a thorough evaluation of the models' strengths and weaknesses, providing a clear picture of their performance in predicting adverse motor outcomes in infants with hypoxic-ischemic encephalopathy (HIE) who received therapeutic hypothermia.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of various models to evaluate their performance in predicting adverse motor outcomes in infants with hypoxic-ischemic encephalopathy (HIE) who received therapeutic hypothermia. We assessed both logistic regression (LR) and machine learning (ML) models, including baseline models, stepwise models, LASSO regression, and models utilizing all MRI features and clinical variables.\n\nFor logistic regression, we started with a baseline model that used the categorical severity score of the MRI, which served as a validation of the original scoring system. We then built stepwise and LASSO regression models, reducing features until the Akaike information criterion (AIC) was minimized. This approach allowed us to compare the performance of more complex models against a simpler baseline.\n\nIn the machine learning domain, we developed three different models. The first was a baseline model using the categorical MRI score, similar to the LR baseline. The second was a comprehensive model that included all 76 MRI scoring components and clinical variables. The third model employed feature reduction using SHAP scores to create a parsimonious model.\n\nTo ensure a fair comparison, we evaluated all models using the same metrics: accuracy, precision, recall, and area under the receiver-operator curve (AUC). Cross-validation was performed where applicable, and the average of the five cross-validation runs was reported. This rigorous evaluation process allowed us to compare the performance of different models and identify the most effective approach for predicting adverse motor outcomes.\n\nNot applicable.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe performance metrics presented in the study include accuracy, precision, recall, and the area under the receiver-operator curve (AUC). These metrics were used to assess the performance of various models, including logistic regression and machine learning models. However, the specific confidence intervals for these metrics are not explicitly stated in the provided information.\n\nStatistical significance is crucial for claiming that one method is superior to others and baselines. The study employed cross-validation techniques, such as ten-fold cross-validation for LASSO regression and five-fold cross-validation for other models, to ensure robust performance evaluation. These methods help in assessing the generalizability of the models and reducing the risk of overfitting. The use of cross-validation suggests that the results are likely to be statistically significant, as it provides a more reliable estimate of model performance.\n\nAdditionally, the study utilized feature selection methods like SHAP scores and AIC minimization to optimize model performance. These techniques help in identifying the most important features and improving the model's accuracy, which further supports the statistical significance of the results.\n\nIn summary, while the exact confidence intervals for the performance metrics are not provided, the use of cross-validation and feature selection methods indicates that the results are likely statistically significant. This provides a reasonable level of confidence in the superiority of the proposed methods over the baselines.",
  "evaluation/availability": "Not applicable."
}