{
  "publication/title": "Deep learning model-assisted detection of kidney stones on computed tomography.",
  "publication/authors": "Caglayan A, Horsanali MO, Kocadurdu K, Ismailoglu E, Guneyli S",
  "publication/journal": "International braz j urol : official journal of the Brazilian Society of Urology",
  "publication/year": "2022",
  "publication/pmid": "35838509",
  "publication/pmcid": "PMC9388181",
  "publication/doi": "10.1590/s1677-5538.ibju.2022.0132",
  "publication/tags": "- Deep Learning\n- Kidney Stones\n- CT Imaging\n- Artificial Intelligence\n- Medical Diagnosis\n- Image Classification\n- Convolutional Neural Networks\n- ResNet Architecture\n- Stone Detection\n- Radiology\n- Machine Learning\n- Medical Imaging\n- Diagnostic Accuracy\n- Gradient-based Localization\n- Cross-entropy Loss\n- Adam Algorithm\n- Fastai Library\n- Google Collaboratory\n- Sensitivity and Specificity\n- Receiver Operating Characteristic (ROC) Curve Analysis",
  "dataset/provenance": "The dataset used in this study consists of computed tomography (CT) images from 455 patients who underwent CT scanning for kidney stones between January 2016 and January 2020. Out of these, 405 patients were diagnosed with kidney stones, while 50 were not. The patients were categorized into three groups based on the size of their kidney stones: Group 1 (0-1 cm), Group 2 (1-2 cm), and Group 3 (>2 cm). The CT images were acquired using a specific scanner and reconstructed in axial, coronal, and sagittal planes. In total, 2,959 CT images were evaluated using a deep learning model. This dataset was used to train and test the model, with the aim of investigating the success of the deep learning model in detecting kidney stones in different planes according to stone size on unenhanced CT images. The images were not preprocessed or augmented in any way during the training process.",
  "dataset/splits": "The dataset was divided into three groups based on the sizes of kidney stones: Group 1 (0-1 cm), Group 2 (1-2 cm), and Group 3 (>2 cm). Each group was further split into training and testing sets.\n\nFor the training set, the distribution of patients and CT images with and without kidney stones was as follows:\n\n* Group 1: 40 normal patients (200 images) and 91 patients with stones (753 images).\n* Group 2: 40 normal patients (200 images) and 109 patients with stones (753 images).\n* Group 3: 40 normal patients (200 images) and 126 patients with stones (753 images).\n\nFor the testing set, the distribution was:\n\n* Group 1: 10 normal patients (50 images) and 44 patients with stones (150 images).\n* Group 2: 10 normal patients (50 images) and 26 patients with stones (150 images).\n* Group 3: 10 normal patients (50 images) and 9 patients with stones (150 images).\n\nThe training and testing were performed in the three planes (axial, coronal, and sagittal) for each of the three study groups.",
  "dataset/redundancy": "The datasets used in this study were split into training and testing sets to evaluate the performance of the deep learning model. The training set consisted of CT images from patients with and without kidney stones, which were used to train the AI model. The testing set, on the other hand, was used to assess the model's accuracy and effectiveness in detecting kidney stones.\n\nThe training and testing were performed in three planes: axial, coronal, and sagittal. This approach allowed for a comprehensive evaluation of the model's performance across different imaging planes. The datasets were also divided among three study groups based on the sizes of the kidney stones: Group 1 (0-1 cm), Group 2 (1-2 cm), and Group 3 (>2 cm). This grouping helped in analyzing the model's performance for different stone sizes.\n\nTo ensure the independence of the training and test sets, the images used for training the model were not preprocessed or augmented in any way. This method helped in maintaining the integrity of the data and preventing any potential bias that could arise from data manipulation. The distribution of the datasets in terms of the number of patients and CT images with and without kidney stones is presented in Table 1. This table provides a clear comparison of the datasets used in this study with previously published machine learning datasets, highlighting the diversity and representativeness of the data.\n\nThe deep learning model was trained using the Fastai (v2) library and the Google Collaboratory platform. The Adam algorithm was used as the optimization algorithm, and cross-entropy loss was utilized as the loss function. During model training, the learning rate was set to 0.01, and the best validation scores were achieved after an average of the 35th epoch. This rigorous training process ensured that the model was well-equipped to handle the complexity of the datasets and provide accurate results.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm used in our study is the Adam algorithm. This is a widely-used optimization algorithm in the field of machine learning, particularly for training deep learning models. It is not a new algorithm; it was introduced by Diederik P. Kingma and Jimmy Ba in their 2014 paper \"Adam: A Method for Stochastic Optimization.\"\n\nThe Adam algorithm is a popular choice due to its efficiency and effectiveness in handling sparse gradients on noisy problems. It combines the advantages of two other extensions of stochastic gradient descent. Specifically, Adam computes adaptive learning rates for each parameter, which allows for faster convergence and better performance on problems with sparse gradients, such as those encountered in deep learning.\n\nGiven that Adam is a well-established algorithm, it was not necessary to publish it in a machine-learning journal. Instead, our focus was on applying this proven optimization technique to the specific problem of kidney stone detection using deep learning models. The novelty of our work lies in the application of the xResNet50 architecture and the Adam optimizer to this particular medical imaging task, rather than in the development of a new optimization algorithm.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, the images used for training the model were not preprocessed or augmented in any way. The CT images of patients with and without kidney stones were directly used for training and testing the deep learning algorithm. The images were acquired using a CT scanner with specific parameters, including a matrix size of 512\u00d7512 pixels, a voltage of 120 kV, and a slice thickness of \u22641.25 mm. All images were reconstructed in the axial, coronal, and sagittal planes with a 2-mm section thickness. The deep learning model utilized was xResNet50, which is a convolutional neural network architecture derived from ResNet with minor changes. This architecture consists of an input stem, four xResNet50 blocks, and an output stem. The images were inputted through the stem, processed within the model, and classified in the output stem, returning a percentage indicating the presence or absence of kidney stones. The training and testing were performed using the Fastai (v2) library and the Google Collaboratory platform, with the Adam algorithm as the optimization algorithm and cross-entropy loss as the loss function. The learning rate was set to 0.01, and the best validation scores were achieved after an average of the 35th epoch.",
  "optimization/parameters": "The deep learning model utilized in this study is based on the xResNet50 architecture, which is a variant of the ResNet convolutional neural network. The xResNet50 architecture consists of an input stem, four xResNet50 blocks, and an output stem. The specific number of parameters in the model is not explicitly stated, but it is inherent to the xResNet50 architecture.\n\nThe selection of the xResNet50 architecture was influenced by its proven effectiveness in image recognition tasks. The model was trained using the Adam optimization algorithm, with a learning rate of 0.01. The best validation scores were achieved after an average of the 35th epoch. The images used for training were not preprocessed or augmented in any way, ensuring that the model's performance is a direct result of its architectural design and training process.\n\nThe training and testing of the model were conducted in three planes (axial, coronal, and sagittal) and among three study groups categorized by kidney stone sizes (0-1 cm, 1-2 cm, and >2 cm). The Fastai (v2) library and the Google Collaboratory platform were used for this purpose. Cross-entropy loss was utilized as the loss function during the training process.",
  "optimization/features": "The input features for our deep learning model consisted of CT images of patients, both with and without kidney stones. These images were used in their raw form without any preprocessing or augmentation. The model was trained and tested in three different planes: axial, coronal, and sagittal. The images were acquired using a specific CT scanner with defined parameters, ensuring consistency in the input data.\n\nFeature selection, in the traditional sense of selecting specific variables or attributes from a dataset, was not applicable here. Instead, the model relied on the entire image data as input features. The images were directly fed into the xResNet50 convolutional neural network architecture, which is designed to handle image data effectively. The model's architecture, including the input stem, four xResNet50 blocks, and the output stem, was designed to process and classify the images based on the presence or absence of kidney stones.\n\nThe training and testing of the model were performed using the Fastai (v2) library and the Google Collaboratory platform. The Adam algorithm was used as the optimization algorithm, with a learning rate of 0.01. The best validation scores were achieved after an average of the 35th epoch. This approach ensured that the model was trained to recognize patterns and features directly from the CT images, without the need for manual feature selection.",
  "optimization/fitting": "The deep learning model employed in this study utilized the xResNet50 architecture, which is a convolution-based deep residual network. This architecture inherently has a large number of parameters due to its deep structure and multiple residual blocks. The number of parameters in such models is typically much larger than the number of training points, which can lead to overfitting if not properly managed.\n\nTo mitigate overfitting, several strategies were implemented. First, the model was trained using a substantial dataset of CT images, which included 2,959 unenhanced CT images, comprising 2,709 with kidney stones and 250 without. This large and diverse dataset helped the model to generalize better. Second, the Adam optimization algorithm was used, which adapts the learning rate for each parameter, helping to converge faster and more accurately. Additionally, cross-entropy loss was utilized as the loss function, which is effective for classification tasks. The learning rate was set to 0.01, and the model achieved the best validation scores after an average of the 35th epoch, indicating that the training process was well-controlled to avoid overfitting.\n\nTo further ensure that the model did not underfit, the training process was carefully monitored. The images used for training were not preprocessed or augmented, which means the model had to learn from the raw data, potentially increasing its robustness. The model's performance was evaluated in three different planes (axial, coronal, and sagittal) and among three study groups, ensuring that it could generalize across different views and stone sizes. The high accuracy rates achieved in the training group (ranging from 97.3% to 99.1%) indicate that the model was able to learn the underlying patterns in the data effectively, ruling out underfitting.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available. The deep learning model was trained using the Fastai (v2) library on the Google Collaboratory platform. The Adam algorithm was employed as the optimization algorithm, with a learning rate set to 0.01. Cross-entropy loss was utilized as the loss function. The best validation scores were achieved after an average of the 35th epoch. The images used for training the model were not preprocessed or augmented in any way.\n\nThe specific details of the model architecture, including the layer organization of the xResNet50 deep learning model, are described in the publication. The xResNet50 architecture consists of an input stem, four xResNet50 blocks, and an output stem. This architecture was derived from the convolution-based deep residual network architecture ResNet with a few minor changes.\n\nRegarding the availability of model files and optimization parameters, the publication provides a comprehensive description of the methods and configurations used. However, the actual model files and optimization parameters are not directly available in the publication. For access to the model files and further details, interested parties may need to contact the authors directly. The publication is licensed under terms that allow for academic use and citation, ensuring that the methods and findings can be replicated and built upon by other researchers in the field.",
  "model/interpretability": "The model employed in our study is not a black box. To enhance interpretability, we utilized the Grad-CAM technique. This method provides visual explanations for the decisions made by our convolutional neural network. By applying Grad-CAM, we were able to highlight the specific areas within the CT images that the model focused on when determining the presence or absence of kidney stones. This technique allows for a clearer understanding of how the model arrives at its classifications.\n\nFor instance, in our figures, we demonstrated CT images of patients with and without kidney stones, visualized using the Grad-CAM technique. These visualizations show the regions of interest that the model concentrated on, providing insights into the model's decision-making process. This approach not only aids in validating the model's accuracy but also builds trust by making the internal workings more transparent.",
  "model/output": "The model employed in this study is designed for classification tasks. Specifically, it is used to classify CT images of patients into two categories: those with kidney stones and those without. The model's architecture, xResNet50, processes input images through an input stem, four xResNet50 blocks, and an output stem. The final output is a percentage indicating the likelihood of kidney stone presence or absence. This classification is performed across three imaging planes: axial, coronal, and sagittal, and for different stone size groups. The model's performance is evaluated using metrics such as precision, recall, f1-score, accuracy, positive predictive value, negative predictive value, sensitivity, and specificity, which are standard for classification tasks in medical imaging.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, the evaluation of the deep learning model for kidney stone detection involved a comprehensive process that included both training and testing phases. The model was trained using CT images of patients with and without kidney stones, utilizing the Fastai (v2) library and the Google Collaboratory platform. The Adam algorithm was employed as the optimization algorithm, with cross-entropy loss serving as the loss function. The learning rate was set to 0.01, and the best validation scores were achieved after an average of the 35th epoch. Notably, the images used for training were not preprocessed or augmented in any way.\n\nThe evaluation was conducted across three different planes: axial, coronal, and sagittal, and among three study groups categorized by kidney stone sizes: 0-1 cm, 1-2 cm, and greater than 2 cm. The model's performance was assessed using various metrics, including sensitivity, specificity, and positive and negative predictive values, which were calculated using receiver operating characteristic (ROC) curve analysis for each group.\n\nThe accuracy rates of the deep learning model in the training group were remarkably high, with success rates of 98.2% in the axial section, 99.1% in the coronal section, and 98.2% in the sagittal section for group 1. Similarly, group 2 achieved accuracy rates of 99.1% in the axial section, 98.2% in the coronal section, and 98.2% in the sagittal section. Group 3 had slightly lower but still impressive accuracy rates of 97.3% in the axial section, 97.3% in the coronal section, and 98.2% in the sagittal section.\n\nIn the testing phase, the model's performance was verified in an independent test group. The success rates obtained were 78% in the axial section, 63% in the coronal section, and 85% in the sagittal section for group 1. Group 2 showed success rates of 68% in the axial section, 72% in the coronal section, and 89% in the sagittal section. Group 3 had success rates of 70% in the axial section, 64% in the coronal section, and 93% in the sagittal section.\n\nAdditionally, the Grad-CAM technique was used to produce visual explanations for the convolutional neural networks, identifying the areas where the models were concentrated. This technique provided insights into the model's decision-making process, enhancing the transparency and reliability of the results.",
  "evaluation/measure": "In the evaluation of our deep learning model for detecting kidney stones, several key performance metrics were reported to provide a comprehensive assessment of the model's effectiveness. These metrics include accuracy, precision, recall (sensitivity), F1-score, positive predictive value (PPV), and negative predictive value (NPV). These metrics were calculated for different planes (axial, coronal, and sagittal) and for three groups of kidney stone sizes (0-1 cm, 1-2 cm, and >2 cm).\n\nAccuracy rates were determined for both the training and testing groups. For the training group, the accuracy rates were exceptionally high, ranging from 97.3% to 99.1% across the different planes and stone size groups. In the testing group, the accuracy rates varied more, with the sagittal plane generally showing the highest accuracy, particularly for larger stone sizes.\n\nPrecision and recall were reported for both normal and stone cases. Precision indicates the proportion of true positive predictions among all positive predictions, while recall (sensitivity) measures the proportion of true positives correctly identified by the model. The F1-score, which is the harmonic mean of precision and recall, provides a single metric that balances both concerns.\n\nPositive predictive value (PPV) and negative predictive value (NPV) were also calculated. PPV represents the probability that a positive test result is a true positive, while NPV represents the probability that a negative test result is a true negative. These metrics are crucial for understanding the clinical relevance of the model's predictions.\n\nThe reported metrics are representative of standard practices in the literature for evaluating medical imaging models. They provide a thorough evaluation of the model's performance, covering aspects such as the model's ability to correctly identify kidney stones, its precision in making positive predictions, and its reliability in negative predictions. This set of metrics ensures that the model's performance is assessed from multiple angles, making the evaluation robust and comprehensive.",
  "evaluation/comparison": "Not applicable\n\nThe study focused on the development and evaluation of a deep learning model for detecting kidney stones using CT images. The model was trained and tested using specific datasets of patients with and without kidney stones, categorized into three groups based on stone size. The evaluation metrics included accuracy, sensitivity, specificity, and predictive values for different imaging planes (axial, coronal, and sagittal).\n\nThe study did not explicitly mention a comparison to publicly available methods or simpler baselines on benchmark datasets. The primary focus was on assessing the performance of the deep learning model within the context of the study's own datasets and criteria.",
  "evaluation/confidence": "The evaluation of our deep learning model's performance was conducted using several metrics, including accuracy, sensitivity, specificity, and positive and negative predictive values. These metrics were calculated for each imaging plane (axial, coronal, and sagittal) across three groups of kidney stone sizes. The results were derived from receiver operating characteristic (ROC) curve analysis, which is a standard method for evaluating the performance of diagnostic tests.\n\nThe accuracy rates of the model in the training group were high, with values ranging from 97.3% to 99.1% across different planes and groups. In the test group, the accuracy rates varied more, with the sagittal plane generally showing the highest performance. For instance, the sagittal plane achieved accuracy rates of 85%, 89%, and 93% for groups 1, 2, and 3, respectively. These results suggest that the model performs well, particularly in the sagittal plane.\n\nHowever, specific details about confidence intervals for these performance metrics are not provided. The statistical significance of the results in comparison to other methods or baselines is also not explicitly stated. While the high accuracy rates and other performance metrics indicate strong model performance, the lack of confidence intervals and statistical significance testing means that the precise reliability and superiority of the model over other methods cannot be definitively claimed. Further statistical analysis would be necessary to provide a more comprehensive evaluation of the model's performance and its comparative advantages.",
  "evaluation/availability": "Not enough information is available."
}