{
  "publication/title": "Cervical lesion assessment using real-time microendoscopy image analysis in Brazil: The CLARA study.",
  "publication/authors": "Hunt B, Fregnani JHTG, Brenes D, Schwarz RA, Salcedo MP, Possati-Resende JC, Antoniazzi M, de Oliveira Fonseca B, Santana IVV, de Mac\u00eado Matsushita G, Castle PE, Schmeler KM, Richards-Kortum R",
  "publication/journal": "International journal of cancer",
  "publication/year": "2021",
  "publication/pmid": "33811763",
  "publication/pmcid": "PMC8815862",
  "publication/doi": "10.1002/ijc.33543",
  "publication/tags": "- Cervical Cancer\n- High-Resolution Microendoscopy\n- Diagnostic Performance\n- Colposcopy\n- Cervical Intraepithelial Neoplasia\n- Image Analysis\n- Morphologic Analysis\n- Convolutional Neural Network\n- Screening Tests\n- Brazil\n- Biomedical Imaging\n- Cancer Detection\n- Medical Diagnostics\n- Cervical Biopsy\n- Prospective Study",
  "dataset/provenance": "The dataset used in this study was collected from women who had abnormal cervical cancer screening tests and were referred for colposcopy. The participants were identified through a regional screening program operated by Barretos Cancer Hospital (BCH). The inclusion criteria for the study were women with abnormal cervical screening tests, aged 18 or older, with an intact uterine cervix, not pregnant, no known allergy to the fluorescent dye used for HRME imaging, not belonging to an indigenous Brazilian population, and willing to provide written informed consent.\n\nA total of 1,486 subjects completed the study and were included in the analysis. The dataset includes high-resolution microendoscopy (HRME) images, colposcopy results, and histopathology diagnoses. The histopathology diagnoses were categorized as negative, CIN 1, CIN 2, CIN 3, and invasive carcinoma. The dataset was divided into training, validation, and test sets, with approximately 60%, 20%, and 20% of the data, respectively. Each partition had an equal distribution of pathology outcomes.\n\nThe dataset was used to train a multi-task convolutional neural network (CNN) to classify HRME images. The CNN model utilized an architecture proposed by Mehta et al. to perform joint segmentation and classification of histopathology images. The dataset has not been used in previous papers by the community, as this is the first study to explore the use of a multi-task CNN for improving the diagnostic accuracy of HRME. The dataset is unique and specifically collected for this study to evaluate the diagnostic performance of HRME with morphologic image analysis and to explore the potential of deep learning methods to further improve diagnostic accuracy.",
  "dataset/splits": "The dataset was divided into three splits: training, validation, and test sets. The training set consisted of 870 patients, with 516 negative cases, 98 cases of CIN 1, 55 cases of CIN 2, 189 cases of CIN 3, and 12 cases of invasive carcinoma. The validation set included 302 patients, with 181 negative cases, 33 cases of CIN 1, 20 cases of CIN 2, 64 cases of CIN 3, and 4 cases of invasive carcinoma. The test set comprised 314 patients, with 185 negative cases, 38 cases of CIN 1, 19 cases of CIN 2, 66 cases of CIN 3, and 6 cases of invasive carcinoma. Each split was designed to have an equal distribution of pathology outcomes.",
  "dataset/redundancy": "The dataset was divided into three partitions: training, validation, and test sets. This division was done randomly by patient, ensuring that each partition had an equal distribution of pathology outcomes. The training set consisted of approximately 60% of the data, the validation set around 20%, and the test set also around 20%.\n\nThe independence of the training and test sets was enforced by ensuring that data from the same patient did not appear in more than one partition. This approach helps to prevent data leakage and ensures that the model's performance on the test set is a true reflection of its generalizability.\n\nThe distribution of pathology outcomes in each set was designed to mirror the overall distribution in the study. For instance, the training set included 516 negative cases, 98 CIN 1 cases, 55 CIN 2 cases, 189 CIN 3 cases, and 12 invasive carcinoma cases. Similarly, the validation and test sets had proportional distributions of these outcomes.\n\nThis method of dataset splitting is crucial for evaluating the model's performance accurately. By maintaining independent sets and ensuring a balanced distribution of pathology outcomes, the study aims to provide a robust assessment of the multi-task convolutional neural network's diagnostic accuracy. This approach is consistent with best practices in machine learning, where the goal is to train a model on one subset of data, validate it on another, and finally test it on a completely independent set to ensure unbiased performance evaluation.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in this study utilizes a multi-task convolutional neural network (CNN). This class of machine-learning algorithms is well-established and widely used for various image analysis tasks, including segmentation and classification.\n\nThe specific multi-task CNN architecture used was not newly developed for this study. Instead, it was based on an existing architecture proposed by Mehta et al. This architecture was chosen for its effectiveness in performing joint segmentation and classification of histopathology images.\n\nThe decision to use an existing architecture rather than developing a new one was driven by the primary focus of the study, which was to evaluate the diagnostic performance of high-resolution microendoscopy (HRME) for detecting cervical intraepithelial neoplasia (CIN). The study aimed to explore whether deep learning methods could improve the diagnostic accuracy of HRME, and using a proven architecture allowed for a more straightforward and focused assessment of this objective.\n\nGiven the study's focus on medical diagnostics rather than the development of new machine-learning algorithms, it was appropriate to publish the findings in a cancer research journal. This allowed the results to reach the relevant medical and research communities, highlighting the potential of deep learning in improving HRME performance for cervical cancer detection.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it employs a multi-task convolutional neural network (CNN) designed to perform joint segmentation and classification of histopathology images. This approach does not rely on data from other machine-learning algorithms as input. The multi-task CNN is trained in two stages: first, it optimizes nuclear segmentation on a pixel-by-pixel basis, and second, it optimizes image classification accuracy. The architecture used is based on a previously proposed model by Mehta et al., which is specifically tailored for histopathology image analysis.\n\nThe training data for the multi-task CNN is divided into three sets: training, validation, and test sets. These sets are partitioned by patient to ensure that each partition has an equal distribution of pathology outcomes. This division helps to maintain independence in the training data, as images from the same patient are not split across different sets. The model's performance is monitored using the validation set to avoid overfitting, and the final model is selected based on its performance on this validation set. The test set is then used to prospectively analyze the model's diagnostic performance.\n\nIn summary, the model does not use data from other machine-learning algorithms as input and is not a meta-predictor. The training data is carefully partitioned to ensure independence, with each set containing a balanced distribution of pathology outcomes.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps. Initially, the circular region of high-resolution microendoscopy (HRME) images corresponding to the fiber bundle was cropped to yield four non-overlapping, square sub-images. This step ensured that the relevant areas of the images were isolated for analysis.\n\nNuclear segmentation masks generated using morphologic image analysis were employed as a weakly supervised ground truth for pixel-level segmentation. These masks provided the necessary guidance for the convolutional neural network (CNN) to learn and optimize nuclear segmentation.\n\nThe multi-task CNN model utilized an architecture designed to perform joint segmentation and classification of histopathology images. The model was trained in two stages. The first stage focused on optimizing nuclear segmentation on a pixel-by-pixel basis. The second stage aimed to optimize image classification accuracy, specifically distinguishing between less severe (CIN 2-) and more severe (CIN 2+) cervical intraepithelial neoplasia.\n\nDuring the training process, the diagnostic performance for images in the validation set was monitored to prevent overfitting. The model with the best performance on the validation set was selected and used to prospectively analyze images in the test set. This approach ensured that the model generalized well to unseen data.\n\nThe final model was used to assess per-site and per-patient diagnostic performance in the validation and test sets by comparing results to histologic diagnosis. A multi-task CNN score was calculated for each site image by averaging the network output (probability of CIN 2+) across the four sub-images classified by the network. The per-patient CNN score was defined as the maximum multi-task CNN score for all images. This scoring method provided a comprehensive evaluation of the diagnostic accuracy of the HRME images using the multi-task CNN.",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "The input features for the multi-task convolutional neural network (CNN) were derived from high-resolution microendoscope (HRME) images. The images were preprocessed by cropping the circular region corresponding to the fiber bundle into four non-overlapping, square sub-images. This preprocessing step effectively created four sub-images per original HRME image, each serving as a distinct input feature for the CNN.\n\nFeature selection was not explicitly performed in the traditional sense of reducing the number of features. Instead, the model utilized a joint optimization approach where nuclear segmentation masks generated using morphologic image analysis were used as a weakly supervised ground truth for pixel-level segmentation. This approach inherently selects relevant features by focusing on nuclear morphologies, which are critical for diagnosing cervical abnormalities.\n\nThe segmentation masks were used to train the CNN in two stages: first, optimizing nuclear segmentation on a pixel-by-pixel basis, and second, optimizing image classification accuracy. This two-stage training process ensured that the model learned to focus on the most relevant features for both segmentation and classification tasks. The use of validation data during training helped to monitor performance and avoid overfitting, ensuring that the model generalized well to unseen data.",
  "optimization/fitting": "The multi-task convolutional neural network (CNN) model utilized in this study was designed to handle a large number of parameters relative to the number of training points. To mitigate the risk of overfitting, several strategies were employed. Firstly, the dataset was divided into training, validation, and test sets, ensuring that each partition had an equal distribution of pathology outcomes. This division helped in evaluating the model's performance on unseen data.\n\nDuring the training process, diagnostic performance for images in the validation set was monitored. The model with the best performance on the validation set was selected, which helped in avoiding overfitting to the training data. Additionally, the model was trained in two stages: first, optimizing nuclear segmentation on a pixel-by-pixel basis, and second, optimizing image classification accuracy. This two-stage training approach allowed for a more robust feature representation, which could better account for various tissue morphologies.\n\nTo further ensure that the model did not underfit, the architecture proposed by Mehta et al. was used, which is known for its effectiveness in joint segmentation and classification tasks. The model was trained to perform simultaneous image segmentation and classification, leveraging the weakly supervised ground truth for pixel-level segmentation. This joint optimization likely contributed to a more accurate and generalizable model.\n\nThe final model's performance was assessed using a threshold for positivity determined by the point on the ROC curve that minimized the Euclidean distance with respect to the operating point of colposcopy. This approach ensured that the model's diagnostic performance was comparable to that of colposcopy, a well-established diagnostic method. The use of DeLong\u2019s test for significance testing further validated the model's performance, providing statistical evidence of its diagnostic accuracy.",
  "optimization/regularization": "To prevent overfitting during the training of the multi-task convolutional neural network (CNN), several techniques were employed. One key method involved monitoring the diagnostic performance on a validation set. This set, comprising approximately 20% of the total data, was used to evaluate the model's performance during training. By tracking the model's accuracy on this validation set, it was possible to identify when the model began to overfit to the training data. The model that demonstrated the best performance on the validation set was selected for further analysis, ensuring that it generalized well to unseen data.\n\nAdditionally, the dataset was divided into training, validation, and test sets, with each partition containing an equal distribution of pathology outcomes. This balanced partitioning helped to ensure that the model learned to generalize across different types of pathology rather than memorizing specific training examples.\n\nThe multi-task CNN was trained in two stages. The first stage focused on optimizing nuclear segmentation on a pixel-by-pixel basis. This initial training phase helped the model to learn the basic features of the images without overfitting to the classification task. In the second stage, the diagnostic classification branch was appended to the architecture, and the network was trained to perform simultaneous image segmentation and classification. This two-stage training process helped to regularize the learning process and prevent overfitting.\n\nFurthermore, the use of nuclear segmentation masks generated through morphologic image analysis provided a weakly supervised ground truth for pixel-level segmentation. This approach helped to guide the model's learning process and reduce the risk of overfitting to the training data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study is a multi-task convolutional neural network (CNN), which is inherently a black-box model. This means that the decision-making process within the network is not directly interpretable by humans. The CNN operates by learning complex patterns and features from the input data through multiple layers of processing, but the specific mechanisms by which it arrives at its classifications are not explicitly defined or easily understandable.\n\nHowever, the model's architecture and training process provide some level of transparency. The multi-task CNN was designed to perform joint segmentation and classification of HRME images. During the training process, the model was first optimized for nuclear segmentation on a pixel-by-pixel basis. This step involved identifying and delineating the nuclei within the cervical tissue images, which is a crucial task for diagnosing cervical intraepithelial neoplasia (CIN). The segmentation masks generated using morphologic image analysis served as a weakly supervised ground truth for this pixel-level segmentation.\n\nOnce the segmentation performance was optimized, a diagnostic classification branch was appended to the architecture. The network was then trained to perform simultaneous image segmentation and classification. This dual-task approach allows the model to leverage the spatial information obtained from segmentation to improve its classification accuracy. The final model was evaluated using per-site and per-patient diagnostic performance metrics, comparing the results to histologic diagnosis.\n\nWhile the internal workings of the CNN remain opaque, the structured approach to training and evaluation provides insights into how the model utilizes the input data. The use of segmentation as an intermediate step adds a layer of interpretability, as the model's ability to accurately segment nuclei can be independently assessed and validated. This process helps to ensure that the model is focusing on relevant features within the images, even if the exact decision-making process is not fully transparent.",
  "model/output": "The model employed in this study is a multi-task convolutional neural network (CNN) designed for classification tasks. Specifically, it was trained to classify high-resolution microendoscopy (HRME) images into categories based on the severity of cervical intraepithelial neoplasia (CIN). The primary classification task was to distinguish between less severe (CIN 2-) and more severe (CIN 2+) diagnoses. Additionally, the model was trained to perform nuclear segmentation, which is a form of image classification at the pixel level.\n\nThe diagnostic performance of the model was evaluated using receiver operator characteristic (ROC) curves, which are commonly used in classification problems to illustrate the trade-off between sensitivity and specificity. The area under the ROC curve (AUC) was calculated using the trapezoidal rule to quantify the model's ability to discriminate between different classes.\n\nThe model's output includes a score for each site image, calculated by averaging the network's output (probability of CIN 2+) across four sub-images. The per-patient score is defined as the maximum multi-task CNN score for all images associated with that patient. These scores were used to compare the model's performance against colposcopy and HRME using morphologic image analysis.\n\nSignificance testing for differences in diagnostic performance was conducted using DeLong\u2019s test for AUC comparisons and McNemar\u2019s test for comparing the performance at specific thresholds. The model's performance was also visualized using ROC curves and cross-tabulations of outcomes, providing a comprehensive evaluation of its classification capabilities.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a retrospective performance analysis using a multi-task convolutional neural network (CNN) to classify high-resolution microendoscopy (HRME) images. The study data were divided into training, validation, and test sets, ensuring an equal distribution of pathology outcomes across each partition. The training set consisted of approximately 60% of the data, the validation set around 20%, and the test set also around 20%.\n\nThe multi-task CNN model was trained in two stages. The first stage focused on optimizing nuclear segmentation on a pixel-by-pixel basis. The second stage aimed to optimize image classification accuracy, specifically distinguishing between less severe (CIN 2-) and more severe (CIN 2+) cervical abnormalities. The model's performance was monitored during training using the validation set to prevent overfitting. The model that performed best on the validation set was selected for prospective analysis on the test set.\n\nThe final model was used to assess diagnostic performance by comparing results to histologic diagnosis. A multi-task CNN score was calculated for each site image by averaging the network's output across four sub-images. The per-patient CNN score was defined as the maximum multi-task CNN score for all images of a patient. Statistical analysis, including one-way ANOVA on ranks, was utilized to evaluate differences in multi-task CNN score distributions by histopathology diagnosis. A threshold for positivity by the multi-task CNN was determined based on the receiver operating characteristic (ROC) curve, aiming to minimize the Euclidean distance with respect to the operating point of colposcopy. The performance of the multi-task CNN at this cutoff was then compared to colposcopy for both CIN 2+ and CIN 3+ endpoints, with significance testing performed using McNemar\u2019s test.",
  "evaluation/measure": "In our study, we evaluated the diagnostic performance of high-resolution microendoscopy (HRME) using several key metrics to ensure a comprehensive assessment. We primarily focused on sensitivity and specificity, which are crucial for understanding the true positive and true negative rates of the diagnostic tool. These metrics were calculated on both a per-site and per-patient basis, providing a detailed view of HRME's effectiveness.\n\nTo compare HRME with colposcopy, we used McNemar\u2019s test, which is a statistical method suitable for paired nominal data. This allowed us to determine if there were significant differences in the sensitivity and specificity between HRME and colposcopy. Additionally, we performed receiver operator characteristic (ROC) analysis to assess the trade-off between sensitivity and specificity at various thresholds. The area under the ROC curve (AUC) was calculated using the trapezoidal rule, providing a single metric that summarizes the overall performance of the diagnostic test across all possible thresholds.\n\nFor the retrospective analysis using a multi-task convolutional neural network (CNN), we also reported the AUC to evaluate the improvement in diagnostic accuracy. We compared the performance of HRME using the multi-task CNN to that of colposcopy and HRME using morphologic image analysis. The diagnostic performance was monitored during training to avoid overfitting, and the model with the best performance on the validation set was selected for prospective analysis on the test set.\n\nWe also conducted significance testing for differences in the area under the curve for squamous versus columnar/metaplasia tissues using DeLong\u2019s test. This helped us understand how well HRME performs across different tissue types. Furthermore, we used one-way ANOVA on ranks to evaluate differences in multi-task CNN score distributions by histopathology diagnosis, ensuring that our findings were statistically robust.\n\nIn summary, our study reports a comprehensive set of performance metrics, including sensitivity, specificity, AUC, and statistical tests for significance. These metrics are representative of those commonly used in the literature for evaluating diagnostic tools, ensuring that our results can be compared and contrasted with other studies in the field.",
  "evaluation/comparison": "In our study, we conducted a retrospective performance analysis to explore whether deep learning methods could enhance the diagnostic accuracy of high-resolution microendoscopy (HRME). We trained a multi-task convolutional neural network (multi-task CNN) using a subset of HRME images to classify these images. The diagnostic accuracy of HRME using this multi-task CNN was then compared to that of colposcopy and to HRME using morphologic image analysis.\n\nTo ensure a fair comparison, we divided the study data randomly by patient into training, validation, and test sets, each with an equal distribution of pathology outcomes. The multi-task CNN model utilized an architecture designed for joint segmentation and classification of histopathology images. The model was trained in two stages: first, optimizing nuclear segmentation on a pixel-by-pixel basis, and second, optimizing image classification accuracy.\n\nThe performance of the multi-task CNN was evaluated using the test set, and the results were compared to those of colposcopy and HRME with morphologic image analysis. We calculated a multi-task CNN score for each site image by averaging the network output across four sub-images. The per-patient CNN score was defined as the maximum multi-task CNN score for all images. We used one-way ANOVA on ranks to evaluate differences in multi-task CNN score distributions by histopathology diagnosis.\n\nA threshold for positivity by the multi-task CNN was determined as the point on the ROC curve that minimized the Euclidean distance with respect to the operating point of colposcopy. The performance of the multi-task CNN at this cutoff was then compared to colposcopy for both CIN 2+ and CIN 3+ endpoints, with significance testing performed using McNemar\u2019s test.\n\nIn summary, our comparison involved evaluating the multi-task CNN against established methods like colposcopy and morphologic image analysis, using a robust dataset and statistical methods to ensure the reliability of our findings.",
  "evaluation/confidence": "The evaluation of our study's performance metrics includes confidence intervals to provide a range within which the true value is likely to fall. Specifically, 95% confidence intervals are reported for various metrics, such as sensitivity and specificity, to indicate the precision of our estimates.\n\nStatistical significance is assessed using appropriate tests to determine if the observed differences in performance are likely due to actual effects rather than random variation. For instance, McNemar\u2019s test is employed to compare the performance of different diagnostic methods, such as colposcopy and high-resolution microendoscopy (HRME) with a multi-task convolutional neural network (CNN). This test helps to ascertain whether the differences in sensitivity and specificity between these methods are statistically significant.\n\nAdditionally, DeLong\u2019s test is used to compare the areas under the receiver operating characteristic (ROC) curves, which is crucial for evaluating the overall diagnostic accuracy of different methods. Significance levels are indicated using symbols such as ns (P>0.05), *(P\u22640.05), **(P\u22640.01), ***(P\u22640.001), and ****(P\u22640.0001), providing a clear indication of the strength of the evidence supporting the observed differences.\n\nOverall, the inclusion of confidence intervals and the use of statistical tests ensure that our claims about the superiority of our methods are robust and supported by empirical evidence.",
  "evaluation/availability": "Not enough information is available."
}