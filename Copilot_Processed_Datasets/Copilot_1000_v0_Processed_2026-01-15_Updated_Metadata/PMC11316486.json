{
  "publication/title": "A Real-World Study on the Short-Term Efficacy of Amlodipine in Treating Hypertension Among Inpatients.",
  "publication/authors": "Wang T, Tan J, Wang T, Xiang S, Zhang Y, Jian C, Jian J, Zhao W",
  "publication/journal": "Pragmatic and observational research",
  "publication/year": "2024",
  "publication/pmid": "39130528",
  "publication/pmcid": "PMC11316486",
  "publication/doi": "10.2147/por.s464439",
  "publication/tags": "- Hypertension\n- Amlodipine\n- Machine Learning\n- Predictive Modeling\n- LightGBM\n- Subgroup Analysis\n- Clinical Decision-Making\n- Feature Selection\n- SHAP Analysis\n- Patient Outcomes\n- Cardiovascular Health\n- Medical Decision-Making\n- Personalized Medicine\n- Hypertensive Patients\n- Treatment Efficacy",
  "dataset/provenance": "The dataset used in this study was sourced from electronic health records (EHR) of hypertensive patients. The study enrolled a total of 870 hypertensive patients. The data included comprehensive records of 31 clinical indicators measured within the first 24 hours of admission. These indicators encompassed general information such as age, sex, systolic blood pressure (SBP), and diastolic blood pressure (DBP). Additionally, the dataset included blood routine examinations, coagulation tests, and biochemical indicators. The dataset was divided into a training set (614 patients) and a validation set (256 patients) to evaluate the predictive model\u2019s performance and ensure its generalizability within the study population.\n\nThe dataset was preprocessed using Excel 2016, and statistical analysis was performed using SPSS 25.0, R 4.2.1, and Python 3.9.12. The enumeration data were expressed as counts and percentages, while quantitative data were analyzed for normality. If the data followed a normal distribution, they were expressed as mean \u00b1 standard deviation and compared using the t-test. For non-normally distributed data, the median and interquartile range were used, and the Mann\u2013Whitney U-test was employed for comparisons.\n\nThe dataset has not been used in previous papers or by the community, as it is specific to this study. The raw data supporting the conclusions of this article will be provided upon request to the corresponding author.",
  "dataset/splits": "The dataset was divided into two primary splits: a training set and a validation set. The training set consisted of 614 data points, while the validation set contained 256 data points. This partitioning strategy was designed to evaluate the predictive model\u2019s performance and ensure its generalizability within the study population. The data was randomly divided in a 7:3 ratio to achieve this split.",
  "dataset/redundancy": "The dataset used in this study consisted of 870 hypertensive patients, with a focus on evaluating the efficacy of amlodipine. To ensure the robustness and generalizability of the predictive models, the dataset was randomly divided into a training set and a validation set using a 7:3 ratio. This resulted in 614 patients in the training set and 256 patients in the validation set. The partitioning strategy aimed to evaluate the predictive model\u2019s performance and ensure its generalizability within the study population.\n\nThe training and validation sets were independent, with no overlap between them. This independence was enforced through random partitioning, which helps in assessing the model's performance on unseen data, thereby providing a more reliable estimate of its generalizability.\n\nRegarding the distribution of the dataset, it included a comprehensive set of 31 clinical indicators, which were carefully selected to enhance data integrity. The indicators covered a wide range of variables, including general information, blood routine examinations, coagulation tests, and biochemical indicators. This comprehensive approach ensures that the dataset is representative and comparable to previously published machine learning datasets in the field of hypertension treatment.\n\nThe dataset was preprocessed using Excel 2016, and statistical analysis was performed using SPSS 25.0, R 4.2.1, and Python 3.9.12. The enumeration data were expressed as counts and percentages, while quantitative data were analyzed for normality. If the data followed a normal distribution, they were expressed as mean \u00b1 standard deviation; otherwise, they were expressed as median and interquartile range. This rigorous statistical approach ensures the reliability and validity of the dataset.",
  "dataset/availability": "The data used in this study is not publicly available. However, the authors have committed to providing the raw data that supports the conclusions of the article upon request. Interested parties should direct their requests to Tingting Wang at wangtt9910@163.com. This approach ensures that the data is shared responsibly while maintaining control over its distribution. The study received approval from the Ethics Committee of Chongqing Medical University, and all methods were performed in accordance with relevant guidelines and regulations, including the Declaration of Helsinki. Due to the retrospective and anonymized nature of the data, informed consent was waived by the Ethics Review Committee.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to the ensemble learning class, specifically decision tree-based algorithms. The algorithms employed include Random Forest (RF), eXtreme Gradient Boosting (XGBoost), Gradient Boosting Decision Tree (GBDT), Categorical Boosting (CatBoost), Adaptive Boosting (AdaBoost), and LightGBM.\n\nLightGBM, one of the algorithms used, is a relatively novel model based on decision tree algorithms. It is known for its fast training speed and low memory utilization, making it more powerful and efficient than traditional algorithms. This algorithm has been successfully applied in various studies, including investigations into the reduction of all-cause in-hospital mortality among critically ill hypertensive patients treated with ACEI/ARB drugs.\n\nThe decision to use these specific algorithms was driven by their demonstrated effectiveness and robust performance in similar studies. Each algorithm possesses unique strengths, such as robustness to noise and outliers, computational efficiency, strong predictive performance, automatic handling of categorical features, and support for parallel and distributed computing. These characteristics make them well-suited for analyzing the short-term efficacy of amlodipine in hypertension treatment.\n\nThe algorithms were evaluated using metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic (ROC) curve (AUC). Through comprehensive evaluation, LightGBM consistently exhibited superior performance, achieving high AUC values even with simplified model structures. This underscores the versatility and robustness of LightGBM, positioning it as a promising candidate for future applications in personalized medicine and precision healthcare.\n\nThe study's findings highlight the importance of individual differences in medical decision-making and provide valuable insights for developing personalized treatment strategies tailored to specific patient populations. The integration of demographic characteristics and clinical risk factors aims to predict amlodipine efficacy, facilitating personalized application, particularly in hospitalized hypertensive patients receiving amlodipine monotherapy.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. Instead, it relies on a single machine learning algorithm, LightGBM, which demonstrated superior performance in predicting the efficacy of amlodipine. The LightGBM model was trained and evaluated using a set of independent factors, including HCT, TT, TG, SBP, TP, DBP, TCHO, and PDW, which were identified through a variable reduction process.\n\nThe study implemented six different machine learning algorithms\u2014Random Forest (RF), eXtreme Gradient Boosting (XGBoost), Gradient Boosting Decision Tree (GBDT), Categorical Boosting (CatBoost), Adaptive Boosting (AdaBoost), and LightGBM\u2014to predict the efficacy of amlodipine. Among these, LightGBM consistently showed the best overall performance, achieving an AUC of 0.808 with eight indicators and 0.803 with three key variables (TT, HCT, and PDW).\n\nThe training data for the LightGBM model was carefully selected to ensure independence. The study conducted subgroup analyses to explore the impact of various factors, such as additional drug treatments, high-risk populations, and surgical complications, on the model's performance. These analyses further validated the robustness and versatility of the LightGBM model in different patient scenarios.\n\nIn summary, the model is not a meta-predictor but rather a standalone LightGBM model that was rigorously trained and evaluated using independent data. The focus was on streamlining the model structure to enhance interpretability and practicality, making it a promising candidate for personalized medicine and precision healthcare.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the robustness and reliability of our machine learning models. We employed several rigorous methodologies to handle and prepare the data effectively.\n\nInitially, we categorized the patients based on various factors such as undergoing surgery during amlodipine treatment, usage of hypolipidemic drugs, usage of antidiabetic drugs, high-risk status, and Charlson scores. This categorization allowed for a detailed demographic analysis, which was conducted separately for each subgroup.\n\nFor feature selection, we utilized multiple algorithms including recursive feature elimination (RFE), Linear Regression, Random Forest (RF), Pearson Correlation Coefficient (Corr), and Maximal Information Coefficient (MIC). These methods helped in identifying the most significant variables that influence the efficacy of amlodipine. The results from these feature selection algorithms were then combined with the model importance rankings to streamline the model and enhance its interpretability.\n\nThe data was encoded to handle both numerical and categorical features. Numerical features were standardized to ensure that they contributed equally to the model's predictions. Categorical features were encoded using techniques such as one-hot encoding, which converts categorical variables into a format that can be provided to machine learning algorithms to improve predictions.\n\nWe also conducted SHAP (SHapley Additive exPlanations) analysis to interpret the model's decision-making process. SHAP assigns a Shapley value to each feature, indicating its positive or negative contribution to the prediction results. This approach provided a comprehensive understanding of how each feature impacts the model's performance.\n\nAdditionally, we employed Beeswarm plots to visualize the SHAP values, making it easier to interpret the significance of each feature in predicting the outcomes. This visualization technique effectively showcased the impact of various features on the model's predictions.\n\nOverall, the data encoding and preprocessing steps were designed to ensure that our machine learning models were robust, reliable, and interpretable, providing valuable insights for clinical decision-making and healthcare practices.",
  "optimization/parameters": "In our study, we initially considered eight independent factors that significantly impacted the predictions: HCT, TT, TG, SBP, TP, DBP, TCHO, and PDW. These variables were identified through rigorous feature selection algorithms, including recursive feature elimination (RFE), Linear Regression, Random Forest (RF), Pearson Correlation Coefficient (Corr), and Maximal Information Coefficient (MIC). These methodologies ensured the robustness and reliability of our predictive models.\n\nTo streamline the model and enhance its interpretability, we conducted a meticulous analysis of model configurations with varying numbers of variables. We evaluated models with 6, 5, 4, and 3 variables. Notably, reducing the model to three key variables\u2014TT, HCT, and PDW\u2014maintained outstanding performance while yielding more intuitive results. This simplification not only improved the model's practicality but also highlighted the essential influencing factors, thereby enhancing its interpretability and applicability in clinical settings.\n\nThe LightGBM model, which demonstrated superior performance, was further analyzed using SHAP (SHapley Additive exPlanations) to provide a comprehensive understanding of the model\u2019s decision-making process. This analysis assigned Shapley values to each feature, indicating their positive or negative contribution to the prediction results. The SHAP values were visualized using Beeswarm plots, which effectively showcased the significance of each feature in predicting outcomes.\n\nIn summary, the final model utilized three key variables: TT, HCT, and PDW. This selection was based on a thorough evaluation of various model configurations and the application of rigorous feature selection algorithms, ensuring that the model was both robust and interpretable.",
  "optimization/features": "In the optimization process of our study, we initially considered a comprehensive set of 31 indicators as potential input features. To enhance the model's performance and interpretability, we employed rigorous feature selection methodologies. These included recursive feature elimination (RFE), Linear Regression, Random Forest (RF), Pearson Correlation Coefficient (Corr), and Maximal Information Coefficient (MIC). The application of these techniques allowed us to identify and retain the most significant variables that influence the efficacy of amlodipine treatment.\n\nThrough this feature selection process, we narrowed down the number of input features to eight key variables: HCT, TT, TG, SBP, TP, DBP, TCHO, and PDW. These variables were found to have a substantial impact on the model's predictions. Further analysis revealed that reducing the model to just three key variables\u2014TT, HCT, and PDW\u2014maintained outstanding performance while providing more intuitive results. This streamlining not only simplified the model but also enhanced its interpretability and practicality in clinical settings.\n\nThe feature selection was performed using the training set only, ensuring that the model's generalizability and robustness were not compromised. This approach allowed us to focus on the most relevant features, thereby improving the model's accuracy and reliability in predicting the effectiveness of amlodipine treatment.",
  "optimization/fitting": "In our study, we employed several machine learning algorithms, including Random Forest (RF), eXtreme Gradient Boosting (XGBoost), Gradient Boosting Decision Tree (GBDT), Categorical Boosting (CatBoost), Adaptive Boosting (AdaBoost), and LightGBM. These algorithms are known for their robustness and ability to handle large datasets with numerous parameters.\n\nTo address the potential issue of overfitting, given the number of parameters was much larger than the number of training points, we implemented rigorous feature selection methods. These included recursive feature elimination (RFE), Linear Regression, RF, Pearson Correlation Coefficient (Corr), and Maximal Information Coefficient (MIC). By combining the results of these five feature selection algorithms with model importance ranking, we were able to identify and retain only the most crucial variables. This process effectively reduced the model's complexity and mitigated the risk of overfitting.\n\nAdditionally, we utilized cross-validation techniques to ensure the generalizability of our models. The dataset was randomly divided into a training set (70%) and a validation set (30%). This partitioning strategy allowed us to evaluate the models' performance on unseen data, further validating their robustness and reliability.\n\nTo rule out underfitting, we carefully selected and tuned our models. Each algorithm was configured with optimal hyperparameters through techniques such as grid search and random search. This meticulous tuning process ensured that the models were neither too simple nor too complex, striking a balance that captured the underlying patterns in the data without overcomplicating the model structure.\n\nFurthermore, we employed SHAP (SHapley Additive exPlanations) analysis to enhance the interpretability of our models. SHAP assigns a Shapley value to each feature, indicating its positive or negative contribution to the prediction results. This approach provided a comprehensive understanding of the model's decision-making process and helped in identifying the key features influencing the predictions.\n\nIn summary, through the use of advanced feature selection methods, rigorous model validation techniques, and careful hyperparameter tuning, we ensured that our models were neither overfitted nor underfitted. This comprehensive approach resulted in robust and reliable predictive models that provided valuable insights for clinical decision-making and healthcare practices.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our predictive models. One of the key methods used was recursive feature elimination (RFE), which helps in selecting the most relevant features by recursively removing the least important ones. This process not only simplifies the model but also reduces the risk of overfitting by focusing on the most predictive variables.\n\nAdditionally, we utilized ensemble learning algorithms such as Random Forest (RF) and LightGBM. These algorithms are inherently designed to reduce overfitting by averaging the predictions of multiple decision trees. LightGBM, in particular, demonstrated exceptional performance and robustness in our analysis, achieving high accuracy and AUC scores even with a simplified model structure.\n\nWe also implemented regularization techniques within our machine learning models. Regularization helps to penalize large coefficients, thereby preventing the model from becoming too complex and overfitting the training data. This was particularly important in our feature selection process, where we aimed to identify the most crucial variables for treatment efficacy.\n\nFurthermore, we evaluated our models using a comprehensive set of metrics, including accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic curve (AUC). This thorough evaluation ensured that our models were not only accurate but also generalizable to new data.\n\nBy leveraging these rigorous methodologies, we were able to construct predictive models that are both reliable and interpretable, providing valuable insights for clinical decision-making and healthcare practices.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "In our study, we have taken significant steps to ensure that our model is not a black box, but rather a transparent and interpretable tool. To achieve this, we employed SHAP (SHapley Additive exPlanations) analysis, which is a powerful method for interpreting machine learning models. SHAP assigns a Shapley value to each feature, indicating the impact of that feature on the model's predictions. This allows us to understand the contribution of each feature to the prediction results, making the model's decision-making process more transparent.\n\nThe SHAP analysis provides valuable insights into the critical factors that influence the model's decisions. For instance, in our analysis, HCT (Hematocrit) emerged as the most significant feature influencing the model\u2019s predictions. The SHAP plot visually represents these insights, with the horizontal axis showing the SHAP values and the color of the points indicating the magnitude of the feature values. This visualization helps in understanding how each feature contributes to the prediction outcome, with the most influential features positioned at the top.\n\nBy integrating the outcomes of the SHAP analysis, we obtain a deeper understanding of the model\u2019s predictions. This transparency is crucial for building trust and confidence in the model's predictions. Moreover, the SHAP analysis highlights its role as an interpretative tool, enhancing the transparency and interpretability of the model. This approach not only provides actionable information but also guides the refinement of future clinical practices and research directions.\n\nIn addition to SHAP, we utilized other feature selection algorithms such as recursive feature elimination (RFE), Linear Regression, Random Forest (RF), Pearson Correlation Coefficient (Corr), and Maximal Information Coefficient (MIC). These methods helped in identifying the most important variables crucial to treatment efficacy, further streamlining the model and making it more interpretable.\n\nOverall, our model is designed to be transparent and interpretable, providing clear insights into its decision-making process. This transparency is essential for clinical decision-making and healthcare practices, ensuring that the model's predictions are reliable and trustworthy.",
  "model/output": "The model employed in this study is a classification model. It is designed to predict the efficacy of amlodipine treatment in hypertensive patients. The performance of the model is evaluated using various metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic curve (AUC). These metrics are typically used to assess the performance of classification models. The model's output is binary, indicating whether the treatment is successful or not. This is evident from the results presented in the tables, which show the model's performance in terms of these classification metrics. The study also involves subgroup analyses to categorize patients based on various factors, further supporting the classification nature of the model.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our predictive models was conducted using a comprehensive set of metrics to ensure robustness and reliability. We utilized accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic curve (AUC) to assess model performance. These metrics provided a thorough evaluation of the models' ability to correctly classify patients based on the efficacy of amlodipine treatment.\n\nTo validate the generalizability of our models, we employed a 7:3 split of the dataset into training and validation sets. This partitioning strategy allowed us to evaluate the models' performance on unseen data, ensuring that they could effectively predict outcomes in real-world scenarios. Additionally, we conducted subgroup analyses using the LightGBM model, which demonstrated optimal performance. These analyses categorized patients based on various factors such as surgery history, use of hypolipidemic and antidiabetic medications, high-risk status, and Charlson Comorbidity Index (CCI) scores. By focusing on these metrics and validation techniques, we aimed to reveal disparities in treatment outcomes among different patient subgroups and explore key factors influencing treatment efficacy.\n\nThe LightGBM model, in particular, showed strong performance across multiple metrics, including an accuracy of 0.727, sensitivity of 0.643, specificity of 0.853, PPV of 0.868, NPV of 0.613, and an AUC of 0.808. This model's effectiveness was further validated through subgroup analyses, which highlighted its ability to handle diverse patient characteristics and provide actionable insights for clinical decision-making. The integration of these evaluation methods ensured that our models were not only accurate but also reliable and interpretable, ultimately enhancing their utility in clinical settings.",
  "evaluation/measure": "In our study, we evaluated the performance of various machine learning models using a comprehensive set of metrics to ensure a thorough assessment. The primary metrics reported include accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic curve (AUC). These metrics provide a well-rounded view of the models' predictive capabilities.\n\nAccuracy measures the overall correctness of the model's predictions, while sensitivity (also known as recall or true positive rate) indicates the model's ability to correctly identify positive cases. Specificity, on the other hand, reflects the model's ability to correctly identify negative cases. PPV and NPV provide insights into the probability that positive and negative predictions are correct, respectively. The AUC offers a single scalar value that summarizes the model's performance across all classification thresholds, with higher values indicating better performance.\n\nThe use of these metrics is representative of standard practices in the literature, ensuring that our evaluation is both rigorous and comparable to other studies in the field. This comprehensive approach allows us to confidently assess the robustness and reliability of our models, providing valuable insights for clinical decision-making and healthcare practices.",
  "evaluation/comparison": "In our study, we employed a comprehensive approach to evaluate and compare various machine learning algorithms to predict the efficacy of amlodipine in treating hypertension. We selected six different algorithms: Random Forest (RF), eXtreme Gradient Boosting (XGBoost), Gradient Boosting Decision Tree (GBDT), Categorical Boosting (CatBoost), Adaptive Boosting (AdaBoost), and LightGBM. Each of these algorithms has unique strengths, such as robustness to noise and outliers, computational efficiency, and strong predictive performance.\n\nTo ensure the reliability and interpretability of our results, we evaluated the models using several metrics, including accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic curve (AUC). These metrics provided a thorough assessment of each model's performance.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on leveraging a diverse set of machine learning algorithms tailored to our specific research question. This approach allowed us to establish robust and versatile predictive models for analyzing the short-term efficacy of amlodipine in hypertension treatment.\n\nIn addition to comparing different machine learning algorithms, we also implemented five feature selection methods: recursive feature elimination (RFE), Linear Regression, Random Forest (RF), Pearson Correlation Coefficient (Corr), and Maximal Information Coefficient (MIC). These methods helped us identify the most crucial variables for treatment efficacy, leading to a more streamlined and interpretable model.\n\nThe integration of feature selection algorithms with model importance ranking facilitated the identification of key variables, such as HCT, TT, TG, SBP, TP, DBP, TCHO, and PDW, which significantly impacted the predictions. This process of variable reduction effectively eliminated non-significantly associated independent variables, contributing to the streamlining of the model's complexity.\n\nAmong the six algorithms, LightGBM consistently demonstrated exceptional performance, achieving an AUC of 0.808. Further analysis with reduced variable sets showed that LightGBM maintained outstanding performance even with a simplified model structure, achieving an AUC of 0.803 with just three key variables (TT, HCT, and PDW). This finding underscores the versatility and robustness of LightGBM, positioning it as a promising candidate for future applications in personalized medicine and precision healthcare.",
  "evaluation/confidence": "The evaluation of our models focused on several key performance metrics, including accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the curve (AUC). These metrics were chosen to provide a comprehensive assessment of the models' predictive capabilities. However, specific confidence intervals for these metrics were not explicitly reported in our study. The performance metrics were derived from the models' predictions on a validation set, and statistical significance was assessed through standard methods such as the chi-square test and t-tests, depending on the data distribution.\n\nThe LightGBM model demonstrated superior performance across multiple metrics, particularly in terms of accuracy, specificity, and AUC. This model's performance was compared against other machine learning algorithms, including CatBoost, Random Forest (RF), Gradient Boosting Decision Trees (GBDT), XGBoost, and AdaBoost. The LightGBM model consistently outperformed these alternatives, indicating its robustness and reliability for predicting the efficacy of amlodipine in hypertensive patients.\n\nStatistical significance was established through rigorous evaluation methodologies, ensuring that the observed differences in performance were not due to random chance. The use of multiple evaluation metrics and comparison against established baselines provided a strong foundation for claiming the superiority of the LightGBM model. However, while the results are promising, it is important to note that the study is subject to certain limitations, such as the retrospective design and potential confounding factors related to prior medication use. These factors may affect the generalizability of the findings and warrant further investigation in prospective studies.",
  "evaluation/availability": "The raw data supporting the conclusions of this article is available without reservation. Requests to access these datasets should be directed to the corresponding author. This ensures that other researchers can verify the findings and potentially build upon the work, promoting transparency and reproducibility in scientific research."
}