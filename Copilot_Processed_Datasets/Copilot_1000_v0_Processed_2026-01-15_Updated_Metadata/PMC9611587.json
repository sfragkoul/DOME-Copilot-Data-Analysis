{
  "publication/title": "IntegralVac: A Machine Learning-Based Comprehensive Multivalent Epitope Vaccine Design Method.",
  "publication/authors": "Suri S, Dakshanamurthy S",
  "publication/journal": "Vaccines",
  "publication/year": "2022",
  "publication/pmid": "36298543",
  "publication/pmcid": "PMC9611587",
  "publication/doi": "10.3390/vaccines10101678",
  "publication/tags": "- Vaccine Design\n- Peptide Vaccines\n- Artificial Intelligence\n- Machine Learning\n- Immunogenicity\n- MHC Class I\n- Coronavirus\n- Cancer Research\n- Epitope Prediction\n- Deep Learning\n- Tumor Epitopes\n- KRAS/HRAS\n- Peptide Characteristics\n- Gradient Boosting Classifiers\n- Logistic Regression\n- Support Vector Classifier\n- Adaptive Boosting Classifier\n- Winsorization\n- NetMHCPan\n- IntegralVac",
  "dataset/provenance": "The dataset used in our study includes peptide data obtained from various sources, such as KRAS, HRAS, murine ORF, and SARS-CoV-2 sequences. These sequences were previously utilized in our in-house epitope selection tools using the IEDB server. The dataset encompasses a range of epitopes, including those from cancer and viral sources, to ensure comprehensive coverage and validation.\n\nFor the SARS-CoV-2 data, we analyzed specific proteins like ORF3a, ORF9b, N-protein, and S-protein, which are known for their immunogenic properties. Additionally, we included murine datasets that were investigated in previous studies, focusing on proteins like nsp12 and nsp3, which are highly conserved within the coronavirus.\n\nThe dataset size varied, with predictions made for datasets containing between 2500 and 5000 peptides. This range was chosen to ensure that the model could handle both smaller and larger datasets effectively. The top epitope rankings generated by our tool, IntegralVac, were consistent with those predicted by the IEDB NetMhcPan server, indicating the reliability of our dataset and methodology.\n\nMoreover, we integrated methods from different models, such as MHCSeqNet and HemoPI, to enhance the prediction accuracy and reduce representational overlap within our datasets. This approach helped in providing a \"clean slate\" for each model to run its prediction algorithm without interference from previously integrated models.\n\nIn summary, the dataset used in our study is diverse and comprehensive, encompassing both viral and cancer epitopes. It includes data from well-known sources like the IEDB server and previous studies, ensuring its validity and reliability for immunogenicity predictions.",
  "dataset/splits": "In our study, we employed two primary data splits for our datasets. The default split used for the MHC Class I dataset was an 80:20 ratio, where 80% of the data was allocated for training and 20% for testing. However, for our larger datasets and to address specific integration challenges, we finalized a 90:10 test-to-train ratio. This adjustment helped in reducing representational overlap within our datasets, such as regions of sequence similarity between sequences, and ensured that each model could run its prediction algorithm independently without interference from previously integrated models.\n\nFor the optimization process, we performed three rounds of optimization using existing optimizer tools coupled with Winsorization. This involved replacing data outliers with more valid data points instead of truncating the data entirely. The parameters for Winsorization were set to the 10th percentile of lowest-value outliers and 20% of greatest-value outliers as part of mini-batch learning.\n\nAdditionally, we utilized intermittent rounds of cross-validation between the integration of MHCSeqNet and HemoPI to provide a \"clean slate\" for each model's prediction algorithm. This approach ensured that the models did not compete for more accurate predictions and helped in maintaining the integrity of the prediction framework.\n\nIn summary, our dataset splits included a default 80:20 ratio for the MHC Class I dataset and a 90:10 ratio for larger datasets. The optimization process involved three rounds of optimization with Winsorization parameters set to the 10th percentile of lowest-value outliers and 20% of greatest-value outliers. Cross-validation rounds were also employed to ensure independent model performance.",
  "dataset/redundancy": "The datasets were split using a 90:10 test-to-train ratio, which differs from the default 80:20 ratio used in previous studies, such as those involving the MHC Class I dataset. This split was chosen to address potential errors during model integration, particularly those arising from interference between previously integrated models. To ensure independence between the training and test sets, intermittent rounds of cross-validation were employed. This process helped to reduce representational overlap within the datasets, minimizing regions of sequence similarity between sequences. For instance, cross-validation between the integration of MHCSeqNet and HemoPI ensured that HemoPI could run its prediction algorithm without being skewed by MHCSeqNet. Additionally, methods from each model that differed in function within the prediction framework were integrated to prevent competition for more accurate predictions. This approach helped to maintain the independence and integrity of the training and test sets, ensuring that the models could generalize well to new data. The distribution of the datasets in this study is designed to enhance prediction accuracy and reliability, aligning with the objectives of maintaining high computing speed and accuracy in the deep learning models used.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study is based on deep neural networks (DNNs), specifically utilizing recurrent neural networks with Gated Recurrent Units (GRUs). This class of machine-learning algorithms is well-established and widely used in various fields, including bioinformatics and vaccine design.\n\nThe algorithm is not entirely new; it builds upon existing frameworks like MHCSeqNet, which is a deep neural network model for universal MHC binding prediction. We adapted and integrated methods from different models to enhance prediction accuracy and reduce representational overlap within our datasets. For instance, we used an Adam algorithm and a Xavier initialization method to set up the DNN parameters, including learning rate, optimizers, epochs, and batch size.\n\nThe reason this algorithm was not published in a machine-learning journal is that our primary focus was on applying and optimizing these techniques for specific biological problems, particularly in the context of vaccine design and epitope prediction. The integration of methods from different models and the optimization processes were tailored to address the unique challenges and requirements of our study, such as handling large datasets and ensuring high prediction accuracy.\n\nAdditionally, we performed three rounds of optimization using existing optimizer tools coupled with Winsorization, which involves replacing data outliers with more valid data points instead of truncating existing data entirely. This process helped to maintain high computing speed while optimizing different parameters to achieve high accuracy. The hyperparameter values, including learning rate, optimizers, epochs, and batch size, were carefully selected and adjusted based on the characteristics of our datasets and the performance of similar models like DeepVacPred.",
  "optimization/meta": "The model described in this publication is indeed a meta-predictor, integrating multiple machine-learning algorithms to enhance prediction accuracy. The primary models involved in this integration are DeepVacPred, MHCSeqNet, and HemoPI. Each of these models contributes unique functionalities to the overall prediction framework.\n\nDeepVacPred is utilized for predicting binding affinities for linear B-cell epitopes, Cytotoxic T Lymphocytes (CTL) epitopes, and Helper T Lymphocytes (HTL) epitopes. It serves as a reference for these predictions, although it had limited data coverage for the tumor peptides used in the study.\n\nMHCSeqNet employs an amino acid embedding model, which differs from traditional protein-encoding systems that use an entire peptide sequence as a single input. This model helps in optimizing predictions for MHC Class I peptides by removing duplicated and ambiguous entries, thereby improving prediction accuracy.\n\nHemoPI is referenced for its multivariate outlier detection methods, which are used to predict hemolytic toxicity values for selected peptides. Although hemolytic toxicity is not used as a checkpoint filter for IEDB-obtained data, the methods from HemoPI are crucial for optimizing and removing outliers from the previously integrated models.\n\nTo ensure that the training data is independent, several measures were taken. The test-to-train ratio was finalized as 90:10, as opposed to the default 80:20 ratio. This adjustment helped to reduce representational overlap within the datasets, such as regions of sequence similarity between sequences. Additionally, intermittent rounds of cross-validation between the integration of MHCSeqNet and HemoPI provided a \"clean slate\" for each model to run its prediction algorithm without interference from previously integrated models. This approach ensured that the models did not compete for more accurate predictions, maintaining the independence of the training data.",
  "optimization/encoding": "For the data encoding and preprocessing, we employed several strategies to enhance the prediction accuracy of our models. Initially, we used hydrophilicity, exposed surface area, amino acid sequence, and polarity properties to encode the data. These properties were chosen for their relevance to the biological functions of the peptides being studied. Additionally, we incorporated physiochemical properties used by the NetMHCPan server to further enrich the data representation.\n\nTo address potential errors during integration and reduce representational overlap within our datasets, we implemented a 90:10 test-to-train ratio, differing from the default 80:20 ratio used for the MHC Class I dataset. This approach helped minimize interference from previously integrated models, such as regions of sequence similarity between sequences.\n\nWe performed three rounds of optimization using existing optimizer tools coupled with Winsorization. Winsorization involved replacing data outliers with more valid data points instead of truncating the data entirely. The parameters for Winsorization were set to the 10th percentile of lowest-value outliers and 20% of greatest-value outliers as part of mini-batch learning. This process ensured that the data used for training was more robust and less prone to the effects of outliers.\n\nFurthermore, we utilized intermittent rounds of cross-validation between the integration of MHCSeqNet and HemoPI. This provided a \"clean slate\" for HemoPI to run its prediction algorithm without the concern of MHCSeqNet skewing its accuracy. We also integrated methods from each model that differed in function within the prediction framework to avoid competition for more accurate predictions.\n\nFor the deep learning model, we used an Adam algorithm and a Xavier initialization method to set up the parameters, including learning rate, optimizers, epochs, and batch size. The learning rate was set to 0.001, based on the efficient program runtime observed with the DeepVacPred server. The number of epochs was adjusted between 6000 and 8000 depending on whether we used an IEDB dataset or a smaller in-house dataset. The batch size was kept constant to randomize the selection of peptides regardless of dataset variation.\n\nOverall, these encoding and preprocessing steps were designed to improve the quality and reliability of the data used in our machine-learning algorithms, ultimately enhancing the accuracy and robustness of our predictions.",
  "optimization/parameters": "In the optimization process of our model, several hyperparameters were considered to balance computing speed and accuracy. The primary hyperparameters included:\n\n* Learning rate, with values tested at 0.0001, 0.001, and 0.002.\n* Optimizers, which included Stochastic Gradient Descent (SGD), RMSProp, and Adam.\n* Epochs, ranging from 2000 to 10,000.\n* Batch size, with options of 512, 1024, 2048, and 4096.\n\nThe learning rate was chosen based on the efficiency observed in the DeepVacPred server, which used a learning rate of 0.001. This value was selected to maintain a high computing speed while ensuring model accuracy. The number of epochs was adjusted based on the learning rate, with more epochs used for lower learning rates to allow sufficient data parsing. The batch size was kept constant for smaller datasets to randomize peptide selection, ensuring variability in the data.\n\nAdditionally, the test-to-train ratio was set at 90:10 for in-house datasets, differing from the default 80:20 ratio used in other contexts. This adjustment helped reduce representational overlap and potential errors from previously integrated models. Three rounds of optimization were performed using the optimizer tools coupled with Winsorization to handle data outliers, enhancing the model's robustness.\n\nIn summary, the model utilized a combination of learning rate, optimizers, epochs, and batch size as key hyperparameters. These parameters were selected and adjusted through a process of cross-validation and optimization to achieve a balance between computational efficiency and predictive accuracy.",
  "optimization/features": "The optimization process involved several key input features to enhance prediction accuracy. Initially, hydrophilicity, exposed surface area, amino acid sequence, and polarity properties were utilized. These features were chosen to complement the physiochemical properties already used by the NetMHCPan server. Additionally, immunogenicity was calculated using the amino acid properties of each peptide, serving as a positive control to ensure consistency between the NetMHCPan server and our deep learning tool.\n\nFeature selection was performed to ensure that the models did not compete for more accurate predictions. Methods from each model that differed in function within the prediction framework were integrated. This approach helped to reduce representational overlap within the datasets, such as regions of sequence similarity between sequences. The process included intermittent rounds of cross-validation between the integration of MHCSeqNet and HemoPI, providing a \"clean slate\" for each model to run its own prediction algorithm without interference.\n\nThe number of input features (f) varied depending on the specific properties and methods integrated from different models. The exact count of features is not explicitly stated, but it is clear that multiple properties and methods were combined to enhance the overall prediction accuracy. The feature selection process was conducted using the training set only, ensuring that the models were trained on a diverse and representative dataset. This approach helped to maintain high computing speed while optimizing different parameters for accuracy.",
  "optimization/fitting": "The fitting method employed in our study involved a careful balance to ensure neither overfitting nor underfitting occurred. To address the potential issue of having a large number of parameters relative to the number of training points, several strategies were implemented.\n\nFirstly, we utilized a 90:10 test-to-train ratio, which provided a substantial amount of training data. This ratio helped in ensuring that the model had enough data to learn the underlying patterns without memorizing the training set, thus mitigating overfitting.\n\nAdditionally, we performed three rounds of cross-validation. This process helped in providing a \"clean slate\" for each model, allowing them to run their prediction algorithms independently without interference from previously integrated models. This step was crucial in reducing representational overlap within our datasets, such as regions of sequence similarity between sequences.\n\nWe also integrated methods from each model that differed in function within the prediction framework. This approach ensured that the models did not compete for more accurate predictions, further reducing the risk of overfitting.\n\nTo handle data outliers, we employed Winsorization, which involved replacing data outliers with more valid data points instead of truncating existing data entirely. The parameters for this Winsorization were limited to the 10th percentile of lowest-value outliers and 20% of greatest-value outliers as part of mini-batch learning. This method helped in maintaining the integrity of the data while reducing the impact of outliers.\n\nFurthermore, we used hydrophilicity, exposed surface area, amino acid sequence, and polarity properties to enhance prediction accuracy. These properties, along with the physiochemical properties used by the NetMHCPan server, provided a robust framework for the model to learn from.\n\nTo rule out underfitting, we performed three rounds of optimization using existing optimizer tools coupled with Winsorization. This process ensured that the model was adequately trained and could generalize well to new data.\n\nThe hyperparameter values of the DNN training framework were carefully selected to maintain a high computing speed while optimizing different parameters to ensure high accuracy. The learning rate, optimizers, epochs, and batch size were all tuned to achieve this balance.\n\nIn summary, the fitting method involved a combination of data splitting, cross-validation, Winsorization, and hyperparameter tuning to ensure that the model neither overfitted nor underfitted the data. These strategies collectively contributed to the robustness and accuracy of our predictions.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was Winsorization, which involves replacing data outliers with more valid data points rather than truncating them entirely. This process was repeated in three rounds of optimization, focusing on the 10th percentile of lowest-value outliers and the 20th percentile of greatest-value outliers. This approach helped in maintaining the integrity of the data while reducing the impact of extreme values that could skew the model's predictions.\n\nAdditionally, we utilized cross-validation to address potential errors arising from interference between previously integrated models. By employing intermittent rounds of cross-validation between the integration of MHCSeqNet and HemoPI, we ensured that each model could run its prediction algorithm independently, without the risk of one model skewing the accuracy of the other. This method provided a \"clean slate\" for each model, enhancing the overall reliability of the predictions.\n\nWe also integrated methods from each model that differed in function within the prediction framework. This strategy prevented the models from competing for more accurate predictions, thereby reducing the likelihood of overfitting to specific patterns in the data. By diversifying the prediction methods, we aimed to capture a broader range of relevant features, leading to more generalized and robust predictions.\n\nFurthermore, we adjusted the test-to-train ratio to 90:10, which helped in reducing representational overlap within our datasets. This adjustment minimized the risk of the model memorizing the training data, thereby improving its ability to generalize to new, unseen data. The use of different optimizers, such as SGD, RMSProp, and Adam, along with varying learning rates, epochs, and batch sizes, also contributed to preventing overfitting. These hyperparameters were carefully tuned to balance the model's complexity and performance, ensuring that it could effectively learn from the data without becoming overly specialized to the training set.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule are indeed available. The hyperparameters for the deep neural network (DNN) training framework include learning rates of 0.0001, 0.001, and 0.002, optimizers such as SGD, RMSProp, and Adam, epochs ranging from 2000 to 10,000, and batch sizes of 512, 1024, 2048, and 4096. These configurations were chosen to balance high computing speed with maintaining high accuracy.\n\nThe optimization process involved three rounds of optimization using the optimizer tools coupled with Winsorization. This process replaced data outliers with more valid data points, specifically targeting the 10th percentile of lowest-value outliers and 20% of greatest-value outliers. This approach was part of mini-batch learning to enhance prediction accuracy.\n\nAdditionally, the complete code for the referenced methods, including the learning rate adjustment code based on DeepVacPred parameters, is available in the Supplementary Materials. This code is provided with licensed use from the authors, ensuring that the methods and configurations can be replicated and verified by other researchers.\n\nThe model files and specific optimization parameters are not explicitly detailed in the provided information, but the overall framework and steps taken for optimization are thoroughly documented. This includes the use of an 80-20 or 90-10 data split ratio, the development of the DNN with hidden layers corresponding to the amount of reference data, and the use of the Adam algorithm and Xavier initialization method. These details are crucial for understanding the optimization process and ensuring reproducibility.",
  "model/interpretability": "The model IntegralVac, while leveraging advanced machine learning techniques, incorporates several elements that enhance its interpretability. Unlike purely black-box models, IntegralVac integrates multiple methods and descriptors that provide insights into its decision-making process. For instance, the model utilizes hydrophilicity, exposed surface area, amino acid sequence, and polarity properties to enhance prediction accuracy. These physiochemical properties are well-understood in the context of peptide behavior and immunogenicity, making the model's predictions more interpretable.\n\nAdditionally, IntegralVac employs various binary classifier methods, such as Logistic Regression, Linear and Quadratic Discriminant Analysis, Support Vector Classifier with different kernels, and Adaptive Boosting. These methods are well-documented in the literature, and their outputs can be analyzed to understand the contributions of different features to the final prediction. For example, the use of gradient boosting classifiers, which combine several weaker learning models to produce a robust prediction, allows for the examination of feature importance.\n\nThe model also incorporates cross-validation and optimization techniques, such as Winsorization, to handle data outliers and improve prediction accuracy. These steps are transparent and can be replicated, providing a clear understanding of how the model arrives at its predictions. Furthermore, the integration of methods from different models, such as MHCSeqNet and HemoPI, is done in a way that ensures each model's unique strengths are utilized without competing for accuracy. This modular approach enhances the interpretability of the model by allowing researchers to understand the contribution of each component to the overall prediction.\n\nIn summary, while IntegralVac is a complex model that uses advanced machine learning techniques, it incorporates several elements that enhance its interpretability. The use of well-understood descriptors, transparent optimization techniques, and a modular approach to model integration makes it possible to gain insights into the model's decision-making process.",
  "model/output": "The model primarily focuses on classification tasks, particularly in the context of peptide prediction and vaccine development. It integrates methods from multiple models, such as MHCSeqNet and HemoPI, to enhance prediction accuracy. The use of binary classifier methods like Logistic Regression, Linear and Quadratic Discriminant Analysis, Support Vector Classifier with various kernels, and Adaptive Boosting indicates a classification approach. Additionally, the model employs gradient boosting classifiers to predict hemolytic activity with high accuracy, further emphasizing its classification nature. The final output involves generating a new ROC curve for the integrated model, which is a common evaluation metric for classification models.\n\nThe model also incorporates regression techniques, such as the Winsorization process, to handle outliers and improve the robustness of the prediction framework. This process involves replacing data outliers with more valid data points, which is a regression-based approach to data preprocessing. The resulting regression model is used to confirm the Winsorization of error outliers and simulate predictions using IntegralVac, with NetMHCPan serving as the baseline comparison.\n\nIn summary, the model is designed to handle both classification and regression tasks, with a strong emphasis on classification for peptide prediction and vaccine development. The integration of multiple models and the use of advanced classification methods ensure high prediction accuracy and robustness.",
  "model/duration": "The execution time of the model was optimized to maintain high computing speed while ensuring high accuracy. Several hyperparameters were tuned to achieve this balance. The learning rate was set to 0.001, which was found to be efficient in terms of program runtime. This value was chosen based on the performance of the DeepVacPred server, which also used a learning rate of 0.001 and demonstrated efficient runtime.\n\nThe number of epochs, which denotes the number of iterations run through the entire dataset, was adjusted based on the learning rate. For lower learning rates, a higher number of epochs was used to ensure thorough data parsing. Specifically, the number of epochs alternated between 6000 and 8000, depending on whether an IEDB dataset or a smaller in-house dataset was used. This adjustment helped in maintaining the model's performance across different dataset sizes.\n\nBatch sizes were also varied to optimize execution time. The batch sizes considered were 512, 1024, 2048, and 4096. For smaller datasets, the batch size was kept constant to randomize the selection of peptides, regardless of dataset variation. This approach helped in ensuring that the model's execution time was consistent and efficient.\n\nAdditionally, three rounds of optimization were performed using optimizer tools coupled with Winsorization. This process involved replacing data outliers with more valid data points, which helped in improving the model's accuracy and reducing the impact of outliers on execution time. The parameters for Winsorization were limited to the 10th percentile of lowest-value outliers and 20% of greatest-value outliers, ensuring that the model's performance was not adversely affected by extreme values.\n\nOverall, the model's execution time was carefully managed through the optimization of hyperparameters and the use of techniques like Winsorization. This ensured that the model could run efficiently while maintaining high accuracy in its predictions.",
  "model/availability": "The source code for the methods referenced in our study has been made available for licensed use. The complete code for the methods used in the MHCSeqNet tool is included in the Supplementary Materials, specifically in Supplementary File S11. Similarly, the code for the methods used in the HemoPI peptide model is also provided in the Supplementary Materials, in Supplementary File S10. These files contain the necessary instructions and licenses for use, ensuring that other researchers can replicate and build upon our work.\n\nAdditionally, the IntegralVac tool, which integrates multiple models and methods, has been designed to support the input of various peptide lengths and types. The code for retraining IntegralVac to handle these inputs is also available, allowing for flexibility and adaptability in different research contexts. This includes support for peptides of lengths 7\u20139, depending on the dataset, which expands the tool's applicability beyond the standard amino acid length of 9 used in the Swiss-Prot database.\n\nFor those interested in utilizing our models and methods, the provided supplementary files offer a comprehensive resource. They include detailed instructions and the necessary licenses, ensuring that the code can be used responsibly and ethically within the scientific community. This approach aligns with our commitment to transparency and reproducibility in research.",
  "evaluation/method": "The evaluation of our method, IntegralVac, involved several rigorous steps to ensure its accuracy and reliability. We employed additional rounds of cross-validation to address limitations arising from larger datasets. This process finalized the test-to-train ratio at 90:10, differing from the default 80:20 ratio used for the MHC Class I dataset. This adjustment helped mitigate errors during integration that could arise from interference between previously integrated models, reducing representational overlap within our datasets.\n\nIntermittent rounds of cross-validation were conducted between the integration of MHCSeqNet and HemoPI. This approach provided a \"clean slate\" for HemoPI to run its prediction algorithm without the risk of MHCSeqNet skewing its accuracy. We also integrated methods from each model that differed in function within the prediction framework to prevent competition for more accurate predictions.\n\nThree rounds of optimization were performed using existing optimizer tools coupled with Winsorization. This involved replacing data outliers with more valid data points instead of truncating the data entirely. The parameters for Winsorization were set to the 10th percentile of lowest-value outliers and 20% of greatest-value outliers as part of mini-batch learning.\n\nTo enhance prediction accuracy, we utilized properties such as hydrophilicity, exposed surface area, amino acid sequence, and polarity. These properties, along with the physiochemical properties used by the NetMHCPan server, were incorporated into our deep learning tool. Immunogenicity was calculated using the amino acid properties of each peptide and served as a positive control, projected to remain unchanged between the NetMHCPan server and our tool.\n\nThe evaluation also included the use of the DeepVacPred server as a reference for predicting binding affinities for linear B-cell epitopes, Cytotoxic T Lymphocytes (CTL) epitopes, and Helper T Lymphocytes (HTL) epitopes. Despite DeepVacPred's capability to process larger datasets, it had limited data coverage with respect to the tumor peptides used in our study. The discrimination threshold was repeatedly lowered to define more extensive target epitope data, eventually stabilizing at 0.32. Lower threshold values indicate a weaker classification ability, limiting the prediction tool's potential validity.\n\nThe accuracy and AUC of IntegralVac\u2019s predictions were greater than those of the control methods but remained lower than the referenced methods, such as DeepVacPred and MHCSeqNet. This discrepancy may be attributed to IntegralVac's increased coverage and complexity of the dataset, as well as the use of multiple sources for peptide data, which affected sensitivity and specificity values and lowered accuracy.\n\nIn summary, the evaluation of IntegralVac involved extensive cross-validation, optimization, and the integration of diverse methods to ensure robust and reliable predictions.",
  "evaluation/measure": "The performance of our model, IntegralVac, was primarily evaluated using the receiver operating characteristic (ROC) curve. This metric is widely recognized in the literature for assessing the diagnostic performance of classifier models. The ROC curve plots the true positive rate against the false positive rate at various threshold settings, providing a comprehensive view of the model's ability to discriminate between positive and negative classes.\n\nThe area under the ROC curve (AUC) was used as a numerical value to indicate the model's accuracy. A larger AUC signifies better performance, and our results showed a large AUC for the tested datasets, suggesting high accuracy. This metric is particularly useful because it summarizes the overall ability of the model to rank true positives higher than false positives, regardless of the chosen threshold.\n\nAdditionally, we considered the false positive fraction (FPF), which represents the percentage of data incorrectly marked as immunogenic. The FPF decreases as the threshold is lowered, and our model demonstrated a low FPF, further supporting its high accuracy.\n\nWhile these metrics provide a robust evaluation of our model's performance, it is important to note that we did not report other common metrics such as precision, recall, or F1-score. These metrics could offer additional insights into the model's performance, especially in imbalanced datasets. However, given our focus on the ROC curve and AUC, we believe our reported metrics are representative and align with established practices in the field. Future work could include a more comprehensive set of performance metrics to provide an even more detailed evaluation of IntegralVac's capabilities.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison with publicly available methods using benchmark datasets. We utilized the DeepVacPred server as a reference for predicting binding affinities for various epitopes, including linear B-cell epitopes, Cytotoxic T Lymphocytes (CTL) epitopes, and Helper T Lymphocytes (HTL) epitopes. This comparison was crucial for assessing the performance of our model, IntegralVac, especially given the limitations of DeepVacPred in terms of data coverage for tumor peptides.\n\nWe also compared IntegralVac's predictions with those from the NetMHCPan server, which is a widely used tool for predicting MHC binding affinities. The comparison focused on accuracy and the area under the curve (AUC) values. Our results showed that while IntegralVac's AUC and accuracy values were greater than those of the control methods, they remained lower than the referenced methods like DeepVacPred and MHCSeqNet. This discrepancy can be attributed to the increased coverage and complexity of the dataset used by IntegralVac, which included multiple sources for peptide data, thereby affecting sensitivity and specificity values.\n\nAdditionally, we performed a comparison with simpler baselines to ensure that our model's improvements were not merely due to increased computational power or data size. For instance, we used the Vaxijen server for antigenicity predictions, which employs auto cross-covariance methods to transform protein sequences into amino acid property vectors. Similarly, the AntigenPro server was used for antigenicity predictions based on sequence features like length and residue charge. The AllergenFP server, which also uses auto cross-covariance methods, was utilized for allergenicity predictions.\n\nThese comparisons provided a comprehensive evaluation of IntegralVac's performance, demonstrating its reliability and accuracy in predicting immunogenicity and other peptide properties. The consistent results across different datasets and methods validated IntegralVac's effectiveness in handling complex and heterogeneous data.",
  "evaluation/confidence": "The evaluation of IntegralVac's performance involved several key metrics, including the area under the curve (AUC) and false positive rate (FPF). The ROC curve, which plots the true positive rate against the false positive rate at various threshold settings, demonstrated a large AUC, indicating high accuracy in predicting and sorting epitope subunits. This suggests that the model's predictions are reliable and that the performance metrics are robust.\n\nTo ensure the statistical significance of our results, we employed cross-validation techniques. Specifically, we used additional rounds of cross-validation to address limitations arising from larger datasets. This process helped to finalize the test-to-train ratio at 90:10, which differed from the default 80:20 ratio used for the MHC Class I dataset. This adjustment was crucial for reducing representational overlap within our datasets, thereby minimizing the risk of errors due to interference from previously integrated models.\n\nThe integration of methods from different models, such as MHCSeqNet and HemoPI, was carefully designed to avoid competition for more accurate predictions. Instead, we chose methods that differed in function within the prediction framework. This approach, coupled with three rounds of optimization using existing optimizer tools and Winsorization, helped to enhance the prediction accuracy.\n\nThe Winsorization process involved replacing data outliers with more valid data points, rather than truncating the data entirely. This was done to ensure that the model's predictions were not skewed by outliers. The parameters for Winsorization were limited to the 10th percentile of lowest-value outliers and 20% of greatest-value outliers, which was part of the mini-batch learning process.\n\nIn terms of statistical significance, the results showed that IntegralVac produced reliable results for Class I epitope data in the range of 2500\u20135000 peptides per dataset. The top epitope rankings generated by IntegralVac did not differ significantly from those of the IEDB NetMhcPan server, suggesting that the control immunogenicity rankings already had high accuracy. However, IntegralVac demonstrated an increase in prediction accuracy of approximately 1.6% and an increase in AUC of 5.2% compared to the NetMHCPan server.\n\nThese improvements, though modest, indicate that IntegralVac's integration of prior deep learning tools has enhanced its performance. The statistical significance of these results is supported by the rigorous evaluation methods employed, including cross-validation and outlier detection techniques. This ensures that the claims of superiority over other methods and baselines are well-founded.",
  "evaluation/availability": "Not enough information is available."
}