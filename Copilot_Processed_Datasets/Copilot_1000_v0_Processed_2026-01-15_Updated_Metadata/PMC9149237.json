{
  "publication/title": "Machine Learning Models for Predicting the Occurrence of Respiratory Diseases Using Climatic and Air-Pollution Factors.",
  "publication/authors": "Ku Y, Kwon SB, Yoon JH, Mun SK, Chang M",
  "publication/journal": "Clinical and experimental otorhinolaryngology",
  "publication/year": "2022",
  "publication/pmid": "34990536",
  "publication/pmcid": "PMC9149237",
  "publication/doi": "10.21053/ceo.2021.01536",
  "publication/tags": "- Machine Learning\n- Respiratory Diseases\n- Climate\n- Air Pollution\n- Gradient Boosting\n- Gaussian Process Regression\n- Predictive Modeling\n- Environmental Factors\n- Public Health\n- Disease Forecasting",
  "dataset/provenance": "The dataset used in this study originates from the National Health Insurance Service (NHIS) of South Korea, which is accessible to all citizens. This service records diagnosis-related information whenever citizens receive medical treatment, making it a comprehensive source for estimating disease occurrences. Specifically, the NHIS provides data on the daily number of patients treated for respiratory diseases, which are prevalent in South Korea.\n\nThe study area was limited to Seoul, the capital city of South Korea, with a population of approximately 10 million. The dataset includes the daily number of patients treated for respiratory diseases in Seoul, along with the levels of climatic and air-pollution factors. The data spans from January 1, 2014, to December 31, 2019.\n\nThe dataset comprises daily records, resulting in a substantial number of data points over the six-year period. However, the exact number of data points is not explicitly stated. It is important to note that data from holidays and the days immediately following holidays were excluded from the analysis due to significant differences in patient numbers compared to regular days. This preprocessing step ensures that the dataset is more consistent and representative of typical daily patterns.\n\nThe use of NHIS data is particularly valuable because very few countries have such comprehensive insurance systems that provide detailed and accessible health records. This makes the research significantly unique and beneficial for understanding the influence of climatic and air-pollution factors on respiratory diseases. The dataset has not been extensively used in previous studies, making this research a pioneering effort in integrating climatic and air-pollution factors to predict respiratory disease occurrences.",
  "dataset/splits": "In our study, we employed a temporal validation approach to split the dataset into two primary splits: a training set and a test set. The training set comprised the first 75% of the data, spanning from 2014 to the first half of 2018. Within this training set, a holdout validation method was used, where 30% of the training data was reserved for validation purposes. The test set consisted of the remaining 25% of the data, which was unseen during the training phase and covered the latter part of 2018 and 2019.\n\nThe dataset initially included daily records of respiratory disease patients, along with climatic and air-pollution factors. However, after preprocessing, data from holidays and the days immediately following holidays were excluded due to significant differences in patient numbers compared to regular days. This exclusion was based on statistical analysis using one-way ANOVA and Bonferroni post hoc testing, which revealed that the number of respiratory disease patients on holidays was significantly lower than on regular days, while the number on days after holidays was significantly higher.\n\nThe final dataset used for model training and testing thus consisted of data from regular days only. The specific distribution of data points in each split is as follows:\n\n* Training set: 75% of the data from 2014 to the first half of 2018.\n* Validation set (within the training set): 30% of the training data.\n* Test set: 25% of the data from the latter part of 2018 to 2019.\n\nThis temporal splitting approach ensured that the model was trained on historical data and evaluated on more recent, unseen data, providing a robust assessment of its predictive performance.",
  "dataset/redundancy": "The dataset used in this study was split temporally to ensure independence between the training and test sets. The first 75% of the data, spanning from 2014 to the first half of 2018, was designated as the training set. This set was further divided using holdout validation, where 30% of the training data was used for internal validation during model development. The remaining 25% of the data, covering the latter part of 2018 and all of 2019, served as the test set. This temporal splitting ensures that the test set consists of unseen data, which is crucial for evaluating the model's predictive performance on future, unobserved data.\n\nThe distribution of the dataset is unique compared to many previously published machine learning datasets, as it focuses on daily respiratory disease patient counts in Seoul, South Korea, along with corresponding climatic and air-pollution factors. This specificity to a particular geographic area and time frame, along with the inclusion of both climatic and air-pollution data, sets it apart from more general or synthetic datasets. The temporal validation approach used here is particularly suited for time series forecasting, ensuring that the model's predictions are evaluated on data that was not available during the training phase. This method helps to simulate real-world scenarios where predictions are made for future, unseen data.",
  "dataset/availability": "The data used in this study, including the daily number of patients treated for respiratory diseases and the levels of climatic and air-pollution factors, were obtained from the National Health Insurance Service (NHIS) and other relevant sources. However, the specific datasets used for this research are not publicly released in a forum. The data were collected and analyzed under the approval of the Institutional Review Board of Chung-Ang University Hospital, ensuring compliance with ethical standards and data privacy regulations. The study period spanned from January 1, 2014, to December 31, 2019, focusing on Seoul, the capital city of South Korea.\n\nThe data preprocessing steps, such as the exclusion of holidays and days after holidays, as well as the application of a 7-day moving average, were clearly documented. The machine-learning models were developed using gradient boosting and Gaussian process regression (GPR) methods, with performance evaluated using the coefficient of determination (R2) and root mean square error (RMSE). The models were trained on the first 75% of the data and tested on the remaining 25%, ensuring a temporal validation approach.\n\nWhile the detailed datasets are not publicly available, the methods and results are thoroughly described, allowing for reproducibility by other researchers. The study adheres to the tenets of the Declaration of Helsinki, and the written informed consent requirement was waived due to the use of anonymized data. For further details on the data and methods, interested parties may refer to the supplementary materials or contact the corresponding author.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to the class of non-parametric Bayesian algorithms and supervised machine learning techniques based on decision trees.\n\nThe algorithms employed are Gaussian Process Regression (GPR) and Gradient Boosting. GPR is a well-established method in the field of machine learning, particularly known for its application in time series data prediction. It operates under Gaussian assumptions, where data points with similar input values tend to have similar outputs. The model is defined using a covariance function, or kernel, and its hyperparameters, which specify how input changes affect the output.\n\nGradient Boosting, on the other hand, is a supervised machine learning technique that combines weak prediction models into a single strong learner through an iterative framework. At each step, the algorithm fits the difference between the observed response and the aggregated prediction of all previous learners by minimizing the mean-squared error. This method is known for providing both high accuracy and interpretability.\n\nBoth algorithms are not new but are widely recognized and used in the machine learning community. The choice to use these algorithms in this study was driven by their effectiveness in handling the specific types of data and prediction tasks at hand. The focus of this study is on applying these algorithms to predict the occurrence of respiratory diseases using climatic and air-pollution factors, rather than on developing new machine-learning algorithms. Therefore, publishing in a machine-learning journal was not the primary objective.",
  "optimization/meta": "The models developed in this study do not function as meta-predictors. Instead, two distinct prediction models were created using gradient boosting and Gaussian process regression (GPR) methods. These models were trained independently using the same dataset, which included climatic and air-pollution factors to predict the daily number of respiratory disease patients.\n\nThe gradient boosting model is a supervised machine learning technique based on decision trees. It combines weak prediction models into a single strong learner in an iterative framework, minimizing the mean-squared error at each step. The GPR model, on the other hand, is a non-parametric Bayesian algorithm popularly applied to prediction in time series data. It uses a covariance function, or kernel, to determine how the response at one point is affected by responses at other points.\n\nBoth models were trained using the same dataset, with the first 75% of the data from 2014 to the first half of 2018 used for training. Holdout validation was performed using 30% of the training data, and the trained models were then prospectively evaluated with the remaining 25% of the data from the latter part of 2018 to 2019. This approach ensures that the training data is independent for each model, as they were trained on the same dataset but evaluated on different subsets of the data.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for developing accurate machine learning models. Initially, we focused on regular days, excluding holidays and the days following holidays due to significant differences in respiratory disease patient numbers. This decision was supported by statistical tests, including one-way ANOVA and Bonferroni post hoc tests, which confirmed the necessity of this exclusion.\n\nWe applied a 7-day moving average to the input features to smooth out short-term fluctuations and highlight longer-term trends. This step was essential for capturing the underlying patterns in the data, which are often obscured by daily variations.\n\nFollowing this, we employed a relief-based feature selection algorithm to identify the most relevant climatic and air-pollution factors. This algorithm helped us determine the importance of each feature by evaluating their statistical relevance to the target response. Features with negative weights were excluded from further analysis, ensuring that only the most significant factors were considered in model development.\n\nThe selected features included three climatic factors: cloud amount, precipitation, and sunshine duration, and one air-pollution factor: ozone (O3). These factors were chosen based on their ability to influence respiratory disease occurrences, as indicated by the relief-based feature selection algorithm.\n\nThe data was then split into training and test sets. The first 75% of the data, spanning from 2014 to the first half of 2018, was used for model training. Within this training set, holdout validation was performed using 30% of the data to optimize model parameters. The remaining 25% of the data, from the latter part of 2018 to 2019, was used as unseen test data to evaluate the model's predictive performance.\n\nThis preprocessing and encoding strategy ensured that our machine learning models were trained on relevant and high-quality data, enhancing their ability to accurately predict the occurrence of respiratory diseases based on climatic and air-pollution factors.",
  "optimization/parameters": "In our study, we utilized a relief-based feature selection algorithm to determine the most relevant input parameters for our prediction models. This algorithm helped us identify the importance of various climatic and air-pollution factors in predicting the number of respiratory disease patients. Initially, we considered 15 different factors, including cloud amount, average temperature, temperature difference, precipitation, average humidity, atmospheric pressure, daylight duration, sunshine duration, total solar insolation amount, PM2.5, PM10, O3, NO2, CO, and SO2.\n\nAfter applying the relief-based feature selection algorithm and excluding features with negative weights, we narrowed down the number of input parameters. The top features identified were average temperature, daylight duration, average humidity, atmospheric pressure, SO2, total solar insolation amount, CO, and PM2.5. These factors were found to have the strongest influences on the occurrence of respiratory diseases among patients.\n\nThe selection process ensured that only the most relevant parameters were included in the model, enhancing its predictive performance. The final number of parameters used in the model varied depending on the specific algorithm and optimization process, but the key climatic and air-pollution factors remained consistent across different models.",
  "optimization/features": "In the development of our prediction models, we initially considered 15 different climatic and air-pollution factors as potential input features. These features included various climatic variables such as cloud amount, average temperature, precipitation, and sunshine duration, as well as air-pollution factors like ozone (O3), particulate matter (PM2.5 and PM10), nitrogen dioxide (NO2), carbon monoxide (CO), and sulfur dioxide (SO2).\n\nTo enhance the model's performance and focus on the most relevant features, we employed a relief-based feature selection algorithm. This algorithm helped us identify and prioritize the features that had the highest importance for predicting the occurrence of respiratory diseases. Features with negative weights, indicating lower importance, were excluded from the input set during the model development process.\n\nThe feature selection process was conducted using the training data only, ensuring that the model's performance on the test data remained unbiased. This approach allowed us to refine our input features and improve the predictive accuracy of our models. The final set of input features, after applying the relief-based feature selection algorithm, included the most significant climatic and air-pollution factors that influenced the daily number of respiratory disease patients.",
  "optimization/fitting": "In our study, we employed Gaussian Process Regression (GPR) and gradient boosting methods to develop prediction models for respiratory diseases. The GPR model, being a non-parametric Bayesian algorithm, does not explicitly define a fixed number of parameters. Instead, it relies on a covariance function (kernel) and its hyperparameters, which are optimized during training. This approach allows the model to adapt to the complexity of the data without a predefined number of parameters, thus avoiding issues related to an excessively large parameter set relative to the number of training points.\n\nTo address potential overfitting, we utilized Bayesian optimization to select the hyperparameters of the machine learning models. This method ensures that the model's complexity is appropriately tuned to the data, preventing it from fitting noise rather than the underlying patterns. Additionally, we performed temporal validation by splitting the data into temporal folds, where the first 75% of the data was used for training and the remaining 25% for testing. This approach helps in evaluating the model's performance on unseen data, further mitigating overfitting risks.\n\nFor the gradient boosting model, we applied techniques such as setting a minimum leaf size and limiting the number of learning cycles. These adjustments help in controlling the model's complexity and preventing overfitting. The use of holdout validation, where 30% of the training data was reserved for validation, also aided in assessing the model's generalization performance.\n\nUnderfitting was addressed by ensuring that the models were sufficiently complex to capture the underlying patterns in the data. The relief-based feature selection algorithm helped in identifying the most relevant features, which were then used to train the models. This step ensures that the models are not overly simplified, thereby reducing the risk of underfitting.\n\nIn summary, our approach involved careful selection and optimization of hyperparameters, use of temporal validation, and feature selection to balance the model complexity, effectively ruling out both overfitting and underfitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method was the use of temporal validation splitting, which is particularly suited for time series data. This approach involved dividing the data into temporal folds, where the first 75% of the data, spanning from 2014 to the first half of 2018, was used for training. Within this training set, we further performed holdout validation using 30% of the data to tune the models and prevent overfitting. The remaining 25% of the data, which included unseen data from the latter part of 2018 to 2019, was used for prospective evaluation. This temporal splitting ensured that our models were not overfitted to the training data and could generalize well to future, unseen data.\n\nAdditionally, we utilized Bayesian optimization to select the hyperparameters of our machine learning models. This method helps in finding the optimal hyperparameters that minimize the risk of overfitting by exploring the hyperparameter space efficiently. For the Gaussian Process Regression (GPR) model, we optimized the exponential kernel, which includes the signal standard deviation and the characteristic length scale. The characteristic length scale was allowed to vary for each predictor, ensuring that the model could capture the specific relationships between different predictors and the output.\n\nFurthermore, we applied a relief-based feature selection algorithm to identify and exclude features with negative weights. This step helped in reducing the dimensionality of the input data and focusing on the most relevant features, thereby improving the model's performance and reducing the risk of overfitting. The features that showed negative weights were excluded from the input features during the model development process.\n\nIn summary, our approach to preventing overfitting included temporal validation splitting, Bayesian optimization for hyperparameter tuning, and relief-based feature selection. These techniques collectively ensured that our models were robust and could generalize well to new data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, for the Gaussian Process Regression (GPR) model, we optimized an exponential kernel containing the signal standard deviation and the characteristic length scale. For the gradient boosting model, we optimized the minimum leaf size and the number of learning cycles. These details are provided in the methods section of the paper.\n\nThe model files and optimization parameters are not explicitly made available as standalone files. However, the methods and results sections provide comprehensive information on how the models were developed and optimized. This includes the use of Bayesian optimization for hyperparameter selection and the performance metrics such as the coefficient of determination (R2) and root mean square error (RMSE) for evaluating the models.\n\nThe publication is distributed under the terms of the Creative Commons Attribution Non-Commercial License, which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. This license allows researchers to access and utilize the methods and findings described in the paper for non-commercial purposes.",
  "model/interpretability": "The models developed in this study are not entirely black-box. To ensure interpretability, Shapley Additive ExPlanations (SHAP) were employed. SHAP is a method that provides a unified approach to interpreting model predictions by attributing the contribution of each input feature to the final prediction. This approach is based on Shapley values from coalitional game theory, which represent the average marginal contribution of a feature across all possible coalitions.\n\nIn the context of our study, SHAP analysis revealed the global importance of various input features in predicting the occurrence of respiratory diseases. The top four features with the strongest influences were climatic factors: average temperature, daylight duration, average humidity, and atmospheric pressure. These features were followed by air pollution factors such as sulfur dioxide (SO2), total solar insolation amount, carbon monoxide (CO), and particulate matter (PM2.5).\n\nThe SHAP summary plot visually represents how each feature impacts the model's output. For instance, reductions in average temperature, daylight duration, average humidity, SO2, total solar insolation amount, and temperature difference were associated with an increase in the number of respiratory disease patients. Conversely, increases in atmospheric pressure, CO, and PM2.5 were linked to a higher number of respiratory disease patients. This detailed breakdown allows for a clear understanding of how each feature contributes to the model's predictions, making the model more transparent and interpretable.",
  "model/output": "The model developed is a regression model. It predicts the daily number of respiratory disease patients per 10,000 inhabitants using climatic and air-pollution factors. The performance of the model was evaluated using the coefficient of determination (R2) and the root mean square error (RMSE) between the original and estimated numbers of respiratory disease patients. Two different prediction models were developed using gradient boosting and Gaussian process regression (GPR) methods. The R2 values for both models were around 0.67-0.68, and the RMSE values were around 13.8-13.9, indicating a good fit for the regression task. The SHAP analysis was used to interpret the estimated output of each machine learning model, providing insights into how different features contribute to the prediction of respiratory disease occurrences.",
  "model/duration": "The execution time for the model development process involved several stages. Initially, data preprocessing was conducted, which included selecting regular days and applying a 7-day moving average to the input features. This step was crucial for preparing the data for feature selection and model training.\n\nFollowing preprocessing, a relief-based feature selection algorithm was applied to identify the most relevant features. This algorithm helped in narrowing down the input features to those that had the strongest influence on the prediction of respiratory disease patients.\n\nThe model training session utilized the first 75% of the data, spanning from 2014 to the first half of 2018. During this phase, holdout validation was performed using 30% of the training data to optimize the model's hyperparameters. This step was essential for ensuring that the model could generalize well to unseen data.\n\nAfter hyperparameter optimization, the trained model was prospectively evaluated using the remaining 25% of the data, which covered the latter part of 2018 and 2019. This evaluation provided insights into the model's performance on unseen data, which is critical for assessing its predictive accuracy.\n\nThe entire process, from data preprocessing to model evaluation, was conducted using MATLAB R2020a. The specific execution times for each stage were not explicitly detailed, but the overall workflow involved iterative steps of data preparation, feature selection, model training, and evaluation.\n\nThe performance of the models was assessed using metrics such as the coefficient of determination (R2) and root mean square error (RMSE). For instance, the gradient boosting model achieved an R2 of 0.68 and an RMSE of 13.8, while the Gaussian Process Regression (GPR) model with an exponential kernel had an R2 of 0.67 and an RMSE of 13.9. These metrics indicate the models' ability to predict the number of respiratory disease patients accurately.\n\nIn summary, the model development process was comprehensive and involved multiple stages of data preparation, feature selection, and model training. The use of MATLAB R2020a facilitated the execution of these steps, and the performance metrics provided a clear indication of the models' predictive capabilities.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study involved a combination of temporal validation and holdout validation techniques. Initially, the dataset was split into temporal folds, with the first 75% of the data, spanning from 2014 to the first half of 2018, designated as the training set. This training set was further divided, with 30% of the data used for holdout validation to tune the model parameters. The remaining 70% of the training set was used to develop the prediction models.\n\nFollowing the training phase, the models were prospectively evaluated using the unseen data, which constituted the remaining 25% of the dataset. This test set included data from the latter part of 2018 to 2019. This approach ensured that the models were tested on data that was not used during the training process, providing a robust evaluation of their predictive performance.\n\nTo assess the performance of the models, two primary metrics were calculated: the coefficient of determination (R\u00b2) and the root mean square error (RMSE). These metrics were used to compare the predicted number of respiratory disease patients with the actual numbers. The R\u00b2 value indicates the proportion of the variance in the dependent variable that is predictable from the independent variables, while the RMSE provides a measure of the average magnitude of the errors between predicted and actual values.\n\nAdditionally, Bayesian optimization was utilized to select the hyperparameters of the machine learning models, ensuring that the models were optimized for the best possible performance. The SHAP (SHapley Additive exPlanations) method was employed to interpret the contributions of specific inputs to the predictions, providing insights into the factors influencing the model's outputs. This comprehensive evaluation approach ensured that the models were rigorously tested and their performance was thoroughly understood.",
  "evaluation/measure": "In our study, we employed two primary performance metrics to evaluate the effectiveness of our prediction models for respiratory diseases: the coefficient of determination (R2) and the root mean square error (RMSE). These metrics are widely used in the literature for assessing the performance of regression models, making our evaluation approach representative and comparable to other studies in the field.\n\nThe coefficient of determination, R2, indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. An R2 value closer to 1 signifies a better fit of the model to the data. In our case, the gradient boosting model achieved an R2 of 0.68, while the Gaussian process regression (GPR) model had an R2 of 0.67. These values suggest that both models explain a substantial portion of the variance in the number of respiratory disease patients.\n\nThe root mean square error, RMSE, measures the average magnitude of the errors between predicted and actual values. A lower RMSE indicates better model performance. Our gradient boosting model had an RMSE of 13.8, and the GPR model had an RMSE of 13.9. These values provide a clear indication of the models' predictive accuracy.\n\nBy reporting both R2 and RMSE, we offer a comprehensive view of our models' performance, addressing both the explanatory power and the predictive accuracy. This set of metrics is standard in the literature, ensuring that our results are interpretable and comparable to other studies in the domain of respiratory disease prediction using climatic and air-pollution factors.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, we focused on developing and optimizing our own machine learning models for predicting respiratory diseases using climatic and air-pollution factors.\n\nWe did, however, compare different machine learning approaches within our study. Specifically, we evaluated the performance of Gaussian Process Regression (GPR) and gradient boosting methods. For GPR, we used an exponential kernel and optimized its hyperparameters, including the signal standard deviation and characteristic length scale. We also explored a sparse version of GPR using a regressor approximation subset to investigate changes in prediction performance.\n\nThe gradient boosting model was implemented with specific hyperparameters, such as a minimum leaf size of 30 and the number of learning cycles set to 100. We found that both gradient boosting and GPR demonstrated similar performance after hyperparameter optimization, with gradient boosting achieving an R2 of 0.68 and an RMSE of 13.8, and GPR achieving an R2 of 0.67 and an RMSE of 13.9.\n\nAdditionally, we compared these models to a simpler baseline by evaluating the sparse GPR, which showed slightly lower performance with an R2 of 0.64 and an RMSE of 14.3. This comparison helped us understand the trade-offs between model complexity and prediction accuracy.\n\nIn summary, while we did not compare our methods to publicly available benchmarks, we conducted internal comparisons between different machine learning techniques and their variations to ensure robust model development and evaluation.",
  "evaluation/confidence": "In our study, we employed several statistical methods to ensure the robustness and significance of our results. To assess the performance of our prediction models, we calculated the coefficient of determination (R\u00b2) and the root mean square error (RMSE) between the original and estimated numbers of respiratory disease patients. These metrics provide a clear indication of how well our models perform in predicting respiratory disease cases.\n\nTo determine the statistical significance of the differences observed between different day groups (regular days, holidays, and days after holidays), we conducted a one-way ANOVA. The results showed significant differences between these groups (F(2, 2243)=1,287.4, P<0.001). Post hoc testing using the Bonferroni correction revealed that the number of respiratory disease patients on holidays was significantly lower than on regular days (P<0.001), while the number of patients on days after holidays was significantly higher than on regular days (P<0.001). These findings are statistically significant and support the exclusion of holiday and day-after-holiday data from further analysis.\n\nAdditionally, we applied Bayesian optimization to select the hyperparameters of our machine learning models, ensuring that our models were optimized for the best possible performance. The use of temporal validation, where the first 75% of the data was used for training and the remaining 25% for testing, further enhanced the reliability of our results. This approach helps in evaluating the model's performance on unseen data, providing a more realistic assessment of its predictive capabilities.\n\nIn summary, our evaluation methods included statistical tests to confirm the significance of our findings, rigorous model optimization, and a robust validation strategy. These steps collectively ensure that our conclusions are reliable and that our models demonstrate superior performance compared to baselines.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data consists of sensitive health and environmental information that is subject to privacy regulations and institutional policies. Therefore, to protect patient confidentiality and comply with ethical guidelines, the raw data cannot be released publicly. However, we have provided detailed descriptions of the data preprocessing steps, feature selection methods, and the statistical analyses performed in our publication. This information should enable other researchers to replicate the study's methodology using their own datasets, ensuring transparency and reproducibility. For specific inquiries or collaborations regarding the data, interested parties are encouraged to contact the corresponding author directly."
}