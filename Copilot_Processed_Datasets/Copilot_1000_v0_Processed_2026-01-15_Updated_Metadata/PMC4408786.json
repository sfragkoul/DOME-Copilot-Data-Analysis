{
  "publication/title": "miRBoost: boosting support vector machines for microRNA precursor classification.",
  "publication/authors": "Tran Vdu T, Tempel S, Zerath B, Zehraoui F, Tahi F",
  "publication/journal": "RNA (New York, N.Y.)",
  "publication/year": "2015",
  "publication/pmid": "25795417",
  "publication/pmcid": "PMC4408786",
  "publication/doi": "10.1261/rna.043612.113",
  "publication/tags": "- microRNA prediction\n- classification\n- boosting\n- support vector machine (SVM)\n- imbalanced data\n- machine learning\n- bioinformatics\n- computational biology\n- gene expression\n- post-transcriptional regulation\n- miRNA precursor\n- cross-validation\n- feature selection\n- sensitivity\n- specificity\n- g-mean\n- ROC space\n- computational tools\n- prediction performance\n- execution time",
  "dataset/provenance": "The dataset used in our study is sourced from the miRBase database, specifically version 18. We focused on eukaryotic genomes that contain at least 100 miRNAs. From these genomes, we selected pre-miRNAs that are less than 400 nucleotides in length. To ensure the quality of our dataset, we removed sequences reported as mis-annotated in later versions of miRBase (versions 19 and 20). Additionally, we used ncRNAclassifier to discard sequences that are mis-annotated due to their association with transposable elements.\n\nThe resulting positive dataset includes 1279 sequences for human and 3082 sequences for cross-species. For the negative dataset, we generated sequences from exonic regions of protein-coding genes that could fold into hairpin-like structures and verified several pre-miRNA characteristics. We also included noncoding RNAs that are not pre-miRNAs from various databases.\n\nThis dataset has been used in our previous work and is also commonly used by the community for similar studies. The selection process ensures that our dataset is robust and representative for evaluating the performance of pre-miRNA classification methods.",
  "dataset/splits": "In our study, we employed a fivefold cross-validation approach to evaluate the classification performance of miRBoost. This method involves dividing the dataset into five subsets, or folds. The model is then trained on four of these folds and tested on the remaining fold. This process is repeated five times, with each fold serving as the test set once. Consequently, each data point is used for both training and testing exactly once.\n\nThe distribution of data points in each fold is designed to be as balanced as possible, ensuring that each fold is representative of the overall dataset. This approach helps to mitigate the risk of overfitting and provides a more robust evaluation of the model's performance.\n\nAdditionally, we evaluated the predictive sensitivity and specificity of miRBoost on novel sequences. For this, we used 690 novel pre-miRNAs from the difference between miRBase versions 19 and 20 and version 18. For predictive specificity, we utilized 8246 non-miRNA sequences. These sequences were carefully selected to ensure a comprehensive assessment of the model's ability to distinguish between pre-miRNAs and non-miRNAs.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in our study is available on our web server. We provide models trained on both human and cross-species data sets, which include 14 human-specific and 18 cross-species-specific features. These features were determined through a feature selection process on the entire data sets. The models are available for the prediction of new sequences. The web server can be accessed at http://EvryRNA.ibisc.univ-evry.fr.\n\nThe positive data set for cross-validation consists of pre-miRNAs from eukaryote genomes containing at least 100 miRNAs in the miRBase database (version 18). These sequences were filtered to remove mis-annotated miRNAs and those corresponding to transposable elements. The resulting data set includes 1279 sequences for human and 3082 sequences for cross-species.\n\nThe negative data set includes sequences generated from exonic regions of protein-coding genes that can be folded into hairpin-like structures and noncoding RNAs that are not pre-miRNAs from various databases.\n\nTo avoid overfitting, sequences reported as mis-annotated in later versions of miRBase (versions 19 and 20) were removed. Additionally, sequences that were mis-annotated because they corresponded to transposable elements were discarded using ncRNAclassifier.\n\nThe data sets and the feature selection process are described in detail in the Materials and Methods section of our publication. The evaluation was conducted through a fivefold cross-validation and a prediction on novel pre-miRNA and non-miRNA sequences. The software miRBoost, which utilizes these data sets, is also available on our web server.",
  "optimization/algorithm": "The machine-learning algorithm class used is Support Vector Machines (SVM), specifically in the form of weakened SVM component classifiers. This approach is combined with the boosting technique to handle imbalanced training data in pre-miRNA classification.\n\nThe algorithm is not entirely new, as boosting and SVM are well-established methods in the machine-learning community. However, the specific application and combination of these techniques for pre-miRNA classification, particularly in dealing with imbalanced data, is novel within the context of this study.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of this work is on its application to bioinformatics, specifically the classification of pre-miRNAs. The innovation lies in the adaptation and optimization of these machine-learning techniques for this particular biological problem, rather than in the development of a entirely new machine-learning algorithm. The boosting method, combined with weakened SVM component classifiers, has shown good performance in classifying imbalanced data and is advantageous in terms of execution time. This makes it particularly suitable for the large and imbalanced datasets commonly encountered in bioinformatics.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it employs a boosting technique with support vector machines (SVM) to classify pre-miRNAs. The methods considered for comparison include CSHMM, triplet-SVM, and microPred, which are machine learning methods that allow retraining their models. Additionally, MIReNA, which is not based on machine learning, is also considered. The boosting technique used in the model allows for the prediction of more positive pre-miRNAs and provides a better compromise between sensitivity and specificity. The training data for the model is derived from human and cross-species datasets, and the feature selection process is conducted independently for each dataset. The model's performance is evaluated through fivefold cross-validation and prediction on novel pre-miRNA and non-miRNA sequences.",
  "optimization/encoding": "The data encoding process for miRBoost involved several key steps to ensure that the sequence features were appropriately quantified and prepared for input into the SVM classifiers. Initially, each sequence candidate was folded into a hairpin structure using miRNAFold. This step was crucial as it allowed for the extraction of relevant features that characterize pre-miRNAs. Following this, a comprehensive set of features was generated, including both novel features developed specifically for this study and existing features from the literature. The total feature set consisted of 187 features, comprising 62 novel features and 125 existing ones.\n\nTo handle the high dimensionality and potential redundancy in the feature set, a search-based technique was employed. This technique aimed to identify highly scored low-dimensional projections of the data, ensuring that the selected features were both distinctive and independent. The feature selection process was essential for improving the predictive capability of the model and reducing execution time.\n\nThe selected features were then used to train the miRBoost model, which utilized a boosting technique combined with weakened SVM component classifiers. This approach allowed the model to iteratively focus on the subsets of data that were not well classified, thereby enhancing its performance on imbalanced datasets. The final model was evaluated through a fivefold cross-validation process, demonstrating its effectiveness in classifying pre-miRNAs with high sensitivity, specificity, and a balanced g-mean.",
  "optimization/parameters": "In our model, we primarily focus on two key parameters: m and d. The parameter m is derived from the equations that govern the training error and the expected value of the error over the dataset S. Specifically, m is bounded by the inequalities that ensure the classifier's weakness on the dataset S. The parameter d, on the other hand, is involved in the lower bound of the training error and plays a crucial role in determining the weakness of the Support Vector Machine (SVM) component classifiers, which in turn affects the performance of miRBoost.\n\nThe selection of d is particularly important. We found that a critical value of d = 0.25 yields optimal performance for miRBoost across different measures, achieving Pareto optimality. This value ensures an appropriate balance between the diversity of component classifiers and the efficiency of the boosting technique. When d is small (close to 0.25), the training errors of the component classifiers become more similar, reducing diversity. Conversely, when d is large (close to 0.5), the weakness of the classifiers is not always guaranteed. Therefore, we chose d within the range [0.25, 0.5] to maintain an optimal trade-off.\n\nFor m, we derived an expression m0 = 3/4 \u2212 d, which is valid for d in the range [0.25, 0.5]. This expression ensures that m falls within the desired bounds, maintaining the classifier's weakness and diversity.\n\nIn summary, our model uses two main parameters, m and d, which are carefully selected to optimize the performance of miRBoost. The parameter d is chosen within a specific range to balance diversity and efficiency, while m is derived to ensure the classifier's weakness on the dataset.",
  "optimization/features": "In our study, we utilized a comprehensive set of features to characterize pre-miRNA sequences. Initially, we calculated 62 novel features that describe intrinsic properties of the pre-miRNA hairpin, such as size, energy, nucleotide composition, and structural elements like bulges and loops. Additionally, we extracted 125 features from the literature, which have been used in various pre-miRNA prediction algorithms. This resulted in a total of 187 features considered for the feature selection process.\n\nFeature selection was indeed performed to identify the most relevant features for classification. We conducted two different processes: one using fivefold cross-validation and another on the whole dataset. For the cross-validation process, features were selected on four subsamples and validated on the fifth, ensuring that the selection was done using the training set only. This approach helped in identifying features that are robust and generalizable across different subsets of the data.\n\nThrough this feature selection process, we identified 18 features that were particularly important for the prediction of pre-miRNAs. These selected features were used as input for our model, ensuring that only the most relevant and non-redundant features were included in the final classification process. This approach not only improved the predictive capability of our model but also enhanced its execution time and accuracy.",
  "optimization/fitting": "In our study, we employed a boosting method combined with weakened Support Vector Machine (SVM) component classifiers to address the challenge of imbalanced training data in pre-miRNA classification. This approach involves a sequence of SVM classifiers, each applied to subsets of data that were not well classified by previous classifiers. This technique not only demonstrates good performance in classifying imbalanced data but also offers advantages in terms of execution time.\n\nTo ensure that our model did not suffer from overfitting, we implemented several strategies. Firstly, we used cross-validation to evaluate the performance of our model on different subsets of the data. This helped us to assess the generalization capability of our model and to avoid overfitting to the training data. Secondly, we carefully selected a set of features that are distinctive for the classification task and independent of each other. Irrelevant features were removed to reduce the predictive capability. Additionally, we used search-based techniques to find highly scored low-dimensional projections of the data, which helped in reducing the complexity of the model and preventing overfitting.\n\nTo address the issue of underfitting, we ensured that our model was complex enough to capture the underlying patterns in the data. We extracted a comprehensive set of features, including 62 novel features and 125 existing ones from the literature. These features characterize various intrinsic properties of pre-miRNA sequences, such as size, energy, nucleotide composition, and structural elements. By including a diverse set of features, we aimed to provide a rich representation of the data, enabling our model to learn the necessary patterns for accurate classification.\n\nFurthermore, we optimized the parameter d, which plays a crucial role in determining the weakness of the SVM component classifiers. We found that a critical value of d = 0.25 provided the best performance, balancing the diversity among component classifiers and ensuring that the model was neither too weak nor too strong. This optimization process helped us to achieve a Pareto optimal state, where no measure could be improved without worsening another.\n\nIn summary, our fitting method involved a combination of cross-validation, feature selection, and parameter optimization to address both overfitting and underfitting. These strategies ensured that our model was robust, generalizable, and capable of accurately classifying pre-miRNA sequences.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and enhance the robustness of our model. One of the key methods used was boosting, which involves training a sequence of classifiers, each focusing on the instances that were misclassified by the previous ones. This iterative process helps to improve the model's performance on the minority class, which is crucial when dealing with imbalanced datasets.\n\nAdditionally, we implemented feature selection to ensure that only the most relevant and non-redundant features were used in the classification process. This step is essential for reducing the complexity of the model and preventing it from learning noise in the data. We utilized search-based techniques to identify highly scored low-dimensional projections of the data, which helped in selecting the most informative features.\n\nFurthermore, we conducted a fivefold cross-validation to evaluate the performance of our model. This technique involves splitting the data into five subsets, training the model on four of them, and testing it on the remaining one. This process is repeated five times, with each subset serving as the test set once. Cross-validation helps to ensure that the model generalizes well to unseen data and does not overfit to the training set.\n\nIn summary, our approach to preventing overfitting included the use of boosting, feature selection, and cross-validation. These techniques collectively contributed to the development of a robust and accurate model for classifying pre-miRNAs.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model presented in this publication is not a black-box model. It is designed to be interpretable, allowing users to understand the underlying mechanisms and features that contribute to its predictions. The model employs a boosting algorithm, specifically AdaBoost, which iteratively learns weak classifiers and combines them into a strong classifier. This process is transparent, as each weak classifier is built with a focus on the samples misclassified by previous classifiers, using weights associated with the training samples.\n\nThe feature selection process is also a key aspect of the model's interpretability. Two different processes of feature selection were carried out. First, feature sets were determined through fivefold cross-validation, validating the model on each of the five subsamples with the features selected on the set of the four others. Second, a feature set was selected upstream on each whole data set. This resulted in eight common features for human data, which can be considered as the properties that characterize human pre-miRNAs. These features include the maximum number of consecutive G's in the longest exact stem, folding free energy of the longest non-exact stem, imbalance of G + A with regard to C + U in the longest non-exact stem, and others. These features provide clear examples of the model's transparency, as they are directly related to the biological characteristics of pre-miRNAs.\n\nAdditionally, the model's performance is evaluated using various measures, such as sensitivity, specificity, PPV, F-score, MCC, and g-mean, which are provided in supplemental data. This allows users to understand the model's strengths and weaknesses in different scenarios. The model's ability to handle imbalanced data is also highlighted, with techniques such as SMOTE and z-SVM being used to address this issue. This further contributes to the model's interpretability, as users can understand how the model deals with real-world data challenges.",
  "model/output": "The model is a classification model. It is designed to predict whether a given sequence is a pre-miRNA or not. The performance of the model is evaluated using metrics such as sensitivity, specificity, and g-mean, which are commonly used for classification tasks. The model's ability to handle imbalanced data and its performance in predicting novel pre-miRNAs and non-miRNA sequences are key aspects of its classification capabilities. Additionally, the model's output is visualized in ROC spaces, which are used to illustrate the trade-off between sensitivity and specificity in classification tasks. The model's performance is compared with other existing pre-miRNA classification methods, further emphasizing its role as a classification model.",
  "model/duration": "The execution time for our model, miRBoost, is notably efficient. It takes approximately 2 minutes and 29 seconds to classify 690 pre-miRNAs and 8246 non-miRNA sequences. This performance is significantly faster compared to other methods. For instance, microPred, which has similar classification ability, takes over 1400 times longer than miRBoost. Similarly, HeteroMirPred and MiPred also require several hours to complete the same task. While methods like triplet-SVM and MIReNA are faster, their prediction performance is considerably lower than that of miRBoost. This efficiency makes miRBoost a practical choice for handling the ever-increasing amount of data from new sequencing technologies.",
  "model/availability": "The software associated with our publication is available for public use. The source code has not been released, but users can access the method through a web server. The web server is hosted at http://EvryRNA.ibisc.univ-evry.fr. This server allows users to run the algorithm without needing to install any software locally. The specific details about the licensing terms for using the web server are provided on the server's website. This approach ensures that users can easily access and utilize the algorithm for their research needs.",
  "evaluation/method": "The method was evaluated through a comprehensive process involving both cross-validation and prediction on novel sequences. A fivefold cross-validation was conducted to assess the classification performance. This involved dividing the data into five subsamples, where each subsample was predicted using a model trained on the remaining four subsamples. This approach ensured that the model's performance was robust and not dependent on a specific subset of data.\n\nIn addition to cross-validation, the method's predictive sensitivity and specificity were evaluated on novel sequences. For sensitivity, 690 novel pre-miRNAs from different versions of the miRBase database were used. For specificity, 8246 non-miRNA sequences were employed. These sequences were carefully selected to ensure they represented a diverse and challenging set of data.\n\nThe evaluation metrics used included sensitivity, specificity, and the geometric mean (g-mean) of sensitivity and specificity. These metrics provided a comprehensive assessment of the method's ability to correctly identify pre-miRNAs and reject non-miRNAs. The results showed that the method achieved a high g-mean, indicating a good balance between sensitivity and specificity.\n\nFurthermore, the running time of the method was compared with other existing tools. The method demonstrated efficient performance, completing the classification task in a reasonable amount of time. This is crucial given the ever-increasing amount of data from new sequencing technologies.\n\nOverall, the evaluation process was designed to thoroughly assess the method's performance, ensuring that it could handle both balanced and imbalanced data sets effectively. The results demonstrated the method's superiority in terms of classification performance, sensitivity, specificity, and running time.",
  "evaluation/measure": "We primarily used sensitivity, specificity, and g-mean to measure the performance of our method. Sensitivity, also known as recall, measures the fraction of pre-miRNAs correctly classified, while specificity measures the fraction of non-miRNAs correctly classified. These metrics are crucial for evaluating the performance of classifiers, especially when dealing with imbalanced data.\n\nThe g-mean, which is the geometric mean of sensitivity and specificity, is particularly useful for evaluating classifiers on imbalanced data. A high g-mean signifies a high value for both sensitivity and specificity simultaneously, indicating a good balance between the two metrics.\n\nIn addition to these primary metrics, we also reported other measures such as accuracy, positive predictive value (PPV), F-score, and Matthews correlation coefficient (MCC). These metrics provide a more comprehensive evaluation of the classifier's performance.\n\nOur choice of performance metrics is representative of the literature in the field of pre-miRNA classification. Sensitivity, specificity, and g-mean are commonly used metrics in this area, and our inclusion of additional metrics such as PPV, F-score, and MCC ensures a thorough evaluation of our method's performance.",
  "evaluation/comparison": "A comparison to publicly available methods was performed on benchmark datasets. The methods compared include CSHMM, triplet-SVM, microPred, MIReNA, HeteroMirPred, MiPred, and mirExplorer. These methods were chosen for their relevance in pre-miRNA classification and their ability to handle imbalanced data, except for MIReNA, which does not use machine learning.\n\nThe comparison involved evaluating the performance of these methods using sensitivity, specificity, and g-mean. Sensitivity measures the fraction of pre-miRNAs correctly classified, while specificity measures the fraction of non-miRNAs correctly classified. The g-mean, which is the geometric mean of sensitivity and specificity, was used to evaluate the performance on imbalanced data.\n\nThe evaluation was conducted through a fivefold cross-validation and a prediction on novel pre-miRNA and non-miRNA sequences. The cross-validation involved training the models on different subsets of the data and testing them on the remaining subset. This process was repeated five times, with each subset being used as the test set once.\n\nThe prediction on novel sequences involved using the models trained on the entire dataset to predict the class of new sequences. The results showed that the method performed favorably in comparison with state-of-the-art tools, achieving high sensitivity and specificity.\n\nA simpler baseline comparison was not explicitly mentioned, but the methods compared include a range of approaches, from those that do not address the imbalanced data issue to those that do. This provides a comprehensive evaluation of the method's performance relative to existing tools.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The evaluation results for miRBoost are available in the supplemental data provided with the publication. The specific measures used for evaluation, such as sensitivity, specificity, and g-mean, are detailed in Supplemental Data 1. The ROC spaces for the classification results of miRBoost and other existing tools on human and cross-species data are illustrated in Figure 1. Additionally, the predictive performance on novel sequences is shown in Figure 2 and further elaborated in Supplemental Data 1. The running times for different tools, including miRBoost, are presented in Table 1. The features selected through the cross-validation process and on the whole data sets are listed in Table 2, with more details available in Supplemental Data 2. The software miRBoost, along with the models and features used, is accessible on the web server at http://EvryRNA.ibisc.univ-evry.fr. The data sets used for training and evaluation are described in the Materials and Methods section, ensuring reproducibility and accessibility for further research."
}