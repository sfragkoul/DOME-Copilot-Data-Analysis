{
  "publication/title": "Multivariable Diagnostic Prediction Model to Detect Hormone Secretion Profile From T2W MRI Radiomics with Artificial Neural Networks in Pituitary Adenomas.",
  "publication/authors": "Baysal B, Eser MB, Dogan MB, Kursun MA",
  "publication/journal": "Medeniyet medical journal",
  "publication/year": "2022",
  "publication/pmid": "35306784",
  "publication/pmcid": "PMC8939455",
  "publication/doi": "10.4274/mmj.galenos.2022.58538",
  "publication/tags": "- Pituitary adenoma\n- Magnetic resonance imaging\n- Machine learning\n- Artificial intelligence\n- Radiomics\n- Hormone secretion\n- Diagnostic prediction\n- Neural networks\n- T2-weighted MRI\n- Medical imaging",
  "dataset/provenance": "The dataset used in this study was sourced from a cohort of patients with pituitary adenomas who were treated at a tertiary care center between January 2015 and January 2020. The cohort consisted of 130 consecutive patients, all of whom were Caucasian. The mean age of the patients was 46.49 years, with a standard deviation of 13.69 years. The gender distribution was 76 females and 54 males.\n\nThe data points in this study were derived from radiomics parameters extracted from coronal T2-weighted magnetic resonance imaging (MRI) scans of the pituitary adenomas. A total of 851 radiomics features were initially considered as predictors. These features underwent rigorous stability analyses, including intraclass correlation coefficient (ICC), coefficient of variation (CoV), and variance inflation factor (VIF) analyses, to ensure reproducibility and precision. Features with ICC values less than 0.75, CoV values greater than 0.15, and VIF values above 10 were eliminated, resulting in a refined set of features for further analysis.\n\nThe dataset was divided into training, test, and validation sets using random sampling. The training set consisted of 70% of the patients, the test set consisted of 15%, and the validation set consisted of the remaining 15%. This division ensured that the subgroups were similarly distributed in terms of predictors and outcomes.\n\nThe outcomes of interest were the hormone secretion profiles of the pituitary adenomas, which were categorized into seven different types: non-functioning pituitary adenomas, growth hormone-secreting adenomas, prolactin-secreting adenomas, adrenocorticotropic hormone-secreting adenomas, pluri-hormonal adenomas, follicle-stimulating hormone and luteinizing hormone-secreting adenomas, and thyroid-stimulating hormone-secreting adenomas.\n\nThis dataset has not been used in previous papers or by the community, as this study represents an original contribution to the field of radiomics and artificial neural networks in the context of pituitary adenomas. The ground truth for the hormone secretion profiles was determined based on hormone plasma levels, as the patient population consisted of individuals admitted to the outpatient clinic of endocrinology.",
  "dataset/splits": "The dataset was split into three distinct subsets for the purpose of training, testing, and validating the neural networks. The random number generator was employed to allocate 70% of the patients to the training set, 15% to the test set, and the remaining 15% to the validation set. This distribution was maintained similarly across predictors and outcomes to ensure a balanced representation in each subset. The training set was used to train the neural networks, the test set was utilized for hyperparameter tuning through the \"early stopping\" algorithm, and the validation set was reserved for assessing the final performance of the trained models.",
  "dataset/redundancy": "The dataset used in this study consisted of 130 consecutive patients with pituitary adenoma. To ensure robust model development, the dataset was split into three subsets: training, test, and validation. The software employed a random number generator to allocate 70% of the patients to the training set, 15% to the test set, and the remaining 15% to the validation set. This splitting process was designed to ensure that each subset had a similar distribution of predictors and outcomes, maintaining the integrity and representativeness of the data across all phases of model development.\n\nThe independence of the training and test sets was enforced through the random sampling process, which ensured that there was no overlap between the patients included in each subset. This approach is crucial for evaluating the model's performance accurately, as it prevents data leakage and ensures that the model's generalizability can be assessed on unseen data.\n\nComparing this dataset splitting method to previously published machine learning datasets, it aligns with standard practices in the field. The use of a hold-out validation set is a common technique to assess model performance and prevent overfitting. The specific proportions used (70% training, 15% test, 15% validation) are also consistent with many studies, although the exact percentages can vary depending on the size and nature of the dataset. The emphasis on maintaining a similar distribution of predictors and outcomes across subsets is a best practice that helps in creating a reliable and generalizable model.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is artificial neural networks (ANNs). Specifically, multilayer perceptron and radial basis function networks were employed. These are well-established types of neural networks commonly used for classification tasks.\n\nThe algorithms used are not new; they are standard techniques in the field of machine learning and have been extensively studied and applied in various domains. The choice to use these specific algorithms was likely driven by their proven effectiveness in handling complex, high-dimensional data, such as that derived from radiomics features in medical imaging.\n\nThe focus of this study is on the application of these algorithms to a specific medical problem\u2014predicting hormone secretion profiles in pituitary adenomas using T2-weighted MRI radiomics. The development and validation of the model, rather than the creation of new machine-learning algorithms, is the primary contribution of this work. Therefore, it is appropriate that the study was published in a medical journal rather than a machine-learning journal. The emphasis is on the clinical relevance and the potential impact on medical practice, leveraging established machine-learning techniques to achieve this goal.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the robustness and reliability of the features used. Initially, a total of 851 radiomics parameters were identified from T2-weighted MRI images. To ensure consistency and reliability, features with an intraclass correlation coefficient (ICC) below 0.75 were eliminated, resulting in the removal of 204 features. Additionally, features with a coefficient of variation (CoV) greater than 0.15 were excluded, leading to the elimination of 552 more features. Further refinement was done using variance inflation factor (VIF) analysis to address collinearity, which removed another 44 features. This process left 51 stable predictors that were used for subsequent analyses.\n\nCorrelation analysis was performed using these stable predictors and outcomes, creating correlation matrices to evaluate the unadjusted relationships. The Spearman correlation (SC) coefficients were all below 0.30, with only five predictors showing a significant p-value (<0.01). Least Absolute Shrinkage and Selection Operator (LASSO) regression was then applied for regularization, selecting the most relevant predictors for neural network training. This method ensured that the features used were both stable and relevant, enhancing the model's predictive accuracy.",
  "optimization/parameters": "In our study, we initially considered a large number of radiomics features, specifically 851 parameters. However, due to the high instability and collinearity among these features, we employed several methods to reduce and select the most relevant predictors.\n\nFirst, we eliminated features with an intraclass correlation coefficient (ICC) below 0.75, removing 204 features. Next, we used the coefficient of variation (CoV) analysis to exclude features with a CoV greater than 0.15, which resulted in the elimination of 552 more features. Additionally, variance inflation factor (VIF) analysis was performed to address collinearity, and features with a VIF above 10 were removed, leading to the elimination of another 44 features.\n\nAfter these steps, we were left with 51 stable predictors. These predictors, along with the outcomes, were used for correlation analysis and to create correlation matrices. Finally, least absolute shrinkage and selection operator (LASSO) regression was applied for regularization, selecting the most relevant predictors for neural network training.\n\nThe final number of parameters (p) used in our model varied depending on the specific neural network and outcome being predicted. However, the process ensured that only the most stable and relevant features were included, enhancing the model's predictive performance.",
  "optimization/features": "In our study, we initially considered 851 radiomics parameters as potential input features. However, feature selection was performed to reduce the dimensionality and improve the model's performance. This process involved several steps:\n\nFirst, features with an intraclass correlation coefficient (ICC) below 0.75 were eliminated, resulting in the removal of 204 features. Next, features with a coefficient of variation (CoV) greater than 0.15 were excluded, leading to the elimination of 552 features. Additionally, 44 more features were removed due to high collinearity, as indicated by a variance inflation factor (VIF) above 10.\n\nFollowing these steps, 51 stable predictors remained. These selected features, along with the outcomes, were used for correlation analysis and to create correlation matrices. Further refinement was done using least absolute shrinkage and selection operator (LASSO) regression for regularization, ensuring that the most relevant predictors were selected for neural network training.\n\nAll feature selection processes were conducted using the training set only, ensuring that the validation and test sets remained independent and unbiased. This rigorous feature selection approach helped in building robust and accurate diagnostic prediction models.",
  "optimization/fitting": "In our study, we developed a diagnostic prediction model using artificial neural networks (ANNs) to detect hormone secretion profiles from T2-weighted MRI radiomics features in pituitary adenomas. The number of initial radiomics features (851) was indeed much larger than the number of training points (130 patients). To address potential overfitting, we employed several strategies.\n\nFirst, we performed rigorous feature selection to reduce the dimensionality of our data. This included eliminating features based on intraclass correlation coefficient (ICC < 0.75), coefficient of variation (CoV > 0.15), and variance inflation factor (VIF > 10). Additionally, we used least absolute shrinkage and selection operator (LASSO) regression for regularization, which helped in selecting the most relevant predictors and further reduced the risk of overfitting.\n\nWe also utilized random sampling and 5-fold cross-validation to ensure that our model generalized well to unseen data. The dataset was split into training (70%), test (15%), and validation (15%) sets, with similar distributions of predictors and outcomes in each subset. Hyperparameter tuning was performed using the \"early stopping\" algorithm, which monitors the error rate on the test set and stops training when the error rate starts to increase, thus preventing overfitting.\n\nTo rule out underfitting, we employed multilayer perceptron and radial basis function networks, which are capable of capturing complex relationships in the data. The software automatically determined the number of layers and neurons, ensuring that the model had sufficient capacity to learn from the data. Furthermore, the use of different activation functions (Tahn for hidden layers and Softmax or Exponential for output layers) helped in modeling the non-linear relationships effectively.\n\nThe performance of our models was evaluated using the area under the receiver operating characteristic curve (AUC), with a threshold of AUC > 0.85 and p-value < 0.01 for considering a model as validated. The results demonstrated high diagnostic accuracy for most hormone secretion profiles, indicating that our models were neither overfitted nor underfitted.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was the Least Absolute Shrinkage and Selection Operator (LASSO) regression with L1 normalization. This technique is particularly effective in feature selection and regularization, helping to reduce the complexity of the model by shrinking some coefficient estimates to zero, thereby eliminating less important features and preventing overfitting.\n\nAdditionally, we utilized random sampling and 5-fold cross-validation during the LASSO regression process. This approach helps in assessing the model's performance more reliably by ensuring that the data is split into training and validation sets multiple times, reducing the risk of overfitting to a specific subset of the data.\n\nFor the neural network training, we implemented the \"early stopping\" algorithm. This method involves training the neural networks with a training set and performing hyperparameter tuning with a test set at the end of each epoch. The training continues as long as the error rate decreases in both the training and test sets. However, if the error rate starts to increase in the test set, the training is terminated. This technique is crucial for preventing overfitting by stopping the training process when the model begins to overfit the training data.\n\nFurthermore, we ensured that the subgroups used for training, testing, and validation were similarly distributed in terms of predictors and outcomes. This balanced distribution helps in maintaining the generalizability of the model and reduces the likelihood of overfitting to any particular subset of the data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in this study are not explicitly detailed in the publication. However, the methods employed for hyperparameter tuning, such as the \"early stopping\" algorithm, are described. This algorithm trains neural networks using a training set and performs hyperparameter tuning with a test set at the end of each epoch. Training continues as long as the error rate decreases in both groups and stops when the error rate starts to increase in the test set.\n\nThe model files and specific optimization parameters are not provided in the publication. The study utilized multilayer perceptron and radial basis function networks, with the software automatically determining the number of layers, neurons, error function, hidden activation, and output activation. Random sampling was used to divide patients into training, test, and validation sets, ensuring similar distributions of predictors and outcomes.\n\nRegarding availability, the publication does not specify where the exact configurations or model files can be accessed. The study was conducted without external financial support, and there is no conflict of interest declared by the authors. The article is licensed under Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0), allowing for non-commercial use and sharing with proper attribution.",
  "model/interpretability": "The model developed in this study is primarily a black-box model, particularly the artificial neural networks (ANNs) used for predicting hormone secretion profiles in pituitary adenomas. These networks, including multilayer perceptron and radial basis function networks, are known for their complexity and lack of interpretability. The internal workings of these models are not easily understandable, making it challenging to trace how specific inputs lead to particular outputs.\n\nHowever, several steps were taken to enhance the interpretability of the model to some extent. Feature selection processes, such as variance inflation factor (VIF) analysis and least absolute shrinkage and selection operator (LASSO) regression, were employed to identify and retain the most relevant predictors. This process helped in reducing the number of features, making the model slightly more interpretable by focusing on a smaller set of significant radiomics features.\n\nAdditionally, correlation analysis and correlation matrices were used to evaluate the relationships between predictors and outcomes. This step provided some insight into how certain features might be related to the different hormone secretion profiles, although it did not fully elucidate the inner workings of the neural networks themselves.\n\nIn summary, while the core predictive model remains a black-box due to the nature of ANNs, efforts were made to improve interpretability through rigorous feature selection and correlation analysis. These steps help in understanding which features are most important, but the exact decision-making process within the neural networks remains opaque.",
  "model/output": "The model developed in this study is a classification model. It is designed to distinguish between different hormone secretion profiles in pituitary adenomas based on T2-weighted MRI radiomics features. The model uses artificial neural networks (ANNs) to classify seven distinct hormone secretion profiles: non-functioning pituitary adenoma, growth hormone-secreting adenomas, prolactinomas, adrenocorticotropic hormone-secreting adenomas, pluri-hormonal secreting adenomas (PHA), follicle-stimulating hormone and luteinizing hormone-secreting adenomas, and thyroid-stimulating hormone adenomas.\n\nThe performance of the model is evaluated using the area under the receiver operating characteristic curve (AUC), with an AUC greater than 0.85 and a p-value less than 0.01 considered successful. The model's output includes metrics such as sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) for each of the seven hormone secretion profiles. For example, the model distinguishing prolactinomas from other adenomas achieved an AUC of 0.95, with a sensitivity of 91% and a specificity of 98%. The model distinguishing PHA had the lowest AUC at 0.74, indicating relatively lower performance for this specific classification task. The other five ANNs had AUC values greater than 0.85, demonstrating strong classification performance across most hormone secretion profiles.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the specific algorithms and models used in this study is not publicly released. The software used for statistical analyses and neural network development was TIBCO Statistica version 13.0.5. However, the methods and tools employed, such as PyRadiomics for feature extraction and 3D Slicer for segmentation, are open-source and publicly available. PyRadiomics can be accessed via its official website and GitHub repository, while 3D Slicer is available for download from its official site. The specific configurations and parameters used in these tools are detailed within the publication. Unfortunately, there is no executable, web server, virtual machine, or container instance provided for direct use of the developed models.",
  "evaluation/method": "The evaluation of the method involved several rigorous steps to ensure the robustness and accuracy of the models. Initially, features were selected using variance inflation factor (VIF) analysis to reduce collinearity, with features having a VIF above 10 being eliminated. This process also considered the coefficient of variation (CoV), preserving features with smaller CoV. Validated imaging biomarkers were further evaluated using Spearman correlation analysis between features and outcomes, with a significance level of p<0.01.\n\nFor feature selection, the least absolute shrinkage and selection operator (LASSO) with L1 normalization was employed. Random sampling and 5-fold cross-validation were used to seed the LASSO, ensuring a comprehensive evaluation of the features.\n\nIn structuring the artificial neural networks, multilayer perceptron and radial basis function networks were selected. The software automatically determined the number of layers, neurons, error function, hidden activation, and output activation. The dataset was split into training (70%), test (15%), and validation (15%) sets, with each subgroup maintaining a similar distribution of predictors and outcomes. Hyperparameter tuning was performed using the \"early stopping\" algorithm, which trains the networks with the training set and tunes hyperparameters with the test set at the end of each epoch. Training continued as long as the error rate decreased in both sets and stopped when the error rate started to increase in the test set. The final performance of the networks was measured using the validation set.\n\nStatistical analyses and neural network development were conducted using TIBCO Statistica version 13.0.5. The results with the highest diagnostic accuracy were presented using the area under the receiver operating characteristic curve (AUC) with 95% confidence intervals. A validated classifier neural network was defined as having an AUC greater than 0.85 and a p-value less than 0.01.",
  "evaluation/measure": "In our study, we evaluated the performance of our neural networks using several key metrics to ensure a comprehensive assessment. The primary metric reported is the Area Under the Receiver Operating Characteristic Curve (AUC), which provides a single scalar value that summarizes the performance of the classifier across all classification thresholds. We considered a neural network to be a validated classifier if the AUC was greater than 0.85 and the p-value was less than 0.01.\n\nIn addition to AUC, we reported the 95% confidence intervals for the AUC to provide a range within which the true AUC is likely to fall. This gives an indication of the precision of our AUC estimates.\n\nWe also reported accuracy (Acc), which measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity (Sen) and specificity (Spec) were included to evaluate the true positive rate and true negative rate, respectively. These metrics are crucial for understanding how well the model identifies positive and negative cases.\n\nPositive Predictive Value (PPV) and Negative Predictive Value (NPV) were also calculated. PPV indicates the probability that subjects with a positive screening test truly have the disease, while NPV indicates the probability that subjects with a negative screening test truly do not have the disease.\n\nThe metrics reported in our study are representative of those commonly used in the literature for evaluating the performance of diagnostic models, particularly in the field of medical imaging and radiomics. These metrics provide a thorough evaluation of the model's ability to distinguish between different types of pituitary adenomas, ensuring that our findings are robust and comparable to other studies in the field.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "The performance metrics presented in this study include confidence intervals, specifically for the Area Under the Curve (AUC) values. These intervals provide a range within which the true AUC value is expected to lie, with a certain level of confidence, typically 95%. This allows for a more nuanced understanding of the model's performance, acknowledging the inherent variability and uncertainty in the estimates.\n\nStatistical significance is also addressed in the evaluation of the neural networks. The AUC values are considered validated classifiers if they are greater than 0.85 and the p-value is less than 0.01. This threshold ensures that the results are statistically significant, indicating that the observed performance is unlikely to have occurred by chance. The p-values for the AUC metrics are all less than 0.001, reinforcing the robustness of the findings.\n\nThe use of cross-validation techniques, such as 5-fold cross-validation, further enhances the reliability of the results. This method helps to ensure that the model's performance is consistent across different subsets of the data, reducing the risk of overfitting and providing a more generalizable assessment of the model's efficacy.\n\nIn summary, the performance metrics are accompanied by confidence intervals, and the results are statistically significant, supporting the claim that the method is superior to others and baselines. The rigorous statistical analysis and validation processes employed in this study bolster the confidence in the reported outcomes.",
  "evaluation/availability": "Not enough information is available."
}