{
  "publication/title": "Mammography-based radiomics for predicting the risk of breast cancer recurrence: a multicenter study.",
  "publication/authors": "Mao N, Yin P, Zhang H, Zhang K, Song X, Xing D, Chu T",
  "publication/journal": "The British journal of radiology",
  "publication/year": "2021",
  "publication/pmid": "34520235",
  "publication/pmcid": "PMC8553203",
  "publication/doi": "10.1259/bjr.20210348",
  "publication/tags": "- Breast cancer\n- Mammography\n- Radiomics\n- Recurrence risk\n- Oncotype DX\n- Estrogen receptor-positive\n- Lymph node-negative\n- Multivariate logistic regression\n- Decision curve analysis\n- Artificial intelligence in medicine",
  "dataset/provenance": "The dataset used in this study was sourced from two hospitals. The primary source was Peking University People\u2019s Hospital, which contributed 240 patients. These patients were divided into a training set consisting of 168 patients and an internal test set of 72 patients, following a 7:3 ratio. Additionally, an external test set comprising 64 patients was obtained from Yantai Yuhuangding Hospital.\n\nThe study focused on patients with ER-positive and LN-negative breast cancer, utilizing the Oncotype DX test to evaluate the risk of recurrence. This test examines the expression of 21 genes in breast cancer tissues, including 16 tumor-related genes and 5 reference genes. The expression levels of these genes were converted into a recurrence risk index, categorized into low, medium, and high risk levels.\n\nThe dataset included histopathological information such as tumor grade, ER, PR, HER2, and Ki-67 status, obtained through medical record systems. Mammography images were acquired using the GE Senographe Essential system, with DICOM data exported from Picture Archiving and Communication Systems. These images underwent segmentation and radiomics feature extraction, involving shape-based, first-order statistical, and texture features.\n\nThe study aimed to predict the risk of recurrence in breast cancer patients, with a particular focus on identifying those with a low risk of recurrence. The dataset was used to develop and validate a multivariate logistic regression model that incorporated radiomics signatures and clinical risk factors. This model demonstrated good predictive performance, with AUCs of 0.92 in the training set and 0.88 in the internal test set. The decision curve analysis indicated that the radiomics model added more net benefit than the \"treat all\" or \"treat none\" schemes.",
  "dataset/splits": "There are three data splits in this study. The first split is the training set, which consists of 168 patients. The second split is the internal test set, comprising 72 patients. The third split is the external test set, which includes 64 patients.\n\nThe distribution of data points in each split follows a 7:3 ratio for the training and internal test sets. The external test set comes from a different hospital. The characteristics of the patients in these sets, such as age, tumor size, and Oncotype DX score, are detailed in the study to ensure there are no significant differences among the sets, indicating a balanced distribution.",
  "dataset/redundancy": "The dataset used in this study consisted of patients from two hospitals. A total of 240 patients from Peking University People\u2019s Hospital were included and divided into a training set and an internal test set according to a 7:3 ratio, resulting in 168 patients in the training set and 72 patients in the internal test set. Additionally, an external test set consisting of 64 patients was obtained from Yantai Yuhuangding Hospital.\n\nThe training and test sets were designed to be independent. The internal test set was derived from the same hospital as the training set but was kept separate to evaluate the model's performance on unseen data from the same population. The external test set, sourced from a different hospital, further ensured the independence and generalizability of the results.\n\nTo enforce the independence of the datasets, patients were randomly assigned to the training and internal test sets from the same hospital, ensuring no overlap. The external test set was entirely separate, coming from a different institution, which helped in validating the model's performance across different patient populations.\n\nThe distribution of clinical characteristics, such as age, tumor size, Oncotype DX score, tumor grade, PR status, HER2 status, and Ki-67 status, was compared among the training, internal test, and external test sets. No significant differences were found in these characteristics, indicating that the datasets were well-balanced and comparable. This balance is crucial for ensuring that the model's performance is not biased by differences in patient characteristics.\n\nIn comparison to previously published machine learning datasets in similar studies, the approach taken here aligns with best practices in ensuring dataset independence and balance. The use of an external test set from a different hospital is particularly noteworthy, as it provides a stronger validation of the model's generalizability. This methodology helps in mitigating the risk of overfitting and ensures that the model can perform well on new, unseen data.",
  "dataset/availability": "The data used in this study is not publicly available. The study involved patients from two hospitals: Peking University People\u2019s Hospital and Yantai Yuhuangding Hospital. The dataset was divided into a training set, an internal test set, and an external test set. The training set consisted of 168 patients, the internal test set of 72 patients, and the external test set of 64 patients. The data splits were determined according to a 7:3 ratio for the training and internal test sets.\n\nThe study was approved by the ethics committees of the two hospitals, and informed consent from the patients was waived. However, the specific details about the data, including the data splits, are not released in a public forum due to privacy and ethical considerations. The data remains confidential and is not accessible to the public.",
  "optimization/algorithm": "The optimization algorithm employed in this study is the Least Absolute Shrinkage and Selection Operator (LASSO) regression, which is a type of linear regression that includes a penalty term to enforce sparsity in the model. This method is particularly well-suited for high-dimensional data, where the number of features exceeds the number of observations.\n\nLASSO regression is not a new machine-learning algorithm; it has been extensively used and studied in the field of statistics and machine learning for several decades. The algorithm was developed to address the challenges of multicollinearity and overfitting in regression models, especially when dealing with a large number of predictors.\n\nThe reason LASSO regression was not published in a machine-learning journal in this context is that the focus of the study is on its application in the medical field, specifically for predicting the risk of breast cancer recurrence. The primary contribution of this work lies in the development and validation of a radiomics model that integrates LASSO-selected features with clinical risk factors to improve the prediction of recurrence risk in ER-positive, LN-negative invasive breast cancer. The study aims to demonstrate the clinical utility and performance of this model rather than introducing a new machine-learning algorithm.",
  "optimization/meta": "The model developed in this study can be considered a meta-predictor, as it integrates both radiomics features and clinical risk factors to predict the risk of breast cancer recurrence. The radiomics signature, which is a key component of the model, is derived from mammography images using various texture features extracted through radiomics analysis. These features are selected using the LASSO (Least Absolute Shrinkage and Selection Operator) regression method, which is a type of machine-learning algorithm designed for high-dimensional data.\n\nThe radiomics signature is then combined with clinical risk factors, such as tumor grade and HER 2 status, which are identified through univariate and multivariate logistic regression analyses. These clinical factors are well-established predictors of breast cancer recurrence and are integrated into the model to enhance its predictive performance.\n\nThe training data used for developing the radiomics signature and the clinical model are independent. The study utilized a training set to develop the initial models and then validated these models using internal and external test sets. The internal test set consisted of data from the same institution as the training set but was not used in the model development process. The external test set included data from different institutions, ensuring that the models were evaluated on independent data.\n\nThe use of independent training and test sets helps to ensure that the model's performance is generalizable and not overly optimized for the specific characteristics of the training data. This approach is crucial for validating the robustness and reliability of the predictive model.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps. Initially, mammography images were acquired using a specific system, ensuring consistent image quality. These images underwent preprocessing, which included gray level standardization using the \u03bc \u00b1 3\u03c3 method to set extreme gray values to zero. This step helped in normalizing the image data. Following this, the gray levels were discretized, and the images were resampled to convert anisotropic voxels into a standardized size of 0.1\u00d7 0.1 mm. These preprocessing steps were crucial for ensuring that the radiomics features extracted from the images were consistent and comparable.\n\nA total of 396 radiomics features were extracted from each image, encompassing shape- and size-based features, first-order statistical features, and texture features. These features were selected to capture various aspects of the tumor's characteristics visible in the mammography images. The extraction process was performed using specialized software designed for medical imaging analysis.\n\nTo ensure the reproducibility of the radiomics features, inter- and intra-observer correlation coefficients (ICCs) were calculated. Two senior radiologists, blinded to the pathology reports, manually segmented the mammography images. The high ICC values indicated good agreement and reliability in the feature extraction process. Features with ICC values greater than 0.8 were retained for further analysis.\n\nSubsequent steps involved Spearman correlation analysis to exclude highly correlated features, ensuring that only the most informative features were retained. Features were further selected using analysis of variance (ANOVA), which helped in identifying significant features between different classes. Finally, the least absolute shrinkage and selection operator (LASSO) regression was applied to select the key radiomics features. The LASSO method, suitable for high-dimensional data, determined the optimal hyperparameter (\u03bb) using 10-fold cross-validation and retained features with non-zero coefficients. The radiomics signature score (Rad-score) was then computed using a linear combination of the key features weighted by their LASSO coefficients. This score was integrated into a multivariate logistic regression model along with clinical risk factors to predict the risk of breast cancer recurrence.",
  "optimization/parameters": "In our study, the number of parameters (p) used in the model was determined through a systematic feature selection process. Initially, a large set of radiomics features was extracted from the mammography images. To handle the high-dimensional data, the Least Absolute Shrinkage and Selection Operator (LASSO) regression method was employed. This method is particularly suitable for regression tasks involving a large number of variables.\n\nThe LASSO regression process involved several steps. First, the hyperparameter (\u03bb) in the LASSO model was optimized using 10-fold cross-validation. The goal was to find the \u03bb value that minimized the binomial deviance, which is a measure of the model's predictive accuracy. The optimized \u03bb corresponded to the least binomial deviance, ensuring that the model was neither overfitted nor underfitted.\n\nOnce the optimal \u03bb was determined, the coefficients of the features were calculated. Features with non-zero coefficients were retained as the final feature subset. This step effectively reduced the dimensionality of the data by selecting only the most relevant features. The radiomics signature score (Rad-score) was then computed using a linear combination of these key features, weighted by their respective LASSO coefficients.\n\nThrough this process, three key radiomics features were selected: HaralickCorrelation_angle45_offset7, GLCMEntropy_AllDirection_offset1_SD, and LongRunLowGreyLevelEmphasis_AllDirection_offset4_SD. These features were integrated into the multivariate logistic regression model, along with clinical risk factors such as tumor grade and HER2 status. The final model included a subset of parameters that were both statistically significant and clinically relevant, ensuring robust predictive performance.",
  "optimization/features": "In the optimization process, a total of 396 radiomics features were initially extracted from each image. These features encompassed various categories, including shape- and size-based, first-order statistical, and texture features.\n\nFeature selection was indeed performed to refine this initial set. The process began with retaining features that demonstrated substantial reproducibility, as indicated by inter- and intra-correlation coefficients (ICCs) greater than 0.8 in the training set. This step ensured that only reliable features were considered for further analysis.\n\nNext, Spearman correlation analysis was employed to exclude highly correlated features. Specifically, if a pair of features had a correlation coefficient greater than 0.9, one of the features in the pair was excluded. This reduced redundancy and improved the robustness of the selected features.\n\nFollowing this, an analysis of variance (ANOVA) was conducted to further select features with a p-value less than 0.001. This statistical method helped in identifying features that had significant discriminative ability between different classes, thereby reducing the number of features and preparing the data for the subsequent least absolute shrinkage and selection operator (LASSO) regression.\n\nFinally, LASSO regression was applied to select the key radiomics features. This method is particularly suitable for high-dimensional data and involves determining the optimal hyperparameter (\u03bb) using 10-fold cross-validation based on minimum binomial deviance. Features with non-zero coefficients were retained as the final feature subset. The radiomics signature score (Rad-score) was then computed using a linear combination of these key features, weighted by their LASSO coefficients.",
  "optimization/fitting": "In our study, we dealt with a high-dimensional dataset, where the number of radiomics features was significantly larger than the number of training samples. To address the risk of overfitting, we employed the Least Absolute Shrinkage and Selection Operator (LASSO) regression method. LASSO is particularly well-suited for high-dimensional data as it performs both variable selection and regularization to enhance the prediction accuracy and interpretability of the statistical model it produces.\n\nTo determine the optimal value of the hyperparameter \u03bb in the LASSO model, we used 10-fold cross-validation based on the minimum criteria of binomial deviance. This process helped in identifying the \u03bb that corresponded to the least binomial deviance, thereby ensuring that the model was neither overfitting nor underfitting the data. The features with non-zero coefficients after this process were retained as the final feature subset, which were then used to compute the radiomics signature score (Rad-score) through a linear combination weighted by their LASSO coefficients.\n\nAdditionally, we conducted univariate and multivariate logistic regression analyses to identify key risk factors related to the recurrence of breast cancer. The multivariate logistic regression model included both the radiomics signature and clinical risk factors, and it was constructed using backward stepwise selection. The process was stopped when the Akaike Information Criterion (AIC) was minimized, further ensuring that the model was optimized and not overfitting the data.\n\nTo validate the performance of our models, we assessed them using the Receiver Operating Characteristic (ROC) curve in the training set and conducted Decision Curve Analysis (DCA) to determine the clinical usefulness of the radiomics models. The models were also validated using internal and external test sets, providing robust evidence of their generalizability and reliability.",
  "optimization/regularization": "In our study, we employed the Least Absolute Shrinkage and Selection Operator (LASSO) regression method to prevent overfitting and select key radiomics features. LASSO is particularly well-suited for high-dimensional data, which is characteristic of radiomics feature sets. To determine the optimal hyperparameter (\u03bb) in the LASSO model, we used 10-fold cross-validation based on the minimum criteria of binomial deviance. This process ensured that the selected \u03bb corresponded to the least binomial deviance, thereby minimizing the risk of overfitting. After determining the optimal \u03bb, we identified the features with non-zero coefficients, which were retained as the final feature subset. This approach effectively reduced the dimensionality of the feature set while maintaining the most relevant features for predicting the risk of breast cancer recurrence. Additionally, we used variance inflation factor (VIF) to eliminate collinearity among the features, further enhancing the robustness of our model.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available upon request from the corresponding author. Specifically, the LASSO regression method was employed for feature selection, with the hyperparameter \u03bb determined through 10-fold cross-validation to minimize binomial deviance. The optimized \u03bb corresponded to the least binomial deviance, and features with non-zero coefficients were retained as the final feature subset.\n\nThe radiomics signature score (Rad-score) was computed using a linear combination of the key features weighted by their LASSO coefficients. For the multivariate logistic regression model, univariate and multivariate analyses were performed to identify risk factors related to breast cancer recurrence. These factors included the Rad-score, age, tumor size, tumor grade, PR, HER2, and Ki-67. The model was constructed using backward stepwise selection, with the process stopping when the Akaike information criterion (AIC) was minimized.\n\nThe performance of the models was assessed using the ROC curve in the training set, and decision curve analysis (DCA) was conducted to determine the clinical usefulness of the radiomics models. The models were validated using internal and external test sets.\n\nThe statistical analysis was conducted using R software (version 3.4.4), and the p-value threshold for statistical significance was set at < 0.05. The specific model files and optimization parameters are not publicly available but can be requested from the corresponding author. The data sharing statement indicates that data are available upon request, ensuring transparency and reproducibility for further research.",
  "model/interpretability": "The model developed in this study is not entirely a black box, as it incorporates both radiomics features and clinical risk factors, providing some level of interpretability. The radiomics signature consists of three specific texture features that were selected using the LASSO regression method. These features are HaralickCorrelation_angle45_offset7, GLCMEntropy_AllDirection_offset1_SD, and LongRunLowGreyLevelEmphasis_AllDirection_offset4_SD. These features are combined using a linear formula to compute the Rad-score, which is a key component of the model.\n\nThe clinical risk factors included in the model are tumor grade and HER 2 status, which are well-established factors in breast cancer prognosis. The model's coefficients for these factors provide insights into their relative importance in predicting recurrence risk. For instance, tumor grade and HER 2 status have significant p-values in the multivariate logistic regression analysis, indicating their strong association with recurrence risk.\n\nThe use of decision curve analysis (DCA) further enhances the interpretability of the model by quantifying the net benefits at different threshold probabilities. This analysis shows that the model adds more net benefit than the \"treat all\" or \"treat none\" schemes, providing a clear indication of its clinical usefulness.\n\nAdditionally, the model's performance metrics, such as the areas under the curve (AUCs) in the training, internal, and external test sets, offer transparency regarding its predictive accuracy. The AUCs of 0.92, 0.88, and 0.84 in the respective sets demonstrate the model's robust performance across different datasets.\n\nIn summary, while the model leverages complex radiomics features, it also incorporates interpretable clinical factors and provides clear performance metrics, making it more transparent than a typical black-box model.",
  "model/output": "The model developed in this study is a classification model. Specifically, it is a multivariate logistic regression model designed to predict the recurrence risk of ER-positive, LN-negative invasive breast cancer. The model incorporates both radiomics features and clinical risk factors to classify patients into different recurrence risk categories: low, intermediate, and high. The performance of the model was evaluated using the area under the curve (AUC) in training, internal, and external test sets, demonstrating its effectiveness in discriminating between these risk categories. The decision curve analysis (DCA) further supported the clinical usefulness of the model by showing that it adds more net benefit than the \"treat all\" or \"treat none\" schemes across a range of threshold probabilities.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its robustness and clinical usefulness. Initially, the performance of the multivariate logistic regression models was assessed using the Receiver Operating Characteristic (ROC) curve in the training set. This helped in understanding the model's ability to distinguish between different risk levels of breast cancer recurrence.\n\nDecision Curve Analysis (DCA) was conducted to determine the clinical usefulness of the radiomics models. DCA quantifies the net benefits at different threshold probabilities, providing insights into whether the model adds value in clinical decision-making compared to treating all patients or treating none.\n\nThe models were validated using both internal and external test sets. The internal test set consisted of patients from the same hospital as the training set, while the external test set included patients from a different hospital. This approach helped in evaluating the generalizability of the model across different patient populations.\n\nStatistical analysis was performed using R software, with a significance level set at p < 0.05. This ensured that the results were statistically significant and reliable. The evaluation process included comparing the differences in ROC curves using DeLong\u2019s test, which is a method for comparing the areas under two or more correlated ROC curves.\n\nIn summary, the method was evaluated through a combination of ROC curve analysis, DCA, and validation on internal and external test sets. These steps ensured that the model was not only accurate but also clinically useful and generalizable.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our models. The primary metric reported is the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve. For the multivariate logistic regression model that includes both the radiomics signature and clinical risk factors, we achieved an AUC of 0.92 (95% CI, 0.86\u20130.97) in the training set and 0.88 (95% CI, 0.75\u20131.00) in the internal test set. These AUC values indicate strong discriminative ability.\n\nAdditionally, we conducted a Decision Curve Analysis (DCA) to assess the clinical usefulness of our radiomics model. The DCA showed that our model provides more net benefit than the \"treat all\" or \"treat none\" schemes across a range of threshold probabilities (from 0.1 to 1.0) in the internal test set. This suggests that our model has practical clinical value.\n\nWe also compared the differences in ROC curves between the training and internal test sets using DeLong\u2019s test, which showed a significant difference (p < 0.001). This comparison helps to validate the robustness of our model across different datasets.\n\nIn summary, the reported performance metrics\u2014AUC, DCA, and DeLong\u2019s test\u2014are comprehensive and representative of the standards used in similar studies in the literature. These metrics collectively demonstrate the strong predictive power and clinical utility of our model.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "The evaluation of the multivariate logistic regression model included the use of performance metrics with confidence intervals. The areas under the curve (AUCs) for the model were reported with 95% confidence intervals, providing a range within which the true AUC is likely to fall. Specifically, the AUCs were 0.92 (95% CI, 0.86\u20130.97) in the training set and 0.88 (95% CI, 0.75\u20131.00) in the internal test set. These intervals give an indication of the precision of the AUC estimates.\n\nStatistical significance was also considered in the evaluation. A significant difference was observed between the differences of ROC curves in the training and internal test sets (p < 0.001). This p-value indicates that the difference in performance between the sets is unlikely to be due to chance, suggesting that the model's performance is robust and generalizable.\n\nAdditionally, decision curve analysis (DCA) was conducted to determine the clinical usefulness of the radiomics models. The DCA indicated that the radiomics model adds more net benefit than the \"treat all\" or \"treat none\" scheme across a range of threshold probabilities (0.1 to 1.0) in the internal test set. This analysis provides further evidence of the model's clinical utility and superiority over simpler decision-making strategies.\n\nOverall, the inclusion of confidence intervals and the demonstration of statistical significance strengthen the confidence in the model's performance and its potential superiority over other methods and baselines.",
  "evaluation/availability": "Not enough information is available."
}