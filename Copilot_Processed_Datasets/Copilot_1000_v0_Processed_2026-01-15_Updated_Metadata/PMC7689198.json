{
  "publication/title": "Machine Learning Analysis of Blood microRNA Data in Major Depression: A Case-Control Study for Biomarker Discovery.",
  "publication/authors": "Qi B, Fiori LM, Turecki G, Trakadis YJ",
  "publication/journal": "The international journal of neuropsychopharmacology",
  "publication/year": "2020",
  "publication/pmid": "32365192",
  "publication/pmcid": "PMC7689198",
  "publication/doi": "10.1093/ijnp/pyaa029",
  "publication/tags": "- Diagnosis and treatment\n- Major depression\n- Machine learning\n- MicroRNA\n- Biomarker discovery\n- Case-control study\n- Mental health\n- Neuropsychopharmacology\n- Clinical evolution\n- Personalized medicine",
  "dataset/provenance": "The dataset used in this study consists of microRNA data collected from peripheral blood samples of patients with major depressive disorder (MDD) and healthy controls. Samples were collected at two time points: baseline (T0) and after 8 weeks of antidepressant treatment (T8). The total number of microRNA samples included for subsequent analyses is 140 MDD cases and 28 healthy controls, resulting in 168 samples. The total number of microRNA features is 285.\n\nThe microRNA data was obtained through small RNA sequencing using the Illumina HiSeq2000 platform. The sequencing data was processed using CASAVA 1.8+ and the Fastx_toolkit for quality control and adapter trimming. Reads were aligned to the human genome (GRCh37) and matched to known microRNA sequences using Bowtie and ncPRO-seq in combination with miRBase (V20). The data was then normalized using the Bioconductor-DESeq2 package.\n\nThis dataset has not been used in a previous paper by the authors, nor has it been widely used by the community. The study represents an original analysis of microRNA data in the context of major depressive disorder and antidepressant response. The dataset was specifically curated for this study to investigate the potential of microRNA as biomarkers for MDD diagnosis, severity classification, and treatment response prediction.",
  "dataset/splits": "The dataset was split into two main parts: training and testing. The training set comprised 70% of the data, while the testing set comprised the remaining 30%. The training set consisted of 122 data points, and it was further divided using a 5-fold cross-validation procedure with 2500 iterations of parameter search to obtain the best training parameters. After identifying the optimal parameters, the model was retrained using the entire training set at once. The testing set was then used to evaluate the model's performance. The performance metric used was the area under the receiver-operating characteristics curve (AUC).",
  "dataset/redundancy": "The datasets were split into 70% for training and 30% for testing. This split ensures that the training and testing sets are independent. To enforce this independence, a model selection procedure based on 5-fold cross-validation with 2500 iterations of parameter search was used to obtain the best training parameters using only the training dataset. After identifying the optimal parameters, the model was retrained using the entire training set and then evaluated on the testing set. This approach helps to prevent data leakage and ensures that the model's performance is assessed on unseen data.\n\nThe distribution of the datasets used in this study is not explicitly compared to previously published machine learning datasets. However, the use of a 70-30 split is a common practice in machine learning to balance the need for a sufficient amount of training data while reserving a substantial portion for independent testing. This split is designed to provide a robust evaluation of the model's generalizability and performance on new, unseen data. The specific details of the dataset distribution, such as the number of samples and the balance between different classes, are not provided in the context, but the methodology ensures that the training and testing processes are conducted independently.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a tree-based ensemble method, specifically the XGBoost implementation. This algorithm is not new; it was introduced by Chen and Guestrin in 2016. The choice to use XGBoost was driven by its proven effectiveness in various classification tasks and its demonstrated success in our previous study on schizophrenia. XGBoost is a scalable and efficient implementation of gradient boosting, known for its high performance and speed. While XGBoost is well-established in the machine-learning community, our application of it to analyze blood microRNA data for biomarker discovery in major depressive disorder is novel. The decision to publish this work in a neuropsychopharmacology journal rather than a machine-learning journal is due to the focus on the clinical implications and the specific application to mental health research. The primary goal of our study is to contribute to the field of psychiatry by leveraging advanced machine-learning techniques to identify reliable biomarkers for major depressive disorder.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the quality and suitability of the microRNA data for analysis. Blood samples were collected at two time points: baseline (T0) and after 8 weeks of antidepressant treatment (T8). RNA was extracted from these samples, and its quality was assessed using the Agilent 2200 Tapestation, with only samples having an RNA integrity number of 6.0 or higher being used.\n\nThe small RNA sequencing libraries were prepared using the Illumina TruSeq protocol, and the samples were sequenced using the Illumina HiSeq2000 platform with 50-nucleotide single-end reads. The sequencing data were processed using CASAVA 1.8+ to extract FASTQ files, and the Fastx_toolkit was used to trim Illumina adapter sequences. Additional filtering was applied to ensure high-quality reads, including a Phred quality mean score higher than 30, read lengths between 15 and 40 nucleotides, and the removal of reads without a detected adapter.\n\nThe reads were then aligned to the human genome (GRCh37) using Bowtie, and known microRNA sequences were matched using ncPRO-seq in combination with miRBase (V20). The sequencing data were normalized using the Bioconductor-DESeq2 package, with a detection threshold of 10 counts per microRNA. This preprocessing ensured that the microRNA data were of high quality and appropriately normalized for machine-learning analysis.\n\nThe datasets were split into 70% for training and 30% for testing. A model selection procedure based on 5-fold cross-validation with 2500 iterations of parameter search was used to obtain the best training parameters using only the training dataset. After obtaining the best training parameters, the model was retrained using the entire training set and evaluated on the testing set. The performance metric used was the area under the receiver-operating characteristics curve (AUC).",
  "optimization/parameters": "In our study, we employed a machine learning approach using the XGBoost implementation to analyze microRNA data for classification tasks related to major depressive disorder (MDD). The datasets were split into 70% for training and 30% for testing. To select the optimal parameters for our model, we utilized a model selection procedure based on 5-fold cross-validation with 2500 iterations of parameter search. This process was conducted using only the training dataset, which consisted of 122 samples. The goal was to identify the best training parameters that would maximize the model's performance.\n\nAfter determining the best parameters through cross-validation, we retrained the model using the entire training set without cross-validation. This final model was then evaluated on the testing set. The performance of the model was assessed using the area under the receiver-operating characteristics curve (AUC) as the primary metric.\n\nThe number of parameters (p) used in the model was not explicitly stated, as the focus was on the overall performance and the selection process rather than the specific count of parameters. The importance of each microRNA feature was ranked, with the top features being crucial for the model's predictive power. For instance, in the case-control classification, 33 out of 285 total microRNAs measured were utilized by the best-trained model. This selection process ensured that the model was optimized for distinguishing between cases and controls, as well as for other classification tasks such as severity classification and antidepressant response prediction.",
  "optimization/features": "In our study, we utilized a total of 285 microRNAs as potential input features. However, the best performing machine learning model for classifying cases and controls used only 33 out of these 285 microRNAs. This indicates that feature selection was indeed performed. The feature selection process was conducted using a model selection procedure based on 5-fold cross-validation with 2500 iterations of parameter search, ensuring that it was done using only the training dataset. This approach helped in identifying the most relevant microRNAs for the classification task, facilitating the discovery of biomarkers with minor effects or complex interactions that might have been overlooked by multiple testing correction methods.",
  "optimization/fitting": "The fitting method employed in this study utilized a machine learning approach, specifically the XGBoost implementation, which is known for its effectiveness in handling complex datasets. The datasets were split into 70% for training and 30% for testing, ensuring a robust evaluation of the model's performance.\n\nTo address the potential issue of overfitting, given that the number of parameters could be large relative to the number of training points, a model selection procedure based on 5-fold cross-validation with 2500 iterations of parameter search was used. This rigorous cross-validation process helped in obtaining the best training parameters using only the training dataset, thereby minimizing the risk of overfitting. After identifying the optimal parameters, the model was retrained on the entire training set and then evaluated on the testing set. The performance metric used was the area under the receiver-operating characteristics curve (AUC), which provided a comprehensive measure of the model's discriminative ability.\n\nTo rule out underfitting, the model's performance was carefully monitored during the cross-validation process. The use of a powerful algorithm like XGBoost, combined with extensive parameter tuning, ensured that the model was capable of capturing the underlying patterns in the data without being too simplistic. Additionally, the evaluation on a separate testing set further validated the model's generalizability, confirming that it was not underfitting the data. The achieved AUC values, particularly the high testing set AUC of 0.97 for distinguishing cases from controls, indicated that the model was well-fitted and capable of making accurate predictions.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our machine learning models. One of the key methods used was regularization. Regularization helps to prevent overfitting by adding a penalty to the loss function, which discourages the model from fitting the noise in the training data. Specifically, we used a regularized gradient boosting algorithm, which incorporates L1 and L2 regularization terms. These terms help to shrink the coefficients of less important features, effectively performing feature selection and reducing the complexity of the model.\n\nAdditionally, we utilized a model selection procedure based on 5-fold cross-validation with 2500 iterations of parameter search. This approach helps to find the optimal set of hyperparameters that generalize well to unseen data, further mitigating the risk of overfitting. After obtaining the best training parameters through cross-validation, we retrained the model using the entire training set and evaluated its performance on a separate testing set. This two-step process ensures that the model's performance is assessed on data that was not used during the training phase, providing a more reliable estimate of its generalization capability.\n\nMoreover, we performed unsupervised clustering of the microRNA data to account for the heterogeneity in major depressive disorder (MDD). By clustering the data, we aimed to create more homogeneous subgroups, which allowed the machine learning algorithm to identify signatures specific to each subgroup more efficiently. This clustering approach helped to improve the classification performance by reducing the variability within each cluster, making the models more robust and less prone to overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the methodology section. Specifically, we employed a model selection procedure based on 5-fold cross-validation with 2500 iterations of parameter search to obtain the best training parameters. After identifying the optimal parameters, we retrained the model using the entire training set and evaluated its performance on the testing set. The model performance metric utilized was the area under the receiver-operating characteristics curve (AUC).\n\nThe software and libraries used for implementing the machine learning model and the consensus clustering procedure are also specified. The machine learning model was implemented using the Python programming language with the \"xgboost\" library. The consensus clustering procedure was implemented using the \"scikit-learn\" and \"scipy\" Python libraries. These tools and their versions are publicly available and can be accessed through their respective websites.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the text. However, the methodologies and tools used are well-documented and can be replicated using the information provided. The specific microRNAs and pathways identified are discussed, but the exact model files and optimization parameters are not made available for direct download. For further details, one would need to refer to the supplementary materials or contact the authors directly.",
  "model/interpretability": "The model employed in this study is not a black box. It utilizes the XGBoost implementation, which is known for its interpretability. This machine learning algorithm provides insights into the importance of individual features, allowing us to understand which microRNAs are most influential in the classification tasks.\n\nFor instance, in the classification of cases from controls, the model identified 33 out of 285 total microRNAs as the most important features. These microRNAs were ranked by their importance, with hsa-miR-27a-3p being the most significant. This transparency enables us to pinpoint specific microRNAs that are potentially linked to the condition, facilitating further biological investigation.\n\nSimilarly, in the antidepressant response classification, the model highlighted specific microRNAs that differed between responders and nonresponders. For example, in one cluster, hsa-miR-5701 was found to be significantly different between responders and nonresponders, suggesting its potential role in treatment response. This level of detail helps in understanding the underlying biological mechanisms and can guide future research and clinical applications.",
  "model/output": "The model employed in our study is a classification model. We utilized machine learning algorithms, specifically the XGBoost implementation, to classify individuals into different categories based on their microRNA data. The primary classifications we addressed include distinguishing cases from healthy controls, classifying the severity of Major Depressive Disorder (MDD) into \"normal-mild\" and \"moderate-severe\" categories, and identifying responders versus nonresponders to antidepressant treatment.\n\nFor the case-control classification, the model achieved an impressive performance with an area under the receiver-operating characteristics curve (AUC) of 0.97 on the testing set. This indicates a high accuracy in differentiating between MDD cases and healthy controls. The model utilized 33 out of 285 total microRNAs measured, highlighting the specific microRNAs that were most informative for this classification task.\n\nIn the severity classification, the model was trained to distinguish between \"normal-mild\" and \"moderate-severe\" MDD grades using microRNA data. The average cross-validation AUC was 0.76, and after retraining on the full dataset, the testing set AUC was 0.63. This suggests a moderate level of accuracy in predicting the severity of MDD based on microRNA profiles.\n\nFor antidepressant response classification, the model aimed to identify responders versus nonresponders. The average cross-validation AUC was 0.62, and the testing set AUC was 0.57. To improve the performance, we performed unsupervised clustering, which resulted in two balanced clusters. The best models for these clusters achieved cross-validation AUCs of 0.65 and 0.67, respectively, and testing set AUCs of 0.54 and 0.49. This indicates that while the model shows some ability to classify responders and nonresponders, there is room for improvement.\n\nOverall, the model's performance varies across different classification tasks, with the highest accuracy observed in the case-control classification and moderate accuracy in severity and antidepressant response classifications. The use of microRNA data and machine learning algorithms provides a promising approach for biomarker discovery in MDD, facilitating a more personalized treatment strategy.",
  "model/duration": "The model selection procedure involved 5-fold cross-validation with 2500 iterations of parameter search, which was computationally intensive. However, the exact execution time for this process is not specified. After obtaining the best training parameters, the model was retrained using the entire training set without cross-validation, and then evaluated on the testing set. This final training and evaluation process was more straightforward and likely completed more quickly. The consensus k-means clustering method was applied with 500 iterations, which also contributed to the overall execution time. Additionally, permutation tests were performed with 500,000 iterations to derive empirical P values, further adding to the computational demands. The software used for these analyses included Python with the xgboost, scikit-learn, and scipy libraries.",
  "model/availability": "The machine learning model implemented in this study was developed using the Python programming language, specifically version 3.7.1. The core library utilized for the machine learning tasks was \"xgboost,\" version 0.81. This library is publicly available and can be accessed via its documentation at https://xgboost.readthedocs.io/.\n\nAdditionally, the consensus clustering procedure was implemented using two other Python libraries: \"scikit-learn,\" version 0.21.2, and \"scipy,\" version 1.3.0. These libraries are also publicly available and can be found at https://scikit-learn.org/ and https://www.scipy.org/, respectively.\n\nThe source code for the specific implementations used in this study is not publicly released. However, the libraries mentioned are open-source and can be used under their respective licenses, which are typically permissive and allow for both academic and commercial use. For detailed licensing information, one should refer to the official documentation of each library.",
  "evaluation/method": "The evaluation method employed in this study involved a rigorous process to ensure the robustness and generalizability of the machine learning models. Initially, datasets were split into 70% for training and 30% for testing. A model selection procedure based on 5-fold cross-validation with 2500 iterations of parameter search was utilized to identify the optimal training parameters using only the training dataset. This approach helped in mitigating overfitting and ensured that the model generalized well to unseen data.\n\nAfter determining the best training parameters, the model was retrained using the entire training set without cross-validation. This final model was then evaluated on the testing set to assess its performance. The primary metric used for evaluating model performance was the area under the receiver-operating characteristics curve (AUC).\n\nFor the classification of cases from healthy controls, the best-trained model achieved an average cross-validation AUC of 0.93 and a testing set AUC of 0.97. This high performance indicates the model's effectiveness in distinguishing between the two groups.\n\nIn the severity classification task, individuals' MADRS scores were categorized as \"normal-mild\" or \"moderate-severe.\" The model achieved an average cross-validation AUC of 0.76 and a testing set AUC of 0.63. To address the heterogeneity of major depressive disorder (MDD), unsupervised clustering was applied to the microRNA data. This clustering resulted in two clusters, each analyzed separately. The models for these clusters showed improved performance, with cross-validation AUCs of 0.75 and 0.72, and testing set AUCs of 0.76 and 0.70, respectively.\n\nFor antidepressant response classification, the initial model achieved an average cross-validation AUC of 0.62 and a testing set AUC of 0.57. Similar to the severity classification, unsupervised clustering was performed, resulting in two balanced clusters. The models for these clusters had cross-validation AUCs of 0.65 and 0.67, and testing set AUCs of 0.54 and 0.49, respectively. Notably, specific microRNAs were identified as significant markers for treatment response within these clusters, highlighting the potential for personalized treatment strategies.",
  "evaluation/measure": "The primary performance metric reported in our study is the area under the receiver-operating characteristics curve (AUC). This metric was chosen for its ability to provide a single scalar value that represents the trade-off between the true positive rate and the false positive rate across all possible classification thresholds.\n\nFor the classification of cases from healthy controls, we achieved an average cross-validation AUC of 0.93 and a testing set AUC of 0.97. This indicates a high level of discriminative power for our model in distinguishing between these two groups.\n\nIn the severity classification task, where we aimed to differentiate between \"normal-mild\" and \"moderate-severe\" MADRS grades, the average cross-validation AUC was 0.76, and the testing set AUC was 0.63. These values suggest a moderate level of performance, which is consistent with the complexity of the task and the inherent variability in depression severity.\n\nFor the antidepressant response classification, the average cross-validation AUC was 0.62, and the testing set AUC was 0.57. These results indicate a more challenging classification problem, likely due to the heterogeneity in treatment responses among patients.\n\nAdditionally, we performed clustering to address this heterogeneity and evaluated the performance of our models within each cluster. For cluster 1, the cross-validation AUC was 0.75, and the testing set AUC was 0.76. For cluster 2, the cross-validation AUC was 0.72, and the testing set AUC was 0.70. These results suggest that clustering may help improve the performance of our models by reducing the heterogeneity within each group.\n\nThe set of metrics reported is representative of the literature in the field of machine learning for psychiatric disorders. The AUC is a widely used metric for evaluating the performance of classification models, particularly in medical and biological research. The use of cross-validation AUC and testing set AUC provides a comprehensive evaluation of model performance, accounting for both the model's ability to generalize to new data and its robustness to overfitting.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "The evaluation of our machine learning models included several performance metrics, each accompanied by confidence intervals to provide a measure of uncertainty. For instance, the area under the receiver-operating characteristics curve (AUC) for discriminating cases from healthy controls was reported with a standard deviation, indicating the variability in performance across different iterations. Specifically, the best-trained model achieved an average cross-validation AUC of 0.93 with a standard deviation of 0.06, and a testing set AUC of 0.97.\n\nFor the classification of individuals based on MADRS grades, the average cross-validation AUC was 0.76 with a standard deviation of 0.11, and the testing set AUC was 0.63. These metrics were derived from a model selection procedure based on 5-fold cross-validation with 2500 iterations of parameter search, ensuring robust and reliable performance estimates.\n\nIn the clustering approach, the best models for each cluster also had associated standard deviations. For example, the best model for cluster 1 achieved an average cross-validation AUC of 0.75 with a standard deviation of 0.18, and a testing set AUC of 0.76. Similarly, the best model for cluster 2 had an average cross-validation AUC of 0.72 with a standard deviation of 0.15, and a testing set AUC of 0.70.\n\nFor antidepressant response classification, the average cross-validation AUC was 0.62 with a standard deviation of 0.13, and the testing set AUC was 0.57. After clustering, the best models for each cluster had average cross-validation AUCs of 0.65 and 0.67, respectively, with corresponding standard deviations of 0.085 and 0.16. The testing set AUCs for these models were 0.54 and 0.49, respectively.\n\nStatistical significance was assessed using permutation tests, which involved 500,000 iterations to derive empirical P-values. For example, the microRNA hsa-miR-5701 was found to be significantly different between responders and nonresponders in cluster 1 with a P-value of 0.021. Similarly, in cluster 2, the microRNAs hsa-let-7b-3p and hsa-miR-130b-3p showed nominal significance with P-values of 0.021 and 0.045, respectively, although these did not remain significant after Bonferroni correction.\n\nOverall, the performance metrics and statistical analyses provide a comprehensive evaluation of the models' effectiveness and reliability. The inclusion of confidence intervals and rigorous statistical testing ensures that the results are robust and that the claims of superiority over baselines are well-supported.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data includes sensitive patient information and microRNA sequencing data, which are subject to strict privacy and ethical considerations. Therefore, the datasets are not released to the public to protect participant confidentiality and comply with institutional and ethical guidelines.\n\nThe evaluation process involved machine learning models trained and tested on microRNA data from patients with major depressive disorder (MDD) and healthy controls. The models were assessed using metrics such as the area under the receiver-operating characteristics curve (AUC), and the performance was validated through cross-validation and testing on separate datasets. However, due to the sensitive nature of the data, these raw files are not accessible to the public.\n\nFor researchers interested in replicating or building upon our work, we provide detailed methodologies and results in the publication. This includes information on the machine learning algorithms used, the preprocessing steps for the microRNA data, and the statistical analyses performed. Additionally, the software and libraries utilized, such as Python, XGBoost, scikit-learn, and scipy, are publicly available and can be accessed through their respective websites. This should enable other researchers to implement similar analyses using their own datasets, adhering to ethical and privacy standards."
}