{
  "publication/title": "Early Diagnosis of High-Risk Chronic Obstructive Pulmonary Disease Based on Quantitative High-Resolution Computed Tomography Measurements.",
  "publication/authors": "Zhang W, Zhao Y, Tian Y, Liang X, Piao C",
  "publication/journal": "International journal of chronic obstructive pulmonary disease",
  "publication/year": "2023",
  "publication/pmid": "38162987",
  "publication/pmcid": "PMC10757779",
  "publication/doi": "10.2147/copd.s436803",
  "publication/tags": "- Chronic Obstructive Pulmonary Disease (COPD)\n- Machine Learning\n- Support Vector Machine (SVM)\n- Quantitative Computed Tomography (QCT)\n- High-Risk COPD Prediction\n- Emphysema\n- Airway Anatomy\n- Clinical Information\n- Feature Selection\n- LASSO Method\n- Kernel Functions\n- Pulmonary Function Tests (PFTs)\n- Early Diagnosis\n- Radiomics\n- Inspiratory CT Images",
  "dataset/provenance": "The dataset used in this study was sourced from participants who had undergone quantitative computed tomography (QCT) measurements and clinical evaluations. The study involved a total of 140 subjects, who were divided into training and test sets in a 7:3 ratio. Specifically, the training set consisted of 98 subjects, while the test set included 42 subjects.\n\nThe data utilized in this research included QCT measurements and clinical information. The QCT measurements focused on various lung parameters, such as the percentage of low attenuation areas (%LAA) and lumen diameters (LD) at different generations of the airway. Clinical information encompassed demographic data and pulmonary function test (PFT) results, including forced expiratory volume in one second (FEV1), forced vital capacity (FVC), and the ratio of FEV1 to FVC.\n\nThis dataset was specifically curated for the purpose of identifying high-risk chronic obstructive pulmonary disease (COPD) participants based on precursor conditions. The participants had no airflow obstruction but exhibited respiratory symptoms and structural lung lesions, making them potential candidates for developing COPD over time. The combination of QCT measurements and clinical information provided a comprehensive approach to early diagnosis and risk assessment.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The training set consisted of 98 data points, while the test set had 42 data points. This division followed a 7:3 ratio, ensuring that a larger portion of the data was used for training the model, which is a common practice to enhance the model's learning capacity. The test set, being smaller, was used to evaluate the model's performance on unseen data, providing an unbiased assessment of its generalization ability.",
  "dataset/redundancy": "The dataset used in this study was divided into training and test sets to evaluate the performance of the prediction model. The subjects were split in a ratio of 7:3, resulting in 98 subjects in the training set and 42 subjects in the test set. This split ensures that the training and test sets are independent, which is crucial for assessing the model's generalization ability.\n\nTo enforce the independence of the training and test sets, standard practices were followed. The data was randomly shuffled before splitting to ensure that the distribution of features and labels was similar in both sets. This random shuffling helps to mitigate any potential biases that might arise from the order of the data.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in the field of COPD research. The use of quantitative computed tomography (QCT) measurements and clinical information provides a comprehensive set of features that are relevant for predicting high-risk COPD. The inclusion of both QCT measurements and clinical data enhances the model's ability to capture the complexity of COPD, making it more robust and reliable.\n\nThe dataset's redundancy was managed by carefully selecting features that showed significant differences between the low-risk and high-risk COPD groups. This selection process involved using the LASSO method to determine the optimal regularization coefficient and identify the most relevant features. Additionally, the SVM classifier was applied to normalize the data using Z-score, which helps to avoid tedious calculations and ignore small numerical data, further reducing redundancy.\n\nIn summary, the dataset was split into independent training and test sets using a 7:3 ratio, with random shuffling to ensure similar distributions. The features were carefully selected to minimize redundancy and enhance the model's performance, aligning with best practices in machine learning for COPD research.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is the Support Vector Machine (SVM) classifier. This is a well-established and widely used algorithm in the field of machine learning, particularly for classification tasks.\n\nThe SVM classifier employed in this study is not a new algorithm. It has been extensively used in various domains, including medical research, for its effectiveness in handling high-dimensional spaces and in cases where the number of dimensions exceeds the number of samples.\n\nThe reason this study was published in a medical journal rather than a machine-learning journal is likely due to the focus and contributions of the research. The primary objective of the study was to develop a model for identifying high-risk COPD patients using quantitative computed tomography (QCT) measurements and clinical information. The innovation lies in the application of the SVM classifier to this specific medical problem, rather than in the development of a new machine-learning algorithm. The study's contributions are more aligned with the medical field, particularly in the area of COPD diagnosis and management, which is why it was published in a journal focused on chronic obstructive pulmonary disease.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on quantitative computed tomography (QCT) measurements and clinical information to predict high-risk chronic obstructive pulmonary disease (COPD).\n\nThe primary machine-learning method employed is the Support Vector Machine (SVM) classifier. This classifier was used to construct a high-risk COPD prediction model. The SVM classifier was applied with four different kernel functions: Linear, Radial Basis Function (RBF), Polynomial (Poly), and Sigmoid. The Linear kernel function was ultimately determined to have the best performance.\n\nThe data used for training and testing the model were divided into training sets (n = 98) and test sets (n = 42) in a 7:3 ratio. This division ensures that the training data is independent from the test data, which is crucial for evaluating the model's performance accurately.\n\nThe features selected for the model include ten QCT measurements and three clinical information sets (sex, dyspnea, and persistent cough). These features were chosen based on their significance in distinguishing between low-risk and high-risk COPD groups. The model's performance was evaluated using metrics such as accuracy, sensitivity, specificity, F1-score, and the area under the receiver operating characteristic (ROC) curve. The inclusion of clinical information improved the model's performance, particularly increasing specificity.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps to ensure the data was suitable for modeling. Initially, the dimensions of variables were inconsistent, and the range of values was large. To address this, normalization was applied using the Z-score method. This step was crucial to avoid tedious calculations and to prevent small numerical data from being ignored. The Z-score normalization standardized the data, ensuring that each feature contributed equally to the model.\n\nThe dataset was divided into training and test sets in a 7:3 ratio, with 98 subjects in the training set and 42 in the test set. This split allowed for robust model training and evaluation. Feature selection was performed using the LASSO method, which identified the optimal regularization coefficient (lambda) through ten-fold cross-validation. The final feature candidates were chosen based on their minimum average mean square error (MSE). This process helped in selecting the most relevant features for the model.\n\nThe Support Vector Machine (SVM) classifier was employed for the construction of the high-risk COPD prediction model. The penalty and kernel parameters for the SVM were determined using grid search and ten-fold cross-validation. Four kernel function models were constructed: Linear, Polynomial (Poly), Sigmoid, and Radial Basis Function (RBF). The Linear kernel function ultimately provided the best performance, achieving the highest accuracy, sensitivity, specificity, F1-score, and area under the ROC curve (AUC) in the testing dataset.\n\nThe selected features included ten QCT measurements and three clinical information sets (sex, dyspnea, and persistent cough). These features were statistically analyzed, and their significance in predicting high-risk COPD was validated. The combination of QCT measurements and clinical information improved the model's performance, particularly increasing specificity and AUC. This comprehensive approach to data encoding and preprocessing ensured that the machine-learning model was robust and effective in identifying high-risk COPD patients.",
  "optimization/parameters": "In our study, we utilized a combination of quantitative computed tomography (QCT) measurements and clinical information to construct a prediction model for high-risk chronic obstructive pulmonary disease (COPD). The selection of feature candidates was based on the Least Absolute Shrinkage and Selection Operator (LASSO) method. This method helped in determining the optimal regularization coefficient, lambda, through ten-fold cross-validation, where the final feature candidates were selected based on their minimum average mean square error (MSE).\n\nThe LASSO method identified ten QCT values as significant features. These included various measurements such as %LAA \u2212950-LLL, %LAA\u2212950-RML, max LD-0th-generation, min LD-0th-generation, mean LD-1th-generation, and min LD-1th-generation. Additionally, three clinical information parameters\u2014sex, dyspnea, and persistent cough\u2014were selected as they showed significant value in predicting high-risk COPD patients.\n\nThe optimal lambda value was determined to be 0.009, which corresponded to the smallest MSE. This process ensured that the model was both efficient and interpretable by selecting the most relevant features. The final model incorporated these selected features to improve its performance and accuracy in distinguishing between low-risk and high-risk COPD patients.",
  "optimization/features": "In the optimization process of our study, we initially considered a comprehensive set of features derived from quantitative computed tomography (QCT) measurements and clinical information. The QCT measurements included various parameters such as the percentage of low attenuation areas (%LAA) at different thresholds, lumen diameters (LD) at different generations, and airway wall area percentages (%WA). Clinical information encompassed variables like sex, dyspnea, and persistent cough, which showed significant differences between low-risk and high-risk chronic obstructive pulmonary disease (COPD) groups.\n\nTo enhance the model's performance and interpretability, feature selection was performed using the least absolute shrinkage and selection operator (LASSO) method. This technique is particularly effective for variable selection and regularization in regression models. The optimal regularization coefficient (lambda) was determined through ten-fold cross-validation, focusing on minimizing the average mean square error (MSE). This process ensured that the selected features were the most relevant for distinguishing between low-risk and high-risk COPD.\n\nThe feature selection was conducted exclusively on the training set, which consisted of 98 subjects. This approach prevented data leakage and ensured that the model's performance on the test set was a true reflection of its generalization capability. As a result, ten QCT values and three clinical features were selected as the most significant predictors. These selected features were then used to build and evaluate the support vector machine (SVM) classifier, which demonstrated improved accuracy and robustness in predicting high-risk COPD.\n\nThe final set of input features used in the model included %LAA \u2212950-LLL, %LAA \u2212950-RML, max LD-0th-generation, min LD-0th-generation, mean LD-1th-generation, min LD-1th-generation, %WA-2th-generation, max LD-2th-generation, min LD-3th-generation, min LD-4th-generation, sex, dyspnea, and persistent cough. This refined set of features allowed for a more efficient and effective prediction model, balancing complexity and performance.",
  "optimization/fitting": "In our study, we employed the LASSO (Least Absolute Shrinkage and Selection Operator) method to handle the high-dimensional data and prevent overfitting. The number of features initially considered was indeed much larger than the number of training points. To address this, we used ten-fold cross-validation to determine the optimal regularization coefficient lambda, ensuring that the final feature candidates were selected based on their minimum average mean square error (MSE). This process helped in selecting the most relevant features and discarding the less important ones, thereby reducing the risk of overfitting.\n\nAdditionally, we utilized the Support Vector Machine (SVM) classifier with different kernel functions to build our prediction model. The penalty and kernel parameters were optimized using grid search and ten-fold cross-validation. This approach helped in finding the best combination of parameters that minimized the risk of both overfitting and underfitting. The SVM classifier with a linear kernel function ultimately provided the best performance, indicating that it effectively captured the underlying patterns in the data without overcomplicating the model.\n\nTo further enhance the model's performance, we combined quantitative computed tomography (QCT) measurements with clinical information. This integration improved the model's accuracy, sensitivity, specificity, F1-score, and area under the curve (AUC), demonstrating that the model was neither underfitting nor overfitting the data. The inclusion of clinical information provided additional relevant features that complemented the QCT measurements, leading to a more robust and generalizable prediction model.",
  "optimization/regularization": "In our study, we employed the Least Absolute Shrinkage and Selection Operator (LASSO) method to prevent overfitting and to select the most relevant features for our prediction model. This regularization technique is particularly useful in scenarios where the number of predictors is large compared to the number of observations, as it helps to simplify the model by shrinking some of the coefficients to zero.\n\nThe optimal regularization coefficient, lambda, was determined through ten-fold cross-validation, where the final feature candidates were selected based on their minimum average mean square error (MSE). This process ensured that the model generalized well to unseen data by minimizing the risk of overfitting.\n\nAdditionally, we used Support Vector Machine (SVM) classifiers with different kernel functions, including Linear, Radial Basis Function (RBF), Polynomial (Poly), and Sigmoid. The penalty and kernel parameters were optimized using grid search and ten-fold cross-validation, further enhancing the model's robustness and preventing overfitting. The SVM classifier with the linear kernel function ultimately provided the best performance, demonstrating the effectiveness of our regularization and feature selection techniques.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available and reported within the publication. Specifically, the optimal regularization coefficient lambda for the LASSO method was determined through ten-fold cross-validation, focusing on the minimum average mean square error (MSE). For the Support Vector Machine (SVM) classifier, the penalty and kernel parameters were determined using grid search and ten-fold cross-validation. Four kernel function models of SVM were constructed: Linear, Poly, Sigmoid, and radial basis functions (RBF).\n\nThe model files and optimization parameters are not explicitly provided as downloadable assets, but the methods and results are thoroughly detailed in the text. The analyses were performed using the \u201cScikit-learn\u201d package in Python, which is an open-source machine learning library. The specific configurations and steps taken to optimize the models are described in the methods section, ensuring reproducibility.\n\nAll the data and methods used are openly available and can be accessed through the publication. The use of open-source software like Scikit-learn ensures that the tools and techniques employed are accessible to the research community. The detailed descriptions of the processes and parameters used provide a clear pathway for other researchers to replicate or build upon our work.",
  "model/interpretability": "The model employed in this study is not a blackbox. It leverages the Support Vector Machine (SVM) classifier, which is inherently interpretable due to its use of kernel functions and feature weights. The interpretability of the model is further enhanced by the use of the Least Absolute Shrinkage and Selection Operator (LASSO) method for feature selection.\n\nThe LASSO method helps in identifying the most relevant features by assigning weights to them, effectively shrinking less important features to zero. This process not only improves the model's performance but also makes it more interpretable by highlighting the key features that contribute most to the prediction of high-risk COPD patients.\n\nFor instance, the feature %LAA\u2212950-LLL, which represents the percentage of low attenuation area with attenuation less than \u2212950 HU for the left lower lobe, showed the highest absolute value of weight (0.183). This indicates that it is a crucial factor in distinguishing between low-risk and high-risk COPD patients. Other significant features include min LD-0th-generation (\u22120.123), min LD-1th-generation (0.122), and max LD-0th-generation (0.098). These features are related to the lumen diameter of the airways, which are critical in assessing airway obstruction and remodeling in COPD.\n\nAdditionally, clinical information such as sex, dyspnea, and persistent cough were also selected as important features, with weights of 0.076, 0.106, and 0.096, respectively. These clinical variables, along with the QCT measurements, provide a comprehensive view of the factors contributing to the risk of COPD.\n\nThe use of different kernel functions in the SVM classifier, such as Linear, RBF, Poly, and Sigmoid, allows for flexibility in modeling the relationships between the features and the target variable. The linear kernel function, in particular, demonstrated the best overall performance, indicating that the relationships between the features and the target variable are largely linear.\n\nIn summary, the model's transparency is ensured through the use of interpretable machine learning techniques and the clear identification of key features that contribute to the prediction of high-risk COPD patients. This makes the model not only effective but also understandable, which is crucial for its practical application in clinical settings.",
  "model/output": "The model developed is a classification model. It is designed to predict whether a patient falls into the category of high-risk or low-risk Chronic Obstructive Pulmonary Disease (COPD). The Support Vector Machine (SVM) classifier was employed, utilizing various kernel functions to distinguish between these two groups. The performance of the model was evaluated using metrics such as accuracy, sensitivity, specificity, F1-score, and the area under the receiver operating characteristic curve (AUC). The model's effectiveness was validated through the use of quantitative computed tomography (QCT) measurements and clinical information, demonstrating improved predictive accuracy when both types of data were combined.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the specific algorithms used in this study is not publicly released. However, the analyses were performed using the \"Scikit-learn\" package in Python, which is an open-source machine learning library. This package is freely available under the BSD license and can be accessed via its official website. Additionally, the NeuLungCARE software, used for quantifying emphysema and airway lesions from CT images, is a commercial scientific software provided by Neusoft Medical Systems Co. Ltd. This software is not open-source and is intended for use within clinical and research settings.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive approach to ensure the robustness and accuracy of the prediction model for high-risk COPD. The optimal regularization coefficient, lambda, for the LASSO method was determined through ten-fold cross-validation, focusing on minimizing the average mean square error (MSE). This process helped in selecting the final feature candidates that were most relevant for the model.\n\nFor the Support Vector Machine (SVM) classifier, four different kernel functions\u2014Linear, Radial Basis Function (RBF), Polynomial (Poly), and Sigmoid\u2014were tested using quantitative computed tomography (QCT) measurements. The performance of each kernel function was evaluated to identify the one that provided the best overall accuracy. The dataset was divided into training and test sets in a 7:3 ratio, with 98 subjects in the training set and 42 in the test set. The penalty and kernel parameters for the SVM were optimized using grid search and ten-fold cross-validation.\n\nThe evaluation metrics used included accuracy (ACC), sensitivity (SEN), specificity (SPE), F1-score, and the area under the receiver operating characteristic curve (AUC). The Linear kernel function demonstrated the highest performance metrics, achieving an accuracy of 85.71%, sensitivity of 88.34%, specificity of 84.00%, F1-score of 83.33%, and an AUC of 0.93 in the testing dataset. This indicated that the Linear kernel function was the most effective for classifying low-risk and high-risk COPD patients based on QCT measurements.\n\nAdditionally, the model's performance was further enhanced by incorporating clinical information that showed significant differences between the low-risk and high-risk groups. This combination improved the specificity by 8.00% and increased the AUC to 0.96, highlighting the added value of clinical data in predicting high-risk COPD. The evaluation process ensured that the model was thoroughly validated and optimized for accurate and reliable predictions.",
  "evaluation/measure": "In the evaluation of our prediction model for high-risk COPD patients, we reported several key performance metrics to comprehensively assess the model's effectiveness. These metrics include Accuracy (ACC), Sensitivity (SEN), Specificity (SPE), F1-score, and the Area Under the Receiver Operating Characteristic Curve (AUC).\n\nAccuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall, indicates the proportion of actual positives that are correctly identified by the model. Specificity measures the proportion of actual negatives that are correctly identified. The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. The AUC provides an aggregate measure of performance across all classification thresholds.\n\nWe tested four classical kernel functions for the Support Vector Machine (SVM) classifier: Linear, Radial Basis Function (RBF), Polynomial (Poly), and Sigmoid. The linear kernel function demonstrated the best overall performance with an accuracy of 85.71%, sensitivity of 88.34%, specificity of 84.00%, F1-score of 83.33%, and an AUC of 0.93 in the testing dataset. This set of metrics is representative of standard practices in the literature for evaluating classification models, particularly in medical diagnostics where balancing sensitivity and specificity is crucial.\n\nAdditionally, we combined Quantitative Computed Tomography (QCT) measurements with clinical information to further enhance the model's performance. This combination significantly improved the specificity, increasing it by 8.00% and resulting in an AUC of 0.96. This improvement highlights the added value of integrating clinical data with QCT measurements for predicting high-risk COPD patients.\n\nThe reported metrics are aligned with commonly used evaluation criteria in the field, ensuring that our model's performance can be compared and validated against other studies in the literature. The use of multiple metrics provides a holistic view of the model's strengths and areas for potential improvement.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, our focus was on evaluating the performance of different kernel functions within the Support Vector Machine (SVM) classifier framework. We tested four classical kernel functions: Linear, Radial Basis Function (RBF), Polynomial (Poly), and Sigmoid. The performance of these kernel functions was assessed using quantitative computed tomography (QCT) measurements.\n\nTo ensure a comprehensive evaluation, we used a ten-fold cross-validation approach to determine the optimal parameters for each kernel function. This method helped us to identify the kernel function that provided the best overall performance. The Linear kernel function emerged as the most effective, achieving the highest accuracy, sensitivity, specificity, F1-score, and area under the curve (AUC) in the testing dataset.\n\nAdditionally, we compared the performance of the SVM classifier using QCT measurements alone versus a combination of QCT measurements and clinical information. The inclusion of clinical information significantly improved the model's performance, particularly in terms of specificity and AUC. This comparison highlighted the added value of integrating clinical data with QCT measurements for predicting high-risk chronic obstructive pulmonary disease (COPD) patients.\n\nWhile we did not compare our method against simpler baselines or publicly available datasets, our approach demonstrated the effectiveness of using SVM with different kernel functions and the importance of incorporating clinical information to enhance predictive accuracy.",
  "evaluation/confidence": "The evaluation of the prediction model's performance was conducted using several metrics, including accuracy (ACC), sensitivity (SEN), specificity (SPE), F1-score, and the area under the receiver operating characteristic curve (AUC). These metrics were calculated for different classifiers and feature sets to assess their effectiveness in distinguishing between low-risk and high-risk COPD patients.\n\nThe performance metrics for the Support Vector Machine (SVM) classifier with different kernel functions were reported, with the linear kernel achieving the highest overall performance. The linear kernel model demonstrated an accuracy of 85.71%, sensitivity of 88.34%, specificity of 84.00%, F1-score of 83.33%, and an AUC of 0.93. These results indicate strong discriminative power in identifying high-risk COPD patients.\n\nWhen clinical information was combined with QCT measurements, the performance of the linear kernel SVM classifier improved significantly. The accuracy increased to 90.48%, sensitivity remained at 88.24%, specificity improved to 92.00%, and the F1-score was 88.24%. The AUC also increased to 0.96, suggesting a more robust model.\n\nStatistical significance was assessed for various measurements and features. For instance, the severity of emphysema, as indicated by perc15, %LAA\u2212950, and %LAA\u2212910, showed significant differences between the study groups with p-values less than 0.001. Similarly, the min LD in the 0th-4th generations airway and other airway measurements like %WA, mean LD, and max LD exhibited significant differences within the 0th-3rd generations airway, with p-values lower than 0.01.\n\nThe selection of features using the LASSO method and their weights further supported the statistical significance of the model. Features such as %LAA\u2212950-LLL, min LD-0th-generation, min LD-1th-generation, and max LD-0th-generation had the highest absolute weights, indicating their importance in predicting high-risk COPD patients. Clinical information like sex, dyspnea, and persistent cough also showed significant weights, contributing to the model's predictive power.\n\nThe correlations between key QCT measurements and pulmonary function tests (PFTs) were explored, revealing significant correlations for %LAA\u2212950-LLL with FEV1, FVC, and FEV1/FVC. These correlations underscore the relevance of the selected features in the context of COPD severity.\n\nIn summary, the performance metrics and statistical significance of the results provide strong evidence that the SVM classifier, particularly with the linear kernel and combined QCT measurements and clinical information, is effective in predicting high-risk COPD patients. The improvements in accuracy, specificity, and AUC when incorporating clinical data highlight the model's robustness and reliability.",
  "evaluation/availability": "Not enough information is available."
}