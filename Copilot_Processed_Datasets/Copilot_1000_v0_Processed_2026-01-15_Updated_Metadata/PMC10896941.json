{
  "publication/title": "Diagnosing and grading gastric atrophy and intestinal metaplasia using semi-supervised deep learning on pathological images: development and validation study.",
  "publication/authors": "Fang S, Liu Z, Qiu Q, Tang Z, Yang Y, Kuang Z, Du X, Xiao S, Liu Y, Luo Y, Gu L, Tian L, Liang X, Fan G, Zhang Y, Zhang P, Zhou W, Liu X, Tian J, Wei W",
  "publication/journal": "Gastric cancer : official journal of the International Gastric Cancer Association and the Japanese Gastric Cancer Association",
  "publication/year": "2024",
  "publication/pmid": "38095766",
  "publication/pmcid": "PMC10896941",
  "publication/doi": "10.1007/s10120-023-01451-9",
  "publication/tags": "- Gastric Atrophy\n- Intestinal Metaplasia\n- Deep Learning\n- Pathology\n- Diagnostic Model\n- Gastric Cancer\n- Machine Learning\n- Medical Imaging\n- Semi-Supervised Learning\n- Multiple Instance Learning",
  "dataset/provenance": "The dataset used in this study was sourced from 13 tertiary hospitals in China. The study enrolled 609 potentially eligible patients between December 2017 and September 2020. After excluding 64 patients due to superficial biopsy samples, 545 patients with a total of 2725 whole slide images (WSIs) were included in the analysis.\n\nThe patients were randomly divided into three cohorts: a training set consisting of 349 patients with 1745 WSIs, a validation set with 87 patients and 435 WSIs, and a test set comprising 109 patients and 545 WSIs. The dataset was divided using stratified sampling based on the true atrophy grade of the patients to avoid prediction bias caused by differences in data distribution.\n\nThe dataset includes baseline characteristics of the patients, such as age, gender, and the distribution of patients among OLGA and OLGIM stages. There were no significant differences in these baseline characteristics or the distribution of patients among OLGA and OLGIM stages between the training, validation, and test sets.\n\nThe data used in this study has not been previously published or used by the community in other papers. The dataset is specific to this study and focuses on diagnosing and grading gastric atrophy and intestinal metaplasia using semi-supervised deep learning techniques.",
  "dataset/splits": "The dataset consists of 546 patients, which were randomly divided into three splits: training, validation, and test sets. The training set includes 348 patients, the validation set includes 88 patients, and the test set includes 110 patients. The data was split using stratified sampling based on the true atrophy grade of the patients to avoid model prediction bias caused by differences in the data distribution of each cohort. This approach ensures that the distribution of patients among OLGA and OLGIM stages is similar across all three sets, with no significant differences observed (p > 0.05). The baseline characteristics of the patients in each split are summarized in a table, showing that the age and gender distributions, as well as the distribution of OLGA and OLGIM stages, are comparable across the training, validation, and test sets.",
  "dataset/redundancy": "The dataset used in this study consisted of 546 patients, each with whole slide images (WSIs) from five different parts of the stomach. To ensure that the model's predictions were not biased by differences in data distribution, stratified sampling was employed. This method divided the dataset according to the true atrophy grade of the patients.\n\nThe patients were randomly split into three cohorts: a training set, a validation set, and a test set. The training set included 348 patients, the validation set had 88 patients, and the test set comprised 110 patients. This division was done to ensure that each cohort had a representative distribution of patients across different atrophy grades, maintaining the independence of the training and test sets.\n\nThe baseline characteristics of the patients, including age, gender, and OLGA/OLGIM stages, were compared across the three sets. There were no significant differences in these characteristics (p > 0.05), indicating that the distribution of patients was balanced and comparable across the training, validation, and test sets. This balance is crucial for evaluating the model's performance and generalizability.\n\nIn comparison to previously published machine learning datasets, this study's approach to dataset splitting and stratification is robust. By ensuring that the training and test sets are independent and representative of the overall patient population, the study aims to provide reliable and generalizable results. The use of stratified sampling helps to mitigate the risk of model overfitting and ensures that the model's performance can be accurately assessed on unseen data.",
  "dataset/availability": "The dataset used in this study is not publicly available. The data consists of 546 patients with 2725 whole slide images (WSIs) collected from 13 tertiary hospitals. The patients were randomly divided into training, validation, and test sets using stratified sampling based on the true atrophy grade to avoid prediction bias. The training set includes 348 patients with 1740 WSIs, the validation set includes 88 patients with 440 WSIs, and the test set includes 110 patients with 550 WSIs. The dataset is not released in a public forum due to privacy and ethical considerations. The ethics committees of the participating hospitals approved the trial protocol, and all participants signed informed consent forms. An independent data safety monitoring committee was responsible for monitoring the progress and safety of the trial. The data was used solely for the purposes of this study and was not shared publicly.",
  "optimization/algorithm": "The machine-learning algorithm class used is deep learning, specifically a deep neural network named GasMIL. This algorithm is designed to predict the degree of atrophy and intestinal metaplasia of gastric tissue slice images using weakly supervised learning, particularly multiple instance learning (MIL). The choice of MIL allows the algorithm to require only coarse-grained labels for pathological diagnosis, avoiding the need for complicated manual annotations by doctors.\n\nThis algorithm is not entirely new, as it builds upon existing frameworks like SimCLR for contrastive learning and ResNet for feature extraction. However, the specific application and adaptation of these techniques to the problem of gastric tissue diagnosis are novel. The reason it was not published in a machine-learning journal is likely because the focus of the study is on its application in medical diagnosis rather than the development of new machine-learning techniques. The primary goal is to demonstrate the effectiveness of the algorithm in improving the accuracy and efficiency of pathological grading and gastric cancer risk stratification.\n\nThe algorithm's design includes constructing multi-scale patch embeddings and using a multi-layer perceptron (MLP) network as a classifier to feed these embeddings. This approach helps in making comprehensive grade decisions by integrating both shallow low-level features and deep high-level features from the pathological images. The use of self-supervised learning for patch embedding further enhances the robustness of the image representations without the need for manual labeling.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it employs a deep neural network named GasMIL, which is designed to predict the degree of atrophy and intestinal metaplasia (IM) in gastric tissue slice images. This network utilizes weakly supervised learning, specifically multiple instance learning (MIL), to achieve its predictions. The MIL approach allows the model to require only coarse-grained labels for pathological diagnosis, eliminating the need for detailed manual annotations by doctors.\n\nThe GasMIL model processes whole slide images (WSIs) from five different parts of the stomach for each patient. It aggregates features from these images to produce a comprehensive patient-level grading prediction. The model constructs multi-scale patch embeddings by cropping each WSI into non-overlapping blocks at different resolutions. These embeddings are then used to train the model through a contrastive learning framework, which helps in learning robust image representations without manual labeling.\n\nThe training, validation, and test sets were carefully divided to ensure that the data distribution was balanced and to avoid prediction bias. The model's performance was evaluated using metrics such as the area under the curve (AUC), sensitivity, and specificity. The results indicate that the model achieves good diagnostic performance in predicting pathological images of different grades.\n\nIn summary, the model does not rely on data from other machine-learning algorithms as input. It is a standalone deep learning model that uses MIL and contrastive learning to predict gastric atrophy and IM grades from WSIs. The training data for the model was independently divided to ensure unbiased performance evaluation.",
  "optimization/encoding": "In our study, the data encoding and preprocessing involved several key steps to prepare the whole slide images (WSIs) for the machine-learning algorithm. Initially, each WSI was cropped into non-overlapping blocks at resolutions of 224 \u00d7 224 pixels, with fields of view of 0.5 micrometers per pixel (MPP) and 2.0 MPP. This step ensured that the images were standardized and suitable for further processing.\n\nBefore applying multiple instance learning (MIL), we employed self-supervised learning to pre-learn embeddings for each cut patch. We used the SimCLR framework, which is designed for contrastive learning, to learn robust image representations without the need for manual labeling. For each original patch, we applied various data augmentation operations, such as random rotation and random color distortion, to generate sub-images. These sub-images were then passed through a ResNet-18-based encoder to extract features. A contrastive loss function was used to minimize the distance between sub-images from the same original image in the feature space, ensuring that the learned representations were robust and informative.\n\nTo construct multi-scale patch embeddings, we created single-scale WSI classifiers for both 0.5 MPP and 2.0 MPP magnifications. The patch embeddings under 2.0 MPP magnification were spliced with the embeddings corresponding to the physical 0.5 MPP magnification positions. This approach allowed us to obtain a comprehensive patch embedding that captured both fine and coarse details of the tissue samples.\n\nIn the MIL hypothesis, when a WSI is marked as positive (label > 0), at least one patch is assumed to be the target lesion area. Conversely, if the mark is negative, all patch labels should be negative. Based on this assumption, we used a multi-layer perceptron (MLP) network as a classifier to feed the multi-scale patch embeddings. After training the patch-level classifier, we obtained the probability of all patches in the current WSI being predicted as lesion areas. We then sorted these probabilities to identify the patches that should be the most focused on. For each WSI, we uniformly selected the top 20 patches with the highest ranking to input into the downstream aggregator.\n\nTo enhance the aggregation of patches, we introduced a transformer into the aggregation stage. Traditional MIL methods use pooling algorithms to evaluate the prediction probability of the top patches, but these methods ignore the correlation information between patches. By using a transformer, we were able to capture the correlations between the 100 most critical patch vectors obtained from each WSI. These patch vectors were sequentially passed to the transformer classifier to predict the entire rank probability of the WSI, thereby improving the overall accuracy and reliability of the diagnostic model.",
  "optimization/parameters": "The model, named GasMIL, utilizes a deep neural network framework designed to predict the degree of atrophy and intestinal metaplasia in gastric tissue slide images. The development of this model involved several key steps and considerations regarding the input parameters.\n\nThe model employs a weakly supervised learning approach, specifically multiple instance learning (MIL). This method requires coarse-grained labels for the pathological diagnosis of each image, which avoids the need for detailed manual annotations by pathologists. The use of MIL allows the model to learn from the overall characteristics of the images rather than relying on specific, finely annotated features.\n\nOne of the critical aspects of the model is the construction of multi-scale patch embeddings. The whole slide images (WSIs) are cropped into non-overlapping blocks at resolutions of 224 \u00d7 224 with fields of view of 0.5 micrometers per pixel (MPP) and 2.0 MPP, respectively. This multi-scale approach ensures that both low-level features (such as local edges and textures) and high-level features (such as severe disease appearances) are captured. The integration of these comprehensive multi-scale image features helps in making accurate grade decisions.\n\nThe selection of key patches within the WSIs is another important parameter. The MIL hypothesis assumes that if a WSI is marked as positive (label > 0), at least one patch contains the target lesion area. Conversely, if the WSI is marked as negative, all patch labels should be negative. A multi-layer perceptron (MLP) network is used as a classifier to feed the multi-scale patch embeddings, ensuring that the most relevant patches are selected for further analysis.\n\nThe model's performance is evaluated using various metrics, including the area under the curve (AUC), sensitivity, specificity, and Cohen's kappa coefficient. These metrics provide a comprehensive assessment of the model's diagnostic accuracy and its agreement with human pathologists.\n\nIn summary, the input parameters for the GasMIL model include the use of multi-scale patch embeddings, the selection of key patches through MIL, and the evaluation of model performance using established metrics. These parameters were chosen to ensure that the model can accurately predict the degree of atrophy and intestinal metaplasia in gastric tissue slide images, providing a reliable diagnostic tool for pathologists.",
  "optimization/features": "The input features for our model are derived from whole slide images (WSIs) of gastric tissue samples. Specifically, each WSI is divided into non-overlapping blocks at resolutions of 224 \u00d7 224 pixels, with fields of view of 0.5 micrometers per pixel (MPP) and 2.0 MPP. This results in a comprehensive set of features that capture both low-level details (such as local edges and textures) and high-level information (such as severe disease appearance).\n\nFeature selection is inherently performed through the use of multiple instance learning (MIL) and self-supervised learning techniques. The self-supervised learning framework, SimCLR, is employed to pre-learn embeddings for each patch, ensuring that robust image representations are obtained without the need for manual labeling. This process involves data augmentation operations like random rotation and color distortion, which help in generating sub-images and extracting meaningful features.\n\nThe MIL framework further refines these features by aggregating multi-scale patch embeddings. This aggregation helps in selecting key patches that are most relevant for the prediction of atrophy and intestinal metaplasia grades. The MIL hypothesis assumes that if a WSI is marked as positive, at least one patch contains the target lesion area, while if marked as negative, all patches should be negative. This assumption guides the selection of key patches, ensuring that the most informative features are used for the final prediction.\n\nThe feature selection process is conducted using the training set only, adhering to best practices to avoid data leakage and ensure the model's generalizability to unseen data. This approach allows the model to learn and select the most relevant features from the training data, which are then validated and tested on separate validation and test sets.",
  "optimization/fitting": "The model developed in this study, GasMIL, employs a deep neural network framework designed to predict the degree of atrophy and intestinal metaplasia in gastric tissue slide images. The architecture leverages multiple instance learning (MIL), which requires only coarse-grained labels for pathological diagnosis, thereby avoiding the need for detailed manual annotations.\n\nGiven the complexity of the model and the relatively large number of parameters, there is a potential risk of overfitting, especially when dealing with a finite number of training samples. To mitigate this risk, several strategies were implemented. Firstly, stratified sampling was used to divide the dataset according to the true atrophy grade of the patients, ensuring a balanced distribution of data across training, validation, and test sets. This approach helps in maintaining the representativeness of the data and reduces the likelihood of the model learning spurious patterns specific to certain subsets of the data.\n\nAdditionally, self-supervised learning techniques were employed to pre-learn embeddings for each cropped patch of the whole slide images (WSIs). This involved using SimCLR, a contrastive learning framework, to generate robust image representations without manual labeling. By applying data augmentation operations and constructing a contrastive loss, the model learns to minimize the distance between sub-images from the same original image in feature space. This pre-training step helps in extracting meaningful features that are generalizable across different parts of the WSIs.\n\nTo further ensure that the model does not underfit, multi-scale patch embeddings were constructed. This involved creating single-scale WSI classifiers for both 0.5 micrometers per pixel (MPP) and 2.0 MPP magnifications. The embeddings from these different resolutions were then spliced together to obtain a comprehensive patch embedding. This multi-scale approach allows the model to capture both low-level features (such as local edges and textures) and high-level features (such as severe disease appearance), providing a richer set of features for grade prediction.\n\nThe model's performance was evaluated on separate validation and test sets, which were not used during the training process. The consistent performance metrics across these sets, including high area under the curve (AUC) values and other diagnostic metrics, indicate that the model generalizes well to unseen data. This suggests that overfitting was effectively managed, and the model is robust and reliable for the intended diagnostic tasks.",
  "optimization/regularization": "In our study, we employed stratified sampling to divide the dataset according to the true atrophy grade of the patients. This technique helped to avoid model prediction bias caused by differences in the data distribution of each cohort. By ensuring that each subset (training, validation, and test) maintained a similar distribution of patient characteristics, we aimed to create a more robust and generalizable model.\n\nAdditionally, we utilized a combination of statistical tests, including the T-test and Wilcoxon signed-rank test, to examine the impact of age at baseline. For gender analysis, we employed the Chi-square test, Fisher\u2019s exact test, continuously corrected Chi-square test, and signed-rank test. These statistical methods helped to validate the consistency and reliability of our model's predictions across different patient demographics.\n\nFurthermore, we assessed inter-observer agreement between our diagnostic models and human pathologists using Cohen\u2019s kappa coefficient. This metric provided insights into the consistency and reliability of our model's diagnoses compared to those made by experienced pathologists.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not explicitly detailed in the provided information. However, the methods used for model development and optimization are described.\n\nThe model development involved a deep neural network named GasMIL, which utilizes multiple instance learning (MIL) to predict the degree of atrophy and intestinal metaplasia in gastric tissue slice images. The model employs self-supervised learning for patch embedding using SimCLR, which learns robust image representations without manual labeling. This process involves data augmentation operations and feature extraction through a ResNet18-based encoder.\n\nThe construction of multi-scale patch embedding is also mentioned, where embeddings from different resolutions are combined to obtain comprehensive patch embeddings. These embeddings are then used in a WSI classifier to select key patches, following the MIL hypothesis.\n\nThe statistical analysis section mentions the use of Python and PyTorch for building WSI algorithms, which implies that the code and possibly the model files could be available through these platforms. However, specific details about the availability of hyper-parameter configurations, optimization schedules, and model files, including their licenses, are not provided.\n\nNot sure if the optimization parameters are reported, as the provided information does not explicitly list them. The focus is more on the methodological approach rather than the specific parameters used.",
  "model/interpretability": "The model in question is a deep learning-based system, which inherently possesses characteristics of a black box. This means that while it can provide accurate predictions, the internal workings and decision-making processes are not easily interpretable. We have attempted to observe the model's attention to different areas using heat maps, but even this visualization method falls short in providing a clear explanation of how the model learns and arrives at its conclusions. The complexity of deep learning models often makes it challenging to trace back the specific features or patterns that influence the output, thereby limiting the transparency of the model.",
  "model/output": "The model is designed for classification tasks, specifically for diagnosing various gastric conditions. It predicts grades for inflammation, activity, intestinal metaplasia (IM), atrophy, OLGIM, and OLGA stages. The output consists of performance metrics such as accuracy, sensitivity, specificity, and area under the curve (AUC) for different datasets (training, validation, and test sets). These metrics indicate the model's effectiveness in classifying the presence and severity of gastric conditions. The model's performance is evaluated using receiver operating characteristic (ROC) curves and AUC, which quantify the diagnostic classifier's performance. Additionally, the model's predictions are compared against diagnoses made by pathologists, with metrics like Cohen\u2019s kappa coefficient used to assess inter-observer agreement. The model's outputs are integral to its application in assisting pathologists in diagnosing and grading gastric conditions, thereby aiding in the risk stratification of atrophic gastritis patients.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the GasMIL algorithm is not publicly released. However, the models were built using Python and Pytorch, which are widely available and open-source programming languages and libraries. This allows for reproducibility of the methods described in the study, although the specific implementation details of the GasMIL algorithm are not accessible.\n\nThe study does not mention the availability of an executable, web server, virtual machine, or container instance to run the algorithm. Therefore, it is not possible to directly use the GasMIL algorithm as described in the study without implementing it based on the provided methods and descriptions.",
  "evaluation/method": "The evaluation of our diagnostic model involved several key steps and methods to ensure its robustness and generalizability. We began by dividing the dataset of 546 patients into training, validation, and test sets using stratified sampling based on the true atrophy grade of the patients. This approach helped to avoid prediction bias caused by differences in data distribution across cohorts.\n\nFor the training set, which consisted of 348 patients, we evaluated the model's performance using metrics such as the area under the curve (AUC), sensitivity, specificity, and weighted kappa. The validation set, comprising 88 patients, was used to tune hyperparameters and prevent overfitting. Finally, the test set, with 110 patients, was employed to assess the model's performance on unseen data, providing an unbiased evaluation of its generalizability.\n\nIn addition to these standard evaluation methods, we conducted an observer study involving 60 patients from the test set. These patients were randomly selected, and their clinical information was concealed. The digital whole slide images (WSIs) were distributed to 10 pathologists, who were divided into two groups: one with the aid of our GasMIL diagnostic results and the other without. This study allowed us to compare the diagnostic performance of our model with that of human pathologists, both with and without assistance from our model.\n\nWe used a combination of statistical tests, including the T-test, Wilcoxon signed-rank test, Chi-square test, Fisher\u2019s exact test, and continuously corrected Chi-square test, to analyze various baseline characteristics and histological data. The performance of our model was quantified using receiver operating characteristic (ROC) curves and the area under the curve (AUC), as well as accuracy, sensitivity, and specificity. The cutoff value for the ROC curve was set at 0.5. Furthermore, Cohen\u2019s kappa coefficient was used to assess inter-observer agreement between our diagnostic model and human pathologists.\n\nThe results of our evaluation demonstrated that our model achieved high performance metrics across various diagnostic tasks, such as inflammation, activity, intestinal metaplasia (IM), and atrophy, at both the slide and patient levels. Moreover, our model's performance was comparable to or even surpassed that of human pathologists in many cases, highlighting its potential as a valuable tool in clinical practice.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the diagnostic model's effectiveness. The primary metric used was the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, which quantifies the model's ability to distinguish between different grades of pathological images. This metric was reported for various conditions, including inflammation, activity, intestinal metaplasia (IM), atrophy, OLGIM, and OLGA, across training, validation, and test cohorts.\n\nIn addition to AUC, we also reported sensitivity and specificity, which provide insights into the model's true positive rate and true negative rate, respectively. These metrics were crucial for understanding the model's performance in correctly identifying positive and negative cases.\n\nFurthermore, we used Cohen's kappa coefficient to assess inter-observer agreement between the diagnostic model and human pathologists. This metric helped in evaluating the consistency and reliability of the model's predictions compared to expert diagnoses.\n\nThe reported metrics are representative of standard practices in the literature for evaluating diagnostic models, particularly in the context of medical imaging and pathology. The use of AUC, sensitivity, specificity, and Cohen's kappa coefficient ensures a comprehensive assessment of the model's performance, covering aspects of discrimination, accuracy, and agreement with human experts.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, our focus was on evaluating the performance of our diagnostic model, GasMIL, within the context of our specific dataset and clinical application.\n\nHowever, we did compare the performance of GasMIL against human pathologists. Specifically, we conducted an observer study involving 60 patients from the test set, where digital whole slide images (WSIs) were distributed to 10 pathologists for diagnosis. The pathologists were divided into two groups: one with the aid of GasMIL diagnostic results and the other without. This allowed us to assess the impact of GasMIL on the diagnostic performance of pathologists.\n\nIn terms of simpler baselines, our approach involved a comprehensive evaluation of GasMIL's performance across various metrics, including accuracy, sensitivity, specificity, and the area under the curve (AUC). These metrics provided a robust assessment of GasMIL's diagnostic capabilities compared to traditional pathological evaluations.\n\nAdditionally, we used statistical tests such as the T-test, Wilcoxon signed-rank test, Chi-square test, Fisher\u2019s exact test, and Cohen\u2019s kappa coefficient to analyze and compare the performance of GasMIL with human pathologists. These statistical methods ensured that our comparisons were rigorous and reliable.\n\nOverall, while we did not compare GasMIL directly with other publicly available methods on benchmark datasets, our evaluation included a thorough assessment against human experts and a detailed analysis of diagnostic performance metrics.",
  "evaluation/confidence": "The evaluation of our model, GasMIL, includes performance metrics with confidence intervals, providing a clear indication of the reliability of our results. For instance, the Area Under the Curve (AUC) for different conditions such as inflammation, activity, intestinal metaplasia (IM), and atrophy are reported with their respective confidence intervals. This approach ensures that the performance metrics are not just point estimates but are accompanied by a range within which the true value is likely to fall.\n\nStatistical significance is a crucial aspect of our evaluation. We employed various statistical tests, including the T-test, Wilcoxon signed-rank test, Chi-square test, Fisher\u2019s exact test, and continuously corrected Chi-square test, to analyze different variables and ensure the robustness of our findings. These tests help in determining whether the observed differences in performance are due to chance or if they are statistically significant.\n\nIn the observer study, we compared the diagnostic performance of pathologists with and without the aid of GasMIL. The results, including AUC, sensitivity, specificity, and consistency, were analyzed to assess the impact of GasMIL on diagnostic accuracy. The use of Cohen\u2019s kappa coefficient further helped in evaluating the inter-observer agreement, providing a quantitative measure of how well the model\u2019s predictions align with those of human pathologists.\n\nThe sample size and the stratification of the data set were carefully considered to avoid bias and ensure that the results are generalizable. The model\u2019s performance was evaluated on training, validation, and test sets, with no significant differences in baseline characteristics among these sets. This rigorous evaluation process ensures that our claims of superiority over other methods and baselines are well-founded and statistically significant.",
  "evaluation/availability": "Not enough information is available."
}