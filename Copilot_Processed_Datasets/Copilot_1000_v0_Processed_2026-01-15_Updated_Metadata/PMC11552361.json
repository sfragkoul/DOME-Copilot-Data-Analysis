{
  "publication/title": "The utility of wearable electroencephalography combined with behavioral measures to establish a practical multi-domain model for facilitating the diagnosis of young children with attention-deficit/hyperactivity disorder.",
  "publication/authors": "Chen IC, Chang CL, Chang MH, Ko LW",
  "publication/journal": "Journal of neurodevelopmental disorders",
  "publication/year": "2024",
  "publication/pmid": "39528958",
  "publication/pmcid": "PMC11552361",
  "publication/doi": "10.1186/s11689-024-09578-1",
  "publication/tags": "- ADHD\n- EEG\n- Machine Learning\n- Classification Models\n- Neurodevelopmental Disorders\n- Child Psychology\n- Predictive Modeling\n- Ensemble Learning\n- Bi-Directional LSTM\n- Decision Tree\n- Random Forest\n- Cross-Validation\n- Wearable Technology\n- Clinical Decision Support\n- Brain Dynamics\n- Hyperactivity\n- Inattentiveness\n- Diagnostic Tools\n- Preschool Children\n- Multimodal Systems",
  "dataset/provenance": "The dataset utilized in this study is derived from a combination of behavioral scales, computerized attention tests, and wireless EEG data. The study involves two primary groups: children with ADHD and typically developing (TD) children. The demographic and clinical measurements are compared between these two groups, with a total sample size of 78 participants, comprising 43 children with ADHD and 35 typically developing children.\n\nThe behavioral data includes scores from the Disruptive Behavior Disorder Rating Scale (DBDRS), which provides subjective observations from main caregivers and teachers. The DBDRS assesses both inattentiveness and hyperactivity dimensions. Additionally, the Conners' Kiddie Continuous Performance Test Second Edition (K-CPT-2) is used to offer objective behavioral quantification, measuring various aspects such as detectability, omission, commission, perseveration, hit reaction time (HRT), and inter-stimulus interval (ISI) change.\n\nThe EEG data is collected using wireless EEG recordings, which indicate brain signals related to attention. These EEG datasets are analyzed individually for each participating child, focusing on patient-specific identification of ADHD. The EEG features are extracted from segments of EEG data, with 60,000 resting and 450,000 task EEG data samples used as input to the LSTM classifier.\n\nThis multimodal dataset aligns with clinical guidelines for preschool ADHD diagnosis, incorporating multiple assessment approaches to ensure a reliable and diverse evaluation scheme. The combination of behavioral scales, computerized attention tests, and EEG data provides a comprehensive framework for assisting in the diagnosis of ADHD in young children.",
  "dataset/splits": "In our study, we utilized two primary data splits for training and testing our models. Specifically, we allocated 70% of the data for training purposes and the remaining 30% for testing. Additionally, during the validation phase, we used 90% of the data for training and 10% for validation. This approach ensured that our models were robust and generalizable. The distribution of data points in each split was designed to maintain a representative sample of both ADHD and typically developing (TD) participants, ensuring that the models could accurately differentiate between the two groups. The specific number of data points in each split was determined by the total dataset size and the proportions allocated for training, testing, and validation.",
  "dataset/redundancy": "The datasets used in this study were split to ensure robust evaluation of the models. For the EEG-based model, 70% of the data was allocated for training, while the remaining 30% was reserved for testing. During the validation phase, 90% of the data was used for training, and 10% was used for validation. This split ensures that the training and test sets are independent, reducing the risk of data leakage and overfitting.\n\nTo enforce the independence of the training and test sets, we employed a 5-fold cross-validation technique. This method involves dividing the data into five subsets, where the model is trained on four subsets and tested on the remaining one. This process is repeated five times, with each subset serving as the test set once. This approach helps to ensure that the model's performance is evaluated on different portions of the data, providing a more reliable estimate of its generalization capability.\n\nThe distribution of the datasets in this study compares favorably with previously published machine learning datasets for ADHD classification. The use of multiple modalities, including EEG data, clinical neuropsychological measures, and behavioral scales, aligns with the clinical guidelines for preschool ADHD diagnosis. This multimodal approach provides a comprehensive assessment, incorporating subjective observations from caregivers, objective behavioral quantification, and brain signal data related to attention. The ensemble model integrates these diverse datasets, leveraging their unique strengths to enhance the overall diagnostic accuracy. This method ensures that the model benefits from a rich and varied set of features, improving its robustness and reliability in real-world applications.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and include decision trees, random forests, and bidirectional Long Short-Term Memory (LSTM) networks. These algorithms are part of the broader classes of tree-based methods and recurrent neural networks, respectively.\n\nThe decision tree and random forest algorithms are fundamental techniques in machine learning, known for their interpretability and effectiveness in handling both numerical and categorical data. Random forests, in particular, are an ensemble method that combines multiple decision trees to improve predictive accuracy and control over-fitting.\n\nBidirectional LSTMs are a type of recurrent neural network designed to capture dependencies in sequential data by processing information in both forward and backward directions. This makes them particularly suitable for tasks where the context from both past and future elements is crucial, such as in natural language processing and time-series analysis.\n\nThese algorithms are not new but are applied in a novel context within this research. The focus of this study is on their application to EEG data and neuropsychological measurements for the classification of ADHD. The specific combination and application of these models to this particular dataset and problem domain are what contribute to the novelty of the work.\n\nThe decision to publish in a neurodevelopmental disorders journal rather than a machine-learning journal is driven by the primary focus of the research. The study aims to advance the understanding and diagnosis of ADHD using advanced machine-learning techniques. Therefore, the target audience and the relevance of the findings are more aligned with the field of neurodevelopmental disorders.",
  "optimization/meta": "The model employs an ensemble approach, utilizing a meta-predictor that aggregates the outputs of multiple machine-learning algorithms. This meta-predictor integrates predictions from three distinct classifiers: a decision tree, a random forest, and a bidirectional Long Short-Term Memory (LSTM) model.\n\nThe decision tree and random forest classifiers are trained on clinical neuropsychological measures, specifically the Disruptive Behavior Disorder Rating Scale (DBDRS) and the Conners' Kiddie Continuous Performance Test Second Edition (K-CPT-2) scores, respectively. The bidirectional LSTM model, on the other hand, is trained on Electroencephalography (EEG) data, which is analyzed on a patient-specific basis.\n\nThe ensemble model combines the predictions from these three classifiers using an aggregator function. This function, denoted as f(x), is a weighted sum of the predicted outputs from each model. The threshold value for the aggregator function is set at 0.5, meaning that if the value of f(x) is greater than 0.5, the predicted value is 1; otherwise, it is 0.\n\nIt is clear that the training data for each of the individual models is independent. The decision tree and random forest models are trained on different clinical measures, while the bidirectional LSTM model is trained on EEG data. This independence ensures that the ensemble model benefits from diverse sources of information, enhancing its predictive performance. The final ensemble model achieves an accuracy of 0.974, demonstrating the effectiveness of this approach.",
  "optimization/encoding": "In our study, the data encoding and preprocessing involved several key steps to prepare the EEG data for the machine-learning algorithm. Initially, Independent Component Analysis (ICA) was employed to separate multivariate signals into regions of interest and those containing artifacts. A conservative threshold of 25% was set to retain as many valid signals as possible. Artifact-related components were identified and removed, ensuring that the remaining components were clean for further analysis. This process resulted in retaining over 75% of valid ICA components on average.\n\nThe datasets were then divided into one-minute resting power and 7.5 minutes of task-related K-CPT-2 power, which were processed separately. To convert the raw time-domain signals into frequency band domains ranging from 0 to 50 Hz, the Welch function of the Fast Fourier Transform (FFT) was utilized. Five distinct frequency bands were defined: delta (1\u20134 Hz), theta (4\u20138 Hz), alpha (8\u201313 Hz), beta (13\u201330 Hz), and low gamma (30\u201350 Hz). The total artifact-free power spectral density of the EEG data for each participant was investigated using the short-time Fourier transform spectrogram function in MATLAB.\n\nMin-max normalization was applied to the absolute power of the data to ensure that the input features were scaled appropriately for the machine-learning models. This normalization step is crucial for improving the performance and convergence of the models.\n\nFor the deep learning model, specifically the bidirectional Long Short-Term Memory (LSTM) network, EEG datasets from each participant were analyzed individually. Features were extracted from every 0.001-second segment of EEG data, resulting in 60,000 resting and 450,000 task EEG data samples. These features served as input to the LSTM classifier, which was trained to identify ADHD on a patient-specific basis.\n\nHyperparameter tuning was conducted using grid search to select the most optimal pattern for the training model. The data was split into 70% for training and 30% for testing, with an additional 90% for training and 10% for validation during the validation phase. This approach ensured that the models were robust and generalizable to new data.",
  "optimization/parameters": "In our study, the input parameters varied depending on the specific model used. For the decision tree and random forest models, which were trained on clinical neuropsychological measures, the input parameters consisted of features derived from the Disruptive Behavior Disorder Rating Scale (DBDRS) and the Conners' Kiddie Continuous Performance Test Second Edition (K-CPT-2) scores. The exact number of parameters for these models was determined through feature selection processes, focusing on the most significant features that contributed to the model's predictive power.\n\nFor the bidirectional Long Short-Term Memory (LSTM) model, which was trained on EEG data, the input parameters were extracted from the EEG signals. Specifically, features were extracted from every 0.001-second segment of EEG data, resulting in a large number of input parameters. The selection of these parameters was guided by the need to capture the temporal dynamics of the EEG signals, which are crucial for identifying patterns associated with ADHD.\n\nThe selection of input parameters was optimized through a combination of domain knowledge and empirical validation. For the decision tree and random forest models, feature importance analysis was used to identify the most relevant features. For the LSTM model, hyperparameter tuning using grid search was employed to select the most optimal pattern for training. This approach ensured that the models were trained on the most informative features, enhancing their predictive accuracy and robustness.",
  "optimization/features": "In our study, we utilized a multimodal approach to develop a robust classification system for ADHD diagnosis. The input features for our models were derived from three distinct datasets: behavioral scales, computerized attention tests, and EEG data.\n\nFor the behavioral scales, we used the Disruptive Behavior Disorder Rating Scale (DBDRS), which includes both parent and teacher versions. The key features from DBDRS that were identified as significant include the inattentiveness and hyperactivity dimensions. Specifically, DBRShT and DBRSiT were found to be the most important features, affecting the precision of our models significantly.\n\nIn the case of computerized attention tests, we employed the Conners' Kiddie Continuous Performance Test Second Edition (K-CPT-2). The important features from K-CPT-2 included hit reaction time (HRT), HRT standard deviation (HRT SD), and HRT inter-stimulus interval (ISI) change. These features were crucial in differentiating between ADHD and typical development (TD) groups.\n\nFor the EEG data, we extracted features from 0.001-second segments of EEG signals. The most important features identified were O2 low-gamma, O2 beta, and O2 alpha. These features played a significant role in the performance of our bidirectional LSTM model.\n\nFeature selection was performed using permutation methods to determine the order of important features from the inner loop in the individual models. This process ensured that the most relevant features were used for model training and validation. The feature selection was conducted using the training set only, adhering to best practices to prevent data leakage and ensure the robustness of our models.\n\nIn summary, our models utilized a combination of behavioral, attention test, and EEG features. Feature selection was an integral part of our optimization process, focusing on identifying the most significant features from each dataset to enhance the performance and interpretability of our classification system.",
  "optimization/fitting": "In our study, we employed a bidirectional Long Short-Term Memory (LSTM) model for EEG data analysis, which inherently involves a large number of parameters due to its recurrent neural network architecture. The model processes input sequences in both forward and backward directions, capturing dependencies from past and future contexts. This complexity means the number of parameters is indeed much larger than the number of training points.\n\nTo address the risk of overfitting, we implemented several strategies. Firstly, we used 5-fold cross-validation during the testing phase to ensure the robustness of our results. This technique helps in assessing the model's performance on different subsets of the data, providing a more reliable estimate of its generalization capability. Secondly, we monitored the model's performance on a validation set during training. The model achieved a maximum training accuracy of 94.72% and a maximum validation accuracy of 87.68%, indicating that it generalized well to unseen data. Additionally, we observed that the model attained maximum and stable accuracy after 120 epochs, suggesting that it did not overfit to the training data.\n\nTo mitigate underfitting, we ensured that our model was sufficiently complex to capture the underlying patterns in the data. The bidirectional LSTM architecture, with its ability to process sequences in both directions, provided the necessary capacity to learn from the EEG data. Furthermore, we used an ensemble model that aggregated the predictions of multiple models, enhancing the overall performance and reducing the risk of underfitting. The ensemble model achieved an accuracy of 97.4%, demonstrating its effectiveness in capturing the complexities of the data.\n\nIn summary, we carefully managed the balance between overfitting and underfitting by employing cross-validation, monitoring validation performance, and using a robust model architecture. These measures ensured that our model generalized well to new data while capturing the essential patterns in the EEG signals.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed grid search for hyperparameter tuning to select the most optimal pattern for our training model. The details of this process, including the specific hyperparameter settings, are provided in the supplementary material, particularly in Supplementary Fig. 2.\n\nThe model files and optimization parameters are not directly available in the main text but are implied through the description of the models and their performance. For instance, model 3, which was generated using EEG data, achieved a maximum training accuracy of 94.72% and a maximum validation accuracy of 87.68% after 120 epochs. The robustness of the results was ensured using 5-fold cross-validation during the testing phase, yielding an accuracy of 95%.\n\nRegarding the availability and licensing of these configurations, the supplementary material is typically made available under the same licensing terms as the main publication. However, specific details about the licensing of the supplementary material would need to be checked directly with the journal or publisher. Generally, academic publications allow for the reuse of figures and data for non-commercial purposes, but explicit permission may be required for commercial use.\n\nFor those interested in replicating our study or using our models, the supplementary material provides a comprehensive overview of the methods and configurations used. This includes the hyperparameter settings, optimization schedule, and performance metrics, which are essential for understanding and potentially reproducing our results.",
  "model/interpretability": "The ensemble model proposed in our research is not entirely a black box, as it incorporates interpretable components alongside more complex elements. The ensemble model consists of three basic classifiers: a decision tree, a random forest, and a bidirectional LSTM. Each of these classifiers contributes to the final prediction, and their individual performances can be analyzed separately.\n\nThe decision tree and random forest models are inherently interpretable. Decision trees provide a clear, visual representation of the decision-making process, showing how different features influence the final prediction. Random forests, while slightly more complex due to the ensemble of multiple decision trees, can still be interpreted by examining the importance of features across all trees in the forest.\n\nThe bidirectional LSTM, on the other hand, is more of a black-box model due to its complex architecture involving recurrent neural networks. However, the ensemble model's aggregator function, which combines the outputs of the three classifiers, adds a layer of interpretability. The aggregator function uses a simple weighted average of the predicted outputs, with a threshold value of 0.5 to determine the final class label. This makes the final decision process more transparent.\n\nAdditionally, we conducted a significant features analysis to identify the most important features contributing to the model's predictions. For instance, in the decision tree model, the most important feature was found to be DBRShT, which significantly affects the precision of the model. Similarly, in the random forest model, features like DBRSiT were identified as crucial. This analysis helps in understanding which clinical and EEG features are most influential in the classification task.\n\nIn summary, while the ensemble model includes complex components like the bidirectional LSTM, the overall model benefits from the interpretability of the decision tree and random forest classifiers. The aggregator function and the significant features analysis further enhance the transparency of the model, making it possible to understand the contributions of different features and classifiers to the final prediction.",
  "model/output": "The model is a classification model designed to predict target label classes. It employs an aggregator function, denoted as f(x), which combines the predicted outputs from three different models: a decision tree, a random forest, and a bidirectional LSTM. The function f(x) is defined as the average of these three outputs, with each model contributing equally to the final prediction. The threshold value for classification is set at 0.5. If the value of f(x) is greater than or equal to 0.5, the predicted value is 1; otherwise, it is 0.\n\nThe ensemble model, which integrates these three base classifiers, achieves a high accuracy of 0.974. This indicates that the model is effective in distinguishing between the classes it was trained to identify. The use of an ensemble approach helps to leverage the strengths of each individual model, leading to improved overall performance.\n\nDuring the training phase, model 3, which was generated using EEG data, reached a maximum training accuracy of 94.72% and a maximum validation accuracy of 87.68%. The model attained stable accuracy after 120 epochs, demonstrating its ability to learn from the data effectively. Additionally, 5-fold cross-validation was used during the testing phase to ensure the robustness of the results, and the model achieved an accuracy of 95%.\n\nThe precision, recall, and F1 scores for models 1 and 2 are also provided, showcasing their individual performances. These metrics are crucial for evaluating the model's effectiveness in correctly identifying positive instances (precision), capturing all positive instances (recall), and balancing these two aspects (F1 score).\n\nIn summary, the model is a classification model that uses an ensemble of three different classifiers to make predictions. The ensemble model demonstrates high accuracy and robustness, making it a reliable tool for the intended classification task.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, we employed a robust evaluation method to ensure the reliability and validity of our models. For the model generated using EEG data, we achieved a maximum training accuracy of 94.72% and a maximum validation accuracy of 87.68%. The model attained stable accuracy after 120 epochs, with epochs represented 10 times for each scale. To further validate the model's performance, we used 5-fold cross-validation during the testing phase, resulting in an accuracy of 95%.\n\nFor the other models, we evaluated their performance using precision, recall, and F1 scores. These metrics provided a comprehensive assessment of the models' ability to correctly identify positive instances (recall), the proportion of positive identifications that were actually correct (precision), and the harmonic mean of precision and recall (F1 score).\n\nTo ensure the quality of the predictive EEG-based model, we allocated 70% of the data to training and 30% to testing. In validation, we used 90% of the data for training and 10% for validation. This approach helped us to assess the model's generalizability and robustness.\n\nAdditionally, we used permutation methods to determine the order of important features from the inner loop in the individual models. This feature analysis helped us to clarify which features were most important for differentiation between ADHD and typical development.\n\nOverall, our evaluation method combined multiple techniques to ensure the thorough assessment of our models' performance and the identification of key features for classification.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our models in classifying ADHD and typical development (TD). The primary metrics reported include precision, recall, F1 score, and accuracy. These metrics provide a comprehensive view of the models' performance, ensuring that we capture both the correctness and the robustness of our classifications.\n\nPrecision measures the accuracy of the positive predictions made by the model, indicating how many of the predicted positive cases are actually positive. Recall, on the other hand, assesses the model's ability to identify all relevant instances within the dataset, showing how many of the actual positive cases were correctly predicted. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. Accuracy gives an overall measure of the model's correctness by calculating the proportion of true results (both true positives and true negatives) among the total number of cases examined.\n\nFor model 1, which used a decision tree classifier, we achieved a precision, recall, and F1 score of 0.909, along with an accuracy of 0.909. Model 2, utilizing a random forest classifier, showed slightly better performance with a precision, recall, and F1 score of 0.922, and an accuracy of 0.922. Our model 3, a bidirectional LSTM, demonstrated the highest individual performance with a precision of 0.950, recall of 0.940, F1 score of 0.950, and accuracy of 0.950. These metrics indicate that our models are highly effective in distinguishing between ADHD and TD cases.\n\nAdditionally, we implemented an ensemble model that combines the outputs of the three individual models. This ensemble approach further enhanced our classification performance, achieving an accuracy of 0.974. The ensemble model leverages the strengths of each individual model, providing a more robust and reliable classification system.\n\nThe set of metrics used in our study is representative of standard practices in the literature for evaluating classification models, particularly in the context of neurodevelopmental disorders. Precision, recall, F1 score, and accuracy are commonly reported metrics that allow for a clear and comparative assessment of model performance across different studies. By including these metrics, we ensure that our results are both transparent and comparable to other research in the field.",
  "evaluation/comparison": "In our study, we evaluated the performance of three distinct models for classifying ADHD and typical development (TD) using different types of data. The models included a Decision Tree, a Random Forest, and a Bidirectional Long Short-Term Memory (LSTM) network. Each model was trained on specific datasets: the Decision Tree on Disruptive Behavior Disorder Rating Scale (DBDRS) features, the Random Forest on Conners\u2019 Kiddie Continuous Performance Test Second Edition (K-CPT-2) features, and the Bidirectional LSTM on EEG data.\n\nTo ensure a comprehensive evaluation, we compared the performance metrics of these individual models, including precision, recall, F1 score, and accuracy. The Decision Tree model achieved a precision, recall, and F1 score of 0.909, with an accuracy of 0.909. The Random Forest model slightly outperformed the Decision Tree with a precision, recall, and F1 score of 0.922, and an accuracy of 0.922. The Bidirectional LSTM model demonstrated the highest performance among the individual models, with a precision of 0.950, a recall of 0.940, an F1 score of 0.950, and an accuracy of 0.950.\n\nIn addition to evaluating individual models, we developed an ensemble model that combined the predictions of the Decision Tree, Random Forest, and Bidirectional LSTM models. This ensemble approach aimed to leverage the strengths of each model to improve overall classification performance. The ensemble model achieved a precision of 0.974, indicating a significant enhancement in classification accuracy compared to the individual models.\n\nTo validate the robustness of our models, we employed 5-fold cross-validation during the testing phase. This method ensured that the models were evaluated on different subsets of the data, providing a more reliable estimate of their performance. The Bidirectional LSTM model, in particular, attained a stable accuracy after 120 epochs, demonstrating its effectiveness in capturing complex patterns in the EEG data.\n\nIn summary, our evaluation involved a comparison of different models and an ensemble approach to enhance classification performance. The Bidirectional LSTM model showed superior performance, and the ensemble model further improved accuracy, highlighting the benefits of combining multiple models for better classification results.",
  "evaluation/confidence": "The evaluation of our models included several metrics to ensure the robustness and reliability of our results. For model 3, which utilized EEG data, we achieved a maximum training accuracy of 94.72% and a maximum validation accuracy of 87.68%. To further validate our model's performance, we employed 5-fold cross-validation during the testing phase, resulting in an accuracy of 95%. This rigorous validation method helps to ensure that our model's performance is not due to overfitting and is generalizable to new data.\n\nFor models 1 and 2, which were based on clinical neuropsychological measures, we reported precision, recall, and F1 scores. These metrics provide a comprehensive view of the models' performance, including their ability to correctly identify positive instances (recall) and the balance between precision and recall (F1 score). The precision, recall, and F1 scores for these models are listed in a table, allowing for a clear comparison of their performance.\n\nStatistical significance was assessed using independent t-tests for demographic and clinical measures, and chi-squared tests for categorical variables. This ensured that any observed differences between groups were not due to chance. For instance, significant differences were found in specific DBDRS and K-CPT-2 scores between the ADHD and typical development groups, with p-values indicating strong statistical significance (e.g., p < .001 for several DBDRS dimensions).\n\nThe ensemble model, which combined the outputs of the three individual models, achieved an accuracy of 97.4%. This high accuracy suggests that the ensemble approach effectively leverages the strengths of each individual model, leading to superior performance. The use of an aggregator function with a threshold value of 0.5 ensures that the final prediction is based on a balanced consideration of all models' outputs.\n\nIn summary, our evaluation methods included robust validation techniques, comprehensive performance metrics, and statistical significance testing. These steps provide confidence in the reliability and superiority of our models compared to baselines and other methods.",
  "evaluation/availability": "The datasets analyzed during the current study are available from the corresponding author upon reasonable request. This approach ensures that the data can be accessed by other researchers for verification or further study, promoting transparency and reproducibility in scientific research. However, the raw evaluation files are not publicly released."
}