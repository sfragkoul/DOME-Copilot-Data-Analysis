{
  "publication/title": "Prediction of B-cell linear epitopes with a combination of support vector machine classification and amino acid propensity identification.",
  "publication/authors": "Wang HW, Lin YC, Pai TW, Chang HT",
  "publication/journal": "Journal of biomedicine & biotechnology",
  "publication/year": "2011",
  "publication/pmid": "21876642",
  "publication/pmcid": "PMC3163029",
  "publication/doi": "10.1155/2011/432830",
  "publication/tags": "- Epitope prediction\n- Linear epitope prediction\n- Support vector machine\n- Machine learning\n- B-cell epitopes\n- Amino acid segments\n- Epitope index\n- SVM classification\n- Protein sequences\n- Antigenic determinants\n- Epitope datasets\n- Cross-validation\n- Epitope verification\n- Statistical analysis\n- Epitope candidates\n- Epitope features\n- Epitope prediction systems\n- Epitope prediction accuracy\n- Epitope prediction performance\n- Epitope prediction indicators",
  "dataset/provenance": "The datasets used in this study were sourced from various established databases and previous research. The Bcipep dataset, which comprised 1230 experimentally verified, B-cell, and non-redundant linear epitopes (LEs) with lengths ranging from 3 to 56 residues, was identified in over 1000 antigen proteins. This dataset was utilized to analyze the statistical characteristics associated with the frequencies of occurrence of amino acid segments (AASs) of 2 to 4 residues in length that represented epitopes.\n\nThe Chen dataset contained 872 epitopes and 872 non-epitopes, all restricted to a length of 20 residues. These verified epitopes were retrieved from the Bcipep dataset through a truncation-extension treatment. Non-epitopes were generated by randomly selecting peptide segments from the Swiss-Prot database, ensuring none matched the 872 epitopes.\n\nAdditionally, the AntiJen dataset, recommended at an international meeting sponsored by the National Institute for Allergy and Infectious Disease, contained 171 protein sequences with 691 verified, non-overlapping epitopes. The HIV dataset was a collection of the antigenic determinants located on 10 HIV proteins with 54 non-overlapping, verified epitopes.\n\nThe PC dataset, generated in this study, consisted of 12 protein sequences with 98 non-overlapping, verified epitopes. To balance variations in quantity and antigen diversity, these three datasets were merged into a comprehensive dataset called the AHP dataset. This dataset was analyzed with different linear epitope (LE) predictors, including BepiPred, ABCPred, BCPred, and FBCPred, to compare performances with that of the LEPS developed in this study.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets used in this study are publicly available and have been utilized in previous research. The AntiJen dataset, recommended at an international meeting sponsored by the National Institute for Allergy and Infectious Disease, contains 171 protein sequences with 691 verified, nonoverlapping epitopes. The HIV dataset is a collection of the antigenic determinants located on 10 HIV proteins with 54 nonoverlapping, verified epitopes. The PC dataset, generated in this study, is a collection of 12 protein sequences with 98 nonoverlapping, verified epitopes. These datasets were merged into one comprehensive dataset called the AHP dataset to balance out the variation in quantity and antigen diversity.\n\nThe Bcipep dataset, comprising 1230 experimentally verified, B-cell, and nonredundant linear epitopes (LEs) with lengths ranging from 3 to 56 residues, was used to analyze the statistical characteristics associated with the frequencies of occurrence of amino acid segments (AASs) of 2 to 4 residues in length that represented epitopes. The Chen dataset contained 872 epitopes and 872 non-epitopes, all restricted to a length of 20 residues. The non-epitopes were generated by randomly selecting peptide segments from the Swiss-Prot database, ensuring none matched any of the 872 epitopes.\n\nThe datasets are freely available for academic use. The LEPS system, which utilizes these datasets, is accessible at http://leps.cs.ntou.edu.tw. The system employs the LIBSVM toolbox for executing classification tasks, and the datasets are used to train the SVM model to recognize features of amino acid segments with lengths from 2 to 4 residues. The training process involves evaluating the statistical characteristics of AASs and using these features to classify epitope and non-epitope peptides. The performance of the LEPS system was verified using the PC, AntiJen, HIV, and AHP datasets, demonstrating its effectiveness in predicting linear epitopes.",
  "optimization/algorithm": "The machine-learning algorithm class used is Support Vector Machine (SVM). This is a well-established class of algorithms in the field of machine learning, known for its effectiveness in classification tasks.\n\nThe specific SVM implementation employed is from the LIBSVM library, which is a widely-used tool for SVM classification. The choice of SVM was driven by its ability to handle high-dimensional spaces and to perform well with a clear margin of separation.\n\nThe SVM model was trained using a dataset that included features derived from amino acid segments (AASs) with lengths from 2 to 4 residues. The training process involved evaluating the statistical characteristics of these segments to distinguish between epitopes and non-epitopes.\n\nFour common kernel functions were examined: linear, polynomial, radial basis function (RBF), and sigmoid. Through a 5-fold cross-validation process, the RBF kernel was selected as the default kernel function due to its superior cross-validation accuracy with the training data.\n\nThe SVM model was then applied to train the entire testing dataset, constructing the final SVM classifier. This classifier was used to predict the target value of each instance in the testing set, where each instance corresponded to a peptide, and the target value indicated whether the peptide was an epitope.\n\nThe performance of the SVM classifier was evaluated using several indicators, including sensitivity, specificity, positive predictive value, accuracy, and Matthews\u2019 correlation coefficient. These metrics provided a comprehensive assessment of the classifier's effectiveness in predicting epitopes.",
  "optimization/meta": "The model described in this publication is a meta-predictor, as it integrates multiple machine learning methods to enhance the prediction of linear epitopes. The primary components of this meta-predictor include the Linear Epitope Prediction by Propensities and Support Vector Machine (LEPS) system. This system combines physico-chemical propensities and mathematical morphology approaches with Support Vector Machine (SVM) classification.\n\nThe SVM classifier is trained to recognize features of amino acid segments (AASs) with lengths from 2 to 4 residues. This classifier is used to characterize patterns as epitope and non-epitope clusters, thereby improving the prediction accuracy. The training process involves evaluating the statistical characteristics of amino acid segments from an independent B-cell epitope prediction dataset.\n\nThe model also incorporates data from other machine-learning algorithms as input. Specifically, it uses predictions from various linear epitope (LE) predictors, such as BepiPred, ABCPred, BCPred, and FBCPred, to compare performances. These predictors employ different machine learning approaches, including hidden Markov models, subsequence kernels, and artificial neural networks.\n\nRegarding the independence of training data, it is clear that the datasets used for training and validation are distinct. For instance, the Chen dataset is used to construct the SVM model, while the PC, AntiJen, HIV, and AHP datasets are used for performance evaluation. This ensures that the training data is independent of the testing data, which is crucial for assessing the model's generalizability and performance.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to prepare the input for the machine-learning algorithm. We focused on peptides, where each peptide corresponded to an instance in the dataset. The target value for each instance was binary, indicating whether the peptide was an epitope (1) or not (\u22121).\n\nFor feature extraction, we utilized amino acid segments (AASs) of varying lengths. Specifically, we considered AASs of 2, 3, and 4 residues. For each peptide, we calculated three feature values based on these AASs: Epidex 2, Epidex 3, and Epidex 4. These values were derived from the frequencies of occurrence of AASs in epitope and non-epitope datasets.\n\nTo compute Epidex 2, we analyzed 400 possible combinations of residue pairs. The epitope index for each pair was calculated using the logarithm of the ratio of its frequency in epitopes to its frequency in non-epitopes. For AASs of 3 and 4 residues, due to the large number of possible combinations and the potential for zero frequencies in the non-epitope dataset, we modified the calculation to avoid division by zero. The epitope indexes for AASs of 3 and 4 residues were defined as the ratio of their frequencies in epitopes to the total frequency in the epitope dataset.\n\nThese epitope indexes were then normalized to a range of [0, 1] to ensure that no single index dominated the learning process. For a given peptide, such as a 20-mer, we decomposed it into subsegments of AASs and calculated the average epitope index for each type of AAS. These averages served as the feature values for the peptide.\n\nThe preprocessing steps ensured that the data was in a suitable format for the Support Vector Machine (SVM) algorithm. We used the LIBSVM toolbox for classification, which required the input data to be in a specific format where each instance had a target value and several feature values. The features were derived from the statistical analysis of AASs, providing a robust basis for the SVM to distinguish between epitopes and non-epitopes.",
  "optimization/parameters": "In the optimization process, the model utilized three feature values for each peptide instance. These features were derived from the epitope indexes Epidex 2, Epidex 3, and Epidex 4. The selection of these parameters was based on the statistical analysis of amino acid segments (AASs) of lengths 2, 3, and 4 residues. This approach was chosen to capture the essential characteristics of epitopes and non-epitopes, enhancing the model's predictive accuracy. The use of these three features allowed the Support Vector Machine (SVM) to effectively distinguish between epitopes and non-epitopes in the training dataset. The radial basis function (RBF) kernel was selected as the default kernel function due to its superior performance in cross-validation, further refining the model's ability to generalize from the training data to new instances.",
  "optimization/features": "In the optimization process, three specific features were used as input for the Support Vector Machine (SVM) model. These features were derived from the epitope indexes Epidex 2, Epidex 3, and Epidex 4, which were calculated based on the statistical characteristics of amino acid segments (AASs) of lengths 2, 3, and 4 residues, respectively.\n\nFeature selection was inherently performed during the calculation of these epitope indexes. The epitope indexes were determined by analyzing the frequencies of occurrence of AASs in both epitope and non-epitope datasets. This process involved calculating the logarithm of the ratio of these frequencies for AASs of length 2, and directly using the frequencies for AASs of lengths 3 and 4. The values were then normalized to ensure they fell within a specific range, which helped in avoiding the dominance of any individual feature in the classification process.\n\nThe feature selection process was conducted using the training dataset, specifically the Chen dataset, which contained both epitope and non-epitope sequences. This dataset was used to train the SVM model through a 5-fold cross-validation approach, ensuring that the model's performance was robust and generalizable. The radial basis function (RBF) kernel was selected as the default kernel function due to its superior cross-validation accuracy with the training data.",
  "optimization/fitting": "The fitting method employed in this study utilized a Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel. The number of parameters in the SVM model was not excessively large compared to the number of training points. This was ensured by the nature of the SVM algorithm, which aims to find the optimal hyperplane that maximizes the margin between classes, thereby controlling the complexity of the model.\n\nTo rule out over-fitting, a 5-fold cross-validation technique was used. The training dataset was divided into five subsets, with four subsets used for training and one subset used for testing. This process was repeated five times, ensuring that each subset was used as the testing set once. The RBF kernel was selected because it provided the best cross-validation accuracy, indicating that the model generalized well to unseen data.\n\nUnder-fitting was addressed by ensuring that the model had sufficient complexity to capture the underlying patterns in the data. The use of the RBF kernel, which is capable of modeling non-linear relationships, helped in capturing the intricate details of the epitope and non-epitope patterns. Additionally, the statistical analysis of amino acid segments (AASs) with lengths from 2 to 4 residues provided a rich feature set, enabling the SVM to learn effectively from the training data.",
  "optimization/regularization": "In our study, we employed a Support Vector Machine (SVM) with a radial basis function (RBF) kernel to classify epitopes and non-epitopes. To prevent overfitting, we utilized a 5-fold cross-validation technique. This method involved dividing the training dataset into five subsets, using four of them for training and the remaining one for testing. This process was repeated five times, with each subset serving as the testing set once. This approach ensured that the model was trained and validated on different portions of the data, reducing the risk of overfitting. Additionally, the RBF kernel was selected because it provided the best cross-validation accuracy, further enhancing the model's generalization capability.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in the study are not explicitly detailed in the provided information. However, the study does mention the use of the LIBSVM toolbox for executing the classification, and it specifies that the radial basis function (RBF) kernel was selected as the default kernel function due to its best cross-validation accuracy with the training data. The study also describes the use of a 5-fold cross-validation process, where the training dataset was equally divided into 5 different subsets, with four subsets used for training and one for testing, repeated five times.\n\nRegarding the availability of model files and optimization parameters, the study does not provide specific details on where these can be accessed or under what license. The LEPS system is mentioned as being freely available for academic use at a specified URL, but there is no explicit mention of the availability of the model files or optimization parameters themselves.\n\nNot sure if the optimization schedule is available.",
  "model/interpretability": "The model employed in this study is not a blackbox. It utilizes a Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel, which is a well-understood and interpretable machine learning technique. The SVM model is trained on features derived from amino acid segments (AASs) of lengths 2 to 4 residues. These features, known as epitope indexes (Epidex), are calculated based on the occurrence frequencies of AASs in epitope and non-epitope datasets. For example, Epidex2 is determined by the logarithm of the ratio of the frequency of an AAS2 in epitopes to its frequency in non-epitopes. This process ensures that the model's decisions are grounded in statistically significant patterns observed in the data.\n\nThe transparency of the model is further enhanced by the use of a 5-fold cross-validation technique. This method involves dividing the training dataset into five subsets, using four for training and one for testing, and repeating this process five times with each subset used as the testing set once. This approach helps in assessing the model's performance and generalizability, providing insights into how well the model is likely to perform on unseen data.\n\nAdditionally, the model's performance is evaluated using several metrics, including sensitivity, specificity, positive predictive value, accuracy, and Matthews' correlation coefficient. These metrics offer a comprehensive view of the model's effectiveness in predicting epitopes, making it easier to interpret the results and understand the model's strengths and weaknesses.\n\nIn summary, the model's use of interpretable features, cross-validation, and performance metrics ensures that it is not a blackbox. Instead, it provides clear insights into how predictions are made, allowing for a better understanding of the underlying biological processes.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict whether a given peptide is an epitope or not. The model uses a Support Vector Machine (SVM) to classify peptides based on their feature values, which are derived from the frequencies of amino acid segments (AASs) of lengths 2 to 4 residues. The target value for each peptide is binary, indicating whether the peptide is an epitope (1) or not (\u22121). The model's performance is evaluated using metrics such as sensitivity, specificity, positive predictive value, accuracy, and Matthews' correlation coefficient, which are all relevant to classification tasks. The final output of the model is a set of predicted epitope candidates, which are highlighted in the query sequence and visualized in a predicted structure.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The software developed in this study, named LEPS (Linear Epitope Prediction by Propensity and Support Vector Machine), is freely available for academic use. It can be accessed at the URL http://leps.cs.ntou.edu.tw. The system utilizes the LIBSVM tool, which is an open-source library for Support Vector Machines (SVMs). LEPS integrates this tool to recognize features of amino acid segments (AASs) with lengths from 2 to 4 residues, characterizing these patterns as epitope and non-epitope clusters. The source code and specific details about the license under which it is released are not provided. However, the system is designed to be user-friendly, allowing biologists to predict linear epitope candidates easily. Users can input their query sequences in FASTA format or as plain text, and the system will output the predicted linear epitopes along with visualizations of these epitopes on simulated 3D protein structures. The platform also provides options to dynamically modify several physicochemical propensities and adjust the scanning window size for each parameter, offering flexibility in the prediction process.",
  "evaluation/method": "The method was evaluated using a combination of cross-validation and multiple datasets. A 5-fold cross-validation was employed to assess the performance of the Support Vector Machine (SVM) model. This involved dividing the training dataset into five subsets, using four for training and one for testing, and repeating this process five times with each subset used as the testing set once.\n\nThe performance of the Linear Epitope Prediction System (LEPS) was further validated using four different datasets: the PC dataset, the AntiJen dataset, the HIV dataset, and the AHP dataset. The PC dataset, generated in this study, contained 12 sequences with 98 non-overlapping, verified epitopes. The AntiJen dataset included 171 protein sequences with 691 verified epitopes, while the HIV dataset focused on 10 HIV proteins with 54 verified epitopes. The AHP dataset was a comprehensive merge of the PC, AntiJen, and HIV datasets to balance variations in epitope length and antigen diversity.\n\nThe evaluation metrics used were sensitivity (SEN), specificity (SPE), positive predictive value (PPV), accuracy (ACC), and Matthews' correlation coefficient (MCC). These metrics provided a comprehensive assessment of the system's performance in correctly identifying epitopes and non-epitopes. The results showed that LEPS outperformed other predictors in terms of specificity and positive predictive value, indicating its effectiveness in reducing false positives and improving the efficiency of identifying real epitopes.",
  "evaluation/measure": "In our evaluation, we employed five key performance metrics to assess the effectiveness of our system. These metrics are sensitivity, specificity, positive predictive value, accuracy, and Matthews' correlation coefficient.\n\nSensitivity, also known as recall, measures the proportion of actual epitopes that were correctly identified by our system. It is a crucial metric for understanding how well our system can detect true positives.\n\nSpecificity, on the other hand, evaluates the proportion of non-epitopes that were correctly identified. This metric is important for assessing the system's ability to avoid false positives.\n\nThe positive predictive value indicates the probability that a predicted epitope is indeed an epitope. This metric is particularly important in the context of vaccine development, as it helps in reducing the number of false positives, thereby improving the efficiency and effectiveness of identifying real epitopes.\n\nAccuracy provides an overall measure of the system's performance by calculating the proportion of correctly predicted peptides, both epitopes and non-epitopes.\n\nMatthews' correlation coefficient is a balanced measure that incorporates both sensitivity and specificity into a single value, ranging from -1 to +1. It provides a comprehensive evaluation of the system's predictive performance.\n\nThese metrics are widely used in the literature for evaluating the performance of epitope prediction systems, making our evaluation representative and comparable to other studies in the field.",
  "evaluation/comparison": "In the evaluation of our Linear Epitope Prediction by Propensities and Support Vector Machine (LEPS) system, a comprehensive comparison was conducted with several publicly available methods on benchmark datasets. The datasets used for this comparison included the PC dataset, which was specifically generated for this study, as well as the AntiJen dataset, the HIV dataset, and the AHP dataset, which is a merged dataset combining the other three.\n\nThe performance of LEPS was compared against four other linear epitope predictors: BepiPred, ABCPred, BCPred, and FBCPred. These predictors were chosen because they are widely recognized and used in the field of immunoinformatics. The comparison was based on several key performance metrics, including sensitivity (SEN), specificity (SPE), accuracy (ACC), positive predictive value (PPV), and Matthews' correlation coefficient (MCC). These metrics provide a thorough evaluation of the predictors' ability to correctly identify epitopes and non-epitopes.\n\nThe results of this comparison, as illustrated in Figure 2 and Table 2, showed that LEPS consistently outperformed the other predictors across multiple datasets. For instance, LEPS demonstrated the highest specificity and positive predictive value in all datasets, which are crucial for reducing false positives and improving the efficiency of epitope identification. Additionally, LEPS showed the best accuracy in three out of the four datasets, further highlighting its superior performance.\n\nIn terms of simpler baselines, the comparison was inherently included in the evaluation of the other predictors, which represent more straightforward or traditional approaches to linear epitope prediction. By outperforming these methods, LEPS not only validated its effectiveness but also demonstrated the advantages of integrating machine learning technologies with physico-chemical propensities.\n\nOverall, the comparison to publicly available methods and simpler baselines on benchmark datasets provided strong evidence of LEPS's robustness and reliability in linear epitope prediction.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not enough information is available."
}