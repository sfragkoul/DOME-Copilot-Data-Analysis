{
  "publication/title": "Random forest machine learning method outperforms prehospital National Early Warning Score for predicting one-day mortality: A retrospective study.",
  "publication/authors": "Pirneskoski J, Tamminen J, Kallonen A, Nurmi J, Kuisma M, Olkkola KT, Hoppu S",
  "publication/journal": "Resuscitation plus",
  "publication/year": "2020",
  "publication/pmid": "34223321",
  "publication/pmcid": "PMC8244434",
  "publication/doi": "10.1016/j.resplu.2020.100046",
  "publication/tags": "- Emergency medical services\n- Prehospital\n- Cardiac arrest prevention\n- Early warning score\n- National Early Warning Score\n- NEWS\n- Random forest\n- Machine learning\n- Mortality prediction\n- Clinical decision making",
  "dataset/provenance": "The dataset used in this study was sourced from electronic ambulance mission reports within the Helsinki and Uusimaa Hospital District, Finland. The data collection period spanned from August 17th, 2008, to December 18th, 2015. The dataset includes all mission reports during this time frame, excluding cases that lacked the vital signs required to calculate NEWS values and blood glucose measurements. This exclusion was done to maximize data quality for statistical analysis and to avoid imputations in machine learning model training, although it may have introduced selection bias.\n\nThe final study cohort consisted of 26,458 prehospital EMS patients. Of these, 278 patients (1.0%) died within one day. The dataset was recorded in an electronic patient record system called Merlot Medi, developed by CGI Suomi Oy in Helsinki, Finland. Physiological variables such as oxygen saturation, heart rate, and blood pressure were automatically recorded from monitors, while respiratory rate, body temperature, level of consciousness, and oxygen use required manual input. The initial values for each physiological variable were used for the analysis, except for heart rate and oxygen saturation, for which the mean of the first five minutes was used.\n\nThis dataset has not been used in previous publications by the community.",
  "dataset/splits": "In our study, we employed ten-fold stratified cross-validation for model evaluation. This approach involves dividing the dataset into ten distinct subsets, or folds. Each fold is used once as a testing set while the remaining nine folds form the training set. This process is repeated ten times, with each fold serving as the testing set exactly once. Consequently, every data point is used for both training and testing, ensuring a comprehensive evaluation of the model's performance.\n\nThe distribution of data points in each fold is designed to be as uniform as possible, maintaining the overall distribution of the target variable (one-day mortality) within each fold. This stratification helps in ensuring that each fold is representative of the entire dataset, which is crucial for reliable model evaluation.\n\nThe overall performance of the model is then determined by averaging the performance metrics obtained from each of the ten testing folds. This method provides a robust estimate of the model's predictive accuracy and generalizability.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the random forest algorithm. This is a well-established and widely used ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe random forest algorithm is not new; it has been extensively studied and applied in various fields, including healthcare. The reason it was not published in a machine-learning journal is that our focus was on demonstrating its superior performance in a specific medical context\u2014predicting one-day mortality in prehospital settings\u2014rather than on the development of the algorithm itself. Our study aimed to compare the predictive performance of the random forest algorithm with the traditional National Early Warning Score (NEWS) using prehospital vital signs. The results showed that the random forest algorithm outperformed NEWS, highlighting its potential for improving clinical decision-making in emergency medical services.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data used for the machine-learning algorithm was collected from electronic ambulance mission reports. The physiological variables, such as oxygen saturation, heart rate, and blood pressure, were automatically recorded from monitors. Other variables like respiratory rate, body temperature, level of consciousness, and oxygen use required manual input. The initial values for each physiological variable were utilized for the analysis, except for heart rate and oxygen saturation, where the mean of the first five minutes was used. This approach ensured that the data was consistent and relevant for predicting one-day mortality. The data was then used to train random forest models, which are known for their ability to handle noisy input data and learn complex relationships between variables. The models were evaluated using ten-fold stratified cross-validation to ensure robust performance metrics.",
  "optimization/parameters": "In our study, the random forest models utilized several input parameters, specifically the National Early Warning Score (NEWS) variables. These variables include respiration rate, blood oxygen saturation, use of supplemental oxygen, body temperature, systolic blood pressure, heart rate, and level of consciousness on the AVPU scale. Additionally, blood glucose was included as an input parameter in one of the random forest models to assess its impact on predictive performance. The selection of these parameters was based on their known prognostic value in prehospital settings and their availability in the electronic patient record system. The inclusion of blood glucose was motivated by previous suggestions that it could enhance the predictive performance of the NEWS system. The models were trained using these parameters, and their performance was evaluated through ten-fold stratified cross-validation, ensuring a robust assessment of their predictive accuracy.",
  "optimization/features": "The study utilized a set of physiological variables recorded in prehospital electronic patient record systems as input features for the random forest models. These variables included oxygen saturation, heart rate, blood pressure, respiratory rate, body temperature, level of consciousness, and the use of supplemental oxygen. Additionally, blood glucose was considered as a separate input feature in one of the models. The specific number of features used as input is not explicitly stated, but it can be inferred that the primary model used the variables required to calculate the National Early Warning Score (NEWS), which typically includes respiratory rate, oxygen saturation, temperature, systolic blood pressure, pulse rate, level of consciousness, and new confusion. The enhanced model included these NEWS variables plus blood glucose.\n\nFeature selection was not explicitly mentioned as a separate process. Instead, the variables were chosen based on their known prognostic value and availability in the prehospital setting. The training of the random forest models involved a ten-fold stratified cross-validation process, ensuring that the selection of features and the training of the models were performed using the training set only. This approach helps to maximize the information gain for the entire forest and ensures that the models are robust and resistant to overfitting.",
  "optimization/fitting": "The fitting method employed in this study utilized random forest models, which are inherently resistant to overfitting. This resistance is due to the ensemble nature of random forests, where multiple decision trees are combined to make predictions. Each tree is trained on a different subset of the data, and the final prediction is an average of the individual tree predictions, reducing the risk of overfitting to any single subset.\n\nThe random forest models were trained using a ten-fold stratified cross-validation approach. This method ensures that the model is evaluated on multiple independent data subsets, providing a robust estimate of its performance. By using cross-validation, the risk of overfitting is further mitigated, as the model is not trained and tested on the same data.\n\nAdditionally, the random forest models were evaluated using the area under the receiver operating characteristic curve (AUROC) as the performance metric. The AUROC values were computed for each of the ten folds, and the overall performance was determined by combining the bootstrap samples from these folds. This approach helps in estimating the confidence intervals for the predictors and ensures that the model's performance is not overly optimistic.\n\nTo address the potential issue of underfitting, the random forest models were trained with a uniform sampling of input feature thresholds at each split node. This process maximizes information gain for the entire forest, ensuring that the models capture the underlying patterns in the data effectively. The inclusion of blood glucose as an additional variable further enhanced the model's predictive performance, indicating that the models were not underfitting the data.\n\nIn summary, the random forest models used in this study were designed to minimize both overfitting and underfitting. The use of cross-validation, bootstrap resampling, and the inclusion of additional relevant variables ensured that the models were robust and generalizable to the prehospital setting.",
  "optimization/regularization": "Random forest models were employed in this study, which are inherently resistant to overfitting. This resistance is due to the ensemble nature of random forests, where multiple decision trees are generated and combined to make predictions. Each tree is trained on a different subset of the data, and the final prediction is an average of the individual trees' predictions. This method helps to reduce the risk of overfitting by ensuring that the model does not become too complex and overly tailored to the training data.\n\nAdditionally, the training feature space was randomly populated with a uniform sampling of input feature thresholds at each split node. This technique maximizes information gain for the entire forest, further contributing to the model's robustness and generalizability. By using this approach, the model is less likely to fit noise in the training data, thereby improving its performance on unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The random forest model used in this study is considered a black-box model. This means that while it can provide accurate predictions, the internal workings and decision-making processes are not easily interpretable. The random forest approach involves generating hundreds of decision trees, each making decisions based on different subsets of the data. This complexity makes it challenging to trace back and understand the specific reasons behind a particular prediction.\n\nThe decisions made by the individual trees within the forest are not straightforward to visualize or interpret clinically. Although the decision trees can be visualized, the sheer number of trees and the randomness introduced at each split node make it extremely difficult to derive clear, clinically meaningful insights from the model. This lack of interpretability is a known limitation of random forest models, as they prioritize predictive accuracy over transparency.",
  "model/output": "The model in question is a classification model. It is designed to predict one-day mortality in adult prehospital patients. The output of the model is a probability, which can be interpreted as the likelihood of a patient dying within one day of an ambulance mission. This probability is generated using a random forest algorithm, which is a collection of decision trees. The model was trained and validated using a ten-fold cross-validation method, and its performance was evaluated using the area under the receiver operating characteristic curve (AUROC). The AUROC values indicate that the model outperforms the traditional National Early Warning Score (NEWS) in predicting one-day mortality. Specifically, the AUROC for the random forest model trained with NEWS variables only was 0.858, and it was 0.868 when blood glucose was included as an additional variable. These values are higher than the AUROC of 0.836 for NEWS, demonstrating the superior predictive performance of the random forest model.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a ten-fold stratified cross-validation process. This process was repeated ten times, with each iteration involving a different subset of data for training and testing. The random forest algorithm was applied to each fold, using independent data subsets for training and testing. The performance was assessed using the area under the receiver operating characteristic curve (AUROC) as the primary metric.\n\nTo ensure the robustness of the results, bootstrap resampling with 10,000 sample points was employed to estimate confidence intervals for the predictors. This approach was necessary because the normality of cross-validated AUROC scores was not guaranteed. The overall model performance was derived from the combination of bootstrap samples across all ten testing folds, providing a comprehensive distribution of AUROC values.\n\n95% confidence intervals were calculated for the continuous variables, and all AUROC results were presented with these intervals. Additionally, the bootstrapping method was used to numerically estimate p-values for the null hypothesis of equal AUROCs, ensuring a rigorous statistical evaluation of the model's performance.",
  "evaluation/measure": "The primary performance metric reported in this study is the area under the receiver operating characteristic curve (AUROC). This metric was chosen to evaluate the predictive performance of the models for one-day mortality. The AUROC values were calculated for three different models: the traditional National Early Warning Score (NEWS), a random forest model trained with NEWS variables only, and a random forest model trained with NEWS variables and blood glucose. The AUROC provides a single scalar value that represents the ability of the model to discriminate between patients who will die within one day and those who will not.\n\nIn addition to the AUROC, 95% confidence intervals (CI) were calculated for the continuous variables to provide a range of values within which the true AUROC is likely to fall. This helps to understand the precision of the AUROC estimates. The bootstrapping method was used to estimate these confidence intervals, as the normality of cross-validated AUROC scores is not guaranteed.\n\nThe study also reports p-values to indicate the statistical significance of the differences in AUROC between the models. These p-values were estimated numerically using the bootstrapping method, with the null hypothesis being that the AUROCs are equal. This allows for a comparison of the predictive performance of the different models.\n\nThe use of AUROC as the primary performance metric is representative of the literature, as it is a commonly used metric for evaluating the performance of binary classification models, especially in medical research. The inclusion of confidence intervals and p-values further strengthens the reporting of the performance metrics, providing a comprehensive evaluation of the models' predictive performance.",
  "evaluation/comparison": "In our study, we compared the performance of the random forest machine learning method to the traditional National Early Warning Score (NEWS) for predicting one-day mortality in prehospital settings. This comparison was not performed on publicly available benchmark datasets but rather on a large, retrospective dataset of electronic ambulance mission reports collected from a single EMS system over several years.\n\nThe random forest models were trained and validated using a ten-fold cross-validation method, which involved splitting the data into ten subsets, training the model on nine subsets, and testing it on the remaining subset. This process was repeated ten times, with each subset serving as the test set once. The performance of the models was evaluated using the area under the receiver operating characteristic curve (AUROC), a commonly used metric for assessing the predictive accuracy of binary classifiers.\n\nIn addition to comparing the random forest models to NEWS, we also performed a secondary analysis that included a larger cohort of patients with complete NEWS data but potentially missing blood glucose measurements. This analysis allowed us to assess the performance of the random forest models in a more generalizable setting, as it included a broader range of patients.\n\nThe random forest models were compared to NEWS, which served as a simpler baseline. The results demonstrated that the random forest models, both with and without blood glucose, outperformed NEWS in predicting one-day mortality. The inclusion of blood glucose in the model further improved its predictive performance, highlighting the potential benefits of incorporating additional physiological variables into prehospital risk stratification tools.",
  "evaluation/confidence": "The evaluation of the model's performance was conducted using ten-fold stratified cross-validation, which involved training and testing the model ten times with different data subsets. This process allowed for the estimation of predictive performance using the area under the receiver operating characteristic curve (AUROC) metric. To ensure the reliability of these estimates, bootstrap resampling with 10,000 sample points was employed to computationally estimate confidence intervals for the different predictors. This step was necessary because the normality of cross-validated AUROC scores was not guaranteed.\n\nThe overall performance of the model was determined by combining the bootstrap samples from the ten testing folds, resulting in AUROC distributions. For continuous variables, 95% confidence intervals (CI) were calculated, and all AUROC results are presented with these 95% CI in parentheses. This approach provided a robust measure of the model's performance and its variability.\n\nIn addition to calculating confidence intervals, the bootstrapping method was used to estimate p-values numerically, testing the null hypothesis for equal AUROCs. The results indicated that the AUROC of the random forest models were significantly higher than that of the National Early Warning Score (NEWS). Specifically, the p-value for the comparison between NEWS and the random forest model trained with NEWS variables only was 0.005, and the p-value for the comparison between NEWS and the random forest model trained with NEWS variables and blood glucose was less than 0.001. Furthermore, the AUROCs of the two random forest models also differed significantly, with a p-value of 0.032.\n\nThese statistical analyses confirmed that the random forest models outperformed the traditional NEWS in predicting one-day mortality, and the inclusion of blood glucose in the model further improved its predictive performance. The use of confidence intervals and p-values provided a strong basis for claiming the superiority of the random forest method over the baseline NEWS.",
  "evaluation/availability": "Not enough information is available."
}