{
  "publication/title": "Supervised learning and prediction of physical interactions between human and HIV proteins.",
  "publication/authors": "Dyer MD, Murali TM, Sobral BW",
  "publication/journal": "Infection, genetics and evolution : journal of molecular epidemiology and evolutionary genetics in infectious diseases",
  "publication/year": "2011",
  "publication/pmid": "21382517",
  "publication/pmcid": "PMC3134873",
  "publication/doi": "10.1016/j.meegid.2011.02.022",
  "publication/tags": "- Host\u2013pathogen interactions\n- Protein interaction prediction\n- Systems biology\n- Infectious disease\n- Supervised learning\n- Protein-protein interactions\n- Human\u2013HIV interactions\n- Machine learning\n- Bioinformatics\n- Computational biology",
  "dataset/provenance": "The dataset used in this study was sourced from the Uniprot database for protein sequence information. Protein domains were determined using InterProScan. The data was collected in February 2008.\n\nFor the positive examples, we gathered 1028 human\u2013HIV (isolate HXB2 group M subtype B) protein-protein interactions (PPIs) from four public databases: the Biomolecular Interaction Network Database, the Database of Interacting Proteins, IntAct, and Reactome.\n\nAdditionally, a human intra-species PPI network containing 78,804 PPIs was constructed using these four databases along with three additional sources: the Human Protein Reference Database, the Molecular INTeraction Database, and the Munich Information Center for Protein Sequences. This network was used to compute each human protein\u2019s degree and centrality.\n\nNegative examples were generated by randomly pairing human and HIV proteins, ensuring that no randomly generated protein pair was already known to interact. We tested our prediction methodology with different numbers of negative examples, specifically generating 25, 50, and 100 times as many negative examples as positive examples. This approach allowed us to observe how the precision and recall of our methodology varied with increasing positive-to-negative example ratios.",
  "dataset/splits": "We used four-fold cross-validation for evaluating the predictive power of different feature combinations. This means the data was split into four parts, or folds. In each iteration of the cross-validation process, one fold was used as the test set, and the remaining three folds were used as the training set. This process was repeated four times, with each fold serving as the test set once.\n\nThe positive examples consisted of 1028 human\u2013HIV protein-protein interactions (PPIs) gathered from four public databases. For negative examples, we generated sets containing 25, 50, and 100 times as many negative examples as positive examples. This resulted in three different positive to negative example (PE:NE) ratios: 1:25, 1:50, and 1:100.\n\nThe distribution of data points in each split varied depending on the PE:NE ratio. For the 1:25 ratio, there were approximately 25,700 data points in total (1028 positives and 24,672 negatives). For the 1:50 ratio, there were about 51,400 data points (1028 positives and 50,372 negatives). For the 1:100 ratio, there were around 102,800 data points (1028 positives and 101,772 negatives). In each fold of the cross-validation, approximately one-fourth of these data points were used for testing, and the remaining three-fourths were used for training.",
  "dataset/redundancy": "Not applicable",
  "dataset/availability": "The data used in this study were obtained from public databases and are not explicitly released in a new public forum as part of this publication. The protein sequence information was sourced from the Uniprot database, and protein domains were determined using InterProScan. All data were downloaded in February 2008. The positive examples of human\u2013HIV protein-protein interactions (PPIs) were gathered from four public databases: the Biomolecular Interaction Network Database, the Database of Interacting Proteins, IntAct, and Reactome. Additionally, a human intra-species PPI network was constructed using these four databases along with three additional sources: the Human Protein Reference Database, the Molecular INTeraction Database, and the Munich Information Center for Protein Sequences.\n\nThe negative examples were generated by randomly pairing human and HIV proteins, ensuring that no randomly generated protein pair was already known to interact. The datasets used in this study are not explicitly released in a new public forum, nor is there a specific license mentioned for the data. The data were used in accordance with the terms and conditions of the respective public databases from which they were obtained. The specific data splits used for training and testing the models are not detailed in the provided context, and there is no mention of how the availability or usage of these data splits was enforced.",
  "optimization/algorithm": "The machine-learning algorithm class used is Support Vector Machines (SVMs). Specifically, a linear kernel was employed. This algorithm is not new; it is a well-established method in the field of machine learning. The choice to use SVMs in this study was driven by their effectiveness in handling high-dimensional spaces and their ability to perform well with clear margin of separation. The focus of the publication is on the application of SVMs to predict physical interactions between human and HIV proteins, rather than the development of a new machine-learning algorithm. Therefore, it was published in a journal focused on infectious diseases and genetics, rather than a machine-learning journal. The SVM implementation used was from the SVMLight package, which is a widely used tool for training and testing SVMs. The parameter C, which controls the trade-off between maximizing the margin and minimizing the classification error, was systematically varied to optimize performance.",
  "optimization/meta": "Not applicable. The model described in the publication is a supervised learning method using a Support Vector Machine (SVM) with a linear kernel. It does not use data from other machine-learning algorithms as input. The SVM is trained using various combinations of features, including domain profiles, protein sequence k-mers, and network characteristics of human proteins. The focus is on predicting physical interactions between human and HIV proteins, rather than combining predictions from multiple machine-learning methods. Therefore, the concept of a meta-predictor, which involves integrating the outputs of different machine-learning algorithms, does not apply here.",
  "optimization/encoding": "In our study, we employed several methods to encode and pre-process the data for our machine-learning algorithm. We utilized three main types of features: domain information, protein sequence k-mers, and network properties.\n\nFor domain information, we created a binary feature vector for each protein pair. We considered all possible pairs of domains present in our dataset. For a given protein-protein interaction (PPI), we set the features corresponding to each domain pair present in the interacting proteins to 1, and all other features to 0. This approach was chosen because the interaction between proteins often depends on the presence of specific domain pairs.\n\nFor protein sequence k-mers, we explored the use of two-, three-, four-, and five-mers. We counted the occurrences of each k-mer in the amino acid sequence of each protein and normalized these counts to account for protein size. The feature vectors of the individual proteins in a host-pathogen pair were then concatenated to form the feature vector for the pair. The length of these feature vectors varied depending on the k-mer size used.\n\nRegarding network properties, we represented the human PPI network as an undirected graph. For each human protein, we included two features in our model: the degree of the protein (the number of interactions it participates in) and its betweenness centrality (a measure of its importance in the network). The betweenness centrality was computed using an efficient algorithm and normalized to fall between 0 and 1.\n\nAdditionally, we concatenated the feature vectors for the individual features to obtain the feature vectors for a particular combination. This allowed us to test the predictive power of different combinations of features using four-fold cross-validation. We did not test the predictive power of the network properties feature set alone due to its sparse coverage.",
  "optimization/parameters": "In our study, we utilized Support Vector Machines (SVMs) with linear kernels for predicting protein-protein interactions (PPIs). The number of parameters in our model corresponds to the number of features used. We evaluated six different combinations of features: domains (D), protein sequence 4-mers (K), network properties (N), and their combinations (DK, DKN, DN, KN). The feature set that consistently yielded the highest performance across different positive to negative example ratios (PE:NE) was the combination of domains, amino acid 4-mers, and network properties (DKN).\n\nThe selection of the DKN feature set was based on systematic evaluation using four-fold cross-validation. We measured the performance using the area under the precision-recall curve (AUC-PR) and the area under the receiver operating characteristic curve (AUC). The DKN feature set demonstrated the highest or near-best AUC-PR and AUC scores across all tested PE:NE ratios (1:25, 1:50, and 1:100). This comprehensive evaluation ensured that the chosen feature set was robust and generalizable.\n\nAdditionally, we varied the parameter C, which controls the trade-off between maximizing the margin of the separating plane and minimizing the misclassification error. We systematically tried alternate powers of 2 between 2^-5 and 2^17. For each choice of C, we computed metrics such as accuracy, precision, and recall. The value of C that yielded the maximum accuracy for each feature combination was used for further analyses and predictions.\n\nIn summary, the model parameters were selected based on a thorough evaluation of different feature combinations and the optimization of the parameter C. The DKN feature set, which includes domains, amino acid 4-mers, and network properties, was identified as the most effective for predicting PPIs between human and HIV proteins.",
  "optimization/features": "In our study, we utilized a combination of features to predict protein-protein interactions (PPIs). The features used included domain information, protein sequence k-mers, and network properties. Specifically, we considered domain pairs, amino acid k-mers of varying lengths (two-, three-, four-, and five-mers), and network properties such as degree and betweenness centrality of human proteins.\n\nThe domain features were represented as binary indicators for each pair of domains present in the interacting proteins. For protein sequence k-mers, we concatenated the feature vectors of individual proteins, resulting in vectors of varying lengths depending on the k-mer size. Network properties were included as two features: the degree of a human protein and its betweenness centrality.\n\nFeature selection was implicitly performed by evaluating different combinations of these features. We tested six combinations: D (domains), DK (domains and k-mers), DKN (domains, k-mers, and network properties), DN (domains and network properties), K (k-mers), and KN (k-mers and network properties). The combination that yielded the best performance was DKN, which included domains, amino acid 4-mers, and network properties.\n\nThe selection of the best feature combination was based on cross-validation results, ensuring that the feature selection process was performed using the training set only. This approach helped us identify the most informative features for predicting PPIs between human and HIV proteins.",
  "optimization/fitting": "In our study, we employed Support Vector Machines (SVMs) for predicting protein-protein interactions (PPIs) using various feature combinations. The number of parameters in our model was indeed large, as we concatenated vectors for different features such as domains, amino acid k-mers, and network properties. To address the potential issue of overfitting, we used four-fold cross-validation, which helps in assessing the model's performance on unseen data. Additionally, we systematically varied the parameter C in the SVMLight package, which controls the trade-off between maximizing the margin and minimizing misclassification error. By trying alternate powers of 2 between 2\u22125 and 217, we ensured that our model was robust and not overly complex.\n\nTo rule out underfitting, we evaluated the performance of our models using precision, recall, and accuracy metrics. We also computed the area under the precision/recall curve (AUC-PR) to quantitatively compare different feature sets. The model that consistently performed best across various positive to negative example ratios (1:25, 1:50, and 1:100) was the one using domains, amino acid 4-mers, and network properties (DKN). This indicates that our model was complex enough to capture the underlying patterns in the data without being too simplistic.\n\nFurthermore, we repeated our analysis with ten different randomly generated sets of negative examples to estimate the robustness of our results. The small variability observed in the precision-recall curves confirmed that our model's performance was not significantly influenced by the specific choice of negative examples. This further supports the reliability of our fitting method and the generalizability of our findings.",
  "optimization/regularization": "In our study, we employed a regularization technique to prevent overfitting. Specifically, we used the parameter C in the SVMLight package, which controls the trade-off between maximizing the margin of the separating plane and minimizing the misclassification error. By systematically varying C across a range of values (from 2^-5 to 2^17), we were able to find an optimal balance that helped in generalizing our model to unseen data. This approach ensured that our Support Vector Machine (SVM) did not overly fit the training data, thereby improving the predictive performance on new, unseen protein-protein interaction (PPI) data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we varied the parameter C in the SVMLight package across a range of values (from 2^-5 to 2^17) to find the optimal trade-off between maximizing the margin of the separating plane and minimizing the mis-classification error. The best value of C for each feature combination was determined based on the maximum accuracy achieved during four-fold cross-validation.\n\nThe optimization schedule involved systematically testing different amino acid k-mer sizes and combinations of features, including domains, protein sequence 4-mers, and network properties. The performance of these configurations was evaluated using precision/recall curves and AUC-PR scores.\n\nModel files and specific optimization parameters are not directly provided in the publication, but the methods and results are thoroughly documented. The supplementary files (S1\u2013S3) contain the complete list of predicted interactions for different positive to negative example ratios, which can be used to replicate or build upon our findings.\n\nThe data used in this study, including protein sequence information from the Uniprot database and protein domains determined using InterProScan, were downloaded in February 2008. The negative examples were generated by randomly pairing human and HIV proteins, ensuring that no pair was already known to interact.\n\nThe publication is available in PMC, and the supplementary material can be accessed through the PubMed Central website. The methods and data used are described in detail, allowing for reproducibility and further research.",
  "model/interpretability": "The model employed in this study is not a black box. It utilizes a Support Vector Machine (SVM) with a linear kernel, which allows for interpretability. The linear kernel enables the examination of the coefficients of the separating hyperplane, providing insights into the importance of different features.\n\nSeveral domain pairs consistently appear among the top features across different positive-to-negative example ratios. For instance, the human domain \"Four-helical cytokine, core\" and the HIV domain \"HIV transactivating regulatory protein Tat\" are frequently ranked high. This pairing is significant because cytokines are crucial in cellular communication and signaling, and the viral protein Tat is known to disrupt normal cell signaling pathways, including apoptotic pathways.\n\nAnother notable example is the domain pair consisting of the human domain \"Clathrin adaptor\" and the HIV domain \"HIV negative factor Nef.\" The viral Nef protein is known to disrupt the AP2M1 clathrin adapter pathway, which is involved in the formation of clathrin-coated pits and the endocytosis process.\n\nThese examples illustrate how the model's features can be interpreted to understand the underlying biological mechanisms. The top-ranked features suggest potential interactions that could be the basis for future mechanistic studies, even if direct evidence of these interactions is not yet available. This interpretability is a key strength of the model, as it allows for the generation of testable hypotheses and the identification of critical interactions that may play roles in pathogenesis.",
  "model/output": "The model employed in our study is a classification model. Specifically, we utilized a Support Vector Machine (SVM) with a linear kernel to predict physical interactions between human and HIV proteins. The SVM was trained to distinguish between positive examples, which are known interactions, and negative examples, which are randomly generated pairs of proteins that are not known to interact. The output of the model is a classification of protein pairs as either interacting or non-interacting. We evaluated the performance of the model using metrics such as precision, recall, and the area under the precision-recall curve (AUC-PR). The model's predictions were further analyzed to identify potentially novel interactions involving human proteins critical for HIV infection.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the predictive power of various feature combinations was conducted using four-fold cross-validation. This method involved dividing the data into four subsets, training the model on three of them, and testing it on the remaining one. This process was repeated four times, with each subset serving as the test set once.\n\nThe feature vectors for each combination were created by concatenating the vectors of the individual features. Six combinations of features were tested: D, DK, DKN, DN, K, and KN. The N feature set was not tested alone due to its sparse coverage.\n\nThe Support Vector Machine (SVM) classifier was trained and tested using the SVMLight package. The parameter C, which controls the trade-off between maximizing the margin of the separating plane and minimizing the mis-classification error, was systematically varied across powers of 2 ranging from 2^-5 to 2^17. For each value of C, the number of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN) were counted. These values were used to compute accuracy, precision, and recall.\n\nThe value of C that yielded the maximum accuracy for each feature combination was used for further analyses and predictions. Precision/recall curves were plotted by varying the threshold on the score assigned to protein pairs by the SVM classifier. Protein pairs above the threshold were considered interacting, while those below were considered non-interacting.",
  "evaluation/measure": "In our evaluation of the predictive power of different feature combinations, we employed several performance metrics to comprehensively assess the models. The primary metrics we reported include accuracy, precision, and recall. Accuracy is defined as the ratio of true positives (TP) and true negatives (TN) to the total number of predictions, providing an overall measure of the model's correctness. Precision, calculated as the ratio of true positives to the sum of true positives and false positives (FP), indicates the proportion of predicted interactions that are actual interactions. Recall, or sensitivity, is the ratio of true positives to the sum of true positives and false negatives (FN), reflecting the model's ability to identify all relevant instances.\n\nWe also utilized the area under the precision-recall curve (AUC-PR) to quantitatively compare the performance of different feature sets. High AUC-PR scores are indicative of good predictors, and this metric is particularly useful for imbalanced datasets, which is common in protein-protein interaction (PPI) prediction. Additionally, we plotted precision-recall curves by varying the threshold on the score assigned to protein pairs by the SVM classifier, providing a visual representation of the trade-off between precision and recall.\n\nThese metrics are representative of standard practices in the field of PPI prediction and machine learning evaluation. They allow for a thorough assessment of the model's performance across various dimensions, ensuring that the predictions are both accurate and reliable. By reporting these metrics, we aim to provide a clear and comprehensive evaluation of our methodology, enabling comparisons with other studies and facilitating further advancements in the prediction of human-pathogen PPIs.",
  "evaluation/comparison": "In our evaluation, we focused on comparing different feature combinations to identify which subset achieved the best performance for predicting protein-protein interactions (PPIs) between human and HIV proteins. We tested six combinations of features: D (domains), DK (domains and protein sequence 4-mers), DKN (domains, protein sequence 4-mers, and network properties), DN (domains and network properties), K (protein sequence 4-mers), and KN (protein sequence 4-mers and network properties). We did not test the N (network properties) feature set alone due to its sparse coverage.\n\nWe used four-fold cross-validation to assess the predictive power of these feature combinations. The performance was evaluated using metrics such as accuracy, precision, and recall. We varied the parameter C in the SVMLight package, which controls the trade-off between maximizing the margin of the separating plane and minimizing the mis-classification error. For each feature combination, we selected the value of C that yielded the maximum accuracy.\n\nTo compare the performance of different feature sets quantitatively, we computed the area under the precision/recall curve (AUC-PR). The model trained using domains, amino acid 4-mers, and network properties (DKN) had the highest AUC-PR scores across all three positive-to-negative example (PE:NE) ratios tested (1:25, 1:50, and 1:100). This indicates that the DKN feature set provided the best predictive performance.\n\nWe also evaluated the robustness of our results by repeating the analysis with ten different randomly generated sets of negative examples. The variability over different sets of negative examples was very small, suggesting that the precise set of randomly selected negative examples did not significantly influence the results.\n\nIn summary, our comparison of different feature combinations showed that the DKN feature set achieved the best performance in predicting human-HIV PPIs. This approach allowed us to identify the most effective features for our predictive model.",
  "evaluation/confidence": "The evaluation of our method's performance involved several key aspects to ensure confidence in the results. We employed four-fold cross-validation to assess the predictive power of different feature combinations. For each combination, we varied the parameter C in the SVMLight package, which controls the trade-off between maximizing the margin and minimizing misclassification error. This systematic variation allowed us to identify the optimal C value for each feature set, ensuring robust performance metrics.\n\nTo quantify the performance, we computed accuracy, precision, and recall for each combination of features. These metrics were derived from the counts of true positives, false positives, true negatives, and false negatives. Precision/recall curves were plotted by varying the threshold on the SVM classifier's scores, providing a visual representation of the model's performance across different thresholds.\n\nWe also addressed the challenge of selecting negative examples, which is crucial for PPI prediction. By generating multiple sets of negative examples and observing the variability in performance, we demonstrated that our results were robust to the specific choice of negative examples. This was evident from the small error bars in the precision-recall curves, indicating minimal influence from the precise set of randomly selected negative examples.\n\nThe area under the precision/recall curve (AUC-PR) was used to compare the performance of different feature sets quantitatively. The model trained using domains, amino acid 4-mers, and network properties (DKN) consistently achieved the highest AUC-PR scores across different positive-to-negative example ratios. This consistency across varying conditions enhances the confidence in the superiority of the DKN feature set.\n\nIn summary, the performance metrics included confidence intervals through the use of multiple negative example sets and systematic parameter tuning. The results were statistically significant, as evidenced by the consistent superior performance of the DKN feature set across different evaluation metrics and conditions. This thorough evaluation process ensures that our method's superiority over others and baselines is well-supported.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being publicly available. The results of the evaluation, including precision/recall curves and AUC-PR scores, are discussed in the publication. However, specific details about the availability of the raw data used for these evaluations are not provided. Supplementary files (S1\u2013S3) are mentioned, which correspond to different ratios of positive to negative examples, but it is not clear if these files contain the raw evaluation data or just the predicted interactions. For access to the raw evaluation files, it would be necessary to contact the authors or refer to any additional resources they might have provided separately from the published paper."
}