{
  "publication/title": "Prediction of breath-holding spells based on electrocardiographic parameters using machine-learning model.",
  "publication/authors": "Khalilian MR, Tofighi S, Attar EZ, Nikkhah A, Hajipour M, Ghazavi M, Samimi S",
  "publication/journal": "Annals of noninvasive electrocardiology : the official journal of the International Society for Holter and Noninvasive Electrocardiology, Inc",
  "publication/year": "2024",
  "publication/pmid": "37935110",
  "publication/pmcid": "PMC10770810",
  "publication/doi": "10.1111/anec.13093",
  "publication/tags": "- Breath holding\n- Electrocardiography\n- Machine learning\n- Pediatrics\n- Predictive modeling\n- ECG parameters\n- Breath-holding spells\n- Gradient boosting\n- Repolarization\n- Childhood arrhythmias",
  "dataset/provenance": "The dataset used in this study consisted of 202 subjects, which included 52 patients with a confirmed history of breath-holding spells (BHS) and 150 healthy children serving as the control group. The distribution of genders was statistically similar in each group, with 37 males (71.2%) in the BHS group and 110 males (73.3%) in the control group. Both groups were of the same age, with a mean age of 11.90 \u00b1 6.63 months for the BHS group and 11.33 \u00b1 6.17 months for the control group.\n\nThe dataset primarily focused on electrocardiogram (ECG) characteristics, including heart rate, PR interval, QRS segment, and various repolarization parameters such as QTc, QTd, TpTe, and TpTe/QT. Notably, the repolarization parameters were significantly higher in BHS patients compared to normal healthy subjects.\n\nThe dataset was divided into three categories: a training set with 106 data points, a validation set with 35 data points, and a testing set with 61 data points. The training and validation sets were used for the initial training and cross-validation of the model, while the testing set, which was not seen by the system during learning, was used to evaluate the prediction performance of the final model.\n\nThe development of the model and further evaluations were conducted using the R programming language in the RStudio software environment (version 22), utilizing the H2O machine-learning package and the grid-search method. This approach ensured a robust and systematic development process for the predictive model.",
  "dataset/splits": "The dataset used in this study consisted of a total of 202 subjects. This dataset was divided into three distinct categories: the training set, the validation set, and the testing set.\n\nThe training set comprised 106 data points. This set was used for the initial training of the model, allowing it to learn from the data and adjust its parameters accordingly.\n\nThe validation set consisted of 35 data points. This set was utilized during the learning process to perform cross-validation, helping to fine-tune the model and prevent overfitting.\n\nThe testing set included 61 data points. This set was kept separate from the training and validation sets and was not seen by the system during the learning process. It was used to evaluate the final model's prediction performance, providing an unbiased assessment of the model's accuracy and generalizability.",
  "dataset/redundancy": "The dataset used in this study consisted of 202 subjects, divided into three categories: a training set, a validation set, and a testing set. The training set comprised 106 subjects, the validation set included 35 subjects, and the testing set consisted of 61 subjects. The training and validation sets were utilized during the initial training and cross-validation phases of the model development process. The testing set, which the system had not encountered during the learning process, was employed to evaluate the final model's prediction performance.\n\nThe independence of the training and test sets was ensured by not exposing the testing data to the system during the model training phase. This approach helps in assessing the model's generalizability and performance on unseen data.\n\nRegarding the distribution of the dataset, it included 52 patients with a confirmed history of breath-holding spells (BHS) and 150 healthy children serving as the control group. The gender distribution was statistically similar in both groups, with 71.2% males in the BHS group and 73.3% males in the control group. Additionally, the mean ages of the BHS and control groups were 11.90 \u00b1 6.63 months and 11.33 \u00b1 6.17 months, respectively, indicating no significant age difference between the groups.\n\nThe dataset's distribution compares favorably with previously published machine learning datasets in the medical field, particularly those focusing on pediatric conditions. The inclusion of a diverse range of subjects and the careful splitting of the dataset into training, validation, and testing sets ensure robust model development and evaluation. This approach aligns with best practices in machine learning, aiming to create a model that can generalize well to new, unseen data.",
  "dataset/availability": "The data supporting the findings of this study are not publicly available. However, they can be obtained from the corresponding author upon reasonable request. This approach ensures that the data is shared responsibly and ethically, adhering to the guidelines set by the Research Ethics Committee of the School of Medicine \u2013 Shahid Beheshti University of Medical Sciences. The ethics board approval ID for this study is IR.SBMU.MSP.REC.1401.383. This method of data sharing allows for verification and potential replication of the study while maintaining the privacy and confidentiality of the participants.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the ensemble method, specifically the Gradient Boosting (GB) model. This model is not new; it is a popular technique for categorization issues. Gradient Boosting combines several models, referred to as \"weak learners,\" to enhance their performance and create the best possible final model. The decision tree model typically serves as the core of these weak learners.\n\nThe reason this algorithm was not published in a machine-learning journal is that our focus was on applying this well-established method to a specific medical problem\u2014predicting breath-holding spells based on electrocardiographic parameters. The innovation lies in the application of the Gradient Boosting model to this particular medical dataset, rather than in the development of a new machine-learning algorithm. Our study demonstrates the effectiveness of this model in the context of pediatric cardiology, showcasing its superior performance compared to traditional logistic regression models.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the model's effectiveness. Initially, the dataset, consisting of 202 subjects, was divided into three categories: a training set with 106 samples, a validation set with 35 samples, and a testing set with 61 samples. This division allowed for robust training, cross-validation, and evaluation of the model.\n\nThe electrocardiogram (ECG) parameters, which included heart rate, PR interval, QRS duration, QTc, QT dispersion (QTd), TpTe, and TpTe/QT ratio, were extracted from the ECG recordings of all subjects. These parameters were crucial for distinguishing between patients with breath-holding spells (BHS) and healthy controls.\n\nGiven the high-dimensional nature of the ECG data, feature selection was performed to identify the most relevant parameters. The repolarization variables, such as QTc, QTd, TpTe, and TpTe/QT ratio, were found to be significantly higher in BHS patients compared to healthy children. These variables were thus prioritized in the model.\n\nThe data was then normalized to ensure that all features contributed equally to the model's predictions. This step is essential for machine-learning algorithms, particularly gradient boosting, to prevent any single feature from dominating the model due to its scale.\n\nThe preprocessing steps were executed using the R programming language in the RStudio software environment, version 22. The H2O machine-learning package and the grid-search method were employed to fine-tune the model's hyperparameters, ensuring optimal performance.\n\nIn summary, the data encoding and preprocessing involved dividing the dataset, extracting and selecting relevant ECG parameters, normalizing the data, and using advanced tools in R to prepare the data for the gradient boosting algorithm. These steps were crucial for developing a highly efficient machine-learning model to predict breath-holding spells based on ECG parameters.",
  "optimization/parameters": "In our study, we utilized a comprehensive set of electrocardiogram (ECG) parameters as input features for our machine learning model. These parameters included age, sex, heart rate, PR interval, QRS duration, corrected QT interval (QTc), QT dispersion (QTd), T-peak to T-end interval (TpTe), and the TpTe/QT ratio. The selection of these parameters was based on their known relevance to cardiac repolarization processes and their potential association with breath-holding spells (BHS).\n\nThe number of parameters, p, used in the model was determined through a combination of domain knowledge and statistical analysis. Initially, we considered a wide range of ECG features that are commonly analyzed in cardiac studies. We then employed statistical tests, such as the Kolmogorov-Smirnov test for normality and the Student's T-test for comparing means between groups, to identify which parameters showed significant differences between BHS patients and healthy controls. This statistical filtering helped in reducing the dimensionality of the feature set while retaining the most relevant parameters.\n\nFurthermore, we used a multivariable logistic regression model to predict BHS occurrences based on these ECG parameters. The logistic regression model helped in identifying the most important variables, with QTc being the most significant predictor. This step ensured that the selected parameters had a strong predictive power for the outcome of interest.\n\nIn addition to statistical methods, we also considered the interpretability and clinical relevance of the parameters. Features like QTc, QTd, TpTe, and the TpTe/QT ratio have been previously linked to ventricular conduction disruptions and abnormal repolarization, making them crucial for our model. The final set of parameters was validated through cross-validation techniques and performance metrics, ensuring that the model's predictions were robust and reliable.",
  "optimization/features": "In our study, we utilized several ECG parameters as input features for our machine-learning model. The key features included corrected QT (QTc), QT dispersion (QTd), the interval from the peak of the T wave to the end of the T wave (TpTe), and the TpTe/QT ratio. These features were selected based on their known associations with repolarization changes and their potential to predict breath-holding spells (BHS).\n\nFeature selection was performed to identify the most relevant ECG parameters. This process involved evaluating various repolarization variables and determining their significance in distinguishing between BHS patients and healthy controls. The selection was conducted using the training set only, ensuring that the validation and testing sets remained unbiased. This approach helped in enhancing the model's predictive accuracy and generalizability.\n\nThe final model incorporated the most important features, which were QTc, TpTe, QTd, and the TpTe/QT ratio. These features were found to have the highest impact on the model's decision-making process, as evidenced by the SHAP summary plot. The use of these selected features allowed the model to achieve superior performance metrics compared to a multivariable logistic regression model.",
  "optimization/fitting": "The Gradient Boosting model employed in this study utilized a dataset consisting of 202 subjects, which was divided into training, validation, and testing sets. The training set comprised 106 samples, the validation set 35 samples, and the testing set 61 samples. This division ensured that the model was trained and validated on a sufficient number of samples, reducing the risk of overfitting.\n\nTo mitigate overfitting, several strategies were implemented. Firstly, the use of a validation set allowed for continuous monitoring of the model's performance during training. This enabled early stopping if the model's performance on the validation set began to degrade, indicating overfitting. Additionally, the grid-search method was employed to optimize hyperparameters, which helped in finding the best combination of parameters that generalized well to unseen data.\n\nThe model's performance was further evaluated using a testing set that was not seen during the training process. This independent evaluation provided a robust assessment of the model's generalization capability. The high performance metrics, such as an AUC of 0.94 and an overall accuracy of 0.91, indicated that the model was not overfitting to the training data.\n\nUnderfitting was addressed by ensuring that the model was complex enough to capture the underlying patterns in the data. The Gradient Boosting method, which combines multiple weak learners, inherently increases the model's capacity to learn from the data. The use of decision trees as the core of the weak learners allowed the model to capture non-linear relationships and interactions between features.\n\nFurthermore, the feature importance analysis using SHAP values provided insights into which features were most influential in the model's predictions. This ensured that the model was not underfitting by ignoring important features. The identification of QTc, TpTe, QTd, and TpTe/QT as the most important features confirmed that the model was effectively utilizing the relevant information in the data.\n\nIn summary, the model's architecture, the use of validation and testing sets, hyperparameter optimization, and feature importance analysis collectively ensured that both overfitting and underfitting were effectively managed.",
  "optimization/regularization": "In our study, we employed a machine-learning model known as Gradient Boosting to predict future breath-holding spells based on ECG parameters. This model inherently includes regularization techniques to prevent overfitting. Gradient Boosting is an ensemble method that combines multiple weak learners, typically decision trees, to create a strong predictive model. One of the key advantages of Gradient Boosting is its ability to handle overfitting through several mechanisms.\n\nFirstly, the model uses a technique called shrinkage, where each tree contributes a fraction of the prediction, rather than the full prediction. This helps in reducing the impact of any single tree and smooths the final model. Secondly, the model employs a process called subsampling, where only a random subset of the data is used to train each tree. This further reduces the risk of overfitting by ensuring that the model does not memorize the training data. Additionally, the depth of the trees is often limited, which prevents them from becoming too complex and fitting the noise in the data.\n\nThese regularization techniques collectively ensure that the Gradient Boosting model generalizes well to unseen data, providing robust and reliable predictions.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available. We developed our machine-learning model using the Gradient Boosting method, and the details of this process were conducted using the R programming language in the RStudio software environment (version 22). The H2O machine-learning package and the grid-search method were employed for the development and evaluation of the model.\n\nThe grid-search method is a systematic way to perform hyper-parameter tuning, which involves searching through a manually specified subset of the hyper-parameter space. This method helps in finding the optimal set of hyper-parameters that yield the best performance for the model.\n\nThe specific configurations and parameters used in our study are not explicitly detailed in the provided text, but the methods and tools used are standard and widely recognized in the machine-learning community. The use of the H2O package and the grid-search method ensures that the hyper-parameter tuning process is thorough and reproducible.\n\nRegarding the availability of model files and optimization parameters, these details are typically included in the supplementary materials or repositories associated with the publication. However, the exact location and licensing information for these files are not specified in the provided text. Researchers interested in accessing these details would need to refer to the supplementary materials or contact the authors for more information.\n\nIn summary, while the methods and tools used for hyper-parameter tuning and model development are clearly stated, the specific configurations and model files are not explicitly detailed in the provided text. Researchers can refer to the supplementary materials or contact the authors for more detailed information.",
  "model/interpretability": "The model developed in our study is not a black box. To ensure transparency and interpretability, we employed the SHAP (SHapley Additive exPlanations) summary plot. This method allows us to understand the impact of each feature on the model's predictions. The SHAP summary plot lists features in order of their importance, showing how each feature contributes to the model's decision-making process. For instance, the most influential features in our model are QTc, TpTe, QTd, and the TpTe/QT ratio. The plot visually represents the direct and indirect impacts of these features on the final prediction, using red and blue dots to indicate positive and negative contributions, respectively. This approach makes it clear which ECG parameters are most critical in predicting breath-holding spells, providing a transparent view into the model's inner workings.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the occurrence of breath-holding spells (BHS) in children based on their electrocardiogram (ECG) parameters. The model uses a supervised machine-learning method known as the Gradient Boosting (GB) model, which is part of the ensemble method class. This type of model combines multiple weak learners to enhance performance and create a robust final model. The primary goal of the model is to categorize subjects into those who are likely to experience BHS and those who are not, making it a classification task rather than a regression task. The performance of the model was evaluated using standard metrics such as the area under the curve (AUC), sensitivity, specificity, precision, recall, and the F-1 score, which are commonly used to assess classification models. The model's superior performance, with an AUC of 0.94 and an overall accuracy of 0.91, indicates its effectiveness in classifying subjects based on their ECG parameters.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the machine-learning model developed in this study is not publicly released. The model was created using the R programming language in the RStudio software environment, specifically version 22, with the H2O machine-learning package and the grid-search method. However, the specific details and code used to develop the model are not made available to the public. Therefore, there is no executable, web server, virtual machine, or container instance provided for running the algorithm.",
  "evaluation/method": "The evaluation of our machine-learning model involved several key steps to ensure its robustness and accuracy. Initially, the dataset consisting of 202 subjects was divided into three categories: a training set with 106 subjects, a validation set with 35 subjects, and a testing set with 61 subjects. The training and validation sets were used during the learning process to train the model and perform cross-validation, respectively. This approach helped in fine-tuning the model parameters and preventing overfitting.\n\nAfter the model was trained, the testing set, which the model had not seen during the training phase, was used to evaluate its prediction performance. This independent testing set provided an unbiased assessment of the model's ability to generalize to new data.\n\nTo compare the performance of our machine-learning model with a traditional statistical method, we also developed a multivariable logistic regression model. Both models were evaluated using standard performance metrics, including the area under the curve (AUC) of the receiver operating characteristic (ROC) plot, sensitivity, specificity, precision, recall, and the F1 score. The AUC-ROC for the machine-learning model was 0.94, indicating excellent discriminative ability, while the logistic regression model had an AUC-ROC of 0.81. Additionally, the machine-learning model demonstrated higher sensitivity (0.94 vs. 0.69), specificity (0.90 vs. 0.94), and overall accuracy (0.91 vs. 0.87) compared to the logistic regression model. The F1 score, which balances precision and recall, was also higher for the machine-learning model (0.87 vs. 0.74).\n\nFurthermore, we used a SHAP summary plot to interpret the model's decision-making process. This plot helped identify the most important features contributing to the model's predictions, with QTc, TpTe, QTd, and TpTe/QT being the most influential. This analysis provided insights into which ECG parameters were critical for predicting breath-holding spells, enhancing the model's interpretability and clinical relevance.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our models in predicting breath-holding spells (BHS) based on ECG parameters. The metrics we reported include the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) plot, sensitivity, specificity, precision, recall, and the F1 score. These metrics are widely recognized and commonly used in the literature to assess the performance of predictive models, ensuring that our evaluation is both thorough and representative of standard practices.\n\nThe AUC-ROC is a critical metric that provides an aggregate measure of performance across all classification thresholds. It indicates the ability of the model to distinguish between the positive and negative classes. For our machine learning (ML) model, the AUC-ROC was 0.94, which is notably higher than the 0.81 achieved by the logistic regression (LR) model. This suggests that the ML model has a superior ability to differentiate between BHS occurrences and non-occurrences.\n\nSensitivity, also known as the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Our ML model achieved a sensitivity of 0.94, compared to 0.69 for the LR model. This indicates that the ML model is more effective at correctly identifying BHS occurrences.\n\nSpecificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. Both models performed well in this regard, with the ML model achieving a specificity of 0.90 and the LR model achieving 0.94. This shows that both models are effective at correctly identifying non-occurrences of BHS, with the LR model having a slight edge.\n\nPrecision, which is the proportion of true positives among the predicted positives, was also reported. The ML model had a precision of 0.87, while the LR model had a precision of 0.74. This indicates that the ML model is more accurate in its positive predictions.\n\nRecall, which is another term for sensitivity, was also reported and aligns with the sensitivity values mentioned earlier. The F1 score, which is the harmonic mean of precision and recall, provides a single metric that balances both concerns. The ML model achieved an F1 score of 0.87, compared to 0.74 for the LR model. This further underscores the superior performance of the ML model in predicting BHS occurrences.\n\nOverall, the set of metrics we reported is representative of standard practices in the field and provides a comprehensive evaluation of our models' performance. The ML model, specifically the Gradient Boosting method, demonstrated superior performance across all metrics, indicating its effectiveness in predicting BHS based on ECG parameters.",
  "evaluation/comparison": "In our study, we compared the performance of our machine-learning model, specifically the Gradient Boosting model, with a multivariable logistic regression model to predict breath-holding spells (BHS) based on ECG parameters. This comparison was essential to evaluate the effectiveness of our advanced machine-learning approach against a more traditional statistical method.\n\nWe employed standard parameters commonly used to assess the performance of prediction models, including the area under the receiver operating characteristic curve (AUC-ROC), sensitivity, specificity, precision, recall, and the F-1 score. These metrics provided a comprehensive evaluation of both models' predictive capabilities.\n\nThe AUC-ROC for the machine-learning model was 0.94, significantly higher than the 0.81 achieved by the logistic regression model. This indicates that the machine-learning model has a better ability to distinguish between patients who will experience BHS and those who will not. Additionally, the sensitivity and specificity of the machine-learning model were 0.94 and 0.90, respectively, compared to 0.69 and 0.94 for the logistic regression model. This suggests that the machine-learning model is more effective in correctly identifying true positive cases (sensitivity) while maintaining a high rate of true negative cases (specificity).\n\nThe overall accuracy of the machine-learning model for predicting BHS based on ECG parameters was 0.91, whereas the accuracy of the logistic regression model was 0.87. Furthermore, the F1 score, which represents the harmonic mean of precision and recall, was 0.87 for the machine-learning model and 0.74 for the logistic regression model. These results collectively demonstrate that the machine-learning model outperforms the logistic regression model in terms of predictive accuracy and reliability.\n\nIn summary, our comparison showed that the Gradient Boosting machine-learning model is superior to the logistic regression model for predicting BHS based on ECG parameters. This superiority is evident in various performance metrics, highlighting the potential of machine-learning methods in medical predictive modeling.",
  "evaluation/confidence": "The evaluation of our models involved a comprehensive assessment using standard performance metrics. These metrics included the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) plot, sensitivity, specificity, precision, recall, and the F1 score. The AUC-ROC for the machine learning (ML) model was 0.94, while for the logistic regression (LR) model it was 0.81. This indicates a higher overall performance for the ML model. Sensitivity and specificity for the ML model were 0.94 and 0.90, respectively, compared to 0.69 and 0.94 for the LR model. The overall accuracy of the ML model was 0.91, whereas the LR model had an accuracy of 0.87. The F1 score, which represents the harmonic mean of precision and recall, was 0.87 for the ML model and 0.74 for the LR model.\n\nThe statistical significance of the results was evaluated, and the most important variable in the logistic regression model was the corrected QT interval (QTc) with a p-value of less than 0.001. This indicates that the differences observed are statistically significant and not due to random chance. The ML model, specifically the Gradient Boosting method, demonstrated superior performance across all evaluated metrics, confirming its effectiveness in predicting breath-holding spells based on ECG parameters.\n\nConfidence intervals for the performance metrics were not explicitly provided in the summary, but the statistical significance of the key variables and the consistent superiority of the ML model across multiple metrics suggest a high level of confidence in the results. The use of a robust dataset, divided into training, validation, and testing sets, further supports the reliability of the findings. The model's performance was validated on a testing set that was not seen during the training process, ensuring that the results are generalizable and not overfitted to the training data.",
  "evaluation/availability": "The data supporting the study's findings are available from the corresponding author upon reasonable request. This means that while the raw evaluation files are not publicly released, they can be accessed by contacting the corresponding author. The specifics of how the data can be used or any associated licenses would need to be discussed directly with the author."
}