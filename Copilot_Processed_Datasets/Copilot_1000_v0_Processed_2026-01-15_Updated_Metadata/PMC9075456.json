{
  "publication/title": "Multiclass Arrhythmia Detection and Classification From Photoplethysmography Signals Using a Deep Convolutional Neural Network.",
  "publication/authors": "Liu Z, Zhou B, Jiang Z, Chen X, Li Y, Tang M, Miao F",
  "publication/journal": "Journal of the American Heart Association",
  "publication/year": "2022",
  "publication/pmid": "35322685",
  "publication/pmcid": "PMC9075456",
  "publication/doi": "10.1161/jaha.121.023555",
  "publication/tags": "- Arrhythmia Detection\n- Photoplethysmography\n- Deep Convolutional Neural Networks\n- Machine Learning\n- Statistical Analysis\n- Cardiovascular Disease\n- Data Visualization\n- Medical Imaging\n- Signal Processing\n- Healthcare Technology",
  "dataset/provenance": "The dataset used in this study consists of photoplethysmography (PPG) and electrocardiogram (ECG) recordings from patients with arrhythmias. The study enrolled 242 patients who met the inclusion criteria. However, 14 patients were excluded due to issues such as detachment of ECG electrodes or PPG sensors, or recordings lasting less than 10 minutes. This resulted in a final dataset of 228 pairs of PPG and ECG recordings, with one recording per patient.\n\nThese 228 PPG recordings were divided into 158,355 10-second segments. Out of these, 127,562 segments were retained after removing those with poor signal quality or poor-quality ECG reference data. Among the clean PPG segments, 118,217 (92.7%) were labeled with a definite rhythm by two cardiologists. The labeled segments were distributed as follows: 38,081 for sinus rhythm, 11,372 for premature ventricular contraction, 11,248 for premature atrial contraction, 5,783 for ventricular tachycardia, 12,539 for supraventricular tachycardia, and 39,194 for atrial fibrillation.\n\nThe dataset was then partitioned into independent training, validation, and test sets in a 6:2:2 ratio. Specifically, 60% of the segments (71,390 segments) were used for training, 20% (23,643 segments) for validation, and 20% (23,174 segments) for testing. This partitioning ensured that the model could be trained, validated, and tested on distinct subsets of the data, enhancing the robustness of the evaluation process.",
  "dataset/splits": "The dataset was divided into three independent splits: training, validation, and test sets. The data was partitioned in a 6:2:2 ratio.\n\nThe training set consisted of 137 recordings, which included 71,390 clean 10-second photoplethysmography segments. The validation set contained 46 recordings, and the test set had 45 recordings. Each recording was from a different patient, and each segment within the recordings had only one identified rhythm type.\n\nThe distribution of rhythm types across these datasets was as follows:\n\n* Sinus rhythm (SR): 38,081 segments\n* Premature ventricular contraction (PVC): 11,372 segments\n* Premature atrial contraction (PAC): 11,248 segments\n* Ventricular tachycardia (VT): 5,783 segments\n* Supraventricular tachycardia (SVT): 12,539 segments\n* Atrial fibrillation (AF): 39,194 segments\n\nThese segments were used to train, validate, and test the deep convolutional neural network (DCNN) model for arrhythmia detection.",
  "dataset/redundancy": "The dataset used in this study was partitioned into three independent subsets: training, validation, and test sets, following a 6:2:2 ratio. This partitioning ensures that the training subset is used to train the deep convolutional neural network (DCNN) model over 200 epochs. The model's performance is then evaluated on the validation subset to select the optimal model, which is subsequently tested on the independent test subset.\n\nThe independence of the training and test sets is crucial for evaluating the model's generalizability. To enforce this independence, the data was carefully divided such that there is no overlap between the sets. This means that the data used for training the model is entirely separate from the data used for testing it, ensuring that the model's performance metrics are a true reflection of its ability to generalize to new, unseen data.\n\nRegarding the distribution of rhythm types across the datasets, it is important to note that the distribution was balanced to ensure that each subset represents the overall population adequately. This balancing helps in maintaining the integrity of the model's performance evaluation, as it prevents any subset from being biased towards a particular rhythm type.\n\nComparing this dataset to previously published machine learning (ML) datasets, the approach taken here aligns with standard practices in the field. The use of independent training, validation, and test sets is a common method to ensure robust model evaluation. The specific ratio of 6:2:2 is chosen to provide a substantial amount of data for training while reserving enough data for validation and testing to accurately assess the model's performance. This method helps in mitigating overfitting and ensures that the model's performance is reliable and generalizable.",
  "dataset/availability": "The data used in this study is not publicly available. The study involved 228 patients with arrhythmia, from whom pairs of photoplethysmography and ECG recordings were obtained. These recordings were divided into segments, with a total of 118,217 clean 10-second photoplethysmography segments retained for analysis. These segments were partitioned into independent training, validation, and test datasets in the ratio 6:2:2.\n\nThe data was not released in a public forum, and thus, there is no specific license associated with its use. The study was conducted with the consent of the patients, and the data was used solely for the purposes outlined in the research. The specific details of the data splits and the segments used for training, validation, and testing are described in the results section of the publication.",
  "optimization/algorithm": "The optimization algorithm used in our study is not a new machine-learning algorithm. Instead, we employed well-established machine-learning algorithms for arrhythmia detection. Specifically, we utilized four different machine-learning algorithms: artificial neural network, random forest, k-nearest neighbors, and support vector machine. These algorithms are widely recognized and have been previously applied in the field of photoplethysmography-based arrhythmia detection.\n\nThe choice of these algorithms was driven by their proven effectiveness in handling complex data and their ability to capture intricate patterns within the photoplethysmography waveforms. By leveraging these established methods, we aimed to build robust models that could accurately detect various arrhythmia types.\n\nThe implementation of these algorithms was carried out using the Scikit-learn library in a Python programming environment. This library provides a comprehensive suite of tools for machine learning, making it a popular choice for researchers and practitioners alike. The use of Scikit-learn ensured that our models were built on a reliable and well-documented foundation, facilitating reproducibility and comparability with other studies in the field.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, the data encoding and preprocessing for the machine-learning algorithms involved several key steps. Initially, we detected the positions of peaks in the photoplethysmography (PPG) waveform. This step was crucial for extracting the inter-beat intervals (IBI) series, which were obtained by calculating the time differences between successive peaks.\n\nFollowing peak detection, we computed a set of handcrafted features from both the PPG waveform and the IBI series. For the PPG waveform, we calculated eight features: standard deviation (STD), kurtosis, skewness, sample entropy (SampEn), Shannon entropy (ShEn), Hjorth mobility, Hjorth complexity, and spectral purity index (SPI). For the IBI series, we derived nine features: mean value, STD, coefficient of variation (CoV), SampEn, ShEn, coefficient of sample entropy (COSEn), normalized root mean square of successive differences (nRMSSD), and point-care plot SD and SD2.\n\nThese features were then used to train and evaluate four different machine-learning algorithms: artificial neural network, random forest, k-nearest neighbors, and support vector machine. All algorithms were implemented using the Scikit-learn library in a Python programming environment. The data was partitioned into independent training, validation, and test sets in a 6:2:2 ratio. The training subset was used to train our deep convolutional neural network (DCNN) model over 200 epochs, and the model with the optimal performance on the validation subset was saved for further evaluation with the test subset.\n\nFor statistical analysis, continuous variables with normal distribution were expressed as mean \u00b1 SD and compared using the t-test. Non-normally distributed continuous data were expressed as median (interquartile range) and compared using the Mann-Whitney test. Categorical variables were expressed as numbers (percentages) and compared using \u03c72 or Fisher exact tests as appropriate. To verify the performance of the proposed DCNN model, traditional machine-learning-based models, which rely on explicit rules and handcrafted features derived from IBI sequences and PPG waveforms, were used for comparison. Each machine-learning-based detector was trained and evaluated on the same training and test data sets as the DCNN model.",
  "optimization/parameters": "In our study, the deep convolutional neural network (DCNN) model employed consists of a total of 1,496,102 parameters. These parameters are distributed across 13 one-dimensional convolutional layers, five one-dimensional max-pooling layers, and two fully connected layers. Each convolutional layer is followed by a one-dimensional batch normalization layer and a rectified linear unit (ReLU) function. Additionally, a ReLU layer and a dropout layer (with a dropout rate of 0.5) are applied between the fully connected layers.\n\nThe selection of the number of parameters was guided by the need to balance model complexity and computational efficiency. Initially, we started with a modified version of the VGGNet-16 architecture, which is designed for 2-dimensional image classification. To adapt it for one-dimensional physiological signals, several modifications were made. The convolution and max-pooling layers were revised to be one-dimensional with a kernel size of 1 \u00d7 3. The number of filters was reduced from 64, 128, 256, and 512 to 32, 64, 128, and 256, respectively. Furthermore, the number of fully connected layers was reduced from 4 to 2. These adjustments were crucial for increasing the training speed without compromising the performance of the deep learning models.\n\nThe weights of the model were initialized using the Kaiming initializer, which is known for its effectiveness in training deep neural networks. The model was trained using the Adam optimizer with default parameters and a mini-batch size of 128. The learning rate was set to 0.001 at the beginning and then decayed exponentially during the training process, with a decay rate (gamma) of 0.95. This approach ensured that the model could converge efficiently while avoiding issues related to overfitting.",
  "optimization/features": "In our study, we utilized a total of 17 handcrafted features as input for the machine learning-based models. These features were derived from the photoplethysmography (PPG) waveform and the inter-pulse interval (IPI) series. The features included eight PPG waveform features: standard deviation value (STD), kurtosis, skewness, sample entropy (SampEn), Shannon entropy (ShEn), Hjorth mobility, Hjorth complexity, and spectral purity index (SPI). Additionally, nine IPI features were calculated: mean value, STD, coefficient of variation (CoV), SampEn, ShEn, coefficient of sample entropy (COSEn), normalized root mean square of successive differences (nRMSSD), and point-care plot SD and SD2.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, we relied on domain knowledge to select these 17 features, which have been previously reported and used for PPG-based arrhythmia detection. This approach ensured that the features were relevant and informative for the task at hand. The selection of these features was done independently of the training set, as they were chosen based on established literature and domain expertise.",
  "optimization/fitting": "The deep convolutional neural network (DCNN) model was trained using a dataset partitioned into independent training, validation, and test sets in a 6:2:2 ratio. This partitioning helps to ensure that the model is evaluated on unseen data, reducing the risk of overfitting.\n\nThe model was trained over 200 epochs, with the learning rate initially set to 0.001 and then decayed exponentially during training. This decay helps in fine-tuning the model parameters as training progresses, which can prevent overfitting by reducing the learning rate as the model converges.\n\nTo address overfitting, several techniques were employed. Dropout layers with a probability of 0.5 were applied between the fully connected layers. Dropout randomly sets a fraction of input units to 0 at each update during training time, which helps prevent overfitting. Additionally, the model's performance was monitored on a validation subset, and the model with the optimal performance on this subset was saved and used for further evaluation. This approach ensures that the model generalizes well to unseen data.\n\nUnderfitting was addressed by using a sufficiently complex architecture with multiple convolutional and fully connected layers. The DCNN architecture includes 33 layers, with each convolutional layer followed by batch normalization and a rectified linear unit (ReLU) activation function. This design allows the model to learn complex features from the input data.\n\nThe total number of parameters in the model is 1,496,102, which is relatively large compared to the number of training points. However, the use of regularization techniques such as dropout and early stopping, along with the validation process, helps to mitigate the risk of overfitting.\n\nIn summary, the model's architecture and training process were designed to balance complexity and generalization, ensuring that both overfitting and underfitting are minimized. The use of dropout, learning rate decay, and validation-based model selection are key strategies employed to achieve this balance.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and improve the generalization of our deep convolutional neural network (DCNN) model. One of the key techniques used was dropout, which was applied between the fully connected layers. Dropout works by randomly setting a fraction of the input units to zero at each update during training time, which helps to prevent overfitting by ensuring that the model does not become too reliant on any single neuron. In our implementation, we used a dropout rate of 0.5, meaning that half of the neurons were randomly dropped during each training iteration.\n\nAdditionally, batch normalization was used after each convolutional layer. Batch normalization helps to stabilize and accelerate the training process by normalizing the inputs of each layer. This technique not only aids in preventing overfitting but also allows for the use of higher learning rates, which can speed up the training process.\n\nFurthermore, we utilized a relatively large dataset, which was partitioned into independent training, validation, and test sets in the ratio 6:2:2. This partitioning ensured that the model was trained on a substantial amount of data, reducing the risk of overfitting to the training set. The model's performance was continuously monitored on the validation set, and the model with the optimal performance on this set was saved and used for further evaluation with the test set.\n\nThese regularization methods, combined with careful data partitioning and monitoring, helped to ensure that our DCNN model generalized well to unseen data, providing robust and reliable performance in arrhythmia detection from photoplethysmography signals.",
  "optimization/config": "The configuration details of the deep convolutional neural network (DCNN) used in our study are comprehensively reported. The structure and configuration of the DCNN, including the types of layers, output sizes, filters, kernel sizes, strides, padding, and the number of parameters for each layer, are provided in a detailed table. This table outlines the specific architecture of the model, making it reproducible.\n\nThe modifications made to the traditional VGGNet-16 for one-dimensional input signals are also documented. These modifications include changing the convolution and max-pooling layers to one-dimensional with a kernel size of 1 \u00d7 3, reducing the number of filters, and decreasing the number of fully connected layers. These adjustments were made to enhance training speed without compromising model performance.\n\nThe initialization method for the weights, the optimizer used (Adam with default parameters), and the mini-batch size (128) are all specified. Additionally, the use of one-dimensional batch normalization (BatchNorm1d) and rectified linear unit (ReLU) functions following each convolutional layer, as well as the application of ReLU and dropout layers between the fully connected layers, are detailed.\n\nThe specific configuration of our DCNN model, including the number of convolutional, max-pooling, and fully connected layers, is clearly described. This information, along with the detailed table, ensures that the model can be replicated by other researchers.\n\nRegarding the availability of model files and optimization parameters, they are not explicitly mentioned as being publicly available. However, the comprehensive documentation of the model's configuration and training procedures should facilitate replication and further research. For access to specific model files or additional optimization parameters, interested parties may need to contact the authors directly.",
  "model/interpretability": "The model employed in this study is a deep convolutional neural network (DCNN), which is typically considered a black-box model due to its complex, multilayered architecture. However, efforts were made to enhance the interpretability of the DCNN's decisions. To achieve this, two techniques were utilized: t-distributed stochastic neighbor embedding (t-SNE) and guided gradient-weighted class activation mapping (Grad-CAM).\n\nt-SNE is a nonlinear dimensionality reduction technique that allows for the visualization of high-dimensional data in a lower-dimensional space. This method was used to map the features automatically learned by the various layers of the DCNN into a 2-dimensional space, making it easier to understand the data's structure and the model's decision-making process.\n\nGrad-CAM, on the other hand, combines fine-grained guided backpropagation and gradient-weighted class activation mapping. This technique generates a high-resolution, class-discriminative heatmap from the final convolutional layer of the DCNN. The heatmap highlights the regions in the photoplethysmography (PPG) waveforms that are crucial for the model's predictions. By superimposing this heatmap over the PPG waveforms, it becomes possible to visually interpret which parts of the input data the model focuses on when predicting a specific rhythm category.\n\nThese techniques collectively help in demystifying the DCNN's decision-making process, providing insights into how the model interprets PPG waveforms to detect arrhythmias. While the DCNN itself remains a complex model, these interpretability tools offer a clearer view of its internal workings and the features it considers important for classification.",
  "model/output": "The model discussed in this publication is a classification model. It is designed to detect and classify various types of arrhythmias from photoplethysmography (PPG) signals. The model categorizes the input data into six different rhythm types: sinus rhythm (SR), premature ventricular contraction (PVC), premature atrial contraction (PAC), ventricular tachycardia (VT), supraventricular tachycardia (SVT), and atrial fibrillation (AF). The performance of the model is evaluated using metrics such as sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) for each rhythm type. Additionally, the overall accuracy of the model is provided, indicating its effectiveness in correctly classifying the arrhythmias. The model's output is visualized using techniques like t-distributed stochastic neighbor embedding and guided gradient-weighted class activation mapping to highlight the important regions in the PPG waveforms that contribute to the classification decisions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the deep convolutional neural network (DCNN) model is not publicly released. The construction and evaluation of the DCNN were implemented using Pytorch in the CentOS7.3 operating system. However, no specific details about the availability of an executable, web server, virtual machine, or container instance for running the algorithm have been provided. Therefore, it is not possible to run the algorithm using a publicly available method at this time.",
  "evaluation/method": "The evaluation of the proposed deep convolutional neural network (DCNN) model involved a rigorous process to ensure its performance and reliability. The data was partitioned into independent training, validation, and test sets in a 6:2:2 ratio. The training subset was used to train the DCNN model over 200 epochs. The model that demonstrated optimal performance on the validation subset was selected and subsequently evaluated using the test subset.\n\nTo verify the DCNN's performance, traditional machine learning (ML) models were also employed for comparison. These ML models relied on explicit rules and handcrafted features derived from interbeat intervals and photoplethysmography waveforms. Specifically, 17 handcrafted features and four ML algorithms\u2014artificial neural network, random forest, k-nearest neighbors, and support vector machine\u2014were used to develop the ML-based detectors. Each ML-based detector was trained and evaluated on the same datasets as the DCNN model.\n\nReceiver operating characteristic curves were generated for each rhythm to be detected, and a microaverage receiver operating characteristic curve was created. The area under this curve and its corresponding 95% confidence interval were computed and compared for all arrhythmia detectors using the DeLong test. Additionally, sensitivity, specificity, positive predictive value, negative predictive value, and overall accuracy were calculated for each detector, along with their corresponding 95% confidence intervals.\n\nAll statistical tests conducted in this study were two-sided, with a significance level set at P<0.05. SPSS version 21.0 and Python version 3.8.8 were utilized for data analysis. To enhance the interpretability of the DCNN's decisions, techniques such as t-distributed stochastic neighbor embedding and guided gradient-weighted class activation mapping were employed. These methods helped visualize the features learned by the DCNN and highlight the important regions in the photoplethysmography waveforms that contributed to the model's predictions.",
  "evaluation/measure": "In our study, we evaluated the performance of our deep convolutional neural network (DCNN) model and traditional machine learning (ML) based detectors using several key metrics. These metrics include sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and overall accuracy. Each of these metrics was calculated along with their corresponding 95% confidence intervals (CI) to provide a comprehensive assessment of the models' performance.\n\nSensitivity measures the ability of the model to correctly identify positive cases, while specificity assesses the model's ability to correctly identify negative cases. PPV indicates the probability that a positive test result is a true positive, and NPV indicates the probability that a negative test result is a true negative. Overall accuracy provides a single metric that summarizes the proportion of true results (both true positives and true negatives) among the total number of cases evaluated.\n\nThese metrics are widely used in the literature for evaluating the performance of arrhythmia detection models, making our evaluation representative and comparable to other studies in the field. By reporting these metrics, we aim to provide a clear and comprehensive understanding of the performance of our DCNN model and the traditional ML-based detectors.",
  "evaluation/comparison": "To evaluate the performance of our proposed deep convolutional neural network (DCNN) model for arrhythmia detection from photoplethysmography, we conducted a comprehensive comparison with traditional machine learning (ML) based models. These ML models rely on explicit rules and handcrafted features derived from interbeat intervals and photoplethysmography waveforms. Specifically, we used 17 handcrafted features and four ML algorithms: artificial neural network, random forest, k-nearest neighbors, and support vector machine. These algorithms have been previously used for photoplethysmography-based arrhythmia detection.\n\nEach ML-based detector was trained and evaluated on the same training and test datasets as our DCNN model. This ensured a fair comparison by using identical data partitions. The performance of each arrhythmia detector was assessed using receiver operating characteristic curves, and a microaverage receiver operating characteristic curve was created for each detector. The area under the microaverage receiver operating characteristic curve and its corresponding 95% confidence interval were computed and compared using the DeLong test. Additionally, we calculated sensitivity, specificity, positive predictive value, negative predictive value, and overall accuracy for each detector, along with their corresponding 95% confidence intervals.\n\nThe detailed performance of the ML-based detectors for each rhythm type is summarized in supplementary tables. The ML-based detector using the artificial neural network algorithm had the highest performance among the ML-based detectors in all evaluation metrics. However, it did not perform as well as the DCNN model. The DCNN model outperformed the best ML-based model by significant margins in overall accuracy, average sensitivity, specificity, positive predictive value, and negative predictive value. Moreover, the area under the microaverage receiver operating characteristic curve of the DCNN was significantly higher than those of all ML-based detectors, indicating superior performance.",
  "evaluation/confidence": "The evaluation of our arrhythmia detection model includes a comprehensive assessment of performance metrics, each accompanied by confidence intervals to provide a clear understanding of the results' reliability. Sensitivity, specificity, positive predictive value, negative predictive value, and overall accuracy were calculated for each detector, along with their corresponding 95% confidence intervals. These intervals help in understanding the precision of the estimates and the potential variability in the results.\n\nTo ensure the statistical significance of our findings, we employed the DeLong test to compare the area under the microaverage receiver operating characteristic curve across different arrhythmia detectors. This test is specifically designed for comparing the areas under correlated receiver operating characteristic curves, providing a robust statistical basis for our comparisons.\n\nAll statistical tests conducted in this study were two-sided, with a significance level set at P<0.05. This stringent threshold ensures that any claimed superiority of our method over others and baselines is supported by strong statistical evidence. The use of SPSS version 21.0 and Python version 3.8.8 for data analysis further ensures the rigor and reproducibility of our statistical evaluations.",
  "evaluation/availability": "Not enough information is available."
}