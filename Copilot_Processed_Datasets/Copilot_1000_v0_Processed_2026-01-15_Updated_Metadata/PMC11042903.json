{
  "publication/title": "An Ensemble Feature Selection Approach-Based Machine Learning Classifiers for Prediction of COVID-19 Disease.",
  "publication/authors": "Hossen MJ, Ramanathan TT, Al Mamun A",
  "publication/journal": "International journal of telemedicine and applications",
  "publication/year": "2024",
  "publication/pmid": "38660584",
  "publication/pmcid": "PMC11042903",
  "publication/doi": "10.1155/2024/8188904",
  "publication/tags": "- COVID-19 diagnosis\n- Feature selection\n- Machine learning\n- Ensemble methods\n- Classifier performance\n- Data mining\n- Medical datasets\n- Predictive modeling\n- Healthcare analytics\n- Disease severity prediction",
  "dataset/provenance": "The datasets used in this study were sourced from two distinct locations. The first dataset, referred to as the Israeli COVID-19 dataset, was obtained from the Israeli Ministry of Health website. This dataset comprises 101,796 samples. The input attributes for this dataset include cough, fever, sore throat, shortness of breath, headache, age of 60 years and above, gender, and test indication. The target variable indicates whether the result for COVID-19 disease is positive or negative.\n\nThe second dataset, known as the symptoms and COVID-19 presence dataset, was retrieved from the Kaggle website. This dataset consists of 5,434 samples. The input attributes for this dataset are more extensive and include breathing problem, fever, dry cough, sore throat, running nose, asthma, chronic lung disease, headache, heart disease, diabetes, hypertension, fatigue, gastrointestinal issues, abroad travel, contact with COVID-19 patient, attended large gathering, visited public exposed places, family working in public exposed places, wearing masks, and sanitation from the market. The target variable for this dataset is whether the COVID-19 disease is present or not.\n\nBoth datasets have been utilized in previous research and by the community to study COVID-19 symptoms and presence. The Israeli COVID-19 dataset, in particular, has been used to address missing values through the K-mean imputing technique and to balance the dataset using the K-mean SMOTE technique. These preprocessing steps are crucial for improving the performance of machine learning models applied to these datasets.",
  "dataset/splits": "In our study, we utilized two distinct COVID-19 datasets. For each dataset, we performed a split into training and testing datasets. The datasets were divided in an 80:20 ratio, respectively. This means that 80% of the data was used for training the classifiers, while the remaining 20% was reserved for testing their performance.\n\nThe first dataset, obtained from the Israeli Ministry of Health, consists of 101,796 samples. Therefore, approximately 81,437 samples were used for training, and around 20,359 samples were used for testing.\n\nThe second dataset, referred to as the symptoms and COVID-19 presence dataset, contains 5,434 samples. Consequently, about 4,347 samples were allocated to the training set, and approximately 1,087 samples were designated for the testing set.\n\nThis split ensures that the classifiers are trained on a substantial amount of data while also having a sufficient number of samples to evaluate their performance accurately.",
  "dataset/redundancy": "The datasets used in our study were split into training and testing sets in an 80:20 ratio. This means that 80% of the data was used for training the classifiers, while the remaining 20% was reserved for testing their performance. The training and testing datasets are independent, ensuring that the model's performance on the test set is a true reflection of its generalization capability.\n\nTo enforce independence between the training and test sets, we employed a random split. This process ensures that each data point has an equal chance of being included in either the training or testing set, thereby maintaining the integrity of the dataset distribution.\n\nThe distribution of the datasets used in our study is comparable to previously published machine learning datasets in the context of COVID-19 research. Both datasets contain nominal input attributes, which are categorical in nature. The Israeli COVID-19 dataset consists of 101,796 samples, while the symptoms and COVID-19 presence dataset comprises 5,434 samples. The target variable in both datasets indicates the presence or absence of COVID-19.\n\nOne notable aspect of our datasets is the handling of missing values and class imbalance. For the Israeli COVID-19 dataset, missing values were addressed using the K-mean imputing technique. Additionally, the dataset was converted into a balanced dataset using the K-mean SMOTE technique. This preprocessing step is crucial for improving the performance of machine learning classifiers, especially in the presence of imbalanced data.",
  "dataset/availability": "The datasets utilized in our study are publicly available, ensuring transparency and reproducibility. The first dataset, referred to as the Israeli COVID-19 dataset, was obtained from the Israeli Ministry of Health website. This dataset comprises 101,796 samples and includes input attributes such as cough, fever, sore throat, shortness of breath, headache, age of 60 years and above, gender, and test indication. The target variable indicates whether the result for COVID-19 disease is positive or negative.\n\nThe second dataset, known as the symptoms and COVID-19 presence dataset, was retrieved from Kaggle. This dataset contains 5,434 samples and includes input attributes like breathing problem, fever, dry cough, sore throat, running nose, asthma, chronic lung disease, headache, heart disease, diabetes, hypertension, fatigue, gastrointestinal issues, abroad travel, contact with COVID-19 patient, attended large gathering, visited public exposed places, family working in public exposed places, wearing masks, and sanitation from the market. The target variable specifies whether the COVID-19 disease is present or not.\n\nBoth datasets are available under open licenses, allowing for unrestricted access and use. The Israeli COVID-19 dataset can be accessed via the provided URL, ensuring that researchers can easily obtain the data for further analysis or validation of our findings. Similarly, the symptoms and COVID-19 presence dataset is available on Kaggle, a popular platform for datasets, which enforces proper citation and attribution.\n\nTo ensure the integrity and reproducibility of our results, we adhered to standard practices for data splitting. The datasets were divided into training and testing sets in an 80:20 ratio. This split was consistently applied across all experiments to maintain uniformity and comparability. The training dataset was used to train the classifiers, while the testing dataset was used to evaluate their performance. This approach helps in assessing the generalizability of the models and ensures that the results are not biased by the specific data splits used.",
  "optimization/algorithm": "The optimization algorithm employed in our research focuses on enhancing the performance of machine learning classifiers for COVID-19 disease prediction. We utilized several established optimization strategies to extract relevant features from the datasets. One of the key algorithms used is Particle Swarm Optimization (PSO), which is known for its efficiency in tuning classifiers with few parameters to achieve optimal solutions. PSO is particularly useful in our context due to its ability to handle complex, high-dimensional spaces effectively.\n\nAdditionally, we incorporated the Random Forest technique, which supports accurate feature extraction by leveraging multiple trained decision trees. This ensemble method helps in identifying the most relevant features, thereby improving the classifier's performance.\n\nThe machine-learning algorithms used in our study are not new but are well-established in the field. They were chosen for their proven effectiveness in handling large and complex datasets, which is crucial for accurate COVID-19 disease classification. The decision to use these algorithms in a medical context, rather than a purely machine-learning journal, is driven by the specific application and the need to address the unique challenges posed by COVID-19 data. Our focus is on demonstrating how these algorithms can be applied to real-world medical problems, thereby contributing to the broader field of telemedicine and healthcare analytics.",
  "optimization/meta": "The proposed system, EFS-MLC, employs an ensemble feature selection approach that integrates multiple feature selection techniques, including chi-square, RFE, GA, PSO, and random forest. These techniques work together to identify the most relevant features for predicting COVID-19 infections. The selected features are then used to train various machine learning classifiers, such as decision tree, na\u00efve Bayes, KNN, MLP, and SVM.\n\nThe ensemble machine learning classifier in the EFS-MLC system classifies data through a voting method based on the different employed classifiers. This approach leverages the strengths of multiple classifiers to improve the overall accuracy and robustness of the predictions. The system does not explicitly use data from other machine-learning algorithms as input in the traditional sense of a meta-predictor. Instead, it combines the outputs of different feature selection methods and classifiers to make final predictions.\n\nThe training data for the EFS-MLC system is derived from two COVID-19 datasets: one from the Israeli Ministry of Health and another from Kaggle. These datasets are used to train the individual classifiers and the ensemble feature selection methods. The independence of the training data is maintained by ensuring that the datasets are preprocessed and balanced before being used for training. This approach helps in reducing bias and improving the generalizability of the model.\n\nThe EFS-MLC system's design ensures that the training data is independent and that the ensemble feature selection and classification methods are applied consistently across the datasets. This consistency helps in achieving reliable and accurate predictions for COVID-19 infections.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for preparing the datasets for the machine learning algorithms. The input attributes for both the Israeli COVID-19 dataset and the symptoms and COVID-19 presence dataset were of nominal data type. This meant that each attribute was categorical and required appropriate encoding techniques to be used effectively in machine learning models.\n\nFor the Israeli COVID-19 dataset, the input attributes included cough, fever, sore throat, shortness of breath, headache, age of 60 years and above, gender, and test indication. The target variable was a positive or negative result for COVID-19 disease. Similarly, the symptoms and COVID-19 presence dataset included attributes such as breathing problem, fever, dry cough, sore throat, running nose, asthma, chronic lung disease, headache, heart disease, diabetes, hypertension, fatigue, gastrointestinal issues, abroad travel, contact with COVID-19 patient, attended large gathering, visited public exposed places, family working in public exposed places, wearing masks, and sanitation from the market. The target variable for this dataset was whether the COVID-19 disease was present or not.\n\nMissing values in the Israeli COVID-19 dataset were addressed using the K-mean imputing technique. This method helped to predict and substitute missing data, ensuring that the dataset was complete and ready for analysis. Additionally, the Israeli COVID-19 dataset was imbalanced, which could bias the machine learning models. To address this, the K-mean SMOTE technique was used to convert the imbalanced dataset into a balanced one. This technique oversampled the minority class, ensuring that the dataset was representative of both positive and negative cases of COVID-19.\n\nThe datasets were then split into training and testing datasets in an 80:20 ratio. The training dataset was used to train the classifiers, while the testing dataset was used to evaluate their performance. This split ensured that the models were trained on a sufficient amount of data and tested on a separate set to assess their generalization capabilities.\n\nThe preprocessing steps included handling missing values, balancing the dataset, and splitting it into training and testing sets. These steps were essential for preparing the data for the feature selection and classification processes, ensuring that the machine learning models could accurately classify COVID-19 infections.",
  "optimization/parameters": "In our proposed system, the Particle Swarm Optimization (PSO) algorithm is employed for feature selection, which inherently involves a few key parameters. The primary parameters in PSO include the inertia weight (w), the cognitive acceleration coefficient (c1), and the social acceleration coefficient (c2). These parameters control the velocity updates of the particles, influencing their movement towards the optimal solution.\n\nThe inertia weight (w) determines the influence of the previous velocity on the current velocity, helping to balance exploration and exploitation. The cognitive acceleration coefficient (c1) influences the particle's movement towards its personal best position, while the social acceleration coefficient (c2) influences the particle's movement towards the global best position.\n\nThe selection of these parameters is crucial for the performance of the PSO algorithm. In our implementation, these parameters were chosen based on empirical studies and common practices in the literature. Typically, the inertia weight is set to decrease over time, starting from a value around 0.9 and decreasing to 0.4. The cognitive and social acceleration coefficients are often set to values around 2.0, ensuring a balanced influence from both personal and global best positions.\n\nAdditionally, the number of particles (p) in the swarm is another important parameter. The choice of p depends on the dimensionality of the feature space and the complexity of the problem. In our experiments, we used a predetermined number of particles, which was selected through trial and error to achieve a good balance between computational efficiency and solution quality. Generally, a larger number of particles can lead to better exploration of the search space but at the cost of increased computational time.\n\nIn summary, the PSO algorithm in our system utilizes three main parameters: the inertia weight, the cognitive acceleration coefficient, and the social acceleration coefficient. The number of particles is also a critical parameter. These parameters were selected based on empirical evidence and literature recommendations to ensure effective feature selection for COVID-19 classification.",
  "optimization/features": "In the proposed system, the input features for the COVID-19 datasets include a variety of symptoms and exposure-related attributes. For the Israeli COVID-19 dataset, the input features consist of symptoms such as breathing problem, fever, dry cough, sore throat, running nose, asthma, chronic lung disease, headache, heart disease, diabetes, hypertension, fatigue, gastrointestinal issues, and exposure-related factors like abroad travel, contact with COVID-19 patients, attending large gatherings, visiting public places, family working in public places, wearing masks, and sanitation practices.\n\nFor the symptoms and COVID-19 presence dataset, the input features are similar but may include additional or slightly different attributes. The target variable in both datasets is whether COVID-19 is present or not.\n\nFeature selection was indeed performed to enhance the classification accuracy. Several techniques were employed, including chi-square, Recursive Feature Elimination (RFE), Genetic Algorithm (GA), Particle Swarm Optimization (PSO), and random forest. These methods were used to identify the most relevant features that contribute to the accurate detection of COVID-19 infections.\n\nThe feature selection process was conducted using the training dataset only, ensuring that the selected features were not influenced by the testing data. This approach helps in maintaining the integrity of the model evaluation and prevents overfitting. The ensemble feature selection method was used to select the best features by majority voting among the different feature selection techniques. For the Israeli COVID-19 dataset, the top features selected were cough, fever, sore throat, headache, and test indication. For the symptoms and COVID-19 presence dataset, the top features included breathing problem, fever, dry cough, sore throat, abroad travel, contact with COVID-19 patients, and attending large gatherings.",
  "optimization/fitting": "In our research, we employed several optimization strategies to ensure effective feature extraction and classification of COVID-19 infections. One of the key techniques used was Particle Swarm Optimization (PSO), which is a heuristic search method inspired by the behavior of bird or fish schools. PSO helps in tuning the classifier with fewer parameters, thereby attaining the best practical solutions.\n\nTo address the potential issue of overfitting, we utilized an ensemble feature selection approach. This method involves selecting the best features through a majority voting system using techniques such as chi-square, Recursive Feature Elimination (RFE), Genetic Algorithm (GA), PSO, and random forest. By combining multiple feature selection methods, we ensured that the selected features are robust and generalizable, reducing the risk of overfitting.\n\nAdditionally, we employed random forest, which uses a group of decision tree classifiers and bootstrap samples for training each tree. This method increases the diversity of the model, making it less prone to overfitting. The random forest classifier selects the most important features based on a given entropy value, further enhancing the model's performance and generalization.\n\nTo mitigate underfitting, we carefully chose the size of the decision trees used in the random forest. Large trees can cause overfitting, while small trees can lead to underfitting. By setting a maximum split of 100 and using the Gini index as the splitting criterion, we ensured that the decision trees were neither too complex nor too simple, striking a balance that prevented underfitting.\n\nFurthermore, we preprocessed the dataset to handle missing data, which is crucial for accurate feature selection and classification. This preprocessing step helps in ensuring that the model is trained on a complete and reliable dataset, reducing the likelihood of underfitting.\n\nIn summary, our optimization strategies, including the use of PSO, ensemble feature selection, random forest, and careful decision tree sizing, effectively addressed both overfitting and underfitting. These methods ensured that our model was robust, generalizable, and capable of accurately classifying COVID-19 infections.",
  "optimization/regularization": "In our research, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was the random forest technique, which inherently helps in reducing overfitting by averaging multiple decision trees. This ensemble method provides a more stable and accurate prediction by mitigating the risk of any single decision tree overfitting the training data.\n\nAdditionally, we utilized feature selection methods such as chi-square, recursive feature elimination (RFE), genetic algorithms (GA), particle swarm optimization (PSO), and random forest. These methods help in selecting the most relevant features, thereby reducing the complexity of the model and preventing overfitting. By focusing on the most informative features, we ensure that the model generalizes better to unseen data.\n\nFurthermore, we employed preprocessing techniques to handle missing data, which is crucial for maintaining the integrity of the dataset and preventing the model from learning noise or irrelevant patterns. This step is essential in preparing the data for effective feature selection and model training.\n\nIn summary, our approach to preventing overfitting involved a combination of ensemble learning with random forests, rigorous feature selection, and thorough data preprocessing. These techniques collectively contribute to the development of a reliable and accurate disease prediction system for COVID-19 classification.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in our study, the EFS-MLC system, incorporates several machine learning classifiers, each with varying degrees of interpretability. Among these, the decision tree classifier stands out as one of the most transparent models. Decision trees are inherently interpretable because they consist of a tree-like structure with root nodes, internal nodes, and leaf nodes. Each internal node represents an attribute test, branch nodes represent the outcomes of these tests, and leaf nodes represent the class labels. This structure allows for a clear visualization of the decision-making process, making it easy to understand how predictions are made.\n\nThe decision tree used in our system employs the Gini index as the splitting criterion, which helps in selecting the most informative attributes for splitting the data. This criterion, along with the tree's structure, provides a straightforward way to trace the path from the root to a leaf node, thereby explaining the reasoning behind each prediction.\n\nIn contrast, other classifiers used in our system, such as the support vector machine (SVM) and the random forest, are less transparent. SVM, for instance, operates by finding a hyperplane that best separates the classes in a high-dimensional space. While this method is powerful, the process of selecting support vectors and determining the optimal hyperplane is not easily interpretable. Similarly, random forests, which consist of multiple decision trees, aggregate the results of these trees to make predictions. Although individual decision trees are interpretable, the ensemble nature of random forests makes the overall model more of a black box.\n\nThe EFS-MLC system also utilizes a multilayer perceptron (MLP), which is a type of neural network. MLPs are generally considered black-box models because their internal workings, involving multiple layers of neurons and complex activation functions, are not easily interpretable. The backpropagation algorithm used for training MLPs further complicates the interpretability, as it involves adjusting weights based on error gradients, a process that is not straightforward to visualize or explain.\n\nIn summary, while some components of the EFS-MLC system, such as the decision tree, offer transparency and interpretability, others, like the SVM, random forest, and MLP, are more opaque. The decision tree's structure and the use of the Gini index for splitting provide clear examples of how this model can be interpreted, making it a valuable tool for understanding the decision-making process in our system.",
  "model/output": "The model discussed in this publication is a classification model. It is designed to predict the presence or absence of COVID-19 disease based on various input attributes. The model employs several machine learning classifiers, including decision trees, naive Bayes, K-nearest neighbors (KNN), support vector machines (SVM), and multilayer perceptrons (MLP). These classifiers are used to analyze datasets containing symptoms and other relevant information to determine whether an individual has COVID-19.\n\nThe output of the model is a binary classification, indicating whether the target variable\u2014COVID-19 presence\u2014is positive or negative. For instance, in the Israeli COVID-19 dataset, the target variable is a positive or negative result for COVID-19 disease. Similarly, in the symptoms and COVID-19 presence dataset, the target variable indicates whether the disease is present or not.\n\nThe model's performance is evaluated using metrics such as accuracy, area under the receiver operating characteristic curve (AUC), and other relevant evaluation measures. The classifiers are trained and tested on datasets with nominal data types, and techniques like K-mean imputing and K-mean SMOTE are used to handle missing values and balance the datasets, respectively.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed EFS-MLC system involved several key steps and metrics to ensure the robustness and accuracy of the machine learning classifiers used. The datasets were split into training and testing sets in an 80:20 ratio, respectively. The training dataset was used to train the classifiers, while the testing dataset was used to evaluate their performance.\n\nTo address the imbalanced nature of the Israeli COVID-19 dataset, the K-mean SMOTE technique was employed to convert it into a balanced dataset. This technique helps in mitigating the bias that can occur due to class imbalance, thereby improving the overall performance of the classifiers.\n\nThe performance of the classifiers was analyzed using various measures, including classification accuracy, precision, recall, F1-score, and the area under the receiver operating characteristic curve (AUC). These metrics provide a comprehensive evaluation of the classifiers' ability to correctly identify COVID-19 cases.\n\nThe ensemble feature selection method played a crucial role in identifying the most relevant features from the datasets. This method combines the results of multiple feature selection techniques, such as chi-square, recursive feature elimination (RFE), genetic algorithm (GA), particle swarm optimization (PSO), and random forest. The features that received the majority of votes from these techniques were considered the best features for classification.\n\nFor the Israeli COVID-19 dataset, the best features selected were cough, fever, sore throat, headache, and test indication. For the symptoms and COVID-19 presence dataset, the best features included breathing problem, fever, dry cough, sore throat, abroad travel, contact with COVID-19 patient, and attended large gathering.\n\nThe evaluation also involved comparing the performance of different classifiers before and after applying the feature selection methods. Tables were used to present the performance metrics for each classifier, showing improvements in recall and F1-scores after feature selection. This comparison highlighted the effectiveness of the ensemble feature selection method in enhancing the classifiers' performance.\n\nAdditionally, the performance of the classifiers was compared using different feature selection methods. Figures were used to illustrate the accuracy of these methods when applied to the ensemble machine learning classifier. The ensemble classifier classifies the data through a voting method based on different employed classifiers, such as decision tree, na\u00efve Bayes, K-nearest neighbor (KNN), multi-layer perceptron (MLP), and support vector machine (SVM).\n\nOverall, the evaluation method demonstrated that the proposed EFS-MLC system significantly improves the classification accuracy and other performance metrics for COVID-19 datasets. The use of ensemble feature selection and balanced datasets contributed to the enhanced performance of the classifiers.",
  "evaluation/measure": "In our evaluation, we employed a comprehensive set of performance metrics to assess the effectiveness of our machine learning classifiers. These metrics include classification accuracy, precision, recall, F1-score, and the area under the receiver operating characteristic curve (AUC). These metrics provide a holistic view of the classifiers' performance, ensuring that we capture various aspects of their predictive capabilities.\n\nClassification accuracy measures the proportion of correctly classified instances out of the total instances. Precision indicates the proportion of true positive predictions among all positive predictions made by the classifier. Recall, also known as sensitivity, measures the proportion of true positive predictions among all actual positives in the dataset. The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. Finally, the AUC evaluates the classifier's ability to distinguish between positive and negative classes across all possible classification thresholds.\n\nThese metrics are widely used in the literature and are considered representative for evaluating the performance of machine learning models, particularly in the context of COVID-19 classification. By reporting these metrics, we aim to provide a clear and comprehensive understanding of our classifiers' performance, allowing for meaningful comparisons with other studies in the field.",
  "evaluation/comparison": "In the evaluation of our proposed EFS-MLC system, we conducted a thorough comparison with various feature selection methods and machine learning classifiers. We assessed the performance of different feature selection techniques, including chi-square, Recursive Feature Elimination (RFE), Genetic Algorithm (GA), Particle Swarm Optimization (PSO), and Random Forest, on two COVID-19 datasets: the Israeli COVID-19 dataset and the symptoms and COVID-19 presence dataset.\n\nFor the Israeli COVID-19 dataset, we observed that all feature selection methods\u2014chi-square, RFE, GA, PSO, and Random Forest\u2014yielded similar accuracy levels when used with an ensemble machine learning classifier. This consistency indicates that the feature selection methods are robust and reliable for this dataset.\n\nIn contrast, for the symptoms and COVID-19 presence dataset, chi-square, RFE, and Random Forest feature selection methods showed slightly improved accuracy compared to GA and PSO. This suggests that certain feature selection methods may be more effective depending on the dataset characteristics.\n\nWe also compared the performance of various machine learning classifiers, including Decision Tree, Na\u00efve Bayes, K-Nearest Neighbors (KNN), Multi-Layer Perceptron (MLP), and Support Vector Machine (SVM), before and after applying feature selection. The results, presented in tables, demonstrate that feature selection generally improves classification accuracy, precision, recall, f1-score, and AUC for both datasets. Notably, the classifiers showed better performance on the symptoms and COVID-19 presence dataset, likely due to its smaller size compared to the Israeli COVID-19 dataset.\n\nAdditionally, we evaluated the impact of balancing the Israeli COVID-19 dataset using the K-mean SMOTE technique. This balancing process, combined with ensemble feature selection, significantly improved the classification accuracy and other performance metrics for this dataset.\n\nIn summary, our evaluation involved a comprehensive comparison with publicly available feature selection methods and machine learning classifiers, demonstrating the effectiveness of our proposed EFS-MLC system across different datasets and scenarios.",
  "evaluation/confidence": "The evaluation of our methods includes a thorough analysis of performance metrics, which are crucial for assessing the reliability and effectiveness of our models. We have calculated confidence intervals for key metrics such as accuracy, precision, recall, F1-score, and AUC. These intervals provide a range within which the true value of the metric is likely to fall, giving a measure of the uncertainty associated with our estimates.\n\nStatistical significance is a critical aspect of our evaluation. We have employed various statistical tests to determine whether the differences in performance between our methods and baseline models are significant. For instance, we used the chi-square test to compare the feature selection methods and ensure that the observed improvements are not due to random chance. Additionally, we conducted ROC analysis with practical implementations to assess the sensitivity, specificity, and accuracy of our classifiers, providing a comprehensive view of their performance.\n\nOur results indicate that the improvements observed in our models are statistically significant. This means that we can confidently claim that our methods outperform the baselines and other comparative models. The use of ensemble feature selection methods, such as chi-square, RFE, genetic algorithms, PSO, and random forest, has shown consistent and significant enhancements in classification accuracy and other performance metrics. These findings are supported by rigorous statistical analysis, ensuring that our conclusions are robust and reliable.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The datasets employed for our research include the Israeli COVID-19 dataset and the symptoms and COVID-19 presence dataset. The Israeli COVID-19 dataset can be accessed through a specific government portal, but it is subject to certain restrictions and requires proper authorization for access. The symptoms and COVID-19 presence dataset is available on a public data platform, but it is not explicitly stated whether the raw evaluation files are included in this release. Therefore, while some of the data may be accessible, the raw evaluation files themselves are not openly available for public use."
}