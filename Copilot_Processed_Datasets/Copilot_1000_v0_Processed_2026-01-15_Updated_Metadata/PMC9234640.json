{
  "publication/title": "Identification of hepatic steatosis in living liver donors by machine learning models.",
  "publication/authors": "Lim J, Han S, Lee D, Shim JH, Kim KM, Lim YS, Lee HC, Jung DH, Lee SG, Kim KH, Choi J",
  "publication/journal": "Hepatology communications",
  "publication/year": "2022",
  "publication/pmid": "35377548",
  "publication/pmcid": "PMC9234640",
  "publication/doi": "10.1002/hep4.1921",
  "publication/tags": "- Hepatic steatosis\n- Living liver donors\n- Machine learning models\n- Prediction model\n- Noninvasive variables\n- Logistic regression\n- Random forest\n- Support vector machine\n- Deep neural network\n- Regularized discriminant analysis\n- Mixture discriminant analysis\n- Flexible discriminant analysis\n- Liver biopsy\n- Predonation evaluation\n- Radiologic information\n- Hounsfield units\n- Macrovesicular steatosis\n- Donor selection\n- Transplant outcomes\n- Noncontrast CT scan",
  "dataset/provenance": "The dataset used in this study was sourced from potential living liver donors who underwent donation workup, including percutaneous liver biopsy, in the Republic of Korea between 2016 and 2019. The study population consisted of 1652 participants. The data were divided into two sets: the training set, which included 1165 participants (70.5%), and the test set, which included 487 participants (29.5%). The division was based on the date of the liver biopsy, with the training data set comprising those who underwent workup between January 2016 and January 2019, and the test data set comprising those who underwent workup between February 2019 and December 2019.\n\nThe dataset included baseline demographic variables such as age, sex, and body mass index (BMI). Biochemical tests were also conducted, including measurements of hemoglobin, platelet count, prothrombin time, activated partial thromboplastin time, aspartate aminotransferase, alanine aminotransferase (ALT), alkaline phosphatase, gamma-glutamyltransferase, total bilirubin, direct bilirubin, albumin, protein, creatinine, cholesterol, triglyceride, high-density lipoprotein (HDL) cholesterol, low-density lipoprotein cholesterol, calcium, phosphorus, and fasting glucose. Additionally, CT scans of the abdomen and pelvis were obtained for all potential liver donors as part of the routine predonation evaluation. The radiologic assessment of hepatic steatosis was estimated by measuring the Hounsfield units (HUs) of the liver and spleen using the region-of-interest measurement on nonenhanced phase CT scans.\n\nThe primary outcome of interest was the identification of potential donors with macrovesicular hepatic steatosis, as microvesicular steatosis has not been reported to be associated with graft outcomes. The study aimed to develop a model that could discriminate between potential donors with macrovesicular steatosis \u22645%, who can safely donate their liver without a liver biopsy, and those with macrovesicular steatosis >5%, who require further investigation to ascertain donation adequacy. The dataset has not been used in previous papers or by the community.",
  "dataset/splits": "The dataset was divided into two main splits: the training set and the test set. The training set consisted of 1165 participants, which accounted for 70.5% of the total dataset. The test set comprised 487 participants, making up 29.5% of the total dataset. The participants in the training set underwent predonation evaluation between January 2016 and January 2019, while those in the test set underwent evaluation between February 2019 and December 2019. The baseline characteristics, such as age, sex, BMI, and various biochemical markers, were similar between the two sets, ensuring a representative distribution of data points in each split.",
  "dataset/redundancy": "The dataset used in this study consisted of 1652 participants, which was divided into two sets: the training set and the test set. The training set included 1165 participants (70.5% of the total), while the test set comprised 487 participants (29.5% of the total). The division of the dataset was based on the date of the liver biopsy. Specifically, the training set included participants who underwent the predonation evaluation between January 2016 and January 2019, while the test set included those who underwent the evaluation between February 2019 and December 2019. This temporal split ensured that the training and test sets were independent, reducing the risk of data leakage and ensuring that the model's performance could be evaluated on unseen data.\n\nThe baseline characteristics of the participants in both sets were compared to ensure that they were similar. Most characteristics did not show significant differences between the training and test sets, indicating that the split was representative of the overall population. However, there were statistically significant differences in a few characteristics, such as blood pressure, prothrombin time, and direct bilirubin, creatinine, and calcium levels. Despite these statistical differences, the numerical differences were small and not considered clinically significant.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of medical research. The use of a temporal split is a robust method to ensure independence between training and test sets, which is crucial for validating the model's generalizability. This approach helps in assessing the model's performance on data that was not used during the training phase, providing a more reliable estimate of its real-world applicability.",
  "dataset/availability": "The data used in this study is not publicly available. The study involved potential living liver donors who underwent donation workup, including percutaneous liver biopsy, in the Republic of Korea between 2016 and 2019. The dataset was divided into training and test sets based on the date of liver biopsy, with 70.5% of the data used for training and 29.5% for testing. However, the specific data splits and individual patient data are not released in a public forum. The study results and the prediction model are provided on a website under the name DONATION Model, but the actual dataset remains confidential to protect patient privacy. The model and its performance metrics are available for use and distribution under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs License, which permits non-commercial use and distribution without modifications.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are not new. They are well-established methods in the field of machine learning and statistics. The algorithms employed include random forest (RF), support vector machine (SVM), deep neural network (DNN), regularized discriminant analysis (RDA), mixture discriminant analysis (MDA), flexible discriminant analysis (FDA), and traditional logistic regression.\n\nThe random forest algorithm is based on ensemble learning theory, constructing multiple decision trees during training to make predictions. The support vector machine aims to find a hyperplane in a high-dimensional space that separates data points of different classes with the maximum margin. The deep neural network used is a multilayer perceptron, which consists of input, hidden, and output layers and minimizes a cost function to maximize predictive ability.\n\nThese algorithms were chosen for their proven effectiveness in various classification tasks and their ability to handle different types of data and complexities. The study utilized these established methods to build a prediction model for evaluating macrovesicular steatosis in potential liver donors, focusing on their performance and calibration abilities.\n\nThe algorithms were implemented using standard R packages, such as randomForest for RF, e1071 for SVM, and keras and tensorflow for DNN. The RDA, MDA, and FDA methods were implemented using the mda and klaR packages. The choice of these packages ensures reliability and ease of use, leveraging well-documented and widely-used tools in the statistical and machine learning communities.\n\nThe decision to use these established algorithms rather than developing new ones was driven by the need for robust, validated methods that could effectively address the specific challenges of the study. The focus was on applying these algorithms to a novel medical context\u2014predicting hepatic steatosis in living liver donors\u2014rather than innovating in the algorithmic space. This approach allows for a clear evaluation of the algorithms' performance in a new domain, contributing to the field of medical diagnostics and predictive modeling.",
  "optimization/meta": "The model employed in this study does not function as a meta-predictor. Instead, it utilized various machine learning algorithms independently to predict macrovesicular hepatic steatosis in potential living liver donors. The algorithms used included random forest (RF), support vector machine (SVM), regularized discriminant analysis (RDA), mixture discriminant analysis (MDA), flexible discriminant analysis (FDA), and deep neural network (DNN), along with traditional logistic regression.\n\nEach of these methods was trained and tested separately on the dataset, which was divided into training and test sets based on the date of liver biopsy. The training data set comprised individuals who underwent workup between January 2016 and January 2019, while the test data set included those who underwent workup between February 2019 and December 2019. This division ensured that the training data was independent of the test data, allowing for an unbiased evaluation of model performance.\n\nThe performance of each model was assessed using metrics such as accuracy and the area under the receiver operating curve (AUROC). The logistic regression model ultimately demonstrated the best prediction power and was selected for its favorable calibration and interpretability. The final model did not combine the outputs of multiple machine learning algorithms; rather, it relied on the traditional logistic regression approach for its predictions.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps. Initially, data were obtained from electronic medical records, including demographic variables such as age, sex, and BMI. Biochemical tests were conducted, measuring various parameters like hemoglobin, platelet count, prothrombin time, and liver enzymes. Imaging data from CT scans were also included, specifically the Hounsfield units (HUs) of the liver and spleen.\n\nFor the machine learning models, the data were divided into training and test sets based on the date of liver biopsy. The training set comprised participants who underwent workup between January 2016 and January 2019, while the test set included those from February 2019 to December 2019. This division ensured that the models were trained on historical data and tested on more recent data, providing a robust evaluation of their performance.\n\nThe data were expressed as means \u00b1 standard deviations for continuous variables and as numbers with percentages for categorical variables. A complete case analysis was applied, using 1652 observations for model development. The binary outcome variable, which indicated the presence of macrovesicular hepatic steatosis, was used for discrimination-based algorithms and machine learning models.\n\nFor the deep neural network (DNN), the data were encoded and preprocessed to fit a multilayer perceptron architecture. This involved specifying the number of nodes in each layer, the activation functions, and the optimization parameters. The DNN used a three-layer architecture with one input layer, two hidden layers (each with 50 nodes), and one output layer. The ReLU or sigmoid activation functions were considered for the hidden and output layers. The RMSprop optimizer was used for gradient descent, and binary cross-entropy was specified as the loss function. The batch size and epoch sizes were determined through grid search to optimize model performance.\n\nThe random forest (RF) model utilized ensemble learning theory, constructing multiple decision trees during training. The predicted class was derived from the mode of the predicted classes in each individual decision tree. The support vector machine (SVM) aimed to find a hyperplane in a high-dimensional space that maximally separated the data points of different classes. This approach is robust to high-dimensional data and helps protect models from overfitting.\n\nIn summary, the data encoding and preprocessing involved a combination of demographic, biochemical, and imaging data. The models were trained and tested on distinct datasets, and specific preprocessing steps were applied to fit the requirements of each machine learning algorithm.",
  "optimization/parameters": "In our study, we utilized several input parameters to build and optimize our models for identifying hepatic steatosis. The specific parameters included demographic, laboratory, and imaging variables. Among these, the liver Hounsfield Unit (HU), ALT level, BMI, serum HDL cholesterol level, total cholesterol, age, and glucose level were identified as the most significant predictors.\n\nThe selection of these parameters was driven by their importance scores derived from the random forest model, which highlighted their contributions to predicting the steatosis group. Additionally, logistic regression analysis in the training cohort confirmed these variables as predictive factors for hepatic steatosis.\n\nThe number of parameters used in the final logistic regression model was seven. These parameters were chosen based on their statistical significance and their ability to improve the model's discriminative and calibration abilities. The selection process ensured that the model was statistically stable and justifiable, aligning with our goal of securing as many donor candidates as possible while minimizing unnecessary liver biopsies.",
  "optimization/features": "In the study, a variety of clinical, biochemical, and radiologic features were used as input for the models. These features included demographic variables such as age, sex, and body mass index (BMI). Biochemical tests encompassed measurements like hemoglobin, platelet count, prothrombin time, activated partial thromboplastin time, aspartate aminotransferase, alanine aminotransferase (ALT), alkaline phosphatase, gamma-glutamyltransferase, total bilirubin, direct bilirubin, albumin, protein, creatinine, cholesterol, triglyceride, high-density lipoprotein (HDL) cholesterol, low-density lipoprotein cholesterol, calcium, phosphorus, and fasting glucose. Additionally, radiologic assessments included Hounsfield units (HUs) of the liver and spleen measured from CT scans.\n\nFeature selection was performed using the random forest (RF) model to obtain importance scores of predictive variables. Among the patients\u2019 demographic, laboratory, and imaging variables, the liver HU had the largest contribution to the prediction of the steatosis group, followed by the ALT level, BMI, serum HDL cholesterol level, cholesterol, age, and glucose level. This selection process was conducted using the training set only, ensuring that the test set remained independent for evaluating model performance.",
  "optimization/fitting": "In our study, we employed several methods to address the potential issues of overfitting and underfitting. Given that we used a variety of models, including traditional statistical methods and machine learning algorithms, the approaches to mitigating these issues varied.\n\nFor the regularized discriminant analysis (RDA), which is known to perform well with small sample sizes and a large number of variables, we utilized regularization techniques. These techniques help in shrinking the coefficients of the less important variables, thereby reducing the risk of overfitting. The RDA's robustness against multicollinearity among covariates further aids in preventing overfitting.\n\nThe flexible discriminant analysis (FDA) and mixture discriminant analysis (MDA) were used to handle nonlinear classification schemes and clustered non-normal settings, respectively. These methods produce nonlinear decision boundaries, which can capture complex patterns in the data, thus reducing the risk of underfitting.\n\nMachine learning algorithms such as random forest (RF) and support vector machine (SVM) were also employed. The RF, based on ensemble learning theory, constructs multiple decision trees during training. This ensemble approach helps in reducing overfitting by averaging the predictions of individual trees. The SVM, on the other hand, aims to find a hyperplane in a high-dimensional space that maximizes the margin between classes. This regularization approach helps in protecting the model from overfitting.\n\nThe deep neural network (DNN) used in our study was a multilayer perceptron with one input layer, two hidden layers, and one output layer. To prevent overfitting, we employed techniques such as dropout and early stopping. Dropout randomly sets a fraction of input units to zero at each update during training time, which helps in preventing overfitting. Early stopping monitors the model's performance on a validation set and stops training when the performance starts to degrade, thus avoiding overfitting.\n\nAdditionally, we used cross-validation to ensure that our models generalized well to unseen data. This technique involves splitting the data into training and validation sets multiple times and averaging the results, which helps in assessing the model's performance and preventing both overfitting and underfitting.\n\nIn summary, we utilized a combination of regularization techniques, ensemble methods, and cross-validation to address the issues of overfitting and underfitting in our models. These approaches ensured that our models were robust and generalizable to new data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting, ensuring that our models generalized well to unseen data. One of the key methods used was regularization, particularly in the context of the support vector machine (SVM) algorithm. The SVM inherently includes a regularization parameter that helps to control the trade-off between achieving a low training error and minimizing the model complexity. This regularization approach is crucial for protecting the model from overfitting, especially when dealing with high-dimensional data.\n\nAdditionally, we utilized ensemble learning techniques, such as the random forest (RF) algorithm. The RF constructs multiple decision trees during the training phase and aggregates their predictions to make a final decision. This ensemble approach helps to reduce overfitting by averaging out the errors of individual trees, leading to a more robust and generalizable model.\n\nFor the deep neural network (DNN), we employed techniques like dropout and early stopping. Dropout involves randomly setting a fraction of the input units to zero at each update during training time, which helps to prevent overfitting by ensuring that the network does not become too reliant on any single neuron. Early stopping monitors the model's performance on a validation set and halts the training process when the performance starts to degrade, thereby preventing the model from overfitting to the training data.\n\nFurthermore, we divided our data into training and test sets based on the date of liver biopsy, ensuring that the models were trained on one subset of data and evaluated on a completely separate subset. This approach helps to assess the model's performance on unseen data, providing a more reliable estimate of its generalization capability.\n\nIn summary, we implemented various regularization and ensemble learning techniques to prevent overfitting and enhance the robustness of our models. These methods included the use of regularization parameters in SVM, ensemble learning in RF, dropout and early stopping in DNN, and a clear separation of training and test data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed a multilayer perceptron with the architecture 15/50/50/1, utilizing the rmsprop optimizer and binary cross-entropy as the loss function. The activation functions considered were ReLU and sigmoid. The batch size and epoch sizes were determined through a grid search process. All data analyses were conducted using R software, version 4.0.4, with specific packages such as mda, klaR, e1071, and randomForest for various methods.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the methods and configurations are thoroughly described, allowing for reproducibility. The study adheres to open access terms under the Creative Commons Attribution-NonCommercial-NoDerivs License, which permits use and distribution in any medium, provided the original work is properly cited, the use is non-commercial, and no modifications or adaptations are made. This ensures that the configurations and methods can be accessed and utilized by other researchers for similar studies.",
  "model/interpretability": "The models employed in this study vary in their interpretability, ranging from highly interpretable to more complex, black-box approaches.\n\nThe logistic regression model is one of the most interpretable models used. It provides clear, linear relationships between the input variables and the output, making it easy to understand the contribution of each variable to the prediction. The coefficients in the logistic regression model indicate the direction and strength of the relationship between each predictor and the likelihood of hepatic steatosis.\n\nThe random forest (RF) model, while powerful, is considered a black-box model due to its complexity. It combines the outputs of many decision trees, making it difficult to interpret the exact relationships between variables. However, variable importance scores can be derived from the RF model, which indicate the relative contribution of each variable to the predictions. For instance, liver HU, ALT level, and BMI were identified as the most important predictors of hepatic steatosis.\n\nThe support vector machine (SVM) and deep neural network (DNN) models are also considered black-box models. SVM finds a hyperplane in a high-dimensional space to separate classes, which is not straightforward to interpret. Similarly, DNNs, with their multiple layers and complex interactions, are notoriously difficult to interpret. However, they are highly flexible and capable of capturing intricate patterns in the data.\n\nThe regularized discriminant analysis (RDA), mixture discriminant analysis (MDA), and flexible discriminant analysis (FDA) models offer varying degrees of interpretability. RDA and MDA provide probabilistic interpretations based on Gaussian distributions, making them somewhat interpretable. FDA, which uses nonparametric regression, is more complex but still provides insights into the decision boundaries between classes.\n\nIn summary, while some models like logistic regression offer clear interpretability, others like RF, SVM, and DNN are more opaque. Variable importance scores and probabilistic interpretations can provide some level of transparency in the more complex models.",
  "model/output": "The model is a classification model. It is designed to identify potential liver donors with macrovesicular hepatic steatosis, specifically those with more than 5% steatosis, who require further investigation. The model uses various prediction algorithms, including traditional logistic regression and machine learning methods like random forest, support vector machine, regularized discriminant analysis, mixture discriminant analysis, flexible discriminant analysis, and deep neural network. The output of the model is a binary classification indicating whether a donor has significant steatosis or not. The performance of the model was evaluated using metrics such as accuracy and the area under the receiver operating curve (AUROC) in both training and test datasets. The logistic regression model demonstrated the best prediction power with an accuracy of 80.9% in the test dataset. A cut-off value of 31.1% for the predicted risk of hepatic steatosis was selected, providing a sensitivity of 77.7% and specificity of 81.0%. This model helps in identifying optimal potential living donors by avoiding unnecessary liver biopsies.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for our model is not publicly released. However, we have made our model accessible through a user-friendly web interface. The model can be applied in real-world settings via a website, where users can input several variables for a potential donor to calculate the probability of having hepatic steatosis. This web-based tool is designed to be readily available and easy to use, ensuring that the model's benefits can be widely utilized without the need for additional software installations or technical expertise. The website is hosted at https://hanseungbong.shinyapps.io/shiny_app_up/ under the name DONATION Model. The model is provided under the terms of the Creative Commons Attribution-NonCommercial-NoDerivs License, which permits use and distribution in any medium, provided the original work is properly cited, the use is non-commercial, and no modifications or adaptations are made.",
  "evaluation/method": "The evaluation of the method involved a comprehensive approach to ensure its robustness and generalizability. The study included a total of 1652 participants, who were divided into training and test datasets. Specifically, 1165 participants (70.5%) were assigned to the training dataset, while 487 participants (29.5%) were allocated to the test dataset. This split allowed for the development and validation of various machine learning models.\n\nThe training dataset comprised subjects who underwent predonation evaluation between January 2016 and January 2019, while the test dataset included those who underwent evaluation between February 2019 and December 2019. This temporal separation helped in assessing the model's performance on unseen data, simulating a real-world scenario.\n\nSeveral machine learning algorithms were employed, including logistic regression, random forest (RF), support vector machine (SVM), and deep neural network (DNN). The RF algorithm, based on ensemble learning, constructs multiple decision trees during training, with the final prediction derived from the mode of the individual tree predictions. This method is effective in handling both simple and complex classification functions.\n\nThe SVM algorithm aims to find a hyperplane in a high-dimensional space that maximizes the margin between different classes, making it robust for high-dimensional data and reducing the risk of overfitting. The DNN, specifically a multilayer perceptron, was used for its flexibility and success in various domains, including text, image, voice, and video analysis. The neural network comprised one input layer, two hidden layers, and one output layer, optimized using the rmsprop gradient descent method and binary cross-entropy loss function.\n\nThe evaluation metrics included classification accuracy, which was used to assess the performance of the models. The statistical significance was set at p < 0.05, ensuring that the results were reliable. The models were built and validated using over 25 variables from the predonation evaluation, incorporating demographic, laboratory, and radiologic information. The radiologic information, specifically the liver Hounsfield units (HU) from noncontrast CT scans, played a crucial role in the model's performance.\n\nIn summary, the method was evaluated using a robust dataset split, various machine learning algorithms, and comprehensive evaluation metrics. The inclusion of radiologic information and the use of ensemble learning techniques ensured the model's accuracy and reliability in identifying hepatic steatosis in potential living liver donors.",
  "evaluation/measure": "In the evaluation of our models, we reported several key performance metrics to comprehensively assess their effectiveness in identifying hepatic steatosis. The primary metrics we focused on were accuracy and the area under the receiver operating curve (AUROC). Accuracy was calculated as the proportion of true results (both true positives and true negatives) among the total number of cases examined. This metric provided a straightforward measure of how often the models correctly predicted the presence or absence of hepatic steatosis.\n\nThe AUROC, on the other hand, offered a more nuanced evaluation by considering the trade-off between the true positive rate and the false positive rate across different threshold settings. A higher AUROC indicates better model performance in distinguishing between the steatosis and non-steatosis groups. We also reported the 95% confidence intervals for the AUROC to provide a sense of the precision of these estimates.\n\nIn addition to these metrics, we examined the calibration of our models using calibration charts and the Hosmer-Lemeshow test. Calibration charts visually depicted the agreement between the predicted probabilities of steatosis and the observed outcomes, helping us assess whether the models' predictions were well-calibrated. The Hosmer-Lemeshow test provided a statistical measure of this agreement, with p-values indicating the goodness of fit.\n\nThese performance metrics are widely recognized and used in the literature for evaluating classification models, particularly in medical and biological research. They provide a robust framework for comparing the performance of different models and ensuring that our findings are both reliable and reproducible. By reporting accuracy, AUROC, and calibration metrics, we aimed to offer a comprehensive view of our models' strengths and limitations, thereby contributing to the broader scientific understanding of hepatic steatosis identification.",
  "evaluation/comparison": "In our study, we employed a variety of methods to identify hepatic steatosis in potential living liver donors. These methods included both traditional statistical approaches and advanced machine learning algorithms. We utilized regularized discriminant analysis (RDA), flexible discriminant analysis (FDA), and mixture discriminant analysis (MDA) for discriminant-based algorithms. Additionally, we implemented traditional logistic regression alongside three machine learning algorithms: random forest (RF), support vector machine (SVM), and deep neural network (DNN).\n\nThe RDA is particularly effective in settings with small sample sizes and a large number of variables, making it robust against multicollinearity among covariates. In contrast, the FDA addresses nonlinear classification schemes through multivariate nonparametric regression. The MDA models classes as mixtures of Gaussian distributions, which is beneficial for clustered non-normal settings and produces nonlinear decision boundaries.\n\nFor machine learning, the RF algorithm, based on ensemble learning theory, constructs multiple decision trees during training. The predicted class is determined by the mode of the predicted classes from individual trees, allowing it to learn both simple and complex classification functions. The SVM aims to find a hyperplane in high-dimensional space that maximizes the margin between data points of different classes, making it robust for high-dimensional data and efficient in learning complex classification functions. The DNN, specifically a multilayer perceptron, was used for its flexibility and success in various domains. It minimizes a cost function to maximize predictive ability, with the architecture consisting of one input layer, two hidden layers, and one output layer.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets. However, we did compare the performance of these diverse models within our own dataset, which included over 1600 potential living liver donors. The models were evaluated based on their accuracy and area under the receiver operating curve (AUROC) in both training and test datasets. The RF model showed the highest performance in the training dataset, while the logistic and RDA models performed best in the test dataset. This comprehensive evaluation allowed us to select the most effective model for identifying hepatic steatosis.",
  "evaluation/confidence": "The evaluation of our models included several performance metrics, and we ensured that these metrics were robust and statistically significant. For instance, the area under the receiver operating curve (AUROC) was reported with 95% confidence intervals, providing a clear indication of the reliability of our results. The confidence intervals for the AUROC of different models, such as the random forest (RF) and logistic regression models, were narrow, indicating high precision in our estimates.\n\nStatistical significance was a key consideration in our analysis. We used a p-value threshold of less than 0.05 to determine significance. This threshold was applied to various comparisons, including the differences in baseline characteristics between the training and test datasets, as well as the differences in laboratory values between participants with and without hepatic steatosis. For example, the differences in ALT, total cholesterol, glucose, and HDL cholesterol levels between the steatosis and nonsteatosis groups were all statistically significant with p-values less than 0.01.\n\nIn terms of model performance, the RF model showed the highest accuracy in the training dataset, achieving 100% accuracy. However, in the test dataset, the logistic regression and regularized discriminant analysis (RDA) models demonstrated the highest accuracy at 80.9%. The AUROC values for these models were also high, with the logistic regression and Fisher discriminant analysis (FDA) models achieving the highest AUROC of 0.87. These results were statistically significant and indicated that our models performed well in identifying hepatic steatosis.\n\nAdditionally, the calibration of our models was assessed using the Hosmer-Lemeshow test, which showed adequate agreement between predicted and observed risks in both the training and test cohorts. The p-values for these tests were 0.50 and 0.19, respectively, further supporting the reliability of our models. Overall, the performance metrics and statistical significance of our results provide strong evidence that our models are effective in identifying hepatic steatosis in potential living liver donors.",
  "evaluation/availability": "Not applicable."
}