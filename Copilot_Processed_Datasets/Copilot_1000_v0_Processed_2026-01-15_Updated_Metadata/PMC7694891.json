{
  "publication/title": "Supervised Machine Learning Models for Prediction of COVID-19 Infection using Epidemiology Dataset.",
  "publication/authors": "Muhammad LJ, Algehyne EA, Usman SS, Ahmad A, Chakraborty C, Mohammed IA",
  "publication/journal": "SN computer science",
  "publication/year": "2021",
  "publication/pmid": "33263111",
  "publication/pmcid": "PMC7694891",
  "publication/doi": "10.1007/s42979-020-00394-7",
  "publication/tags": "- Machine Learning\n- COVID-19\n- Predictive Modeling\n- Epidemiology\n- Data Mining\n- Public Health\n- Artificial Intelligence\n- Healthcare Management\n- Supervised Learning\n- Pandemic Prediction",
  "dataset/provenance": "The dataset used in this study is an epidemiology dataset of positive and negative COVID-19 cases from Mexico. This dataset was reported by the General Directorate of Epidemiology, Secretariat of Health in Mexico, and is available on their official website. The data originates from the Viral Respiratory Diseases Epidemiological Surveillance System, which is reported by 475 viral respiratory disease monitoring units (USMER) throughout the country.\n\nThe dataset contains lab Reverse Transcription Polymerase Chain Reaction (RT-PCR) testing results for COVID-19 cases in Mexico. It comprises 263,007 instances or records, each with 41 features. These features include demographic and clinical data, as well as the results of RT-PCR tests for COVID-19 in patients diagnosed with viral respiratory conditions.\n\nFor this particular work, only two demographic features (age and sex) and eight clinical features (pneumonia, diabetes, asthma, hypertension, cardiovascular diseases, obesity, chronic kidney diseases, and tobacco use) were considered, along with the RT-PCR test result. The dataset has been encoded such that 1 represents positive cases and 0 represents negative cases for both the COVID-19 test results and the sex data feature (where 1 indicates male and 0 indicates female). The dataset is complete, with no missing values.",
  "dataset/splits": "The dataset was partitioned into two splits: a training set and a testing set. The training set comprised 80% of the dataset, while the testing set consisted of the remaining 20%. This split was used to train and evaluate the machine learning models developed to predict COVID-19 infection. The dataset originally contained 263,007 instances or records. Therefore, approximately 210,406 records were used for training, and around 52,601 records were used for testing. This distribution ensured that the models were trained on a substantial amount of data while also having a significant portion reserved for evaluating their performance.",
  "dataset/redundancy": "The dataset used in this study was split into training and testing sets to develop and evaluate the machine learning models. The dataset was partitioned such that 80% of the data was used for training the models, while the remaining 20% was reserved for testing. This split ensures that the training and test sets are independent, allowing for an unbiased evaluation of the models' performance.\n\nTo enforce the independence of the training and test sets, standard practices were followed. The dataset was randomly shuffled before splitting to ensure that the distribution of data points in both sets is representative of the overall dataset. This random shuffling helps to mitigate any potential biases that might arise from the order of the data points.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in the context of epidemiological studies. The dataset contains a large number of instances, specifically 263,007 records, which provides a robust foundation for training and testing machine learning models. The features included in the dataset are carefully selected to cover demographic and clinical aspects relevant to COVID-19 cases, ensuring that the models can capture a wide range of factors influencing the infection.\n\nThe dataset was obtained from the Viral Respiratory Diseases Epidemiological Surveillance System in Mexico, which is a reliable source of epidemiological data. This ensures that the data is of high quality and representative of the population under study. The features were translated into English and encoded appropriately to facilitate the machine learning processes. For instance, the RT-PCR test results were encoded as 1 for positive and 0 for negative, and similar encoding was done for other features like sex, pneumonia, diabetes, and so on. This standardization helps in maintaining consistency and accuracy in the model training and evaluation processes.",
  "dataset/availability": "The dataset used in this study is publicly available. It was reported by the General Directorate of Epidemiology, Secretariat of Health in Mexico and can be accessed on their official website. The dataset originates from the Viral Respiratory Diseases Epidemiological Surveillance System, which is maintained by 475 viral respiratory disease monitoring units (USMER) across the country.\n\nThe dataset contains lab Reverse Transcription Polymerase Chain Reaction (RT-PCR) testing results for COVID-19 cases in Mexico. It includes 263,007 instances or records with 41 features, encompassing demographic and clinical data as well as RT-PCR test results for COVID-19 in patients with a viral respiratory diagnosis.\n\nThe dataset was prepared by translating the feature names from Spanish to English and encoding specific values for clarity. For instance, the RT-PCR test results were encoded as 1 for positive and 0 for negative, and sex data was encoded as 1 for male and 0 for female. The dataset has no missing values, ensuring completeness for analysis.\n\nThe dataset was partitioned into training and testing sets, with 80% of the data used for training and the remaining 20% for testing. This split was enforced to evaluate the performance of the machine learning models developed in this study.\n\nThe dataset is available for public use, allowing other researchers to replicate and build upon the findings presented in this work. The specific license details for the dataset can be found on the official website of the General Directorate of Epidemiology, Secretariat of Health in Mexico.",
  "optimization/algorithm": "The machine-learning algorithm class used in this work is supervised learning. Specifically, the algorithms employed include decision tree, logistic regression, naive Bayes, support vector machine, and artificial neural network. These are well-established techniques in the field of machine learning and have been extensively used for various predictive modeling tasks.\n\nThe algorithms used are not new; they are widely recognized and have been applied in numerous studies and applications. The decision to use these specific algorithms was likely driven by their proven effectiveness in handling labeled datasets and their ability to provide accurate predictions for complex problems, such as diagnosing diseases.\n\nThe choice of algorithms was tailored to the specific problem of developing predictive models for COVID-19 infection using an epidemiology labeled dataset. These algorithms were selected because they are robust and have been successfully applied in similar contexts, making them suitable for the task at hand.\n\nThe decision to use these algorithms in this particular study, rather than publishing them in a machine-learning journal, is likely due to the focus of the research. The primary goal was to apply these algorithms to a specific real-world problem\u2014predicting COVID-19 infection\u2014rather than developing new machine-learning techniques. The study aims to demonstrate the practical application of these algorithms in a critical healthcare context, showcasing their utility and effectiveness in addressing pressing public health challenges.",
  "optimization/meta": "The model developed in this work does not use data from other machine-learning algorithms as input. Instead, it directly utilizes an epidemiology dataset of positive and negative COVID-19 cases from Mexico. This dataset includes demographic and clinical features such as age, sex, pneumonia, diabetes, asthma, hypertension, cardiovascular diseases, obesity, chronic kidney diseases, tobacco use, and RT-PCR test results.\n\nThe machine learning techniques employed in this study are supervised learning algorithms, specifically decision tree, logistic regression, naive Bayes, support vector machine (SVM), and artificial neural network (ANN). These algorithms were used to develop predictive models for COVID-19 infection. The dataset was partitioned into training and testing sets, with 80% of the data used for training and the remaining 20% for testing.\n\nThe training data is independent, as it was carefully partitioned from the overall dataset to ensure that the models were trained and tested on separate subsets. This approach helps in evaluating the models' performance accurately and ensures that the results are not biased by overlapping data.\n\nThe models were evaluated using performance metrics such as accuracy, sensitivity, and specificity. These metrics provide a comprehensive assessment of the models' efficiency and quality in predicting COVID-19 infection. The accuracy metric, in particular, indicates the percentage of dataset instances correctly predicted by the models.",
  "optimization/encoding": "The dataset used in this study was an epidemiology dataset of positive and negative COVID-19 cases from Mexico. The dataset contained 263,007 instances with 41 features, including demographic and clinical data, as well as results of RT-PCR tests for COVID-19 in patients with a viral respiratory diagnosis.\n\nThe dataset was initially in Spanish, so the feature names were translated into English for consistency. For this work, only two demographic features (age and sex) and eight clinical features (pneumonia, diabetes, asthma, hypertension, cardiovascular diseases, obesity, chronic kidney diseases, and tobacco use) were considered, along with the RT-PCR test result.\n\nThe original dataset encoded positive cases as 1 and negative cases as 2. For this study, the encoding was modified to 1 for positive and 0 for negative across all dataset instances. Similarly, the sex feature was encoded as 1 for male and 0 for female.\n\nThe dataset did not have any missing values, which simplified the preprocessing steps. The features were ready for use in the supervised machine learning algorithms without further imputation or handling of missing data.\n\nThe dataset was then analyzed to understand its profile, including minimum, maximum, mean, and standard deviation values for each feature. This analysis helped in understanding the distribution and characteristics of the data, which is crucial for the effective training of machine learning models.\n\nIn summary, the data encoding involved translating feature names, selecting relevant features, modifying the encoding scheme for positive and negative cases, and encoding the sex feature. The dataset was then analyzed to ensure it was ready for use in the machine learning algorithms.",
  "optimization/parameters": "In our study, we utilized a dataset containing 11 input parameters for developing predictive models for COVID-19 infection. These parameters include age, sex, pneumonia, diabetes, asthma, hypertension, cardiovascular diseases (CVDs), obesity, chronic kidney diseases (CKDs), tobacco use, and the RT-PCR test result.\n\nThe selection of these parameters was driven by their relevance to COVID-19 outcomes as indicated by existing literature and their availability in the epidemiology dataset. Age and sex are fundamental demographic features, while the other parameters represent various clinical conditions and risk factors that have been associated with COVID-19 severity and mortality. The dataset was carefully curated to include only these relevant features, ensuring that the model could effectively capture the relationships between these factors and the likelihood of COVID-19 infection.\n\nThe dataset underwent thorough preprocessing, including translation of feature names, encoding of categorical variables, and normalization of values. This preparation ensured that the data was in a suitable format for training machine learning models. The final dataset consisted of 263,007 instances, providing a robust foundation for model development and evaluation.",
  "optimization/features": "In the optimization phase of our study, we utilized a subset of features from the original dataset for developing our predictive models. The dataset initially contained 41 features, but we performed feature selection to focus on the most relevant ones for predicting COVID-19 infection.\n\nWe selected a total of 10 features as input for our models. These features include two demographic variables: age and sex. The remaining eight features are clinical variables: pneumonia, diabetes, asthma, hypertension, cardiovascular diseases, obesity, chronic kidney diseases, and tobacco use. Additionally, the RT-PCR test result for COVID-19 was used as the target variable.\n\nFeature selection was indeed performed to ensure that only the most relevant features were included in the model development process. This step is crucial for improving the model's performance and interpretability. The selection of these features was based on domain knowledge and their potential relevance to COVID-19 infection.\n\nTo maintain the integrity of the model evaluation, feature selection was conducted using the entire dataset before splitting it into training and testing sets. This approach ensures that the testing set remains unseen during the feature selection process, preventing data leakage and providing a more accurate assessment of the model's generalizability.",
  "optimization/fitting": "The fitting method employed in this study involved the use of supervised machine learning algorithms, specifically decision tree, logistic regression, naive Bayes, support vector machine (SVM), and artificial neural network (ANN). These algorithms were applied to an epidemiology dataset containing 263,007 instances with 41 features, which were reduced to 10 relevant features for the purpose of this work.\n\nThe dataset was partitioned into training and testing sets, with 80% of the data used for training and the remaining 20% for testing. This partitioning helps in ensuring that the model generalizes well to unseen data, thereby mitigating the risk of overfitting. Overfitting was further addressed by evaluating the models using multiple performance metrics, including accuracy, sensitivity, and specificity. These metrics provide a comprehensive assessment of the model's performance, ensuring that it does not merely memorize the training data but can generalize to new, unseen data.\n\nTo rule out underfitting, the models were developed using a variety of algorithms, each with its own strengths and weaknesses. This diversity in algorithm selection helps in capturing different patterns in the data, reducing the likelihood of underfitting. Additionally, the correlation coefficient analysis between the dependent and independent features was conducted to ensure that there was a meaningful relationship between the features and the target variable. This analysis helped in selecting the most relevant features, thereby improving the model's ability to fit the data adequately.\n\nThe use of cross-validation techniques, such as 10-fold cross-validation in related studies, further ensures that the models are robust and not prone to underfitting. By training and testing the models on different subsets of the data, cross-validation helps in assessing the model's performance more reliably.\n\nIn summary, the fitting method involved careful partitioning of the dataset, the use of multiple performance metrics, and the selection of diverse algorithms. These steps collectively help in ruling out both overfitting and underfitting, ensuring that the models developed are reliable and generalizable.",
  "optimization/regularization": "Not applicable",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a blackbox model. The decision tree model, which was found to be the best in terms of accuracy, provides a transparent and interpretable structure. This model clearly indicates the most important features influencing the prediction of COVID-19 infection. For instance, age is identified as the most significant feature, with individuals above the age of 45 being more prone to infection. Additionally, the presence of certain clinical conditions such as pneumonia, chronic kidney diseases, cardiovascular diseases, diabetes, asthma, obesity, and hypertension are also highlighted as important factors. Gender is another crucial feature, with males being more susceptible to COVID-19 infection than females. Furthermore, tobacco use is noted as a high-risk factor. These insights make the decision tree model particularly useful for healthcare workers, as it aids in the diagnosis of suspected COVID-19 patients and supplements RT-PCR testing, thereby reducing the burden on healthcare systems.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict COVID-19 infection status based on various demographic and clinical features. The model uses supervised learning algorithms, including decision tree, logistic regression, naive Bayes, support vector machine (SVM), and artificial neural network (ANN). These algorithms are trained to classify instances into two categories: COVID-19 positive or negative. The performance of these models is evaluated using metrics such as accuracy, sensitivity, and specificity, which are crucial for assessing the effectiveness of classification models in medical diagnostics. The decision tree model, in particular, demonstrated the highest accuracy at 94.99%, making it the most effective among the models developed for this classification task.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the developed models was conducted using three primary performance metrics: accuracy, sensitivity, and specificity. These metrics were chosen to assess the efficiency and quality of the models in predicting COVID-19 infection status.\n\nAccuracy was measured as the percentage of correctly predicted instances out of the total instances in the dataset. This metric provides an overall indication of the model's performance. The formula used for accuracy is:\n\nAccuracy = (tp + tn) / (tp + tn + fn + fp)\n\nwhere tp represents true positives, tn represents true negatives, fp represents false positives, and fn represents false negatives.\n\nSensitivity, also known as recall, measures the proportion of actual positive cases that were correctly identified by the model. It is crucial for understanding how well the model can detect COVID-19 positive patients. The formula for sensitivity is:\n\nSensitivity = tp / (tp + fn)\n\nSpecificity, on the other hand, measures the proportion of actual negative cases that were correctly identified. This metric is important for assessing the model's ability to correctly identify COVID-19 negative patients. The formula for specificity is:\n\nSpecificity = tn / (tn + fp)\n\nThe dataset used for this study was partitioned into training and testing sets, with 80% of the data used for training the models and the remaining 20% used for testing. This split ensures that the models are evaluated on unseen data, providing a more reliable assessment of their generalizability.\n\nFive different machine learning classification algorithms were employed to develop the predictive models: decision tree, logistic regression, naive Bayes, support vector machine (SVM), and artificial neural network (ANN). Each model was evaluated using the aforementioned metrics to determine their performance.\n\nThe decision tree model achieved the highest accuracy at 94.99%, making it the best-performing model among those developed. However, other models like SVM and ANN showed superior sensitivity, indicating their strength in correctly identifying positive COVID-19 cases. The performance results of all models are summarized in a table, providing a clear comparison of their accuracy, sensitivity, and specificity.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our machine learning models in predicting COVID-19 infection. The primary metrics we reported are accuracy, sensitivity, and specificity.\n\nAccuracy is a fundamental metric that indicates the proportion of true results (both true positives and true negatives) among the total number of cases examined. It provides a general measure of how often the model is correct. The formula for accuracy is given by the sum of true positives (tp) and true negatives (tn) divided by the total number of cases (tp + tn + fn + fp), where fn is false negatives and fp is false positives.\n\nSensitivity, also known as recall or true positive rate, measures the proportion of actual positives that are correctly identified by the model. It is crucial for understanding how well the model can detect COVID-19 positive cases. Sensitivity is calculated as the ratio of true positives (tp) to the sum of true positives and false negatives (tp + fn).\n\nSpecificity, or the true negative rate, assesses the proportion of actual negatives that are correctly identified by the model. This metric is important for evaluating the model's ability to correctly identify COVID-19 negative cases. Specificity is determined by the ratio of true negatives (tn) to the sum of true negatives and false positives (tn + fp).\n\nThese metrics collectively provide a comprehensive evaluation of the models' performance. Accuracy gives an overall sense of the model's correctness, while sensitivity and specificity offer insights into the model's ability to correctly identify positive and negative cases, respectively. This set of metrics is widely used in the literature for evaluating classification models, particularly in medical diagnostics, making our evaluation representative and robust.",
  "evaluation/comparison": "In the evaluation of our models, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, we focused on developing and evaluating several supervised machine learning models using an epidemiology dataset specific to COVID-19 cases in Mexico. The models we developed included decision tree, logistic regression, naive Bayes, support vector machine (SVM), and artificial neural network (ANN).\n\nFor the comparison, we evaluated the performance of these models based on accuracy, sensitivity, and specificity. The decision tree model emerged as the best performer in terms of accuracy, achieving 94.99%. However, when considering sensitivity, which measures the percentage of COVID-19 positive patients correctly identified by the models, the SVM model showed the highest sensitivity at 93.34%.\n\nWhile we did not compare our models to simpler baselines explicitly, the evaluation metrics provided a comprehensive assessment of each model's performance. The decision tree model's superior accuracy suggests it is effective for predicting COVID-19 infection, while the SVM model's high sensitivity indicates its strength in correctly identifying positive cases.\n\nThe dataset used for this study was obtained from the General Directorate of Epidemiology, Secretariat of Health in Mexico, and contained 263,007 instances with 41 features. We preprocessed the dataset by translating feature names into English and encoding categorical variables. The dataset was then split into training and testing sets, with 80% used for training and 20% for testing.\n\nIn summary, our evaluation focused on the internal comparison of different machine learning models using a specific dataset, providing insights into their relative performance in predicting COVID-19 infection.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe performance metrics presented in this study include accuracy, sensitivity, and specificity for various machine learning models. However, confidence intervals for these metrics are not explicitly provided. The results indicate that the decision tree model achieved the highest accuracy at 94.99%, followed closely by logistic regression and naive Bayes models. The support vector machine (SVM) model showed the highest sensitivity at 93.34%, while the decision tree model also performed well in terms of specificity at 93.22%.\n\nWhile the performance differences among the models are notable, statistical significance tests to confirm the superiority of one model over others are not detailed. The dataset used for this study is substantial, comprising 263,007 instances, which provides a robust foundation for the models' training and testing. The models were evaluated using a split of 80% training data and 20% testing data, ensuring a comprehensive assessment of their predictive capabilities.\n\nThe weak positive correlation coefficients between the dependent and independent features suggest that while there are relationships, they are not strong predictors individually. This could imply that the models' performance is more reliant on the collective interaction of features rather than any single feature.\n\nIn summary, while the performance metrics are promising, the lack of confidence intervals and statistical significance tests means that the claims of one model's superiority over others are not definitively proven. Further statistical analysis would be beneficial to strengthen the confidence in these results.",
  "evaluation/availability": "The raw evaluation files used in this study are not publicly available. The dataset utilized for developing the supervised machine learning models was obtained from the General Directorate of Epidemiology, Secretariat of Health in Mexico, and was made available on their official website. However, the specific evaluation files, such as the performance metrics and model outputs, are not released publicly. The study focuses on the methodology and results of using machine learning algorithms to predict COVID-19 infection based on an epidemiology dataset, but it does not provide access to the raw evaluation files. Therefore, the data and models are not openly accessible for further analysis or replication."
}