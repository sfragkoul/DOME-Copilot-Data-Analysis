{
  "publication/title": "Predictors of ccf-mtDNA reactivity to acute psychological stress identified using machine learning classifiers: A proof-of-concept.",
  "publication/authors": "Trumpff C, Marsland AL, Sloan RP, Kaufman BA, Picard M",
  "publication/journal": "Psychoneuroendocrinology",
  "publication/year": "2019",
  "publication/pmid": "31112904",
  "publication/pmcid": "PMC6637411",
  "publication/doi": "10.1016/j.psyneuen.2019.05.001",
  "publication/tags": "- Machine Learning\n- Psychophysiology\n- Stress Reactivity\n- Mitochondrial DNA\n- Predictive Analytics\n- Cardiovascular Regulation\n- Psychological Stress\n- Behavioral Factors\n- Physiological Measures\n- Socio-evaluative Stress",
  "dataset/provenance": "The dataset used in this study was obtained from the Vaccination and Immunity Project, a longitudinal study that investigates the association of psychosocial, physiological, and behavioral factors with antibody response to hepatitis B vaccination in a middle-aged adult population. This project has been previously reported in other studies.\n\nThe present study included a total of 46 healthy middle-aged adult participants, with 28 men and 18 women, predominantly Caucasian, aged between 41 and 58 years. Participants had at least paired observations for task and +30 min at session 1 or session 2, resulting in 74 observations in total, as 64% of participants completed both visits. The data and samples were collected across two laboratory sessions scheduled one month apart.\n\nThe dataset comprises a comprehensive and unbiased set of psychophysiological measurements, self-reported psychosocial measures, and demographic factors, totaling 56 variables. These variables were used to identify predictors of circulating cell-free mitochondrial DNA (ccf-mtDNA) reactivity induced by socio-evaluative stress. The study leveraged data collected in previous analyses, including an examination of the effects of stress reactivity on ccf-mtDNA levels.",
  "dataset/splits": "In our study, we utilized data from 46 healthy middle-aged adult participants, with a total of 74 observations, as some participants completed both visits. Each participant visit was treated as a unique observation. The data was split into training and test sets using bootstrapping with random sampling and replacement. The training set was used to build the decision trees for the Random Forest classifier, while the test set was used to evaluate the classification accuracy of these trees. The specific number of data points in each split varied due to the bootstrapping process, but the overall distribution aimed to ensure robustness and generalizability of the findings. Additionally, we performed a sensitivity analysis by repeating the main analysis while excluding four divergent responders to ensure they did not drive the results of the main group-level analysis.",
  "dataset/redundancy": "The datasets were split using bootstrapping of random sampling with replacement of individuals. This method was employed to ensure that the training set, used to build the decision trees, and the test set, used to define classification accuracy based on these trees, were robust and could handle large datasets effectively. The training and test sets were not entirely independent due to the nature of bootstrapping, which involves sampling with replacement. However, this approach helps to mitigate overfitting and ensures that the model generalizes well to unseen data. The distribution of the datasets was designed to include a comprehensive and unbiased set of psychophysiological measurements, self-reported psychosocial measures, and demographic factors, totaling 56 variables. This approach aligns with the use of machine learning in high-dimensional data, where the goal is to identify key predictors from a large set of variables. The specific machine learning classifiers used, partial least squares discriminant analysis (PLS-DA) and random forest (RF), are well-suited for handling such datasets and leveraging the overlap across models to ensure the robustness of the identified predictors.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are partial least squares discriminant analysis (PLS-DA) and Random Forest (RF). These are well-established methods in the field of machine learning and have been extensively used in various domains, including psychoneuroendocrinology.\n\nPLS-DA is a technique that separates two or more groups by relating two data matrices\u2014X (the raw data) and Y (the groups to be separated)\u2014by finding a linear subspace of the explanatory variables. This allows for the prediction of group affiliation based on a number of partial least square components. PLS-DA is particularly advantageous for handling highly collinear and noisy datasets.\n\nRandom Forest, on the other hand, is a machine learning algorithm that generates multiple decision trees to maximize the accurate grouping of individuals among groups. It involves splitting the total dataset into a training set and a test set, using the training set to build the decision trees and the test set to define classification accuracy.\n\nBoth PLS-DA and RF are not new algorithms; they have been developed and refined over several years. PLS-DA was introduced by Wold et al. in 2001, while Random Forest was developed by Breiman in 2001. These algorithms are widely recognized and have been applied in numerous studies across different fields.\n\nThe choice to use these specific algorithms in this study was driven by their complementary strengths. PLS-DA is effective in reducing high-dimensional datasets, while RF is particularly good at eliminating irrelevant variables. By combining these two methods, the study aimed to leverage their respective advantages to identify robust predictors of ccf-mtDNA reactivity.\n\nThe algorithms were implemented using Metaboanalyst 3.0, an open-source web software, which facilitated the analysis and interpretation of the data. The use of these established algorithms in a psychoneuroendocrinology context highlights their versatility and applicability in exploring complex biological and psychological interactions.",
  "optimization/meta": "The model employed in this study leverages the strengths of multiple machine learning algorithms to identify predictors of ccf-mtDNA reactivity. Specifically, it utilizes a meta-predictor approach by combining the results of two distinct machine learning classifiers: Partial Least Squares Discriminant Analysis (PLS-DA) and Random Forest (RF). These methods were chosen for their complementary strengths; PLS-DA excels in reducing high-dimensional datasets, while RF is effective at eliminating irrelevant variables.\n\nThe process involved training both classifiers on the same dataset, which included psychological, behavioral, and physiological measurements collected across two testing sessions. The top 15 variables from each model were ranked based on their importance in predicting group affiliation. The overlap between these top variables was then identified, resulting in a reduced set of eight predictors that were used for further analysis.\n\nRegarding the independence of the training data, it is clear that the same dataset was used to train both PLS-DA and RF. However, the study did not explicitly validate the model's prediction accuracy on an entirely independent sample. This limitation means that while the convergence of the two models helps to refine and identify robust predictors, the generalizability of these findings to new, unseen data remains to be fully established.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps. Initially, each participant visit was treated as a unique observation, resulting in a total of 74 observations. The change in cell-free mitochondrial DNA (ccf-mtDNA) levels after stress was computed using the delta task to recovery, which is the difference between post-stress and pre-stress levels.\n\nThe distribution of the response was then divided into tertiles to define low, medium, and high responder groups. This categorization helped in focusing the analysis on the most distinct groups, namely the high responders (top tertile) and low responders (bottom tertile).\n\nA total of 56 physiological and psychological variables were considered for the analysis. These variables were further classified as either trait or state measures. This classification was crucial for analyzing the enrichment of specific types of variables in the final set of predictors.\n\nThe machine learning models used for the analysis included partial least squares discriminant analysis (PLS-DA) and random forest (RF). For the RF model, 700 trees and 7 predictors were used. These models were run using Metaboanalyst 3.0, an open-source web software. The PLS-DA technique relates two data matrices\u2014X (the raw data used to separate the groups) and Y (the groups to be separated)\u2014by finding a linear subspace of the explanatory variables. This allows for the prediction of group affiliation based on a number of partial least square (PLS) components. The PLS components describe the behavior of the groups as they span the mathematical subspace where the explanatory variables are projected. This method is particularly advantageous for handling highly collinear and noisy datasets.\n\nIn contrast, the RF algorithm generates multiple decision trees to maximize the accurate grouping of individuals among the defined groups. The total dataset is split into two groups: two-thirds of the data is used to generate a training set, and one-third is used as a test set. This approach helps in ensuring the robustness and generalizability of the model.\n\nOverall, the data encoding and preprocessing involved a systematic approach to categorize responses, classify variables, and apply advanced machine-learning techniques to identify key predictors of ccf-mtDNA reactivity.",
  "optimization/parameters": "In our study, we utilized a comprehensive set of 56 physiological and psychological variables as input parameters for our machine learning models. These variables were chosen to capture a wide range of psychophysiological measurements, self-reported psychosocial measures, and demographic factors. The selection of these parameters was guided by our aim to explore the determinants of inter-individual and within-person differences in stress psychophysiology.\n\nTo ensure the robustness of the identified predictors, we employed two distinct machine learning classifiers: partial least squares discriminant analysis (PLS-DA) and Random Forest (RF). These models were chosen for their complementary strengths in handling high-dimensional datasets and eliminating irrelevant variables. PLS-DA is particularly effective in reducing dimensionality and managing collinear data, while RF excels at variable selection and is robust to overfitting and outliers.\n\nThe top 15 predictors from each model were ranked based on their ability to discriminate between low and high responders to stress-induced changes in cell-free mitochondrial DNA (ccf-mtDNA) levels. By comparing these rankings, we identified a reduced set of 8 overlapping measures that were used for subsequent analyses. This approach leveraged the convergence of both models to refine and identify the most relevant predictors.\n\nThe selection of these parameters was part of an analytical plan established prior to performing any analysis. This plan included the focus on overlapping variables across models and downstream univariate statistical comparisons only on these overlapping variables. Participants with missing values for more than 20% of the variables were excluded from the analysis. This rigorous approach ensured that our findings were based on a robust and reliable set of predictors.",
  "optimization/features": "In our study, we utilized a comprehensive set of 56 physiological and psychological variables as input features. These features were carefully selected to cover a wide range of psychophysiological measurements, self-reported psychosocial measures, and demographic factors. To ensure the robustness of our identified predictors, we employed two distinct machine learning classifiers: partial least squares discriminant analysis (PLS-DA) and Random Forest (RF). These classifiers were chosen for their complementary strengths in handling high-dimensional data and eliminating irrelevant variables.\n\nFeature selection was performed using the training set only. Specifically, we ranked the variables predicting group affiliation based on their importance metrics: Variable of Importance Score (VIP) for PLS-DA and Mean Decrease Accuracy for RF. The top 15 variables from each model were then compared, and only the overlapping variables across both classifiers were identified as \"predictors\" for further analysis. This approach helped to refine and identify the most relevant predictors, ensuring that our findings were not biased by the specific characteristics of a single model.",
  "optimization/fitting": "In our study, we employed two distinct machine learning classifiers, partial least squares discriminant analysis (PLS-DA) and Random Forest (RF), to identify predictors of ccf-mtDNA reactivity. These methods were chosen for their complementary strengths in handling high-dimensional data and reducing the risk of overfitting.\n\nThe number of variables (56) was indeed larger than the number of observations (74), which could potentially lead to overfitting. To mitigate this risk, we utilized bootstrapping with replacement in the RF algorithm, which helps to create robust and generalizable models by averaging multiple decision trees. Additionally, we leveraged the convergence of results from two different machine learning algorithms, PLS-DA and RF, to refine and identify predictors. This approach helped to ensure that the identified predictors were not merely artifacts of a single model's overfitting tendencies.\n\nPLS-DA is particularly effective at handling collinear and noisy datasets, which is crucial given the high variable-to-individual ratio in our study. It reduces dimensionality by finding a linear subspace of the explanatory variables that best separates the groups, thereby minimizing the risk of overfitting. The RF algorithm, on the other hand, is robust to overfitting due to its ensemble nature, where multiple decision trees are generated and averaged to improve predictive accuracy and generalization.\n\nTo address the potential for underfitting, we ensured that our models were complex enough to capture the underlying patterns in the data. The RF algorithm, with 700 trees and 7 predictors, provided a sufficiently complex model to capture the nuances in the data. Similarly, PLS-DA, by optimizing the number of components, balanced the trade-off between bias and variance, ensuring that the model was neither too simple nor too complex.\n\nIn summary, by using complementary machine learning algorithms and leveraging their strengths, we effectively managed the risks of both overfitting and underfitting in our analysis. This approach allowed us to identify robust predictors of ccf-mtDNA reactivity, despite the high variable-to-individual ratio in our dataset.",
  "optimization/regularization": "In our study, we employed several techniques to prevent over-fitting and ensure the robustness of our predictive models. One of the primary methods used was the combination of two distinct machine learning classifiers: Partial Least Squares Discriminant Analysis (PLS-DA) and Random Forest (RF). This approach leverages the strengths of both models, with PLS-DA excelling at handling high-dimensional datasets and RF being effective at eliminating irrelevant variables. By using both classifiers, we aimed to identify overlapping predictors, thereby reducing the risk of over-fitting to specific noise within the sample.\n\nAdditionally, we utilized bootstrapping with random sampling and replacement to generate a test set. This technique helps in creating a more robust model by ensuring that the training set is used to build the decision trees, while the test set is used to define classification accuracy based on these trees. This method is particularly useful in handling large datasets and is known for its robustness against over-fitting and outliers.\n\nFurthermore, we performed a sensitivity analysis to verify that our findings were not biased by baseline levels. This involved repeating the analysis using baseline-adjusted delta variables, which helped in confirming the consistency of our results. We also excluded participants with missing values for more than 20% of the variables, which further ensured the integrity of our dataset and reduced the potential for over-fitting.\n\nIn summary, our study incorporated multiple regularization techniques, including the use of two complementary machine learning classifiers, bootstrapping for test set generation, and sensitivity analysis, to mitigate the risk of over-fitting and enhance the reliability of our predictive models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are not explicitly detailed in the main text. However, specific details about the machine learning models employed are provided. For instance, the Random Forest (RF) model was configured with 700 trees and 7 predictors. The Partial Least Squares Discriminant Analysis (PLS-DA) model was run using MetaboAnalyst 3.0, an open-source web software. The license for MetaboAnalyst 3.0 is typically open-source, allowing users to access and utilize the software for their analyses.\n\nThe optimization parameters and model files are not directly reported in the publication. The focus was on the methodological approach and the results derived from the models rather than the specific configurations and files used. Therefore, while the general approach and some specific configurations are available, detailed hyper-parameter settings and optimization schedules are not explicitly documented.",
  "model/interpretability": "The models employed in this study, specifically Partial Least Squares Discriminant Analysis (PLS-DA) and Random Forest (RF), offer varying degrees of interpretability. PLS-DA is relatively transparent, as it reduces the dimensionality of the data while maximizing the covariance between the predictors and the response variable. This allows for the identification of the most important variables contributing to the discrimination between groups. The Variable Importance in Projection (VIP) score for the first component in PLS-DA provides a clear metric for ranking the importance of each variable in predicting group affiliation.\n\nOn the other hand, Random Forest is somewhat of a black-box model, as it consists of an ensemble of decision trees. However, it provides a measure of variable importance through the Mean Decrease Accuracy (MDA) score, which indicates how much the prediction accuracy decreases when the values of a variable are permuted. This metric helps in identifying the most influential predictors.\n\nTo enhance interpretability, the study leveraged the convergence of both models. By identifying overlapping variables across PLS-DA and RF, the analysis focused on a reduced set of predictors that were consistently important in both models. This approach not only improved the robustness of the findings but also provided a clearer understanding of the key factors driving the differences between low and high responders. The top 15 variables from each model were compared, and the overlapping measures were selected for further analysis, ensuring that the identified predictors were reliable and interpretable.",
  "model/output": "The model employed in this study is a classification model. Specifically, two distinct machine learning classifiers were used: Partial Least Squares Discriminant Analysis (PLS-DA) and Random Forest (RF). These classifiers were trained to discriminate between two groups: \"high responders\" and \"low responders\" based on changes in cell-free mitochondrial DNA (ccf-mtDNA) levels after stress. The goal was to identify key variables that predict group affiliation, rather than to predict a continuous outcome, which aligns with a classification approach. The models were evaluated based on their ability to accurately classify individuals into these predefined groups.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the machine learning algorithms used in this study is not released. However, the specific software used for running the models, MetaboAnalyst 3.0, is an open-source web software. This tool is freely available and can be accessed online. MetaboAnalyst 3.0 allows users to perform partial least squares discriminant analysis (PLS-DA) and random forest (RF) classification models, among other analytical techniques. The software is designed to handle high-dimensional datasets and is user-friendly, making it accessible for researchers in various fields. While the custom scripts or specific configurations used in this study are not publicly available, the general methodology and tools employed are documented and can be replicated using MetaboAnalyst 3.0.",
  "evaluation/method": "The evaluation method employed in this study involved the use of two distinct machine learning classifiers, partial least squares discriminant analysis (PLS-DA) and Random Forest (RF), to ensure the robustness of the identified predictors. These classifiers were chosen for their complementary strengths: PLS-DA excels at reducing high-dimensional datasets, while RF is effective at eliminating irrelevant variables.\n\nThe study utilized data collected across two occasions of testing. The analytical plan was established prior to performing any analysis, focusing on overlapping variables across models and conducting downstream univariate statistical comparisons only on these overlapping variables. Participants with missing values for more than 20% of the variables were excluded from the analysis.\n\nThe top 15 variables from each model were ranked by their importance in predicting group affiliation. The Variable of Importance Score (VIP) was used for PLS-DA, and Mean Decrease Accuracy was used for RF. Only the overlapping variables across both classifiers were identified as predictors for further analysis. This approach helped to refine and identify reliable predictors by leveraging the convergence of two distinct machine learning algorithms.\n\nTo verify that the reactivity findings were not biased by baseline levels, a sensitivity analysis was conducted using baseline-adjusted delta variables, which yielded similar results. For continuous variables, group differences between low and high responders in the selected predictors were assessed using the non-parametric Mann-Whitney test for independent samples, and effect sizes were calculated as Hedges' g. The strength of the association between the selected predictors was evaluated using Spearman\u2019s rho. Group differences in categorical variables were tested using the Chi-Square test.\n\nAdditionally, in a subset of participants classified as low responders at one session and high responders at another, the identified predictors at the group level were tested to see if they could predict individual responses. The percent difference in each predictor between the low and high responder groups was compared to the percent difference between the \"low\" and \"high\" session for each person. The proportion of cases where group-level predictors correctly matched within-person divergent responses across the two sessions was calculated. Furthermore, the main analysis was repeated while excluding the four divergent responders to ensure that they did not drive the results of the main group-level analysis.\n\nStatistical analyses were performed using SAS statistical software 9.3, SPSS (version 24), and Prism 7.0. The evaluation method thus combined rigorous statistical techniques with machine learning approaches to identify and validate predictors of ccf-mtDNA reactivity induced by socio-evaluative stress in healthy adults.",
  "evaluation/measure": "In our study, we employed two distinct machine learning classifiers, Partial Least Squares Discriminant Analysis (PLS-DA) and Random Forest (RF), to identify predictors of ccf-mtDNA reactivity. For PLS-DA, we reported several key performance metrics: accuracy, R-squared (R2), and Q-squared (Q2). The accuracy of 0.62 indicates the proportion of correctly classified instances. R2, which measures the proportion of variance explained by the model, was 0.50. Q2, representing the predictive accuracy of the model, was -0.10, suggesting some overfitting but still providing a moderate level of discrimination between groups.\n\nFor the Random Forest classifier, we reported the out-of-bag (OOB) error, which was 0.478. This metric estimates the classification error rate by using the trees that were not included in the bootstrap sample for prediction.\n\nThese metrics are commonly used in the literature for evaluating the performance of machine learning models, particularly in high-dimensional datasets. The choice of metrics allows for a comprehensive assessment of model performance, including both explanatory power and predictive accuracy. However, it is important to note that the relatively low performance metrics of each model individually are likely due to the small sample size, which is a limitation of the current study. Future work with larger sample sizes could potentially improve these metrics and provide more robust validation of the model's predictive accuracy.",
  "evaluation/comparison": "In our study, we employed two distinct machine learning classifiers to ensure the robustness of our identified predictors. These classifiers, partial least squares discriminant analysis (PLS-DA) and Random Forest (RF), are mathematically distinct and offer complementary approaches to variable selection. PLS-DA is particularly effective in reducing high-dimensional datasets, while RF excels at eliminating irrelevant variables. By combining the results of these two classifiers, we aimed to leverage their strengths and enhance the reliability of our findings.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on the internal consistency and complementarity of the two chosen classifiers. The PLS-DA model demonstrated a moderate level of discrimination between groups, indicating that the information within the 56 variables was sufficient to partially discriminate between individuals with low or high levels of ccf-mtDNA reactivity upon psychological stress. The prediction accuracy metrics for PLS-DA were: accuracy = 0.62, R2 = 0.50, Q2 = \u22120.10. For RF, the out-of-bag error was 0.478, reflecting relatively poor performance characteristics by each model separately. However, by comparing the top 15 predictors from each model, we identified a reduced set of 8 overlapping measures that were used for subsequent analyses.\n\nWhile we did not compare our methods to simpler baselines, the use of two complementary classifiers provided a robust framework for identifying predictors. The convergence of both models yielded a set of predictors that were more likely to be reliable and generalizable. This approach ensured that our findings were not dependent on the idiosyncrasies of a single model but rather on the consensus of two distinct analytical methods.",
  "evaluation/confidence": "The evaluation of our models' performance metrics did not include confidence intervals. The metrics reported for the Partial Least Squares Discriminant Analysis (PLS-DA) model were accuracy = 0.62, R2 = 0.50, and Q2 = \u22120.10. For the Random Forest (RF) model, the out-of-bag error was 0.478. These metrics indicate relatively modest performance characteristics for each model individually.\n\nStatistical significance was assessed for the enrichment of certain variable types among the predictors. For instance, state variables were significantly over-represented among the predictors (X2=7.03; p=0.008), suggesting that ccf-mtDNA reactivity is more dependent on the current state of the individual rather than stable traits. Additionally, physiological characteristics were significantly enriched over psychological ones (X2=4.36; p=0.04). Sex was identified as a significant trait predictor, with a notable difference in the distribution of sex between low and high responders (X2=26.95; p<0.0001).\n\nWhile the individual performance metrics of the models were not exceptionally high, the convergence of the two distinct machine learning algorithms helped to refine and identify robust predictors. This approach leveraged the strengths of both PLS-DA and RF, which are mathematically distinct and complement each other in variable selection. The use of multiple classifiers increased the confidence in the identified predictors, despite the limitations imposed by the small sample size.",
  "evaluation/availability": "Not enough information is available."
}