{
  "publication/title": "Comprehensive assessment of machine learning methods for diagnosing gastrointestinal diseases through whole metagenome sequencing data.",
  "publication/authors": "Lee S, Lee I",
  "publication/journal": "Gut microbes",
  "publication/year": "2024",
  "publication/pmid": "38972064",
  "publication/pmcid": "PMC11229738",
  "publication/doi": "10.1080/19490976.2024.2375679",
  "publication/tags": "- Gut microbiome\n- Metagenomic datasets\n- Crohn\u2019s disease\n- Colorectal cancer\n- Machine learning\n- Classification models\n- Cross-validation\n- Feature importance\n- Biomarkers\n- Disease diagnosis\n\nNot sure if the tags provided are the ones used in the article, but they are a good summary of the topics covered in the paper.",
  "dataset/provenance": "The dataset used in this study was sourced from public databases, specifically the NCBI Sequence Read Archive (NCBI SRA). We collected raw sequencing reads from 21 published studies, comprising 10 case-control datasets for Crohn\u2019s disease (CD) and 12 for colorectal cancer (CRC). This resulted in a total of 2,553 high-quality metagenomic samples after preprocessing and quality control measures.\n\nThe samples were carefully selected to minimize non-biological biases. Only baseline samples without antibiotic treatment within three months before collection were included. Additionally, samples with insufficient read depth or high levels of host DNA contamination were excluded. This rigorous selection process ensured that the dataset was robust and suitable for reliable analysis.\n\nThe dataset includes metadata such as disease status, age, sex, and body mass index for each sample, which were acquired from the corresponding publications' supplementary materials and the curatedMetagenomicData v3.6.2. This metadata is crucial for understanding the demographic and clinical context of the samples, enabling more nuanced analyses.\n\nThe dataset has been used to evaluate various machine learning (ML) pipelines for disease diagnosis, focusing on CD and CRC. The evaluation involved 5,184 combinations of profile modalities, batch correction methods, normalization approaches, and classification models. This comprehensive assessment aimed to identify the optimal methods for each element of the ML pipeline, ensuring that the models are generalizable and reliable across diverse populations.\n\nThe dataset's diversity in terms of geographic and ethnic representation is a key strength, as it allows for the identification of reproducible gut microbiome-based biomarkers. This diversity is essential for developing diagnostic tools that can be applied in real-world clinical settings, where patient populations are heterogeneous.",
  "dataset/splits": "In our study, we utilized a leave-one-dataset-out cross-validation (LODOCV) framework to evaluate the performance of our machine learning pipelines. This approach involved creating multiple data splits, where each split held out all samples from a single study as the test set, while the remaining studies were used as the training set.\n\nWe had a total of 21 datasets, which resulted in 21 different data splits. Each split contained a unique test set consisting of samples from one study and a training set comprising samples from the other 20 studies. This method ensured that each study was used as a test set exactly once, providing a comprehensive evaluation of the models' cross-cohort generalizability.\n\nThe number of data points in each split varied depending on the size of the individual studies. After preprocessing and quality control, we retained 2,553 samples in total. These samples were distributed across the 21 datasets, with each dataset contributing a varying number of samples to the training and test sets in different splits.\n\nThe distribution of data points in each split was designed to mitigate potential biases from imbalanced class distributions. We performed the cross-validation analysis 20 times for each pipeline and averaged their performance scores. This resulted in a total of 725,760 evaluations for Crohn\u2019s disease (CD) and 933,120 for colorectal cancer (CRC), ensuring robust and reliable performance metrics.",
  "dataset/redundancy": "In our study, we gathered whole metagenome sequencing (WMS) data for Crohn\u2019s disease (CD) and colorectal cancer (CRC) from various bibliographic databases and metagenomic sequence repositories. The acquired datasets underwent a standardized preprocessing protocol to ensure high quality, excluding samples with inadequate read counts or high levels of host DNA contamination. This resulted in 22 WMS datasets, comprising 10 for CD and 12 for CRC.\n\nTo ensure the robustness and generalizability of our machine learning (ML) models, we divided these datasets into discovery and validation cohorts. This split was designed to represent a broad range of geographic and ethnic diversity, reflecting the real-world variability in patient populations. The discovery cohort was used to train the models, while the validation cohort was used to test their performance on unseen data.\n\nTo enforce independence between training and test sets, we employed a leave-one-dataset-out cross-validation (LODOCV) approach. In this method, all samples from a single study are held out from training and used as the test set. This process was repeated for each study, ensuring that the models were evaluated on data from entirely different cohorts. This approach prioritizes cross-cohort generalizability and the identification of reproducible gut microbiome-based biomarkers across diverse demographic groups.\n\nThe distribution of our datasets compares favorably to previously published ML datasets in terms of diversity and representativeness. By including samples from multiple studies and ensuring geographic and ethnic diversity, we aimed to create a more comprehensive and robust benchmark for WMS-based disease diagnosis. This approach helps to mitigate potential biases and ensures that our findings are applicable to a wide range of populations.",
  "dataset/availability": "The raw sequencing reads for the metagenomic datasets used in this study were obtained from the NCBI Sequence Read Archive (NCBI SRA). These datasets include 10 case-control studies for Crohn\u2019s disease (CD) and 12 for colorectal cancer (CRC), sourced from 21 published studies. Metadata, such as disease status, age, sex, and body mass index, were acquired from the corresponding publications' supplementary materials and the curatedMetagenomicData v3.6.2.\n\nThe data collection process involved stringent criteria to ensure high-quality samples. Only baseline samples without antibiotic treatment within three months before stool collection were included. Samples with insufficient read depth or high host contamination were excluded. The preprocessing steps involved trimming low-quality base pairs and adapter sequences, aligning reads to the human reference genome to remove contaminant reads, and filtering out samples with inadequate read depth or high contamination rates.\n\nThe datasets were split into discovery and validation cohorts to ensure a broad representation of geographic and ethnic diversity. The specific splits and preprocessing steps are detailed in the methods section of the publication.\n\nThe data, including the splits used, are not explicitly released in a public forum. However, the methods and criteria for data collection and preprocessing are thoroughly documented, allowing for reproducibility. The use of public databases like NCBI SRA ensures that the raw data is accessible to the scientific community under the terms and conditions set by NCBI, typically involving proper citation and acknowledgment of the original studies.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages established machine-learning techniques tailored for disease diagnosis using whole metagenome shotgun (WMS) data. For Crohn\u2019s disease (CD), a linear classifier, specifically Logistic Regression (LR), was selected. This choice was driven by the need for a model that could effectively handle the data's characteristics while maintaining simplicity and interpretability. For colorectal cancer (CRC), an ensemble classifier, XGBoost (XGB), was chosen. XGB is a non-linear model known for its robustness and ability to manage complex relationships within the data.\n\nThese algorithms are well-established in the machine-learning community and have been extensively validated in various applications. The decision to use these specific algorithms was based on their performance in our rigorous evaluation process, which included leave-one-dataset-out cross-validation (LODOCV) and systematic assessment of different pipeline elements. The algorithms were not newly developed for this study but were selected from a comprehensive benchmarking of various machine-learning models.\n\nThe reason these algorithms were not published in a machine-learning journal is that our focus was on applying and optimizing existing methods for the specific context of WMS-based disease diagnosis. The novelty of our work lies in the integration of these algorithms into optimal machine-learning pipelines, the evaluation of their performance on diverse and unseen datasets, and the provision of practical guidelines for developing effective diagnostic tools. This approach aligns with the interdisciplinary nature of our research, which combines bioinformatics, machine learning, and clinical applications.",
  "optimization/meta": "The optimization process for our machine learning pipelines involved a comprehensive evaluation of various methods tailored for whole metagenome shotgun (WMS) data-based diagnosis of gastrointestinal diseases, specifically Crohn's disease (CD) and colorectal cancer (CRC). While our approach did not explicitly use a meta-predictor that combines outputs from other machine-learning algorithms as input, the process involved selecting the best-performing methods for each element of the machine learning pipeline.\n\nThe optimal machine learning pipelines for CD and CRC were constructed by identifying the most effective methods for each pipeline element through systematic leave-one-dataset-out cross-validation (LODOCV). For CD, a logistic regression (LR) model, a linear classifier, was selected, while for CRC, an extreme gradient boosting (XGB) model, a non-linear ensemble classifier, was chosen. These models were selected based on their performance in diagnosing the respective diseases using WMS data.\n\nThe training data for these models was derived from multiple case-control datasets obtained from public databases, ensuring that the data was independent and diverse. The datasets included metagenomic samples from various studies, and the models were evaluated on holdout validation cohorts to assess their generalizability to unseen data. The performance of the models was measured using metrics such as unit Matthews correlation coefficient (unitMCC), F1 score, ROC curve, and area under the ROC curve (AUROC).\n\nIn summary, while the approach did not involve a traditional meta-predictor, the optimization process involved selecting the best-performing machine learning methods for each disease based on rigorous evaluation and validation. The training data was independent and diverse, ensuring the robustness and generalizability of the models.",
  "optimization/encoding": "In our study, the data encoding and preprocessing for the machine-learning algorithms involved several crucial steps to ensure the robustness and generalizability of our models. Initially, we gathered whole metagenome sequencing (WMS) data for Crohn\u2019s disease (CD) and colorectal cancer (CRC) from various bibliographic databases and metagenomic sequence repositories. The acquired data underwent a standardized preprocessing protocol, where low-quality samples with inadequate read counts or high levels of host DNA contamination were excluded.\n\nThe WMS datasets were then divided into discovery and validation cohorts, ensuring a broad representation of geographic and ethnic diversity. For disease diagnosis, we developed a comprehensive set of composite machine-learning (ML) pipelines. These pipelines combined 12 distinct microbiome profiling modalities, six methods for batch correction (including the option of no correction), eight methods for data normalization and transformation (including the option of no normalization), and nine different classification algorithms.\n\nCompositional transformations, specifically the isometric log-ratio (ILR) and centered log-ratio (CLR) transformations, were employed to address the inherent challenges of microbiome data. Both methods performed similarly well, transforming the data into a real vector space suitable for analysis using standard multivariate methods. However, each transformation has its limitations. CLR transformation can lead to a singular covariance matrix, creating collinearity among the adjusted features. In contrast, ILR transformation reduces the data dimensionality by one, complicating the interpretation as it disrupts the one-to-one correspondence between pre- and post-transformation features. Considering these characteristics, we recommend employing CLR for feature importance analysis post-ML model training, as it facilitates easier interpretation of individual features. On the other hand, ILR is preferable for ordination analyses that require beta diversity calculations, such as Principal Coordinate Analysis (PCoA), where preserving the relative differences between samples is crucial.\n\nFor batch correction, it is crucial to avoid over-correcting to the extent that disease-relevant differences are lost. Our benchmarking analysis revealed that the effectiveness of batch correction tools largely hinges on their ability to preserve variance related to the disease during the adjustment process. Thus, we recommend employing a combination of validation metrics, such as LISI or the PERMANOVA test, to identify a batch correction method that minimizes batch effects while maintaining crucial differences between groups in the dataset.\n\nIn summary, our data encoding and preprocessing involved rigorous standardization, compositional transformations, and careful batch correction to ensure that the ML models could effectively diagnose diseases using WMS data. These steps are essential to establish reliable and effective diagnostic tools in clinical settings.",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "In our study, the input features for the machine learning pipelines were primarily focused on gut-specific, species-level taxonomic features derived from whole metagenome sequencing (WMS) data. These features were selected based on their contribution to the top-performing machine learning pipelines. The feature selection process was conducted using the training data only, ensuring that the validation and testing phases remained unbiased. This approach helped in identifying the most relevant taxonomic features for disease diagnosis, such as Crohn's disease (CD) and colorectal cancer (CRC). The selected features were then used to construct the optimal machine learning pipelines, which demonstrated robust performance and generalizability across diverse datasets. The number of features used as input varied depending on the specific pipeline and disease being diagnosed, but the focus was on the top 20 important species for each disease. This selection was based on their differential abundance between patients and healthy controls, as analyzed using the MaAsLin2 tool. The feature selection process was integral to enhancing the performance and interpretability of the machine learning models.",
  "optimization/fitting": "In our study, we evaluated a vast number of machine learning pipelines, totaling 5,184 combinations of profile modalities, batch correction methods, normalization approaches, and classification models. This extensive evaluation was conducted using a 20-fold leave-one-dataset-out cross-validation (LODOCV) framework, resulting in 1.65 million training processes. This approach ensured that our models were robust and generalizable, as each dataset was used as a test set once, while the remaining datasets were used for training.\n\nGiven the high dimensionality of our data, with a large number of features relative to the number of samples, we employed models that are well-suited to handle such complexity. Ensemble methods, such as XGBoost (XGB), were particularly effective due to their ability to manage high-dimensional data and built-in regularization techniques that prevent overfitting. For linear models, we used regularization techniques to mitigate overfitting risks.\n\nTo further ensure that our models did not overfit, we used cross-validation, which provides a more reliable estimate of model performance than a single train-test split. Additionally, we evaluated the performance of our models on unseen validation cohorts, demonstrating their generalizability. The optimal pipelines for both Crohn\u2019s disease (CD) and colorectal cancer (CRC) showed consistent performance across different validation sets, indicating that overfitting was not a significant issue.\n\nUnderfitting was addressed by selecting models and hyperparameters that could capture the complexity of the data. For instance, we chose ensemble methods for their ability to model complex relationships. Moreover, the consistent performance of our models across different validation sets suggests that underfitting was not a concern.\n\nIn summary, our approach involved a rigorous evaluation process that included cross-validation and testing on unseen data, ensuring that our models were neither overfitted nor underfitted. The use of regularization techniques and appropriate model selection further supported the robustness and generalizability of our findings.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our machine learning models. One of the key methods used was regularization, which was integrated into our linear models. Regularization techniques such as L1 and L2 penalties were applied to constrain the model complexity and prevent it from fitting the noise in the training data.\n\nAdditionally, we utilized ensemble methods like gradient boosting trees and random forests, which inherently provide regularization by combining the predictions of multiple models. These ensemble techniques help to reduce overfitting by averaging out the errors of individual models.\n\nWe also implemented a rigorous cross-validation strategy known as leave-one-dataset-out cross-validation (LODOCV). This approach involves holding out all samples from a single study for testing while training on the remaining data. By doing so, we prioritized the generalizability of our models across different cohorts and minimized the risk of overfitting to any specific dataset.\n\nFurthermore, we performed extensive hyperparameter tuning and model selection processes. This involved evaluating a wide range of hyperparameter settings and selecting the best-performing configurations based on cross-validated performance metrics. This systematic approach helped to ensure that our models were optimized for generalization rather than memorization of the training data.\n\nIn summary, our study incorporated multiple overfitting prevention techniques, including regularization in linear models, the use of ensemble methods, a robust cross-validation strategy, and thorough hyperparameter tuning. These measures collectively contributed to the development of reliable and generalizable machine learning pipelines for disease diagnosis based on gut microbiome data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the main text. However, the methods and models employed are described comprehensively, including the specific machine learning algorithms and data processing techniques used. For instance, we utilized logistic regression (LR) for Crohn\u2019s disease (CD) and extreme gradient boosting (XGB) for colorectal cancer (CRC) as part of our optimal machine learning pipelines. The feature matrices underwent compositional normalization techniques such as isometric log-ratio (ILR) for CD and centered log-ratio (CLR) for CRC. Batch effects were managed using ComBat-seq for CRC, while no batch correction was applied for CD.\n\nThe study also mentions the use of a 20-fold leave-one-dataset-out cross-validation (LODOCV) framework, which involved evaluating 5,184 combinations of profile modalities, batch correction methods, normalization approaches, and classification models. This extensive evaluation process ensures that the optimal methods for each element of the machine learning pipeline were identified rigorously.\n\nRegarding the availability of model files and optimization parameters, these details are not provided in the main text. However, the supplementary materials, specifically Supplementary table S1, contain the data supporting the findings of this study. This table likely includes relevant information that could be used to replicate the experiments or understand the configurations better.\n\nFor those interested in the specific hyper-parameters and optimization schedules, it would be advisable to refer to the supplementary materials or contact the authors directly for more detailed information. The study was conducted with the support of various funding sources, including the National Research Foundation and the Technology Innovation Program, which underscores the rigor and thoroughness of the research conducted.",
  "model/interpretability": "The models employed in our study are not entirely black-box, as we utilized Shapley additive explanations (SHAP) to interpret feature importance. SHAP values provide a model-agnostic approach to estimate the contribution of each taxonomic feature to the model's predictions, offering an intuitive understanding of feature importance. This method adheres to properties like efficiency and additivity, making it a reliable tool for interpretability.\n\nFor our diagnostic models of Crohn\u2019s disease (CD) and colorectal cancer (CRC), we calculated SHAP values using the optimal machine learning (ML) pipelines. We focused on the top 20 important species and their differential abundance between patients and healthy controls across discovery cohorts. The SHAP values were computed from 100 independent model instances and then averaged, providing a robust measure of feature importance.\n\nThe absence of error bars in the SHAP value plots is due to the deterministic behavior of the XGBoost (XGB) model under the current parameter settings, resulting in uniform outcomes across all iterations. This consistency further enhances the transparency of our models, as it indicates stable and reliable feature importance rankings.\n\nIn summary, while the ML models themselves may be complex, the use of SHAP values allows for a clear and interpretable understanding of which bacterial species are most influential in the diagnostic process. This transparency is crucial for validating the models and ensuring that the key features driving the predictions are biologically meaningful.",
  "model/output": "The models discussed in this publication are primarily focused on classification tasks. Specifically, they are designed for diagnosing diseases such as Crohn\u2019s disease (CD) and colorectal cancer (CRC) based on gut microbiome data. The performance of these models is evaluated using metrics suitable for classification problems, such as unitMCC, F1 score, ROC curve, and AUROC values. These metrics indicate that the models are trained to classify samples into distinct categories, such as diseased or healthy, rather than predicting continuous outcomes.\n\nThe models include various types of machine learning algorithms, such as ensemble models (e.g., Random Forest and XGBoost), non-linear models (e.g., Radial SVM and Artificial Neural Networks), and linear models (e.g., Logistic Regression, Linear SVM, and Naive Bayes Classifier). Each of these models is assessed for its ability to accurately classify disease states based on microbiome profiles.\n\nThe evaluation of these models involves comparing their performance across different normalization methods and feature engineering techniques. For instance, the study recommends specific normalization methods like CLR and LOG for different models to optimize their classification performance. The models are also tested on unseen datasets to validate their generalizability and robustness in real-world applications.\n\nIn summary, the models discussed are classification models aimed at diagnosing diseases based on gut microbiome data. Their performance is evaluated using standard classification metrics, and they are optimized through various data processing and normalization techniques to enhance their diagnostic accuracy.",
  "model/duration": "The execution time for our study was substantial due to the extensive evaluation process. We assessed 5,184 combinations of profile modalities, batch correction methods, normalization approaches, and classification models. This evaluation was conducted using a 20-fold leave-one-dataset-out cross-validation (LODOCV) framework, resulting in a total of 1.65 million training processes. The unitMCC score for each machine learning pipeline was calculated by averaging scores of all cross-validation folds, weighted proportionally to the test set size of each fold. This comprehensive approach ensured that we identified the optimal methods for each element of the machine learning pipeline, but it required significant computational resources and time. The exact duration of the entire process is not specified, but it is clear that the scale of the evaluation was extensive and time-consuming.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, we employed a rigorous evaluation method to assess the performance of various machine learning (ML) pipelines for diagnosing Crohn\u2019s disease (CD) and colorectal cancer (CRC) using whole metagenome sequencing (WMS) data. Our primary focus was on ensuring cross-cohort generalizability and identifying reproducible gut microbiome-based biomarkers across diverse demographic groups.\n\nWe utilized the leave-one-dataset-out cross-validation (LODOCV) approach. This method involves holding out all samples from a single study for testing while using the remaining studies for training. This strategy is crucial for evaluating the model's ability to generalize to new, unseen datasets, which is essential for real-world clinical applications.\n\nTo mitigate potential biases from imbalanced class distributions between training and test data, we performed the cross-validation analysis 20 times for each pipeline and averaged their performance scores. This resulted in a comprehensive evaluation, with a total of 725,760 evaluations for CD and 933,120 for CRC.\n\nWe used Matthew\u2019s Correlation Coefficient (MCC) as our primary evaluation metric due to its balanced nature and robustness in handling class imbalances. To enhance interpretability, we normalized the MCC score to align with the scale of the Area Under the Receiver Operating Characteristic Curve (AUROC).\n\nOur evaluation process involved developing 5,184 composite ML pipelines, combining various microbiome profiling modalities, batch correction methods, normalization and transformation techniques, and classification algorithms. This extensive evaluation allowed us to identify the optimal methods for each element of the ML pipeline and develop guidelines for WMS-based disease diagnosis.",
  "evaluation/measure": "In our study, we employed Matthew\u2019s Correlation Coefficient (MCC) as the primary evaluation metric for assessing the performance of our machine learning models. The MCC was chosen for its balanced nature, which ensures that a classifier receives high scores only when it performs well across all four rates of the confusion matrix. This metric is particularly robust in real-world diagnostic scenarios due to its agnosticism towards class imbalances.\n\nTo enhance the interpretability of the MCC scores, we normalized them to align with the scale of the Area Under the Receiver Operating Characteristic Curve (AUROC). This normalization process, referred to as unitMCC, facilitates a more intuitive understanding of the model's performance.\n\nIn addition to MCC, we implemented a rigorous cross-validation procedure known as leave-one-dataset-out cross-validation (LODOCV). This approach involves holding out all samples from a single study for testing while using the remaining studies for training. This method is designed to prioritize cross-cohort generalizability and the identification of reproducible gut microbiome-based biomarkers across diverse demographic groups. To mitigate potential biases from imbalanced class distributions, we performed the cross-validation analysis 20 times for each pipeline and averaged their performance scores.\n\nThe use of MCC and unitMCC, along with the LODOCV approach, ensures that our evaluation metrics are both representative and comprehensive. These metrics are well-aligned with the literature, particularly in studies focusing on the diagnostic potential of gut microbiome data. By normalizing the MCC scores and employing a robust cross-validation strategy, we aim to provide a thorough and reliable assessment of our models' performance.",
  "evaluation/comparison": "In our study, we conducted a comprehensive evaluation of whole metagenome shotgun (WMS)-based machine learning (ML) methods for diagnosing diseases, with a focus on Crohn\u2019s disease (CD) and colorectal cancer (CRC). We gathered WMS data from various public databases and repositories, ensuring a diverse representation of geographic and ethnic backgrounds. The data underwent a standardized preprocessing protocol to exclude low-quality samples, resulting in 22 datasets (10 for CD and 12 for CRC).\n\nWe developed 5,184 composite ML pipelines, combining different microbiome profiling modalities, batch correction methods, normalization techniques, and classification algorithms. This extensive comparison allowed us to assess the impact of various methods on the performance of WMS-based disease diagnosis across diverse populations.\n\nTo evaluate the performance of these pipelines, we used Matthew\u2019s Correlation Coefficient (MCC) as our primary metric due to its balanced nature and robustness in real-world diagnostic scenarios. We normalized the MCC score to align with the scale of the Area Under the Receiver Operating Characteristic Curve (AUROC) for better interpretability.\n\nOur evaluation framework included a leave-one-dataset-out cross-validation (LODOCV) approach, where all samples from a single study were held out from training and used as the test set. This method prioritizes cross-cohort generalizability and the identification of reproducible gut microbiome-based biomarkers. To mitigate biases from imbalanced class distributions, we performed the cross-validation analysis 20 times for each pipeline and averaged their performance scores.\n\nIn addition to comparing different ML pipelines, we also evaluated various batch correction methods, such as na\u00efve batch mean centering, ComBat-seq, LIMMA, MMUPHin, and ConQuR. These methods were assessed for their ability to correct for batch effects across cohorts, which is crucial for ensuring the reliability of diagnostic tools in clinical settings.\n\nWe also explored different data normalization and transformation methods, including Total Sum Scaling (TSS), Cumulative Sum Scaling (CSS), Trimmed Mean of M-values (TMM), Centered Log-Ratio Transformation (CLR), Isometric Log-Ratio Transformation (ILR), Arcsine Square Root Transformation (ARS), and Log Transformation. These methods were evaluated for their impact on the performance of the ML pipelines.\n\nOverall, our study provides a systematic evaluation of WMS-based ML methods for disease diagnosis, offering practical guidelines for developing reliable and effective diagnostic tools in clinical settings. The extensive comparison of different methods and techniques ensures that our findings are robust and generalizable across diverse populations.",
  "evaluation/confidence": "The evaluation process employed in this study prioritizes robustness and generalizability. To ensure the reliability of the performance metrics, we utilized a leave-one-dataset-out cross-validation (LODOCV) approach. This method involves holding out all samples from a single study for testing while using the remaining data for training. This process was repeated 20 times for each pipeline to mitigate biases from imbalanced class distributions, resulting in a comprehensive evaluation framework.\n\nThe unit Matthews Correlation Coefficient (unitMCC) score for each machine learning (ML) pipeline was calculated by averaging the scores of all cross-validation folds, weighted proportionally to the test set size. This approach helps to avoid overestimating scores computed on relatively small test sets.\n\nTo assess the statistical significance of the best-performing pipeline, we employed a 1-sample sign test using the signTest function from the EnvStats package with default parameters. This test helps to determine whether the performance of the top pipeline is significantly better than random chance.\n\nAdditionally, the contribution of each classification model to the top 1% best-performing ML pipelines was analyzed using Fisher\u2019s exact test. This statistical test provides insights into the enrichment significance of different models in the top-performing pipelines, with significance levels denoted by asterisks (e.g., '*' for p < 0.05, '**' for p < 0.01, etc.).\n\nThe Mann-Whitney U test was used to assess statistical significance across different groups of model architectures (e.g., ensemble models, non-linear models, and linear models) and to evaluate the geometric separability index of the training dataset after batch correction and normalization.\n\nOverall, the evaluation process includes multiple statistical tests to ensure that the performance metrics are reliable and that the results are statistically significant. This rigorous approach enhances the confidence in the superiority of the identified methods over others and baselines.",
  "evaluation/availability": "Not enough information is available."
}