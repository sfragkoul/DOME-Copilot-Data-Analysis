{
  "publication/title": "Detection of active and inactive phases of thyroid-associated ophthalmopathy using deep convolutional neural network.",
  "publication/authors": "Lin C, Song X, Li L, Li Y, Jiang M, Sun R, Zhou H, Fan X",
  "publication/journal": "BMC ophthalmology",
  "publication/year": "2021",
  "publication/pmid": "33446163",
  "publication/pmcid": "PMC7807896",
  "publication/doi": "10.1186/s12886-020-01783-5",
  "publication/tags": "- Machine learning\n- Thyroid-associated ophthalmopathy\n- Magnetic resonance imaging\n- Deep convolutional neural network\n- Orbital MRI\n- Active phase\n- Inactive phase\n- Medical imaging\n- Deep learning\n- Ophthalmology",
  "dataset/provenance": "The dataset used in this study was sourced from patients who visited the Ophthalmology Clinic of the Ninth People's Hospital between May 1, 2018, and July 1, 2019. The inclusion criteria for the patients were:\n\n* Age over 18 years\n* Meeting the internationally recognized diagnostic criteria for thyroid-associated ophthalmopathy (TAO)\n* Intraorbital involvement confirmed by orbital MRI\n\nThe exclusion criteria were:\n\n* Eyelid retraction, exophthalmos, and eye movement disorders caused by other eye diseases\n* Patients with metal implants or mental illness\n\nA total of 160 orbital MRIs were performed before and after treatment on 108 patients, with 66 females and 42 males. The data types included basic information of patients, physical examination, auxiliary examination, and treatment suggestions. Additionally, the therapeutic effect and adverse events were recorded during treatment.\n\nThe dataset was divided into training and testing sets. The testing set consisted of 32 images, with 7 MRI images of the active phase and 25 MRI images of the inactive phase. The remaining dataset was used for training with K-fold cross-validation (k = 5) to tune hyperparameters.\n\nThe dataset was annotated using the Clinical Activity Score (CAS), which is the most commonly used clinical staging index of TAO. Patients with a CAS score of 3 or higher were annotated as being in the active phase, while those with a score below 3 were annotated as being in the inactive phase. The activity of TAO was assessed based on the CAS score by two ophthalmologists with more than 5 years of experience in orbital diseases. Disagreements were resolved by a senior chief physician after an empirical evaluation of the orbital MRI. After annotation, there were 50 MRI images of the active phase and 110 MRI images of the inactive phase.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The test set was generated by randomly splitting 20% of the entire dataset, resulting in a 32-image dataset. This test set included 7 MRI images of the active phase and 25 MRI images of the inactive phase.\n\nThe remaining 80% of the dataset was used as the training set. To optimize hyperparameters, K-fold cross-validation was employed with k=5. This means the training set was divided into 5 folds. During each cross-validation process, 4 folds were used for training, and the remaining fold was used for validation. This process was repeated 5 times, ensuring that each fold was used once for validation.\n\nIn summary, the dataset splits consisted of a test set with 32 images and a training set that was further divided into 5 folds for cross-validation.",
  "dataset/redundancy": "The dataset was divided into training and testing sets to ensure independence between them. A random split of 20% of the entire dataset was used to generate the testing set, which did not participate in the training process. This resulted in a 32-image testing dataset, comprising 7 MRI images of the active phase and 25 MRI images of the inactive phase.\n\nTo enforce independence, K-fold cross-validation was employed on the remaining dataset, which served as the training set. This algorithm divided the data into 5 folds randomly without replacement. During each cross-validation process, 4 folds were used for training, and the remaining fold was used for validation. This process was repeated 5 times to ensure that each fold was used once for validation.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the medical field, particularly those involving MRI images. The use of K-fold cross-validation helps to mitigate issues related to small datasets and ensures that the model generalizes well to unseen data. This approach is particularly important in medical imaging, where datasets are often limited in size due to the complexity and cost of acquiring high-quality MRI images.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm used in our study is the Adam optimizer, which is a popular choice for training deep learning models. Adam is not a new algorithm; it was introduced by Diederik P. Kingma and Jimmy Ba in 2014. It is a method that computes adaptive learning rates for each parameter, combining the advantages of two other extensions of stochastic gradient descent.\n\nThe Adam optimizer was chosen for its efficiency and effectiveness in handling sparse gradients on noisy problems. It is widely used in the deep learning community due to its ability to converge quickly and handle large datasets.\n\nThe reason the Adam optimizer is discussed in a medical journal rather than a machine-learning journal is that the focus of our study is on the application of deep learning techniques to medical imaging, specifically for staging the activity of thyroid-associated ophthalmopathy (TAO) using orbital MRI images. The optimization algorithm is a crucial component of the deep learning pipeline, but the primary contribution of our work lies in the medical application and the novel use of deep convolutional neural networks (DCNNs) in this context.\n\nIn addition to the Adam optimizer, other techniques such as learning rate decay, weight decay, and momentum optimization were applied to accelerate convergence and improve training speed. These methods are standard practices in the field of deep learning and are used to enhance the performance and stability of the training process.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps to ensure the MRI images were suitable for training deep convolutional neural networks (DCNNs). Initially, MRI scans were performed using a 3.0-T MRI system, with patients' heads stabilized in a supine position. The orbital MRI imaging protocol included T1-weighted turbo spin-echo (TSE), T2-weighted TSE spectral presaturation with inversion recovery (SPIR), and T2-weighted driven equilibrium radiofrequency reset pulse (DRIVE). Axial SPIR was chosen for the study, with specific parameters for repetition time, echo time, field of view, slice thickness, and matrix size.\n\nData annotation was crucial for the supervised learning method used. The Clinical Activity Score (CAS) was employed to annotate the activity stage of orbital MRI. Patients with a CAS of 3 or higher were annotated as being in the active phase, while those with a CAS below 3 were annotated as being in the inactive phase. Two experienced ophthalmologists assessed the activity of thyroid-associated ophthalmopathy (TAO) based on the CAS score, with disagreements resolved by a senior chief physician.\n\nThe dataset was divided into training and testing sets. A random split of 20% of the entire dataset was used for testing, ensuring it did not participate in the training process. The remaining dataset underwent K-fold cross-validation (k = 5) for hyperparameter tuning. This involved dividing the data into k folds, using k-1 folds for training and the remaining fold for validation, repeated k times.\n\nData normalization and augmentation were essential to address intensity nonuniformity in MRI images, known as bias field. N4 bias field correction was applied to reduce inconsistencies caused by patient location, scanner parameters, and environmental factors. After correction, the pixel intensities of each image were normalized to have an average of 0 and a standard deviation of 1. The orbital parts of the MRI images were intercepted using ITK-SNAP 3.6.0 and zoomed to a size of 164 \u00d7 164 pixels. With the optic nerve plane as the center, five slices of MRI images were selected.\n\nTo avoid overfitting, data augmentation techniques were employed before each training session. These techniques included random flipping and random cropping, resulting in MRI images of size 128 \u00d7 128 \u00d7 5 pixels. These preprocessing steps ensured that the data was standardized and augmented, making it suitable for training the DCNNs effectively.",
  "optimization/parameters": "In our study, we employed two deep convolutional neural networks (DCNNs), referred to as Network A and Network B. Network A was designed with five convolutional modules, each containing two convolutional layers and one max-pooling layer, followed by four fully connected layers. Network B, built upon Network A, included eight ResBlock modules, each with two convolutional layers and one residual path, in addition to the original structure of Network A.\n\nThe specific number of parameters (p) in each network was not explicitly stated, as it can vary based on the dimensions of the layers and the number of filters used. However, Network B, with its additional ResBlock modules, inherently has more parameters than Network A due to its increased depth and complexity.\n\nThe selection of the network architectures and their parameters was influenced by the need to balance model complexity and performance. Network A, inspired by the VGG network, used small 3x3 filters to reduce computational complexity. Network B, incorporating elements from ResNet, aimed to increase depth while mitigating the vanishing gradient problem through residual connections. This design choice was intended to enhance the network's ability to learn more complex features from the data.\n\nDuring training, techniques such as weight decay, dropout, and batch normalization were employed to prevent overfitting and improve generalization. The dropout probability was set to 0.5, meaning that half of the parameters were randomly dropped during each training iteration. Batch normalization was applied after every convolutional layer to normalize the distribution of each batch, which helped in reducing the phenomenon of gradient disappearance and accelerating convergence.\n\nThe hyperparameters, including learning rate, batch size, and epoch numbers, were carefully tuned and are detailed in Table 1. The learning rate decay strategy was implemented to adjust the learning rate during training, ensuring stable convergence. The Adam optimizer, with momentum parameters \u03b21=0.9 and \u03b22=0.999, was used to optimize the networks efficiently.",
  "optimization/features": "The input features for our deep learning system consist of MRI images of the orbital region. Specifically, five slices of MRI images are used, each with a size of 128 \u00d7 128 pixels, resulting in a total of 128 \u00d7 128 \u00d7 5 pixels per input sample.\n\nFeature selection in the traditional sense was not performed, as the features are directly derived from the MRI images. However, data preprocessing and augmentation techniques were applied to enhance the quality and variability of the input features. These techniques included normalization, N4 bias field correction, random flipping, and random cropping. The optic nerve plane was used as the center for selecting the five slices of MRI images, ensuring that the most relevant regions were captured for analysis.\n\nThe preprocessing steps were carried out using ITK-SNAP software, which helped in intercepting and zooming the orbital parts of the MRI images to the required size. These preprocessing steps were applied to the entire dataset, including both the training and test sets, to ensure consistency and to avoid data leakage. The use of data augmentation techniques helped in increasing the diversity of the training data, which is particularly important given the small size of the dataset. This approach ensures that the model generalizes well to new, unseen data.",
  "optimization/fitting": "The deep convolutional neural networks (DCNNs) employed in this study were designed to mitigate both overfitting and underfitting. Overfitting is a common issue in deep learning, especially when the number of parameters is significantly larger than the number of training points. To address this, several techniques were implemented.\n\nFirstly, data augmentation was used to artificially increase the size of the training dataset. Techniques such as random flipping and random cropping were applied to the MRI images, which helped to generalize the model better.\n\nSecondly, dropout layers were incorporated into the network architecture. Dropout randomly sets a fraction of the input units to zero at each update during training time, which helps prevent overfitting by ensuring that the network does not rely too heavily on any single neuron.\n\nAdditionally, batch normalization was applied after every convolutional layer. This technique normalizes the inputs of each layer, which helps to stabilize and accelerate the training process, and also acts as a regularizer, reducing the risk of overfitting.\n\nThe networks were also designed with residual blocks, which allow for deeper architectures without the vanishing gradient problem. This helps in training deeper networks effectively, which can capture more complex patterns in the data.\n\nTo further prevent overfitting, weight decay (L2 regularization) was applied. This technique adds a penalty term to the loss function, encouraging the model to keep the weights small and thus reducing the complexity of the model.\n\nIn terms of underfitting, the networks were designed with sufficient depth and complexity to capture the necessary features from the data. The use of residual blocks and the deep architecture of the networks ensured that the models were capable of learning the underlying patterns in the data.\n\nThe training process involved multiple runs to evaluate the stability and performance of the networks. The convergence of the loss value during training was monitored, and the networks were trained for a sufficient number of epochs to ensure that they had enough time to learn from the data.\n\nOverall, the combination of these techniques helped to ensure that the networks were neither overfitting nor underfitting the data, leading to robust and generalizable performance.",
  "optimization/regularization": "In our study, several regularization methods were employed to prevent overfitting and improve the generalization of our deep convolutional neural networks (DCNNs). One of the key techniques used was dropout, which randomly drops a portion of the parameters during training with a probability of 0.5. This helps to simplify the network and prevent it from becoming too reliant on specific features, thereby reducing overfitting.\n\nAdditionally, batch normalization was applied after every convolutional layer. This technique normalizes the distribution of each batch, which helps to stabilize and accelerate the training process. It also mitigates the issue of vanishing gradients, making the network more robust.\n\nWeight decay, specifically L2 regularization, was implemented to penalize large weights, encouraging the model to keep weights small and reducing the complexity of the model. This was applied with different lambda values in the convolutional and fully connected layers.\n\nFurthermore, data augmentation techniques such as random flipping and random cropping were used to artificially increase the diversity of the training dataset. This helps the model to generalize better by exposing it to a wider variety of input variations.\n\nThese regularization methods collectively contributed to the stability and performance of our networks, ensuring that they could generalize well to unseen data despite the small dataset size.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule are detailed in Table 1. This table provides specific adjustments for two networks, including depth, activation function, loss function, filter size, batch size, epoch, learning rate, optimizer, batch normalization, and regularization. The detailed adjustments of hyperparameters are openly available in the publication.\n\nThe model files and optimization parameters are not explicitly mentioned as being available for download or access. However, the methods and configurations used are thoroughly described, allowing for replication of the experiments. The publication does not specify a license for the use of these configurations or parameters, but they are presented in a manner that encourages reproducibility in research.\n\nThe evaluation metrics and results, including accuracy, precision, sensitivity, specificity, and F1 score, are provided in Table 2. These metrics offer a clear understanding of the performance of the networks under the given configurations. The convergence of loss values and the ROC curves during the training and testing processes are illustrated in Figure 3, further supporting the reproducibility of the results.\n\nThe study also includes detailed descriptions of the data preprocessing and augmentation techniques, as well as the hardware and software used for the experiments. This information is crucial for replicating the experimental setup and understanding the optimization process. The use of specific techniques like N4 bias field correction and data augmentation is clearly outlined, ensuring that other researchers can follow the same procedures.\n\nIn summary, while the exact model files and optimization parameters may not be directly downloadable, the comprehensive details provided in the publication enable researchers to replicate the experiments and optimize their own models accordingly. The availability of hyper-parameter configurations and optimization schedules, along with the detailed descriptions of methods and results, supports the reproducibility and further development of the research.",
  "model/interpretability": "The model employed in this study is not entirely transparent and can be considered somewhat of a black box, which is a common characteristic of deep convolutional neural networks (DCNNs). However, efforts were made to enhance interpretability. To address the \"black box\" problem, occlusion testing, a visualization method, was applied. This technique involves setting a gray occlusion region on the input image and recording the output probability while different regions are occluded. By converting these probability changes into a heat map, the key parts of the input image that are crucial for decision-making can be highlighted. The results of the occlusion testing indicated that the key parts for decision-making were mainly located on the edematous extraocular muscle, which aligns with medical knowledge and expectations. This approach helps to reveal insights into the decisions made by the neural networks, making the model more interpretable.",
  "model/output": "The model is a classification model. It is designed to distinguish between the active and inactive phases of thyroid-associated ophthalmopathy (TAO) using magnetic resonance imaging (MRI) data. The model outputs a decision based on the probability calculated from the input images, indicating whether the patient is in the active or inactive phase of TAO. The performance of the model is evaluated using metrics such as accuracy, precision, sensitivity, specificity, and F1 score, which are typical for classification tasks. The model's output is binary, categorizing the input data into one of two classes: active or inactive phase of TAO.",
  "model/duration": "The entire training process was conducted on a machine equipped with an RTX2080 GPU, utilizing TensorFlow 2.0 as the backend. The experiment was run four times to evaluate the stability of training. However, the exact execution time for each run or the total time spent is not specified. The convergence of the loss value was achieved during training, indicating that the models were trained to a satisfactory level. The training process involved using an Adam optimizer, learning rate decay, weight decay, and momentum optimization to accelerate convergence and improve training speed. Detailed adjustments of hyperparameters, such as the number of epochs and learning rates, were made to optimize the training process.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method involved running the experiment four times to assess the stability of training. The convergence of the loss value during training was monitored to evaluate the training process. Preprocessed images were input into the well-trained networks, and the output probability was used to make a decision.\n\nSeveral metrics were calculated from the test set over four runs, including the average and standard deviation of accuracy, precision, sensitivity, specificity, and F1 score. These metrics are defined as follows:\n\n- Accuracy is the ratio of true positive (TP) and true negative (TN) results to the total number of cases.\n- Precision is the ratio of true positive results to the sum of true positive and false positive (FP) results.\n- Sensitivity, also known as recall, is the ratio of true positive results to the sum of true positive and false negative (FN) results.\n- Specificity is the ratio of true negative results to the sum of true negative and false positive results.\n- The F1 score is the harmonic mean of precision and sensitivity, providing a balance between the two.\n\nAdditionally, the receiver operating characteristic (ROC) curve was drawn, and the area under the curve (AUC) was calculated to evaluate the effectiveness of the models. Occlusion testing, a visualization method, was applied to reveal insights into the decisions made by the neural networks. This involved setting a gray occlusion region on the input image and recording the output probability while different regions were occluded. The probability changes were converted into a heat map to display the key parts of the input image used for decision-making.",
  "evaluation/measure": "In our study, we evaluated the performance of our deep learning models using several key metrics to ensure a comprehensive assessment. The primary metrics reported include accuracy, precision, sensitivity, specificity, and the F1 score. These metrics provide a well-rounded view of the model's performance by capturing different aspects of its predictive capabilities.\n\nAccuracy measures the overall correctness of the model's predictions, indicating the proportion of true results (both true positives and true negatives) among the total number of cases examined. Precision focuses on the correctness of positive predictions, showing the proportion of true positives among all positive predictions made. Sensitivity, also known as recall, assesses the model's ability to identify positive cases, representing the proportion of true positives among all actual positives. Specificity evaluates the model's ability to correctly identify negative cases, indicating the proportion of true negatives among all actual negatives. The F1 score is the harmonic mean of precision and sensitivity, providing a single metric that balances both concerns, especially useful when dealing with imbalanced datasets.\n\nAdditionally, we used the area under the receiver operating characteristic curve (AUC) to evaluate the model's performance. The AUC provides a single scalar value that summarizes the model's ability to discriminate between the positive and negative classes across all possible classification thresholds. A higher AUC value indicates better model performance.\n\nThese metrics are widely used in the literature for evaluating binary classification models, ensuring that our evaluation is representative and comparable to other studies in the field. The combination of these metrics allows us to thoroughly assess the strengths and weaknesses of our models, providing a robust evaluation of their performance in differentiating between the active and inactive phases of TAO based on orbital MRI images.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, we focused on developing and evaluating two deep convolutional neural networks (DCNNs) tailored to our specific task of staging the activity of thyroid-associated ophthalmopathy (TAO) using orbital MRI images.\n\nWe designed two networks: Network A, which was inherited from the VGG-16 architecture, and Network B, which incorporated ResBlock modules from ResNet to address issues like vanishing gradients. Both networks were optimized using techniques such as weight decay, learning rate decay, and momentum.\n\nTo evaluate the performance and stability of these networks, we ran experiments four times and calculated the average and standard deviation of key metrics such as accuracy, precision, sensitivity, specificity, and F1 score. This approach allowed us to assess the robustness and generalizability of our models.\n\nWhile we did not compare our methods against simpler baselines or publicly available datasets, our results demonstrated that both networks performed well, with high accuracy and area under the curve (AUC) values. This suggests that our DCNN-based approach is effective for the task at hand. The use of occlusion testing further provided insights into the decision-making process of the networks, highlighting the key regions in the MRI images that were crucial for classification.",
  "evaluation/confidence": "The evaluation of the deep learning system involved running the experiment four times to assess the stability of training. The performance metrics, including accuracy, precision, sensitivity, specificity, and F1 score, were calculated as averages with standard deviations (SD) across these runs. This approach provides a measure of confidence in the performance metrics, indicating the variability and reliability of the results.\n\nThe results showed that both networks achieved high accuracy, with Network A at 0.863 \u00b1 0.055 and Network B at 0.855 \u00b1 0.018. The smaller SD in Network B suggests more stable training. Additionally, the area under the receiver operating characteristic curve (AUC) for both networks was 0.922, indicating strong discriminative ability.\n\nThe statistical significance of the results was not explicitly stated, but the consistent performance across multiple runs and the low variability in the metrics for Network B suggest that the method is robust and reliable. The use of standard deviations provides a clear indication of the confidence in the performance metrics, showing that the results are not just chance occurrences but reflect the true capabilities of the networks.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study involved a deep learning system based on deep convolutional neural networks (DCNN) to recognize orbital MRI for differentiating the active phase from the inactive phase in patients with thyroid-associated ophthalmopathy (TAO). The evaluation process included running the experiment four times to assess the stability of training and the convergence of loss values. The performance was measured using metrics such as accuracy, precision, sensitivity, specificity, and F1 score. Additionally, the receiver operating characteristic (ROC) curve and the area under the curve (AUC) were used to evaluate the effectiveness of the networks. The results of these evaluations are summarized in the study, but the raw data files used for these evaluations are not released to the public."
}