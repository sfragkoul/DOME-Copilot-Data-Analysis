{
  "publication/title": "Application of multi-modality MRI-based radiomics in the pre-treatment prediction of RPS6K expression in hepatocellular carcinoma.",
  "publication/authors": "Yang F, Wan Y, Shen X, Wu Y, Xu L, Meng J, Wang J, Liu Z, Chen J, Lu D, Wen X, Zheng S, Niu T, Xu X",
  "publication/journal": "Molecular biomedicine",
  "publication/year": "2023",
  "publication/pmid": "37482600",
  "publication/pmcid": "PMC10363521",
  "publication/doi": "10.1186/s43556-023-00133-3",
  "publication/tags": "- Molecular Biomedicine\n- Radiomics\n- Hepatocellular Carcinoma\n- MRI\n- Machine Learning\n- Nomogram\n- RPS6K Expression\n- mTOR Inhibitors\n- Immunohistochemistry\n- Clinical Translation",
  "dataset/provenance": "The dataset used in this study was sourced from patients diagnosed with liver masses and treated between January 2018 and May 2019 at the First Affiliated Hospital of Zhejiang University School of Medicine. The study retrospectively enrolled and evaluated these patients.\n\nThe dataset consists of 147 hepatocellular carcinoma (HCC) samples, which were used to create a tissue microarray. For model construction and validation, the patients were randomly divided into a training cohort of 104 patients and a validation cohort of 43 patients, maintaining a 7:3 ratio.\n\nThe data includes complete pre-surgery gadoxetic acid-enhanced MRI scans, paraffin-embedded surgical tumor biospecimens, and comprehensive clinical information. The inclusion criteria ensured that the data was of high quality, with complete and uncompromised medical images and clinical details. Exclusion criteria removed cases with distal metastasis, concurrent malignancies, unqualified MR images, small tumors, and incomplete clinical information.\n\nThe dataset has not been used in previous publications by the community. The raw data is available upon reasonable request to qualified researchers from the corresponding authors.",
  "dataset/splits": "The study utilized two primary data splits: a training cohort and a validation cohort. The training cohort consisted of 104 data points, while the validation cohort comprised 43 data points. These splits were created by randomly dividing the enrolled patients in a 7:3 ratio. This division was essential for constructing and validating the MRI-radiomics models for predicting RPS6K expression in hepatocellular carcinoma (HCC) patients. The training cohort was used to develop the models, while the validation cohort was employed to assess their performance and ensure the models' reliability and accuracy.",
  "dataset/redundancy": "The study involved a retrospective enrollment of patients diagnosed with liver mass and treated between January 2018 and May 2019. The patients were categorized into two groups based on the immunohistochemistry (IHC) score of RPS6K: high and low expression groups. For the construction and validation of the models, the patients were randomly divided into a training cohort and a validation cohort in a 7:3 ratio, resulting in 104 patients in the training cohort and 43 patients in the validation cohort.\n\nThe training and validation sets are independent. This independence was enforced through random assignment of patients to either the training or validation cohort. The random split ensures that the models are trained on one subset of data and then tested on a completely separate subset, which helps in evaluating the generalizability and robustness of the models.\n\nThe distribution of the datasets in this study is comparable to previously published machine learning datasets in medical research. The use of a 7:3 split is a common practice in medical imaging studies to ensure a sufficient number of samples for both training and validation while maintaining the independence of the datasets. This approach helps in mitigating overfitting and provides a more reliable assessment of the model's performance.",
  "dataset/availability": "The raw data of this manuscript is available to qualified researchers upon reasonable request. The corresponding authors are responsible for providing access to the data. This approach ensures that the data is shared responsibly and ethically, maintaining the privacy and confidentiality of the patients involved. The data is not publicly released in a forum, but it can be obtained by contacting the corresponding authors directly. The specific terms and conditions for data access, including any licensing agreements, would be determined on a case-by-case basis to ensure compliance with ethical and legal standards.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. Specifically, multiple logistic regression (MLR), support vector machine (SVM) with a Gaussian kernel, random forest (RF), and artificial neural network (ANN) algorithms were employed. These algorithms are not new but are chosen for their robustness and effectiveness in handling various types of data and predictive modeling tasks.\n\nThe decision to use these established algorithms rather than developing a new one is driven by several factors. First, these algorithms have been extensively validated and are known for their reliability in medical and biological research. Second, the focus of this study is on integrating clinical parameters and radiomics features to develop a predictive model for RPS6K expression in hepatocellular carcinoma (HCC) patients, rather than on innovating new machine-learning techniques. The primary goal is to leverage the strengths of these algorithms to achieve accurate and non-invasive predictions, which can guide clinical decision-making.\n\nGiven the context of the study, the use of these established algorithms ensures that the results are comparable with existing literature and can be readily applied in clinical settings. The emphasis is on the practical application of machine learning in medical diagnostics, rather than on the development of new algorithms. This approach aligns with the study's objective of bridging the gap between bench research and clinical practice.",
  "optimization/meta": "In our study, we developed a predictive nomogram that incorporates both radiomics features and clinical indices to enhance the prediction of RPS6K expression in hepatocellular carcinoma (HCC) patients. This nomogram can be considered a meta-predictor as it integrates outputs from various machine learning algorithms and clinical data.\n\nThe nomogram leverages the radiomics score (RadScore) derived from multiple machine learning algorithms, including multiple logistic regression (MLR), supporting vector machine (SVM), random forest (RF), and artificial neural network (ANN). These algorithms were used to construct predictive models based on radiomics features extracted from T2-weighted and diffusion-weighted imaging (DWI) phases. The best-performing model among these was the ANN-based hybrid model, which combined features from both imaging phases.\n\nIn addition to the RadScore, the nomogram includes a key clinical index, albumin (ALB), which was identified through statistical analysis as a significant factor. The combination of ALB with the RadScore resulted in a model with superior diagnostic performance, achieving an area under the curve (AUC) of 0.917 in the training cohort and 0.845 in the validation cohort.\n\nTo ensure the robustness of our meta-predictor, we maintained independent training and validation cohorts. The training cohort was used to develop and optimize the models, while the validation cohort was used to assess their performance. This separation ensures that the training data is independent of the validation data, reducing the risk of overfitting and providing a more reliable evaluation of the model's generalizability.\n\nThe calibration curves and Hosmer-Lemeshow test further validated the goodness-of-fit of the nomogram, indicating that it accurately predicts the probability of RPS6K expression in HCC patients. This meta-predictor offers a non-invasive and accurate tool for clinical decision-making, particularly in guiding mTOR-inhibitor (mTORi) therapy.",
  "optimization/encoding": "To prepare the data for the machine-learning algorithms, several preprocessing steps were undertaken. Initially, all images were resampled to a uniform voxel size of 1 \u00d7 1 \u00d7 1 mm\u00b3 using the bicubic interpolation method. This step ensured consistency across all image scans, reducing variability due to differences in image resolution.\n\nNext, the intensity values of the images were discretized into a range from 1 to 64. This discretization process helped to minimize differences among various image scans, making the features more comparable.\n\nA total of 547 radiomics features were extracted from each region of interest (ROI) using an open-source radiomics package in MATLAB 2016a. These features included shape features, histogram features, gray-level co-occurrence matrix (GLCM) features, gray-level run-length matrix (GLRLM) features, gray-level size zone matrix (GLSZM) features, neighborhood gray-tone difference matrix features, and wavelet-based features. Since two modalities of MR images were involved, a total of 1094 radiomics features were collected from each patient.\n\nTo account for differences in scale between various features, all radiomics features were normalized to a Z-score. This normalization involved subtracting the mean and dividing by the standard deviation of each feature. The mean and standard deviation of each feature in the training cohort were used to normalize the corresponding features in the validation cohort, ensuring consistency across datasets.\n\nThe Mann\u2013Whitney U tests and the Max-Relevance and Min-Redundancy (mRMR) algorithm were employed to perform feature dimension reduction and selection. Features with a two-sided p-value less than 0.05 were retained. The mRMR algorithm was used to identify the most relevant features to the status of RPS6K expression while minimizing redundancy. The specific number of radiomics features was determined through a fivefold cross-validation experiment in the training cohort, with the number of features set from three to ten. The optimal feature subset was identified based on the highest AUC value in the internal validation cohort.\n\nThis preprocessing and encoding pipeline ensured that the data was standardized and optimized for input into the machine-learning algorithms, facilitating accurate and reliable model construction and evaluation.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the specific algorithm and the phase of the imaging data. For the diffusion-weighted imaging (DWI) phase, the best-performing model was built using three radiomics features. For the T2 phase, the optimal model incorporated seven features. When considering multi-modality features, the best-performing model utilized six radiomics features.\n\nThe selection of these features was a meticulous process. Initially, we extracted a total of 1094 radiomics features from each patient, encompassing various types such as shape features, histogram features, gray-level co-occurrence matrix (GLCM) features, gray-level run-length matrix (GLRLM) features, gray-level size zone matrix (GLSZM) features, neighborhood gray-tone difference matrix features, and wavelet-based features. To manage this large dataset, we employed the Mann\u2013Whitney U test to filter out features with a two-sided p-value less than 0.05. Subsequently, we applied the Max-Relevance and Min-Redundancy (mRMR) algorithm to retain the most relevant features with minimal redundancy. The specific number of features was determined through a fivefold cross-validation experiment in the training cohort, with the number of features ranging from three to ten. The optimal feature subset was identified based on the highest Area Under the Curve (AUC) value in the internal validation cohort. This rigorous selection process ensured that the models were built with the most informative and non-redundant features, enhancing their predictive performance.",
  "optimization/features": "In our study, we initially extracted a large number of radiomics features from the delineated tumor regions of interest (ROIs) on both diffusion-weighted imaging (DWI) and T2-weighted imaging phases. Specifically, 547 radiomics features were extracted from each ROI, resulting in a total of 1094 features per patient due to the involvement of two MRI modalities.\n\nGiven the high dimensionality of the feature set, feature selection was performed to reduce dimensionality and retain the most relevant features. This process was conducted using the training cohort only, ensuring that the validation cohort remained independent for unbiased performance evaluation. The feature selection involved two main steps: first, features with a two-sided p-value less than 0.05 from Mann\u2013Whitney U tests were retained. Second, the Maximum Relevance Minimum Redundancy (mRMR) algorithm was applied to select features that were most relevant to the status of RPS6K expression while minimizing redundancy. The optimal number of features was determined through a fivefold cross-validation experiment in the training cohort, with the number of features ranging from three to ten.\n\nFor the single-phase models, the DWI-based model used a specific set of features, while the T2-based model utilized seven features. For the multi-modality hybrid model, six radiomics features were selected, demonstrating the best performance among the algorithms tested. These selected features were used to construct predictive models, including multiple logistic regression (MLR), support vector machine (SVM) with a Gaussian kernel, random forest (RF), and artificial neural network (ANN) algorithms. The performance of these models was evaluated using the area under the receiver operating characteristic curve (AUC) and other metrics.",
  "optimization/fitting": "In our study, we employed several strategies to address potential issues of overfitting and underfitting, given the large number of radiomics features relative to the number of training points.\n\nTo mitigate overfitting, we utilized a two-step feature selection process. Initially, we applied the Mann\u2013Whitney U test to filter out irrelevant features, retaining only those with a p-value less than 0.05. Subsequently, we employed the Max-Relevance and Min-Redundancy (mRMR) algorithm to select the most relevant features while minimizing redundancy. This process was further refined through a fivefold cross-validation experiment in the training cohort, ensuring that the selected features were robust and generalizable.\n\nAdditionally, we used regularization techniques inherent in the machine learning algorithms we employed. For instance, the support vector machine (SVM) with a Gaussian kernel and the random forest (RF) algorithm both incorporate mechanisms to prevent overfitting. The SVM achieves this through the regularization parameter, while the RF does so by averaging multiple decision trees.\n\nTo address underfitting, we constructed multiple models using different algorithms, including multiple logistic regression (MLR), SVM, RF, and artificial neural networks (ANN). By comparing the performance of these models, we ensured that our final model was complex enough to capture the underlying patterns in the data. The use of the Akaike Information Criterion (AIC) in the backward search method for variable selection also helped in balancing model complexity and fit, thereby avoiding underfitting.\n\nFurthermore, we validated our models using both training and validation cohorts, ensuring that the models generalized well to unseen data. The calibration curves and the Hosmer\u2013Lemeshow test confirmed the goodness-of-fit of our models, indicating that they were neither overfitted nor underfitted. The decision curve analysis (DCA) provided additional evidence of the models' clinical utility, demonstrating their ability to provide a net benefit across a range of threshold probabilities.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our models. One key method involved the use of cross-validation, specifically a fivefold cross-validation test, which helped in determining the optimal hyperparameters for model construction. This process was conducted using the training cohort, ensuring that the models generalized well to unseen data.\n\nAdditionally, feature selection was performed using the Mann\u2013Whitney U tests and the Max-Relevance and Min-Redundancy (mRMR) algorithm. This approach helped in reducing the dimensionality of the feature set, retaining only the most relevant features while minimizing redundancy. The specific number of radiomics features was determined through a fivefold cross-validation experiment in the training cohort, further enhancing the model's performance and preventing overfitting.\n\nThe calibration process also played a crucial role in model validation. It utilized a resampling algorithm with 1000 random experiments and 50 samples in each resampling experiment to evaluate the proposed model. This rigorous calibration process ensured that the models were well-calibrated and not overfitted to the training data.\n\nMoreover, the goodness of fit of the logistic models was assessed using the Hosmer\u2013Lemeshow test, which provided an additional layer of validation to ensure that the models were not overfitting the data. The risk was split into ten quantiles, and a false ordinal logistic regression model was set for calibration, further enhancing the model's reliability.\n\nIn summary, our study employed a combination of cross-validation, feature selection, and rigorous calibration processes to prevent overfitting and ensure the robustness of our predictive models.",
  "optimization/config": "The hyperparameters for model construction were determined through a fivefold cross-validation test conducted using the training cohort. The specific configurations and optimization schedules used for the models are not explicitly detailed in the main text, but the methods and packages used for statistical analyses and model construction are mentioned. These include IBM SPSS Statistics 20, R software (version 3.4.1), and various R packages such as \"rms,\" \"generalhoslem,\" \"pROC,\" and \"dca.R.\"\n\nThe raw data of this manuscript is available by the corresponding authors to qualified researchers upon reasonable request. This indicates that while the specific hyperparameter configurations and optimization parameters are not publicly available, they can be obtained by contacting the authors. The data and materials are subject to ethical approval and consent for publication, ensuring that the information is used responsibly.\n\nThe study was supported by several funding sources, including the National Key Research and Development Program of China, the Major Research Plan of the National Natural Science Foundation of China, and the Key Research & Development Plan of Zhejiang Province. These funding details are provided in the acknowledgments section, but specific information about the availability of model files or optimization parameters under a particular license is not mentioned.\n\nIn summary, while the hyperparameter configurations and optimization parameters are not publicly available, they can be requested from the authors. The study adheres to ethical guidelines and has been supported by various research grants.",
  "model/interpretability": "The model developed in this study, particularly the nomogram for RPS6K expression in HCC patients, is designed to be interpretable and transparent. Unlike black-box models, which often lack clear explanations for their predictions, the nomogram provides a visual representation that allows clinicians to understand how different variables contribute to the final prediction.\n\nThe nomogram incorporates both clinical indices and radiomics features, such as albumin (ALB) levels and the radiomics score (RadScore). These features are selected based on statistical significance and their ability to improve the model's performance. The inclusion of ALB and RadScore in the nomogram is justified by their strong association with RPS6K expression, as evidenced by the multivariable analysis and the model's low Akaike Information Criterion (AIC) value.\n\nThe calibration curves and the Hosmer-Lemeshow test further support the model's goodness-of-fit, indicating that the predicted probabilities align well with the observed outcomes. This transparency is crucial for clinical translation, as it allows healthcare providers to trust the model's predictions and use them to inform treatment decisions.\n\nIn summary, the nomogram model is not a black-box but a transparent tool that integrates clinical and radiomics data to predict RPS6K expression in HCC patients. This interpretability enhances the model's reliability and utility in clinical practice.",
  "model/output": "The model developed in this study is primarily a classification model. It focuses on predicting the expression status of RPS6K in hepatocellular carcinoma (HCC) patients. The performance of the model is evaluated using the Area Under the Receiver Operating Characteristic Curve (AUC), which is a common metric for assessing the effectiveness of classification models. The model incorporates both clinical indices and radiomics features, utilizing multiple logistic regression and other machine learning algorithms such as Support Vector Machine (SVM), Random Forest (RF), and Artificial Neural Network (ANN). The final predictive nomogram, which combines Albumin (ALB) and Radiomics Score (RadScore), demonstrates strong classification performance with high AUC values in both training and validation cohorts. Additionally, the model's clinical utility is evaluated through Decision Curve Analysis (DCA), further confirming its effectiveness in classification tasks.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the radiomics feature extraction process is available through an open-source radiomics package in MATLAB 2016a. This toolkit can be found and installed from the Add-On Explorer of MATLAB or accessed via an open-source repository on GitHub. The specific URL for the repository is https://github.com/mvallieres/radiomics.\n\nThe statistical analyses were performed using IBM SPSS Statistics 20 and R software (version 3.4.1). The R packages used include \"rms\" for creating nomograms and calibration tests, \"generalhoslem\" for assessing the goodness of fit of logistic models using the Hosmer\u2013Lemeshow test, \"pROC\" for AUC analysis, and \"dca.R\" for decision curve analysis. These packages are publicly available and can be installed from the Comprehensive R Archive Network (CRAN) or other relevant repositories.\n\nThe hyperparameters for model construction were determined through a fivefold cross-validation test conducted using the training cohort. The models constructed include multiple logistic regression (MLR), support vector machine (SVM) with a Gaussian kernel, random forest (RF), and artificial neural network (ANN) algorithms. The performance of these models was evaluated using the area under the receiver operating characteristic curve (AUC) and decision curve analysis (DCA).\n\nThe specific details of the algorithms derived models, including MLR, SVM, RF, and ANN, are provided in the supplementary material, specifically in Additional file 1: Supplementary Table 1 and Additional file 2: Supplementary Figure 1. These files contain detailed information about the overall enrollment of the study and the radiomics feature selection strategy.\n\nThe raw data of this manuscript is available by the corresponding authors to qualified researchers upon reasonable request. This ensures that the data and methods used in the study can be replicated and verified by other researchers in the field.",
  "evaluation/method": "The evaluation of the method involved several rigorous statistical and analytical techniques to ensure the robustness and accuracy of the models developed. Statistical analyses were performed using IBM SPSS Statistics 20 and R software, with a significance threshold set at a P-value of less than 0.05. For continuous variables, Mann\u2013Whitney U tests were employed, while chi-square tests were used for qualitative variables. Radiomics features and several clinical factors were considered continuous variables, whereas age, gender, and other discrete variables were analyzed using appropriate statistical tests.\n\nA two-step feature selection strategy was utilized to identify the most relevant clinical factors. Initially, univariate analysis with Mann\u2013Whitney or chi-square tests was conducted to select significant clinical factors. Subsequently, a multivariable analysis approach, specifically the backward search method using the Akaike Information Criterion (AIC) score, was employed to determine the optimal combination of variables for model development. This method carefully evaluated the quality of the developed models by considering both the binomial deviance and the number of variables.\n\nThe calibration process involved a resampling algorithm with 1000 random experiments and 50 samples in each resampling experiment to evaluate the proposed model. The goodness of fit of logistic models was assessed using the Hosmer\u2013Lemeshow test. The risk was split into ten quantiles, and a false ordinal logistic regression model was set for calibration. The Area Under the Curve (AUC) analysis was conducted using the \"pROC\" package, and Decision Curve Analysis (DCA) was performed using the \"dca.R\" function. Hyperparameters for model construction were determined through a fivefold cross-validation test conducted using the training cohort.\n\nThe Delong-test method was used to evaluate the significance among different models. The calibration curve was applied to evaluate the performance of the nomogram, with the degree of overlap between the calibration curve and the diagonal representing the predictive accuracy. Decision Curve Analysis (DCA) was employed to assess the additive value of the clinical index, with the threshold of predicted probability using the nomogram plotted on the x-axis and the clinical decision net benefit for patients on the y-axis. The decision curves for the treat-all scheme and the treat-none scheme were used as reference points in the DCA.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our predictive models. For the radiomics-based models, we primarily reported the Area Under the Curve (AUC) of the receiver operating characteristic (ROC) curve, which provides a comprehensive measure of the model's ability to discriminate between different classes. We calculated the AUC for both the training and validation cohorts to ensure the model's generalizability.\n\nFor the single-phase radiomics features, we evaluated models built using Diffusion Weighted Imaging (DWI) and T2-weighted imaging. The best-performing model for DWI features achieved an AUC of 0.717 in the validation cohort. For T2 features, the Support Vector Machine (SVM)-based model, utilizing seven specific T2 features, showed the best performance with an AUC of 0.802 in the validation cohort.\n\nIn addition to single-phase models, we developed multi-modality hybrid models that combined features from both DWI and T2 imaging. The Artificial Neural Network (ANN)-based hybrid model demonstrated superior performance, with an AUC of 0.887 in the training cohort and 0.826 in the validation cohort. This hybrid model outperformed the single-phase models, indicating the benefit of integrating multi-modality features.\n\nWe also constructed a clinical model using multiple logistic regression, which included six clinical indices. This model exhibited a moderate diagnostic ability with an AUC of 0.727 in the training cohort and 0.679 in the validation cohort. To enhance predictive accuracy, we incorporated the radiomics score (RadScore) with albumin (ALB) levels, resulting in a nomogram. This combined nomogram achieved the highest performance among all models, with an AUC of 0.917 in the training cohort and 0.845 in the validation cohort.\n\nTo assess the calibration of our models, we used the Hosmer-Lemeshow (H\u2013L) test, which indicated non-significant statistic deviations, suggesting good model fit. Decision Curve Analysis (DCA) was also performed to evaluate the clinical utility of the nomogram, comparing it against other models.\n\nThese performance metrics are widely used in the literature for evaluating predictive models in medical imaging and clinical research, ensuring that our results are comparable and representative of current standards.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of various models to evaluate their performance in predicting RPS6K expression. We assessed multiple machine learning algorithms, including Support Vector Machine (SVM), Multiple Logistic Regression (MLR), Random Forest (RF), and Artificial Neural Network (ANN). Each of these algorithms was applied to different sets of features, including single-phase radiomics features from Diffusion Weighted Imaging (DWI) and T2-weighted imaging, as well as multi-modality hybrid features.\n\nFor the DWI single-phase features, we found that the SVM-based model performed well, achieving an Area Under the Curve (AUC) of 0.717 in the validation cohort. Similarly, for the T2 single-phase features, the SVM-based model with seven T2 features showed the best performance, with an AUC of 0.802 in the validation cohort. These results indicate that SVM is a robust algorithm for single-phase radiomics feature analysis.\n\nIn the case of multi-modality hybrid features, the ANN-based hybrid model demonstrated superior performance compared to other algorithms. This model, developed with six radiomics features, achieved an AUC of 0.887 in the training cohort and 0.826 in the validation cohort. This suggests that combining features from multiple modalities can enhance predictive accuracy.\n\nAdditionally, we compared the performance of the hybrid model with other machine learning algorithms in the validation cohort. The SVM-based hybrid model had an AUC of 0.790, the MLR-based hybrid model also had an AUC of 0.790, and the RF-based hybrid model had an AUC of 0.752. These comparisons highlight the effectiveness of the ANN-based hybrid model in leveraging multi-modality features for improved prediction.\n\nFurthermore, we developed a clinical model using multiple logistic regression, which exhibited a mediocre diagnostic ability with an AUC of 0.679 in the validation cohort. We then constructed a nomogram incorporating Albumin (ALB) and Radiomics Score (RadScore), which demonstrated the best performance among all built models, with an AUC of 0.845 in the validation cohort. The calibration curves and decision curve analysis (DCA) further validated the goodness-of-fit and clinical utility of the nomogram.\n\nIn summary, our study involved a thorough comparison of different machine learning algorithms and feature sets, providing a robust evaluation of their predictive capabilities for RPS6K expression. The ANN-based hybrid model and the nomogram incorporating ALB and RadScore showed particularly promising results.",
  "evaluation/confidence": "The evaluation of our models included several statistical measures to ensure confidence in the results. We employed the Hosmer\u2013Lemeshow test to assess the goodness-of-fit of our logistic models, which helps in understanding how well the predicted probabilities match the observed outcomes. The calibration curves, which showed non-significant statistic deviations in both training and validation cohorts, further supported the reliability of our models.\n\nFor performance metrics, we reported the Area Under the Receiver Operating Characteristic Curve (AUC) with 95% confidence intervals. For instance, the nomogram constructed with ALB and RadScore achieved an AUC of 0.917 (95%CI: 0.847\u20130.962) in the training cohort and 0.845 (95%CI: 0.702\u20130.937) in the validation cohort. These confidence intervals provide a range within which the true AUC is likely to fall, giving a sense of the precision of our estimates.\n\nStatistical significance was determined using a P-value threshold of less than 0.05 for all tests. We used the Delong-test method to evaluate the significance among different models, ensuring that any claims of superiority were backed by robust statistical evidence. Additionally, the decision curve analysis (DCA) was employed to assess the clinical net benefit of our models, providing a practical measure of their utility in real-world settings.\n\nOverall, the combination of these statistical methods and performance metrics with confidence intervals ensures that our findings are reliable and that our models demonstrate significant improvement over baselines and other methods.",
  "evaluation/availability": "The raw data used in this manuscript is available to qualified researchers upon reasonable request. This data can be obtained from the corresponding authors, ensuring that those interested in replicating or building upon our findings have access to the necessary information. The availability of this data supports transparency and reproducibility in our research."
}