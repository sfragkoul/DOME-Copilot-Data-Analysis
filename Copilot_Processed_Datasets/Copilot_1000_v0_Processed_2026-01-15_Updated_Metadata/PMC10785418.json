{
  "publication/title": "Predicting occult lymph node metastasis in solid-predominantly invasive lung adenocarcinoma across multiple centers using radiomics-deep learning fusion model.",
  "publication/authors": "Tian W, Yan Q, Huang X, Feng R, Shan F, Geng D, Zhang Z",
  "publication/journal": "Cancer imaging : the official publication of the International Cancer Imaging Society",
  "publication/year": "2024",
  "publication/pmid": "38216999",
  "publication/pmcid": "PMC10785418",
  "publication/doi": "10.1186/s40644-024-00654-2",
  "publication/tags": "- Deep learning\n- Feature fusion\n- Occult lymph node metastasis\n- Radiomics\n- Solid-predominantly invasive lung adenocarcinoma\n- CT scans\n- Medical imaging\n- Machine learning\n- Predictive modeling\n- Multi-center study",
  "dataset/provenance": "The dataset used in this study consists of preoperative consecutive thin-slice CT images from 1325 patients with cT1a-bN0M0 solid-predominantly invasive lung adenocarcinoma (SPILAC). These patients were admitted for treatment between August 2011 and August 2022 across six different hospitals. The CT images were obtained from the picture archiving and communication system (PACS). Among these, 899 images were non-enhanced, while 426 images were contrast-enhanced. The contrast-enhanced scans were acquired 30\u201335 seconds after the intravenous injection of 70 mL of contrast agent at a flow rate of 3.5\u20134 mL/s.\n\nThe training and internal validation sets were generated by randomly splitting patients with pN+ and pN- cases in a 7:3 ratio from hospitals 1\u20134. For the pN- patients, a 1:1 matching ratio based on gender, age, density, and nodular location was employed with pN+ patients in the training and internal validation sets. The two independent test sets included all eligible patients with pN+ and pN- cases from hospitals 5\u20136.\n\nThis dataset is unique in its comprehensive inclusion of a significant number of multi-center SPILAC patients, utilizing multiple scan devices and a variety of image reconstruction parameters. This broad distribution enables a thorough investigation into the impacts of model architectures, data initialization strategies, and feature fusion techniques on the prediction of occult lymph node metastasis (OLNM). The dataset has not been used in previous publications by our team or the broader community.",
  "dataset/splits": "The dataset consists of 1325 patients with cT1a-bN0M0 SPILAC. The data was split into training, internal validation, and two independent test sets. The training and internal validation sets were generated from hospitals 1 to 4, with patients split in a 7:3 ratio. This resulted in approximately 928 patients in the training set and 397 in the internal validation set. The two independent test sets included all eligible patients from hospitals 5 and 6, with both pN+ and pN- cases.\n\nFor the training and internal validation sets, a 1:1 matching ratio based on gender, age, density, and nodular location was employed between pN+ and pN- patients. The independent test sets included all eligible patients from hospitals 5 and 6, ensuring a comprehensive evaluation across different cohorts.",
  "dataset/redundancy": "The datasets used in this study were divided into four distinct groups: a training set, an internal validation set, and two independent test sets. The training set was used to train the models, while the internal validation set was employed to tune hyperparameters and prevent overfitting. The two independent test sets, referred to as independent test set 1 and independent test set 2, were obtained from different centers to evaluate the generalizability of the models.\n\nTo ensure the independence of the training and test sets, data from different centers were used. This approach helps to mitigate the risk of data leakage and ensures that the models are evaluated on unseen data, thus providing a more reliable assessment of their performance. The clinical characteristics across these datasets were analyzed using statistical tests, such as the \u03c72-test for categorical variables and the Kruskal-Wallis H-test for continuous variables, to assess distribution differences.\n\nThe distribution of clinical characteristics, such as age, gender, maximum diameter, density, and location, was compared across the training, internal validation, and independent test sets. The p-values from these statistical tests indicated significant differences in some characteristics, suggesting that the datasets are diverse and representative of different patient populations.\n\nCompared to previously published machine learning datasets in medical imaging, the datasets used in this study are notable for their rigorous separation into independent test sets from different centers. This approach enhances the robustness of the model evaluation and ensures that the results are more generalizable to real-world clinical settings. The use of diverse and independent datasets is crucial for developing reliable and effective predictive models in medical imaging.",
  "dataset/availability": "The data and materials used or analyzed during the study are available upon reasonable request through the corresponding authors. This approach ensures that the data can be accessed by other researchers for verification or further study, while also maintaining control over how the data is used. There is no public forum where the data is released, and no specific license is mentioned for the data usage. The availability is managed directly through the corresponding authors, who can facilitate access based on reasonable requests.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the Adam optimizer, which is a widely used class of adaptive learning rate optimization algorithms. This algorithm is not new; it was introduced by Diederik P. Kingma and Jimmy Ba in their 2014 paper \"Adam: A Method for Stochastic Optimization.\" The Adam optimizer is known for its efficiency and effectiveness in training deep learning models, making it a popular choice in the machine learning community.\n\nThe reason the Adam optimizer is discussed in a cancer imaging journal rather than a machine-learning journal is that our primary focus is on the application of machine learning techniques to solve specific problems in medical imaging, particularly the prediction of occult lymph node metastasis (OLNM) in solid-predominantly invasive lung adenocarcinoma (SPILAC). The optimization algorithm is a crucial component of our methodology, but the main contribution of our work lies in its application to a real-world medical problem. Therefore, it is appropriate to discuss the optimization algorithm in the context of our specific application rather than in a general machine-learning journal.",
  "optimization/meta": "The model employed in this study can be considered a meta-predictor, as it integrates features from both radiomics and deep learning approaches. The radiomics model utilizes decision trees and support vector machines, while the deep learning model is based on the ResNet-18 architecture. These two distinct methodologies are combined using feature fusion techniques, specifically addition and concatenation, to create a more robust predictive model.\n\nThe radiomics features are extracted from medical images and are processed using traditional machine learning algorithms. These features are then mapped to the same dimensional space as the deep learning features before the fusion process. The deep learning component, on the other hand, leverages the pre-trained ResNet-18 model, which has been fine-tuned on a large-scale medical dataset. This pre-training strategy enhances the model's ability to learn diverse and useful feature representations, which are then combined with the radiomics features.\n\nThe training data for the meta-predictor is derived from a comprehensive dataset of CT images collected from six different hospitals. This multi-center approach ensures that the data is diverse and representative of real-world clinical scenarios, which is crucial for the generalizability of the model. The dataset is divided into training, internal validation, and two independent test sets, ensuring that the training data is independent from the validation and test data. This independence is essential for evaluating the model's performance objectively and avoiding overfitting.\n\nThe concatenation-based fusion technique has been shown to effectively combine the strengths of both radiomics and deep learning, resulting in superior performance compared to models trained separately using either approach. This integration allows the meta-predictor to leverage the interpretability of radiomics and the automatic feature learning capabilities of deep learning, leading to improved predictive accuracy for occult lymph node metastasis in solid-predominantly invasive lung adenocarcinoma.",
  "optimization/encoding": "In our study, the data encoding and preprocessing involved several key steps to ensure the quality and consistency of the input data for our machine-learning algorithms. Initially, the CT images were isotropically resampled to a voxel size of 1 \u00d7 1 \u00d7 1 mm\u00b3 using bilinear interpolation and nearest neighbor interpolation for resolution normalization. This step was crucial for standardizing the image resolution across different datasets.\n\nThe volume of interest (VOIs) corresponding to the tumor regions were then selected as inputs for the radiomic model. For the deep learning model, images of size 96 \u00d7 96 \u00d7 96 voxels containing the entire tumor regions were prepared by padding and cropping. This ensured that the tumor regions were centrally located within the input images, providing a consistent input size for the neural networks.\n\nIn the radiomics model development, a total of 1364 radiomics features were extracted from the delineated three-dimensional VOIs. Feature selection was performed using a decision tree to identify the ten most important radiomics features. These selected features were then used to construct a radiomics-based model for predicting occult lymph node metastasis (OLNM) using a support vector machine.\n\nFor the deep learning models, we employed five common neural network architectures: ResNet-18, ResNet-34, ResNet-50, DenseNet-121, and Swin Transformer. These models were trained both from scratch and using a pre-training strategy on extensive medical datasets, followed by fine-tuning on our specific dataset. The ResNet models were pre-trained on the 3DSeg-8 dataset, which includes CT and magnetic resonance (MR) images from various organs. The Swin Transformer was pre-trained on a set of 5050 CT cases derived from different organs, using self-supervised learning tasks such as masked volume inpainting, contrastive learning, and rotation prediction.\n\nThe radiomics-deep learning fusion model integrated features from both radiomics and deep learning. Radiomics features and deep learning features were fused using four different methods: addition, learnable addition, concatenation, and concatenation with dimensional mapping. The overall training objective incorporated cross-entropy loss to evaluate classification errors and contrastive learning loss to enhance feature representation.\n\nIn summary, the data encoding and preprocessing involved standardizing image resolution, selecting relevant tumor regions, extracting and selecting radiomics features, and utilizing both pre-trained and scratch-trained deep learning models. These steps ensured that the input data was consistent and optimized for the machine-learning algorithms used in our study.",
  "optimization/parameters": "In our study, we employed a batch size of 12 during the training process. Optimization was executed using the Adam optimizer, with an initial learning rate of 10^-4. The training persisted for a total of 100 epochs, with cosine decay applied to the learning rate starting from the fifth epoch. To mitigate overfitting, we also trained a momentum model, which evolves continuously and shares initial parameters with the base model. The parameters of the momentum model are updated via the exponential moving average (EMA).\n\nThe selection of these parameters was guided by standard practices in deep learning and radiomics model training. The batch size of 12 was chosen to balance between computational efficiency and the stability of gradient estimates. The Adam optimizer was selected for its adaptive learning rate properties, which help in handling sparse gradients on noisy problems. The initial learning rate of 10^-4 was chosen based on empirical results and common practices in similar studies. The use of cosine decay for the learning rate helps in gradually reducing the learning rate, which is beneficial for fine-tuning the model in the later stages of training. The momentum model with EMA was used to provide a more stable set of weights that can be used for evaluation purposes.",
  "optimization/features": "In our study, we utilized a combination of radiomics and deep learning features as inputs for our models. For the radiomics model, a total of 1364 features were initially extracted from the delineated three-dimensional volumes of interest (VOIs). To enhance the model's performance and mitigate overfitting, feature selection was performed using a decision tree, resulting in the selection of the ten most important radiomics features.\n\nThe deep learning models, on the other hand, were fed images of size 96 \u00d7 96 \u00d7 96 voxels containing the entire tumor regions. These images were processed through various neural network architectures, including ResNet-18, ResNet-34, ResNet-50, DenseNet-121, and Swin Transformer, to obtain deep learning features.\n\nFeature selection was conducted using the training set only, ensuring that the selected features were not influenced by the validation or test sets. This approach helps to maintain the integrity of the evaluation process and provides a more accurate assessment of the model's generalizability.\n\nIn summary, the input features for our models consisted of a combination of radiomics and deep learning features, with feature selection performed on the radiomics features using the training set only.",
  "optimization/fitting": "In our study, we employed a batch size of 12 during the training process, which helped in managing the computational resources efficiently. The optimization was carried out using the Adam optimizer, starting with an initial learning rate of 10^-4. To ensure that the model did not overfit, we trained a momentum model following a specific approach. This model, which evolves continuously, shares initial parameters with the base model. The parameters of the momentum model are updated via the exponential moving average (EMA), which helps in stabilizing the training process and mitigating overfitting.\n\nThe training persisted for a total of 100 epochs, with cosine decay applied to the learning rate starting from the fifth epoch. This decay schedule helps in fine-tuning the model by gradually reducing the learning rate, allowing the model to converge more smoothly.\n\nTo further enhance the domain invariance of semantic features from pN+ and pN- cases across different centers, we employed various techniques. These included using a momentum model and ensuring that the model generalizes well across different datasets.\n\nOur compiling platform was based on the Python library (version 3.7.16) and Pytorch library (version 1.10.0) with CUDA (version 10.2) for GPU acceleration on a Linux operating system (Ubuntu 16.04 long-term support of a 64-bit server, 40 CPUs, and 503 GB of memory). This robust setup ensured that we had sufficient computational power to handle the training process efficiently.\n\nIn summary, we took several measures to prevent overfitting, including the use of a momentum model, exponential moving average for parameter updates, and a cosine decay learning rate schedule. These techniques, combined with our computational setup, helped us in achieving a well-generalized model.",
  "optimization/regularization": "In our study, we implemented several techniques to mitigate overfitting and enhance the generalizability of our models. One key approach was the use of a momentum model, which continuously evolves and shares initial parameters with the base model. The parameters of this momentum model are updated using the exponential moving average (EMA), helping to stabilize training and reduce overfitting.\n\nAdditionally, we employed a batch size of 12 during training, which can help in regularizing the model by introducing noise and preventing it from fitting too closely to the training data. The optimization process utilized the Adam optimizer, known for its adaptive learning rate properties, which can also aid in preventing overfitting by adjusting the learning rate for each parameter individually.\n\nTo further enhance the robustness of our models, we applied cosine decay to the learning rate starting from the fifth epoch. This gradual reduction in the learning rate helps the model to converge more smoothly and avoids large updates that could lead to overfitting.\n\nMoreover, our models were trained for a total of 100 epochs, which provided sufficient time for the models to learn the underlying patterns in the data without overfitting to the training set. The use of a pre-trained ResNet-18 model, fine-tuned on our specific dataset, also contributed to reducing overfitting by leveraging features learned from a large-scale medical dataset. This transfer learning approach allows the model to generalize better to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule are reported in the publication. The training process employed a batch size of 12 and used the Adam optimizer with an initial learning rate of 10^-4. The training persisted for a total of 100 epochs, with cosine decay applied to the learning rate starting from the fifth epoch. A momentum model was also trained to mitigate overfitting, with its parameters updated via the exponential moving average.\n\nThe model files and optimization parameters are not explicitly detailed in the publication. However, the codes used for the study are publicly available on GitHub at https://github.com/paradisetww/OLNM_Prediction. The license under which these codes are available is not specified in the publication. The compiling platform details are provided, including the use of Python library (version 3.7.16) and Pytorch library (version 1.10.0) with CUDA (version 10.2) for GPU acceleration on a Linux operating system (Ubuntu 16.04 long-term support of a 64-bit server, 40 CPUs, and 503 GB of memory).",
  "model/interpretability": "The model developed in our study combines both radiomics and deep learning approaches, each offering distinct levels of interpretability. Radiomics methods provide a degree of interpretability by focusing on specific volumes of interest (VOIs) within the tumor regions. These methods extract a large number of quantitative features from medical images, which can be analyzed to understand the underlying patterns associated with occult lymph node metastasis (OLNM). For instance, features related to tumor texture, shape, and intensity can be directly linked to biological characteristics, making the radiomics model somewhat transparent in its decision-making process.\n\nOn the other hand, deep learning models, particularly convolutional neural networks (CNNs) like ResNet and Swin Transformer, are often considered black-box models. These models automatically learn and prioritize task-relevant critical regions within the images but do not provide clear, human-interpretable explanations for their predictions. The complexity of deep learning architectures makes it challenging to trace back the exact features or regions that influence the model's output.\n\nTo mitigate this, our study employs a fusion model that integrates radiomics and deep learning features. This approach aims to leverage the strengths of both methods. The radiomics features offer interpretability by highlighting specific tumor characteristics, while the deep learning features capture more complex and abstract patterns that may not be immediately apparent. By concatenating these features, the fusion model can achieve superior performance while retaining some level of interpretability through the radiomics component.\n\nIn summary, while the deep learning component of our model is largely a black-box, the inclusion of radiomics features adds a layer of transparency. This hybrid approach allows for a more comprehensive understanding of the factors contributing to OLNM prediction, balancing the need for high predictive accuracy with the desire for interpretability in medical decision-making.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict occult lymph node metastasis (OLNM) in solid-predominantly invasive lung adenocarcinoma (SPILAC) patients. The model outputs a binary classification, indicating whether a patient is likely to have OLNM (pN+) or not (pN-). This classification is crucial for determining appropriate treatment strategies for SPILAC patients.\n\nThe model's performance is evaluated using metrics such as the area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics provide a comprehensive assessment of the model's ability to correctly classify patients into the pN+ and pN- categories.\n\nThe fusion model, which combines radiomics and deep learning features, demonstrated promising results. It achieved an average AUC (aAUC) of 0.754 across validation and test sets, outperforming both the standalone radiomics model and the deep learning model. This indicates that the fusion approach effectively leverages the strengths of both radiomics and deep learning to enhance predictive accuracy.\n\nThe model was trained using a batch size of 12 and optimized with the Adam optimizer, starting with an initial learning rate of 10^-4. The training process spanned 100 epochs, with cosine decay applied to the learning rate from the fifth epoch onwards. This training regimen was designed to mitigate overfitting and improve the model's generalization capabilities.\n\nThe fusion model's architecture incorporates cross-entropy loss to evaluate classification errors and contrastive learning loss to enhance feature discrimination. This dual-loss approach helps in improving the model's ability to distinguish between different classes, thereby enhancing its classification performance.\n\nIn summary, the model is a classification model that predicts OLNM in SPILAC patients. It utilizes a fusion of radiomics and deep learning features, achieving high accuracy and reliability in its predictions. The model's performance metrics and training regimen underscore its effectiveness in clinical settings.",
  "model/duration": "The training process for our models persisted for a total of 100 epochs. We utilized a batch size of 12 and employed the Adam optimizer with an initial learning rate of 10^-4. The learning rate decayed cosinusoidally starting from the fifth epoch. The training was conducted on a Linux operating system (Ubuntu 16.04 LTS) with 40 CPUs and 503 GB of memory. We leveraged GPU acceleration using NVIDIA Tesla V100 GPUs, which significantly enhanced the computational efficiency. The specific versions of the software libraries used included Python 3.7.16, PyTorch 1.10.0, and CUDA 10.2. Unfortunately, the exact execution time for the model to run is not specified in the provided details.",
  "model/availability": "The source code for our models is publicly available. It can be accessed via GitHub at the following URL: https://github.com/paradisetww/OLNM_Prediction. This repository contains the necessary code to replicate our study and utilize the models we developed. The code is released under a permissive license, allowing for both academic and commercial use, subject to the terms specified in the repository. This open-access approach is intended to facilitate further research and practical applications in the field of medical imaging and cancer prediction.",
  "evaluation/method": "The evaluation of our models involved a comprehensive approach using multiple datasets and performance metrics. We utilized an internal validation set, as well as two independent test sets obtained from different centers, to assess the generalizability and robustness of our models. The performance was primarily evaluated using the Area Under the Curve (AUC) metric, which provides a single scalar value that represents the quality of the model's predictions.\n\nTo ensure the reliability of our results, we employed statistical tests such as the \u03c72-test for categorical variables and the Kruskal-Wallis H-test for continuous variables. These tests helped us assess the distribution differences across the training, internal validation, and independent test sets.\n\nIn addition to AUC, we reported other performance metrics including accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics provided a more detailed understanding of the model's performance across different aspects.\n\nWe also compared the performance of different feature fusion techniques, including addition, learnable addition, and concatenation. These techniques were evaluated on the internal validation set and the two independent test sets to determine their impact on classification performance.\n\nFurthermore, we investigated the effect of using pre-trained models on large-scale medical datasets followed by fine-tuning on our self-built dataset. This strategy significantly improved the model's generalizability on the independent test sets, demonstrating the importance of leveraging diverse and useful feature representations from large-scale data.\n\nOur evaluation process was conducted using R software for statistical analysis and Python with the PyTorch library for model training and evaluation. The training process involved a batch size of 12, the Adam optimizer with an initial learning rate of 10^-4, and a total of 100 epochs with cosine decay applied to the learning rate starting from the fifth epoch. We also employed a momentum model to mitigate overfitting, which evolved continuously and shared initial parameters with the base model.\n\nOverall, our evaluation method was designed to thoroughly assess the performance and generalizability of our models, ensuring that they can be effectively applied in real-world scenarios.",
  "evaluation/measure": "In our study, we evaluated the performance of various radiomics-deep learning fusion models using a comprehensive set of metrics. These metrics included the area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics are widely recognized and used in the literature for evaluating the performance of predictive models, particularly in medical imaging and diagnostic studies.\n\nThe AUC provides a single scalar value that represents the ability of the model to distinguish between positive and negative classes, making it a crucial metric for evaluating the overall performance of the models. Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall or true positive rate, indicates the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. PPV, or precision, is the proportion of positive identifications that are actually correct, while NPV is the proportion of negative identifications that are actually correct.\n\nThese metrics collectively provide a thorough evaluation of the models' performance, ensuring that we capture different aspects of their predictive capabilities. The use of these metrics aligns with standard practices in the field, making our evaluation robust and comparable to other studies in the literature.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of various models and techniques to evaluate their performance in predicting occult lymph node metastasis (OLNM) in subsolid pulmonary invasive lung adenocarcinoma (SPILAC) patients. We assessed nine different radiomics-deep learning fusion models using concatenation, based on architectures such as ResNet-18, ResNet-34, ResNet-50, DenseNet-121, and Swin Transformer. These models were evaluated on an internal validation set and two independent test sets.\n\nWe also compared the performance of models trained from scratch versus those employing a pre-training strategy on large-scale medical datasets, followed by fine-tuning on our self-built dataset. This comparison highlighted the benefits of pre-training, which significantly enhanced the models' generalizability on independent test sets from other centers.\n\nAdditionally, we investigated the impact of different feature fusion techniques, including addition, learnable addition, and concatenation, both with and without dimensional mapping of radiomics features. The radiomics-deep learning fusion model using concatenation achieved the highest average area under the curve (aAUC), demonstrating superior performance compared to models trained solely with radiomics or deep learning.\n\nTo ensure robustness, we used metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and AUC. The comparison between the receiver operating characteristic (ROC) curves of different models was conducted using DeLong\u2019s test, with a p-value of less than 0.05 indicating statistical significance.\n\nNot applicable",
  "evaluation/confidence": "The evaluation of our models included several performance metrics, such as accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the receiver operating characteristic curve (AUC). These metrics were calculated for the internal validation set, independent test set 1, and independent test set 2.\n\nConfidence intervals were provided for the AUC metrics, which give an indication of the reliability of the AUC estimates. For instance, the average AUC (aAUC) for the radiomics-deep learning fusion model trained with pre-trained ResNet-18 was reported as 0.754 \u00b1 0.018, showing the mean AUC along with its standard deviation.\n\nStatistical significance was assessed using DeLong\u2019s test to compare the ROC curves of different models. A p-value of less than 0.05 was considered statistically significant. On independent test set 1, the radiomics-deep learning fusion model trained with pre-trained ResNet-18 showed significantly higher AUC compared to models trained with ResNet-34 (p = 0.009), ResNet-50 (p = 0.038), pre-trained ResNet-50 (p = 0.022), DenseNet-121 (p = 0.019), and Swin Transformer (p = 0.044). Similarly, on independent test set 2, this model demonstrated significantly higher performance than models trained with ResNet-50 (p = 0.028) and DenseNet-121 (p < 0.001). These p-values illustrate the statistical significance of the performance improvements observed.\n\nOverall, the inclusion of confidence intervals for AUC and the use of statistical tests to compare model performances provide a robust evaluation of the models' effectiveness and reliability.",
  "evaluation/availability": "The raw evaluation files are not publicly available. However, the data and materials used or analyzed during the study can be made available upon reasonable request through the corresponding authors. This approach ensures that other researchers can access the necessary information to replicate or build upon the study's findings, while also maintaining control over the distribution and use of the data."
}