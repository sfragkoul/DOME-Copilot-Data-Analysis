{
  "publication/title": "A Predictive Machine Learning Tool for Asthma Exacerbations: Results from a 12-Week, Open-Label Study Using an Electronic Multi-Dose Dry Powder Inhaler with Integrated Sensors.",
  "publication/authors": "Lugogo NL, DePietro M, Reich M, Merchant R, Chrystyn H, Pleasants R, Granovsky L, Li T, Hill T, Brown RW, Safioti G",
  "publication/journal": "Journal of asthma and allergy",
  "publication/year": "2022",
  "publication/pmid": "36387836",
  "publication/pmcid": "PMC9664923",
  "publication/doi": "10.2147/jaa.s377631",
  "publication/tags": "- Digital inhalers\n- Machine learning\n- Asthma exacerbations\n- Predictive modeling\n- Personalized medicine\n- Respiratory diseases\n- Gradient-boosting trees\n- Albuterol use\n- Peak inspiratory flow\n- Inhaler sensors",
  "dataset/provenance": "The dataset used in this study was sourced from a 12-week, open-label study involving adult patients with poorly controlled asthma. The study was conducted across 45 centers in the USA between February 2017 and February 2018. Patients were enrolled if they had a physician diagnosis of asthma, at least one moderate or severe asthma exacerbation in the 12 months prior to screening, and poorly controlled asthma as defined by an Asthma Control Questionnaire-5 (ACQ-5) score of \u22651.5.\n\nA total of 449 patients were screened, and 397 were enrolled in the intention-to-treat population. Of these, 360 patients completed the study with at least one valid inhalation using the Digihaler, making them eligible for the predictive analysis dataset. Further exclusions were applied, resulting in a final predictive analysis population of 298 patients.\n\nThe data collected included inhaler use, peak inspiratory flow (PIF), inhalation volume, inhalation duration, and time to PIF, all recorded by the ProAir Digihaler. Additionally, baseline demographic information and clinical data were gathered. This dataset was used to develop a machine learning model aimed at predicting impending asthma exacerbations.\n\nThe dataset has not been used in previous papers by the community, as this study represents an original research effort to develop a predictive machine learning tool for asthma exacerbations using data from an electronic multi-dose dry powder inhaler with integrated sensors.",
  "dataset/splits": "The dataset was divided into three main splits: the training set, the test set, and the validation set. The training set comprised 184 patients, the test set comprised 60 patients, and the validation set comprised 54 patients. The training set was further partitioned into four mutually exclusive and collectively exhaustive subsets. In each repeat of the training process, the algorithm was trained on data from three of these subsets, ensuring that the model was robust and generalizable. This approach allowed for a comprehensive evaluation of the model's predictive performance. The distribution of data points in each split was designed to balance the need for adequate training data with the requirement for reliable testing and validation.",
  "dataset/redundancy": "The dataset was divided into three distinct groups: a training set, a test set, and a validation set. The training set comprised 184 patients, the test set included 60 patients, and the validation set consisted of 54 patients. This division was crucial for ensuring that the model was trained, optimized, and validated independently.\n\nTo enforce independence between the training and test sets, a 4-fold cross-validation technique was employed. This method involved randomly partitioning the training set into four mutually exclusive and collectively exhaustive subsets. In each of the four distinct repeats, the algorithm was trained on data from three of these subsets, ensuring that the model did not see the same data during both training and testing phases. This approach helped to mitigate overfitting and provided a more robust evaluation of the model's performance.\n\nThe distribution of the dataset in this study is designed to be comparable to other machine learning datasets used in similar predictive modeling tasks. By using a combination of case report form data, Digihaler data, and baseline characteristics, the dataset aims to capture a comprehensive set of features that are relevant to predicting asthma exacerbations. This approach aligns with previous studies that have attempted to develop predictive models using clinical and billing data, but it goes further by incorporating day-to-day variations in disease activity.\n\nThe use of gradient-boosting trees, specifically the XG-Boost implementation, was identified as the most appropriate algorithm for this predictive model. This choice was based on its ability to handle sparse data and iteratively combine trees to optimize the predictive model. The model's performance was evaluated using the receiver operating characteristics (ROC) curve of sensitivity versus specificity, with the ROC area under the curve (AUC) value representing the model's capability to separate between classes. The ROC AUC was computed separately for each group and then averaged to provide a single quality measure for the model. This method ensures that the model's performance is assessed comprehensively and reliably.",
  "dataset/availability": "The datasets used and analyzed in this study are available upon reasonable request. Qualified researchers can request access to patient-level data and related study documents, including the study protocol and the statistical analysis plan. To protect the privacy of trial participants and to safeguard commercially confidential information, patient-level data will be de-identified, and study documents will be redacted accordingly. Requests for data access should be directed to Guilherme Safioti. This approach ensures that the data is shared responsibly while maintaining the necessary confidentiality and ethical standards.",
  "optimization/algorithm": "The machine-learning algorithm class used is gradient-boosting trees. This technique is well-established and has been utilized in various fields, including computational biology. Specifically, the XG-Boost implementation of gradient-boosting was employed. XG-Boost is known for its efficiency in handling sparse data and its ability to iteratively combine trees to optimize predictive models.\n\nThis algorithm is not new; it has been previously described and validated in the literature. For instance, the gradient-boosting technique was detailed in a statistical publication. The choice to use this algorithm in the current study was driven by its proven effectiveness in predictive modeling, particularly in scenarios requiring high accuracy and the ability to handle complex datasets.\n\nThe decision to implement XG-Boost in this context was based on its strong performance in predictive tasks, as demonstrated in previous studies. The algorithm's ability to manage sparse data and its iterative optimization process made it a suitable choice for developing a model that could accurately predict impending asthma exacerbations. The focus of the current study is on the application of this algorithm to a specific medical problem, rather than the development of a new machine-learning technique. Therefore, it was published in a journal focused on asthma and allergy, rather than a machine-learning journal.",
  "optimization/meta": "The model developed for predicting impending asthma exacerbations does not function as a meta-predictor. Instead, it relies on a single machine learning technique, specifically gradient-boosting trees, to make predictions. The gradient-boosting model, particularly the XG-Boost implementation, was chosen for its ability to handle sparse data and optimize predictive accuracy through an iterative process.\n\nSeveral supervised machine learning algorithms, including logistic regression, random forest, and gradient-boosting trees, were initially applied to the data. However, gradient-boosting trees demonstrated the strongest performance on the test set and were subsequently evaluated on the validation set. This indicates that the final model does not combine predictions from multiple machine learning algorithms but rather uses gradient-boosting trees exclusively.\n\nThe data used for training, testing, and validating the model were carefully partitioned to ensure independence. Patients were randomly divided into three groups: a training set, a test set, and a validation set. The training set was used to develop the model, the test set was used to optimize it, and the validation set was used to evaluate its performance. A 4-fold cross-validation technique was employed to compare the predictive performance metrics of the algorithms, further ensuring that the training data was independent and that the model's performance was robust.\n\nIn summary, the predictive model for asthma exacerbations is based solely on gradient-boosting trees and does not incorporate data from other machine-learning algorithms as input. The training data for the model was independently partitioned to ensure reliable and unbiased performance evaluation.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the machine-learning algorithm could effectively learn from the input features. We began by collecting a variety of data from the ProAir Digihaler, including inhaler use, peak inspiratory flow (PIF), inhalation volume, inhalation duration, and time to PIF. Additionally, we gathered baseline demographic information and clinical data from the patients.\n\nThe data on the number of inhalations and inhalation parameters from the days preceding the prediction were combined with baseline features. Although data on actual ACQ-5 scores and lung function were not collected, the available data were sufficient for our predictive model. Respiratory symptoms were not collected after enrollment, so they were not included in the model.\n\nTo develop the predictive model, we applied machine learning techniques to a combination of case report form data, Digihaler data, and patient baseline characteristics. The number of inhalations and the mean of each inhalation parameter during the first 10 days of the study were considered as baseline features. A feature engineering process was conducted to determine the most relevant features for the model.\n\nThe data inputs were converted into explanatory variables structured suitably for predictive modeling. Several supervised machine learning algorithms, including logistic regression, random forest, and gradient-boosting trees, were applied. The patients were randomly divided into three groups: a training set to train the model, a test set to optimize the model, and a validation set to validate the chosen model. A 4-fold cross-validation technique was used to compare the predictive performance metrics of the algorithms. This involved partitioning the training set into four mutually exclusive and collectively exhaustive subsets, and training the algorithm in four distinct repeats, each time using data from three of the subsets.\n\nThe relevance of the features used for the model was given as a percentage, relating to the variance reduced by data splits in the feature engineering that used this variable among all trees of the model. A large percentage variance reduction indicated that the feature had a large amount of relevance to the model and contributed significantly to its performance. The feature with the highest weight in the model was the mean number of daily inhalations during the 4 days prior to the day the prediction was made. This feature was particularly important in identifying patterns that could predict impending exacerbations.",
  "optimization/parameters": "In the optimization of our predictive model, we utilized a combination of parameters derived from various sources to enhance its accuracy. The primary input parameters included case report form data collected on the first day of the study, such as age, body mass index, blood pressure, and the history of previous exacerbations and hospitalizations. Additionally, data from the Digihaler, including the timestamp of inhalation, inhalation status, peak inspiratory flow (PIF), inhalation volume, time to PIF, and inhalation duration, were crucial. The number of inhalations and the mean of each inhalation parameter during the first 10 days of the study were considered as baseline features.\n\nTo determine the most relevant features, a feature engineering process was conducted. This process involved evaluating the importance of various parameters in predicting impending exacerbations. The strongest predictive factors identified were the mean number of daily inhalations during the 4 days prior to the prediction, which contributed significantly to the model's performance. Other important features included the inhalation parameters during the 4 days prior to prediction and comparisons to baseline inhalation parameters.\n\nThe selection of these parameters was based on their ability to provide meaningful insights into the patient's respiratory health and their potential to improve the model's predictive accuracy. The gradient-boosting algorithm, specifically the XG-Boost implementation, was chosen for its effectiveness in handling sparse data and optimizing the predictive model through iterative tree combinations. This approach allowed us to balance the accuracy of predictions with the need for timely intervention, ultimately enhancing the model's reliability and practical applicability.",
  "optimization/features": "The predictive model utilized a combination of features derived from various data sources. These included case report form data collected on study Day 1, such as age, body mass index, blood pressure, previous exacerbations, and the number of exacerbations and hospitalizations in the previous 12 months. Additionally, data from the Digihaler, both prior to and including the day of the prediction, were used. This included baseline characteristics like the timestamp of inhalation, inhalation status, peak inspiratory flow (PIF), inhalation volume, time to PIF, and inhalation duration. The number of inhalations and the mean of each inhalation parameter during the first 10 days of the study were considered as baseline features.\n\nA feature engineering process was conducted to determine the most relevant features for the model. This process involved converting the data inputs into explanatory variables structured suitably for predictive modeling. Several supervised machine learning algorithms, including logistic regression, random forest, and gradient-boosting trees, were applied. The gradient-boosting algorithm, specifically the XG-Boost implementation, displayed the strongest performance on the test set and was subsequently evaluated on the validation set.\n\nThe features that contributed most to the model's performance included the number of inhalations during the 4 days prior to prediction, inhalation parameters during the same period, and trends of inhalation parameters prior to prediction. Other features, such as history of previous exacerbations and comorbidities, body mass index, and systolic blood pressure, also contributed to the model's performance.\n\nThe feature selection process was performed using the training set only, ensuring that the model's performance was evaluated on unseen data during the testing and validation phases. This approach helped in identifying the most relevant features that significantly contributed to the predictive model's accuracy.",
  "optimization/fitting": "The predictive model employed in this study utilized gradient-boosting trees, specifically the XG-Boost implementation, which is well-suited for handling sparse data and iteratively combining trees to optimize predictive performance. The model was trained on a dataset comprising 184 patients, with an additional 60 patients in the test set and 54 in the validation set. This division ensured that the model was trained on a substantial number of data points, reducing the risk of overfitting.\n\nTo mitigate overfitting, several techniques were employed. Firstly, a 4-fold cross-validation technique was used, which involved partitioning the training set into four subsets. The model was trained on three of these subsets and validated on the remaining one, repeating this process four times. This approach helped in assessing the model's performance on different subsets of the data, ensuring that it generalized well to unseen data.\n\nAdditionally, feature engineering was conducted to determine the most relevant features for the model. This process involved converting raw data inputs into explanatory variables structured suitably for predictive modeling, thereby reducing the dimensionality and focusing on the most informative features. The relevance of each feature was quantified as a percentage of variance reduction, indicating its contribution to the model's performance.\n\nThe model's performance was evaluated using the receiver operating characteristic (ROC) curve and the area under the curve (AUC) value. The ROC AUC value of 0.83 for the validation set indicated strong discriminative ability, suggesting that the model was not underfitting. Furthermore, the model's sensitivity and specificity at various risk percentiles were analyzed, providing a comprehensive view of its predictive accuracy.\n\nIn summary, the model's architecture, cross-validation technique, and feature engineering process collectively ensured that overfitting was minimized and underfitting was avoided, resulting in a robust predictive model for anticipating exacerbations in asthma patients.",
  "optimization/regularization": "The predictive model employed gradient-boosting trees, specifically the XG-Boost implementation. This algorithm is designed to handle sparse data and iteratively combines trees to optimize the predictive model. One of the key features of gradient-boosting trees is their inherent ability to prevent overfitting through regularization techniques. These techniques include L1 and L2 regularization, which add penalty terms to the loss function to constrain the model complexity. L1 regularization can lead to sparse models by driving some coefficients to zero, while L2 regularization penalizes large coefficients, encouraging smaller weights. Additionally, the algorithm uses techniques such as subsampling of data and features, which further help in reducing overfitting by ensuring that the model does not become too complex and overly tailored to the training data. The use of cross-validation, specifically 4-fold cross-validation, also played a crucial role in assessing the model's performance and generalizability, ensuring that the model's predictions are reliable and not merely a result of overfitting to the training set.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a black-box model. It utilizes gradient-boosting trees, which inherently provide some level of interpretability. The model's predictions are based on a variety of features derived from the digital inhaler data and baseline patient characteristics. These features include the mean number of daily inhalations during the four days prior to the prediction, comparisons to baseline inhalation parameters, and trends in inhalation parameters prior to the prediction. The relevance of each feature to the model's performance is quantified as a percentage, indicating the variance reduced by data splits in the feature engineering process. Features with a large percentage variance reduction are considered more relevant to the model's predictions. For instance, the mean number of daily inhalations during the four days prior to the prediction was the feature with the highest weight in the model. This transparency allows for a better understanding of which factors contribute most significantly to the prediction of impending exacerbations, facilitating clinical interpretation and potential intervention strategies.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict whether a patient will experience an asthma exacerbation within the next five days. The model uses supervised learning techniques, specifically gradient-boosting trees, to classify data inputs into two categories: positive predictions, where an exacerbation is anticipated, and negative predictions, where no exacerbation is expected. The primary measure for the predictive analysis is albuterol use, with various parameters such as the number of inhalations and inhalation patterns being key features. The model's performance is evaluated using metrics like sensitivity and specificity, which are crucial for understanding its accuracy in predicting exacerbations. The use of gradient-boosting trees, particularly the XG-Boost implementation, allows the model to iteratively combine and optimize diverse data inputs to maximize predictive accuracy. This approach ensures that the model can effectively classify new data based on the relationships identified during the training phase.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method for the predictive model involved several key steps to ensure its robustness and accuracy. The model was trained using data from three subsets of patients, with the process repeated four times to enhance reliability. The predictive performance was assessed using the receiver operating characteristics (ROC) curve, which plots sensitivity against specificity. The area under the curve (AUC) value from the ROC curve was used to measure the model's ability to distinguish between different classes, with values ranging from 0 to 1, where 1 indicates perfect performance.\n\nThe ROC AUC was calculated separately for each group and then averaged to provide a single quality measure for the model. This approach ensured that the model's performance was evaluated comprehensively across different patient subsets.\n\nAdditionally, the relevance of the features used in the model was determined by the percentage of variance reduced by data splits in the feature engineering process. Features that contributed significantly to variance reduction were considered highly relevant to the model's performance.\n\nThe study utilized a 4-fold cross-validation technique to compare the predictive performance metrics of various algorithms. This method involved randomly partitioning the training set into four subsets, with the model trained on three subsets and tested on the remaining one, repeated four times. This process helped in optimizing and validating the model's performance.\n\nThe gradient-boosting model, specifically the XG-Boost implementation, was identified as the most effective algorithm. It was evaluated on a validation set comprising 54 patients, where it achieved an ROC AUC value of 0.83, indicating strong predictive capability. The model's performance was further validated by predicting exacerbations within the following 5 days, demonstrating its potential for real-time or near real-time identification of asthma exacerbations.",
  "evaluation/measure": "The performance of the predictive model was primarily evaluated using the receiver operating characteristic (ROC) curve, which plots sensitivity against specificity. The area under the ROC curve (AUC) was used as the key metric to assess the model's ability to distinguish between patients who would experience an exacerbation and those who would not. The AUC value ranges from 0 to 1, with 1 indicating perfect predictive performance.\n\nThe ROC AUC was computed separately for each group of patients and then averaged to provide a single quality measure for the model. In the validation set, the gradient-boosting model achieved an ROC AUC value of 0.83, with a 95% confidence interval ranging from 0.77 to 0.90. This value indicates strong predictive performance, suggesting that the model is effective in identifying patients at risk of exacerbations within the next five days.\n\nThe choice of the five-day predictive window was based on a balance between the accuracy of the prediction and the need for adequate time to intervene and prevent exacerbations. This approach ensures that the model provides timely and actionable insights for clinical decision-making.\n\nThe set of metrics reported is representative of standard practices in the field of predictive modeling for healthcare outcomes. The use of ROC AUC is a well-established method for evaluating the performance of binary classification models, particularly in medical research where the balance between sensitivity and specificity is crucial. This metric allows for a comprehensive assessment of the model's discriminative power, making it a reliable indicator of its predictive performance.",
  "evaluation/comparison": "Not applicable. The publication focuses on the development and evaluation of a predictive model for asthma exacerbations using machine learning techniques, specifically gradient-boosting trees implemented via XG-Boost. The evaluation primarily involves assessing the model's performance using metrics such as the receiver operating characteristic (ROC) curve and area under the curve (AUC). The study does not mention comparisons to publicly available methods or simpler baselines on benchmark datasets. Instead, it details the use of cross-validation techniques and the division of patient data into training, test, and validation sets to evaluate the model's predictive performance. The emphasis is on the internal validation and optimization of the model rather than external comparisons with other methods.",
  "evaluation/confidence": "The evaluation of the predictive model's performance included the calculation of the receiver operating characteristic (ROC) area under the curve (AUC) value, which is a key metric for assessing the model's capability to distinguish between classes. The ROC AUC value for the validation set was reported as 0.83, with a 95% confidence interval ranging from 0.77 to 0.90. This confidence interval provides a measure of the uncertainty around the estimated AUC value, indicating the range within which the true AUC value is likely to fall with 95% confidence.\n\nThe statistical significance of the results was not explicitly discussed in terms of comparing the model's performance to other methods or baselines. However, the provision of confidence intervals for the ROC AUC value suggests a level of statistical rigor in the evaluation process. The confidence intervals help to understand the precision of the AUC estimate and provide insight into the reliability of the model's performance metrics.\n\nIn summary, the performance metrics include confidence intervals, which are crucial for interpreting the results and understanding the model's reliability. While direct comparisons to other methods or baselines were not detailed, the use of confidence intervals indicates a commitment to statistical significance and the robustness of the evaluation process.",
  "evaluation/availability": "The datasets used for the study are available upon reasonable request. Qualified researchers can request access to patient-level data and related study documents, including the study protocol and the statistical analysis plan. To protect the privacy of trial participants and to safeguard commercially confidential information, patient-level data will be de-identified, and study documents will be redacted accordingly. Interested parties should contact Guilherme Safioti for any requests."
}