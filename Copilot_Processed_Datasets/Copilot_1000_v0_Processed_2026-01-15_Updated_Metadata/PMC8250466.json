{
  "publication/title": "Classification and analysis of outcome predictors in non-critically ill COVID-19 patients.",
  "publication/authors": "Venturini S, Orso D, Cugini F, Crapis M, Fossati S, Callegari A, Pellis T, Tonizzo M, Grembiale A, Rosso A, Tamburrini M, D'Andrea N, Vetrugno L, Bove T",
  "publication/journal": "Internal medicine journal",
  "publication/year": "2021",
  "publication/pmid": "33835685",
  "publication/pmcid": "PMC8250466",
  "publication/doi": "10.1111/imj.15140",
  "publication/tags": "- COVID-19\n- Non-critically ill\n- Prediction\n- Machine learning\n- Clinical outcome\n- Random forest\n- Decision trees\n- Medical data analysis\n- Hospitalized patients\n- Prognostic factors",
  "dataset/provenance": "The dataset used in this study was sourced from non-critically ill COVID-19 patients admitted to the general medicine department of a hospital in Pordenone. The data collection period spanned from March 1, 2020, to April 30, 2020. The dataset consists of 176 patients who were positive for SARS-CoV-2, as detected by real-time polymerase chain reaction in a nasopharyngeal swab. These patients were admitted from the emergency department and were suffering from COVID-19.\n\nThe dataset includes a variety of clinical data points collected from each patient. These data points encompass demographic information such as age, gender, weight, height, and body mass index. Additionally, the dataset includes details on the length of stay in the hospital, the delay from the onset of symptoms to hospitalization, and the medical ward admitting the patient. Clinical presentation data, such as the presence of fever, cough, shortness of breath, myalgia, diarrhea, and gastrointestinal complaints, were also recorded.\n\nThe dataset further includes clinical history information, such as smoking status, arterial hypertension, use of angiotensin-converting enzyme (ACE) inhibitor drugs, coronary artery disease, diabetes mellitus, obesity, atrial fibrillation, neoplasm, rheumatic diseases, dementia, respiratory disease, liver failure, and metabolic syndrome. The number of comorbidities for each patient is also documented.\n\nVital signs, including systolic and diastolic arterial pressure, heart rate, body temperature, and blood gas analysis results (pH, arterial partial pressure of oxygen and carbon dioxide), were collected. Additionally, the dataset includes blood chemistry tests at hospitalization, such as white blood cell count, neutrophils, lymphocytes, red blood cell count, hemoglobin, platelets, C-reactive protein, procalcitonin, creatinine, and glomerular filtration rate (GFR). Plasma sodium and potassium levels, liver functionality markers, coagulation system parameters, interleukin-6 levels, and venous thromboembolic disease prediction scores were also recorded.\n\nThe dataset also includes information on the administered therapy, such as hydroxychloroquine, azithromycin, lopinavir/ritonavir, darunavir/cobicistat, and low-molecular-weight heparin. Clinical outcomes, including discharge, death, and transfer to the intensive care unit (ICU), are documented for each patient.\n\nThis dataset has not been used in previous papers or by the community, as it is specific to this study and the patients admitted to the general medicine department of the hospital in Pordenone during the specified time period.",
  "dataset/splits": "Not applicable",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to the class of regression tree models. Specifically, five different types of regression tree models were implemented:\n\n* A conditional inference random forest model\n* A classic random forest model\n* An ordinal forest model\n* A traditional decision trees model\n* A recursive partitioning regression tree model using permutation tests to hierarchize predictor variables\n\nThese algorithms are not new; they are well-established methods in the field of machine learning. The choice to use these specific models was driven by their robustness and widespread use in predictive analytics, particularly in medical research.\n\nThe decision to publish this work in a medical journal rather than a machine-learning journal was likely influenced by the primary focus of the study. The research aims to identify predictors for clinical outcomes in non-critically ill COVID-19 patients, which is a medical research question. The machine-learning models were tools used to achieve this goal, but the main contribution of the study is in the medical field, specifically in improving the understanding and management of COVID-19.",
  "optimization/meta": "Not applicable",
  "optimization/encoding": "In our study, we collected a wide range of clinical data from non-critically ill COVID-19 patients. This data included both continuous variables, such as age, body mass index, and various blood test results, and categorical variables, like gender, clinical presentation symptoms, and comorbidities.\n\nFor continuous variables, we handled missing values using Gibbs sampling, which is a statistical method for imputing missing data. This approach helped us to maintain the integrity of our dataset and ensure that all variables were complete for analysis.\n\nCategorical variables were assessed using appropriate statistical tests, such as the Chi-squared test or Fisher's exact test, depending on the sample size and expected frequencies. These tests allowed us to compare the distribution of categorical variables across different clinical outcomes.\n\nTo prepare the data for machine learning models, we implemented five types of regression tree models: a conditional inference random forest model, a classic random forest model, an ordinal forest model, a traditional decision trees model, and a recursive partitioning regression tree model using permutation tests. Each of these models required the data to be encoded in a specific format. Continuous variables were standardized or normalized as needed, while categorical variables were encoded using techniques like one-hot encoding or label encoding to convert them into a numerical format suitable for the algorithms.\n\nWe also performed a k-fold cross-validation method with five folds to evaluate the performance of our machine learning models. This technique involved splitting the data into training and validation sets multiple times to ensure that the models were robust and generalizable. A two-tailed P-value of \u22640.05 was considered statistically significant, and we applied the Benjamini and Hochberg\u2019s method for correction for multiplicity when appropriate.\n\nAll statistical analyses were conducted using the open-source R-CRAN software, version 4.0.0. The main packages implemented included \u2018compareGroups\u2019, \u2018randomForest\u2019, \u2018mice\u2019, \u2018rpart\u2019, \u2018party\u2019, and \u2018caret\u2019. These packages provided the necessary tools for data preprocessing, model building, and performance evaluation.",
  "optimization/parameters": "In our study, we utilized a comprehensive set of clinical variables as input parameters for our machine learning models. These variables were selected based on their clinical relevance and availability in the electronic health records of the patients. The specific parameters included demographic information such as age and gender, vital signs like body temperature and blood pressure, laboratory results including white blood cell count, creatinine, glomerular filtration rate, and serum sodium levels, as well as clinical history details such as the presence of comorbidities like hypertension, diabetes, and respiratory diseases. Additionally, we considered treatment information, such as the administration of low-molecular-weight heparin and other medications.\n\nThe selection of these parameters was driven by the need to capture a broad spectrum of factors that could influence the clinical outcome of non-critically ill COVID-19 patients. We aimed to include variables that were readily measurable and had been previously identified in the literature as potential predictors of disease severity. The choice of parameters was also influenced by the availability of data in our retrospective cohort, ensuring that the models could be trained and validated with sufficient and reliable information.\n\nThe number of parameters used in the models varied depending on the specific machine learning algorithm employed. However, all models were designed to handle a large set of input variables, allowing for a thorough evaluation of their predictive power. The models included a conditional inference random forest, a classic random forest, an ordinal forest, a traditional decision tree, and a recursive partitioning regression tree. Each of these models was trained using a k-fold cross-validation method to ensure robustness and generalizability of the results. The performance of the models was assessed based on their accuracy, sensitivity, and specificity, providing a comprehensive evaluation of their predictive capabilities.",
  "optimization/features": "The study utilized a comprehensive set of clinical variables as input features to predict the clinical outcomes of non-critically ill COVID-19 patients. These features included demographic information such as age, gender, weight, height, and body mass index. Additionally, clinical presentation details like fever, cough, shortness of breath, myalgia, diarrhoea, and gastrointestinal complaints were considered. Medical history factors such as smoking, arterial hypertension, diabetes mellitus, obesity, and various comorbidities were also included. Vital signs like systolic and diastolic arterial pressure, heart rate, and body temperature were recorded. Blood gas analysis results, including pH, arterial partial pressure of oxygen and carbon dioxide, and the PaO2/FiO2 ratio, were part of the input features. Blood chemistry tests at hospitalisation, such as white blood cell count, neutrophils, lymphocytes, haemoglobin, platelets, C-reactive protein, procalcitonin, creatinine, and glomerular filtration rate, were analyzed. Liver functionality markers, coagulation system parameters, interleukin-6 levels, and venous thromboembolic disease prediction scores were also included. The administered therapies, such as hydroxychloroquine, azithromycin, lopinavir/ritonavir, darunavir/cobicistat, and low-molecular-weight heparin, were considered. The clinical outcomes of discharge, death, and transfer to the intensive care unit were the target variables.\n\nFeature selection was not explicitly mentioned as a separate step in the methodology. However, the use of machine learning models inherently involves feature importance assessment, which can be seen as a form of feature selection. The models used, such as the conditional inference random forest, classic random forest, ordinal forest, traditional decision trees, and recursive partitioning regression tree, automatically rank features based on their predictive power. This process ensures that the most relevant features are utilized for making predictions. The models were trained and validated using a k-fold cross-validation method, which helps in assessing the generalizability of the selected features and the model's performance.",
  "optimization/fitting": "Not enough information is available.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models employed in our study range from transparent to somewhat opaque, depending on the specific algorithm used. The random forest model (M2) and the conditional inference tree model (M5) are among the most accurate, with an accuracy of 79%. These models provide insights into the key predictors of clinical outcomes in COVID-19 patients.\n\nThe conditional inference tree model (M5) is particularly transparent. It uses a decision tree structure that hierarchizes predictor variables through permutation tests. For instance, the plasma sodium level is the first predictive node, followed by body temperature, hospitalization in a COVID-19 dedicated ward, and the PaO2/FiO2 ratio. This model clearly outlines the decision-making process, making it easier to interpret the factors influencing patient outcomes.\n\nSimilarly, the classic classification decision tree model (M4) is also transparent. It identifies key determinants such as creatinine levels, white blood cell count, and age, which are used to predict clinical outcomes. This model's accuracy is 65%, which is lower than that of M2 and M5 but still provides valuable insights.\n\nIn contrast, the random forest model (M2) is somewhat more opaque. While it is highly accurate, it combines multiple decision trees, making it difficult to trace the exact path of decision-making. However, it highlights important predictors such as glomerular filtration rate, creatinine, age, and fraction-inspired oxygen, which are crucial for understanding patient outcomes.\n\nOverall, while some models offer clear, interpretable results, others provide a more complex view that requires deeper analysis to fully understand the underlying factors influencing clinical outcomes.",
  "model/output": "The models employed in this study are classification models. They were used to analyze a series of non-critically ill COVID-19 patients admitted to a general medicine ward. The goal was to determine if any clinical variables recorded could predict the clinical outcome. The outcomes considered were discharge, death, or transfer to the intensive care unit.\n\nFive types of regression tree models were implemented:\n\n* A conditional inference random forest model\n* A classic random forest model\n* An ordinal forest model\n* A traditional decision trees model\n* A recursive partitioning regression tree model using permutation tests to hierarchize predictor variables\n\nThe most accurate models were the classic random forest model and the recursive partitioning regression tree model, both achieving an accuracy of 79%. For the classic random forest model, the most accurate predictors for the outcome were glomerular filtration rate and creatinine, followed by age and fraction-inspired oxygen. For the recursive partitioning regression tree model, the most reliable predictors were serum sodium, body temperature, and the arterial pressure of oxygen and inspiratory fraction of oxygen ratio.\n\nThe models were compared based on their accuracy, sensitivity, and specificity performances. A resampling procedure using a k-fold cross-validation method with five folds was used to evaluate the machine learning models. A two-tailed P-value of \u22640.05 was considered statistically significant, and a correction for multiplicity by Benjamini and Hochberg\u2019s method was applied when appropriate. All statistical analyses were generated using the open-source R-CRAN software.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not applicable",
  "evaluation/method": "The evaluation of the machine learning models involved a comprehensive statistical analysis to compare registered characteristics based on clinical outcomes. Continuous variables with parametric distribution were assessed using the Student t test, while non-parametric distributions were evaluated with the Kruskal-Wallis test. Categorical variables were analyzed using the Chi-squared test or the Fisher exact test when appropriate.\n\nFive types of regression tree models were implemented: a conditional inference random forest model, a classic random forest model, an ordinal forest model, a traditional decision trees model, and a recursive partitioning regression tree model using permutation tests to hierarchize predictor variables. Missing values were imputed using Gibbs sampling.\n\nTo evaluate the machine learning models, a k-fold cross-validation method with five folds was employed. This resampling procedure ensured that the models were robust and generalizable. A two-tailed P-value of \u22640.05 was considered statistically significant, and a correction for multiplicity using Benjamini and Hochberg\u2019s method was applied when necessary.\n\nThe models were compared based on their accuracy, sensitivity, and specificity performances. The main packages used for these analyses included \u2018compareGroups\u2019, \u2018randomForest\u2019, \u2018mice\u2019, \u2018rpart\u2019, \u2018party\u2019, and \u2018caret\u2019. All statistical analyses were conducted using the open-source R-CRAN software (version 4.0.0).",
  "evaluation/measure": "In our study, we evaluated the performance of five different machine learning classification models using several key metrics to ensure a comprehensive assessment. The primary metrics reported include accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and detection rate. These metrics were chosen to provide a well-rounded evaluation of each model's performance across different aspects of prediction.\n\nAccuracy measures the overall correctness of the models, indicating the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall, assesses the model's ability to correctly identify positive cases, which is crucial for detecting severe outcomes such as death or the need for ICU transfer. Specificity evaluates the model's ability to correctly identify negative cases, ensuring that non-severe outcomes are accurately predicted.\n\nPPV and NPV provide insights into the probability that a positive or negative test result is correct, respectively. PPV is particularly important in clinical settings where the cost of false positives can be high, while NPV is critical when the cost of false negatives is significant. The detection rate further complements these metrics by indicating the proportion of actual positives that are correctly identified by the model.\n\nThe reported metrics are representative of standard practices in the literature, ensuring that our evaluation is both rigorous and comparable to other studies in the field. By including a diverse set of performance measures, we aim to provide a thorough understanding of each model's strengths and weaknesses, facilitating informed decision-making in clinical settings.",
  "evaluation/comparison": "The study did not compare the proposed methods to publicly available methods on benchmark datasets. Instead, the focus was on comparing different machine learning classification models within the same dataset of non-critically ill COVID-19 patients.\n\nFive types of regression tree models were implemented and compared:\n\n* A conditional inference random forest model\n* A classic random forest model\n* An ordinal forest model\n* A traditional decision trees model\n* A recursive partitioning regression tree model using permutation tests to hierarchize predictor variables\n\nThe models were evaluated based on their accuracy, sensitivity, and specificity performances. The two models with the greatest accuracy were the classic random forest model and the conditional inference tree model, both achieving an accuracy of 79%. The traditional decision trees model had the lowest accuracy at 65%.\n\nAll models demonstrated good sensitivity in predicting discharge, good specificity in predicting death or the need for transfer to the intensive care unit, but poor sensitivity for these latter outcomes.\n\nThe comparison did not include simpler baselines, as the emphasis was on evaluating the performance of different machine learning models within the context of predicting clinical outcomes for COVID-19 patients.",
  "evaluation/confidence": "The performance metrics for the models indeed include confidence intervals. For instance, the accuracy of the models is presented with a range, such as 0.70 (0.54 \u2013 0.83) for the conditional random forest model. This provides a clear indication of the variability and reliability of the accuracy estimates.\n\nStatistical significance is also considered in the analysis. A two-tailed P-value of \u22640.05 is used as the threshold for statistical significance. Additionally, a correction for multiplicity using Benjamini and Hochberg\u2019s method is applied when appropriate, ensuring that the results are robust and not due to chance.\n\nThe models were compared based on their accuracy, sensitivity, and specificity performances. The random forest model and the conditional inference tree model both achieved the highest accuracy of 79%, indicating their superior performance compared to the other models. The traditional decision trees model had the lowest accuracy at 65%, showing it was the least effective among the five models evaluated.\n\nThe statistical tests used, such as the Student t test, Kruskal-Wallis test, Chi-squared test, and Fisher exact test, ensure that the comparisons between groups and models are statistically sound. The use of k-fold cross-validation with five folds further enhances the reliability of the model evaluations by providing a more robust estimate of their performance.\n\nOverall, the performance metrics and statistical analyses provide a strong foundation for claiming the superiority of certain models over others and baselines.",
  "evaluation/availability": "Not enough information is available."
}