{
  "publication/title": "Random forest based classification of alcohol dependence patients and healthy controls using resting state MRI.",
  "publication/authors": "Zhu X, Du X, Kerich M, Lohoff FW, Momenan R",
  "publication/journal": "Neuroscience letters",
  "publication/year": "2018",
  "publication/pmid": "29626649",
  "publication/pmcid": "PMC5960433",
  "publication/doi": "10.1016/j.neulet.2018.04.007",
  "publication/tags": "- Alcohol use disorder\n- Functional connectivity\n- Resting state\n- Machine learning\n- Random forest\n- Neuroimaging\n- Brain networks\n- Classification performance\n- Executive control network\n- Reward network\n\nNot applicable",
  "dataset/provenance": "The dataset used in this study consists of resting-state functional connectivity data from 92 participants, evenly divided into two groups: 46 individuals with Alcohol Use Disorder (AUD) and 46 control subjects. The demographic and clinical profiles of these participants are detailed in Table 1, which includes information such as age, gender, race, and smoking status.\n\nThe data was collected using functional magnetic resonance imaging (fMRI), and the analysis focused on identifying alterations in resting-state functional connectivity between the AUD and control groups. The study employed Independent Component Analysis (ICA) to derive 32 component maps, which were then used to extract within-network and between-network connectivity features.\n\nThe within-network connectivity features were obtained by calculating the averaged z-value within each mask derived from the group-level component maps. This resulted in 32 within-network connectivity features per subject. Between-network connectivity features were computed by assessing the temporal correlations between the time series of different networks, yielding 496 features after Fisher z-transformation.\n\nThis dataset has not been previously used in other published studies by the community. The analysis involved a covariate analysis of age and gender to minimize potential confounding influences. The random forest algorithm was applied to both within-network and between-network functional connectivity data to distinguish patterns between AUD and control subjects. The study aimed to explore the utility of functional connectivity alterations in diagnosing AUD and predicting those at risk.",
  "dataset/splits": "In our study, we employed leave-one-out cross-validation (LOOCV) for evaluating the performance of our classifier. This method involves creating multiple data splits, where each split leaves out one subject's data. Consequently, the number of data splits is equal to the number of subjects in our dataset. For each split, the classifier is trained on the remaining data and then used to predict the label of the left-out subject. This process is repeated for each subject, ensuring that every subject's data is used for both training and testing exactly once.\n\nThe distribution of data points in each split is straightforward: one data point is left out for testing, and the rest are used for training. This means that in each iteration, the training set consists of all but one subject's data, and the testing set consists of the single left-out subject's data. This approach helps in maximizing the use of available data and provides a robust estimate of the classifier's performance.\n\nThe number of trees in the ensemble was set to 600, and the number of features analyzed at each node to find the best split was the square root of the total number of features. This setup was chosen to balance computational efficiency and model performance.",
  "dataset/redundancy": "In our study, we employed leave-one-out cross-validation (LOOCV) to explore an optimal set of feature variables. This method involves leaving out one subject's data from the dataset and using the remaining data to create an optimal classifier. The classifier then predicts the label of the left-out subject, and this process is repeated for each subject in the dataset. This ensures that the training and test sets are independent, as each subject's data is used once as a test set while the rest of the data is used for training.\n\nThe distribution of our dataset compares favorably to previously published machine learning datasets in the context of neuroimaging studies. We had a balanced dataset with 46 subjects in the AUD group and 46 subjects in the control group. This balance is crucial for avoiding biases that can arise from imbalanced datasets, which is a common issue in many machine learning applications. By ensuring that the training and test sets are independent and that the dataset is balanced, we aimed to achieve robust and generalizable results.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the random forest, which is an ensemble learning method. This algorithm is not new; it has been established and widely used in various fields, including bioinformatics and neuroscience. The random forest algorithm was chosen for its robustness, ability to handle high-dimensional data, and effectiveness in dealing with non-linear relationships, which are common in biological datasets.\n\nThe decision to use the random forest algorithm in this context, rather than developing a new one, was driven by its proven track record and suitability for our specific research questions. Random forests are known for their ability to provide feature importance scores, which are crucial for identifying the most predictive features in our dataset. This capability aligns well with our goal of exploring optimal sets of feature variables for distinguishing between alcohol use disorder (AUD) and control subjects.\n\nAdditionally, the random forest algorithm offers advantages such as resistance to overfitting, simplicity in tuning parameters, and the ability to handle large datasets efficiently. These characteristics make it a reliable choice for our study, which involves complex and high-dimensional resting-state functional connectivity data.\n\nGiven these considerations, there was no need to develop a new machine-learning algorithm. The random forest algorithm has been extensively validated and is well-suited for the type of analysis we conducted. Therefore, it was published in a neuroscience journal rather than a machine-learning journal, as the focus of our study is on the application of this algorithm to understand the neurobiological underpinnings of AUD.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The random forest algorithm was used to create an optimal classifier. The random forest algorithm uses two levels of randomness: first, each tree uses a bootstrapped version of the training data, and second, at each node, a random subset of variables is selected to split. The number of trees in the ensemble and the number of variables selected at each node are the two main parameters of the random forest algorithm. The prediction data included true positive, false negative, true negative, and false positive classifications. The accuracy and precision were computed using the following formulas: Accuracy = (TP + TN)/(TP + TN + FP + FN) * 100 % and Precision (Sensitivity) = TP/(TP + FP) * 100 %. The prediction accuracy was computed by using leave-one-out cross-validation. The procedure was repeated as many times as the number of subjects, with a different subject being left out each time. The total accuracy was computed for each category. The stability of within-network features was tested using leave-one-out cross-validation. The three most important features were consistent across different feature elimination scenarios. The stability of between-network features was also presented. The random forest algorithm was first performed on all features, and the ranking of average feature importance was used for feature elimination. The classification performance was evaluated based on accuracy and precision. The prediction accuracy was computed 92 times by using leave-one-out cross-validation. The mean and standard error of feature importance of 92 random forests by using leave-one-out cross-validation were presented. The results showed that classification performance significantly improved with feature elimination. The within-network features that have the strongest predicting power were found in the executive control network and the reward network. The between-network features that have shown the strongest predicting power were found between the Default Mode Network and the reward network, and between the executive control network and the reward network. The results provided evidence that the machine-learning methods may offer a diagnostic tool for identifying the brain biomarkers to distinguish AUD from controls.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for the effective application of the machine-learning algorithm. Initially, we focused on resting state functional connectivity data, which was derived from neuroimaging studies. This data was preprocessed to ensure consistency and quality. Preprocessing steps included spatial normalization, motion correction, and band-pass filtering to isolate relevant frequency bands.\n\nFor the machine-learning algorithm, specifically the random forest classifier, the data was encoded in a manner that facilitated feature selection and classification. Each subject's data was represented as a vector of features, where each feature corresponded to a specific measure of functional connectivity between different brain regions. These features were then used to train the random forest model.\n\nOne of the key preprocessing steps involved handling the high dimensionality of the data. Given the large number of variables, we employed feature elimination techniques to reduce the dimensionality. This was done by first performing random forest on all features and then ranking them based on their average importance. Features with lower importance scores were eliminated, which helped in mitigating the \"curse of dimensionality\" and improving the model's performance.\n\nThe random forest algorithm itself introduced two levels of randomness. First, each tree in the forest was trained on a bootstrapped version of the training data, using approximately 66% of the samples with replacement. The remaining data was used to estimate error and variable importance. Second, at each node of the decision tree, a random subset of features was selected to determine the best split, which helped in adding diversity to the trees and improving the overall robustness of the model.\n\nThe number of trees in the ensemble and the number of features analyzed at each node were carefully tuned. We used 600 trees in the random forest, and for each split, the square root of the total number of features was considered. This parameter tuning was essential for achieving optimal classification performance.\n\nIn summary, the data encoding and preprocessing involved spatial normalization, motion correction, band-pass filtering, and feature elimination. The random forest algorithm was then applied with specific parameters to handle the high dimensionality and ensure robust classification performance.",
  "optimization/parameters": "In our study, the number of parameters, p, refers to the number of features analyzed at each node to find the best split in the random forest algorithm. For a dataset with p features, the square root of p were used in each split. This approach is a common heuristic in random forest implementations to balance between capturing the complexity of the data and avoiding overfitting.\n\nThe specific number of trees in the ensemble was set to 600. This parameter, along with the number of features selected at each node, are the two main parameters of the random forest algorithm. The choice of 600 trees was based on empirical evidence suggesting that this number provides a good trade-off between computational efficiency and model performance. The number of features selected at each node was determined dynamically as the square root of the total number of features, which is a standard practice in random forest implementations to ensure that a diverse set of features is considered at each split, thereby enhancing the model's robustness and generalization ability.",
  "optimization/features": "In our study, we initially utilized a large set of features derived from resting state functional connectivity data to distinguish between individuals with Alcohol Use Disorder (AUD) and controls. The exact number of initial features (f) is not specified here, but it was sufficiently large to warrant feature elimination techniques.\n\nFeature selection was indeed performed to mitigate the \"curse of dimensionality\" and enhance the classifier's performance. This process involved using the random forest algorithm to rank features based on their importance. The feature importance scores were calculated using the mean decrease impurity method, which measures the average accumulated decrease in node impurity over all trees for each feature.\n\nThe feature elimination was conducted in a systematic manner. Initially, the random forest was trained on all available features. Subsequently, features were ranked according to their importance scores, and a percentage of the least important features were eliminated. This procedure was repeated for different levels of feature elimination, specifically at 50% and 90% reduction levels.\n\nCrucially, the feature selection process was performed using the training data only, ensuring that the evaluation of the classifier's performance on the test data remained unbiased. This approach helped in identifying the most relevant features that contributed significantly to the classification task, thereby improving the model's accuracy and precision. The stability of these selected features was further validated using leave-one-out cross-validation, confirming their robustness and reliability in predicting AUD and control classifications.",
  "optimization/fitting": "In our study, we employed a random forest algorithm, which is an ensemble learning method that uses multiple decision trees to improve predictive accuracy and control over-fitting. The random forest algorithm inherently addresses the issue of over-fitting through two main mechanisms: bagging and random feature selection.\n\nFirstly, bagging involves creating multiple subsets of the training data by sampling with replacement. Each decision tree in the forest is trained on a different subset, which helps to reduce the variance and prevent over-fitting. Specifically, about 66% of the training data was used for each tree, and the remaining data was used to estimate error and variable importance.\n\nSecondly, at each node of a decision tree, a random subset of features is considered for splitting. This introduces additional randomness and helps to decorrelate the trees, further reducing the risk of over-fitting. The number of features considered at each split is a hyperparameter that can be tuned, and in our case, we used the square root of the total number of features.\n\nTo ensure that our model did not under-fit the data, we carefully selected the number of trees in the forest and the depth of each tree. We used 600 trees, which is a commonly used number that provides a good balance between bias and variance. Additionally, we employed feature elimination based on importance scores derived from the random forest. This process helped to identify and retain the most relevant features, improving the model's ability to capture the underlying patterns in the data.\n\nWe also used leave-one-out cross-validation (LOOCV) to evaluate the model's performance. In LOOCV, each subject's data is left out once, and the model is trained on the remaining data. This procedure is repeated for each subject, providing a robust estimate of the model's generalization performance. The results showed that the classification performance significantly improved with feature elimination, indicating that the model was able to capture the relevant patterns in the data without under-fitting.\n\nIn summary, the random forest algorithm's inherent mechanisms of bagging and random feature selection, along with careful hyperparameter tuning and feature elimination, helped to address both over-fitting and under-fitting in our study. The use of LOOCV further ensured that the model's performance was robust and generalizable.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and improve the generalization ability of our classifier. One of the primary methods used was feature elimination. When dealing with a large number of variables, random forests can struggle if the relevant variables are few. Additionally, high dimensionality can lead to the \"curse of dimensionality,\" making it difficult to draw meaningful conclusions from the data. To mitigate this, we first performed random forest on all features and then used the ranking of average feature importance for feature elimination. This process helped in reducing the dimensionality of the feature space and focusing on the most relevant features.\n\nAnother key technique we used was leave-one-out cross-validation (LOOCV). In LOOCV, one subject's data is left out of the dataset, and the random forest creates an optimal classifier using the remaining data. The classifier then predicts the label of the left-out subject, and this procedure is repeated for each subject. This method ensures that the model is evaluated on data it has not seen during training, providing a robust estimate of its performance and helping to prevent overfitting.\n\nFurthermore, the random forest algorithm itself incorporates mechanisms to reduce overfitting. It uses two levels of randomness: bootstrapping, where each tree is trained on a random sample of the data with replacement, and random feature selection at each node. This ensemble approach helps to create a diverse set of decision trees, reducing the risk of overfitting to the training data. The number of trees in the ensemble and the number of features analyzed at each node are carefully tuned to balance bias and variance, further enhancing the model's generalization ability.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the publication. Specifically, we utilized the random forest algorithm with the following key parameters: the number of trees (ntree) was set to 600, and the number of features analyzed at each node to find the best split was determined by the square root of the total number of features (p). This approach ensures that a diverse set of features is considered at each split, enhancing the robustness of the model.\n\nThe optimization schedule involved a leave-one-out cross-validation (LOOCV) procedure. In LOOCV, one subject\u2019s data is left out of the dataset, and the random forest creates an optimal classifier using the remaining data. This process is repeated for each subject, and the total accuracy is computed for each category. This method provides a comprehensive evaluation of the model's performance by ensuring that each subject's data is used for both training and validation.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the publication. The focus was on reporting the methodology and results of the classification performance rather than sharing the specific model files or detailed optimization parameters. However, the parameters used for the random forest algorithm are clearly stated, allowing for reproducibility of the experimental setup.\n\nThe publication does not discuss the licensing of the data or models used. The primary emphasis was on the methodological approach and the results obtained from the classification of resting-state functional connectivity patterns between individuals with alcohol use disorder (AUD) and controls. The use of the scikit-learn random forest implementation in Python is mentioned, which is an open-source library, but specific details about the licensing of the data or models are not provided.",
  "model/interpretability": "The random forest model used in this study is not a black-box model. It provides a level of transparency through its ability to measure feature importance. This allows for the identification of the most significant features contributing to the model's predictions.\n\nOne of the key advantages of the random forest algorithm is its capability to rank features based on their importance. In this work, the mean decrease impurity method was employed to quantify the importance of each feature. This method calculates the average accumulated decrease in node impurity over all trees for each feature, providing a clear indication of which features are most influential in making predictions.\n\nThe model's transparency is further demonstrated through the feature elimination process. By initially performing random forest on all features and then using the ranking of average feature importance for feature elimination, the model helps in identifying the most relevant variables. This process not only improves the model's performance but also provides insights into which features are crucial for distinguishing between different categories, such as AUD and control subjects.\n\nAdditionally, the stability of the most important features was tested using leave-one-out cross-validation (LOOCV). This method involves leaving out one subject's data at a time, training the model on the remaining data, and then predicting the label for the left-out subject. This procedure was repeated for each subject, and the results showed that the three most important features were consistent across different feature elimination scenarios. This consistency indicates that these features are reliable predictors and adds to the model's interpretability.\n\nIn summary, the random forest model used in this study is transparent and provides clear examples of feature importance and stability. This transparency is achieved through the use of feature importance scores and the feature elimination process, which help in identifying the most relevant variables and improving the model's performance.",
  "model/output": "The model employed in this study is a classification model. Specifically, a random forest classifier was used to distinguish between individuals with Alcohol Use Disorder (AUD) and control subjects based on patterns of resting-state functional connectivity.\n\nThe classification process involved leave-one-out cross-validation (LOOCV), where one subject's data is left out, and the classifier is trained on the remaining data. The classifier then predicts the label (AUD or control) for the left-out subject. This procedure is repeated for each subject in the dataset, and the overall accuracy is computed.\n\nTo ensure that the classification performance was significantly above chance, random assignments of subjects as AUD or control were used to train and test the classifier 1000 times. This generated a distribution of accuracy and precision values, which were then compared to the actual values using Z-tests.\n\nThe results indicated that classification performance significantly improved with feature elimination. The most important features contributing to the classifier were identified within specific brain networks, including the executive control network (ECN) and the reward network (RN). These features were found to be stable across different feature elimination scenarios, making them reliable predictors of AUD and control status.\n\nThe model's performance was evaluated based on accuracy and precision, which were computed using standard formulas involving true positives, true negatives, false positives, and false negatives. The random forest classifier demonstrated good performance in handling highly non-linear biological data and was robust to noise, making it suitable for this type of analysis.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "To evaluate the method, we employed leave-one-out cross-validation (LOOCV). This approach involves iteratively leaving out one subject's data, training the random forest classifier on the remaining data, and then predicting the label (AUD or control) for the left-out subject. This process is repeated for each subject in the dataset, ensuring that every subject's data is used for both training and testing. The overall accuracy is then computed by averaging the results across all iterations.\n\nTo assess whether the classification performance was significantly above chance, we conducted a permutation test. This involved randomly assigning each subject as either AUD or control and using this shuffled dataset to train and test the classifier. This procedure was repeated 1000 times to obtain a distribution of accuracy and precision values. We then used Z-tests to compare the actual accuracy and precision values against the randomly generated values. Additionally, we checked if the actual values were at least two standard deviations above the mean of the generated values, indicating statistical significance.\n\nThe performance of the random forest classifier was evaluated based on accuracy and precision. Accuracy was calculated as the proportion of true positive and true negative classifications out of the total number of classifications. Precision, also known as sensitivity, was calculated as the proportion of true positive classifications out of the total number of positive classifications.\n\nThe evaluation also included feature elimination to address the curse of dimensionality. We first performed the random forest on all features and then used the ranking of average feature importance for feature elimination. The classifier's performance was assessed with no feature elimination, 50% feature elimination, and 90% feature elimination. The results showed that classification performance significantly improved with feature elimination, particularly with 90% feature elimination. This indicates that a smaller set of highly relevant features can enhance the classifier's ability to distinguish between AUD and control subjects.",
  "evaluation/measure": "In our study, we focused on two primary performance metrics to evaluate the effectiveness of our classifier: accuracy and precision. These metrics were chosen for their relevance and common use in the literature for similar classification tasks.\n\nAccuracy is a fundamental metric that measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It provides a general sense of how often the classifier is correct. The formula used is:\n\nAccuracy = (TP + TN) / (TP + TN + FP + FN) * 100%\n\nPrecision, also known as sensitivity or recall, measures the proportion of true positive results (correctly identified positive cases) out of all positive results (both true positives and false positives). It is particularly important in scenarios where the cost of false positives is high. The formula used is:\n\nPrecision = TP / (TP + FP) * 100%\n\nThese metrics were computed using leave-one-out cross-validation (LOOCV), a robust method that ensures each subject's data is used once as a test set while the remaining data is used for training. This approach helps in obtaining a reliable estimate of the classifier's performance.\n\nThe reported accuracy and precision values were compared against a baseline established by randomly assigning labels to subjects. This comparison, conducted using Z-tests, ensured that our classifier's performance was significantly above chance. Additionally, we tested whether the actual accuracy and precision values were at least two standard deviations above the randomly generated values, further validating the robustness of our results.\n\nThe choice of these metrics is representative of standard practices in the field, providing a clear and comprehensive evaluation of the classifier's performance. The use of LOOCV and statistical testing against a random baseline adds rigor to our evaluation, ensuring that the reported performance is both reliable and meaningful.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "To evaluate the confidence in our results, we employed several statistical methods. We used leave-one-out cross-validation (LOOCV) to compute prediction accuracy, ensuring that each subject's data was used once as a test set while the remaining data formed the training set. This process was repeated for each subject, providing a comprehensive assessment of our classifier's performance.\n\nTo determine if our classification performance was significantly above chance, we performed a permutation test. We randomly assigned each subject as either having Alcohol Use Disorder (AUD) or being a control and used this dataset to train and test each classifier. This procedure was repeated 1000 times, generating a distribution of accuracy and precision values. We then used Z-tests to compare the actual accuracy and precision values against these randomly generated values. Additionally, we checked whether the actual values were 2 standard deviations above the generated values, providing further evidence of statistical significance.\n\nOur results indicate that classification performance significantly improved with feature elimination. The performance metrics, including accuracy and precision, were computed for different levels of feature elimination (no elimination, 50% elimination, and 90% elimination). These metrics were found to be statistically significant, as indicated by the asterisks in the results table, denoting that they were two standard deviations above chance.\n\nThe stability of the most important features was also tested using LOOCV, and the results showed consistency across different feature elimination scenarios. This consistency further supports the reliability and robustness of our findings.\n\nIn summary, our evaluation methods included rigorous statistical testing and cross-validation techniques, ensuring that our performance metrics are reliable and that our results are statistically significant. This provides strong confidence in the superiority of our method over baseline approaches.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data consists of sensitive information related to individuals with Alcohol Use Disorder (AUD) and control subjects, which includes resting-state functional connectivity data obtained through neuroimaging techniques. Due to privacy and ethical considerations, this data cannot be shared publicly.\n\nThe evaluation process involved using leave-one-out cross-validation (LOOCV) to assess the prediction accuracy of our random forest classifier. In LOOCV, one subject\u2019s data is left out of the dataset, and the classifier is trained using the remaining data. The classifier then predicts the label (AUD or control) of the left-out subject, and this procedure is repeated for each subject in the dataset. The total accuracy is computed for each category.\n\nTo test the statistical significance of our classification performance, we randomly assigned each subject as AUD or control and used this dataset to train and test each classifier. This procedure was carried out 1000 times to obtain the distribution of accuracy and precision. Z-tests were used to compare the actual accuracy and precision values with the randomly generated values.\n\nThe performance of the random forest classifier was evaluated based on accuracy and precision. Accuracy is defined as the proportion of true positive (TP) and true negative (TN) classifications out of the total number of classifications. Precision, also known as sensitivity, is defined as the proportion of true positive classifications out of the total number of positive classifications.\n\nThe results of our evaluation are summarized in Table 2, which shows the performance of the random forest with no feature elimination, 50% feature elimination, and 90% feature elimination. The classification performance significantly improved with feature elimination, indicating that the most relevant features were effectively identified and utilized in the classifier. The within-network and between-network features that contributed the most to the classifier's performance were also identified and analyzed for their stability using LOOCV."
}