{
  "publication/title": "Machine-Learning-Assisted Microfluidic Nanoplasmonic Digital Immunoassay for Cytokine Storm Profiling in COVID-19 Patients.",
  "publication/authors": "Gao Z, Song Y, Hsiao TY, He J, Wang C, Shen J, MacLachlan A, Dai S, Singer BH, Kurabayashi K, Chen P",
  "publication/journal": "ACS nano",
  "publication/year": "2021",
  "publication/pmid": "34714639",
  "publication/pmcid": "PMC8577373",
  "publication/doi": "10.1021/acsnano.1c06623",
  "publication/tags": "- Machine Learning\n- Microfluidics\n- Nanoplasmonics\n- Digital Immunoassay\n- Cytokine Storm\n- COVID-19\n- Image Processing\n- Convolutional Neural Network\n- High-Throughput Detection\n- Immunoassay Technology\n- Cytokine Profiling\n- Nanoparticle Detection\n- Biomedical Engineering\n- Diagnostic Tools\n- Hyperactive Immune Response",
  "dataset/provenance": "The dataset used in our study consists of dark-field images of silver nanoclusters (AgNCs) obtained from a digital immunoassay. We selected 252 representative images that cover a wide range of cytokine concentrations, from assay blank (0 pg/mL) to 10,000 pg/mL. These images were used to train our convolutional neural network (CNN) for accurate particle counting.\n\nThe images were labeled using a combination of automated thresholding algorithms and manual corrections. The automated process involved computing a global threshold using Otsu's method and applying standard image erosions and dilations to generate a preliminary binary image mask. This mask labeled AgNC spots as class \"1\" and background as class \"0\". However, this initial labeling was not perfect, especially for spots with large intensity variance or aggregated spots. Therefore, we employed several correction algorithms to manually add or remove falsely recognized areas, ensuring accurate labeling of individual, aggregated, bright, and dim spots.\n\nThe labeled images were then used to train the CNN, with a focus on class weight balance to enhance pixel identification accuracy. The class weight was defined as the ratio of the total number of image pixels to the number of pixels for each class, giving more weight to the less frequently appearing AgNC class. This strategy was crucial because the number of AgNC class pixels was significantly smaller than the number of background pixels.\n\nThe dataset was divided into training and test sets. The training set was used to develop the CNN, while the test set, consisting of 126 well-selected images, was used to evaluate the performance of the candidate networks. The finalized CNN was then integrated into our image processing method to recognize AgNC spots in new images.\n\nThe dataset used in this study is novel and specifically curated for the development and validation of our CNN-based image processing method. It has not been used in previous papers or by the community, as it is unique to our research on machine-learning-assisted microfluidic nanoplasmonic digital immunoassays.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a convolutional neural network (CNN). This type of algorithm is well-suited for image processing tasks due to its ability to automatically and adaptively learn spatial hierarchies of features from input images.\n\nThe specific CNN architecture employed in our work is not entirely novel, as CNNs have been extensively used in various image recognition and segmentation tasks. However, the application of this CNN architecture to the specific problem of identifying and counting silver nanocube (AgNC) spots in dark-field images for cytokine detection is innovative. The CNN was tailored to handle the unique challenges of our dataset, such as the presence of aggregated spots and varying intensities.\n\nThe reason this work was published in a nanotechnology journal rather than a machine-learning journal is that the primary focus of our study is the development and application of a machine-learning-assisted microfluidic nanoplasmonic digital immunoassay for cytokine storm profiling in COVID-19 patients. The CNN is a crucial component of this immunoassay, enabling high-throughput and accurate detection of multiple cytokines. The innovation lies in the integration of the CNN with the nanoplasmonic digital immunoassay, rather than the CNN architecture itself. Therefore, the publication venue reflects the interdisciplinary nature of the research, combining advances in nanotechnology, microfluidics, and machine learning.",
  "optimization/meta": "Not applicable. The publication focuses on a machine-learning-assisted microfluidic nanoplasmonic digital immunoassay for cytokine detection, specifically using a convolutional neural network (CNN) for image processing. The CNN is trained using a dataset of dark-field images to classify and segment nanoparticles. The process involves dataset labeling, class weight balancing, network training, and result evaluation. However, there is no mention of a meta-predictor or the use of data from other machine-learning algorithms as input. The CNN is the primary machine-learning method used in this study.",
  "optimization/encoding": "For the machine-learning algorithm, the data encoding and preprocessing involved several key steps to ensure accurate and efficient training of the convolutional neural network (CNN). Initially, a dataset of 252 representative dark-field images was selected, covering a wide range of cytokine concentrations from assay blank to 10,000 pg mL\u22121. These images were used to train the CNN to distinguish between nanoparticles (class \u201c1\u201d) and background (class \u201c0\u201d).\n\nA thresholding algorithm was employed to compute a global threshold using Otsu's method, which helped in generating a preliminary binary image mask. This mask labeled recognized AgNC spot pixels as class \u201c1\u201d and background pixels as class \u201c0\u201d. However, this initial labeling was not perfect, especially for spots with large intensity variance or aggregated spots. To address this, several correction algorithms were applied to manually add or remove falsely recognized areas, ensuring more accurate labeling.\n\nA normalization process was implemented using a 5\u00d75 pixel unit size for all recognized AgNC spots, including individual, aggregated, bright, and dim spots. This normalization helped the neural network to recognize very dim spots and separate aggregated spots with strong intensity, which was challenging with the global thresholding method alone.\n\nClass weight balance was considered using the inverse frequency weighting method, which gave more weight to less frequently appearing classes (AgNC class). This strategy was crucial because the number of AgNC class pixels was significantly smaller than the number of background pixels, enhancing the pixel identification accuracy during training.\n\nThe training process involved stochastic gradient descent with momentum (SGDM) to minimize the loss function, with a total of 200 epochs and 20 samples per minibatch. Four candidate networks with training accuracy above 98% were selected and further evaluated using 126 well-selected test images. The final CNN was integrated into the image processing method to recognize AgNC spots in images, with the spot number calculated by area-size sorting. This preprocessing and encoding ensured that the CNN could accurately identify and count AgNC spots, even in complex images with varying intensities and aggregations.",
  "optimization/parameters": "The model utilized in our study is a convolutional neural network (CNN) designed for image processing tasks. The architecture of the CNN includes both downsampling and upsampling processes. The downsampling process consists of six layers: an image input layer, two convolution 2D layers with six filters and a kernel size of 3x3, two rectified linear unit (ReLU) layers, and one max-pooling layer with a stride of 2. The upsampling process comprises five layers: a transposed convolution 2D layer, a ReLU layer, a convolution 2D layer, a softmax layer, and a pixel classification layer that includes class weight balancing.\n\nThe selection of parameters in the CNN was guided by the need to enhance pixel identification accuracy, particularly for the AgNC class, which had significantly fewer pixels compared to the background. To address this imbalance, a class weighting strategy was employed, defined as the ratio of the total number of image pixels to the number of pixels for each class. This strategy was integrated into the neural network training process to improve the model's performance in identifying AgNC spots.\n\nThe training process involved using the stochastic gradient descent with momentum (SGDM) algorithm to minimize the loss function. The total number of epochs was set to 200, with each minibatch containing 20 samples. Four candidate networks with training accuracies above 98% were selected and further evaluated using 126 well-selected test images. The final CNN was chosen based on its performance in these evaluations.\n\nIn summary, the CNN architecture and training parameters were carefully selected to optimize the model's ability to accurately identify and count AgNC spots in images, addressing the challenges posed by class imbalance and ensuring high performance in practical applications.",
  "optimization/features": "The input features for our convolutional neural network (CNN) are derived from 512\u00d7512 pixel dark-field images. These images are used for category classification, where nanoparticles are labeled as class \"1\" and the background as class \"0\". The CNN architecture includes a downsampling process consisting of an image input layer, two convolution 2D layers with 6 filters and a kernel size of 3\u00d73, two rectified linear unit (ReLU) layers, and one max-pooling layer with a stride of 2. This setup ensures that the network can effectively capture and process the relevant features from the images.\n\nFeature selection in the traditional sense was not performed, as the CNN automatically learns the most relevant features from the raw pixel data during the training process. The network is trained using a dataset of 252 representative dark-field images, which cover a wide range of cytokine concentrations. A thresholding algorithm using Otsu's method was employed to compute a global threshold for initial labeling, followed by manual corrections to refine the labeled images. This process ensures that the network is trained on high-quality, accurately labeled data.\n\nThe class weight balance was considered using the inverse frequency weighting method, which gives more weight to less frequently appearing classes (AgNC class). This approach helps the network to better identify and classify the nanoparticles, even when they are in the minority compared to the background pixels. The training process involves dataset labeling, class weight balance, network training, and result evaluation, all of which contribute to the robustness and accuracy of the CNN.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting during the training of our Convolutional Neural Network (CNN). One of the key methods used was class weight balancing. Given the significant disparity between the number of AgNC class pixels and background pixels, we implemented an inverse frequency weighting strategy. This approach assigns higher weights to the less frequently appearing AgNC class, thereby ensuring that the network pays more attention to these critical pixels during training. The class weight was calculated as the ratio of the total number of image pixels to the number of pixels for each class. This strategy helped enhance the pixel identification accuracy and mitigated the risk of the model being biased towards the more prevalent background class.\n\nAdditionally, we utilized a stochastic gradient descent with momentum (SGDM) algorithm to minimize the loss function. This optimization technique helps in navigating the loss landscape more effectively, reducing the likelihood of the model getting stuck in local minima and thereby improving generalization.\n\nFurthermore, we carefully selected a representative dataset for training, which included a wide range of cytokine concentrations. This diversity in the training data helped the model to generalize better to unseen data. We also employed a thorough validation process, evaluating the performance of multiple candidate networks using well-selected test images. Only the networks that achieved a training accuracy above 98% were considered, and the final model was chosen based on its performance on the test dataset. This rigorous validation process ensured that the selected model was robust and not overfitted to the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed the stochastic gradient descent with momentum (SGDM) algorithm to minimize the loss function during the training of our convolutional neural network (CNN). The total number of epochs was set to 200, with each minibatch consisting of 20 samples. These details are provided to ensure reproducibility of our results.\n\nRegarding the model files and optimization parameters, the specific files and parameters are not explicitly listed in the main text but are part of the supplementary material available on the ACS Publications website. The supplementary material includes detailed experimental descriptions and additional data that support the findings presented in the main manuscript. This supplementary information is available free of charge and can be accessed via the provided DOI.\n\nThe license under which this material is available is typically governed by the publisher's policies. For ACS Publications, the material is often made available under terms that allow for academic use and sharing, but specific details should be verified through the publisher's guidelines or the supplementary material itself.",
  "model/interpretability": "The model employed in our study is a Convolutional Neural Network (CNN), which is inherently a type of black-box model. This means that while the CNN can effectively learn and make predictions based on input data, the internal decision-making process is not easily interpretable by humans. The CNN architecture includes layers such as convolutional layers, rectified linear unit (ReLU) layers, max-pooling layers, transposed convolutional layers, softmax layers, and pixel classification layers. These layers work together to process and classify images, but the specific weights and transformations applied at each layer are not straightforward to interpret.\n\nHowever, the CNN's transparency can be enhanced through several strategies. For instance, the use of class weighting helps to balance the training process, making the model more accurate in identifying less frequent classes, such as AgNC spots. Additionally, the training process involves manual correction of labeled images, which ensures that the model learns from accurately annotated data. This manual intervention adds a layer of interpretability, as it involves human oversight and correction.\n\nFurthermore, the CNN's performance is evaluated using well-selected test images, and the finalized model is integrated into an image processing method that recognizes AgNC spots based on area-size sorting. This approach provides a clear and quantifiable output, making the model's predictions more interpretable in the context of the specific task it was designed for.\n\nIn summary, while the CNN itself is a black-box model, the use of class weighting, manual data annotation, and clear evaluation metrics enhances its transparency and interpretability. The model's predictions are based on well-defined layers and processes, and the final output is quantifiable, making it a reliable tool for counting particle numbers in digital immunoassays.",
  "model/output": "The model is primarily a classification model, designed to identify and count particles in images. It classifies pixels into two categories: nanoparticles (class \"1\") and background (class \"0\"). This classification is crucial for segmenting the nanoparticles from the background in dark-field images. The model's output is then used to count the number of nanoparticles, which is a form of regression in the sense that it provides a numerical output based on the classified pixels. However, the core functionality of the model is pixel classification.\n\nThe output of the model is the number of nanoparticles in an image, which is determined by the area-size sorting of the recognized nanoparticle spots. The model processes images of 512\u00d7512 pixels, and the nanoparticle spots are normalized to a 5\u00d75 pixel unit size. This normalization helps in accurately recognizing and counting individual, aggregated, bright, and dim spots.\n\nThe model's performance was evaluated using 126 well-selected test images, and it was finalized based on its accuracy in recognizing nanoparticle spots. The pre-trained convolutional neural network (CNN) algorithm was integrated into an image processing method to recognize all areas of nanoparticle spots in an image. The final output is the nanoparticle spot number (i.e., particle number) in the image, which is calculated by dividing the recognized nanoparticle spot area by the 5\u00d75 pixel unit size.\n\nThe model's accuracy was verified by comparing its output with the results from the Image-Pro-Plus-assisted manual counting method. The comparison showed an excellent linear regression with a high coefficient of determination, indicating the model's high accuracy and reliability. The model's robustness was further demonstrated by its consistent performance across different experiments and days.\n\nThe model's output is not only accurate but also efficient. It takes approximately 30 seconds to process 288 images from one immunoassay chip, making it a high-throughput solution for nanoparticle counting in dark-field images. This efficiency is a significant improvement over manual counting methods, which can take up to 50 hours to accomplish the same task.",
  "model/duration": "The execution time for processing a set of 288 images using our convolutional neural network (CNN)-based image processing method is approximately 30 seconds. This efficiency is achieved using a customized MATLAB code and a CPU with an AMD Ryzen 5 1600 Six-Core Processor. This rapid processing time is a significant improvement over traditional methods, such as those assisted by Image-Pro Plus, which can take up to 50 hours to complete the same task. The CNN method's speed and accuracy make it highly suitable for high-throughput imaging analysis, ensuring that the detection results are obtained promptly.",
  "model/availability": "The source code for the convolutional neural network (CNN) algorithm used in our study is not publicly released. However, the image processing method was implemented using custom MATLAB code, which was used to analyze the images acquired from our digital immunoassay. This code was specifically designed to handle the preprocessing, segmentation, and post-processing of dark-field images to accurately count the number of silver nanocube (AgNC) spots.\n\nWhile the exact MATLAB code is not available for public use, the methodology and architecture of the CNN are detailed in the publication. This includes the downsampling and upsampling processes, the use of convolutional layers, rectified linear units (ReLU), max-pooling, and transposed convolution layers. The training process involved dataset labeling, class weight balancing, and network training, all of which are described in the methods section.\n\nFor those interested in replicating or building upon our work, the detailed description of the CNN architecture and training procedures should provide a solid foundation. Additionally, the performance evaluation of the CNN method against traditional image processing techniques, such as Image-Pro Plus and global thresholding segmentation (GTS), is thoroughly discussed, offering insights into the advantages and accuracy of our approach.",
  "evaluation/method": "The evaluation of our method involved several key steps to ensure its accuracy, reproducibility, and practical applicability. We began by assessing the reproducibility of our digital immunoassay through replicate determinations on multi-cytokine standards with varying concentrations. This was done using both the same and different batches of multi-antibody microarray chips and AgNC-DAb conjugates. The evaluation was based on calculating intra- and inter-batch coefficients of variation (CVs), which showed low values, indicating excellent reproducibility and repeatability.\n\nTo evaluate the specificity and cross-reactivity of our multiplex cytokine immunoassay, we conducted three control tests. These included using a negative human serum sample without target cytokines, positive serum samples containing only a single analyte, and positive serum samples containing all six target cytokines. The results showed negligible cross-reactivity, confirming the high specificity of our immunoassay.\n\nWe also validated our method by analyzing 16 cytokine-spiked human serum samples and comparing the results with the gold-standard ELISA method. The strong positive correlation between the two methods demonstrated the high accuracy and reliability of our immunoassay, even at low cytokine concentrations.\n\nAdditionally, we applied our immunoassay to measure serum cytokines in 40 human serum specimens from COVID-19 patients. This real-world application further validated the method's practicality and high throughput capabilities, as we completed 1440 tests within just 5 hours.\n\nThe machine-learning-based image processing method, which is a crucial part of our immunoassay, was evaluated by comparing it with commercial software and conventional image processing methods. The CNN method showed superior accuracy in recognizing and counting aggregated/neighboring and dim spots, especially at high AgNC counts. This was further verified by analyzing 288 test images, which showed an excellent linear regression with the benchmark method.\n\nOverall, the evaluation of our method involved a combination of controlled experiments, real-world applications, and comparisons with established methods, all of which demonstrated the high performance and practical applicability of our nanoplasmonic digital immunoassay.",
  "evaluation/measure": "In our evaluation of the nanoplasmonic digital immunoassay, we focused on several key performance metrics to ensure the assay's reliability and accuracy for clinical applications.\n\nFirstly, we assessed the reproducibility of the assay by calculating intra- and inter-batch coefficients of variation (CVs). These metrics were determined through replicate measurements of multi-cytokine standards at low, medium, and high concentrations using both same- and different-batches of multi-antibody microarray chips and AgNC-DAb conjugates. The intra-batch CVs ranged from 3.27% to 8.87%, while the inter-batch CVs ranged from 5.14% to 10.8% for all six cytokines across the tested concentrations. These low CV values indicate excellent reproducibility and repeatability, which are crucial for large-scale production and clinical usage.\n\nTo evaluate the specificity and cross-reactivity of our multiplex cytokine immunoassay, we conducted control tests using human serum samples. These tests included a negative serum sample, positive serum samples with single analytes, and positive serum samples with all six target cytokines. The results showed negligible cross-reactivity, as evidenced by the correlation between the back-calculated cytokine concentrations and their corresponding values. This high specificity is essential for accurate cytokine profiling in complex human serum samples.\n\nAdditionally, we validated the assay's performance by comparing it with the gold-standard ELISA method. We analyzed 16 cytokine-spiked human serum samples and found a strong positive correlation (R\u00b2 = 0.996) between the measured cytokine concentrations by our immunoassay and the reference ELISA. Even at lower cytokine concentrations (5-100 pg mL\u207b\u00b9), the agreement between the two methods remained excellent (R\u00b2 = 0.995), demonstrating the high accuracy and reliability of our immunoassay.\n\nThe dynamic range of the immunoassay was also determined, with sensing ranges of 1-5,000 pg mL\u207b\u00b9 for IL-1\u03b2, IL-10, and IFN-\u03b3; 1-1,000 pg mL\u207b\u00b9 for IL-2; and 1-2,000 pg mL\u207b\u00b9 for IL-6 and TNF-\u03b1. These ranges are comparable to or wider than those reported in the literature for similar assays, ensuring the assay's sensitivity across a broad concentration range.\n\nFurthermore, the limits of detection (LODs) for the six cytokines were calculated, with values ranging from 0.50 pg mL\u207b\u00b9 to 1.44 pg mL\u207b\u00b9. These low LODs highlight the assay's high sensitivity, which is vital for detecting low-level cytokine expressions in clinical samples.\n\nIn summary, the reported performance metrics\u2014including CVs, specificity, cross-reactivity, correlation with ELISA, dynamic range, and LODs\u2014provide a comprehensive evaluation of the nanoplasmonic digital immunoassay's analytical performance. These metrics are representative of the state-of-the-art in cytokine immunoassays and demonstrate the assay's potential for clinical applications.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our machine-learning-based image processing method, utilizing a convolutional neural network (CNN), against publicly available and widely used methods. We benchmarked our CNN method against commercial software such as Image-Pro Plus and conventional image processing techniques like global thresholding and segmentation (GTS).\n\nTo ensure a fair and comprehensive comparison, we analyzed 288 test images containing varying numbers of AgNCs, ranging from 0 to 2,000. These images were distinct from those used for training the CNN, providing an unbiased assessment of its performance. The results obtained from our CNN method were then compared with those from Image-Pro Plus-assisted manual counting, which served as the benchmark.\n\nThe comparison revealed that while all methods could accurately count monodispersed bright spots at low AgNC counts, Image-Pro Plus and GTS methods struggled with aggregated/neighboring and dim spots, especially at higher AgNC counts. In contrast, our CNN method demonstrated superior accuracy and consistency in distinguishing detection signals from false signals/background noise, even in the presence of high scattering intensity variance.\n\nFurthermore, we evaluated the dynamic range and limit of detection (LOD) for six target cytokines using both the CNN method and Image-Pro Plus. The sensing dynamic ranges obtained with Image-Pro Plus were significantly narrower compared to those achieved with the CNN method. Additionally, the LODs calculated using Image-Pro Plus were compromised due to its inability to accurately count aggregated/neighboring and dim spots, leading to underestimation and miscounting of AgNCs.\n\nThese comparisons highlight the advantages of our CNN method in providing accurate and robust image processing for high-throughput imaging analysis, making it a superior choice over simpler baselines and publicly available methods.",
  "evaluation/confidence": "The evaluation of our method's performance includes several key metrics that demonstrate its superiority over other methods, such as Image-Pro Plus and global thresholding and segmentation (GTS). The confidence in these results is supported by rigorous statistical analysis.\n\nFor instance, the comparison between the CNN method and Image-Pro Plus-assisted manual counting shows an excellent linear regression with a slope of 0.9902, a small intercept of 3.1140, and a coefficient of determination (R\u00b2) of 0.9972. This high R\u00b2 value indicates a very strong correlation between the two methods, suggesting that our CNN method is highly accurate. Furthermore, the accuracy of our CNN-based method improves with the number of AgNCs in the range of 0-800, with a slope of 1.0004, an intercept of -0.2588, and an R\u00b2 of 0.9998. These metrics provide strong evidence of the method's reliability and precision.\n\nThe reproducibility of our digital immunoassay was evaluated using intra- and inter-batch coefficients of variation (CVs) for three different multi-cytokine standards with low, medium, and high concentrations. The CVs were found to be in the ranges of 3.27-8.87% and 5.14-10.8%, respectively, indicating excellent reproducibility and repeatability. These low CVs suggest that our method is consistent and reliable for large-scale production and clinical usage.\n\nAdditionally, the specificity and cross-reactivity of our multiplex cytokine immunoassay were assessed through control tests using negative and positive serum samples. The results showed negligible cross-reactivity and high specificity, as other bio-components in human serum did not interfere with the immune sandwich formation. This further confirms the method's accuracy and reliability in complex biological samples.\n\nThe limits of detection (LODs) for the six cytokines were determined to be as low as 0.46 pg mL\u207b\u00b9 (for IL-6), which is among the highest sensitivity levels in nanoplasmonic biosensors for multiplex cytokine detection without signal amplification. The sensing dynamic ranges achieved by our method are also significantly wider than those of standard single-plex cytokine ELISA methods, providing a suitable range for profiling serum cytokines in COVID-19 patients.\n\nOverall, the performance metrics, including high R\u00b2 values, low CVs, and low LODs, along with the statistical significance of the results, provide strong confidence in the superiority of our CNN method over other existing techniques.",
  "evaluation/availability": "Not enough information is available."
}