{
  "publication/title": "Development and validation of a deep learning-based approach to predict the Mayo endoscopic score of ulcerative colitis.",
  "publication/authors": "Qi J, Ruan G, Ping Y, Xiao Z, Liu K, Cheng Y, Liu R, Zhang B, Zhi M, Chen J, Xiao F, Zhao T, Li J, Zhang Z, Zou Y, Cao Q, Nian Y, Wei Y",
  "publication/journal": "Therapeutic advances in gastroenterology",
  "publication/year": "2023",
  "publication/pmid": "37251086",
  "publication/pmcid": "PMC10214058",
  "publication/doi": "10.1177/17562848231170945",
  "publication/tags": "- Artificial Intelligence\n- Gastroenterology\n- Ulcerative Colitis\n- Endoscopy\n- Deep Learning\n- Medical Imaging\n- Diagnostic Tools\n- Mayo Endoscopic Score\n- Multicenter Studies\n- Retrospective Studies",
  "dataset/provenance": "The dataset used in this study was collected from multiple hospitals in China. Specifically, we gathered 15,120 images from 768 patients who underwent colonoscopy between January 2018 and December 2021. These images were sourced from the Army Medical Center of PLA in Chongqing and Sir Run Run Shaw Hospital of Zhejiang University. The dataset was divided into a training set consisting of 13,365 images from 671 cases and an internal test set with 1755 images from 97 cases.\n\nAdditionally, we included external test sets from three other hospitals: 511 images from 42 cases at The First Affiliated Hospital of Chongqing Medical University, 234 images from 45 cases at The Sixth Affiliated Hospital of Sun Yat-Sen University, and 159 images from 11 cases at Tongji Hospital affiliated with Huazhong University of Science and Technology.\n\nThe colonoscopy examinations were performed by well-trained endoscopists using high-definition colonoscopes, and the images included detailed descriptions and schemes of various lesions observed in different colonic segments. This comprehensive dataset was designed to ensure a robust evaluation of the deep learning model developed for predicting the Mayo endoscopic score in ulcerative colitis patients.",
  "dataset/splits": "The dataset used in this study was divided into three main splits: a training set, an internal test set, and external test sets.\n\nThe training set consisted of 13,365 images from 671 cases. These images were collected from two hospitals: Army Medical Center of PLA and Sir Run Run Shaw Hospital of Zhejiang University, spanning from January 2018 to December 2021.\n\nThe internal test set comprised 1,755 images from 97 cases. This set was used to evaluate the performance of the UC-former model after training.\n\nIn addition to the internal test set, there were external test sets collected from three other hospitals to evaluate the generalization of the UC-former. These external test sets included:\n\n* 511 images from 42 cases from The First Affiliated Hospital of Chongqing Medical University.\n* 234 images from 45 cases from The Sixth Affiliated Hospital of Sun Yat-Sen University.\n* 159 images from 11 cases from Tongji Hospital affiliated with Huazhong University of Science and Technology.\n\nThe distribution of data points in each split was designed to ensure a comprehensive evaluation of the model's performance across different settings and to assess its generalization capabilities.",
  "dataset/redundancy": "The dataset used in this study was collected from multiple hospitals and was divided into training and test sets to ensure independence and robustness of the model evaluation. The dataset consisted of 15,120 images from 768 patients, collected from two primary hospitals. These images were randomly split into a training set containing 13,365 images from 671 cases and an internal test set with 1755 images from 97 cases. This random split helps to ensure that the training and test sets are independent, reducing the risk of data leakage and overfitting.\n\nAdditionally, external test sets were created from images collected from three other hospitals. These external test sets included 511 images from 42 cases, 234 images from 45 cases, and 159 images from 11 cases. The use of external test sets from different hospitals helps to validate the model's generalizability and performance across diverse clinical settings.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the field of gastroenterology. The large number of images and the inclusion of data from multiple centers enhance the representativeness and reliability of the results. The random splitting and the use of external test sets are standard practices in machine learning to ensure that the model's performance is not overly optimized for a specific subset of data, thereby providing a more accurate assessment of its real-world applicability.",
  "dataset/availability": "The datasets collected in this study are not publicly released in a forum. However, they are available from the corresponding author upon reasonable request. This approach ensures that the data is shared responsibly while maintaining control over its distribution. The datasets include colonoscopy images from patients with ulcerative colitis (UC), collected from multiple hospitals in China. The data was split into training and test sets, with specific numbers of images allocated to each set. The internal test set consisted of 1755 images, while external test sets included images from additional hospitals. This method of data availability ensures that researchers who wish to replicate or build upon the study can access the necessary information while adhering to ethical and institutional guidelines.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the stochastic gradient descent (SGD) optimizer. This is a well-established class of machine-learning algorithms, widely used for training deep neural networks due to its efficiency and effectiveness in minimizing the loss function.\n\nThe SGD optimizer used in our work is not a new algorithm. It has been extensively studied and applied in various machine-learning and deep learning frameworks. The specific configuration of our SGD optimizer includes a momentum of 0.9 and a weight decay of 1 \u00d7 10^-5. These hyperparameters were chosen to stabilize and accelerate the training process, helping the model to converge more quickly and avoid local minima.\n\nThe reason this work was not published in a machine-learning journal is that the focus of our research is on the application of deep learning techniques to medical imaging, specifically for the classification of ulcerative colitis (UC) endoscopic images. The primary contribution of our study lies in the development and evaluation of the UC-former model, which leverages transformer architecture to improve the accuracy and efficiency of UC diagnosis. The optimization algorithm is a crucial component of the training process, but it is not the main innovation of our work. Therefore, the study is more appropriately published in a journal that specializes in gastroenterology and medical imaging, where the clinical implications and diagnostic performance of the UC-former model can be fully appreciated.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. It is a deep learning-based approach, specifically a transformer model named UC-former, designed to predict the Mayo endoscopic score of ulcerative colitis (UC) images. The UC-former does not use data from other machine-learning algorithms as input. Instead, it directly processes endoscopic images to make predictions.\n\nThe UC-former was trained using a combination of loss functions, including cross-entropy loss for both an auxiliary task and the primary task, as well as a contrastive loss function to diversify the representation of patches in the images. The training process involved eight NVIDIA GeForce RTX 2080 Ti graphics cards, with an initial learning rate of 0.01, adjusted by the exponential attenuation method. The stochastic gradient descent optimizer with a momentum of 0.9 and a weight decay of 1 \u00d7 10^\u22125 was used to train the model for a maximum of 50 epochs.\n\nThe performance of the UC-former was evaluated using an internal test set of 1755 images, and it was also validated across multiple centers to assess its generalization performance. The model's accuracy, sensitivity, specificity, positive prediction value, and negative prediction value were calculated to evaluate its classification performance.\n\nIn summary, the UC-former is a standalone deep learning model that does not rely on the outputs of other machine-learning algorithms. It was trained and validated using endoscopic images to predict the Mayo endoscopic score, demonstrating high accuracy and reliability in both internal and external validation settings.",
  "optimization/encoding": "For the data encoding and preprocessing, we began by applying the contrast-limited adaptive histogram equalization (CLAHE) algorithm to each image. This step was crucial for highlighting the features within the images.\n\nFollowing this, we randomly cropped a 224 \u00d7 224 area from each image. This cropped area was then subjected to various data enhancement operations, including random flipping and random brightness jitter, to increase the diversity of the training data.\n\nThe cropped and enhanced images were then input into the Vision Transformer (ViT) network. The ViT decomposed each input image into a series of patches, with each 224 \u00d7 224 image divided into 196 (14 \u00d7 14) patches, and the size of each patch set to 16 \u00d7 16. Each patch was linearly embedded and location information was added to preserve spatial context.\n\nTo address class imbalances in the dataset, we constructed a patch library for categories with smaller sample sizes. This library contained all the patches from splitting all images of that category in the training set. We then randomly selected, rotated, and rearranged patches from this library to generate new images, which were added back into the training set. This approach helped improve the generalization of the deep model by ensuring that it could learn from a more balanced and diverse set of examples.\n\nAdditionally, a learnable class token was added to the vector sequence for subsequent image classification. This token helped the model to focus on the relevant features for classification tasks. The structure of each transformer encoder included two layerNorm layers, a multihead attention module, and a multilayer perceptron module, which worked together to process the input data effectively.",
  "optimization/parameters": "The model, UC-former, was trained using eight NVIDIA GeForce RTX 2080 Ti graphics cards. The initial learning rate was set to 0.01 and adjusted using the exponential attenuation method. The stochastic gradient descent optimizer was employed with a momentum of 0.9 and a weight decay of 1 \u00d7 10^-5. The model was trained for a maximum of 50 epochs.\n\nThe loss function for the model is a combination of three components: cross-entropy loss for an auxiliary task, cross-entropy loss for the primary task, and a contrastive loss function. These components are weighted as follows: \u03b1 = 0.5, \u03b2 = 0.4, and \u03b3 = 0.1, respectively. The values of these weights were determined through 10-fold cross-validation repeated five times on the training set. This process was conducted using the PyCharm 2020.1.3 platform, with the PyTorch framework version 1.7.0 and Python version 3.8.5.\n\nThe model's performance was evaluated using an internal test set of 1755 images, and various metrics such as AUC, ACC, sensitivity, specificity, positive prediction value, and negative prediction value were calculated. Additionally, heatmaps and attention maps were generated to understand the decision-making basis of the network. The model's performance was also compared with that of six endoscopists, including both junior and senior professionals.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The model employed in this study, the UC-former, utilized a Vision Transformer (ViT) architecture, which inherently has a large number of parameters due to its transformer-based design. This can potentially lead to overfitting, especially when the number of training samples is limited. To mitigate this risk, several strategies were implemented.\n\nFirstly, data augmentation techniques were extensively used. These included contrast-limited adaptive histogram equalization (CLAHE) to enhance image features, random cropping, flipping, and brightness jittering. Additionally, a patch library was created for categories with smaller sample sizes, allowing for the generation of new images by rearranging and rotating patches. This approach helped to increase the diversity of the training data and improve the model's generalization ability.\n\nSecondly, transfer learning was employed to leverage pre-trained models, which provided a good starting point for the training process. This technique helps in reducing the number of epochs required for training and can lead to better performance with fewer data points.\n\nThirdly, multiple loss functions were used during training. These included cross-entropy loss for the primary and auxiliary classification tasks, as well as a contrastive loss function to ensure that the model learned diverse representations for different patches. The combination of these loss functions, weighted appropriately, helped in guiding the model to learn more robust features.\n\nTo further prevent overfitting, techniques such as weight decay and dropout were incorporated. The stochastic gradient descent optimizer with momentum was used, and the learning rate was adjusted using an exponential decay method. These regularization techniques helped in controlling the complexity of the model and preventing it from memorizing the training data.\n\nTo ensure that the model was not underfitting, the performance was evaluated on both internal and external datasets. The internal test set consisted of 1755 images, and the model's performance was assessed using metrics such as AUC, ACC, sensitivity, specificity, PPV, and NPV. Additionally, the model was validated on external datasets from three different hospitals, demonstrating its generalization ability across diverse data distributions.\n\nThe use of 10-fold cross-validation repeated five times on the training set also helped in tuning the hyperparameters effectively, ensuring that the model generalized well to unseen data. This rigorous validation process provided confidence that the model was neither overfitting nor underfitting the data.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and enhance the generalization of our model. One key method used was weight decay, which was set to 1 \u00d7 10^-5. This technique helps to penalize large weights in the model, encouraging simpler models that generalize better to unseen data.\n\nAdditionally, we utilized data augmentation techniques to increase the diversity of our training dataset. This approach helps the model to learn more robust features that are invariant to certain transformations, thereby reducing the risk of overfitting to the specific patterns in the training data.\n\nWe also implemented a contrastive loss function. This loss function encourages the model to learn discriminative features by making the representations of similar patches more alike and those of dissimilar patches more different. This technique aids in improving the model's ability to generalize to new, unseen data.\n\nFurthermore, we performed 10-fold cross-validation repeated five times on the training set to tune the hyperparameters of the UC-former. This method ensures that the model's performance is evaluated on multiple subsets of the data, providing a more reliable estimate of its generalization capability.\n\nLastly, we used an exponential decay method to adjust the learning rate during training. This technique helps in fine-tuning the model by reducing the learning rate as training progresses, allowing the model to converge more stably and avoid overfitting to the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in detail within the publication. Specifically, we utilized eight NVIDIA GeForce RTX 2080 Ti graphics cards for training the deep network. The initial learning rate was set to 0.01 and adjusted using the exponential attenuation method. The stochastic gradient descent optimizer was employed with a momentum of 0.9 and a weight decay of 1 \u00d7 10^-5. The model was trained for a maximum of 50 epochs.\n\nThe loss functions used in the training process are also clearly defined. We employed cross-entropy loss functions for both the auxiliary and primary tasks, as well as a contrast loss function to ensure that shallow and deep features were appropriately diversified. The constructed loss function was a weighted sum of these individual loss functions, with specific weights assigned to each component.\n\nRegarding model files and optimization parameters, the exact details of these are not explicitly provided in the text. However, the implementation was carried out using the PyCharm 2020.1.3 platform, with the PyTorch framework version 1.7.0 and Python version 3.8.5. These tools and versions are standard and widely accessible, ensuring reproducibility.\n\nFor access to the specific model files and optimization parameters, readers would typically refer to supplementary materials or repositories associated with the publication. However, the text does not specify the availability or licensing details of these resources. Therefore, for comprehensive access, it is advisable to contact the authors or check the associated supplementary materials or repositories.",
  "model/interpretability": "The UC-former model is not a black box. It employs feature visualization techniques to explore its working mechanism and judgment basis. Specifically, the model uses heatmaps to highlight important areas in the input images that contribute to the final classification. These heatmaps show that the model focuses on lesion areas, which are significant and distinguishing features in ulcerative colitis (UC) images. This indicates that the UC-former learns to identify key features during training, making it a reliable and robust deep learning model.\n\nThe multihead attention module in each transformer encoder of the UC-former generates feature maps. There are 12 heads in each encoder, each extracting different correlations between image patches. As the network deepens, the features become more focused, and lesion patches are highlighted. This progressive focusing helps in understanding how the model makes decisions.\n\nAdditionally, attention maps from the multihead attention modules are extracted to observe which patch areas the model pays more attention to as the network deepens. This further aids in interpreting the model's decision-making process. The heatmaps and attention maps provide intuitive visualizations of the important parts of the input images, making the UC-former's decision-making basis more transparent.",
  "model/output": "The model is a classification model. It is designed to predict the Mayo endoscopic score of ulcerative colitis (UC) images, which involves categorizing the severity of UC into different levels. The model combines Mayo 0 and Mayo 1 into a 'mild' category and Mayo 2 and Mayo 3 into a 'severe' category for more consistent classification. The output of the model includes predicted probabilities for each category, which are used to determine the final classification. The performance of the model is evaluated using metrics such as AUC, ACC, sensitivity, specificity, positive prediction value, and negative prediction value. Additionally, heatmaps and attention maps are generated to visualize the areas of the input images that are most influential in the model's decision-making process. These visualizations help to understand which parts of the images the model focuses on for classification.",
  "model/duration": "The model, known as UC-former, demonstrated exceptional efficiency in its decision-making process. On average, it took approximately 0.017 seconds to classify each image. This rapid processing speed highlights the model's potential for real-time classification of endoscopic videos, making it a feasible tool for clinical settings. The speed at which the model operates is a significant advantage, as it allows for quick and efficient analysis, which is crucial in medical diagnostics.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the UC-former model involved several rigorous steps to ensure its performance and generalization. Initially, a 10-fold cross-validation was conducted on the training set to assess the model's accuracy, sensitivity, specificity, positive predictive value, negative predictive value, and the area under the receiver operating characteristic curve.\n\nFor a more comprehensive evaluation, the model was tested on an internal test set consisting of 1755 images. This allowed for the calculation of key performance metrics such as accuracy, sensitivity, specificity, positive predictive value, and negative predictive value. Additionally, heatmaps were generated to visualize the areas of the images that the model focused on for decision-making, providing insights into the model's attention mechanisms.\n\nTo further validate the model's performance, it was compared against six endoscopists, including both junior and senior professionals. This comparison involved having the endoscopists independently score the same set of UC images, allowing for a direct assessment of the model's diagnostic accuracy relative to human experts.\n\nMoreover, the model's generalization was evaluated using external datasets collected from three different hospitals. This multicenter validation helped to assess the model's robustness and its ability to perform well across different clinical settings and patient populations. The results from these external datasets were presented in the form of confusion matrices and ROC curves, providing a clear visualization of the model's performance.\n\nOverall, the evaluation process included both internal and external validations, comparisons with human experts, and the use of visual aids to understand the model's decision-making process. This multifaceted approach ensured a thorough assessment of the UC-former's effectiveness and reliability in predicting the Mayo endoscopic score for ulcerative colitis.",
  "evaluation/measure": "In our evaluation of the UC-former model, we employed a comprehensive set of performance metrics to ensure a thorough assessment of its capabilities. The primary metrics reported include Accuracy (ACC), Sensitivity (SEN), Specificity (SPE), Positive Prediction Value (PPV), and Negative Prediction Value (NPV). These metrics were chosen for their relevance and widespread use in evaluating classification models, particularly in medical imaging.\n\nAccuracy provides an overall measure of the model's correctness, indicating the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall, measures the model's ability to correctly identify positive cases, which is crucial for detecting ulcerative colitis (UC) lesions. Specificity assesses the model's ability to correctly identify negative cases, ensuring that non-lesion areas are accurately classified. PPV and NPV offer insights into the precision of positive and negative predictions, respectively, which are essential for understanding the reliability of the model's diagnoses.\n\nAdditionally, we calculated the Area Under the Receiver Operating Characteristic Curve (AUC) to evaluate the model's performance across different threshold settings. The AUC provides a single scalar value that summarizes the model's ability to discriminate between positive and negative classes, offering a comprehensive view of its diagnostic performance.\n\nThese metrics are representative of the standards used in the literature for evaluating medical imaging models. They provide a balanced view of the model's performance, covering aspects such as overall correctness, sensitivity to positive cases, specificity to negative cases, and the reliability of predictions. By reporting these metrics, we aim to offer a transparent and comprehensive evaluation of the UC-former's capabilities, ensuring that our findings are comparable to other studies in the field.",
  "evaluation/comparison": "The evaluation of the UC-former included a comprehensive comparison with endoscopists to assess its performance in classifying the severity of ulcerative colitis (UC). This comparison involved six endoscopists, divided into junior and senior groups based on their experience. The junior endoscopists had approximately 7 years of working experience, while the senior endoscopists had more than 15 years. All endoscopists were skilled in colonoscopy diagnosis and had undergone professional training.\n\nThe performance of the UC-former was evaluated using various metrics, including accuracy (ACC), sensitivity (SEN), specificity (SPE), positive prediction value (PPV), and negative prediction value (NPV). The UC-former demonstrated superior performance compared to both junior and senior endoscopists. Specifically, the overall accuracy of the UC-former was 0.908, which was significantly higher than the best-performing senior endoscopist (0.773) and junior endoscopist (0.849). This comparison highlighted the UC-former's ability to accurately classify UC severity, outperforming human experts.\n\nAdditionally, the UC-former's performance was assessed using external datasets from three different hospitals to evaluate its generalization capability. This multicenter validation further confirmed the model's robustness and reliability in real-world clinical settings. The results showed consistent performance across different hospitals, indicating that the UC-former can be effectively applied in various clinical environments.\n\nIn summary, the UC-former was compared against experienced endoscopists and demonstrated superior accuracy and reliability in classifying UC severity. This comparison underscores the potential of the UC-former as a valuable tool in clinical practice, providing accurate and consistent diagnoses.",
  "evaluation/confidence": "The evaluation of the UC-former model includes several performance metrics, each accompanied by 95% confidence intervals (CIs). These metrics include accuracy (ACC), sensitivity (SEN), specificity (SPE), positive predictive value (PPV), and negative predictive value (NPV). The use of confidence intervals provides a range within which the true value of these metrics is likely to fall, offering a measure of the reliability of the results.\n\nStatistical significance is assessed using the McNemar test for ACC, SEN, and SPE, and the Chi-square test for PPV and NPV. A p-value less than 0.05 is considered statistically significant. The results indicate that the UC-former outperforms both junior and senior endoscopists in terms of overall accuracy, with significant differences noted. For instance, the UC-former's overall accuracy of 0.908 (95% CI, 0.893\u20130.920) is significantly higher than that of the best senior endoscopist (0.773, 95% CI, 0.753\u20130.792) and the best junior endoscopist (0.849, 95% CI, 0.831\u20130.865).\n\nThe area under the receiver operating characteristic curve (AUC) for different Mayo endoscopic scores also shows high values, further supporting the model's strong performance. The AUCs for Mayo 0, Mayo 1, Mayo 2, and Mayo 3 are 0.998, 0.984, 0.973, and 0.990, respectively, all with narrow confidence intervals, indicating high precision and reliability.\n\nAdditionally, the model's performance is validated through multicenter testing, where it demonstrates consistent accuracy across different hospitals. This multicenter validation, along with the statistical tests, provides robust evidence of the UC-former's superiority over human endoscopists in predicting Mayo endoscopic scores for ulcerative colitis.",
  "evaluation/availability": "The datasets collected in this study are available from the corresponding author upon reasonable request. This approach ensures that the data can be accessed for further research while maintaining control over its distribution. The decision to provide the datasets upon request aligns with the ethical considerations and institutional requirements, ensuring that the data is used responsibly and in accordance with the guidelines set by the relevant authorities."
}