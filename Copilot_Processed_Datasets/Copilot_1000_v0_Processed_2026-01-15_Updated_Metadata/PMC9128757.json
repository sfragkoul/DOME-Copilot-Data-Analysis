{
  "publication/title": "Dynamic-Fusion-Based Federated Learning for COVID-19 Detection.",
  "publication/authors": "Zhang W, Zhou T, Lu Q, Lu Q, Wang X, Zhu C, Sun H, Wang Z, Lo SK, Wang FY",
  "publication/journal": "IEEE internet of things journal",
  "publication/year": "2021",
  "publication/pmid": "35663640",
  "publication/pmcid": "PMC9128757",
  "publication/doi": "10.1109/jiot.2021.3056185",
  "publication/tags": "- AI\n- COVID-19\n- CT\n- Federated learning\n- Image processing\n- Machine learning\n- X-Ray\n- Privacy-preserving\n- Medical diagnostic image analysis\n- Dynamic fusion",
  "dataset/provenance": "The dataset used in this study consists of medical diagnostic images, specifically CT scans and X-ray images, for COVID-19 detection. The dataset includes a total of 746 CT images and 2960 X-ray images. Among the CT images, there are 349 images of COVID-19 positive diagnoses and 397 images of negative diagnoses. The X-ray images are sourced from two datasets. The first X-ray dataset contains 2905 images, with 219 images of COVID-19 positive diagnoses, 1341 images of negative diagnoses, and 1345 images of viral pneumonia diagnoses. The second X-ray dataset consists of 55 images of positive diagnoses.\n\nThe dataset was used to evaluate the proposed dynamic fusion-based federated learning approach for COVID-19 detection. The experiments involved selecting 3326 images from the collected datasets and dividing them into 2800 images for the training set and 526 images for the test set. The training set was further divided among three clients with different configurations: 600 images, 900 images, and 1300 images, respectively. The test set included 71 CT images and 455 X-ray images, with varying diagnoses of COVID-19 positive, negative, and viral pneumonia.\n\nThis dataset has been summarized and categorized for use by the machine learning community for image analysis in COVID-19 detection. The evaluation results demonstrate the feasibility and superior performance of the proposed approach compared to the default setting of federated learning in terms of model performance, communication efficiency, and fault tolerance.",
  "dataset/splits": "The dataset used in our study consists of medical diagnostic images for COVID-19 detection, specifically CT and X-ray images. We utilized a total of 3606 images, which were divided into two main categories: 746 CT images and 2960 X-ray images.\n\nThe CT dataset includes 349 images of COVID-19 positive diagnoses and 397 images of negative diagnoses. The X-ray dataset is further divided into two subsets. The first subset contains 2905 images, with 219 images of COVID-19 positive diagnoses, 1341 images of negative diagnoses, and 1345 images of viral pneumonia diagnoses. The second X-ray subset consists of 55 images of positive diagnoses.\n\nFor the experiments, we selected 3326 images from the collected datasets and divided them into a training set and a test set. The training set comprises 2800 images, while the test set includes 526 images. The training data was further distributed among three clients, with each client receiving a different number of images: 600 images for the first client, 900 images for the second client, and 1300 images for the third client. The distribution of CT and X-ray images was adjusted to maintain the same total amount for each client, considering the differences between the two types of images.\n\nIn the test set, there are 71 CT images, including 31 COVID-19 positive diagnoses and 40 negative diagnoses. The remaining 455 images are X-ray images, consisting of 55 COVID-19 positive diagnoses, 200 negative diagnoses, and 200 viral pneumonia diagnoses. It is important to note that the CT images were taken from the top, while the X-ray images were taken from the front.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our work is not a standalone machine-learning algorithm but rather a dynamic fusion method designed to enhance the efficiency and performance of federated learning, particularly in the context of medical diagnostic image analysis for COVID-19 detection.\n\nThis dynamic fusion method is not entirely new; it builds upon the existing federated learning paradigm but introduces novel mechanisms to improve communication efficiency and model performance. The core idea is to dynamically decide which clients participate in each round of model aggregation based on their local model performance and training time. This approach helps in reducing the communication overhead and ensures that only the most relevant and high-performing local models contribute to the global model.\n\nThe reason this work was published in the IEEE Internet of Things Journal rather than a machine-learning-specific journal is due to the interdisciplinary nature of the research. The focus is on applying machine learning techniques to address real-world problems in healthcare, specifically leveraging the Internet of Things (IoT) for medical diagnostic image analysis. The journal provides a suitable platform for discussing the integration of machine learning with IoT technologies, highlighting the practical applications and benefits of the proposed method in a healthcare setting.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithm. We utilized a diverse set of medical diagnostic images, including CT scans and X-ray images, for COVID-19 detection. The dataset comprised 746 CT images and 2960 X-ray images, with specific distributions of COVID-19 positive, negative, and viral pneumonia diagnoses.\n\nFor the CT images, we had 349 positive diagnoses and 397 negative diagnoses. The X-ray images were divided into two datasets: the first containing 2905 images with 219 positive diagnoses, 1341 negative diagnoses, and 1345 viral pneumonia diagnoses, and the second consisting of 55 positive diagnosis images.\n\nThe images were preprocessed to standardize their format and enhance their quality. This involved resizing the images to a uniform dimension, normalizing pixel values, and applying techniques such as random cropping to augment the dataset and improve the model's robustness. The preprocessing steps ensured that the images were consistent and suitable for training deep learning models.\n\nWe conducted experiments using three different models: GhostNet, ResNet50, and ResNet101. The dataset was split into training and test sets, with 2800 images used for training and 526 images for testing. The training set was further divided among three clients, each receiving a different number of images: 600, 900, and 1300 images, respectively. The ratio of CT to X-ray images was adjusted to maintain diversity while keeping the total number of images consistent for each client.\n\nThe test set included 71 CT images and 455 X-ray images, with specific distributions of COVID-19 positive, negative, and viral pneumonia diagnoses. This careful encoding and preprocessing of the data ensured that our machine-learning models could effectively learn from the diverse and high-quality dataset, leading to improved accuracy and robustness in COVID-19 detection.",
  "optimization/parameters": "In our study, we utilized three different models: GhostNet, ResNet50, and ResNet101. Each of these models has a distinct number of parameters, which significantly influences their performance and training time.\n\nGhostNet is designed to be a lightweight model with fewer parameters, making it efficient in terms of computational resources and training time. However, this comes at the cost of potentially lower accuracy compared to more complex models.\n\nResNet50 and ResNet101, on the other hand, are deeper networks with a larger number of parameters. ResNet50 has 50 layers, while ResNet101 has 101 layers. The increased depth and number of parameters in these models allow them to capture more complex patterns in the data, generally leading to higher accuracy. However, this also results in longer training times and higher computational demands.\n\nThe selection of these models was based on their established performance in image classification tasks and their varying complexities. This allowed us to evaluate the effectiveness of our dynamic fusion-based federated learning approach across different model architectures.\n\nIn our experiments, we observed that the dynamic fusion approach significantly reduced the training time for ResNet50 and ResNet101, making them more efficient without compromising accuracy. For GhostNet, the reduction in training time was less pronounced due to its already efficient parameter structure. However, the approach still improved communication efficiency by reducing the number of model uploads.\n\nOverall, the choice of models with different parameter counts provided a comprehensive evaluation of our method's robustness and adaptability across various scenarios.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "Not applicable",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "Not applicable.",
  "model/output": "The model in question is designed for classification tasks, specifically for detecting COVID-19 infections from medical diagnostic images such as CT scans and X-rays. The primary goal is to classify these images into categories indicating the presence or absence of COVID-19, as well as other related conditions like viral pneumonia. The evaluation of the model's performance is focused on accuracy, demonstrating its effectiveness in distinguishing between different diagnostic outcomes.\n\nThe dynamic fusion-based federated learning approach improves communication efficiency and model performance by dynamically deciding which clients participate in the model training process based on their local model performance and training time. This method ensures that only the most relevant and high-performing local models contribute to the global model, enhancing its overall accuracy and robustness.\n\nThe experiments conducted involved training the model with various datasets and comparing the results with the default setting of federated learning. The results showed that the dynamic fusion-based approach achieved higher accuracy in most cases, indicating its superiority in handling data heterogeneity and ensuring fault tolerance. The model's performance was also evaluated using test sets processed by random cropping, further validating its reliability and effectiveness in real-world scenarios.",
  "model/duration": "The execution time of the models varied depending on the network architecture used. For GhostNet, the training time did not significantly change when using the proposed dynamic fusion-based federated learning approach. However, for ResNet50 and ResNet101, there was a notable reduction in training time. Specifically, the training time for ResNet50 was reduced by approximately 8 to 10 minutes, while ResNet101 saw a decrease of 25 to 30 minutes. This improvement in training time is attributed to the reduction in model transmission time, which is more pronounced in models with a larger number of parameters, such as ResNet50 and ResNet101. The GhostNet, having fewer parameters, did not benefit as much from the dynamic fusion approach in terms of training time reduction.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed dynamic fusion-based federated learning approach involved a series of quantitative experiments using medical diagnostic image datasets specifically for COVID-19 detection. These datasets included 746 CT images and 2960 X-ray images, with a detailed breakdown of positive and negative diagnoses for both COVID-19 and other conditions like viral pneumonia.\n\nThe experiments were conducted using three different models: GhostNet, ResNet50, and ResNet101. The datasets were divided into training and test sets, with the training set consisting of 2800 images and the test set consisting of 526 images. The data was distributed among three clients with varying dataset sizes: 600 images, 900 images, and 1300 images, respectively. The ratio of CT to X-ray images was adjusted to maintain the same total amount for each client.\n\nThe evaluation focused on accuracy, comparing the dynamic fusion-based federated learning (DF_FL) with the default setting of federated learning (D_FL). The results showed that DF_FL achieved higher accuracy in 14 out of 18 groups of experiments, with only four groups showing slightly lower accuracy. Additionally, the robustness of the approach was tested by introducing interference in one group of the dataset, where negative diagnosis images were marked as positive COVID-19. The model trained using DF_FL maintained relatively steady and higher accuracy compared to the default setting, demonstrating fault tolerance and robustness.\n\nThe accuracy of each model was also measured using a test set processed by random cropping, further validating the effectiveness of the proposed approach. The experiments were conducted using the GFL federated learning framework, and the results were presented in figures for each type of model. Overall, the evaluation results indicated that the dynamic fusion-based federated learning approach performed better than the default setting in terms of model performance, communication efficiency, and fault tolerance.",
  "evaluation/measure": "In our evaluation of the dynamic fusion-based federated learning approach for COVID-19 detection, we focused on several key performance metrics to ensure a comprehensive assessment. The primary metrics reported include accuracy, training time, and communication efficiency.\n\nAccuracy is a crucial metric in evaluating the performance of machine learning models, particularly in medical diagnostics where precise detection is vital. We compared the accuracy of our dynamic fusion-based federated learning (DF_FL) approach against the default setting of federated learning (D_FL) across 18 groups of experiments. The results demonstrated that DF_FL achieved higher accuracy in 14 out of the 18 groups, with only minor reductions in accuracy in the remaining four groups. This indicates that our approach is effective in improving model performance.\n\nTraining time is another important metric, especially in federated learning where multiple clients are involved. We recorded the training time for different models, including GhostNet, ResNet50, and ResNet101. The results showed that while DF_FL did not reduce the training time for GhostNet, it significantly reduced the training time for ResNet50 and ResNet101. This suggests that our approach is particularly beneficial for models with larger parameter sizes, improving communication efficiency and reducing training time.\n\nCommunication efficiency is a critical aspect of federated learning, as it involves the transfer of model updates between clients and the central server. We measured the upload number and upload time for model updates. The results indicated that DF_FL reduced the upload number and time for all models, with more significant reductions observed for ResNet50 and ResNet101. This demonstrates that our approach can effectively reduce communication overhead, making it more efficient for real-world applications.\n\nIn summary, the performance metrics reported in our evaluation\u2014accuracy, training time, and communication efficiency\u2014provide a representative assessment of the dynamic fusion-based federated learning approach. These metrics are in line with the literature on federated learning and highlight the strengths of our approach in improving model performance and efficiency.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of our proposed dynamic fusion-based federated learning (DF_FL) approach with the default setting of federated learning (D_FL). This comparison was performed across multiple datasets and models to ensure a thorough assessment.\n\nWe utilized a category of medical diagnostic image datasets specifically for COVID-19 detection, which included 746 CT images and 2960 X-ray images. These datasets were divided into training and test sets, with the training set consisting of 2800 images and the test set consisting of 526 images. The datasets were further configured for three clients, each with different data set sizes: 600 images, 900 images, and 1300 images, respectively. The ratio of CT and X-ray images was adjusted to maintain the same total amount for each client.\n\nOur experiments involved three different models: GhostNet, ResNet50, and ResNet101. We conducted 18 groups of experiments in total, comparing the accuracy of DF_FL with D_FL. The results showed that DF_FL achieved higher accuracy in 14 out of the 18 groups, demonstrating its superior performance. Even in the groups where DF_FL had lower accuracy, the differences were minimal, indicating the robustness of our approach.\n\nIn addition to accuracy, we also evaluated the training time and communication efficiency. The training time for ResNet50 and ResNet101 was significantly reduced using DF_FL, while GhostNet showed no change due to its fewer parameters. The communication efficiency was improved across all models, with DF_FL reducing the upload number and time, especially for models with more parameters like ResNet50 and ResNet101.\n\nOverall, our evaluation demonstrated that the proposed dynamic fusion-based federated learning approach outperforms the default setting of federated learning in terms of model accuracy, fault tolerance, robustness, and communication efficiency. This makes it a feasible and effective solution for COVID-19 detection while preserving data privacy.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not applicable"
}