{
  "publication/title": "Social Determinants of Association among Diabetes Mellitus, Visual Impairment and Hearing Loss in a Middle-Aged or Old Population: Artificial-Neural-Network Analysis of the Korean Longitudinal Study of Aging (2014\u207b2016).",
  "publication/authors": "Lee KS, Park KW",
  "publication/journal": "Geriatrics (Basel, Switzerland)",
  "publication/year": "2019",
  "publication/pmid": "30934564",
  "publication/pmcid": "PMC6473411",
  "publication/doi": "10.3390/geriatrics4010030",
  "publication/tags": "- Social determinants of health\n- Chronic diseases\n- Artificial neural networks\n- Longitudinal studies\n- Diabetes mellitus\n- Visual impairment\n- Hearing loss\n- Socioeconomic factors\n- Family support\n- Health-related determinants\n- Predictive modeling\n- Disease association\n- Middle-aged population\n- Old population\n- Health behaviors\n- Structural determinants of health\n- Socioeconomic capital\n- Policy\n- Status and value systems\n- Health prediction",
  "dataset/provenance": "The dataset used in this study is derived from the Korean Longitudinal Study of Aging (KLoSA). This biennial survey employs a multistage stratified sampling method based on geographical areas and housing types across the nation. The survey covers a wide range of demographic, socioeconomic, and health-related topics, utilizing computer-assisted personal interviewing.\n\nThe specific waves of the KLoSA used in this study are the 5th wave (Y2014) and the 6th wave (Y2016). The initial sample sizes for these waves were 8,387 and 7,893 subjects aged 45 or more, respectively. However, subjects lacking demographic, socioeconomic, or health-related information were excluded, resulting in a final analytic sample of 6,120 subjects aged 53 or more. Notably, 75% of these subjects were older than 60.\n\nThe dataset includes information on various demographic factors such as gender, age, marital status, number of children alive, number of siblings cohabiting, and parental status. Socioeconomic status variables include educational level, personal income, health insurance, and economic activity. Social activity metrics cover the monthly frequencies of meeting with friends, religious activity, friendship activity, leisure activity, family activity, voluntary activity, and political activity. Health-related factors include subjective health, BMI, smoking status, drinking status, and drug/medication intake. Additional determinants include religion, residential type, region, and life satisfaction for economic status and overall life.\n\nThe dataset has been used to trace the characteristics of Koreans aged 45 years or more over time, aiding in the development of socioeconomic policies for these rapidly growing populations. The study focuses on the association among diabetes mellitus, visual impairment, and hearing loss, using the disease\u2013disease association in Y2016 as the dependent variable and the demographic, socioeconomic, and health-related factors in Y2014 as independent variables.",
  "dataset/splits": "The dataset was divided into two splits: a training set and a validation set. Each split contained 3060 observations, resulting in a total of 6120 participants. The data was split in a 50:50 ratio, ensuring an equal distribution of data points between the training and validation sets. This approach was used to build and validate the models, with the training set used for model development and the validation set used to assess the models' performance.",
  "dataset/redundancy": "The dataset used in this study consisted of data from 6120 participants. To ensure the reliability and generalizability of the models, the data was divided into training and validation sets with a 50:50 ratio. This means that 3060 observations were used for training the models, and the remaining 3060 observations were used for validating the models. This split ensures that the training and test sets are independent, which is crucial for evaluating the performance of the models.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in terms of size and diversity. The dataset includes a wide range of demographic, socioeconomic, and health-related factors, which are essential for predicting the association among diabetes mellitus, visual impairment, and hearing loss. The participants' data spans various attributes, such as age, income, family structure, and social activities, providing a comprehensive view of the factors that might influence the diseases in question.\n\nTo enforce the independence of the training and validation sets, the data was randomly split. This random split helps to ensure that the models are not overfitted to a specific subset of the data and can generalize well to new, unseen data. The accuracy of the models was introduced as a criterion for validating the models trained, which further ensures that the models are reliable and robust.\n\nThe dataset's redundancy was managed by ensuring that the training and validation sets were independent and that the models were evaluated on a separate set of data. This approach helps to mitigate the risk of overfitting and ensures that the models can generalize well to new data. The use of a 50:50 split also ensures that the models are trained and validated on a sufficiently large and diverse set of observations, which is essential for reliable and robust predictions.",
  "dataset/availability": "The data used in this study is not publicly available. The study utilized longitudinal data from the Korean Longitudinal Study of Aging (KLoSA), which is a biennial survey involving a multistage stratified sampling based on geographical areas and housing types across the nation. The specific dataset used in this research consisted of 6120 subjects aged 53 or more, derived from the 1st, 5th, and 6th waves of the KLoSA for the years 2006, 2014, and 2016, respectively.\n\nThe KLoSA data is not released in a public forum for unrestricted access. Access to the KLoSA data is typically managed through specific procedures and may require approval from the relevant authorities or institutions that oversee the dataset. The data includes a wide range of demographic, socioeconomic, and health-related topics, and its use is governed by the terms and conditions set by the data providers.\n\nThe study did not involve creating or releasing new data splits publicly. The data was divided into training and validation sets with a 50:50 ratio for the purposes of model training and validation. The models were built based on the training set with 3060 observations, and then validated using the validation set with another 3060 observations. The accuracy of the models was evaluated based on the validation set.\n\nThe enforcement of data access and usage is managed by the institutions responsible for the KLoSA dataset. Researchers interested in using the KLoSA data would need to adhere to the guidelines and protocols established by these institutions, which may include obtaining necessary permissions and agreeing to the terms of use.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is an Artificial Neural Network (ANN). This specific ANN architecture includes one input layer, two hidden layers, and one output layer. The input layer consists of 91,800 neurons, which are derived from the multiplication of the number of attributes and observations in the training set. Each hidden layer contains 15 neurons, and the output layer has 8 neurons.\n\nThe ANN employed in this research is not a novel algorithm. It utilizes well-established techniques such as the feedforward algorithm for combining neurons and weights, and the backpropagation algorithm for adjusting weights based on the loss function. These methods are standard in the field of neural networks and have been extensively studied and applied in various domains.\n\nThe decision to use an ANN in this context was driven by its ability to handle complex relationships and interactions within the data. The ANN was compared with other popular machine learning methods, including logistic regression, decision trees, na\u00efve Bayes, random forests, and support vector machines, to ensure its reliability. The results indicated that the ANN performed similarly to the best-performing models, such as logistic regression and random forests, in terms of accuracy.\n\nThe focus of this study is on the application of machine learning techniques to understand the association among diabetes mellitus, visual impairment, and hearing loss in a middle-aged or older population. The ANN was chosen for its capacity to model intricate patterns and provide insights into variable importance, which was crucial for testing the hypotheses related to social determinants and disease associations. The study does not introduce a new machine-learning algorithm but rather demonstrates the effectiveness of existing methods in a specific healthcare context.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it employs a standalone artificial neural network (ANN) for predictions. The ANN architecture includes one input layer, two hidden layers, and one output layer. The input layer consists of 91,800 neurons, derived from the multiplication of the number of attributes and observations in the training set. Each hidden layer contains 15 neurons, and the output layer has 8 neurons.\n\nThe ANN was trained and validated using a dataset divided into training and validation sets with a 50:50 ratio. The training set contained 3060 observations, and the validation set also contained 3060 observations. The model's accuracy was evaluated based on the ratio of correct predictions among the 3060 observations in the validation set.\n\nSeveral other machine learning methods were compared for reliability, including logistic regression, decision tree, na\u00efve Bayes, random forest, and support vector machine. However, these methods were used independently and not as part of a meta-predictor ensemble. The ANN's performance was found to be reliable, with an accuracy similar to that of logistic regression and the random forest.\n\nThe study focused on predicting the association among diabetes mellitus, visual impairment, and hearing loss using various demographic, socioeconomic, and health-related factors. The variable importance from the ANN identified key determinants such as the number of brothers/sisters cohabiting, voluntary activity, and income as significant factors influencing the association among the diseases.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, the dataset consisted of 6120 participants, with data from 2014 serving as independent variables and data from 2016 as the dependent variable. The dataset was split into training and validation sets with a 50:50 ratio, resulting in 3060 observations for training and 3060 for validation.\n\nThe artificial neural network (ANN) used in this study included one input layer, two hidden layers, and one output layer. The input layer had 91,800 neurons, derived from the multiplication of 30 attributes and 3060 observations in the training set. Each hidden layer contained 15 neurons, and the output layer had 8 neurons, corresponding to the eight categories in the dependent variable.\n\nThe preprocessing involved setting initial weights as small random numbers around 0. The feedforward algorithm was used to combine neurons from the input or previous hidden layer with the weights in the next hidden or output layer. The backpropagation algorithm adjusted these weights based on their contribution to the loss, which is the difference between the actual and predicted class labels. This iterative process continued until specific criteria for accurate prediction were met.\n\nThe ANN's architecture and preprocessing steps ensured that the model could effectively learn from the data and make reliable predictions. The accuracy of the ANN was validated against other machine-learning methods, confirming its reliability.",
  "optimization/parameters": "The Artificial Neural Network (ANN) model utilized in this study comprises an input layer with 91,800 neurons. This number is derived from the multiplication of 30 attributes and 3060 observations in the training set. The input layer is followed by two hidden layers, each containing 15 neurons, and an output layer with 8 neurons. The selection of the number of neurons in the input layer is directly tied to the dimensionality of the data, ensuring that all relevant features are considered. The hidden layers' neuron count was chosen based on empirical performance, aiming to balance model complexity and generalization. The output layer's neurons correspond to the eight categories of the dependent variable, representing different combinations of the diseases under study. This structure allows the ANN to effectively capture the intricate relationships among the input variables and the disease associations.",
  "optimization/features": "The study utilized a total of 30 attributes as input features for the artificial neural network (ANN) model. These features encompassed demographic, socioeconomic, and health-related factors from the year 2014, along with the presence of diabetes mellitus, visual impairment, and hearing loss.\n\nFeature selection was implicitly performed through the analysis of variable importance. This process involved evaluating the impact of excluding each variable on the model's accuracy. The importance of each variable was determined by the decrease in accuracy when that variable was excluded from the model. This approach ensured that the most relevant features were identified and retained for the final model.\n\nThe feature selection process was conducted using only the training set, which consisted of 3060 observations. This method helped to prevent data leakage and ensured that the model's performance on the validation set was a true reflection of its generalizability. The training set was used to build the models, and the validation set, also consisting of 3060 observations, was used to validate the models' accuracy.",
  "optimization/fitting": "The artificial neural network (ANN) used in this study includes one input layer, two hidden layers, and one output layer. The input layer consists of 91,800 neurons, derived from the multiplication of 30 attributes and 3060 observations in the training set. Each hidden layer contains 15 neurons, and the output layer has 8 neurons. The weights in the network are initially set as small random numbers around 0 and are adjusted through the feedforward and backpropagation algorithms until certain criteria for accurate prediction are met.\n\nTo address the potential issue of overfitting, given the large number of parameters relative to the number of training points, several measures were taken. Firstly, the data was divided into training and validation sets with a 50:50 ratio, ensuring that the model's performance could be evaluated on unseen data. Secondly, the accuracy of the ANN was compared with other machine learning methods, such as logistic regression and random forest, which showed similar performance. This comparison helps to validate that the ANN is not merely memorizing the training data but is generalizing well to new data. Additionally, the variable importance was derived by assessing the accuracy decrease when specific variables were excluded, providing insight into the model's reliance on different features.\n\nUnderfitting was addressed by ensuring that the ANN had sufficient complexity to capture the underlying patterns in the data. The use of two hidden layers and the adjustment of weights through backpropagation allowed the model to learn complex relationships. The similar accuracy levels achieved by the ANN and other models, such as the random forest and support vector machine, further indicate that the model is not too simplistic and can effectively capture the necessary patterns in the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was the artificial neural network (ANN) architecture itself, which included regularization through dropout layers. Dropout is a technique where during training, a random subset of neurons is temporarily removed from the network, which helps to prevent the model from becoming too reliant on any single neuron and thus reduces overfitting.\n\nAdditionally, we utilized cross-validation to evaluate the performance of our models. Specifically, we divided our dataset into training and validation sets with a 50:50 ratio. This approach allowed us to train our models on one subset of the data and validate them on another, ensuring that the models generalized well to unseen data.\n\nFurthermore, we compared the performance of our ANN with other popular machine learning methods, including logistic regression, decision trees, na\u00efve Bayes, random forests, and support vector machines. This comparative analysis helped us to identify the most reliable model and to ensure that our ANN was not overfitting to the training data.\n\nThe ANN architecture included one input layer, two hidden layers, and one output layer. The input layer had 91,800 neurons, which were derived from the multiplication of the number of attributes and observations in the training set. The hidden layers each had 15 neurons, and the output layer had 8 neurons. This architecture was designed to balance complexity and generalization, further aiding in the prevention of overfitting.\n\nOverall, these techniques collectively contributed to the robustness and generalizability of our models, ensuring that they performed well on both training and validation datasets.",
  "optimization/config": "The configuration details of the artificial neural network (ANN) used in this study are explicitly described. The ANN architecture includes one input layer, two hidden layers, and one output layer. The input layer consists of 91,800 neurons, derived from the multiplication of 30 attributes and 3060 observations in the training set. Each hidden layer contains 15 neurons, and the output layer has 8 neurons. The weights in the network are initially set as small random numbers around 0 and are adjusted using the feedforward and backpropagation algorithms until certain criteria for accurate prediction are met.\n\nThe optimization process involves dividing the data into training and validation sets with a 50:50 ratio. The models were trained on the training set and validated on the validation set, with accuracy serving as the primary criterion for validation. Variable importance was determined by the accuracy gap between the complete model and models excluding specific variables.\n\nThe study utilized Python 3.52 for the analysis, conducted in December 2018. The data used were from the Korean Longitudinal Study of Aging (KLoSA) for the years 2014 and 2016, which are publicly available and de-identified. The models and their configurations are not explicitly provided in a downloadable format, but the methods and parameters used are thoroughly documented in the publication. The study adheres to ethical guidelines and uses nationally representative longitudinal data, ensuring the reliability and reproducibility of the findings.",
  "model/interpretability": "The model employed in this study is an Artificial Neural Network (ANN), which is often considered a black-box model due to its complex, multilayered structure and the non-linear relationships it can capture. This complexity makes it challenging to interpret the exact decision-making process of the ANN. However, efforts were made to enhance interpretability through variable importance analysis.\n\nVariable importance in the ANN was determined by assessing the decrease in model accuracy when specific variables were excluded. This approach provides insights into which variables significantly contribute to the model's predictions. For instance, variables such as the number of brothers/sisters cohabiting, voluntary activity, and income were identified as top determinants of the association among diabetes mellitus, visual impairment, and hearing loss. This method helps in understanding the relative importance of different factors in the model's decision-making process.\n\nAdditionally, the study compared the ANN's variable importance with that of a Random Forest model. Both models highlighted the significance of family support, social activity, and socioeconomic status in disease control. This comparison further aids in interpreting the model's behavior and validating the importance of certain variables.\n\nWhile the ANN itself remains a black-box model, the use of variable importance analysis and comparison with other models provides a level of transparency. This allows for a better understanding of the key factors influencing the model's predictions, even if the exact internal workings of the ANN are not fully interpretable.",
  "model/output": "The model employed in this study is a classification model. It is designed to predict the association among three diseases\u2014diabetes mellitus, visual impairment, and hearing loss\u2014across different categories. The artificial neural network (ANN) used in this study includes one input layer, two hidden layers, and one output layer. The input layer consists of 91,800 neurons, derived from the multiplication of the number of attributes and observations in the training set. The hidden layers each contain 15 neurons, and the output layer has 8 neurons, corresponding to the eight categories in the dependent variable.\n\nThe ANN operates using a feedforward algorithm, where neurons in the input or previous hidden layer are combined with weights in the next hidden or output layer. The weights are initially set as small random numbers around zero and are adjusted through a backpropagation algorithm based on the loss, which is the difference between the actual and predicted class labels. This process iterates until certain criteria for accurate prediction are met.\n\nThe model's performance was evaluated using accuracy as the primary criterion. Accuracy is defined as the ratio of correct predictions among the observations in the validation set. The ANN achieved an accuracy of 0.7507, which is comparable to the accuracies of logistic regression (0.7507) and the random forest (0.7533). This suggests that the ANN is a reliable model for predicting the association among the diseases.\n\nVariable importance was also assessed by measuring the accuracy gap between the full model and models excluding specific variables. For instance, excluding variables such as the number of brothers/sisters cohabiting, voluntary activity, and income resulted in noticeable decreases in accuracy, indicating their significance as determinants of the association.\n\nThe study also compared the ANN with other machine learning methods, including logistic regression, decision trees, na\u00efve Bayes, random forests, and support vector machines. The ANN's performance was found to be on par with the best-performing models, further validating its reliability. The area under the receiver-operating-characteristic (ROC) curve (AUC) averaged over the eight categories was 0.77, indicating the model's power and usefulness.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved comparing six popular machine learning techniques to predict the association among diabetes mellitus, visual impairment, and hearing loss. These methods included Artificial Neural Networks (ANN), logistic regression, decision trees, naive Bayes, random forests, and support vector machines. The data from 6120 participants was split into training and validation sets with a 50:50 ratio, ensuring that the models were trained on 3060 observations and validated on another 3060 observations.\n\nAccuracy was the primary criterion used to validate the models. It was defined as the ratio of correct predictions among the 3060 observations in the validation set. Additionally, variable importance from the ANN was assessed by measuring the accuracy gap between a complete model and a model excluding a certain variable. This approach helped in testing two hypotheses: whether family support, social activity, and socioeconomic status in 2014 were among the top-10 determinants of the association in 2016, and whether diabetes mellitus, visual impairment, and hearing loss in 2014 were among the top-5 determinants of the association in 2016.\n\nThe ANN model demonstrated reliability with an accuracy of 0.7507, which was comparable to that of logistic regression (0.7507) and the random forest (0.7533). The variable importance analysis from the ANN indicated that factors such as the number of brothers/sisters cohabiting, voluntary activity, and income in 2014 were the top-3 determinants of the association in 2016. Other significant determinants included family activity, parents alive, leisure activity, and meeting with friends.\n\nThe results highlighted the importance of promoting family support, social activity, and socioeconomic status in disease control. Both the ANN and random forest results emphasized that diabetes mellitus, visual impairment, and hearing loss in 2014 were not among the top-10 determinants of the association in 2016, suggesting that the association among these three diseases might not be as strong as initially expected.",
  "evaluation/measure": "In the evaluation of our models, several performance metrics were reported to provide a comprehensive assessment of their effectiveness. The primary metric used was accuracy, which is the ratio of correct predictions to the total number of observations. This metric was employed to validate the models trained on the dataset, ensuring that they could accurately predict the association among diabetes mellitus, visual impairment, and hearing loss in a middle-aged or old population.\n\nIn addition to accuracy, variable importance was also considered. For the Artificial Neural Network (ANN), variable importance was derived by measuring the accuracy gap between a complete model and a model excluding a certain variable. This approach helped in identifying the top determinants of the association in the subsequent year. Similarly, for the Random Forest model, variable importance was assessed by the mean impurity gap, which indicates the degree of data being mixed at a node on average.\n\nThe Area Under the Receiver Operating Characteristic Curve (AUC) was another crucial metric reported. The AUC measures the power or usefulness of the model by plotting the true positive rate (sensitivity) against the false positive rate (1-specificity). The ANN demonstrated a strong performance with an AUC averaged over the eight categories being 0.77, suggesting its reliability and effectiveness in predicting the disease associations.\n\nThese metrics collectively provide a robust evaluation framework, aligning with common practices in the literature. Accuracy ensures that the models make correct predictions, variable importance helps in understanding the significance of different factors, and the AUC offers insights into the model's discriminative power. Together, these metrics offer a representative and thorough assessment of the models' performance.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of our artificial neural network (ANN) model with several popular machine learning methods to assess its reliability. The methods included in this comparison were logistic regression, decision tree, na\u00efve Bayes, random forest, and support vector machine. Each of these methods has distinct characteristics: decision trees use a series of attribute tests to make predictions, na\u00efve Bayes applies Bayes\u2019 theorem, random forests aggregate multiple decision trees, and support vector machines maximize the margin between hyperplanes separating the data.\n\nThe comparison was performed using a dataset of 6120 participants, divided into training and validation sets with a 50:50 ratio. The models were trained on the training set and validated on the validation set. Accuracy, defined as the ratio of correct predictions among the observations, was used as the primary criterion for validating the models.\n\nOur results indicated that the ANN model demonstrated comparable accuracy to logistic regression and the random forest, both of which achieved an accuracy of approximately 0.75. This suggests that the ANN is a reliable model for predicting the association among the diseases and categories studied. Additionally, we analyzed variable importance using the ANN, which helped in evaluating specific hypotheses related to the determinants of the association.\n\nThe comparison to simpler baselines, such as decision trees and na\u00efve Bayes, further highlighted the robustness of the ANN. The decision tree model had a lower accuracy of 0.6294, while the na\u00efve Bayes model performed significantly worse with an accuracy of 0.1258. These results underscore the effectiveness of more complex models like the ANN in handling the intricacies of the data.\n\nIn summary, the comparison to both publicly available methods and simpler baselines provided a thorough evaluation of the ANN's performance. The results support the reliability and effectiveness of the ANN model in predicting the associations studied.",
  "evaluation/confidence": "The evaluation of the models in this study includes several performance metrics, primarily focusing on accuracy. The accuracy of the models is presented without explicit confidence intervals, which might limit the ability to assess the statistical significance of the results directly from the provided metrics. However, the study does compare the performance of multiple models, including Multinomial Logistic Regression, Decision Tree, Naive Bayes, Random Forest, Support Vector Machine, and Artificial Neural Networks (ANN). The ANN model, in particular, shows an accuracy of 0.7507, which is comparable to the Random Forest model at 0.7533 and the Support Vector Machine at 0.7542. This suggests that the ANN model is reliable and performs competitively with other established methods.\n\nThe variable importance from the ANN is derived by measuring the accuracy gap between the complete model and models excluding specific variables. This approach provides insights into which variables are most influential in predicting the association among diabetes mellitus, visual impairment, and hearing loss. For instance, the top-3 determinants identified by the ANN are brothers/sisters cohabiting, voluntary activity, and income. These findings are supported by the variable importance from the Random Forest, which also highlights income, meeting with friends, brothers/sisters cohabiting, and children alive as significant determinants.\n\nThe study does not explicitly state the statistical significance of the differences in accuracy between the models. However, the consistent performance of the ANN across different evaluations and its alignment with other robust models like the Random Forest and Support Vector Machine imply a certain level of confidence in its results. The area under the ROC curve (AUC) for the ANN, averaged over the 8 categories, is 0.77, indicating a powerful model. This metric further supports the reliability and effectiveness of the ANN in predicting the association among the diseases.\n\nIn summary, while explicit confidence intervals and statistical significance tests are not provided for the performance metrics, the comparative performance of the ANN with other models and the consistency of the variable importance findings across different methods suggest a reasonable level of confidence in the results. The study's focus on nationally representative longitudinal data and the use of a comprehensive set of determinants also add to the robustness of the findings.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study utilized longitudinal data from the Korean Longitudinal Study of Aging (KLoSA), which is a biennial survey involving a multistage stratified sampling based on geographical areas and housing types across the nation. This data is not freely accessible to the public. The analysis was conducted using Python 3.52, and the models were built and validated using a dataset of 6120 participants, divided into training and validation sets with a 50:50 ratio. The criteria for validating the models included accuracy and variable importance derived from the Artificial Neural Network (ANN). The study did not release the raw evaluation files or the specific datasets used for training and validation."
}