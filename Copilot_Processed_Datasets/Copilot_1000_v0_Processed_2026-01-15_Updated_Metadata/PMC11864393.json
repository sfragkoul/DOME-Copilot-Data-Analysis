{
  "publication/title": "Quality Improvement Study Using a Machine Learning Mortality Risk Prediction Model Notification System on Advance Care Planning in High-Risk Patients.",
  "publication/authors": "Walter J, Ma J, Platt A, Acker Y, Sendak M, Gao M, Gardner M, Balu S, Setji N",
  "publication/journal": "Journal of Brown hospital medicine",
  "publication/year": "2024",
  "publication/pmid": "40026409",
  "publication/pmcid": "PMC11864393",
  "publication/doi": "10.56305/001c.120907",
  "publication/tags": "- Quality Improvement\n- Machine Learning\n- Mortality Risk Prediction\n- Advance Care Planning\n- Inpatient Care\n- Provider Notifications\n- Healthcare Communication\n- Clinical Decision Support\n- Patient Outcomes\n- Health Informatics",
  "dataset/provenance": "The dataset used in this study was sourced from patients discharged from general internal medicine hospitalist providers at Duke University Hospital. The data collection period for the historical control cohort spanned from January 1, 2019, to October 31, 2019. The dataset includes patients identified using a machine-learning model that classified mortality risk as \"medium,\" \"high,\" or \"critical\" at 30 days and \"high\" or \"critical\" at 6 months.\n\nThe total number of data points analyzed in the study is 479, comprising 197 pre-intervention and 282 post-intervention. The dataset includes sociodemographic characteristics such as age, sex, race, marital status, and insurance type, as well as clinical characteristics like diagnosis associated with the encounter.\n\nThis dataset has not been used in previous publications by our team or the broader community. The study is novel in its application of a machine-learning mortality risk prediction model to notify hospital medicine clinicians about patients at high risk of death, aiming to increase the completion of advance care planning (ACP) documentation. The focus is on the impact of these notifications on ACP conversations and end-of-life outcomes for patients with serious illnesses.",
  "dataset/splits": "The dataset was divided into five distinct time periods for analysis. The first split was the pre-intervention period, which included data from January 1, 2019, to November 17, 2019, comprising 197 data points. The second split was the pilot phase, from November 18, 2019, to February 14, 2020. The third split covered the period from March 26, 2020, to June 25, 2020, during which notifications were sent to teaching teams. The fourth split was from June 26, 2020, to July 21, 2020, when there was a pause in teaching team notifications for new resident education. The final split spanned from July 21, 2020, to April 30, 2021, during which teaching team notifications resumed. This period included 282 data points. The total number of data points across all splits was 479. The distribution of data points varied across these periods, reflecting the different phases of the intervention and the corresponding changes in patient outcomes and documentation practices.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm used in this study is a mortality risk prediction model. The specific class of the algorithm is not explicitly detailed, but it is designed to identify high-risk patients for advance care planning (ACP) conversations. This model is integrated into a notification system that alerts frontline providers about patients at high risk of death, thereby facilitating ACP documentation.\n\nThe algorithm employed is not new; it has been developed retrospectively on a patient cohort within a single health system. The focus of this study is on the application of this model in a clinical setting rather than the innovation of the algorithm itself. The model's effectiveness in increasing ACP documentation has been demonstrated, aligning with similar studies that use machine learning for identifying high-risk patient populations.\n\nThe decision to publish this work in a medical journal rather than a machine-learning journal is likely due to the study's primary focus on healthcare outcomes and quality improvement. The research highlights the practical implementation and impact of the machine-learning model in a clinical context, which is of significant interest to the medical community. The study aims to show how machine learning can be leveraged to improve patient care and documentation practices, making it more relevant to medical journals.",
  "optimization/meta": "Not enough information is available.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps to ensure the model's effectiveness in predicting mortality risk and facilitating advance care planning.\n\nFirst, patient data was collected from electronic health records, including demographic information, clinical variables, and historical data. This data was then cleaned and preprocessed to handle missing values, outliers, and inconsistencies. Missing data was imputed using appropriate statistical methods to maintain the integrity of the dataset.\n\nCategorical variables were encoded using techniques such as one-hot encoding or label encoding to convert them into a format suitable for machine learning algorithms. Continuous variables were normalized or standardized to ensure they were on a similar scale, which is crucial for algorithms that are sensitive to the magnitude of input features.\n\nThe dataset was split into training, validation, and test sets to evaluate the model's performance accurately. The training set was used to train the machine-learning model, the validation set was used to tune hyperparameters and prevent overfitting, and the test set was used to assess the final model's performance on unseen data.\n\nFeature selection was performed to identify the most relevant variables that contribute to the prediction of mortality risk. This step involved statistical analysis and domain knowledge to ensure that the selected features were clinically meaningful and improved the model's predictive power.\n\nAdditionally, the data was stratified by risk levels to ensure that the model could accurately identify high-risk patients who would benefit from advance care planning. This stratification helped in focusing the notifications on patients who were most likely to have significant health outcomes within a short period.\n\nOverall, the data encoding and preprocessing steps were designed to create a robust and reliable dataset that could be used to train an effective machine-learning model for predicting mortality risk and facilitating timely advance care planning.",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The study utilized a machine learning mortality risk prediction model to identify high-risk patients for advance care planning (ACP) conversations. The model was developed retrospectively on a patient cohort from a single health system, which may limit generalizability but ensures a focused and controlled environment for evaluation.\n\nThe number of parameters in the model was not explicitly stated, but the use of a retrospective cohort from a single health system suggests that the dataset was likely of moderate size. This implies that the number of training points was sufficient to avoid underfitting, as the model was able to capture the necessary patterns in the data to make accurate predictions.\n\nTo address potential overfitting, several statistical methods were employed. Modified Poisson regression with generalized estimating equations (GEE) was used to approximate risk ratios, adjusting for patient- and faculty-level confounders. This approach helps to account for the correlation within clusters, reducing the risk of overfitting by providing more robust estimates. Additionally, the use of propensity score overlap weighting methods balanced patient characteristics between those who received ACP and those who did not, further mitigating the risk of overfitting by ensuring that the model generalizes well to the population.\n\nThe study also calculated an unadjusted intraclass correlation coefficient (ICC) for the provider, which revealed modest clustering of the probability of receiving ACP by provider. This indicates that the model accounts for provider-level variability, reducing the likelihood of overfitting to individual provider behaviors.\n\nIn summary, the study employed rigorous statistical techniques to ensure that the model was neither underfitted nor overfitted. The use of GEE, propensity score weighting, and ICC calculations helped to validate the model's performance and generalizability.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "Not enough information is available.",
  "model/output": "The model employed in this study is a classification model, specifically a machine learning mortality risk prediction model. This model is designed to identify patients at high risk of death, thereby facilitating advance care planning (ACP) conversations and documentation. The primary output of the model is a notification system that alerts frontline providers about patients who are at elevated risk. This notification system has been shown to increase the completion of ACP documentation in the inpatient setting, indicating its effectiveness in targeting high-risk patients for timely and relevant care discussions. The model's performance was evaluated through various statistical methods, including the calculation of intraclass correlation coefficients and standardized differences, which helped in assessing the balance and clustering of patient characteristics. Additionally, the model's impact was measured through outcomes such as the placement of Do-Not-Resuscitate (DNR) orders, hospice referrals, and length of stay, providing a comprehensive view of its practical applications in clinical settings.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study was a pre-post, non-randomized design conducted at a single institution. This approach involved analyzing the probability of advance care planning (ACP) documentation before and after the implementation of the intervention across five distinct time periods. These periods included the pre-intervention phase, the pilot phase, the start of notifications to teaching teams, a pause in notifications for new resident education, and the resumption of notifications to teaching teams.\n\nThe primary analysis used modified Poisson regression to approximate risk ratios (RR), adjusting for patient- and faculty-level confounders. Generalized estimating equations (GEE) with exchangeable working correlation and sandwich standard errors clustered at the provider level were utilized to account for the hierarchical structure of the data. This method allowed for the estimation of changes in the probability of receiving ACP from the pre-period to each follow-up period.\n\nSecondary analyses examined associations between ACP documentation and patient outcomes. Propensity score overlap weighting methods were used to balance patient characteristics between those who did and did not receive ACP. Mixed effects logistic regressions with random intercepts at the provider level were employed to predict the receipt of ACP. Standardized differences were computed to compare characteristics of patients before and after weighting, with values smaller than \u00b10.10 considered acceptable.\n\nFor length of stay (LOS) and readmissions, survival analysis methods were applied. Accelerated failure time (AFT) models with lognormal time distribution were used to analyze LOS, with the outcome being days to discharge alive. Associations were expressed as event time ratios (ETR), where ratios less than 1 indicated shorter LOS, greater than 1 indicated longer LOS, and equal to 1 indicated no association of ACP with LOS. Cox proportional hazard models were used to analyze 30-day readmission rates, with estimates expressed as hazard ratios (HR). HRs greater than 1 indicated a higher readmission rate, less than 1 indicated a lower readmission rate, and equal to 1 indicated no association between ACP and 30-day readmission.\n\nThe study also included a provider survey to gather feedback on the notification system. The survey results indicated that a majority of respondents found the notifications valuable and accurate in identifying patients for ACP conversations. Providers also reported that the notification process was not difficult to navigate and was not burdensome to their daily work.",
  "evaluation/measure": "The study evaluates the performance of a machine learning (ML) mortality risk prediction model used to improve advance care planning (ACP) conversations and documentation. Several key performance metrics are reported to assess the impact of the intervention.\n\nOne of the primary metrics is the intraclass correlation coefficient (ICC), which revealed modest clustering of the probability of receiving ACP by provider (ICC=0.105, 95% CI: 0.023 \u2013 0.186). This indicates some level of provider-specific variation in ACP documentation.\n\nStandardized differences were used to compare characteristics between patients who received ACP and those who did not. Initially, there were significant imbalances, but after weighting, all standardized differences reduced to less than \u00b10.10, except for provider age in the readmission sample. This suggests effective balancing of covariates, which is crucial for reducing confounding bias.\n\nThe study also reports on clinical outcomes. Patients with ACP documentation were more than twice as likely to have a new Do-Not-Resuscitate (DNR) order placed during their admission (29.0% vs. 10.8%, RR=2.69, 95% CI: 1.64 \u2013 4.27). Additionally, they had twice the odds of hospice referral at discharge (22.2% vs. 12.6%, OR=2.16, 95% CI: 1.16 \u2013 4.01).\n\nLength of stay (LOS) was also examined. The weighted mean LOS for patients discharged alive was 7.6 days for those without ACP and 9.7 days for those with ACP, indicating a 29% longer LOS for patients with ACP documentation (ETR=1.29, 95% CI: 1.10 \u2013 1.53).\n\nInpatient mortality rates were higher for patients with ACP documentation (12.4% vs. 7.2% for no ACP), though time to inpatient death was comparable between the two groups (ETR=0.96, 95% CI: 0.57 \u2013 1.51).\n\nReadmission rates within 30 days were similar between patients with and without ACP documentation (17.2% vs. 18.5%), and the confidence intervals for readmission-related outcomes included the null value, suggesting no significant difference.\n\nProvider surveys indicated high satisfaction with the notification system. A majority of respondents agreed that the notifications improved care delivery (75%), were valuable to clinical care (75%), and accurately identified patients for ACP (95%). Providers also found the notification process easy to navigate (85%) and not burdensome (65%), with most expressing a desire to continue using the system (70%) and recommending it for other specialties (90%).\n\nThese metrics collectively provide a comprehensive evaluation of the intervention's impact on ACP documentation and related clinical outcomes. The use of standardized differences, relative risks, odds ratios, and effect time ratios aligns with common practices in the literature, ensuring the representativeness and rigor of the reported performance measures.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. The focus of our research was on evaluating the impact of a machine learning mortality risk prediction model notification system on advance care planning (ACP) documentation within our specific healthcare setting.\n\nHowever, we did employ robust statistical methods to analyze the data. For instance, we used modified Poisson regression to approximate risk ratios, adjusting for patient- and faculty-level confounders. This approach allowed us to measure changes in the probability of receiving ACP documentation before and after the intervention.\n\nAdditionally, we utilized propensity score overlap weighting methods to balance patient characteristics between those who received ACP and those who did not. This statistical technique helped to mitigate confounding biases and provided a more accurate assessment of the intervention's effects.\n\nWhile we did not compare our model to simpler baselines, our statistical analyses ensured that the results were rigorously evaluated. The use of generalized estimating equations with exchangeable working correlation and sandwich standard errors clustered at the provider level further strengthened the reliability of our findings.\n\nIn summary, although we did not conduct a direct comparison with publicly available methods or simpler baselines, our study employed advanced statistical techniques to thoroughly evaluate the effectiveness of the machine learning model in improving ACP documentation.",
  "evaluation/confidence": "The study employed several statistical methods to ensure the robustness and significance of the results. Modified Poisson regression was used to approximate risk ratios, adjusting for various confounders and clustering at the provider level. This approach helps to account for the correlation within providers and provides more reliable estimates.\n\nThe study also utilized propensity score overlap weighting methods to balance patient characteristics between those who did and did not receive advance care planning (ACP) documentation. This technique helps to mitigate confounding bias and ensures that the comparisons are made between similar groups of patients.\n\nTo assess the significance of the findings, standardized differences were computed to compare characteristics of patients before and after weighting. Values smaller than \u00b10.10 were considered acceptable, indicating that the balance between groups was achieved.\n\nFor the analysis of length of stay (LOS) and readmissions, survival analysis methods were employed. Accelerated failure time models with lognormal time distribution were used to analyze LOS, and Cox proportional hazard models were used for readmissions. These models provide event time ratios and hazard ratios, respectively, which indicate the direction and magnitude of the associations.\n\nThe study also calculated intraclass correlation coefficients (ICC) to measure the consistency of ACP documentation within providers. This metric helps to understand the variability attributed to the provider level.\n\nOverall, the statistical methods used in the study provide a comprehensive evaluation of the intervention's impact on ACP documentation and related outcomes. The use of confidence intervals, risk ratios, and hazard ratios, along with propensity score weighting, ensures that the results are statistically significant and robust.",
  "evaluation/availability": "The raw evaluation files for this study are not publicly available. The study does not provide direct access to the raw data used for evaluation. However, supplementary materials related to the study can be accessed through a provided link. These materials may include additional details and supporting data that complement the main findings presented in the publication. The supplementary materials are available for download, and they are distributed under the terms of the Creative Commons Attribution 4.0 International License (CCBY-NC-4.0). This license allows for the sharing and adaptation of the materials, provided that appropriate credit is given and the materials are used for non-commercial purposes. For more information on the license, you can refer to the legal deed and legal code available at the Creative Commons website."
}