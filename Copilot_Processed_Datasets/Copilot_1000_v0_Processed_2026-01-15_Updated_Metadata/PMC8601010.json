{
  "publication/title": "A proposal for score assignment to characterize biological processes from mass spectral analysis of serum.",
  "publication/authors": "Roder J, Net L, Oliveira C, Meyer K, Asmellash S, Kasimir-Bauer S, Pass H, Weber J, Roder H, Grigorieva J",
  "publication/journal": "Clinical mass spectrometry (Del Mar, Calif.)",
  "publication/year": "2020",
  "publication/pmid": "34820522",
  "publication/pmcid": "PMC8601010",
  "publication/doi": "10.1016/j.clinms.2020.09.001",
  "publication/tags": "- Biological processes\n- Mass spectrometry\n- Proteomics\n- Cancer hallmarks\n- Inflammation\n- Interferon signaling\n- Complement activation\n- Wound healing\n- Extracellular matrix organization\n- Angiogenesis\n- Glycolysis\n- Machine learning\n- Principal component analysis\n- Set enrichment analysis\n- Protein expression\n- Serum proteome\n- Biological scoring\n- Deep MALDI\n- Quality control\n- Reproducibility\n- Clinical outcomes\n- Immune checkpoint inhibitors\n- Melanoma\n- Patient stratification\n- Data processing\n- Spectral analysis\n- Biological markers\n- Molecular phenotyping\n- Multivariate tests\n- Data acquisition\n- Quality assurance",
  "dataset/provenance": "The dataset utilized in this study originates from various clinical sample sets, each serving specific purposes in the analysis. The Score Development Set and the Score Validation Set were derived from patients who received either chemotherapy or erlotinib, with serum samples available for 208 out of 263 enrolled patients. These sets were designed to have similar patient populations.\n\nFor demonstrating the utility of the scores, several sample sets were employed:\n\n* The Melanoma Set included 118 pretreatment serum samples from patients treated with nivolumab in a phase II clinical study.\n* The Ovarian Cancer Set consisted of 102 serum samples collected at the time of surgery from patients with ovarian cancer.\n* The Early Stage Lung Cancer Set comprised serum samples from 117 patients with Stage I NSCLC, collected prior to surgery.\n\nAdditionally, the Quality Control Reference Sample, created by pooling serum from five healthy subjects, was used for quality control and batch correction. The Machine Qualification Set, consisting of 40 samples from patients with lung cancer or colorectal cancer, was used to assess between-batch reproducibility.\n\nThe data acquisition involved an aptamer-based approach to measure protein expression using the SOMAscan assay, which assessed 1305 proteins in Reference Set 1 and 1129 analytes in Reference Set 2. Mass spectrometry was performed using a MALDI-TOF mass spectrometer, with the Deep MALDI methodology to enhance detection and quantitation of MS features in serum.\n\nThe spectral processing included background estimation, normalization, alignment, and batch correction to ensure comparability between samples. A predefined set of 274 MS features with mass/charge ratios between 3 kDa and 30 kDa was used in the study. The datasets were not combined directly due to batch effects and differences in the proteins contained in the two panels. The standard method was applied to Reference Set 2, while an alternative method was used for Reference Set 1 to address these issues.",
  "dataset/splits": "In our study, we utilized multiple datasets to develop and validate our biological scores. The primary splits involved the Score Development Set and the Score Validation Set. These sets were used to ensure that the scores generated were robust and generalizable.\n\nThe Score Development Set and the Score Validation Set were used to create and assess the score distributions. The distributions were compared between these sets to check for any overfitting to the Score Development Set. Good generalization of the score distribution was found between the sets.\n\nAdditionally, we had Reference Set 1 and Reference Set 2. These sets were not combined directly due to batch effects and differences in the proteins contained in the two panels. The standard method was applied to Reference Set 2 due to its relatively small size. The alternative method, which used an alternate enrichment metric averaged over multiple splits, was applied to Reference Set 1.\n\nWe also mentioned the Early Stage Lung Cancer Set, which was used to assess the reproducibility of the scores generated from three independent spectral acquisitions. This set helped in evaluating the consistency of the scores across different runs.\n\nFurthermore, the Melanoma Set was used as the classifier development set to demonstrate the potential utility of the biological scores in stratifying patients with melanoma into groups with better and worse outcomes when treated with an immune checkpoint inhibitor.\n\nThe Quality Control Reference Sample was prepared multiple times to assess within-batch reproducibility. The Machine Qualification Set, consisting of 40 serum samples, was used to evaluate between-batch reproducibility.\n\nIn summary, our study involved several datasets and splits to ensure the robustness and generalizability of the biological scores. The Score Development Set and the Score Validation Set were the primary splits, with additional sets used for specific assessments and validations.",
  "dataset/redundancy": "The datasets used in this study were split into different sets for development and validation purposes. The Melanoma Set was used as the classifier development set, while an independent cohort of patients with advanced melanoma treated with checkpoint inhibition was used for validation. This ensures that the training and test sets are independent, reducing the risk of overfitting and providing a more robust evaluation of the model's performance.\n\nTo enforce independence between the training and test sets, we employed a hierarchical, dropout-regularized classifier architecture. This approach involves iteratively refining the training class labels and the classifier to reveal the molecular structure consistent with the endpoint of interest. Additionally, we compared the distributions of the scores between the development set and the validation set to check for any overfitting to the development set. Good generalization of the score distribution was found between the sets, indicating that the model performs well on unseen data.\n\nThe distribution of the datasets used in this study compares favorably to previously published machine learning datasets in the context of biological and clinical research. By ensuring independence between the training and test sets and validating the model on an independent cohort, we aim to provide reliable and generalizable results. This approach is crucial for the development of robust multivariate tests that can classify patients according to their molecular phenotype, ultimately aiding in personalized medicine and improved patient outcomes.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is hierarchical, dropout-regularized classifiers. This approach involves iteratively refining training class labels and the classifier to reveal the molecular structure consistent with the endpoint of interest. The algorithm is not entirely new, as it builds upon established techniques in machine learning, particularly in the context of regularization and hierarchical modeling. However, the specific application and refinement of this method for the purpose of stratifying patients with melanoma into groups with better and worse outcomes when treated with an immune checkpoint inhibitor is novel within the context of this study.\n\nThe reason this algorithm was not published in a machine-learning journal is likely due to the focus of this study. The primary objective here is to demonstrate the utility of biological scores in clinical settings, rather than to introduce a new machine-learning algorithm. The algorithm serves as a tool to achieve the study's goals, which are centered around biological and clinical outcomes. Therefore, the emphasis is on the application and validation of the scores in a clinical context, making it more appropriate for publication in a clinical or biomedical journal.",
  "optimization/meta": "The model developed for stratifying patients with melanoma into groups with better and worse outcomes when treated with an immune checkpoint inhibitor is a hierarchical, dropout-regularized classifier architecture. This approach involves iteratively refining training class labels and the classifier to reveal the molecular structure consistent with the endpoint of interest. The model uses all 17 biological scores presented in the manuscript as input features.\n\nThe classifier is designed to combine multiple attributes efficiently and robustly to generate predictive tests. While the specific machine-learning methods constituting the whole are not explicitly detailed, the use of a hierarchical architecture and dropout regularization suggests a complex model likely involving neural networks or ensemble methods. The iterative refinement process indicates a semi-supervised learning approach, which aims to improve the model's ability to capture relevant molecular structures.\n\nRegarding the independence of training data, the model was validated on an independent cohort of patients with advanced melanoma treated with checkpoint inhibition. This validation step ensures that the model's performance is generalizable and not overfitted to the development set. The use of an independent validation cohort is a crucial aspect of ensuring that the training data is independent and that the model's predictions are reliable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the mass spectral data was comparable between samples. Initially, spectral processing included background estimation and subtraction, normalization, alignment, and batch correction to reference spectra. This preprocessing was crucial for rendering the spectra comparable.\n\nA predefined set of 274 mass spectrometry (MS) features, with mass/charge (m/z) ratios between 3 kDa and 30 kDa, were used. These features were selected because they are commonly found in spectra generated from human serum and are known to be reproducible. Each MS feature was defined as an m/z range bounded by two specific m/z values. The feature value for a particular spectrum was calculated as the sum of intensities within the m/z range of the feature.\n\nTo further prepare the data for analysis, the logarithm of the feature values was taken to bring the distributions closer to normality. The mean and standard deviation of each MS feature were calculated for the Score Development Set, which consisted of 85 samples. These values were then used to center and scale each feature through z-score normalization.\n\nPrincipal component analysis (PCA) was employed to create scores for biological processes of interest. An ensemble-averaged or bagged version of PCA was used to minimize overfitting, especially when there were more attributes (MS features) than instances (samples). This involved randomly selecting subsets of samples, performing PCA on these subsets, and averaging the principal component (PC) directions over multiple subset realizations. This process ensured that the ensemble-averaged PC directions were meaningful and robust.",
  "optimization/parameters": "In the optimization process, the number of parameters used in the model is determined by the number of mass spectrometry (MS) features associated with each biological process. These features are identified through set enrichment analysis, which assesses the association of MS features with specific biological processes. The threshold for significance in this analysis is typically set at 0.05, but it can be adjusted lower for processes where many features are initially associated, ensuring a more reliable identification of relevant features.\n\nFor each biological process, the number of MS features deemed associated, denoted as Kq, must be at least eight to proceed with score construction. This threshold is arbitrary and could be reduced to allow the combination of fewer MS features if necessary. The specific number of features used for each process varies and is detailed in the supplementary materials.\n\nThe selection of these features is crucial as they form the basis for the principal component analysis (PCA) used to create the scores. The PCA is performed on subsets of the Score Development Set, with the process repeated multiple times to generate ensemble-averaged principal component directions. This approach helps to minimize overfitting, especially when the number of features exceeds the number of samples.\n\nIn summary, the model parameters are the MS features associated with each biological process, with the number of parameters (p) varying by process and determined through a rigorous statistical analysis. The threshold for feature inclusion is set to ensure reliability and relevance, with a minimum of eight features required for score construction.",
  "optimization/features": "In the optimization process, a pre-defined set of 274 mass spectrometry (MS) features were used as input. These features were selected based on their common occurrence in spectra generated from human serum and their known reproducibility. Feature selection was performed to identify MS features associated with specific biological processes of interest. This selection process involved set enrichment analysis methods, which associated features in processed mass spectra with the biological processes. The selection was done using reference sets, which were separate from the Score Development Set used for creating the scores. This ensures that the feature selection process was independent of the training set, minimizing the risk of overfitting. The number of features associated with each biological process varied, but only processes with at least eight associated MS features were considered for score construction.",
  "optimization/fitting": "In our study, we employed a method to create biological scores using mass spectrometry (MS) data, which inherently involves a large number of features (MS features) compared to the number of samples. This scenario can lead to overfitting, where the model performs well on training data but poorly on unseen data.\n\nTo mitigate overfitting, we utilized an ensemble-averaged or bagged version of principal component analysis (PCA). This approach involves performing PCA on multiple random subsets (bags) of the training data and then averaging the resulting principal component (PC) directions. By doing so, we reduce the variance and improve the generalization of the PCA results. Additionally, we ensured that the scores created for a particular process were more strongly associated with that process than with others, further validating the robustness of our model.\n\nTo rule out underfitting, we assessed the reproducibility of the scores within and between batches. The standard deviations across multiple preparations and runs were calculated, demonstrating consistent score generation. Furthermore, we compared the score distributions between the Score Development Set and the Score Validation Set, finding good generalization, which indicates that our model is not too simplistic to capture the underlying patterns in the data.\n\nIn summary, our method carefully balances the risk of overfitting and underfitting by using ensemble-averaged PCA and thorough validation processes. This ensures that the biological scores generated are reliable and generalizable to new data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method involved using a hierarchical, dropout-regularized classifier architecture. Dropout regularization is a technique where, during training, a random subset of neurons is temporarily removed from the network. This helps to prevent the model from becoming too reliant on any single feature and encourages it to learn more generalizable patterns.\n\nAdditionally, we used an iterative refinement approach where training class labels and the classifier were repeatedly adjusted. This process helped to reveal the molecular structure consistent with the endpoint of interest, further reducing the risk of overfitting.\n\nWe also ensured that the scores generated for a particular biological process were more strongly associated with that process than with other biological processes. This involved discarding features that were associated with multiple processes, thereby enhancing the specificity of the scores.\n\nTo validate our models, we used independent cohorts of patients. For instance, a test was developed to stratify melanoma patients into groups with better and worse outcomes when treated with an immune checkpoint inhibitor. This test was validated on an independent cohort, demonstrating its generalizability and reducing the likelihood of overfitting.\n\nFurthermore, we implemented multiple levels of quality control in our data acquisition and processing procedures. This included automated checks to detect degraded, oxidized, or contaminated samples, as well as batch QC checks using reference samples. These measures helped to maintain data quality and reproducibility, which are crucial for preventing overfitting.\n\nIn summary, our approach combined dropout regularization, iterative refinement, feature specificity, independent validation, and rigorous quality control to effectively prevent overfitting and ensure the reliability of our models.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a blackbox. It leverages biological scores derived from mass spectrometry data to characterize specific biological processes. These scores are engineered features that combine multiple mass spectrometry (MS) features associated with particular biological processes. The process of score generation involves several transparent steps, including feature selection, principal component analysis (PCA), and standardization.\n\nFor instance, the Complement Activation Score, Glycolysis Score, Wound Healing Score, and Type 17 Immune Response Score are examples of such biological scores. These scores are created from MS features that are strongly associated with their respective biological processes. The scores are standardized by centering the median at 0 and scaling by the difference between the 84th and 16th percentile, ensuring that higher score values correspond to higher levels or activation of the biological process.\n\nThe model's transparency is further enhanced by the iterative refinement process used during training, where class labels and the classifier are refined to reveal the molecular structure consistent with the endpoint of interest. This approach allows for a clear understanding of how the model combines different attributes to make predictions.\n\nAdditionally, the model's performance is validated on independent cohorts, demonstrating its robustness and generalizability. The hazard ratios and confidence intervals for survival between different prognosis groups provide a quantitative measure of the model's predictive power. For example, the hazard ratio for survival between Good and Poor prognosis groups was 0.60 (95% CI 0.35\u20131.04), indicating a significant difference in outcomes.\n\nIn summary, the model's use of biological scores and transparent feature engineering processes makes it interpretable and understandable. The scores provide clear, biologically meaningful insights into the underlying processes, and the model's performance is rigorously validated, ensuring its reliability and applicability in clinical settings.",
  "model/output": "The model developed in this study is primarily a classification model. It was designed to stratify patients with melanoma into two groups based on their prognosis when treated with an immune checkpoint inhibitor. The model uses a hierarchical, dropout-regularized classifier architecture and iteratively refines training class labels and the classifier to reveal the molecular structure consistent with the endpoint of interest. The output of this model is a classification of patients into \"Good Prognosis\" and \"Poor Prognosis\" groups, which are then compared in terms of overall survival. The hazard ratio (HR) for survival between these groups was calculated, indicating the model's ability to differentiate between the two prognosis categories. Additionally, the scores generated by the model can be used as continuous measures of biological processes, but in the context of this study, they are primarily used for classification purposes.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure the robustness and generalizability of the biological scores developed. Initially, the scores were generated for both the Score Development Set and the Score Validation Set. The distributions of these scores were compared between the two sets to check for any overfitting to the Score Development Set. Good generalization of the score distribution was observed between the sets, indicating that the scores were not overly fitted to the development data.\n\nThe reproducibility of the scores was assessed both within and between batches. For within-batch reproducibility, a Quality Control Reference Sample was prepared multiple times and spotted onto a single MALDI plate. The standard deviations across these preparations were calculated to evaluate consistency. The results showed low standard deviations, suggesting high within-batch reproducibility. For between-batch reproducibility, the Deep MALDI spectra were obtained from multiple runs of the Machine Qualification Set over an extended period. The standard deviations across these batches were also calculated, demonstrating reasonable between-batch reproducibility.\n\nAdditionally, the scores were evaluated on a clinical population representative sample set, the Early Stage Lung Cancer Set. Spectra were acquired for each sample multiple times over an extended period, and the concordance between these repeated measurements was assessed. The coefficients of determination (r\u00b2) and the slopes of the least squares fit lines for the concordance plots indicated good reproducibility, which is crucial for the practical application of the scores.\n\nThe method was also evaluated by stratifying patient cohorts into subgroups based on the scores and comparing overall survival between these subgroups using the Kaplan-Meier method and Cox Proportional Hazards (CPH) models. This evaluation demonstrated the potential utility of the scores in predicting patient outcomes.\n\nIn summary, the evaluation method involved assessing the generalization, reproducibility, and clinical relevance of the biological scores through various statistical and experimental approaches.",
  "evaluation/measure": "In the evaluation of our biological scores, several performance metrics were reported to assess both reproducibility and correlation between different biological processes.\n\nTo evaluate reproducibility, standard deviations were calculated for various scores across different batches and preparations. For instance, within-batch reproducibility was assessed using the Quality Control Reference Sample, where the standard deviations for scores like Complement Activation, Glycolysis, Wound Healing, and Type 17 Immune Response ranged from 0.12 to 0.19. Between-batch reproducibility was evaluated using the Machine Qualification Set, with standard deviations for the same scores ranging from 0.07 to 0.60. Additionally, concordance plots and coefficients of determination (r\u00b2) were used to demonstrate the reproducibility of scores generated from multiple, independent spectral acquisitions. The r\u00b2 values varied between 0.79 and 0.97, indicating reasonable concordance.\n\nTo assess the correlation between scores for different biological processes, heatmaps of the correlation matrix were used. These heatmaps confirmed that the scores displayed expected inter-process correlations, reflecting the intrinsic relationships between various biological processes.\n\nThe set of metrics used is representative of standard practices in the field, focusing on both the consistency of the scores across different conditions and their ability to reflect known biological relationships. This approach ensures that the scores are reliable and meaningful in the context of biological research.",
  "evaluation/comparison": "Not applicable. The publication focuses on the development and validation of biological scores derived from mass spectrometry data to characterize specific biological processes. It does not discuss comparisons to publicly available methods or simpler baselines on benchmark datasets. The evaluation primarily centers around the reproducibility and utility of the scores generated from the described methodology. The study emphasizes the creation of scores from mass spectral data, their standardization, and their application in stratifying patient outcomes, particularly in cancer settings. The methods involve detailed spectral processing, quality control measures, and the use of principal component analysis to generate scores that can be applied to new samples. The evaluation of these scores includes assessments of within-batch and between-batch reproducibility, as well as their ability to stratify patients based on survival outcomes.",
  "evaluation/confidence": "The evaluation of the scores generated in this study includes several statistical measures that provide confidence in the results. For instance, hazard ratios (HR) for survival between different prognosis groups are presented with 95% confidence intervals (CI). This is evident in the stratification of patients with melanoma into good and poor prognosis groups, where the HR for survival is reported as 0.60 with a 95% CI of 0.35\u20131.04. This indicates the range within which the true hazard ratio is likely to fall, providing a measure of the uncertainty around the point estimate.\n\nAdditionally, p-values are provided for various statistical tests, such as those comparing the distributions of scores between different sets. For example, Mann-Whitney p-values and Brown-Forsythe p-values are used to compare medians and variances, respectively, ensuring that the scores generalize well between the development and validation sets. These p-values help determine the statistical significance of the observed differences, reinforcing the reliability of the findings.\n\nThe reproducibility of the scores is also assessed through standard deviations across multiple runs and batches. For instance, the standard deviations for scores like Complement Activation, Glycolysis, Wound Healing, and Type 17 Immune Response are reported, showing the variability and consistency of the scores across different conditions. This provides a quantitative measure of the reproducibility and reliability of the scores.\n\nFurthermore, the concordance between different runs of spectral acquisitions is evaluated using coefficients of determination (r\u00b2) and slopes of least squares fit lines. These metrics indicate the degree of agreement between repeated measurements, with r\u00b2 values ranging from 0.79 to 0.97 and slopes between 0.87 and 1.03, suggesting high reproducibility.\n\nOverall, the inclusion of confidence intervals, p-values, and reproducibility metrics strengthens the confidence in the performance and reliability of the scores generated in this study. These statistical measures ensure that the results are robust and that the method is superior to others and baselines, providing a solid foundation for further applications and validations.",
  "evaluation/availability": "Not enough information is available."
}