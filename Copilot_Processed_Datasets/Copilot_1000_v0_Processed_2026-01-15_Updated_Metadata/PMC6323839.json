{
  "publication/title": "funbarRF: DNA barcode-based fungal species prediction using multiclass Random Forest supervised learning model.",
  "publication/authors": "Meher PK, Sahu TK, Gahoi S, Tomar R, Rao AR",
  "publication/journal": "BMC genetics",
  "publication/year": "2019",
  "publication/pmid": "30616524",
  "publication/pmcid": "PMC6323839",
  "publication/doi": "10.1186/s12863-018-0710-z",
  "publication/tags": "- DNA barcoding\n- Fungal species identification\n- Machine learning\n- Random forest classifier\n- g-spaced base pair features\n- k-mer features\n- Cross-validation\n- Species identification success rate\n- Bioinformatics\n- Computational biology\n- Fungal taxonomy\n- Sequence analysis\n- Molecular ecology\n- Genetic resource collections\n- DNA sequence data\n- Species identification methods\n- Bioinformatics tools\n- Computational methods\n- Fungal diversity\n- DNA barcode sequences",
  "dataset/provenance": "The dataset used in this study is available at a specific online repository. The sequences for various taxonomical entities, such as Inga, Drosophila, Cypraeidae, Fish, and Bat, were retrieved from a particular website. This website has also been utilized in earlier developed species identification methods. Additionally, simulated datasets generated by Weitschek et al. were used to assess the robustness of the proposed model. These datasets include sequences belonging to 50 species, with effective population sizes of 1000, 10000, and 50000. The datasets can be accessed at the same website.\n\nFor the fungal datasets, barcode sequences were submitted by various contributors to the BOLD system. The specific dataset used for comparing the proposed model with existing fungal taxonomy prediction methods consisted of 1363 species, with 10 sequences per species. This dataset was used to evaluate the performance of the methods over a 10-fold cross-validation procedure.\n\nThe number of sequences and species varied across different categories of datasets. For instance, one category had 3770 species with 11210 sequences, where each species had 3 sequences. Other categories had varying numbers of sequences per species, ranging from 4 to 9. The datasets were prepared by randomly drawing sequences from the original dataset, and a k-fold cross-validation procedure was employed to evaluate the species identification success rate.",
  "dataset/splits": "Seven different datasets were prepared with varying numbers of sequences per species, specifically 3, 4, 5, 6, 7, 8, and 9 sequences per species. These sequences were randomly drawn from the original dataset. For each dataset with k sequences per species, a k-fold cross-validation procedure was employed. This means that k subsets were created by randomly splitting the entire dataset such that each subset contained one sequence from each species. In each fold of the cross-validation, k-1 subsets were used for training the model, and the remaining subset was used for validation. This process ensured that each subset had an equal opportunity to serve as the validation set, and the accuracy was measured as the species identification success rate (SISR) averaged over the k folds.\n\nThe number of species and sequences for each category is as follows:\n\n* 3 sequences per species: 3770 species, 11210 sequences\n* 4 sequences per species: 3461 species, 13844 sequences\n* 5 sequences per species: 2777 species, 13885 sequences\n* 6 sequences per species: 2328 species, 13968 sequences\n* 7 sequences per species: 1998 species, 13986 sequences\n* 8 sequences per species: 1773 species, 14184 sequences\n* 9 sequences per species: 1498 species, 13482 sequences\n\nThe SISR is defined as the ratio of the number of correctly classified query instances to the total number of query sequences for each species, averaged across all species.",
  "dataset/redundancy": "The datasets used in this study were prepared with varying numbers of sequences per species, specifically 3, 4, 5, 6, 7, 8, and 9 sequences per species. These sequences were randomly drawn from the original dataset to ensure a diverse and representative sample. The dataset consists of approximately 70% non-redundant sequences, excluding common sequences found in both the Warcup and UNITE datasets.\n\nTo evaluate the species identification success rate (SISR) of the proposed model, a k-fold cross-validation (CV) procedure was employed. For a dataset with k sequences per species, k subsets were created by randomly splitting the entire dataset such that each subset contained one sequence from each species. This ensured that the training and validation sets were independent. In the k-fold CV procedure, k-1 subsets were used for training the model, while the remaining subset was used for validation. This process was repeated k times, with each subset being used as the validation set exactly once. The accuracy was measured in terms of SISR, averaged over the k folds of the CV.\n\nThe distribution of sequences and species across the different categories of datasets is provided in a table. For instance, in the category with 3 sequences per species, there are 3,770 species with a total of 11,210 sequences. This approach ensures that the model's performance is thoroughly evaluated across different dataset sizes and compositions.\n\nThe datasets used in this study are comparable to previously published machine learning datasets in terms of their structure and the methods used for evaluation. The use of k-fold cross-validation is a standard practice in machine learning to ensure that the model's performance is robust and generalizable. The random drawing of sequences from the original dataset helps in creating diverse and representative training and validation sets, which is crucial for the reliability of the model's predictions.",
  "dataset/availability": "The data used in this study, including the data splits, are publicly available. The barcode sequences for various taxonomical entities, such as Inga, Drosophila, Cypraiedae, Fish, and Bat, can be accessed from the website http://dmb.iasi.cnr.it/blog.php. This website also hosts the simulated datasets generated by Weitschek et al., which were used to assess the robustness of the proposed model. These datasets include sequences belonging to 50 species, with effective population sizes of 1000, 10000, and 50000.\n\nAdditionally, the sequences for the comparison with existing fungal taxonomy prediction methods were obtained from a dataset of 1363 species, with 10 sequences per species. This dataset is also publicly available and was used to evaluate the performance of the proposed model against existing methods like RDP classifier, SINTAX, and MOTHUR.\n\nThe data is distributed under the terms of the Creative Commons Attribution 4.0 International License, which allows for unrestricted use, distribution, and reproduction, provided that appropriate credit is given to the original authors and the source. This license ensures that the data can be freely accessed and utilized by the research community, promoting transparency and reproducibility in scientific research.",
  "optimization/algorithm": "The machine-learning algorithm class used is Random Forest (RF). This is a well-established ensemble learning method known for its robustness and ability to handle large datasets with high dimensionality.\n\nThe Random Forest algorithm is not new. It was introduced by Breiman in 2001 and has since been widely adopted in various fields, including bioinformatics.\n\nThe reason it was not published in a machine-learning journal is that the focus of the study is on its application in bioinformatics, specifically for species identification using DNA barcode sequences. The development and optimization of the Random Forest parameters were tailored to this specific biological problem. The study aims to contribute to the field of bioinformatics by demonstrating the effectiveness of Random Forest in this context, rather than introducing a new machine-learning algorithm.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it relies on a single machine learning algorithm, specifically the Random Forest (RF) classifier. This algorithm is used to identify fungal species based on DNA barcode sequences.\n\nThe RF classifier is an ensemble learning method that constructs multiple decision trees during training. Each tree is built using a bootstrap sample of the training data, ensuring that a portion of the data (approximately 36.8%) is left out for each tree. These out-of-bag (OOB) samples are used to estimate the prediction error of the model.\n\nThe RF model was optimized by tuning two key parameters: ntree (the number of decision trees) and mtry (the number of variables considered for splitting at each node). The optimal values for these parameters were determined through a process of training the model with varying numbers of decision trees and different mtry values, and selecting the configuration that minimized the OOB error.\n\nThe training data used for the RF model consisted of DNA barcode sequences from various fungal species. The sequences were divided into multiple datasets, each containing a different number of sequences per species (ranging from 3 to 9). A k-fold cross-validation procedure was employed to evaluate the model's performance, ensuring that the training and validation data were independent.",
  "optimization/encoding": "In our study, the data encoding process was a critical step to transform biological sequences into numeric vectors, which are essential for supervised learning-based predictors. We employed g-spaced base pair features to encode the barcode sequences. This method involves computing the frequency of di-nucleotides with specific gaps (g-spaced features) within the sequences. We utilized five types of g-spaced features: 1-spaced, 2-spaced, 3-spaced, 4-spaced, and 5-spaced. For any nucleotide sequence of length N, each g-spaced feature set results in 16 descriptors. The frequency of a di-nucleotide with a g-gap is calculated as Dg(s, t)/(N \u2212 1), where s and t represent the nucleotides (A, T, G, C), and Dg(s, t) is the count of the di-nucleotide s and t with a g-gap.\n\nThe g-spaced base pair features were computed using the BioSeqClass R-package, specifically with the function featureCKSAAP. This encoding technique was chosen because it has been shown to provide significantly higher accuracy compared to contiguous k-mer features. By using these g-spaced features, we were able to capture the variability of nucleotide distribution in the barcode sequences of fungal species efficiently. This encoding method allowed us to transform the biological sequences into numeric vectors that could be used as input for our machine learning models, specifically the Random Forest classifier.",
  "optimization/parameters": "In our study, we focused on optimizing two key parameters of the Random Forest (RF) model: `ntree` and `mtry`. The `ntree` parameter represents the number of decision trees in the forest, while `mtry` denotes the number of variables randomly sampled as candidates at each split.\n\nFor tuning `ntree`, we trained the RF model using five different feature sets: `g=1`, `g=1+2`, `g=1+2+3`, `g=1+2+3+4`, and `g=1+2+3+4+5`. We varied the number of decision trees from 1 to 500 and used the default `mtry` value, which is the square root of the number of variables (`p`). The optimal `ntree` was determined as the point where the Out-Of-Bag (OOB) error rate stabilized, which was observed to be around 400 trees. However, we set `ntree` to 500 to anticipate further improvement.\n\nNext, we optimized the `mtry` parameter using the optimal `ntree` value of 500. We varied `mtry` values to include 1, `sqrt(p)/2`, `sqrt(p)`, `2*sqrt(p)`, `3*sqrt(p)/2`, and `p`. The `mtry` value that resulted in the lowest OOB error rate was considered optimal. Through this process, we found that the default `mtry` value, which is `sqrt(p)` (9 in our study), yielded the lowest OOB error.\n\nIn summary, the optimal values for the RF parameters were determined to be `ntree = 500` and `mtry = sqrt(p)`, where `p` is the number of variables. This optimization process ensured that our model achieved the highest prediction accuracy.",
  "optimization/features": "In our study, we utilized g-spaced base pair features as input for the Random Forest (RF) classifier. The specific combinations of g-spaced features used were g=1, g=1+2, g=1+2+3, g=1+2+3+4, and g=1+2+3+4+5. The number of features (f) varied depending on the combination of g-spaced base pairs employed. For instance, the combination g=1+2+3+4+5 included a comprehensive set of features, which was found to yield the lowest out-of-bag (OOB) error rate.\n\nFeature selection was implicitly performed by evaluating different combinations of g-spaced features. This process involved training the RF model with varying feature sets and assessing their performance based on the OOB error rate. The optimal feature set was determined to be g=1+2+3+4+5, as it provided the best model performance. This selection process was conducted using the training datasets only, ensuring that the validation and testing phases remained unbiased. The use of g-spaced features allowed for an efficient capture of the variability in nucleotide distribution within the DNA barcode sequences, which is crucial for accurate species identification.",
  "optimization/fitting": "In our study, we employed the Random Forest (RF) method for species identification using DNA barcode sequences. The RF algorithm is an ensemble learning technique that constructs multiple decision trees during training and outputs the class that is the mode of the classes of the individual trees.\n\nThe RF method has two main parameters that require tuning: `ntree`, which represents the number of decision trees in the forest, and `mtry`, which is the number of variables randomly sampled as candidates at each split. To determine the optimal values for these parameters, we conducted a systematic tuning process.\n\nFor `ntree`, we trained the RF model using various feature sets (g=1, g=1+2, g=1+2+3, g=1+2+3+4, and g=1+2+3+4+5) with a varying number of decision trees (from 1 to 500) and the default `mtry` value. The Out-Of-Bag (OOB) error rate was monitored, and the number of trees after which the OOB error rate stabilized was considered optimal. This approach helped us avoid overfitting by ensuring that the model's performance generalized well to unseen data.\n\nOnce the optimal `ntree` was determined, we retrained the RF model with the same datasets but varied the `mtry` values. The `mtry` value that resulted in the lowest OOB error rate was selected as the optimal `mtry`. This step was crucial in preventing underfitting, as it ensured that the model was complex enough to capture the underlying patterns in the data.\n\nTo further validate our model's performance, we used k-fold cross-validation (CV). For a dataset with `k` sequences per species, we prepared `k` subsets, each containing one sequence from each species. In the k-fold CV procedure, `k-1` subsets were used for training, and the remaining subset was used for validation. This process was repeated `k` times, with each subset serving as the validation set once. The species identification success rate (SISR) was evaluated across all folds to ensure that our model performed consistently across different subsets of the data.\n\nBy following this rigorous tuning and validation process, we were able to optimize the RF parameters and ensure that our model neither overfitted nor underfitted the data. The final model, with the optimal `ntree` and `mtry` values, demonstrated robust performance in identifying fungal species based on DNA barcode sequences.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was the Out-Of-Bag (OOB) error estimation, which is inherent to the Random Forest (RF) algorithm. The OOB error provides an unbiased estimate of the generalization error as it is calculated using the samples that were not included in the bootstrap sample for each tree. This helps in assessing the model's performance on unseen data and prevents overfitting.\n\nAdditionally, we performed parameter tuning for the RF model, specifically focusing on the number of decision trees (ntree) and the number of variables to consider at each split (mtry). By varying these parameters and observing the OOB error rates, we were able to identify the optimal values that minimized overfitting. For instance, we found that the OOB error rates stabilized after around 400 decision trees, and we set the optimal ntree to 500 to ensure further improvement.\n\nWe also utilized cross-validation techniques to evaluate the model's performance. Specifically, we employed k-fold cross-validation, where k subsets were created by randomly splitting the dataset. This approach ensured that each sequence of each species was included in the validation set at least once, providing a comprehensive assessment of the model's generalization ability.\n\nFurthermore, we compared different feature sets, including g-spaced base pair features and k-mer features, to determine the most effective representation for species identification. By analyzing the success rates (SISR) for different combinations of these features, we were able to select the feature set that provided the best performance while minimizing the risk of overfitting.\n\nIn summary, our approach to preventing overfitting involved the use of OOB error estimation, parameter tuning, cross-validation, and feature selection. These techniques collectively ensured that our model was robust and capable of generalizing well to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported within the publication. Specifically, we detail the tuning process for the number of classification trees (ntree) and the number of variables randomly sampled as candidates at each split (mtry). The optimal values for these parameters were determined through a systematic evaluation of out-of-bag (OOB) error rates across different datasets and model representations.\n\nThe optimal ntree value was found to be 500, as the OOB-error rates stabilized around this number of trees. For mtry, the default value of 9 was identified as optimal, particularly for the model representation combining g=1+2+3+4+5. This configuration yielded the lowest OOB-error rates.\n\nRegarding model files and optimization parameters, the specific details of the datasets and the feature sets used (such as g-spaced base pair features) are described in the methods section. The datasets were prepared with varying numbers of sequences per species, and a k-fold cross-validation procedure was employed to evaluate the species identification success rate (SISR).\n\nThe publication is distributed under the Creative Commons Attribution 4.0 International License, which permits unrestricted use, distribution, and reproduction in any medium, provided appropriate credit is given to the original authors and the source. This license allows for the sharing and adaptation of the reported configurations and optimization schedules.\n\nFor those interested in implementing or replicating our methods, the executable codes for the algorithms used (such as MOTHUR, RDP classifier, and SINTAX) are available through their respective repositories. The specific versions and links to these repositories are provided in the publication, ensuring transparency and reproducibility.",
  "model/interpretability": "The model employed in this study is a Random Forest (RF) classifier, which is inherently an ensemble learning method consisting of multiple classification trees. This makes the model somewhat of a black box, as the individual decisions of each tree and their combined effect can be complex to interpret directly. However, RF does offer some level of interpretability through several mechanisms.\n\nOne key aspect of RF that aids in interpretability is the use of Out-Of-Bag (OOB) samples. Each tree in the forest is built using a bootstrap sample of the data, and the remaining samples (about 36.8%) are used as OOB samples to estimate the error rate. This process provides a way to assess the model's performance and the importance of individual features.\n\nFeature importance can be derived from the RF model by examining which variables are most frequently used for splitting nodes across all trees in the forest. This information can highlight which features are most influential in making predictions, providing some insight into the model's decision-making process.\n\nAdditionally, the model's performance can be analyzed through cross-validation and OOB error rates, which give a sense of how well the model generalizes to unseen data. The stabilization of OOB error rates after a certain number of trees (ntree) and the effect of different model representations (combinations of g-spaced features) can also offer clues about the model's behavior and robustness.\n\nIn summary, while the RF model is not entirely transparent, it provides several tools and metrics that can help in understanding its decisions and performance. The use of OOB samples, feature importance, and error rate analysis all contribute to making the model more interpretable.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict fungal species based on DNA barcode sequences. The model uses a Random Forest (RF) supervised learning technique, which is an ensemble learning method consisting of multiple classification trees. Each tree in the forest is constructed on a bootstrap resample of the learning dataset, and the final prediction is made by majority voting among the trees. The model's performance is evaluated using metrics such as Out-Of-Bag (OOB) error rates and Species Identification Success Rate (SISR), indicating its effectiveness in classifying different fungal species. The model was also tested on various taxonomical entities, achieving high accuracy in species identification.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for our prediction model is not publicly released. However, we have established a prediction server named \"funbarRF\" to facilitate fungal species identification. This server is accessible at http://cabgrid.res.in:8080/funbarrf/. The user interface of the server is designed using HTML, with PHP and R-programs implemented at the back end to execute the proposed approach.\n\nUsers can submit both reference and query sequences in FASTA format, with sequence identifiers in BOLD format. Upon submission, the server generates two result files: one for the reference (training) set and another for the query (test) set. The training-result-file provides the number of instances observed and correctly predicted for each reference species, while the query-result-file contains the predicted labels for the query sequences. This setup allows users to leverage our model without needing access to the underlying source code.",
  "evaluation/method": "The method was evaluated using a k-fold cross-validation procedure, where k subsets were created by randomly splitting the dataset such that each subset contained one sequence from each species. In this procedure, k-1 subsets were used for training the model, while the remaining subset was used for validation. This process was repeated k times, ensuring that each subset was used as the validation set once. The accuracy of the model was measured in terms of the species identification success rate (SISR), which is the ratio of correctly classified query instances to the total number of query sequences for each species, averaged over the k folds.\n\nAdditionally, the performance of the proposed model was assessed on five different taxonomical entities: Inga, Drosophila, Cypraiedae, Fish, and Bat. The barcode sequences for these entities were retrieved from a specific online source and had been used in earlier species identification methods. The model's robustness was also evaluated using simulated datasets generated by Weitschek et al., which included sequences from 50 species with varying effective population sizes.\n\nThe proposed model's SISR was compared against existing similarity, tree, and diagnostic-based methods for species identification other than fungi. The comparison was made using a diverged dataset consisting of barcode sequences from Inga, Cypraeidae, and Drosophila. Furthermore, the model was compared with existing fungal species identification methods such as RDP classifier, SINTAX, and MOTHUR using a dataset of 1363 species, with accuracies computed over 10-fold cross-validation.\n\nThe parameter optimization for the random forest (RF) model involved tuning the number of decision trees (ntree) and the number of variables randomly sampled as candidates at each split (mtry). The optimal ntree was determined as the point at which the out-of-bag (OOB) error rate stabilized, and the optimal mtry was the value that generated the lowest OOB error rate. The RF methodology was implemented using the randomForest function available in the R-package \"randomForest\".",
  "evaluation/measure": "In our evaluation, we primarily focused on the Species Identification Success Rate (SISR) as our key performance metric. SISR is defined as the ratio of correctly classified query instances to the total number of query sequences for each species, averaged over all species. This metric is particularly relevant for our study as it directly measures the effectiveness of our model in accurately identifying fungal species from DNA barcode sequences.\n\nWe computed SISR over 10-fold cross-validation (CV), where one sequence of each species was present in each fold. This approach ensures that our model's performance is robust and not dependent on a specific subset of the data. The use of 10 sequences per species for training and validation was chosen to align with previous assessments of our model's SISR, providing a consistent basis for comparison.\n\nIn addition to SISR, we also reported the Out-Of-Bag (OOB) error rates for different model representations and parameter settings. OOB error rates provide an internal estimate of the model's generalization error, helping us to tune the Random Forest parameters effectively. We observed that the OOB errors stabilized after 400 classification trees and were lowest for the model representation g=1+2+3+4+5 with the default mtry value.\n\nOur choice of performance metrics is representative of the literature in fungal species identification. SISR is a commonly used metric in similar studies, allowing for direct comparison of our results with existing methods. The use of OOB error rates is also standard practice in evaluating Random Forest models, ensuring that our parameter optimization process is rigorous and well-founded.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our proposed model against several existing approaches for species identification. For fungal species, we compared our model with established methods such as RDP classifier, SINTAX, and MOTHUR. These comparisons were conducted using a dataset consisting of 1363 species, with 10 sequences per species. The accuracies were computed over 10-fold cross-validation, ensuring that each fold contained one sequence from each species.\n\nFor species other than fungi, we assessed our model's performance on five different taxonomical entities: Inga, Drosophila, Cypraeidae, Fish, and Bat. The barcode sequences for these entities were retrieved from a publicly available source, ensuring that the datasets were benchmarked and comparable to earlier developed species identification methods. We also evaluated our model using simulated datasets generated by Weitschek et al., which included three datasets with varying effective population sizes. These datasets were accessed from the same public source.\n\nIn addition to these comparisons, we evaluated our model against simpler baselines, including similarity-based, tree-based, and diagnostic-based approaches. The similarity-based approach assigns species labels based on the maximum number of nucleotide matches between query and reference barcodes. Tree-based approaches use clustering methods like Parsimony (PAR) or Neighbor Joining (NJ) to determine species labels. Diagnostic-based methods, such as DNA-BAR and BLOG, rely on the presence or absence of specific nucleotides in the DNA barcode.\n\nOur model demonstrated higher success rates (SISR) compared to these simpler baselines, particularly in the context of diverged taxonomical entities. The proposed approach achieved over 90% accuracy across various datasets, indicating its robustness and effectiveness in species identification. The comparisons with publicly available methods and simpler baselines highlight the superior performance of our model in both fungal and non-fungal species identification.",
  "evaluation/confidence": "The evaluation of the proposed computational model involved a thorough assessment of its performance using various metrics and comparisons with existing methods. The performance was measured in terms of Species Identification Success Rate (SISR), which is the ratio of correctly classified query instances to the total number of query sequences for each species. This metric was averaged over multiple folds of cross-validation to ensure robustness.\n\nThe model's performance was evaluated using datasets from different taxonomical entities, including fungi, Drosophila, Inga, Fish, Bat, and Cypraiedae. The SISR was computed for different numbers of sequences per species, and it was observed that the success rates improved with an increasing number of sequences. Specifically, the SISR reached 80% when 4 sequences per species were used for training, and it stabilized at higher success rates with more sequences.\n\nThe model's performance was also compared with existing similarity-based, tree-based, and diagnostic-based methods. The comparison was made using a diverged dataset consisting of barcode sequences from Inga, Cypraiedae, and Drosophila. The proposed model demonstrated higher SISR values compared to these existing methods, indicating its superiority in species identification.\n\nAdditionally, the model was evaluated using simulated datasets with varying effective population sizes. The results showed that the model maintained high accuracy across different datasets, further validating its robustness.\n\nStatistical significance was assessed through cross-validation and comparisons with baseline methods. The results indicated that the proposed model's performance was statistically significant, with lower out-of-bag (OOB) error rates and higher SISR values. The OOB error rates stabilized after a certain number of trees in the random forest classifier, and the optimum number of trees was determined to ensure further improvement in performance.\n\nIn summary, the evaluation confidence of the proposed model is high, supported by comprehensive performance metrics, statistical significance, and comparisons with existing methods. The model's ability to achieve high SISR values across different datasets and taxonomical entities demonstrates its effectiveness and reliability in species identification.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. However, the datasets utilized for assessing the performance of our proposed model can be accessed from external sources. Specifically, the barcode sequences for various taxonomical entities, such as Inga, Drosophila, Cypraiedae, Fish, and Bat, were retrieved from http://dmb.iasi.cnr.it/blog.php. Additionally, simulated datasets generated by Weitschek et al. are also available at the same URL. These datasets include sequences belonging to different species and were used to evaluate the robustness of our model.\n\nFor the fungal species identification, the datasets consisted of 1363 species with 10 sequences per species. The performance of our model was compared with existing methods like RDP classifier, SINTAX, and MOTHUR. The executable codes for these methods are available at their respective repositories: MOTHUR (https://github.com/mothur/mothur/releases/tag/v1.40.5), RDP classifier (https://sourceforge.net/projects/rdp-classifier/), and SINTAX (http://www.drive5.com/usearch/manual/cmd_sintax.html).\n\nThe article is distributed under the terms of the Creative Commons Attribution 4.0 International License, which permits unrestricted use, distribution, and reproduction in any medium, provided appropriate credit is given to the original authors and the source. The Creative Commons Public Domain Dedication waiver applies to the data made available in this article, unless otherwise stated. This ensures that the methodologies and findings can be freely accessed and utilized by the scientific community for further research and validation."
}