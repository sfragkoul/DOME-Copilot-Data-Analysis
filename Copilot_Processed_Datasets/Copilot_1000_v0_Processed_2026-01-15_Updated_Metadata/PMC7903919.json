{
  "publication/title": "Machine Learning Analysis Reveals Novel Neuroimaging and Clinical Signatures of Frailty in HIV.",
  "publication/authors": "Paul RH, Cho KS, Luckett P, Strain JF, Belden AC, Bolzenius JD, Navid J, Garcia-Egan PM, Cooley SA, Wisch JK, Boerwinkle AH, Tomov D, Obosi A, Mannarino JA, Ances BM",
  "publication/journal": "Journal of acquired immune deficiency syndromes (1999)",
  "publication/year": "2020",
  "publication/pmid": "32251142",
  "publication/pmcid": "PMC7903919",
  "publication/doi": "10.1097/qai.0000000000002360",
  "publication/tags": "- HIV\n- Frailty\n- Machine Learning\n- Neuroimaging\n- Clinical Signatures\n- Gradient-Boosted Multivariate Regression\n- Functional Connectivity\n- Cerebral Blood Flow\n- Neurocognitive Testing\n- Aging Population",
  "dataset/provenance": "The dataset used in this study was sourced from a clinical cohort of individuals living with HIV. The participants included 105 older individuals, with an average age of 55.6 years. All participants had at least a 3-month history of combination antiretroviral therapy, with a median CD4 T-cell count of 546 cells/mm\u00b3. The dataset comprises various predictors, including demographics, HIV clinical markers, comorbid health conditions, cognition, and neuroimaging data. The neuroimaging data includes volumetrics, resting-state functional connectivity, and cerebral blood flow. This dataset has been utilized in previous studies by the research team, including a deep learning analysis to identify cognitive impairment and frailty in persons living with HIV. The dataset is highly dimensional, incorporating over 1100 data elements, and has been used to build machine learning models to classify frailty in older individuals with HIV.",
  "dataset/splits": "Not applicable",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is gradient-boosted multivariate regression (GBM). This is a form of ensemble machine learning that leverages the \"wisdom of crowds\" approach to optimize accuracy and minimize error. It is not a new algorithm; it has been successfully deployed in various studies, including those conducted by our team and others, to establish novel explanatory models of complex clinical phenotypes.\n\nThe reason it was not published in a machine-learning journal is that the focus of our work is on applying this established method to a specific clinical problem\u2014namely, the classification of frailty in older individuals living with HIV. Our study aims to contribute to the understanding of frailty in this population by utilizing advanced machine-learning techniques, rather than developing new algorithms. The application of GBM to this particular dataset and clinical question is what sets our work apart, rather than the innovation of the algorithm itself.",
  "optimization/meta": "The model employed in this study is a gradient-boosted multivariate regression (GBM), which is a form of ensemble machine learning. This approach leverages the \"wisdom of crowds\" to optimize accuracy and minimize error. It does not use data from other machine-learning algorithms as input; instead, it builds multiple individual models and combines their results to create a more robust final model.\n\nGBM is an ensemble method that primarily uses decision trees as its base learners. The process involves sequentially training each tree to correct the errors of the previous ones, thereby improving the overall performance. This method does not explicitly require training data to be independent for each model, as the ensemble process inherently accounts for dependencies through the iterative correction of errors.\n\nThe use of GBM ensures that the model is less prone to overfitting and provides a more stable and generalizable classification performance. The final model's performance was evaluated using 5-fold cross-validation, which further supports the robustness of the results.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for analysis. Resting-state functional connectivity (rs-fcMRI) scans were registered to a common template through a combined transformation process. This involved aligning the echoplanar imaging (EPI) data to T2-weighted (T2w) and T1-weighted (T1w) images, and then to an atlas. Motion correction was applied to eliminate frames based on DV ARS and frame displacement metrics. Signals from non-gray matter tissues, such as white matter, ventricles, and the extra-axial space, were treated as nuisance regressors and segmented using FreeSurfer. Additional regressors included parameters from rigid body head motion correction, average global signal, and the global signal temporal derivative. Regional averages were extracted for each volume, and preprocessed BOLD time series were obtained from 298 regions of interest. These regions were partitioned into 13 standard networks, including sensorimotor, auditory, default mode, visual, and others. Average connectivity was computed for within and between networks, resulting in a 13 \u00d7 13 network matrix. Each cell in the upper triangle of the matrix represented the correlation between the given networks and was included in the model. Feature selection was conducted using an in-house program based on SciKit and PDPBox, resulting in a final set of over 1100 data elements. Class labels were determined using a probability score based on the sigmoid function with a 0.5 decision boundary and gradient descent to minimize error. The data was further refined by training and testing the algorithms on the 10 features with the strongest classification values, reducing overfitting and enhancing model interpretation.",
  "optimization/parameters": "In the optimization process, the number of parameters used in the model was initially set to a maximum of 10. This selection was based on the features with the strongest classification values, specifically those determined by the mutual information criterion. This approach was chosen to reduce overfitting and enhance model interpretability. The final set of features included over 1100 data elements, but the model was trained and tested using only the top 10 features to ensure robustness and clarity in the classification algorithm. This method aligns with previous successful implementations of machine learning models in similar studies.",
  "optimization/features": "The study utilized a comprehensive set of features to classify frailty in individuals with chronic HIV. Initially, over 1100 data elements were considered. Feature selection was conducted using an in-house program based on SciKit and PDPBox. This process was performed using the training set only, ensuring that the selected features were not influenced by the test data. The final models were built using the top 10 features with the strongest classification values, as determined by the mutual information criterion. This approach helped to reduce overfitting and enhance model interpretability. The selected features included a mix of neuroimaging indices, cognitive performance metrics, and clinical markers, such as CD4 T-cell count.",
  "optimization/fitting": "The study employed gradient-boosted multivariate regression (GBM), an ensemble machine learning method, to build classification models. This approach leverages the \"wisdom of crowds\" to optimize accuracy and minimize error, which is particularly useful when dealing with a high number of parameters relative to the number of training points.\n\nTo mitigate overfitting, several strategies were implemented. First, feature selection was conducted using an in-house program based on SciKit and PDPBox, which helped in identifying the most relevant features. The final set of features included over 1100 data elements, but the algorithms were trained and tested on only 10 features with the strongest classification values, as determined by the mutual information criterion. This reduction in the number of predictors helps in enhancing model interpretation and reducing overfitting.\n\nAdditionally, 5-fold cross-validation was used, consisting of 25 total validation trials, to calculate the average F1 score as the final measure of model performance. This cross-validation technique ensures that the model generalizes well to unseen data, further guarding against overfitting.\n\nTo address underfitting, the GBM method was chosen for its ability to build complex models that capture intricate relationships within the data. The use of interactive features in the GBM allowed for the identification of novel synergies between different variables, which would not have been possible with simpler linear models. The inclusion of both linear and interactive features ensured that the model could capture a wide range of patterns in the data, thereby reducing the risk of underfitting.\n\nThe performance of the GBM models was also compared with logistic regression, which yielded a lower F1 score. This comparison provided additional confidence that the GBM models were appropriately complex and not underfitting the data. The logistic regression models were built using a two-step procedure that first ranked the relative importance of features and then examined the average F1 score using the top 10 features, ensuring a fair comparison.",
  "optimization/regularization": "To prevent overfitting in our machine learning models, several regularization techniques were employed. Firstly, we utilized gradient-boosted multivariate regression (GBM), an ensemble learning method that inherently reduces overfitting by combining the predictions of multiple models. This \"wisdom of crowds\" approach helps to minimize error and improve the generalization of the model.\n\nAdditionally, feature selection was conducted using an in-house program based on SciKit and PDPBox. This process helped in identifying the most relevant features, thereby reducing the complexity of the model and preventing it from learning noise in the data.\n\nWe also limited the number of features used in the final model to a maximum of 10 predictors. This was done by selecting the features with the strongest classification values, as determined by the mutual information criterion. By restricting the feature set, we further reduced the risk of overfitting and enhanced the interpretability of the model.\n\nMoreover, we implemented 5-fold cross-validation, which involved training and testing the algorithms on different subsets of the data. This technique helps to ensure that the model generalizes well to unseen data and is not merely memorizing the training set.\n\nLastly, we compared the results of our GBM models with those obtained through logistic regression. Logistic regression, while simpler, can also be prone to overfitting, especially when the number of predictors is large. By demonstrating that our GBM models outperformed the logistic regression models, we provided additional evidence of the robustness and generalizability of our approach.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study is not a black box. It utilizes gradient-boosted multivariate regression (GBM), an ensemble machine learning method that is inherently interpretable. This approach leverages the \"wisdom of crowds\" to optimize accuracy and minimize error, making it more transparent than many other machine learning models.\n\nThe interpretability of the model is further enhanced by the feature selection process. An in-house program based on SciKit and PDPBox was used to identify the most significant features. This process ensures that the final set of features, which includes over 1100 data elements, is both relevant and understandable.\n\nThe model's performance is evaluated using the F1 score, which balances precision and sensitivity. This metric is particularly useful for unbalanced datasets, providing a clear measure of the model's effectiveness.\n\nIn the linear GBM model, the top features include reduced cerebral blood flow (CBF) in specific brain regions, lower psychomotor performance, and various neuroimaging indices related to brain volumes and network connectivity. These features are ranked by their relative importance, making it easy to understand which factors are most influential in the model's predictions.\n\nThe interactive GBM model, which allows for 2-way interactions, also provides clear insights. For example, it identifies combinations of features such as higher symptoms of depression with lower resting-state functional connectivity (rs-fcMRI) between certain brain networks. These interactive features highlight the complex relationships between different variables, offering a deeper understanding of the underlying mechanisms.\n\nOverall, the model's transparency is a key strength, allowing for clear interpretation of the results and providing actionable insights into the factors contributing to frailty in older individuals living with HIV.",
  "model/output": "The model employed in this study is a classification model. It is designed to distinguish between frail and nonfrail individuals among people living with HIV (PLWH). The model uses gradient-boosted multivariate regression (GBM) to build classification algorithms. These algorithms are evaluated based on their ability to correctly identify frail individuals, with performance metrics including the F1 score, precision, and sensitivity. The model considers various features, including neuroimaging data, clinical markers, and cognitive performance, to make these classifications. Two types of GBMs were implemented: one using linear features and another allowing for 2-way interactions between features. The interactive model, in particular, identified novel synergies between neuroimaging features, female sex, symptoms of depression, and current CD4 count, highlighting the complex interplay of factors contributing to frailty in this population.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the feature selection process was developed using an in-house program based on SciKit and PDPBox. However, the availability of this specific code for public use is not mentioned. The machine learning models employed in this study utilized gradient-boosted multivariate regression (GBM), a widely recognized method in the field of machine learning. While the specific implementations and scripts used for the GBM models are not detailed, the underlying algorithms are well-documented in the literature and can be accessed through various machine learning libraries.\n\nThe study does not provide information on the release of an executable, web server, virtual machine, or container instance for running the algorithm. Therefore, it is not possible to specify how or where these tools might be accessed by the public. The focus of the publication is on the methodological approach and the results obtained, rather than the distribution of the software tools used in the analysis.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure internal and external validity. The algorithms were built using a machine learning technique that minimizes error and overfitting by leveraging results from multiple individual models. This approach, known as gradient-boosted multivariate regression (GBM), is an ensemble machine learning method that optimizes accuracy.\n\nTo further enhance model interpretation and reduce overfitting, the algorithms were trained and tested on the 10 features with the strongest classification values, determined by the mutual information criterion. This step ensures that the model focuses on the most relevant predictors.\n\nAdditionally, 5-fold cross-validation was employed, consisting of 25 total validation trials. This process involved dividing the data into five subsets, training the model on four subsets, and validating it on the remaining subset. This procedure was repeated five times, with each subset serving as the validation set once. The average F1 score across these trials was used as the final measure of model performance. The F1 score, which balances precision and sensitivity, was chosen because it is appropriate for unbalanced datasets and helps avoid the accuracy paradox.\n\nSeparate GBMs were implemented to establish classification algorithms built from linear versus interactive features. The performance of these models was compared to logistic regression models, which were built using a two-step procedure. The first step ranked the relative importance of features according to posterior probabilities, and the second step examined the average F1 score using the 10 input features with the highest coefficient strengths identified in the first step. This comparison helped validate the effectiveness of the GBM approach.",
  "evaluation/measure": "The performance of the models was primarily evaluated using the F1 score, which is a harmonic mean of precision and sensitivity. This metric is particularly suitable for unbalanced datasets, as it provides a balance between the positive predictive value (precision) and the proportion of true positives correctly identified (sensitivity). The F1 score was chosen to avoid the accuracy paradox, which can inflate model performance in unbalanced designs.\n\nIn addition to the F1 score, precision and sensitivity were also reported. Precision indicates the proportion of true positive predictions among all positive predictions made by the model, while sensitivity (also known as recall) measures the proportion of true positives correctly identified out of all actual positives.\n\nThe models were evaluated using 5-fold cross-validation, which involved 25 total validation trials. This approach helps to ensure that the model's performance is robust and generalizable. The average F1 score across these trials was used as the final measure of model performance.\n\nThe use of the F1 score, precision, and sensitivity aligns with common practices in the literature, especially for classification tasks involving imbalanced datasets. These metrics provide a comprehensive view of the model's performance, highlighting its ability to correctly identify positive cases while minimizing false positives.",
  "evaluation/comparison": "In our study, we compared the performance of our gradient-boosted multivariate regression (GBM) models with logistic regression, a widely used and publicly available method. This comparison was conducted to evaluate the effectiveness of our approach against a simpler baseline.\n\nThe logistic regression models were built using a two-step procedure. First, we ranked the relative importance of features according to posterior probabilities. Then, we examined the average F1 score using the 10 input features with the highest coefficient strengths identified in the first step. This process ensured a fair comparison by using a similar number of features as in our GBM models.\n\nThe results showed that the GBM models outperformed the logistic regression models. The linear GBM achieved an F1 score of 71%, with precision of 84% and sensitivity of 66%. The interactive GBM, which included 2-way interactions, also achieved an F1 score of 71%, with precision of 89% and sensitivity of 64%. In contrast, the logistic regression yielded an average F1 score of 57%, with precision of 69% and sensitivity of 53%.\n\nThis comparison demonstrates that our GBM models, which leverage ensemble machine learning and can capture both linear and interactive features, provide a more accurate classification of frailty in older individuals living with HIV. The superior performance of the GBM models highlights their potential for developing more effective clinical strategies to improve long-term health in this population.",
  "evaluation/confidence": "The evaluation of our models included several steps to ensure confidence in the results. We used 5-fold cross-validation, which involved 25 total validation trials, to calculate the average F1 score as the final measure of model performance. This approach helps to provide a more robust estimate of the model's performance by reducing the variance and providing a better indication of how the model will generalize to an independent dataset.\n\nThe F1 score, which represents the harmonic balance between precision and sensitivity, was used as the primary performance metric. This metric is particularly appropriate for unbalanced datasets, which are prone to inflate model performance when examined using accuracy derived from receiver operator curves, a phenomenon known as the accuracy paradox.\n\nThe linear Gradient-Boosted Multivariate Regression (GBM) model classified participants as frail or nonfrail with an F1 score of 71%, with precision at 84% and sensitivity at 66%. The GBM model allowing 2-way interactions yielded a similar classification performance, with an F1 score of 71%, precision at 89%, and sensitivity at 64%. These results indicate that the models have a good balance between precision and sensitivity, suggesting reliable performance.\n\nIn comparison, logistic regression yielded an average F1 score of 57%, with precision at 69% and sensitivity at 53%. This marked difference in performance highlights the superiority of the GBM models over logistic regression for this classification task.\n\nWhile specific confidence intervals for the performance metrics were not explicitly stated, the use of cross-validation and the consistent performance across multiple trials provide a strong indication of the models' reliability. The statistical significance of the results is implied by the consistent performance metrics across validation trials and the clear superiority of the GBM models over logistic regression.",
  "evaluation/availability": "Not enough information is available."
}