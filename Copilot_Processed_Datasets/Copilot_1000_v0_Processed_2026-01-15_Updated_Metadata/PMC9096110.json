{
  "publication/title": "Ensemble-AHTPpred: A Robust Ensemble Machine Learning Model Integrated With a New Composite Feature for Identifying Antihypertensive Peptides.",
  "publication/authors": "Lertampaiporn S, Hongsthong A, Wattanapornprom W, Thammarongtham C",
  "publication/journal": "Frontiers in genetics",
  "publication/year": "2022",
  "publication/pmid": "35571042",
  "publication/pmcid": "PMC9096110",
  "publication/doi": "10.3389/fgene.2022.883766",
  "publication/tags": "- Computational Genomics\n- Machine Learning\n- Antihypertensive Peptides\n- Ensemble Learning\n- Feature Engineering\n- Bioinformatics\n- Predictive Modeling\n- Peptide Identification\n- Hypertension Treatment\n- Nutraceuticals",
  "dataset/provenance": "Two nonredundant datasets were employed in this study. The first dataset was a benchmarking dataset, which contained 913 unique antihypertensive peptides (AHTPs) and 913 unique non-AHTPs. The AHTPs in this dataset were experimentally validated and sourced from the publicly available AHTPDB and BIOPEP databases. The non-AHTPs were random peptides generated from Swiss-Prot proteins, a standard procedure in many peptide-based prediction methods.\n\nThe second dataset was an independent testing dataset, composed of 386 nonredundant, experimentally validated AHTPs and 386 random peptides generated from Swiss-Prot as negative samples. The AHTPs in this dataset were sourced from recent studies.\n\nBoth datasets were used to train and evaluate the performance of the ensemble model for AHTP prediction. The benchmarking dataset was used for initial training and validation, while the independent testing dataset was used to assess the model's generalization performance on new, unseen data.",
  "dataset/splits": "Two nonredundant datasets were employed in this study. The first dataset was a balanced benchmarking dataset, which contained 913 unique AHTPs and 913 unique non-AHTPs. The second dataset was an independent testing dataset, composed of 386 nonredundant, experimentally validated AHTPs and 386 random peptides generated from Swiss-Prot as negative samples.\n\nThe AHTPs in the benchmarking dataset have a length between 5 and 81 amino acids, with an average length of 7.7 amino acids. The non-AHTPs in the benchmarking dataset have a length between 5 and 45, with an average length of eight amino acids.\n\nThe AHTPs in the independent testing dataset have a length between 5 and 24 amino acids, with an average length of 6.48 amino acids. The non-AHTPs in the independent testing dataset have a length between 5 and 29, with an average length of 15.42 amino acids.",
  "dataset/redundancy": "Two nonredundant datasets were employed in this study. The first dataset was a balanced benchmarking dataset, containing 913 unique antihypertensive peptides (AHTPs) and 913 unique non-AHTPs. The AHTPs were experimentally validated, while the non-AHTPs were random peptides generated from Swiss-Prot proteins. The second dataset was an independent testing dataset, composed of 386 nonredundant, experimentally validated AHTPs and 386 random peptides generated from Swiss-Prot as negative samples.\n\nThe benchmarking dataset was used for training and initial evaluation, while the independent testing dataset was used to assess the model's performance on unseen data. This split ensures that the training and test sets are independent, preventing data leakage and providing a more reliable evaluation of the model's generalization performance.\n\nThe distribution of peptide lengths in the datasets is similar to that of previously published machine learning datasets for peptide prediction. In the benchmarking dataset, AHTPs have a length between 5 and 81 amino acids, with an average length of 7.7 amino acids, while non-AHTPs have a length between 5 and 45 amino acids, with an average length of eight amino acids. In the independent testing dataset, AHTPs have a length between 5 and 24 amino acids, with an average length of 6.48 amino acids, and non-AHTPs have a length between 5 and 29 amino acids, with an average length of 15.42 amino acids. This similarity in distribution allows for a fair comparison with other methods.",
  "dataset/availability": "The original contributions presented in the study are included in the article and supplementary material. Further inquiries can be directed to the corresponding author. The data, trained models, and standalone program are available to download at a specified website. This ensures that the datasets used for training and testing the models are accessible to the public, promoting transparency and reproducibility. The availability of these resources allows other researchers to validate the findings and potentially build upon the work. The data is made available under the terms specified by the corresponding author, ensuring that users adhere to the appropriate usage guidelines.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages ensemble learning, which is a well-established class of machine-learning algorithms. Ensemble methods combine multiple base classifiers to improve overall performance and robustness. Specifically, our ensemble model integrates three distinct algorithms: extreme gradient boosting (XGB), random forest (RF), and support vector machine (SVM). These algorithms were selected based on their superior performance during the training process, as evaluated through various metrics such as accuracy, sensitivity, and the area under the receiver operating characteristic curve (AUC).\n\nThe algorithms used in our ensemble are not new; they are widely recognized and utilized in the machine-learning community. XGB is a gradient boosting algorithm known for its efficiency and effectiveness in handling structured/tabular data. RF is a bagging ensemble algorithm that builds multiple decision trees and merges them to get a more accurate and stable prediction. SVM is a powerful supervised learning model that is effective in high-dimensional spaces and can handle both classification and regression tasks.\n\nThe reason these algorithms were not published in a machine-learning journal is that they are established methods that have already been extensively documented and validated in the literature. Our work focuses on applying these well-known algorithms to a specific problem\u2014predicting antihypertensive peptides (AHTPs)\u2014rather than developing new machine-learning algorithms. The novelty of our study lies in the application of these algorithms to a particular biological problem, the development of a new composite feature (comF2) to improve sensitivity, and the integration of these algorithms into an ensemble model tailored for AHTP prediction.",
  "optimization/meta": "The model employs an ensemble approach, utilizing multiple machine-learning algorithms to enhance predictive performance. Specifically, the ensemble consists of three primary models: Support Vector Machine (SVM), Random Forest (RF), and Extreme Gradient Boosting (XGB). These models were selected based on their superior performance across various metrics during the evaluation phase.\n\nThe SVM model uses a distinct set of input features, which were refined through Recursive Feature Elimination (RFE) to reduce redundancy and improve computational efficiency. In contrast, the RF and XGB models utilize the complete 379-feature vector, leveraging their built-in feature selection capabilities.\n\nEach model is assigned a weight proportional to its classification accuracy across all classes. Additionally, the models' capacities for classification and prediction may vary across different classes. Therefore, the classifier with the highest prediction confidence for a particular class is given greater weight for that class.\n\nThe training process involves 10-fold cross-validation to determine the optimal class weights for each classifier in the ensemble. Subsequently, the individual classifiers are aggregated through weighted voting to obtain the final probability and prediction.\n\nThe ensemble model also incorporates composite features, created using logistic regression equations, to improve sensitivity. These composite features, referred to as comF and comF2, are merged into the feature vector as inputs to the ensemble model. The comF2 feature, in particular, has been identified as highly significant in enhancing the model's predictive performance.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure that the machine-learning algorithms could effectively learn from the peptide sequences. We began by extracting a comprehensive set of numerical features to represent the peptide sequences. Initially, we gathered 431 features that could potentially explain the characteristics of antihypertensive peptides (AHTPs). However, not all of these features were relevant or informative for our classification task.\n\nTo address this, we employed a feature selection procedure based on ReliefF scores. This method evaluated how well each feature could distinguish between instances that were near each other, thereby selecting features that aided in the separation of samples from different classes. Features with scores higher than a predefined cutoff were retained, resulting in a reduced set of 379 features. This filtering step helped eliminate irrelevant features and mitigate the curse of dimensionality, which can hinder the performance of machine-learning models.\n\nAdditionally, we used recursive feature elimination (RFE) as a wrapper-type feature selection algorithm for the support vector machine (SVM) model. RFE starts with all features and recursively removes the least relevant ones, refitting the model until the optimal number of features is reached. This process ensured that the SVM model could achieve high performance with a reduced feature set.\n\nFor the random forest (RF) and extreme gradient boosting (XGB) models, we utilized their built-in feature selection capabilities. These models can handle a large number of features and automatically select the most relevant ones during the training process. Therefore, we used the complete 379-feature vector as input for these models.\n\nFurthermore, we created composite features using logistic regression equations. These composite features, such as comF and comF2, were derived from the fusion of two or more existing features. The composite features were then merged into the feature vector as input for the ensemble model. This approach helped improve the sensitivity of our method by capturing unique relationships between features and the target class.\n\nIn summary, our data encoding and preprocessing involved extracting a large set of numerical features, applying ReliefF-based feature selection, using RFE for the SVM model, and creating composite features. These steps ensured that our machine-learning algorithms could effectively learn from the peptide sequences and achieve high classification performance.",
  "optimization/parameters": "In our ensemble model, we utilized a total of 379 features as input parameters for the random forest (RF) and extreme gradient boosting (XGB) algorithms. These algorithms have built-in feature selection capabilities, allowing them to handle the complete feature set effectively.\n\nFor the support vector machine (SVM) model, we employed recursive feature elimination (RFE) as an additional wrapper feature selection step. This process helped to remove redundant features and reduce computational time and memory. As a result, the feature subset used as the input vector for the SVM model was reduced from 379 to 256 attributes.\n\nThe selection of these features was based on a comprehensive feature extraction process, where we initially collected 431 numerical features to represent peptide sequences. Feature selection was crucial to eliminate irrelevant and non-informative features, thereby mitigating the curse of dimensionality and preventing overfitting. The ReliefF score was used as a preprocessing step to filter out irrelevant features, ensuring that only the most relevant and discriminative features were retained for model training.",
  "optimization/features": "In our study, we initially extracted a total of 431 numerical features to represent peptide sequences. However, not all of these features were relevant or informative for explaining the target class. To address this, we employed a feature selection procedure based on ReliefF scores as a preprocessing step. This filtering method helped us remove irrelevant features by evaluating how well each feature could distinguish between instances that were near each other. Features that aided in the separation of samples from different classes were given higher weights.\n\nAfter applying the filtering method, we retained 379 features that had scores higher than the cutoff score. These 379 features were then used to train our models. It is important to note that the feature selection process was performed using the training set only, ensuring that the selected features were not influenced by the test data.\n\nFor the support vector machine (SVM) model, we took an additional step of feature selection using recursive feature elimination (RFE). This wrapper-type feature selection algorithm further reduced the feature subset used as the input vector for the SVM model from 379 to 256 attributes. This step helped to remove redundant features and reduce computational time and memory.\n\nIn summary, we used 379 features as input for most of our models, except for the SVM model, which used a reduced set of 256 features after additional feature selection with RFE. The feature selection process was conducted using the training set only, ensuring the integrity of our model evaluation.",
  "optimization/fitting": "The ensemble model developed in this work integrates three machine learning algorithms: XGB, RF, and SVM. The number of features initially extracted was 431, which is relatively large compared to the number of training points. To mitigate the risk of overfitting, several strategies were employed.\n\nFirstly, feature selection was performed to eliminate irrelevant and redundant features. For the SVM model, Recursive Feature Elimination (RFE) was used as an additional wrapper feature selection step, reducing the feature subset from 379 to 256 attributes. This step helped in removing redundant features and reducing computational time and memory.\n\nSecondly, the models were trained using 10-fold cross-validation. This technique ensures that each model is trained and validated on different subsets of the data, providing a robust estimate of model performance and helping to prevent overfitting.\n\nAdditionally, the ensemble method itself helps to reduce overfitting. By combining the predictions of multiple models, the ensemble approach leverages the strengths of each individual model while mitigating their weaknesses. The individual classifiers were aggregated through weighted voting, where each model's weight was proportional to its classification accuracy across all classes. This weighted voting mechanism further enhances the model's generalization performance.\n\nTo address underfitting, the models were carefully selected based on their diverse measurements and performance on the benchmarking dataset. The best-performing models were chosen as the base classifiers for the ensemble. Furthermore, the training process involved iterative training to find the optimal weight for each class of each classifier, ensuring that the models were adequately capturing the underlying patterns in the data.\n\nThe use of composite features, such as comF and comF2, also contributed to improving the model's sensitivity and reducing the false positive rate. These composite features were created using logistic regression, which helped in determining unique relationships between a large number of features and the target class.\n\nIn summary, the combination of feature selection, 10-fold cross-validation, ensemble learning, and the use of composite features ensured that the model was neither overfitting nor underfitting the data. The ensemble approach provided a balanced and robust solution for predicting AHTPs.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our ensemble model. One of the primary methods used was 10-fold cross-validation. This technique involves dividing the dataset into 10 subsets, training the model on 9 of these subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. This approach helps in assessing the model's performance more reliably and reduces the risk of overfitting to a specific subset of the data.\n\nAdditionally, we utilized feature selection methods to mitigate overfitting. For the Support Vector Machine (SVM) model, we applied Recursive Feature Elimination (RFE) as a wrapper feature selection step. This method iteratively removes the least significant features and rebuilds the model, thereby reducing the dimensionality of the feature space and eliminating redundant features. This not only improves computational efficiency but also helps in preventing overfitting by focusing on the most relevant features.\n\nThe ensemble model itself is designed to reduce overfitting by combining the predictions of multiple base classifiers\u2014SVM, Random Forest (RF), and Extreme Gradient Boosting (XGB). Each of these models has its strengths and weaknesses, and by aggregating their predictions through weighted voting, we achieve a more generalized and robust model. The weights assigned to each model are proportional to their classification accuracy across all classes, ensuring that the most reliable models have a greater influence on the final prediction.\n\nFurthermore, the use of composite features, such as comF and comF2, which are derived from logistic regression, helps in capturing the unique relationships between features and the target class. These composite features are selected based on their sensitivity and are merged into the feature vector, enhancing the model's ability to generalize to new, unseen data.\n\nIn summary, our approach to preventing overfitting includes the use of cross-validation, feature selection, and an ensemble of diverse models. These techniques collectively contribute to the development of a model that is both accurate and generalizable.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters for the models used in our study are reported. Specifically, for the Random Forest (RF) algorithm, the number of estimators was set to 350 and the maximum depth to 12. For the XGBoost (XGB) algorithm, the number of estimators (nrounds) was set to 800, the maximum depth to 10, the learning rate (eta) to 0.01, and the subsample to 0.8.\n\nThe trained models, along with the standalone program and all the data, are available for download. This can be accessed at the provided URL. The program was implemented using Perl, Python, and R scripts and was run on a Fedora Linux-based machine. The availability of these resources ensures reproducibility and allows other researchers to utilize the models and data for further studies.",
  "model/interpretability": "The model employed in this study is not a black-box model. To ensure interpretability, we utilized SHAP (Shapley Additive exPlanations) values, which provide a consistent and reliable way to explain the output of machine learning models. SHAP values correlate optimal credit allocation with local explanations, offering insights into how each feature contributes to the model's predictions.\n\nThe SHAP summary plot, for instance, reveals that the composite feature comF2 was the most significant feature, followed by Pse_SC13 and QSO35. Each dot in the SHAP plot represents a sample from the data, with the color of the dot indicating the value of the associated feature. The x-axis shows the feature's influence on the model's prediction, and the high spread of comF2 suggests that it captures and provides more useful information to the model.\n\nAdditionally, the partial dependence plot (PDP) of comF2 illustrates the impact of this feature on the predicted outcome, allowing for a better understanding of its interdependence with the target class. The PDP shows that higher values of comF2 increase the likelihood of a sample being classified into the AHTP class.\n\nThe distribution of the top six features, including comF2, further highlights the differences between the AHTP and non-AHTP classes. The substantial distribution difference observed in the histogram of comF2 indicates its importance in the model's predictions. The functionality of comF2 can be enhanced, leading to improved prediction performance.\n\nIn summary, the use of SHAP values and PDPs provides clear examples of how the model's predictions can be interpreted, making it transparent and understandable.",
  "model/output": "The model is a classification model. It is designed to predict whether a given sample belongs to the class of antihypertensive peptides (AHTP) or not. The ensemble model combines the predictions of three base classifiers\u2014Support Vector Machine (SVM), Random Forest (RF), and Extreme Gradient Boosting (XGB)\u2014using weighted voting to produce the final classification output. The weights assigned to each classifier are proportional to their classification accuracy across all classes, and the classifier with the highest prediction confidence for a particular class is given greater weight. The model's performance is evaluated using metrics such as accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). The ensemble approach aims to leverage the strengths of different algorithms to improve the overall classification performance.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the proposed method is not publicly released. However, the trained models and a standalone program are available for download. The program was implemented using Perl, Python, and R scripts and can be run on a Fedora Linux-based machine. The data, trained models, and standalone program can be accessed at http://ncrna-pred.com/Ensemble_AHTPpred.htm. The availability of the trained models and standalone program allows users to apply the ensemble model for AHTP prediction without needing access to the source code.",
  "evaluation/method": "The evaluation of the proposed method involved several steps to ensure its robustness and accuracy. Initially, a 10-fold cross-validation was performed on a benchmarking dataset to assess the classification performance of different trained models. This process helped in detecting and combining the strengths of distinct algorithms to form a resilient and stable ensemble.\n\nThe method was further evaluated using an independent testing dataset, which consisted of nonredundant, experimentally validated AHTPs and random peptides generated from Swiss-Prot as negative samples. This evaluation showed that the method achieved an accuracy of 90.4%, outperforming other existing prediction tools.\n\nAdditionally, the method's generalization performance and robustness were assessed using novel AHTPs from recent studies. These peptides, which did not overlap with the training data, were correctly classified with an accuracy of 80%. This demonstrated the method's ability to handle new, unseen data effectively.\n\nThe performance of the method was also compared with existing prediction tools using metrics such as accuracy, sensitivity, specificity, Matthews correlation coefficient, and the area under the receiver operating characteristic curve. The results indicated that the proposed method achieved improved sensitivity and reduced the false positive rate in predicting AHTPs.",
  "evaluation/measure": "In our evaluation, we employed several key performance metrics to comprehensively assess the effectiveness of our ensemble model. These metrics include accuracy (ACC), sensitivity (Sn), specificity (Sp), Matthew's correlation coefficient (MCC), and the area under the receiver operating characteristic curve (AUC).\n\nAccuracy measures the overall correctness of the model by calculating the proportion of true positive and true negative predictions out of the total number of predictions. Sensitivity, also known as recall, evaluates the model's ability to correctly identify positive instances, which is crucial for identifying antihypertensive peptides (AHTPs). Specificity assesses the model's ability to correctly identify negative instances, ensuring that non-AHTPs are accurately classified. Matthew's correlation coefficient provides a balanced measure of the quality of binary classifications, considering both sensitivity and specificity. The AUC metric offers a single scalar value that summarizes the performance of the model across all classification thresholds, providing a comprehensive view of the model's ability to distinguish between positive and negative classes.\n\nThese metrics are widely used in the literature and provide a robust framework for evaluating the performance of classification models. By reporting these metrics, we ensure that our evaluation is representative and comparable to other studies in the field. This comprehensive set of metrics allows for a thorough assessment of our model's strengths and areas for improvement, ensuring that it meets the high standards required for reliable AHTP prediction.",
  "evaluation/comparison": "In the evaluation of our proposed method, a comprehensive comparison was conducted with publicly available prediction tools using benchmark datasets. Specifically, we utilized the benchmarking dataset and the independence testing dataset to assess the performance of our ensemble method against existing techniques. The benchmarking dataset consisted of 913 unique antihypertensive peptides (AHTPs) and 913 unique non-AHTPs, while the independence testing dataset included 386 nonredundant, experimentally validated AHTPs and 386 random peptides generated from Swiss-Prot as negative samples.\n\nOur ensemble method achieved an accuracy of 85.8% on the benchmarking dataset, outperforming most of the other methods. Notably, while the CNN + SVM technique surpassed our ensemble for the training dataset, our ensemble performed substantially better on the independent dataset, achieving an accuracy of 90.4%. This indicates that our method not only performs well on the training data but also generalizes effectively to unseen data.\n\nThe comparison included methods such as CNN + SVM, mAHTPred, PAAP, AHTpin_AAC, and AHTpin_ATC. The results, as shown in the respective tables, demonstrate that our ensemble method consistently achieved higher accuracy, sensitivity, specificity, Matthews correlation coefficient (MCC), and area under the curve (AUC) compared to these existing methods. This thorough evaluation underscores the robustness and accuracy of our proposed ensemble model in predicting AHTPs.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files, including the data, trained models, and the standalone program, are available for download. The resources can be accessed at the provided URL. The data and models are intended for further research and validation by the scientific community. The availability of these resources supports reproducibility and encourages further development in the field of antihypertensive peptide prediction. The specific URL for accessing these resources is http://ncrna-pred.com/Ensemble_AHTPpred.htm."
}