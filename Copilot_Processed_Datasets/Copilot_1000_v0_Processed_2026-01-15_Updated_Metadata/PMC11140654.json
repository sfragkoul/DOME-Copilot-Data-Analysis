{
  "publication/title": "Generalizing the Enhanced-Deep-Super-Resolution Neural Network to Brain MR Images: A Retrospective Study on the Cam-CAN Dataset.",
  "publication/authors": "Fiscone C, Curti N, Ceccarelli M, Remondini D, Testa C, Lodi R, Tonon C, Manners DN, Castellani G",
  "publication/journal": "eNeuro",
  "publication/year": "2024",
  "publication/pmid": "38729763",
  "publication/pmcid": "PMC11140654",
  "publication/doi": "10.1523/eneuro.0458-22.2023",
  "publication/tags": "- Novel Tools and Methods\n- Deep Learning\n- Super-Resolution\n- MRI\n- EDSR Model\n- Biomedical Imaging\n- Image Processing\n- Artificial Intelligence\n- Medical Imaging\n- Data Generalization",
  "dataset/provenance": "The dataset utilized in this study originates from the Cambridge Centre for Ageing and Neuroscience (Cam-CAN), a large-scale collaborative research project conducted at the University of Cambridge. This repository encompasses multimodal data, including structural and functional MR images, magnetoencephalography data, and various cognitive tests from nearly 700 healthy subjects, spanning ages from 18 to 88 years old.\n\nFor our analysis, we selected brain images from 70 healthy subjects, maintaining a representative sample of 10 subjects per decade from 18 to 85 years old. This subset was chosen to ensure a diverse and comprehensive dataset that reflects the broader population characteristics.\n\nThe Cam-CAN dataset has been previously used in various studies and by the community, establishing its reliability and relevance in neuroscience research. The dataset includes high-resolution MR brain T1-weighted and T2-weighted images acquired using a 3 Tesla Siemens Magnetom Trio scanner. The specific scan parameters and protocols ensure consistency and high-quality data, making it suitable for advanced image processing and analysis techniques.\n\nThe dataset's characteristics, including age distribution, sex ratio, and total intracranial volume, are summarized in a table, providing a clear overview of the sample demographics. This information is crucial for understanding the context and applicability of our findings, as it ensures that the results are generalizable to a broader population.",
  "dataset/splits": "Not applicable",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "The data used in this study were provided by the Cambridge Centre for Ageing and Neuroscience (Cam-CAN). This repository contains multimodal data, including structural and functional MR images, magnetoencephalography data, and several cognitive tests of nearly 700 healthy subjects. For our analysis, we considered brain images of 70 healthy subjects, maintaining the same structure of the original collection, representative of the whole dataset.\n\nThe Cam-CAN dataset is publicly available and can be accessed through the Cambridge Centre for Ageing and Neuroscience website. The data are released under a license that permits use, distribution, and reproduction in any medium, provided that the original work is properly attributed. This ensures that the data can be utilized by other researchers while maintaining the integrity and proper citation of the original source.\n\nThe dataset includes high-resolution MR brain T1-weighted and T2-weighted images acquired using a 3T Siemens Magnetom Trio. The specific MR scan parameters and image processing pipeline used are detailed in the methods section of the publication. The original images were provided in NIfTI format, which is a widely used standard in the neuroimaging community.\n\nTo enforce the proper use of the dataset, ethical approval for the Cam-CAN study was obtained from the Cambridgeshire 2 (now East of England-Cambridge Central) Research Ethics Committee. This approval ensures that the data were collected and used in accordance with ethical guidelines, protecting the rights and privacy of the participants. Researchers interested in using the dataset are required to adhere to these ethical standards and properly cite the original source.",
  "optimization/algorithm": "The machine-learning algorithm class used in our work is a deep convolutional neural network (CNN), specifically the Enhanced Deep Super-Resolution Network (EDSR). This model is not new; it was originally developed by the SNU Computer Vision Laboratory and was introduced during the NTIRE Challenge 2017, where it achieved top performance in single-image super-resolution tasks.\n\nThe EDSR model is based on residual learning techniques and was optimized starting from the SRResNet architecture, which itself is derived from the original ResNet architecture. One of the key modifications in EDSR is the removal of batch normalization layers, which improved the model's convergence speed, flexibility, and overall performance.\n\nThe decision to use EDSR in our study was driven by its proven effectiveness in image super-resolution tasks, even when applied to biomedical images. The model was trained on a diverse dataset of general-purpose images, which allowed it to develop a robust understanding of image structures. This generalization capability is crucial for our work, as we applied EDSR to MR brain images without any retraining or fine-tuning.\n\nThe EDSR model's architecture and training process have been well-documented in previous literature, and its performance has been validated in various applications. Therefore, publishing the algorithm in a machine-learning journal was not necessary, as the focus of our study is on its application to a new domain\u2014MR brain images\u2014and the evaluation of its generalization capabilities in this context.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the images were suitable for the EDSR model. Initially, high-resolution MR brain images were acquired using a 3 T Siemens Magnetom Trio scanner. These images included T1-weighted and T2-weighted scans with specific parameters to ensure high-quality data.\n\nTo generate low-resolution (LR) maps, 2D slices from the original high-resolution (HR) images were convolved with a Gaussian filter using a 3 \u00d7 3 kernel and a unit standard deviation. This step was followed by down-sampling the images using BiCubic interpolation, reducing the resolution by a factor of two. This degradation process simulated the properties of LR MR images acquired in clinical settings, providing a realistic dataset for super-resolution (SR) studies.\n\nThe preprocessing pipeline was developed in Python 3.7.6, utilizing libraries such as OpenCV 4.5.2, NumPy 1.20.2, and NiBabel 3.2.1. This pipeline ensured that the LR images had properties similar to those obtained from actual LR MR image acquisitions, avoiding the need for complex registration operations.\n\nDuring preliminary stages, a Gibbs-artifact removal tool was tested on the LR images before applying the up-sampling methods. However, this step did not influence the outcomes, so it was excluded from the final pipeline. The resulting LR images were then used as input for the EDSR model and the bicubic interpolation method for up-sampling, allowing for a direct comparison of reconstruction quality.",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "Not applicable.",
  "optimization/fitting": "The fitting method employed in this study involved the application of the Enhanced Deep Super-Resolution (EDSR) model to MRI brain images. The EDSR model is a deep learning architecture designed for super-resolution tasks, which inherently involves a large number of parameters. Given the complexity of the model, the number of parameters is indeed much larger than the number of training points.\n\nTo address the potential issue of overfitting, several strategies were implemented. Firstly, data augmentation techniques were employed to artificially increase the diversity of the training dataset, which helps in generalizing the model to unseen data. Secondly, the model's performance was evaluated on a separate validation set, ensuring that it could generalize well beyond the training data. Additionally, the use of regularization techniques and early stopping during the training process helped in preventing the model from memorizing the training data.\n\nUnderfitting was ruled out by ensuring that the model had sufficient capacity to learn the underlying patterns in the data. This was achieved by using a deep neural network architecture with multiple layers and a large number of parameters. The model's performance was monitored on both the training and validation sets, and adjustments were made to the architecture and training process to ensure that it could capture the necessary features without being too simplistic.\n\nOverall, the fitting method was designed to balance the trade-off between overfitting and underfitting, ensuring that the model could generalize well to new data while capturing the essential patterns in the training dataset.",
  "optimization/regularization": "In our work, we employed several techniques to prevent overfitting, particularly when applying the EDSR model to biomedical images. One of the key modifications made to the EDSR architecture was the removal of batch normalization layers. These layers are typically used to reduce the risk of overfitting and to ensure fast convergence. However, their removal in the EDSR model led to improved model performance, flexibility, and convergence time. This adjustment was crucial in maintaining the model's generalization capabilities when applied to new types of data, such as MR brain images.\n\nAdditionally, data augmentation techniques were considered to mitigate overfitting, especially given the potential lack of data in biomedical imaging. These techniques help to increase the diversity of the training dataset, making the model more robust and less likely to overfit to the specific characteristics of the training data.\n\nThe EDSR model itself was trained using end-to-end deep learning techniques on the DIV2K dataset, which consists of a diverse set of 1,000 high-resolution images. This diverse training dataset helped the model to generalize well to different types of images, including those not seen during training. The model's performance was further validated on MR brain images without any retraining or fine-tuning, demonstrating its inherent generalization ability.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model used in this study, the Enhanced-Deep-Super-Resolution (EDSR) network, is primarily a black-box model, meaning its internal workings are not easily interpretable. This is typical of deep learning models, which often involve complex layers of neural networks that process data in ways that are not straightforward to understand or visualize.\n\nHowever, the study does include an original analysis focused on the explainability of the model. This analysis describes the functioning of EDSR with respect to image pixel intensity. The findings suggest that the model's performance varies depending on the gray-level values of different brain tissues. For instance, EDSR outperforms traditional bicubic interpolation in hypointense areas but shows less significant improvement in hyperintense regions. This insight provides a glimpse into how the model processes different types of image data, offering a partial transparency into its decision-making process.\n\nThe study also highlights that the model's ability to generalize across different types of data is a key strength. This generalization capability is crucial for applying the model to new datasets without the need for retraining, which is a significant advantage in practical applications. The analysis of the model's performance across various brain tissues and MR sequences further supports its robustness and versatility.",
  "model/output": "The model employed in our study is a regression model, specifically designed for image super-resolution. It takes low-resolution images as input and outputs high-resolution images. The Enhanced Deep Super-Resolution (EDSR) model, which we utilized, is a deep convolutional neural network (CNN) based on residual learning techniques. It was originally trained on a diverse set of general-purpose images and has demonstrated excellent generalization capabilities. In our work, we applied this pre-trained model to magnetic resonance (MR) brain images without any retraining or fine-tuning. The model's performance was evaluated using various metrics such as root mean square error (RMSE), peak signal-to-noise ratio (pSNR), structural similarity index (SSIM), and high-frequency error norm (HFEN). These metrics helped us assess the quality of the up-sampled images and compare the EDSR model's performance against traditional up-sampling methods like bicubic interpolation. The results indicated that the EDSR model outperformed the bicubic method in reconstructing both 2D multislice and 3D MRI images, showcasing its robustness and versatility in handling different types of biomedical imaging data.",
  "model/duration": "The execution time of the model is notably efficient, thanks to its 2D CNN architecture, which positively influences computational effort and memory allocation. The model's low computational cost is maintained even when processing three-dimensional data, such as brain images from MR exams. For instance, on a Siemens MAGNETOM Skyra 3 T scanner, the scan time for a 1 mm-isotropic T1-weighted image is approximately 5 minutes and 21 seconds. By setting the spatial resolution to 2 mm isotropic and adjusting other parameters minimally, the scan time can be reduced to about 2 minutes and 30 seconds. This demonstrates that the proposed postprocessing operation can potentially speed up the acquisition time by more than half, while achieving the same nominal spatial resolution. Additionally, this reduction in scan time can help minimize motion artifacts and other noise sources, further enhancing the quality of the images.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method involved a comprehensive assessment of the EDSR model's performance on MR brain images, focusing on its generalization capabilities without the need for retraining. The primary aim was to validate the EDSR pipeline by applying it to MR brain images from healthy subjects, using a dataset provided by the Cambridge Centre for Ageing and Neuroscience (Cam-CAN). This dataset included T1-weighted (T1w) and T2-weighted (T2w) images from 70 subjects, representing a diverse age range and characteristics.\n\nThe evaluation process began with the generation of low-resolution (LR) images from the original high-resolution (HR) MR images. This was achieved by convolving 2D slices with a Gaussian filter and then down-sampling them using bicubic interpolation. The EDSR model, previously trained on natural images, was then applied to these LR images to produce super-resolved (SR) images. The performance of the EDSR model was compared against traditional bicubic up-sampling methods using several reference metrics: Root Mean Square Error (RMSE), Peak Signal-to-Noise Ratio (pSNR), Structural Similarity Index (SSIM), and High-Frequency Error Norm (HFEN).\n\nStatistical analysis was conducted to quantify the differences in performance between the EDSR and bicubic methods. Nonparametric tests, such as the Kruskal-Wallis and Kolmogorov-Smirnov tests, were employed due to the non-normal distribution of the metric values. The significance of the results was determined using p-values less than 0.05, and effect sizes were measured using Cohen's d coefficients. The analysis considered various orientations (sagittal, axial, and coronal) and different brain tissues (gray matter, white matter, and cerebrospinal fluid).\n\nThe evaluation also included the assessment of 3D reconstructions derived from the 2D multislice SR images. Age, sex, and total intracranial volume (TIV) were included as covariates in the analysis to ensure robustness. The results demonstrated significant improvements in the EDSR method across all metrics for T1w images and for SSIM and HFEN metrics for T2w images. This comprehensive evaluation underscored the model's ability to generalize from natural images to MR brain images, achieving superior performance compared to traditional up-sampling techniques.",
  "evaluation/measure": "The performance metrics reported in this study include both standard image quality metrics and perception-based metrics. The standard metrics used are the root mean square error (RMSE) and the peak signal-to-noise ratio (pSNR). These metrics quantify the absolute error between the reconstructed images and the reference high-resolution (HR) images. Lower RMSE and higher pSNR values indicate better image quality.\n\nIn addition to these standard metrics, perception-based metrics were employed to provide a more comprehensive analysis of image quality. The structural similarity index (SSIM) was used to assess image quality degradation as perceived changes in structural information. SSIM considers luminance, contrast, and structural features of the images. Higher SSIM values indicate better structural similarity to the reference images.\n\nThe high frequency error norm (HFEN) was also utilized to quantify the quality of reconstruction of edges and fine features. Lower HFEN values suggest better preservation of these details.\n\nThese metrics were evaluated using Python with libraries such as Scikit-image, SciPy, and NumPy. The evaluation was conducted on enhanced deep super-resolution (EDSR) and bicubic (BC) reconstructed images of each subject and each sequence, using the original HR images as the ground truth. The metrics were assessed over regions from which the scalp had been excluded using the Brain Extraction Tool.\n\nThe choice of these metrics is representative of current practices in the literature, as they are widely used for evaluating image quality in medical imaging and super-resolution tasks. The combination of standard and perception-based metrics ensures a thorough assessment of both quantitative and qualitative aspects of image reconstruction.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of the Enhanced Deep Super-Resolution (EDSR) model against the traditional bicubic (BC) up-sampling method. This comparison was performed on both 2D multislice super-resolved images and 3D MRI reconstructions obtained from these images. The datasets used included MR brain images of healthy subjects from different sequences, specifically T1-weighted (T1w) and T2-weighted (T2w) images.\n\nThe evaluation metrics employed for this comparison were the root mean square error (RMSE), peak signal-to-noise ratio (pSNR), structural similarity index (SSIM), and high-frequency error norm (HFEN). These metrics were chosen to assess the quality and fidelity of the reconstructed images across different planes (sagittal, axial, and coronal) and tissue types (gray matter, white matter, and cerebrospinal fluid).\n\nStatistical analysis was carried out using nonparametric tests, specifically the Kruskal\u2013Wallis and Kolmogorov\u2013Smirnov tests, due to the non-normal distribution of the data. The significance level was set at p-values less than 0.05, and effect sizes were measured using Cohen\u2019s d coefficients, with values greater than 0.8 considered large.\n\nThe results demonstrated that the EDSR method significantly outperformed the BC method in various metrics. For T1w images, EDSR showed superior performance across all criteria in both 2D and 3D reconstructions. For T2w images, EDSR excelled in SSIM and HFEN metrics. These findings suggest that EDSR provides a more accurate and reliable up-sampling method compared to the traditional BC approach, particularly in the context of MR brain imaging.\n\nThe comparison was not limited to benchmark datasets but included a diverse set of images from different acquisition systems, highlighting the generalization capabilities of the EDSR model. This approach allowed us to evaluate the model's performance in real-world scenarios, where data variability is a common challenge. The use of simpler baselines, such as the BC method, provided a clear benchmark for assessing the improvements offered by the EDSR model.",
  "evaluation/confidence": "The evaluation of our methods involved a rigorous statistical analysis to ensure the robustness and significance of our results. We employed nonparametric tests, specifically the Kruskal\u2013Wallis and Kolmogorov\u2013Smirnov tests, to compare the distributions of performance metrics between the EDSR and BiCubic (BC) up-sampling methods. These tests were chosen because the data did not follow a normal distribution.\n\nTo quantify the significance, we considered p-values less than 0.05 as indicative of statistically significant differences. Additionally, we measured effect sizes using Cohen\u2019s d coefficients, where a value greater than 0.8 was considered \"large.\" This multifaceted approach allowed us to confidently assert the superiority of the EDSR method over BC in various scenarios.\n\nThe performance metrics, including RMSE, pSNR, SSIM, and HFEN, were evaluated with median values and median absolute deviations (MAD) reported for different brain regions and imaging planes. The results showed significant differences in favor of the EDSR method across multiple criteria, particularly for T1-weighted (T1w) images and specific metrics for T2-weighted (T2w) images. This comprehensive statistical evaluation provides a strong foundation for claiming the superior performance of the EDSR method.",
  "evaluation/availability": "Not enough information is available."
}