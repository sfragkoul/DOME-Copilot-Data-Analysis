{
  "publication/title": "Quantification of Head Shape from Three-Dimensional Photography for Presurgical and Postsurgical Evaluation of Craniosynostosis.",
  "publication/authors": "Porras AR, Tu L, Tsering D, Mantilla E, Oh A, Enquobahrie A, Keating R, Rogers GF, Linguraru MG",
  "publication/journal": "Plastic and reconstructive surgery",
  "publication/year": "2019",
  "publication/pmid": "31764657",
  "publication/pmcid": "PMC6905129",
  "publication/doi": "10.1097/prs.0000000000006260",
  "publication/tags": "- Craniosynostosis\n- 3D Photography\n- Head Shape Quantification\n- Surgical Evaluation\n- Machine Learning\n- Support Vector Machine\n- Pre-operative and Post-operative Analysis\n- Normative Statistical Head Shape Model\n- Cranial Bone Metrics\n- Automatic Detection and Classification\n- Cephalic Index\n- Surgical Outcomes\n- Head Malformations\n- Pediatric Surgery\n- Medical Imaging",
  "dataset/provenance": "The dataset used in this study was sourced from retrospective head axial CT images and 3D photographs. The normative population consisted of 201 subjects without cranial pathology, aged between 0 to 6 years. These images were acquired using various CT scanners, including General Electric LightSpeed Ultra and LightSpeed Discovery 690, and Philips Brilliance 40 and Brilliance 64.\n\nFor the patient population, retrospective pre-operative CT images were obtained for 214 patients with craniosynostosis, aged between 0 to 6 years. This group included patients with different types of craniosynostosis, such as sagittal, coronal, and metopic suture fusion, as well as other varieties like multi-suture and pansynostosis.\n\nAdditionally, pre-operative 3D photographs were collected for 52 patients with craniosynostosis, including those with sagittal, coronal, metopic suture fusion, and other types. For 34 of these patients, both pre-operative CT images and 3D photographs were available. The 3D photographs were acquired using the 3DMDhead System.\n\nPost-operative 3D photographs were also collected for 18 patients who had undergone cranial vault reconstruction surgery. These patients had both pre-operative CT images and post-operative 3D photographs available. The surgeries were performed by a combination of neurosurgeons and plastic surgeons at the institution.\n\nThe dataset includes a mix of CT images and 3D photographs, providing a comprehensive set of data for analyzing head shape abnormalities in patients with craniosynostosis. The use of both modalities allows for a detailed comparison and validation of the metrics used in the study.",
  "dataset/splits": "In our study, we utilized multiple data splits to ensure comprehensive analysis and validation of our methods. We had three primary data splits: a normative population, pre-operative patient data, and post-operative patient data.\n\nThe normative population consisted of 201 subjects without cranial pathology. These subjects were used to create a statistical head shape model, providing a baseline for comparison with patient data.\n\nThe pre-operative patient data was further divided into two subsets: CT images and 3D photographs. We obtained pre-operative CT images from 214 patients with craniosynostosis. These images were used to quantify head shape abnormalities and train our classification models. Additionally, we collected pre-operative 3D photographs from 52 patients, which were used to validate the accuracy of 3D photography in quantifying head shape abnormalities. For 34 of these patients, both pre-operative CT images and 3D photographs were available, allowing for direct comparison between the two modalities.\n\nThe post-operative data consisted of 3D photographs from 18 patients who had undergone cranial vault reconstruction surgery. These photographs were used to evaluate the effectiveness of surgical treatments by comparing pre- and post-operative head shape metrics.\n\nThe distribution of data points in each split reflected the diversity of craniosynostosis types and the availability of imaging data. The normative population was balanced in terms of gender, with 89 females and 112 males. The pre-operative CT images included patients with various types of craniosynostosis, such as sagittal, coronal, and metopic suture fusion. The pre-operative 3D photographs and post-operative 3D photographs also included a mix of craniosynostosis types, ensuring that our models and evaluations were robust across different conditions.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is support vector machines (SVM). This is a well-established method in the field of machine learning, particularly known for its effectiveness in classification tasks involving high-dimensional data.\n\nThe SVM algorithm employed is not new; it has been extensively used and validated in various medical applications. The specific implementation of SVM used in our work is based on the support-vector networks as described by Cortes and Vapnik. This method has proven successful in regression analysis of high-dimensional data in the medical field.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of our research is on its application in the medical domain, specifically for the detection and classification of craniosynostosis. Our primary contribution lies in demonstrating the effectiveness of SVM in quantifying and classifying head shape abnormalities from 3D photography and CT images, rather than in developing a new machine-learning algorithm. The medical application and the clinical relevance of our findings are the central aspects of our study, which is why it was published in a medical journal.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "To encode and pre-process the data for our machine-learning algorithm, we first calculated various head shape metrics from different imaging modalities. We computed the average and range of malformations and curvature discrepancies at the area of each cranial bone and suture. These metrics were derived from pre-operative CT images and 3D photographs of patients with craniosynostosis, as well as from a normative population without cranial pathology.\n\nFor the normative population, we created a statistical head shape model using Principal Component Analysis (PCA), retaining 75% of the variance. This model served as a reference to identify the closest normal head shape for each patient. We then quantified two key shape metrics at each point of the head: malformations, which represent the local distances between the patient\u2019s head and its matched normal head shape, and curvature discrepancies, which indicate the local curvature differences.\n\nTo ensure consistency between the CT images and 3D photographs, we compensated for changes caused by natural growth by matching the head size from both modalities at the cranial base using isotropic scaling. This step was crucial because the 3D photographs were typically acquired a few weeks after the matched CT images.\n\nAdditionally, we used the cephalic index alongside the calculated metrics to train a support vector machine classifier. This classifier was designed to distinguish between patients with and without craniosynostosis. We also trained additional classifiers to identify specific types of suture fusion, such as sagittal, coronal, and metopic single suture fusion.\n\nThe data encoding process involved converting the head shapes into signed distance functions to standardize their representation. For 3D photographs, where cranial bones are not visible, we estimated the location of each cranial bone by projecting bone labels from a reference template onto the patient's head shape.\n\nIn summary, our data encoding and pre-processing steps involved calculating head shape metrics, creating a normative statistical head shape model, compensating for growth-related changes, and standardizing the representation of head shapes. These steps ensured that the data was appropriately prepared for training and evaluating our machine-learning classifiers.",
  "optimization/parameters": "In our study, we utilized a comprehensive set of input parameters to train our machine learning models for the detection and classification of craniosynostosis. The specific number of parameters, p, varied depending on the type of analysis being performed.\n\nFor the detection of craniosynostosis, we calculated the average and range of malformations and curvature discrepancies at the area of each cranial bone and suture. These metrics were derived from a normative population and from pre-operative CT images and 3D photographs of patients with craniosynostosis. Additionally, the cephalic index was included as an input parameter. The exact number of parameters, p, is not explicitly stated, but it encompasses these metrics and the cephalic index.\n\nFor the classification of specific suture fusions (sagittal, coronal, and metopic), similar metrics were used. The selection of these parameters was based on their relevance to the head shape abnormalities associated with craniosynostosis. The choice of parameters was informed by previous work in the field, which has successfully used similar metrics for quantifying bone shape abnormalities from CT images.\n\nThe parameters were selected to ensure that the models could accurately distinguish between patients with and without craniosynostosis, as well as between different types of suture fusions. The models were trained using a support vector machine classifier, which is well-suited for high-dimensional data and has been successfully applied in medical regression analysis. The performance of the models was evaluated using cross-validation, and the results were compared with existing methods to ensure their validity.",
  "optimization/features": "The input features used in our study are derived from the quantification of head shape metrics. These metrics include malformations and curvature discrepancies calculated at each point of the head. Additionally, the cephalic index is used as an input feature. These features are obtained from both CT images and 3D photographs of patients with and without craniosynostosis.\n\nFeature selection was not explicitly performed in the traditional sense of reducing the number of features. Instead, the features used are inherently selected based on their relevance to the problem of detecting and classifying craniosynostosis. The metrics of malformations and curvature discrepancies are calculated from the head shapes, which are compared to a normative statistical head shape model. This model is built using Principal Component Analysis (PCA) on a large dataset of subjects without cranial pathology, retaining 75% of the variance.\n\nThe process of feature extraction and selection is integrated into the methodology of building the normative statistical head shape model and comparing patient head shapes to this model. This approach ensures that the features used are directly related to the characteristics of head shape abnormalities associated with craniosynostosis. The use of the cephalic index further supplements these features by providing an additional metric that is commonly used in the assessment of cranial shape.",
  "optimization/fitting": "In our study, we employed a support vector machine (SVM) classifier to distinguish between patients with and without craniosynostosis, as well as to identify specific types of suture fusion. The SVM is a powerful tool for high-dimensional data, which is particularly relevant given the complexity of head shape metrics and curvature discrepancies we analyzed.\n\nThe number of parameters in our SVM model is indeed large compared to the number of training points. To address potential overfitting, we utilized cross-validation techniques. Cross-validation helps in assessing the model's performance on unseen data, thereby providing a more reliable estimate of its generalization capability. Specifically, we used the probability distribution obtained from cross-validation to estimate the power of our classification model. This approach ensured that our model was not merely memorizing the training data but was capable of making accurate predictions on new, unseen data.\n\nTo rule out underfitting, we evaluated the classification accuracy, sensitivity, and specificity using cross-validation. Our model achieved high accuracy, sensitivity, and specificity for detecting craniosynostosis and identifying specific suture fusions. For instance, the classifier obtained an accuracy of 95.29% for detecting craniosynostosis, with a sensitivity of 94.74% and specificity of 96.02%. Similarly, high accuracies were achieved for identifying sagittal, coronal, and metopic single suture fusions. These results indicate that our model is sufficiently complex to capture the underlying patterns in the data without being too simplistic.\n\nAdditionally, we compared our classification results with those obtained by Mendoza et al. using Fisher\u2019s exact test. This comparison served as a benchmark to validate the performance of our method. The results confirmed that our classification approach is robust and not prone to underfitting.\n\nIn summary, through rigorous cross-validation and performance evaluation, we ensured that our model neither overfits nor underfits the data, providing reliable and accurate classifications for craniosynostosis and specific suture fusions.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in our study is not a black box but rather a transparent and interpretable system. We utilized a support vector machine (SVM) classifier, which is known for its interpretability. The SVM classifier operates by identifying a hyperplane that best separates the data into different classes. In our case, the classes are patients with and without craniosynostosis, as well as specific types of suture fusions.\n\nThe interpretability of our model stems from the fact that it relies on well-defined metrics of head shape, such as malformations and curvature discrepancies, which are intuitive and clinically relevant. These metrics are calculated from 3D photography and pre-operative CT images, providing a clear and understandable basis for the model's decisions.\n\nFor instance, positive values in our metrics indicate overdevelopment compared to a normative model, while negative values signify underdevelopment. These values are color-coded for visual guidance, with blue representing negative values and red representing positive values. The intensity of the colors indicates the magnitude of the discrepancies, making it easy to visualize and interpret the results.\n\nMoreover, the model's performance is evaluated using cross-validation, ensuring that the results are robust and generalizable. The accuracy, sensitivity, and specificity of the classifier are provided, giving a clear picture of its effectiveness. For example, the classifier achieved an accuracy of 95.29% for detecting craniosynostosis, with a sensitivity of 94.74% and a specificity of 96.02%.\n\nIn summary, our model is transparent and interpretable, relying on clinically relevant metrics and providing clear visualizations and performance evaluations. This transparency is crucial for gaining trust in the model's predictions and for facilitating its integration into clinical practice.",
  "model/output": "The model developed in our study is primarily a classification model. We utilized a support vector machine classifier to distinguish between patients with and without craniosynostosis. This classifier was trained using metrics of head shape, including malformations and curvature discrepancies, calculated from both normative data and patient data obtained from pre-operative CT images and 3D photographs.\n\nThe classifier achieved high accuracy, sensitivity, and specificity in detecting craniosynostosis, with an overall accuracy of 95.29%, a sensitivity of 94.74%, and a specificity of 96.02%. Additionally, we trained three more classifiers to identify specific types of single suture fusion: sagittal, coronal, and metopic. These classifiers also demonstrated high performance, with accuracies of 99.57%, 99.57%, and 99.13% respectively.\n\nThe output of our model provides a probabilistic distribution that helps estimate the power of the classification. This distribution is derived from cross-validation processes, ensuring the robustness and reliability of our classification results. The model's performance was further validated by comparing it with existing methods, confirming its effectiveness in automatically detecting and classifying craniosynostosis.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its accuracy and reliability. Initially, metrics of head shape were calculated from both pre-operative CT images and 3D photographs of patients with craniosynostosis. These metrics included malformations and curvature discrepancies at various points on the head. The consistency between CT and 3D photography was verified using a dataset of paired images, confirming that both modalities provided similar quantifications of head shape.\n\nA support vector machine classifier was trained using these metrics, along with the cephalic index, to distinguish between patients with and without craniosynostosis. The classifier's performance was assessed through cross-validation, yielding an accuracy of 95.29%, with a sensitivity of 94.74% and a specificity of 96.02%. The power of the classification model was also estimated from the probability distribution obtained during cross-validation.\n\nAdditionally, three more classifiers were trained to identify specific types of single suture fusion: sagittal, coronal, and metopic. These classifiers achieved high accuracies, with values of 99.57%, 99.57%, and 99.13% respectively. The performance of these classifiers was compared with previous methods using Fisher\u2019s exact test, demonstrating that the proposed method was independent and superior.\n\nPost-surgical evaluation was conducted using 3D photography to quantify head shape improvements. Metrics were calculated from pre-surgical CT images and post-surgical 3D photographs of 18 patients. Significant reductions in malformations and curvature discrepancies were observed, indicating the effectiveness of the surgical treatment. The trained classifier correctly identified all pre-operative head shapes as abnormal and noted that post-surgical head shapes, while improved, still fell outside normative ranges.\n\nOverall, the evaluation process involved rigorous testing and comparison with existing methods, ensuring that the proposed framework for quantifying head shape from 3D photography is both accurate and reliable.",
  "evaluation/measure": "In the evaluation of our methods, we focused on several key performance metrics to ensure a comprehensive assessment of our approach. The primary metrics reported include accuracy, sensitivity, and specificity. These metrics were chosen because they are widely recognized and used in the literature for evaluating classification models, particularly in medical imaging and diagnostics.\n\nAccuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It provides an overall measure of the classifier's performance. Sensitivity, also known as the true positive rate, indicates the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, represents the proportion of actual negatives that are correctly identified. These metrics are crucial for understanding the model's ability to distinguish between patients with and without craniosynostosis, as well as between different types of suture fusions.\n\nIn addition to these standard metrics, we also evaluated the power of our classification model. The power of a test refers to its ability to detect an effect if there is one. We estimated the power of our model using the probability distribution obtained from cross-validation, ensuring that our results are robust and reliable.\n\nTo further validate our approach, we compared our classification results with those obtained using methods from previous studies. Specifically, we used Fisher\u2019s exact test to compare our results with the methods by Mendoza et al. This comparison allowed us to assess the performance of our classifier in relation to established techniques, providing a benchmark for our model's effectiveness.\n\nOverall, the set of metrics reported is representative of the standards in the field. Accuracy, sensitivity, and specificity are commonly used metrics in medical imaging and diagnostics, and our inclusion of power estimation and comparative analysis with previous methods ensures a thorough and rigorous evaluation of our approach.",
  "evaluation/comparison": "In our evaluation, we compared our classification results with those obtained by Mendoza et al. using Fisher\u2019s exact test. This comparison was performed on the same dataset of cranial bone shapes derived from CT images. The results indicated that our method was independent from and outperformed the previous methods analyzing cranial bone shapes from CT images, with a p-value of less than 0.001. This comparison provided a robust benchmark to validate the effectiveness of our approach.\n\nAdditionally, we evaluated the performance of our method against simpler baselines by assessing the accuracy, sensitivity, and specificity of our classifiers. For detecting patients with craniosynostosis, our classifier achieved an accuracy of 95.29%, with a sensitivity of 94.74% and a specificity of 96.02%. For identifying the specific fused suture in patients with sagittal, coronal, and metopic single suture fusion, our classifiers achieved accuracies of 99.57%, 99.57%, and 99.13%, respectively. These high performance metrics demonstrate that our method not only matches but also surpasses simpler baselines in terms of accuracy and reliability.",
  "evaluation/confidence": "The evaluation of our method includes several statistical analyses to ensure the confidence and significance of our results. We calculated the power of our classification model using the probability distribution obtained from cross-validation, which provides a measure of confidence in our results. Specifically, our classifier achieved a power of 94% for a 95% confidence interval, indicating a high level of reliability in distinguishing between patients with and without craniosynostosis.\n\nWe also performed statistical tests to compare the head shape metrics obtained from different imaging modalities. For instance, we used the Wilcoxon signed-rank test to determine if there were significant differences between the metrics calculated from CT images and 3D photographs. The p-values obtained (0.39 and 0.44 for malformations and curvature discrepancies, respectively) indicated that there were no statistically significant differences, suggesting that 3D photography provides an equally accurate quantification of head shape as CT images.\n\nIn addition, we evaluated the significance of the improvements in head shape metrics post-surgery. We found a significant reduction in malformations (41.36% reduction, p<0.001 using a paired Wilcoxon signed rank-sum test) and curvature discrepancies (9.68% reduction, p=0.03) after surgical treatment. These results are statistically significant and support the effectiveness of the surgical interventions.\n\nFurthermore, we compared our classification results with those obtained using methods by Mendoza et al. using Fisher\u2019s exact test. The results indicated that our classification method was not independent from previous methods analyzing cranial bone shapes from CT images (p<0.001), suggesting that our approach provides a superior or at least comparable level of accuracy.\n\nOverall, the statistical analyses and confidence intervals reported in our study provide strong evidence for the reliability and significance of our method in detecting and classifying craniosynostosis, as well as in evaluating post-surgical improvements.",
  "evaluation/availability": "Not enough information is available."
}