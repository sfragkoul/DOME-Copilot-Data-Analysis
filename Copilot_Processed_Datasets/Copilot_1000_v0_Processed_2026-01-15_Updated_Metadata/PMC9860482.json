{
  "publication/title": "Artificial intelligence for prediction of endometrial intraepithelial neoplasia and endometrial cancer risks in pre- and postmenopausal women.",
  "publication/authors": "Erdemoglu E, Serel TA, Karacan E, K\u00f6ksal OK, Turan \u0130, \u00d6zt\u00fcrk V, Bozkurt KK",
  "publication/journal": "AJOG global reports",
  "publication/year": "2023",
  "publication/pmid": "36691400",
  "publication/pmcid": "PMC9860482",
  "publication/doi": "10.1016/j.xagr.2022.100154",
  "publication/tags": "- Artificial intelligence\n- Endometrial cancer\n- Endometrial intraepithelial neoplasia\n- Machine learning\n- Minority\n- Prediction\n- Gynecologic oncology\n- Risk assessment\n- Women's health\n- Healthcare disparities",
  "dataset/provenance": "The dataset used in this study was sourced from the Division of Gynecologic Oncology, Department of Obstetrics and Gynecology, at Suleyman Demirel University in Isparta, Turkey. The data was collected from consecutive patients aged 35 years or older between January 2015 and May 2022. The study included a total of 564 patients.\n\nThe dataset comprised various features such as age, menopause status, premenopausal abnormal bleeding, postmenopausal bleeding, obesity, hypertension, diabetes mellitus, smoking, endometrial thickness, and history of breast cancer. Endometrial sampling was performed on all women with postmenopausal bleeding and asymptomatic postmenopausal women with an endometrial thickness of at least 3 mm. Endometrial biopsy was conducted on premenopausal women with abnormal uterine bleeding and asymptomatic premenopausal women with suspected endometrial lesions.\n\nThe data was divided into two groups: a training cohort consisting of 451 patients and an internal validation cohort of 113 patients. This division was done randomly following the 80/20 rule. The features selected for the final modeling using the Boruta algorithm were age, body mass index (BMI), and endometrial thickness. These features were found to be associated with a high risk of developing precancerous and cancerous diseases.\n\nThe dataset has not been used in previous papers or by the community, as this study represents the initial analysis and application of machine learning models to predict endometrial intraepithelial neoplasia and endometrial cancer risks in pre- and postmenopausal women.",
  "dataset/splits": "The dataset was divided into two main splits: a training cohort and an internal validation cohort. The training cohort consisted of data from 451 patients, while the internal validation cohort included data from 113 patients. This division followed the 80/20 rule, where 80% of the data was used for training and 20% for validation. The dataset initially included 564 patients, and the splits were created randomly. The training cohort was used to develop and fine-tune the machine learning models, while the internal validation cohort was used to evaluate the performance of these models.",
  "dataset/redundancy": "The dataset used in this study consisted of 564 patients, with data collected between January 2015 and May 2022. The patients were aged 35 years or older and had undergone various procedures such as transvaginal ultrasound, endometrial biopsy, dilation and curettage, or hysterectomy. The dataset was randomly split into two groups following the 80/20 rule, resulting in 451 patients in the training cohort and 113 patients in the internal validation cohort. This split ensured that the training and test sets were independent, which is crucial for evaluating the performance of machine learning models.\n\nTo enforce independence between the training and test sets, the data was randomly sampled and divided using a predefined ratio. This method helps to prevent data leakage and ensures that the model's performance is evaluated on unseen data, providing a more reliable estimate of its generalizability.\n\nThe distribution of the dataset in this study is comparable to previously published machine learning datasets in the field of gynecologic oncology. The prevalence of precancer or endometrial cancer in our dataset was 7.9%, which is within the range reported in the literature. This prevalence indicates an uneven class distribution, which is a common challenge in medical datasets. To address this, the synthetic minority oversampling technique was used to correct the class imbalance in the training sets, ensuring that the models were trained on a more balanced dataset.\n\nThe features selected for the final modeling were age, body mass index (BMI), and endometrial thickness. These features were identified using the Boruta algorithm, which is a wrapper around the random forest classifier. The algorithm helps to identify the most important features for predicting the outcome, in this case, the risk of developing precancerous and cancerous diseases. The use of these features is consistent with previously published studies, which have also highlighted the importance of age, BMI, and endometrial thickness in predicting endometrial cancer risk.",
  "dataset/availability": "Not applicable",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. These include Random Forest (RF), Logistic Regression (LR), Multilayer Perceptron (MLP), Catboost, Xgboost, and Naive Bayes. These algorithms are part of the broader class of supervised learning methods, which are commonly employed for classification tasks in medical research.\n\nThe algorithms utilized are not new; they have been extensively studied and applied in various domains, including healthcare. The choice of these algorithms was driven by their proven effectiveness in handling complex datasets and their ability to provide robust predictions. The Boruta algorithm, a feature selection method, was also employed to identify the most relevant features for the final modeling. This algorithm is a wrapper around the Random Forest classifier, which helps in estimating feature importance.\n\nThe decision to use these established algorithms was strategic. The primary focus of the study was to apply artificial intelligence for predicting endometrial intraepithelial neoplasia and endometrial cancer risks, rather than developing new machine-learning algorithms. The study aimed to leverage the strengths of existing algorithms to address a critical healthcare challenge. Publishing in a machine-learning journal was not the primary objective, as the study's contributions lie in the application of these algorithms to a specific medical problem, rather than the development of new algorithms. The results demonstrate the potential of these algorithms in improving healthcare outcomes for women, particularly those in rural or minority communities.",
  "optimization/meta": "The model employed in this study does not function as a meta-predictor. Instead, it utilizes a variety of machine learning algorithms independently to analyze the training cohort. The algorithms used include logistic regression, support vector machine, K-nearest neighbors, random forest, gradient-boosted decision tree, and neural network. Each of these methods was applied separately to the dataset, and their performance was evaluated through cross-validation.\n\nThe training data was divided into two groups: one for training the models and another for internal validation. This division ensures that the training data is independent for each model, allowing for an unbiased evaluation of their predictive capabilities. The random forest method, in particular, was highlighted for its high area under the curve (AUC) in predicting hysterectomy, while the multilayer perceptron (MLP) showed strong performance in predicting precancerous diseases with an AUC of 0.94 in the internal validation cohort.\n\nThe study did not combine the outputs of these different algorithms into a single meta-predictor. Instead, each algorithm's performance was assessed individually, and the results were reported separately. This approach allows for a clear understanding of how each method contributes to the prediction of endometrial precancer and cancer risks.",
  "optimization/encoding": "The data collected for this study included various features such as age, menopause status, premenopausal abnormal bleeding, postmenopausal bleeding, obesity, hypertension, diabetes mellitus, smoking, endometrial thickness, and history of breast cancer. These features were initially gathered from 564 patients who met the inclusion criteria.\n\nTo prepare the data for machine learning analysis, it was randomly divided into two groups using an 80/20 split, where 80% of the data was used for training and 20% for internal validation. This division ensured that the model could be trained on a substantial amount of data while still having a separate dataset to evaluate its performance.\n\nFeature selection was performed using the Boruta algorithm, which is a wrapper around the random forest classifier. This algorithm helped in identifying the most important features for the final modeling. Out of the nine features collected, three were selected: age, body mass index (BMI), and endometrial thickness. These features were found to be significantly associated with a high risk of developing precancerous and cancerous diseases.\n\nThe synthetic minority oversampling technique (SMOTE) was employed to address class imbalance in the training sets. This technique helps in balancing the dataset by generating synthetic samples for the minority class, thereby improving the model's ability to learn from underrepresented classes.\n\nFor the machine learning models, Python was used to implement various algorithms, including random forest, logistic regression, multilayer perceptron, Catboost, Xgboost, and Naive Bayes. These models were trained using a 5-fold cross-validation approach to ensure robustness and to fine-tune the parameters for optimal performance.\n\nThe data was encoded and pre-processed to ensure compatibility with the machine learning algorithms. Continuous variables like age, BMI, and endometrial thickness were normalized or standardized to bring them to a similar scale. Categorical variables, if any, were encoded using techniques such as one-hot encoding to convert them into a format suitable for the algorithms.\n\nIn summary, the data encoding and preprocessing involved random splitting, feature selection using the Boruta algorithm, handling class imbalance with SMOTE, and normalization of continuous variables. These steps were crucial in preparing the data for effective machine learning analysis and model training.",
  "optimization/parameters": "In our study, we initially collected data on nine different features from the patients. These features included age, menopause status, premenopausal abnormal bleeding, postmenopausal bleeding, obesity, hypertension, diabetes mellitus, smoking, endometrial thickness, and history of breast cancer. To determine the most relevant features for our predictive model, we employed the Boruta algorithm. This algorithm is a wrapper around the random forest classifier, which helps in estimating the importance of each feature. After running the Boruta algorithm, three features were selected for the final modeling: age, body mass index (BMI), and endometrial thickness. These three features were found to be significantly associated with a high risk of developing precancerous and cancerous diseases, specifically endometrial intraepithelial neoplasia (EIN) and endometrial cancer. Therefore, the final model utilized these three parameters to predict the risk of endometrial precancer and cancer.",
  "optimization/features": "The study initially collected data on nine features: age, menopause status, premenopausal abnormal bleeding, postmenopausal bleeding, obesity, hypertension, diabetes mellitus, smoking, endometrial thickness, and history of breast cancer. However, feature selection was performed using the Boruta algorithm, which is a wrapper around the random forest classifier. This algorithm was applied to both the training and internal validation groups to identify the most relevant features for the final modeling.\n\nAs a result, three features were selected for use in the final model: age, body mass index (BMI), and endometrial thickness. These features were found to be associated with a high risk of developing precancerous and cancerous diseases, specifically endometrial intraepithelial neoplasia and endometrial cancer. The feature selection process ensured that the model focused on the most informative inputs, enhancing its predictive performance.",
  "optimization/fitting": "The study utilized a comprehensive approach to ensure that the machine learning models were neither overfitting nor underfitting the data. The dataset consisted of 564 patients, with 451 used for training and 113 for internal validation. This sample size was deemed sufficient for the features selected by the Boruta algorithm, which identified age, body mass index (BMI), and endometrial thickness as the most significant predictors.\n\nTo address the potential issue of overfitting, several techniques were employed. First, the synthetic minority oversampling technique (SMOTE) was used to correct class imbalances in the training sets, ensuring that the models were not biased towards the majority class. Second, a 5-fold cross-validation approach was implemented, which involved dividing the training data into five subsets and training the models on four subsets while validating on the remaining one. This process was repeated five times, with each subset serving as the validation set once. This method helps to ensure that the models generalize well to unseen data.\n\nAdditionally, tuning and boosting were applied to enhance the performance of the models. This involved adjusting the hyperparameters of the models to optimize their performance metrics, such as accuracy, sensitivity, specificity, positive predictive value, and F1 score. The use of multiple machine learning algorithms, including random forest, logistic regression, multilayer perceptron, Catboost, Xgboost, and Naive Bayes, further mitigated the risk of overfitting by providing a diverse set of models to compare and validate.\n\nTo rule out underfitting, the models were evaluated on their ability to capture the underlying patterns in the data. The high area under the receiver operating characteristic curve (AUC) of 0.94 for predicting precancerous disease in the internal validation cohort indicated that the models were effectively learning from the training data. Furthermore, the precision, recall, and F1 scores were calculated to assess the models' performance, ensuring that they were not too simplistic to capture the complexity of the data.\n\nIn summary, the study employed a robust set of techniques to prevent overfitting and underfitting, including SMOTE for class imbalance, 5-fold cross-validation, hyperparameter tuning, and the use of multiple machine learning algorithms. These measures ensured that the models were both generalizable and capable of capturing the essential patterns in the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and enhance the robustness of our machine learning models. One of the key methods used was the synthetic minority oversampling technique (SMOTE). This technique was applied to address class imbalance in the training sets, which is a common issue in medical datasets. By oversampling the minority class, we ensured that our models were not biased towards the majority class, thereby improving their ability to generalize to new, unseen data.\n\nAdditionally, we utilized a 5-fold cross-validation approach. This method involves dividing the training data into five subsets, training the model on four of these subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. Cross-validation helps to ensure that the model's performance is consistent across different subsets of the data, reducing the risk of overfitting.\n\nFurthermore, we fine-tuned the parameters of our models using techniques such as tuning and boosting. These methods help to optimize the model's performance by adjusting hyperparameters and improving the model's ability to capture complex patterns in the data without overfitting.\n\nIn summary, we implemented SMOTE for handling class imbalance, 5-fold cross-validation for robust performance evaluation, and parameter tuning and boosting for model optimization. These techniques collectively helped to prevent overfitting and enhance the reliability of our predictive models.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available upon request. The study utilized various machine learning algorithms, including Random Forest, Logistic Regression, Multilayer Perceptron, Catboost, Xgboost, and Naive Bayes. The synthetic minority oversampling technique was employed to address class imbalance in the training sets. Additionally, tuning and boosting were applied to enhance model performance using a 5-fold cross-validation approach.\n\nThe specific configurations and parameters for these models were fine-tuned to optimize their performance. For instance, the Multilayer Perceptron (MLP) was fine-tuned to achieve the highest area under the receiver operating characteristic curve (AUC) for predicting precancerous diseases. The Random Forest model demonstrated the highest AUC for predicting the need for hysterectomy.\n\nThe data handling and machine learning analysis were conducted using Python, and the models were evaluated based on metrics such as accuracy, sensitivity, specificity, positive predictive value, and F1 score. These details, including the exact hyper-parameter settings and optimization schedules, can be shared upon approval by the relevant institutional review board.\n\nThe study's findings and the models developed are intended to be shared with the research community to facilitate further advancements in the field. Individual deidentified participant data, including data dictionaries, will be made available if the request is approved by the university. This approach ensures that the research can be replicated and built upon by other researchers, contributing to the broader understanding and improvement of endometrial cancer prediction and management.",
  "model/interpretability": "The model employed in this study is not a black box but rather a transparent one, as it utilizes machine learning algorithms that allow for interpretability. The Boruta algorithm, a feature selection method, was used to identify the most important variables for predicting endometrial intraepithelial neoplasia and endometrial cancer. This algorithm selected age, body mass index (BMI), and endometrial thickness as the key features associated with a high risk of developing these conditions. These selected features are intuitive and clinically relevant, making the model's decisions understandable and interpretable.\n\nThe coefficients of these features, which indicate their importance in the model, are visually represented in a figure. This visualization helps in understanding the contribution of each feature to the model's predictions. For instance, higher values of age, BMI, and endometrial thickness are associated with an increased risk of precancerous and cancerous diseases.\n\nAdditionally, the study used multiple machine learning models, including logistic regression, support vector machine, K-nearest neighbors, random forest, gradient-boosted decision tree, and neural network. The random forest model, in particular, demonstrated the highest area under the curve (AUC) for predicting hysterectomy, indicating its effectiveness in this context. The use of these well-established algorithms further enhances the transparency and interpretability of the model.\n\nThe model's performance metrics, such as accuracy, precision, recall, and F1 score, are also provided, offering a clear understanding of its predictive capabilities. For example, the precision of 0.71 for diagnosing endometrial cancer indicates the model's reliability in making correct positive predictions. The recall and sensitivity values show the model's ability to identify true positive cases, while the F1 score provides a balanced measure of precision and recall.\n\nIn summary, the model is transparent and interpretable, with clear examples of how key features contribute to its predictions. The use of established machine learning algorithms and the provision of performance metrics further enhance its interpretability.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the presence of precancerous or cancerous diseases, specifically endometrial intraepithelial neoplasia and endometrial cancer, in pre- and postmenopausal women. The model uses various machine learning algorithms, including random forest, logistic regression, multilayer perceptron, Catboost, Xgboost, and Naive Bayes, to classify patients based on selected features.\n\nThe primary output of the model is the prediction of whether a patient has a precancerous or cancerous condition. The model's performance is evaluated using metrics such as accuracy, precision, recall, and F1 score. For instance, the accuracy of the model in predicting precancerous diseases is 0.94, with a precision of 0.71, recall of 0.50, and an F1 score of 0.59. These metrics indicate the model's ability to correctly identify positive cases (recall), the proportion of positive identifications that are actually correct (precision), and the harmonic mean of precision and recall (F1 score).\n\nAdditionally, the model's coefficients for the features, such as age, body mass index (BMI), and endometrial thickness, are provided. These coefficients highlight the importance of each feature in predicting the risk of developing precancerous and cancerous diseases. The model does not rely on menopausal status or symptoms, making it more accessible and potentially beneficial for women who may not recognize or report symptoms, such as those from minority groups or rural communities.\n\nThe model's outputs are visualized through figures and tables, which show the coefficients of the features and the performance metrics for different prediction tasks. For example, Figure 1 displays the coefficients of the features, while a table presents the accuracy, precision, recall, and F1 scores for predicting precancerous diseases and hysterectomy as a treatment modality. These visualizations help in understanding the model's performance and the significance of the features used in the predictions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several key steps to ensure its robustness and accuracy. Initially, the data from 564 patients were randomly divided into two groups: a training cohort consisting of 451 patients and an internal validation group of 113 patients. This split followed the 80/20 rule, which is a common practice in machine learning to balance the amount of data used for training and validation.\n\nFeature selection was performed using the Boruta algorithm, which is a wrapper around the random forest classifier. This algorithm helped in identifying the most relevant features for the final modeling. The selected features included age, body mass index (BMI), and endometrial thickness, which were found to be significantly associated with the risk of developing precancerous and cancerous diseases.\n\nMultiple machine learning algorithms were employed for classification, including random forest, logistic regression, multilayer perceptron, Catboost, Xgboost, and Naive Bayes. To address the class imbalance in the training sets, the synthetic minority oversampling technique was used. Additionally, tuning and boosting techniques were applied to enhance the performance of the models. A 5-fold cross-validation approach was utilized to further validate the models' performance.\n\nThe evaluation metrics calculated included accuracy, sensitivity, specificity, positive predictive value, and the F1 score. These metrics provided a comprehensive assessment of the models' effectiveness. For instance, the accuracy for predicting a precancerous disease was 0.94, while the precision, recall, and F1 scores for the test group were 0.71, 0.50, and 0.59, respectively. These results indicate the model's ability to accurately identify women at risk of endometrial intraepithelial neoplasia and endometrial cancer, regardless of menopausal status or symptoms.",
  "evaluation/measure": "In our study, we reported several key performance metrics to evaluate the effectiveness of our artificial intelligence models in predicting endometrial intraepithelial neoplasia and endometrial cancer. The primary metrics we focused on include accuracy, precision, recall, and the F1 score. These metrics provide a comprehensive view of the model's performance, especially in handling imbalanced datasets, which is common in medical diagnostics.\n\nAccuracy was reported as 0.94 for predicting precancerous diseases, indicating a high overall correctness of the model's predictions. Precision, which measures the proportion of true positive predictions among all positive predictions, was 0.71. This metric is crucial for understanding the reliability of positive predictions made by the model.\n\nRecall, also known as sensitivity, was reported as 0.50. Recall measures the proportion of actual positives that were correctly identified by the model. This metric is essential for ensuring that the model does not miss many true positive cases, which is particularly important in medical diagnostics where missing a diagnosis can have severe consequences.\n\nThe F1 score, which is the harmonic mean of precision and recall, was 0.59. The F1 score provides a single metric that balances both precision and recall, making it particularly useful for evaluating models on imbalanced datasets. A higher F1 score indicates a better balance between precision and recall.\n\nAdditionally, we calculated the area under the receiver operating characteristic curve (AUC), which was 0.94 for predicting precancerous diseases. The AUC provides a measure of the model's ability to distinguish between positive and negative classes across all possible classification thresholds.\n\nThese performance metrics are representative of those commonly reported in the literature for similar diagnostic models. They provide a robust evaluation of the model's effectiveness in predicting endometrial intraepithelial neoplasia and endometrial cancer, ensuring that the model is reliable and accurate in clinical settings.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, we focused on developing and evaluating various machine learning algorithms tailored to our specific dataset. The algorithms we employed included random forest, logistic regression, multilayer perceptron, Catboost, Xgboost, and Naive Bayes. These methods were chosen for their robustness and widespread use in medical diagnostics.\n\nWe did, however, compare the performance of these advanced machine learning techniques against simpler baselines. For instance, we used the synthetic minority oversampling technique to address class imbalance in our training sets, which is a common preprocessing step. Additionally, we utilized feature selection through the Boruta algorithm to identify the most relevant predictors, ensuring that our models were not overfitted to noise.\n\nThe performance metrics we calculated, such as accuracy, sensitivity, specificity, positive predictive value, and F1 score, provided a comprehensive evaluation of our models. The F1 score, in particular, was crucial as it balances the trade-off between false negatives and false positives, which is essential for diagnostic accuracy.\n\nWhile we did not benchmark against external datasets or simpler baselines in the traditional sense, our approach ensured that the models were rigorously tested and validated internally. This included using a 5-fold cross-validation approach to enhance the reliability of our results. The final models demonstrated high accuracy and precision, indicating their potential for clinical application.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not applicable."
}