{
  "publication/title": "MRI-Based Topology Deep Learning Model for Noninvasive Prediction of Microvascular Invasion and Assisting Prognostic Stratification in HCC.",
  "publication/authors": "Zheng T, Zhu Y, Jiang H, Yang C, Ye Y, Bashir MR, Li C, Long L, Luo S, Song B, Chen Y, Chen Y",
  "publication/journal": "Liver international : official journal of the International Association for the Study of the Liver",
  "publication/year": "2025",
  "publication/pmid": "39992060",
  "publication/pmcid": "PMC11849444",
  "publication/doi": "10.1111/liv.16205",
  "publication/tags": "- Convolutional Neural Networks\n- Topological Data Analysis\n- Microvascular Invasion\n- Magnetic Resonance Imaging\n- Hepatocellular Carcinoma\n- Machine Learning\n- Medical Imaging\n- Predictive Modeling\n- Deep Learning\n- Homology Image Computation",
  "dataset/provenance": "The dataset used in this study was sourced from two medical centers, referred to as Centre A and Centre B. Centre A contributed data from patients treated between January 2015 and May 2022, while Centre B provided data from patients treated between January 2019 and December 2022. The dataset consists of 589 patients in total, with 423 patients from Centre A and 166 patients from Centre B. The patients included in the study met specific criteria, such as being at least 18 years old, having undergone curative resection for histologically confirmed hepatocellular carcinoma (HCC), and having documented microvascular invasion (MVI) status. Additionally, patients had to have undergone contrast-enhanced MRI within 30 days prior to surgery and had to have key laboratory results available within two weeks before surgery.\n\nThe dataset was divided into training, internal test, and external test groups. The training dataset included 317 patients, the internal test dataset included 106 patients, and the external test dataset included 166 patients. The baseline characteristics of the patients, such as sex, age, and various laboratory results, were collected from electronic health records. The dataset has not been used in previous papers by the community.",
  "dataset/splits": "There are three data splits in this study: the training dataset, the internal test dataset, and the external test dataset. The training dataset consists of 317 patients, while the internal test dataset includes 106 patients. The external test dataset comprises 166 patients. The training and internal test datasets were derived from Centre A, with patients randomly assigned at a ratio of 7:3. The external test dataset was sourced from Centre B. The distribution of patients with microvascular invasion (MVI) is relatively consistent across the datasets, with 48.6% in the training dataset, 49.1% in the internal test dataset, and 51.8% in the external test dataset.",
  "dataset/redundancy": "The datasets were split based on the center from which the patients were recruited. Patients from Centre A, recruited between January 2015 and May 2022, were randomly assigned to either the training or internal test dataset at a ratio of 7:3. This random assignment ensured that the training and internal test sets were independent. Patients from Centre B, recruited from January 2019 to December 2022, were assigned to the external test dataset, ensuring an additional layer of independence.\n\nTo enforce the independence of the datasets, patients who had received any previous antitumoral treatment, had macrovascular invasion, lacked key laboratory results within two weeks prior to surgery, or had MR images of insufficient quality were excluded. This rigorous exclusion criteria helped maintain the integrity and independence of the datasets.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the field of medical imaging. The use of consecutive patients who met specific inclusion criteria and the random assignment to training and internal test sets help to mitigate potential biases. The external test dataset from a different center further validates the generalizability of the models. This approach ensures that the datasets are robust and representative, which is crucial for the development and validation of reliable machine learning models in medical research.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Convolutional Neural Networks (CNNs). Specifically, we employed the EfficientNet-B0 architecture as the common backbone for our CNN models. This choice was made due to its efficiency and effectiveness in image classification tasks.\n\nThe algorithms used are not entirely new; they are well-established in the field of machine learning and computer vision. However, the application and integration of these algorithms in our study are novel, particularly in the context of predicting microvascular invasion (MVI) in hepatocellular carcinoma (HCC) using topological data analysis (TDA). The TopoCNN model, which combines CNN with topological information, is a unique contribution of our work.\n\nThe reason these algorithms were not published in a machine-learning journal is that our focus is on the application of these techniques to a specific medical problem rather than the development of new machine-learning algorithms. Our study is primarily concerned with the clinical utility and diagnostic performance of these models in predicting MVI, which is a critical factor in the management of HCC. The integration of TDA with CNNs to form the TopoCNN model is what sets our work apart and makes it relevant to both the medical and machine-learning communities.",
  "optimization/meta": "The model described in the publication does indeed use data from other machine-learning algorithms as input, specifically in the form of the TopoCNN+Clinic model. This model combines the TopoCNN model with variables selected from a multivariable logistic regression analysis. The TopoCNN model itself is a convolutional neural network (CNN) that incorporates topological data analysis.\n\nThe whole system consists of several components:\n\n1. **Conventional MRI Feature Model**: This model uses traditional MRI features to predict outcomes.\n2. **Pure CNN Model**: A standard convolutional neural network trained on MRI data.\n3. **TopoCNN Model**: A CNN that integrates topological data analysis, enhancing its predictive capabilities.\n4. **TopoCNN+Clinic Model**: This is the meta-predictor, combining the TopoCNN model with clinical variables derived from logistic regression.\n\nRegarding the independence of the training data, it is clear that the data is split into distinct datasets: a training dataset, an internal test dataset, and an external test dataset. The training dataset and internal test dataset come from one hospital, while the external test dataset comes from another hospital. This separation ensures that the training data is independent from the test data, providing a robust evaluation of the model's performance.",
  "optimization/encoding": "For the machine-learning algorithm, the data encoding and preprocessing involved several key steps. Initially, extreme values in individual pixels within the MRI images were corrected by clipping pixels above the 99.5%\u201399.9% percentile of the image range. This step ensured that the data was normalized and that outliers did not disproportionately affect the model.\n\nAutomated liver segmentation was performed on MR images using a semi-supervised deep learning method. This method was crucial for accurately isolating the liver region from the rest of the image, ensuring that the subsequent analysis focused solely on the relevant anatomical area.\n\nTumor segmentation was achieved through a two-stage multi-sequence joint automated framework. This process involved detecting and segmenting tumors on MR images, which was essential for identifying the regions of interest (ROIs) for further analysis. The segmentation quality was rigorously evaluated by two radiologists with varying levels of experience, ensuring high accuracy and reliability.\n\nThe ROIs were extracted by selecting the slice with the largest tumor size in the axial plane and cropping a patch image from this slice. The tumor area was dilated based on tumor size, with large tumors (\u2265 32 mm) dilated by 1.5 times and small tumors (< 32 mm) dilated by 2 times. These cropped patch images were then resized to 96 \u00d7 96 mm using bilinear interpolation, forming the final ROIs for model input.\n\nPersistent homology, a topological analysis tool, was used to extract multi-dimensional topological information from weighted cell complexes. Cubical Ripser was employed to compute the persistent homology of weighted cubical complexes, transforming topological information into quantitative representations. This process involved building a star-filtered cubical complex using MRI intensity values and generating persistence diagrams that described the birth and death of connected components and loops.\n\nHomology images were generated from the persistence diagrams, with intensity computed according to the lifetime map. These homology images, along with the cropped ROIs, were used to construct the TopoCNN model. Inline data augmentation techniques, including scaling, translation, lighting alteration, rotation, Gaussian noise addition, and elastic deformation, were applied to the input images to enhance the model's robustness and generalization.\n\nThe final dataset consisted of cropped ROIs and corresponding homology images, which were used to train the convolutional neural network (CNN) models. This comprehensive preprocessing and encoding pipeline ensured that the data was accurately represented and optimized for the machine-learning algorithm.",
  "optimization/parameters": "In our study, the EfficientNet-B0 was employed as the backbone for both the pure CNN model and the TopoCNN model. The network was trained using the Adam optimizer, with an initial learning rate of 1e-3. This learning rate was dynamically adjusted using the ReduceLROnPlateau schedule, which updates the learning rate based on the validation performance, with a patience of 5 epochs and a decay factor of 0.1. The binary cross-entropy loss function was utilized to measure the performance of the model during training.\n\nThe batch size was set to 4, and a dropout rate of 0.2 was applied to prevent overfitting. The network was trained for a maximum of 200 epochs, with early stopping triggered if the model's performance on the validation set did not improve. The model weights corresponding to the best validation accuracy were saved for further analysis.\n\nFor hyperparameter tuning, a manual search technique was employed during the CNN training process. This involved systematically varying the hyperparameters and selecting the combination that yielded the best performance on the validation dataset. The final model, TopoCNN+Clinic, was constructed by integrating the TopoCNN model with variables selected from a multivariable logistic regression analysis, following the same workflow as the conventional MRI feature model.",
  "optimization/features": "In the optimization process, the input features for the models were derived from both imaging data and clinical variables. For the conventional MRI feature model, three imaging features were identified through multivariable logistic regression analysis: tumour size, HCC growth subtype, and PVP peritumoral hypoenhancement. These features were selected based on their association with microvascular invasion (MVI).\n\nFeature selection was performed using the training dataset only, ensuring that the selected features were not influenced by the test data. This approach helps to prevent data leakage and maintains the integrity of the model evaluation process.\n\nFor the CNN-based models, the input features primarily consisted of the imaging data processed through the EfficientNet-B0 backbone. Additionally, the TopoCNN+Clinic model incorporated variables selected from the multivariable logistic regression analysis, combining both imaging and clinical information.\n\nThe specific number of features used as input varies depending on the model. The conventional MRI feature model used three specific imaging features. The pure CNN model relied on the raw imaging data processed through the convolutional neural network. The TopoCNN model utilized topological features derived from the imaging data, and the TopoCNN+Clinic model combined these topological features with selected clinical variables.",
  "optimization/fitting": "The fitting method employed in our study utilized convolutional neural networks (CNNs) with a specific architecture and training regimen designed to mitigate both overfitting and underfitting.\n\nThe EfficientNet-B0 was chosen as the backbone for the CNN framework, ensuring a balance between model complexity and computational efficiency. The network was trained using the Adam optimizer with an initial learning rate of 1e-3, which was dynamically adjusted using the ReduceLROnPlateau schedule. This schedule reduces the learning rate by a factor of 0.1 after 5 epochs of no improvement, helping to fine-tune the model and prevent overfitting.\n\nTo further combat overfitting, a dropout rate of 0.2 was applied, randomly setting 20% of the neurons to zero during training. This technique forces the network to learn more robust features and reduces reliance on any single neuron. Additionally, early stopping was implemented, halting training when the validation accuracy ceased to improve, ensuring that the model did not memorize the training data.\n\nThe batch size was set to 4, which, while small, was chosen to balance memory constraints and the need for sufficient gradient updates. The network was trained for a maximum of 200 epochs, providing ample opportunity for the model to learn from the data without excessive training time.\n\nTo address the potential for underfitting, manual hyperparameter tuning was performed. This involved systematically adjusting parameters such as learning rate, batch size, and dropout rate to find the optimal configuration. The use of a comprehensive dataset, including training, internal test, and external test sets, ensured that the model was exposed to a wide range of data, reducing the risk of underfitting.\n\nThe model's performance was evaluated using various metrics, including the area under the receiver operating characteristic curve (AUC), calibration curves, and decision curves. These evaluations confirmed that the model generalizes well to unseen data, indicating that neither overfitting nor underfitting was a significant issue. The calibration curves and decision curves further validated the model's reliability and clinical utility.",
  "optimization/regularization": "In our study, several regularization techniques were employed to prevent overfitting during the training of our convolutional neural network (CNN) models. One of the key methods used was dropout, with a dropout rate set to 0.2. Dropout is a technique where, during training, a fraction of the neurons are randomly set to zero, which helps to prevent the model from becoming too reliant on any single neuron and thus reduces overfitting.\n\nAdditionally, early stopping was implemented as a regularization strategy. The network was trained for a maximum of 200 epochs, but the training process was halted early if the validation accuracy did not improve for a specified number of epochs, known as the patience parameter, which was set to 5. This approach ensures that the model does not continue to train beyond the point where it starts to overfit the training data.\n\nAnother regularization technique used was learning rate scheduling. The initial learning rate was set to 1e-3, and it was dynamically adjusted using the ReduceLROnPlateau schedule. This schedule reduces the learning rate by a decay factor of 0.1 when the validation performance plateaus, helping the model to converge more effectively and avoid overfitting.\n\nThese regularization methods collectively contributed to the robustness and generalization capability of our models, ensuring that they performed well on both training and test datasets.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are fully reported. We utilized the EfficientNet-B0 as the backbone for our convolutional neural network (CNN) models. The network was trained using the Adam optimizer with an initial learning rate of 1e-3, which was updated using the ReduceLROnPlateau schedule with a patience of 5 epochs and a decay factor of 0.1. Binary cross-entropy loss was applied as the loss function. The batch size was set to 4, and the dropout rate was 0.2. Training was conducted for a maximum of 200 epochs or until the early stopping condition was met, with the best validation accuracy weights being stored.\n\nThe specific details of these configurations, including the learning rate schedule, batch size, dropout rate, and other relevant parameters, are provided within the main text of the publication. However, the model files themselves and the exact scripts used for optimization are not directly available in the publication. For access to the model files and optimization parameters, readers would need to refer to supplementary materials or contact the authors directly. The license under which these materials might be shared is not specified in the provided information.",
  "model/interpretability": "The interpretability of the models developed in this study is a crucial aspect that sets them apart from traditional black-box models. To enhance the transparency and interpretability of the TopoCNN model, the Grad-CAM algorithm was utilized. This algorithm generates saliency maps that highlight the areas within the input images that contribute most significantly to the model's predictions. These saliency maps provide a visual explanation of the model's decision-making process, making it easier to understand which features are most influential in diagnosing microvascular invasion (MVI).\n\nThe use of Grad-CAM allows for a more intuitive and interpretable model, as it visually indicates the regions of interest that the model focuses on. This is particularly important in medical imaging, where understanding the model's reasoning can build trust among healthcare professionals and patients. By visualizing the areas that contribute most to the diagnosis, clinicians can better assess the model's reliability and potentially gain new insights into the disease.\n\nIn summary, the TopoCNN model is not a black-box model. Instead, it leverages Grad-CAM to provide clear and visual explanations of its predictions, thereby enhancing its interpretability and transparency. This approach ensures that the model's decisions are understandable and can be scrutinized by medical experts, making it a valuable tool in clinical settings.",
  "model/output": "The model developed in this study is primarily a classification model. It is designed to predict the presence of microvascular invasion (MVI) in hepatocellular carcinoma (HCC) patients using MRI images. The output of the model is a probability that indicates the likelihood of MVI, which is then used to classify patients into low-risk and high-risk groups based on a calculated cutoff value.\n\nThe model employs convolutional neural networks (CNNs), specifically the TopoCNN model, which incorporates topological data analysis. This approach allows the model to capture complex patterns in the MRI images that are indicative of MVI. The performance of the model is evaluated using metrics such as the area under the curve (AUC), sensitivity, specificity, and accuracy, which are standard for classification tasks.\n\nIn addition to predicting MVI, the model's output is also used to stratify patients based on their risk of early recurrence-free survival (RFS) and overall survival (OS). This stratification is crucial for personalized management of HCC patients, as it helps in identifying those who may benefit from more aggressive treatment strategies.\n\nThe model's predictions are visualized using saliency maps generated by the Grad-CAM algorithm, which highlight the areas in the MRI images that contribute most to the diagnosis of MVI. This visualization aids in interpreting the model's decisions and understanding the underlying features that drive its predictions.\n\nThe model's performance is compared with a conventional MRI feature model, and it is shown to outperform the conventional model in terms of AUC for both internal and external test datasets. This demonstrates the effectiveness of the TopoCNN model in accurately predicting MVI and stratifying patients based on their risk profiles.",
  "model/duration": "The execution time for the models was not explicitly detailed in the publication. However, some relevant information can be inferred from the training process described. The network was trained for a maximum of 200 epochs or until the early stopping condition was met. The learning rate was adjusted using the ReduceLRonPlateau schedule with a patience of 5 epochs and a decay factor of 0.1. This suggests that the training process could be lengthy, depending on the computational resources and the complexity of the dataset.\n\nAdditionally, the use of the Adam optimizer and a batch size of 4 indicates that the training was likely optimized for efficiency, but specific execution times were not provided. The models, including the pure CNN, TopoCNN, and TopoCNN+Clinic, were evaluated on training, internal test, and external test datasets, which further implies a substantial amount of computational effort. However, without specific details on the hardware used or the exact duration of each training session, it is challenging to provide a precise execution time.",
  "model/availability": "The source code for the specific models and algorithms used in this study is not publicly released. However, the Grad-CAM algorithm, which was utilized to generate saliency maps, is available through the pytorch-grad-cam library on GitHub. This library can be accessed at [https://github.com/jacobgil/pytorch-grad-cam](https://github.com/jacobgil/pytorch-grad-cam). The library is open-source and can be used under the terms of its specified license.\n\nFor the implementation details of the semi-supervised deep learning method used for liver segmentation and the two-stage multi-sequence joint automated tumour detection and segmentation framework, additional information can be found in the Supporting Information S4 and S5, respectively. These details provide insights into the methodologies employed but do not include the actual code.\n\nNot applicable.",
  "evaluation/method": "The evaluation of the models involved several datasets and statistical methods to ensure robust assessment. The models were evaluated on training, internal test, and external test datasets. The training dataset was used to develop and initially validate the models, while the internal and external test datasets were used to assess the generalizability and performance of the models on unseen data.\n\nThe performance of the models was primarily evaluated using the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, which measures the ability of the models to distinguish between patients with and without microvascular invasion (MVI). Additionally, sensitivity, specificity, and accuracy were reported to provide a comprehensive view of the models' diagnostic performance.\n\nStatistical tests such as the DeLong test were used to compare the AUCs of different models, ensuring that any observed differences were statistically significant. The calibration of the models was assessed using calibration curves, the Hosmer-Lemeshow test, and calibration slopes, which evaluate how well the predicted probabilities match the actual outcomes. Decision curve analysis was conducted to evaluate the clinical utility of the models by quantifying the net benefits at various threshold probabilities.\n\nFor subgroup analyses, patients with tumors \u2264 3 cm were specifically considered, and pairwise sensitivities, specificities, and accuracies were compared using the McNemar test. This approach ensured that the models were evaluated not only on the overall patient population but also on specific subgroups, providing insights into their performance across different clinical scenarios.\n\nIn summary, the evaluation method involved a combination of datasets, statistical tests, and performance metrics to thoroughly assess the diagnostic and prognostic capabilities of the models. This comprehensive evaluation ensures that the models are reliable and generalizable, making them suitable for clinical application.",
  "evaluation/measure": "In the evaluation of our models for predicting microvascular invasion (MVI), we reported several key performance metrics to provide a comprehensive assessment of their diagnostic capabilities. The primary metric used was the Area Under the Receiver Operating Characteristic Curve (AUC), which measures the model's ability to distinguish between patients with and without MVI. This metric is widely accepted in the literature for evaluating the performance of diagnostic models.\n\nIn addition to AUC, we also reported sensitivity, specificity, and accuracy. Sensitivity, or the true positive rate, indicates the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, represents the proportion of actual negatives that are correctly identified. Accuracy provides an overall measure of the model's correctness, calculated as the proportion of true results (both true positives and true negatives) among the total number of cases examined.\n\nThese metrics were evaluated across different datasets, including training, internal test, and external test datasets, as well as for overall patients and a subgroup of patients with tumor sizes \u2264 3 cm. This comprehensive evaluation ensures that our models are robust and generalizable to different patient populations.\n\nFurthermore, we assessed model calibration using calibration curves, the Hosmer-Lemeshow test, and calibration slopes. Calibration measures how well the predicted probabilities match the actual outcomes, which is crucial for the clinical applicability of the models. Decision curve analysis was also conducted to evaluate the clinical utility of the models by quantifying the net benefits at various threshold probabilities.\n\nThe reported metrics are representative of those commonly used in the literature for evaluating diagnostic models, ensuring that our results are comparable with other studies in the field. The inclusion of sensitivity, specificity, accuracy, AUC, calibration, and decision curve analysis provides a thorough evaluation of our models' performance and their potential clinical impact.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, several comparisons were conducted to evaluate the performance of different models. The conventional MRI feature model was compared against various CNN-based models, including the pure CNN model, the TopoCNN model, and the TopoCNN+Clinic model. These comparisons were performed across training, internal test, and external test datasets.\n\nThe pure CNN model demonstrated AUCs of 0.845, 0.830, and 0.828 for the training, internal, and external test datasets, respectively. The TopoCNN model showed superior performance with AUCs of 0.903, 0.890, and 0.871 for the same datasets. The TopoCNN+Clinic model, which integrates clinical variables, achieved AUCs of 0.900, 0.895, and 0.879. These results indicate that the TopoCNN and TopoCNN+Clinic models outperformed the pure CNN model and the conventional MRI feature model.\n\nCalibration curves and decision curves were also analyzed to assess model performance. The pure CNN model was found to be poorly calibrated for the internal and external test datasets, while the TopoCNN and TopoCNN+Clinic models were well calibrated. Decision curves showed that the TopoCNN and TopoCNN+Clinic models provided the largest net benefits for the internal and external test datasets.\n\nThe comparisons among the CNN-based models revealed that the TopoCNN model was selected as the representative model due to its reasonable diagnostic performance and relative simplicity. No significant difference in AUC was observed between the TopoCNN and TopoCNN+Clinic models, suggesting that the addition of clinical variables did not substantially improve performance.\n\nIn summary, the evaluation involved a thorough comparison of different models, including simpler baselines and more complex CNN-based approaches. The TopoCNN model was identified as the most effective, balancing performance and simplicity.",
  "evaluation/confidence": "The evaluation of the models in this study includes several performance metrics, each accompanied by confidence intervals to indicate the reliability of the estimates. The area under the receiver operating characteristic curve (AUC) is a primary metric used to assess the models' diagnostic performance. For instance, the AUC for the TopoCNN model on the training dataset is reported as 0.903 with a 95% confidence interval of 0.870\u20130.935, providing a clear range within which the true AUC is likely to fall.\n\nStatistical significance is also a crucial aspect of the evaluation. The p-values associated with the AUC comparisons help determine whether the observed differences in performance between models are statistically significant. For example, the TopoCNN model's AUC is significantly higher than that of the pure CNN model on the training dataset (p < 0.001), indicating a superior performance. Similarly, the TopoCNN model outperforms the conventional MRI feature model on both the internal and external test datasets, with p-values of 0.008 and < 0.001, respectively.\n\nIn addition to AUC, other metrics such as sensitivity, specificity, and accuracy are reported with their respective confidence intervals. These metrics provide a comprehensive view of the models' performance across different aspects of diagnostic accuracy. For example, the sensitivity of the TopoCNN model on the training dataset is 0.844 with a 95% confidence interval of 0.787\u20130.901, and the specificity is 0.828 with a 95% confidence interval of 0.770\u20130.886.\n\nThe calibration and decision curves further support the models' reliability. The TopoCNN and TopoCNN+Clinic models demonstrate good calibration, as indicated by the Hosmer\u2013Lemeshow test and calibration slopes close to 1. This suggests that the predicted probabilities are well-aligned with the observed outcomes. Decision curves show that these models provide the largest net benefits, reinforcing their clinical utility.\n\nOverall, the evaluation confidence is high, with robust statistical analyses and clear reporting of performance metrics and their confidence intervals. The results indicate that the TopoCNN model is superior to both the pure CNN model and the conventional MRI feature model, with statistically significant improvements in diagnostic performance.",
  "evaluation/availability": "Not enough information is available."
}