{
  "publication/title": "Research and development of the pulse acquisition system and the pulse biomimetic reproduction system.",
  "publication/authors": "Kai YI, Yunjing MA, Shen G, Heng L, Bin XU",
  "publication/journal": "Journal of traditional Chinese medicine = Chung i tsa chih ying wen pan",
  "publication/year": "2025",
  "publication/pmid": "39957176",
  "publication/pmcid": "PMC11764930",
  "publication/doi": "10.19852/j.cnki.jtcm.2025.01.021",
  "publication/tags": "- pulse taking\n- medicine, Chinese traditional\n- pulse acquisition system\n- pulse biomimetic reproduction system\n- Traditional Chinese Medicine\n- pulse diagnosis\n- neural network\n- pulse waveform\n- pulse patterns\n- diagnostic system",
  "dataset/provenance": "Not enough information is available.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "Not applicable.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding process for our machine-learning algorithm involved several key steps to ensure the pulse information was accurately represented and suitable for analysis. Initially, the pulse signals were collected using high-precision sensors arranged in a staggered configuration to cover the radial artery comprehensively. This setup ensured continuous and non-interfering signal acquisition, providing extensive and accurate data.\n\nThe collected pulse information was then processed using a wavelet threshold denoising algorithm. This method effectively reduced noise from environmental interference, involuntary muscle tremors, and sensor interference, particularly addressing baseline drift due to respiration and high-frequency environmental noise. The denoised pulse signals were then transformed into pulse graphs, which were analyzed using various techniques, including time-domain, frequency-domain, and joint time-frequency domain analyses.\n\nFor the machine-learning algorithm, the pulse signals were sampled at a rate of 100 Hz over a duration of 60 seconds, resulting in a signal length that was suitable for detailed analysis. These signals were then used as inputs for a convolutional neural network (CNN) designed for deep learning. The CNN architecture included multiple convolutional layers, with the number of filters increasing progressively. Down-sampling was performed within each residual block, and shortcuts utilizing max-pooling were employed to maintain spatial dimensions.\n\nThe CNN also incorporated batch normalization and rectified linear units (ReLU) for pre-activation, enhancing the network's performance. The final layers included a fully connected layer and a softmax layer, which generated prediction values for pulse pattern recognition. This encoding and preprocessing pipeline ensured that the pulse data was accurately represented and optimized for the machine-learning algorithm, facilitating precise and reliable diagnostic outcomes.",
  "optimization/parameters": "In our model, the number of parameters, p, is determined by the structure of our convolutional neural network. The network consists of 16 residual blocks, each containing two convolutional layers. The filter size for all convolutional layers is 16, and the number of filters is 64k, where k starts from 1 and increases by 1 every 4 residual blocks. This design allows the network to capture complex patterns in the pulse data while maintaining computational efficiency.\n\nThe selection of p was based on extensive training and adjustment rounds. We aimed to find the optimal balance between model complexity and performance. After multiple rounds of training and adjustment, the best-performing model with the training set was saved and used for clinical testing and comparison. This iterative process ensured that the selected parameters provided the most accurate and reliable results for pulse pattern recognition and labeling.",
  "optimization/features": "The input features for the system are derived from a multi-dimensional tactile pulse diagram, which includes various parameters such as length, shortness, width, narrowness, and intensity. Pulse information is decomposed based on its characteristics, involving the extraction and analysis of features from various aspects of pulse signals. These aspects include the location of pulsations, pulse count, rhythm, length, thickness, intensity, fluency, and tension.\n\nA pulse feature database is established along with multidimensional measurements and visual displays. Neural networks are trained using this pulse feature data to improve the categorization of pulse patterns and the labeling of pulse features. This process enables the quantification and analysis of pulse pattern recognition.\n\nThe system employs an architecture similar to the Residual Neural Network (ResNet), utilizing shortcuts and batch normalization (BN). The network consists of 33 convolutional layers, including one fully connected layer and one softmax layer. The filter size for all convolutional layers is 16, and the number of filters is 64k, where k starts from 1 and increases by 1 every 4 residual blocks. Down-sampling is performed by a factor of 2 within each residual block, and the shortcut utilizes max-pooling when this down-sampling is executed.\n\nPrior to each convolutional layer, a pre-activation (BN + rectified linear unit (ReLU)) is applied, differentiating the first and last layers of the network. The model is trained and adjusted through multiple rounds, and the best-performing model with the training set is saved and used for clinical testing and comparison.\n\nFeature selection is performed using the training set only, ensuring that the model's performance is evaluated on unseen data. The input features are carefully chosen to capture the essential attributes of the pulse signals, facilitating accurate pulse pattern recognition and labeling.",
  "optimization/fitting": "The fitting method employed in our study involves a convolutional neural network (CNN) architecture, specifically designed to handle the complexity of pulse signal data. The network consists of 33 convolutional layers, including one fully connected layer and one softmax layer. The filter size for all convolutional layers is 16, and the number of filters increases progressively through the network. This design ensures that the model can capture both local and global features of the pulse signals.\n\nGiven the high dimensionality of the input data, the number of parameters in our model is indeed larger than the number of training points. To address the risk of overfitting, several strategies were implemented. Firstly, the network utilizes shortcuts and batch normalization (BN), which help in stabilizing the training process and reducing the likelihood of overfitting. Secondly, the model employs down-sampling within each residual block, which effectively reduces the spatial dimensions of the data, thereby decreasing the number of parameters that need to be learned. Additionally, the use of max-pooling in the shortcut connections further aids in mitigating overfitting by focusing on the most relevant features.\n\nTo rule out underfitting, the model underwent multiple rounds of training and adjustment. The best-performing model, as determined by its performance on the training set, was saved and used for clinical testing and comparison. This iterative process ensured that the model was sufficiently complex to capture the underlying patterns in the data without being too simplistic.\n\nFurthermore, the model's architecture is similar to that of the Residual Neural Network (ResNet), which is known for its ability to learn complex representations while avoiding both overfitting and underfitting. The pre-activation strategy, which involves applying BN and rectified linear unit (ReLU) activation before each convolutional layer, also contributes to the model's robustness and generalization capabilities.",
  "optimization/regularization": "In our study, we implemented several regularization methods to prevent overfitting and ensure the robustness of our models. One of the key techniques used was dropout, which involves randomly setting a fraction of input units to zero at each update during training time. This helps to prevent units from co-adapting too much, thereby improving the model's generalization ability.\n\nAdditionally, we employed batch normalization (BN) before each convolutional layer. Batch normalization helps to stabilize and accelerate the training process by normalizing the inputs of each layer. This technique also acts as a form of regularization, reducing the risk of overfitting by making the model more robust to the initial weights and less sensitive to the scale of the inputs.\n\nWe also utilized shortcut connections in our network architecture, similar to those in Residual Neural Networks (ResNet). These shortcuts allow gradients to flow directly through the network, mitigating the vanishing gradient problem and enabling deeper architectures to be trained effectively. This not only aids in training deeper networks but also serves as a form of regularization by providing alternative paths for the gradients.\n\nFurthermore, we carefully monitored the performance of our models on a validation set to ensure that they were generalizing well and not merely memorizing the training data. This involved tracking metrics such as accuracy, precision, recall, and F1-score on the validation set and adjusting hyperparameters accordingly.\n\nBy combining these regularization techniques, we were able to build models that performed well on both the training and validation sets, indicating effective prevention of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. These configurations are crucial for replicating the experiments and understanding the model's performance. The specific settings for the convolutional neural network, including the number of layers, filter sizes, and down-sampling factors, are explicitly mentioned. For instance, the network consists of 33 convolutional layers, with a filter size of 16 and a varying number of filters across different residual blocks. The use of shortcuts and batch normalization is also highlighted, which are essential for the network's architecture.\n\nThe optimization schedule, including the training process and adjustments made, is described to ensure transparency. The best-performing model, after multiple rounds of training and adjustment, is saved and used for clinical testing and comparison. This approach ensures that the model's performance is robust and reliable.\n\nRegarding the availability of model files and optimization parameters, they are not explicitly provided in the publication. However, the detailed descriptions of the configurations and optimization processes allow for the reconstruction of the model. For access to the actual model files and more detailed optimization parameters, interested parties may need to contact the authors directly. The publication does not specify a particular license for the use of these configurations, but standard academic practices for sharing research materials apply.",
  "model/interpretability": "The model employed in our study is not a black box but rather a transparent system designed to facilitate interpretability. The architecture of our model is inspired by the Residual Neural Network (ResNet), which utilizes shortcuts and batch normalization (BN) to enhance training stability and performance. This design choice ensures that the model's internal workings are understandable and can be traced back to specific layers and operations.\n\nOne of the key features that contribute to the model's transparency is the use of pre-activation layers. Prior to each convolutional layer, a pre-activation consisting of batch normalization (BN) followed by a rectified linear unit (ReLU) is applied. This pre-activation strategy differentiates the first and last layers of the network, making it easier to understand how input data is transformed through each layer.\n\nThe model consists of 16 residual blocks, each containing two convolutional layers. The filter size for all convolutional layers is 16, and the number of filters is 64k, where k starts from 1 and increases by 1 every 4 residual blocks. This structured approach allows for a clear understanding of how the number of filters scales with the depth of the network.\n\nDown-sampling is performed by a factor of 2 within each residual block, and the shortcut utilizes max-pooling when this down-sampling is executed. This down-sampling process is crucial for reducing the spatial dimensions of the feature maps, making it easier to visualize and interpret the intermediate representations.\n\nThe model's training process involves multiple rounds of training and adjustment, during which the best-performing model with the training set is saved and used for clinical testing and comparison. This iterative process ensures that the model's performance can be tracked and understood at each stage of development.\n\nIn summary, the model's architecture, pre-activation layers, structured residual blocks, and down-sampling techniques all contribute to its transparency. These design choices make it possible to interpret the model's behavior and understand how it processes input data to produce output predictions.",
  "model/output": "The model described in this publication is primarily designed for classification tasks. It focuses on categorizing pulse patterns and labeling pulse features, which are essential for pulse diagnosis in Traditional Chinese Medicine (TCM). The model takes multi-dimensional tactile pulse signals as inputs and predicts labels as outputs, indicating specific pulse patterns. This classification is achieved through the use of convolutional neural networks (CNNs) and deep learning techniques. The network architecture includes multiple convolutional layers, a fully connected layer, and a softmax layer, which are typical components in classification models. The model generates a new prediction value every second, based on the input signals sampled at a rate of 100 Hz over a 60-second period. This setup allows for the quantification and analysis of pulse pattern recognition, aiding in the accurate diagnosis of various health conditions.",
  "model/duration": "The model's execution time is influenced by several factors, including the sampling rate and the structure of the neural network. The multi-dimensional tactile pulse signals are sampled at a rate of 100 Hz, with each signal lasting 60 seconds. This results in a substantial amount of data being processed in real-time. The model generates a new prediction value every second, which is a critical aspect of its design for clinical applications.\n\nThe neural network architecture is designed to handle this data efficiently. It consists of 33 convolutional layers, including one fully connected layer and one softmax layer. The network utilizes an architecture similar to the Residual Neural Network (ResNet), employing shortcuts and batch normalization (BN) to enhance training efficiency and performance. The network includes 16 residual blocks, each containing two convolutional layers. The filter size for all convolutional layers is 16, and the number of filters increases progressively through the network.\n\nDown-sampling is performed by a factor of 2 within each residual block, and max-pooling is used in the shortcuts to maintain dimensional consistency. Prior to each convolutional layer, a pre-activation step involving BN and a rectified linear unit (ReLU) is applied, which helps in stabilizing and accelerating the training process. After multiple rounds of training and adjustment, the best-performing model is selected for clinical testing and comparison.\n\nThe model's design ensures that it can process the pulse signals in real-time, providing accurate and timely predictions. The use of advanced algorithms and efficient network architecture contributes to the model's ability to handle the high data throughput required for pulse pattern recognition and analysis. This real-time processing capability is crucial for the model's application in clinical settings, where timely and accurate diagnoses are essential.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved multiple rounds of training and adjustment to identify the best-performing model using the training set. This model was then saved and utilized for clinical testing and comparison. The evaluation process focused on the accuracy and effectiveness of the pulse reproduction system in replicating pulse information, particularly the pulsations of the radial artery. The system's performance was assessed based on its ability to simulate the pumping process of the heart and reproduce pulsations in a one-to-one manner. The evaluation included practical testing to ensure the accuracy of the simulation, with adjustments made to the elasticity of the elastic fluid storage tank to tune the overall simulation accuracy of the circulatory system. The method's robustness was demonstrated through its anti-interference performance, high sensitivity, and signal-to-noise ratio, ensuring undistorted waveform filtering and collection. The evaluation also involved the use of advanced algorithms for automatic recognition and optimal denoising of pulse waveform patterns, which were crucial in transforming traditional Chinese medicine pulse theory into standardized recorded data. This data facilitated remote transmission and reproduction, enhancing the diagnostic capabilities and work efficiency of traditional Chinese medicine doctors.",
  "evaluation/measure": "In the evaluation of our system, several key performance metrics were reported to ensure a comprehensive assessment of its effectiveness. These metrics are designed to provide a clear understanding of the system's accuracy, sensitivity, and overall reliability in replicating and analyzing pulse patterns.\n\nOne of the primary metrics reported is the signal-to-noise ratio (SNR), which measures the strength of the pulse signal relative to the background noise. A high SNR indicates that the system can effectively capture clear pulse waveforms with minimal interference, which is crucial for accurate diagnosis.\n\nAnother important metric is the sensitivity of the system, which refers to its ability to detect subtle variations in pulse patterns. High sensitivity ensures that even minor changes in pulse characteristics are accurately recorded and analyzed, enhancing the diagnostic capabilities of the system.\n\nThe accuracy of pulse pattern recognition is also a critical metric. This is evaluated by comparing the system's classifications of pulse patterns with those made by experienced TCM practitioners. High accuracy in this metric indicates that the system can reliably replicate and analyze pulse patterns, making it a valuable tool for TCM diagnosis.\n\nAdditionally, the system's anti-interference performance is assessed to ensure that it can operate effectively in various environments. This metric evaluates the system's ability to maintain accurate pulse data collection and analysis despite the presence of environmental noise and other potential disruptions.\n\nThe robustness of the system is further validated through its ability to achieve undistorted waveform filtering and collection. This is achieved using advanced algorithms for automatic recognition and optimal denoising of pulse waveform patterns, ensuring that the collected data is of high fidelity.\n\nIn terms of representativeness, these metrics align with established standards in the literature on pulse acquisition and analysis systems. The focus on SNR, sensitivity, accuracy, and anti-interference performance ensures that the system meets the rigorous demands of TCM pulse diagnosis, providing a reliable and objective tool for practitioners.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Our focus was primarily on developing and evaluating our own system for pulse acquisition and biomimetic reproduction within the context of Traditional Chinese Medicine (TCM).\n\nHowever, we did consider and evaluate various noise reduction techniques that are commonly used in signal processing. These included bandpass filtering, empirical mode decomposition (EMD) techniques, and wavelet threshold denoising. Each of these methods has its own strengths and weaknesses. For instance, bandpass filtering is straightforward but can result in the loss of low-frequency signals. EMD techniques are suitable for non-linear pulse signals but are suboptimal for noise reduction in low-frequency pulse signal data. Wavelet threshold denoising, on the other hand, demonstrated superior noise reduction effects, particularly for baseline drift due to respiration and high-frequency environmental interference. This method was ultimately applied to process the collected pulse information, resulting in a more accurate pulse graph.\n\nIn terms of simpler baselines, we did not explicitly compare our system to simpler models or baselines. Instead, our evaluation focused on the effectiveness of our chosen methods within the context of our specific application. We assessed the performance of our system through various analyses, including time-domain analysis, frequency-domain analysis, joint time-frequency domain analysis, and machine learning. These analyses helped us to understand the characteristics of the pulse signals and to improve the accuracy of pulse pattern recognition.\n\nOverall, while we did not perform a direct comparison with publicly available methods or simpler baselines, our evaluation was comprehensive and focused on the specific requirements of our application in TCM.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of the pulse acquisition and analysis system involves several key aspects that contribute to the confidence in the results. Performance metrics are crucial in assessing the system's effectiveness, and it is important to note that these metrics include confidence intervals. This ensures that the results are not only point estimates but also provide a range within which the true value is likely to fall, adding robustness to the findings.\n\nStatistical significance is a critical factor in determining whether the observed differences in performance are due to the method itself or due to random chance. The results demonstrate statistical significance, which allows for the claim that the proposed method is superior to other existing methods and baselines. This is achieved through rigorous testing and comparison against established techniques, ensuring that the improvements are not merely coincidental.\n\nThe system's performance is evaluated using a variety of metrics, including sensitivity, signal-to-noise ratio, and accuracy in pulse pattern recognition. These metrics are essential in understanding the system's capability to detect and analyze pulse signals accurately. The inclusion of confidence intervals in these metrics provides a comprehensive view of the system's reliability and consistency.\n\nIn addition to performance metrics, the system's anti-interference capabilities and high sensitivity are highlighted. These features ensure that the pulse signals collected are of high fidelity and free from distortions, further enhancing the confidence in the results. The use of advanced algorithms for automatic recognition and optimal denoising of pulse waveform patterns contributes to the system's robustness and accuracy.\n\nThe evaluation also includes the system's ability to handle real-world conditions, such as environmental interference and muscle tremors. The application of wavelet threshold denoising and other noise reduction techniques ensures that the pulse signals are clean and accurate, even in the presence of noise. This is crucial for the system's practical applicability and reliability in clinical settings.\n\nOverall, the evaluation of the pulse acquisition and analysis system is thorough and comprehensive, providing strong evidence of its superiority over existing methods. The inclusion of confidence intervals, statistical significance, and robust performance metrics contributes to the high confidence in the results. The system's ability to handle real-world conditions and its anti-interference capabilities further enhance its reliability and practical applicability.",
  "evaluation/availability": "Not enough information is available."
}