{
  "publication/title": "Challenges in interpreting allergen microarrays in relation to clinical symptoms: a machine learning approach.",
  "publication/authors": "Prosperi MC, Belgrave D, Buchan I, Simpson A, Custovic A",
  "publication/journal": "Pediatric allergy and immunology : official publication of the European Society of Pediatric Allergy and Immunology",
  "publication/year": "2014",
  "publication/pmid": "24131308",
  "publication/pmcid": "PMC4282342",
  "publication/doi": "10.1111/pai.12139",
  "publication/tags": "- component-resolved diagnostics\n- asthma\n- wheeze\n- rhinitis\n- airway hyper-reactivity\n- methacholine\n- IgE\n- children\n- machine learning\n- feature selection\n- logistic regression\n- random forests\n- Bayesian networks",
  "dataset/provenance": "The dataset used in this study originates from the Manchester Asthma and Allergy Study, a population-based birth cohort. This study was specifically designed to investigate the association between specific immunoglobulin E (sIgE) patterns and clinical symptoms in children. The data were collected from participants at the age of 11 years.\n\nA total of 822 children were reviewed, and a sample for IgE measurement was obtained from 461 of these children, which constitutes 56.1% of the total cohort. There was no significant difference in gender, family history of allergic diseases, position in sibship, asthma, sensitization (skin tests), or parental atopy between those with and without IgE measurements.\n\nThe presence of sIgE to 112 allergen components was assessed using the ImmunoCAP ISAC/C226. This microarray technology allows for the detection of specific IgE antibodies to a wide range of allergen components, providing a comprehensive profile of allergic sensitization in the study participants.\n\nThe dataset has been used to fit various statistical learning models, including decision trees, Bayesian networks, and logistic regression, to classify contemporaneous asthma, wheezing, airway hyper-reactivity, rhino-conjunctivitis, and eczema. These models were adjusted for gender and aimed to fully exploit the large amount of information provided by the microarray, associating it with clinical symptoms.\n\nThe study population and data sources have been described in detail in previous publications, ensuring that the dataset is well-documented and reproducible. The use of validated questionnaires and standardized measurements, such as the methacholine challenge for assessing airway hyper-reactivity, further enhances the reliability of the data.",
  "dataset/splits": "The study involved a dataset of 822 children. However, the specific sample for IgE measurement was obtained for 461 children, which represents 56.1% of the total participants. There was no significant difference in various demographic and clinical factors between those with and without IgE measurements.\n\nTo assess the ability of the models to generalize on unseen data, a repeated validation procedure was executed 50 times. Each validation involved a randomized training/test split, with 80% of the data used for training and 20% for testing. This process was repeated 50 times to ensure robustness and reliability of the model performance. The distribution of data points in each split followed the 80/20 ratio, meaning approximately 369 data points were used for training and 92 for testing in each iteration.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in our study are well-established and widely recognized in the field. We employed several types of models, including logistic regression, decision trees, random forests, naive Bayes, and Bayesian networks. These algorithms are part of the broader class of supervised learning methods, which are designed to learn from labeled data to make predictions or decisions.\n\nThe algorithms used are not new; they have been extensively studied and applied in various domains. Logistic regression is a fundamental statistical method used for binary classification problems. Decision trees and random forests are popular for their ability to handle nonlinear relationships and interactions between variables. Naive Bayes and Bayesian networks are probabilistic models that can capture dependencies among variables.\n\nThe reason these algorithms were not published in a machine-learning journal is that they are standard techniques that have already been thoroughly documented and validated in the literature. Our focus was on applying these established methods to a specific dataset related to allergic diseases, rather than developing new algorithms. The novelty of our work lies in the application of these methods to analyze specific immunoglobulin E (sIgE) patterns and their association with clinical outcomes such as asthma, wheeze, and rhino-conjunctivitis. By leveraging these well-known algorithms, we aimed to gain insights into the complex relationships between allergen components and clinical symptoms, contributing to the broader understanding of allergic diseases.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, we employed various data encoding and preprocessing techniques to optimize the performance of our machine-learning algorithms. Specifically, we transformed specific IgE (sIgE) values in several ways to better capture the underlying patterns associated with clinical outcomes.\n\nWe initially binarized sIgE values using a threshold of 0.3 ISU, which is a common practice in clinical settings. This approach, however, may oversimplify the data, potentially leading to a loss of important information. To address this, we also discretized sIgE values into four categories based on the manufacturer's semiquantitative scale: undetectable or very low, low, moderate to high, and very high. This method provides a more nuanced representation of sIgE levels.\n\nAdditionally, we used an automated supervised discretization approach, which adaptively determines the optimal number of bins for each allergen component. This method leverages the outcome data to create more informative categories, potentially improving the model's predictive power.\n\nWe also explored continuous transformations of sIgE values, including square-root and hyperbolic-arcsine transformations. These transformations can help normalize the data and reduce the impact of outliers, making the data more suitable for certain machine-learning algorithms.\n\nFurthermore, we applied other normalization methods, such as quantile normalization, to ensure that the sIgE values were comparable across different allergen components. This step is crucial for maintaining the integrity of the data when dealing with high-dimensional datasets.\n\nAll these transformations were applied to the sIgE values measured by the ImmunoCAP ISAC/C226 assay, which assesses the presence of sIgE to 112 allergen components. The transformed data were then used as input features for our machine-learning models, including decision trees, Bayesian networks, logistic regression, and random forests. By comparing the performance of these models across different data encoding strategies, we aimed to identify the most effective approach for predicting clinical outcomes such as asthma, wheezing, airway hyper-reactivity, rhino-conjunctivitis, and eczema.",
  "optimization/parameters": "In our study, the number of variables selected by LogitBoost yielded a median of 9 covariates per model across all validation runs, with an interquartile range of 7 to 18. This indicates that the models typically used between 7 and 18 input parameters. The selection of these variables was influenced by the specific modeling technique employed. For instance, the stepwise heuristic for Na\u00efve Bayes/Bayesian Networks and Logistic Regression with different starting points led to different final sets of variables, likely due to the presence of correlated variables. Additionally, the automated supervised discretization method was found to yield the best results, suggesting that the transformation and discretization policy of specific IgE (sIgE) values played a significant role in variable selection. The models considered a range of allergens, including those from dust mites, cats, dogs, and various pollens, depending on the clinical outcome being predicted. For asthma, a broader set of top-scoring allergens was identified, while for rhino-conjunctivitis, the top-scoring allergens were predominantly pollens followed by dust mites.",
  "optimization/features": "In our study, we utilized a comprehensive set of features derived from specific immunoglobulin E (sIgE) patterns, along with gender, to predict various clinical outcomes. The specific allergen components measured by the ISAC/C226 assay were included as features, resulting in a total of 112 sIgE components plus gender, making 113 features in total.\n\nFeature selection was indeed performed to enhance the predictive performance of our models. For logistic regression, we employed the LogitBoost method, which is a feature selection technique that iteratively builds an additive model to improve predictive accuracy. This method helped in identifying the most relevant covariates for each model across all validation runs.\n\nFor other models, such as decision trees, random forests, and Bayesian networks, feature selection was integrated into the model-building process. Decision trees and random forests inherently perform feature selection by evaluating the importance of each variable in splitting the data. Bayesian networks, on the other hand, select features based on the structure learning algorithm used, which identifies the most relevant variables and their dependencies.\n\nAll feature selection processes were conducted using the training set only, ensuring that the validation and test sets remained unbiased. This approach helped in preventing overfitting and ensured that the selected features were generalizable to new, unseen data.",
  "optimization/fitting": "The study employed various statistical learning models to analyze ISAC/C226 assay data, aiming to predict clinical outcomes such as asthma, wheezing, airway hyper-reactivity (AHR), rhino-conjunctivitis, and eczema. The models included Random Forests (RF), Logistic Regression (LR), Na\u00efve Bayes (NB), and Bayesian Networks (BN). The number of parameters in these models varied, but generally, the feature sets included a substantial number of specific IgE components, along with gender, resulting in a relatively large number of parameters compared to the training points.\n\nTo address over-fitting, several strategies were implemented. Firstly, repeated validation was conducted through 50 randomized training/test splits (80%/20%), ensuring that the models' performance was assessed on unseen data. This approach helped in evaluating the models' ability to generalize. Secondly, the use of embedded feature selection methods, such as the Gini index in RF and information gain in Decision Trees (DT), helped in selecting the most relevant features, thereby reducing the risk of over-fitting. Additionally, the comparison of different models, including simpler ones like LR and NB, provided a benchmark to assess the complexity and performance of more sophisticated models like RF and BN.\n\nUnder-fitting was addressed by comparing the performance of different models and ensuring that the selected models could capture the underlying patterns in the data. The use of nonlinear methods like RF and BN allowed for the modeling of complex interactions among variables, which might not be captured by linear models alone. The assessment of model performance using metrics such as accuracy, AUROC, sensitivity, and specificity ensured that the models were not too simplistic to capture the necessary patterns.\n\nIn summary, the study carefully balanced the risk of over-fitting and under-fitting by employing robust validation techniques, feature selection methods, and a comparison of different model complexities. This approach ensured that the models were neither too complex to generalize well nor too simple to capture the underlying data patterns.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was cross-validation, specifically repeated validation, where we executed a randomized training/test procedure 50 times with an 80%/20% split. This approach helped us assess the ability of our models to generalize to unseen data.\n\nAdditionally, we utilized embedded feature selection methods within some of our models. For instance, in the decision tree (DT) model, we employed information gain and pruning techniques. In the random forest (RF) model, we used the Gini index and random subset selection. These methods help in selecting the most relevant features and pruning less important ones, thereby reducing the complexity of the models and preventing overfitting.\n\nFor logistic regression (LR), we applied LogitBoost, which is an ensemble method that combines multiple weak learners to create a strong predictive model. This technique helps in improving the model's performance and reducing overfitting by focusing on the instances that are harder to classify.\n\nIn the case of naive Bayes (NB) and Bayesian networks (BN), we used a cross-validated wrapper method with a best-first search and the K2 algorithm for feature and topology selection. This approach ensures that the selected features and network structures are optimal and reduces the risk of overfitting by evaluating the model's performance on validation data.\n\nOverall, these regularization techniques were integral to our modeling process, ensuring that our models were robust, generalizable, and not overly complex.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models used in this study vary in their interpretability, ranging from transparent to more complex, black-box approaches.\n\nLogistic regression (LR) is one of the more interpretable models. It provides a linear combination of input features, where each feature has an associated coefficient that indicates its importance and direction of effect. This makes it straightforward to understand the contribution of each allergen component to the predicted outcome. For instance, a positive coefficient would suggest a positive association with the outcome, while a negative coefficient would indicate a negative association.\n\nDecision trees (DTs) are also relatively interpretable. They divide the population into subgroups based on the values of covariates, creating a tree structure that can be easily visualized. Each split in the tree is based on a single feature, making it clear which variables are most important for the prediction. For example, a decision tree might split the data based on whether the IgE level for a specific allergen is above or below a certain threshold.\n\nRandom forests (RF), while powerful in terms of predictive performance, are less interpretable than decision trees or logistic regression. They consist of an ensemble of decision trees, and the final prediction is an average of the predictions from all the trees. This makes it difficult to trace back the importance of individual features. However, RFs do have methods for measuring variable importance, which can help identify the most influential allergens.\n\nBayesian networks (BN) are graphical models that represent dependencies between variables as a directed acyclic graph. While they can capture complex interactions, the resulting networks can be difficult to interpret, especially when they include many variables. Naive Bayes (NB), a simpler version of BN, assumes conditional independence between variables given the outcome, making it more interpretable. It can be abstracted to a main-effect logistic model, where each variable has a weight, similar to LR.\n\nIn summary, while some models like logistic regression and decision trees offer clear interpretability, others like random forests and Bayesian networks are more complex and less transparent. The choice of model depends on the trade-off between predictive performance and interpretability.",
  "model/output": "The models employed in this study are primarily classification models. They were used to predict various clinical outcomes such as asthma, wheezing, airway hyper-reactivity (AHR), rhino-conjunctivitis, and eczema based on specific immunoglobulin E (sIgE) patterns. The performance of these models was evaluated using metrics suitable for classification tasks, such as the area under the receiver operating characteristic curve (AUROC), sensitivity, and specificity.\n\nSeveral types of models were utilized, including logistic regression (LR), decision trees (DT), random forests (RF), naive Bayes (NB), and Bayesian networks (BN). Each of these models was fitted to investigate the discriminative ability of sIgE patterns in relation to the clinical outcomes. The logistic regression models were fitted using both the sum of and the number of positive sIgE values, as well as sIgE to all allergen components with different transformations. Feature selection via LogitBoost was applied to handle the high number of variables in the logistic regression models.\n\nDecision trees and random forests were employed to explore potential nonlinear and interaction effects. Decision trees divide the population into nested subgroups based on the values of covariates, aiming to identify those with the highest discriminatory power. Random forests, an ensemble of decision trees, improve predictive performance by combining multiple decision pathways. Both DTs and RFs have dedicated methods for measuring variable importance, capturing complex interactions without explicitly defining them.\n\nBayesian networks were used to represent dependencies among covariates as graphs, where each node corresponds to a covariate and links between nodes indicate dependencies. These models help in understanding the relationships and interactions among different variables.\n\nThe performance of these models was assessed through repeated validation runs, and the results were summarized in terms of AUROC, sensitivity, and specificity. For most outcomes, the models performed comparably, with random forests generally outperforming others in terms of AUROC. Logistic regression models ranked highest in specificity. The study also highlighted that interactions among allergens might play a significant role, although a simple linear score with fewer allergen components could be as effective as more complex models.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the models was conducted using repeated validation, specifically executing 50 times a randomized training/test procedure with an 80%/20% split. This approach allowed us to assess the models' ability to generalize on unseen data. The performance metrics used included accuracy, area under the receiver operating characteristic (AUROC), sensitivity, and specificity. To compare the differences between models, a paired-corrected t-test was employed. Additionally, the power of the sample in relation to covariate size was assessed. The models were evaluated on their predictive performance for various outcomes such as asthma, wheezing, airway hyper-reactivity (AHR), rhino-conjunctivitis, and eczema. The evaluation also involved examining the importance of variables in relation to clinical outcomes and their dependencies, using methods like random forest feature importance plots and mutually adjusted odds ratios from LogitBoost logistic regression. The performance of different models, including random forests, logistic regression, naive Bayes, and Bayesian networks, was compared across these outcomes. The results indicated that random forests generally outperformed other approaches in terms of AUROC, while logistic regression ranked best in terms of specificity. The evaluation also considered the number of variables selected by different methods, such as LogitBoost, and the consistency of variable selection across different modeling techniques.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our statistical learning models. These metrics included accuracy, area under the receiver operating characteristic curve (AUROC), sensitivity, and specificity. Accuracy represents the percentage of correct predictions made by the model. AUROC measures the model's ability to distinguish between positive and negative classes, with higher values indicating better performance. Sensitivity, also known as recall, assesses the model's ability to correctly identify positive instances, while specificity evaluates the model's ability to correctly identify negative instances.\n\nThese metrics are widely used in the literature and provide a comprehensive view of model performance. Accuracy gives an overall sense of the model's correctness, but it can be misleading if the classes are imbalanced. AUROC is particularly useful for imbalanced datasets as it considers the trade-off between sensitivity and specificity across different threshold levels. Sensitivity and specificity provide detailed insights into the model's performance for positive and negative classes, respectively.\n\nBy reporting these metrics, we aim to provide a thorough evaluation of our models' predictive capabilities. The use of these metrics aligns with standard practices in the field, ensuring that our results are comparable to other studies. Additionally, we conducted repeated validation runs to assess the models' ability to generalize to unseen data, further enhancing the reliability of our findings.",
  "evaluation/comparison": "In our evaluation, we compared several statistical learning models to assess their performance in predicting various clinical outcomes using ISAC/C226 assay data. The models included Random Forests (RF), Logistic Regression (LR), Na\u00efve Bayes (NB), Bayesian Networks (BN), and Decision Trees (DT). We did not specifically compare our methods to publicly available benchmark datasets, but we did evaluate the models against each other using repeated validation procedures.\n\nFor the comparison, we used several performance metrics, including accuracy, area under the receiver operating characteristic (AUROC), sensitivity, and specificity. The ability of each model to generalize to unseen data was assessed through repeated validation, where we executed a randomized training/test procedure 50 times with an 80%/20% split. This approach allowed us to compare the differences between models using a paired-corrected t-test.\n\nWe also considered simpler baselines in our evaluation. For instance, we included a majority class predictor as a baseline for comparison. Additionally, we evaluated different versions of Logistic Regression models, including one that used the number of positive IgE and the sum of all IgE, providing a simpler baseline against more complex models.\n\nThe results indicated that Random Forests generally outperformed other approaches in terms of AUROC for most outcomes, except for rhino-conjunctivitis. Logistic Regression, particularly the model using LogitBoost, ranked highest in specificity. The performance of Na\u00efve Bayes and Bayesian Networks was comparable, suggesting that a simpler model assuming conditional independence among variables could be as effective as more complex models that account for interactions and dependencies.\n\nIn summary, our evaluation involved a comprehensive comparison of different statistical learning models, including simpler baselines, to determine their predictive performance for clinical outcomes. This approach allowed us to identify the strengths and weaknesses of each model and to draw conclusions about their relative effectiveness.",
  "evaluation/confidence": "The performance metrics presented in this study include confidence intervals, specifically the standard deviation, which provides a measure of variability around the mean performance. This allows for an assessment of the reliability and precision of the results.\n\nStatistical significance is also considered in the evaluation. The hypothesis that there was no difference in the mean performance among the random forest, logistic regression, naive Bayes, and Bayesian network models could not be rejected at the 0.05 level in most cases. This indicates that, for the most part, these models performed comparably. However, the decision tree model's performance was consistently inferior to that of the random forest, with a p-value less than 0.05. Similarly, logistic regression model i was also inferior to the random forest, except for the outcome of rhino-conjunctivitis.\n\nThe study employed repeated validation runs to ensure the robustness of the results. The area under the receiver operating characteristic curve (AUROC) plots and tables summarize the prediction performance obtained from these validation runs. This approach helps to build confidence in the reported performance metrics.\n\nIn summary, the performance metrics are accompanied by measures of variability, and statistical tests have been used to compare the models. This provides a solid foundation for evaluating the confidence in the results and the claims of model superiority.",
  "evaluation/availability": "Not enough information is available."
}