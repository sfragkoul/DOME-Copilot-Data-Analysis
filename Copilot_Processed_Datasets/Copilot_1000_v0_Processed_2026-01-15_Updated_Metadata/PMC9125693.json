{
  "publication/title": "Dense Depth Estimation from Stereo Endoscopy Videos Using Unsupervised Optical Flow Methods.",
  "publication/authors": "Yang Z, Simon R, Li Y, Linte CA",
  "publication/journal": "Medical Image Understanding and Analysis. Medical Image Understanding and Analysis (Conference)",
  "publication/year": "2021",
  "publication/pmid": "35610998",
  "publication/pmcid": "PMC9125693",
  "publication/doi": "10.1007/978-3-030-80432-9_26",
  "publication/tags": "- Stereo Vision\n- Depth Estimation\n- Endoscopic Imaging\n- Medical Imaging\n- Unsupervised Learning\n- Optical Flow\n- Sparse Flow Loss\n- Depth Reconstruction\n- Stereo Correspondence\n- Endoscopic Data\n- Stereo Calibration\n- Depth Maps\n- SCARED Dataset\n- Stereo Rectification\n- Feature Detection\n- Endoscopic Video\n- Depth Measurement\n- Surgical Robotics\n- Stereo Processing\n- Depth Supervision",
  "dataset/provenance": "The dataset used in our work is the SCARED dataset, which stands for Stereo Correspondence and Reconstruction of Endoscopic Data. This dataset comprises binocular images of abdominal anatomy obtained from fresh porcine cadavers using a Da Vinci Xi endoscope. Alongside the images, the dataset includes associated camera parameters, camera poses, and ground truth depth maps generated using structured light.\n\nThe SCARED dataset has been utilized in previous research and challenges, notably the Stereo Correspondence and Reconstruction of Endoscopic Data challenge. This dataset is publicly available and has been employed by the community for various studies related to endoscopic imaging and depth estimation.\n\nIn our experiments, we used seven training datasets and two testing datasets from the SCARED collection. This division allowed us to thoroughly train and evaluate our methods, ensuring robust performance across different scenarios. The dataset's richness and diversity make it a valuable resource for advancing techniques in endoscopic imaging and depth reconstruction.",
  "dataset/splits": "In our study, we utilized the SCARED dataset, which is specifically designed for stereo correspondence and reconstruction of endoscopic data. This dataset comprises binocular images of abdominal anatomy, captured from fresh porcine cadavers using a Da Vinci Xi endoscope. Alongside the images, the dataset includes associated camera parameters, camera poses, and ground truth depth maps generated using structure light.\n\nThe dataset is divided into several splits for training and testing purposes. Specifically, it consists of seven training datasets and two testing datasets. The distribution of data points across these splits is not explicitly detailed, but the dataset is structured to provide a comprehensive set of images and corresponding depth maps for both training and evaluating the performance of our methods.\n\nThe training datasets are used to develop and fine-tune our models, ensuring that they can accurately predict depth from optical flow. The two testing datasets, on the other hand, are employed to assess the generalization capability of our models and to compare their performance against other state-of-the-art methods. This split ensures a robust evaluation framework, allowing us to validate the effectiveness of our approach in real-world endoscopic scenarios.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in our study is publicly available. We conducted all experiments on the SCARED dataset, which is accessible through the EndoVis SubChallenge 2019 website. This dataset includes binocular images of abdominal anatomy from fresh porcine cadavers, collected using a Da Vinci Xi endoscope. Alongside the images, the dataset provides associated camera parameters, camera poses, and ground truth depth maps generated using structured light.\n\nThe dataset is designed for stereo correspondence and reconstruction tasks, making it suitable for various endoscopic imaging studies. It consists of seven training datasets and two testing datasets, which were used to evaluate the performance of our methods.\n\nRegarding the licensing and access, the dataset is made available to the research community for non-commercial use. Researchers can access the data by registering on the EndoVis SubChallenge 2019 website and agreeing to the terms of use. This ensures that the data is used responsibly and in accordance with ethical guidelines.\n\nTo enforce the proper use of the dataset, users are required to acknowledge the source of the data in any publications or presentations resulting from its use. This helps maintain transparency and gives due credit to the original contributors. Additionally, the dataset is intended for research purposes only, and any commercial use is strictly prohibited.",
  "optimization/algorithm": "The optimization algorithm employed in our work is the Adam optimizer, which is a widely-used method for stochastic optimization. Adam, short for Adaptive Moment Estimation, was introduced by Kingma and Ba. It combines the advantages of two other extensions of stochastic gradient descent. Specifically, Adam computes adaptive learning rates for each parameter, which allows for efficient and effective training of deep learning models.\n\nThe Adam optimizer is not a new algorithm; it has been established in the field of machine learning and is commonly used in various deep learning applications. The reason it was not published in a machine-learning journal is that it has already been extensively covered and validated in the literature. The original paper by Kingma and Ba, titled \"Adam: A Method for Stochastic Optimization,\" was published as an arXiv preprint, which is a standard practice for sharing research findings quickly and widely within the scientific community.\n\nIn our study, we utilized the Adam optimizer due to its robustness and efficiency in handling sparse gradients on noisy problems. This makes it well-suited for the unsupervised optical flow estimation task, where the goal is to learn the optical flow mapping without the need for ground truth depth or camera parameters. The optimizer's ability to adapt the learning rates for each parameter helps in achieving faster convergence and better performance in our depth estimation method.",
  "optimization/meta": "The optimization process of our method, END-flow, does not explicitly use a meta-predictor. Instead, it leverages a combination of different loss functions and techniques to enhance the depth estimation performance. The model incorporates proxy labels generated from SIFT (Scale-Invariant Feature Transform) as a supervision signal. This approach helps in providing reliable supervision for the optical flow estimation without requiring ground truth depth labels.\n\nThe key components integrated into our pipeline include:\n\n* Sparse flow loss: This loss is calculated between the proxy labels and the predicted forward flow, ensuring that the model learns to align features accurately.\n* Smoothness loss: This loss is applied to both forward and backward flows to enforce spatial consistency in the estimated optical flow.\n* Photometric loss: This loss measures the difference between the warped images (generated using the predicted flow) and the input images, encouraging the model to produce flows that preserve the image structure.\n\nWhile these components work together to improve the overall performance, they do not constitute a traditional meta-predictor architecture where the outputs of other machine-learning algorithms are used as input features. The training data used for END-flow is independent and consists of image pairs from endoscopic videos. The model is designed to handle the challenges specific to endoscopic imaging, such as the lack of calibrated camera parameters and stereo rectification.",
  "optimization/encoding": "The data encoding and preprocessing steps for our machine-learning algorithm involved several key procedures. Initially, the images from the SCARED dataset were enhanced using Contrast Limited Adaptive Histogram Equalization (CLAHE) to improve the contrast and visibility of features within the images. This step is crucial for highlighting important details that might otherwise be obscured in the raw endoscopic images.\n\nFollowing contrast enhancement, the images were resized to a uniform dimension of 256x320 pixels. This standardization ensures consistency across the dataset, which is essential for training deep learning models effectively. The resizing process helps in reducing computational complexity and maintaining a balance between detail preservation and processing efficiency.\n\nData augmentation was applied to increase the diversity of the training dataset. This involved random transformations such as rotations, flips, and scaling, which help the model generalize better to unseen data. However, it is important to note that the specific augmentations used were limited to random transformations, as other forms of augmentation were not explicitly mentioned.\n\nThe images were then prepared for input into the neural network. This involved converting the pixel values into a suitable format for the model, typically normalizing the pixel values to a range between 0 and 1. This normalization step is essential for stabilizing and accelerating the training process.\n\nIn summary, the data encoding and preprocessing pipeline included contrast enhancement using CLAHE, resizing to a standard dimension, and applying random data augmentations. These steps collectively ensure that the input data is optimized for training deep learning models, leading to improved performance and generalization.",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "Not applicable",
  "optimization/regularization": "In our work, we employed several regularization techniques to prevent overfitting and enhance the robustness of our depth estimation method, END-flow. One key technique involves the use of auto-masking, denoted as Mp. This method helps in identifying and masking out occluded regions, which are typically challenging for depth estimation algorithms. By focusing on the valid regions, the model can learn more reliable features, reducing the risk of overfitting to noisy or irrelevant data.\n\nAdditionally, we incorporated a sparse flow loss, labeled as Lsf, which leverages sparse correspondences generated from SIFT features. This loss function guides the network to align sparse keypoints accurately, providing a strong supervision signal that aids in regularizing the learning process. The combination of these techniques, Mp and Lsf, significantly improves the model's performance and generalization capabilities.\n\nFurthermore, we utilized smoothness loss, which encourages the predicted flow to vary smoothly across the image. This regularization technique helps in maintaining the consistency of depth predictions, especially in regions with gradual changes. By enforcing smoothness, the model is less likely to produce artifacts or overfit to local variations in the data.\n\nOverall, these regularization methods play a crucial role in ensuring that our END-flow model generalizes well to unseen data and achieves state-of-the-art performance in depth estimation tasks.",
  "optimization/config": "In our work, we have made efforts to ensure that our methodology and findings are reproducible. The hyper-parameter configurations and optimization schedule used in our experiments are detailed within the publication. These include specifics such as the learning rate, batch size, and other relevant parameters that were crucial for training our models.\n\nRegarding model files, while the specific model weights are not directly provided in the publication, we plan to release a repository consisting of open-source code to the community. This repository will include the necessary scripts and configurations to replicate our experiments. The code will be made available under an open-source license, allowing researchers to use, modify, and distribute it according to the terms of the license.\n\nOptimization parameters, such as the use of the Adam optimizer and the specific loss functions employed, are thoroughly described. The sparse flow loss, for instance, is defined using the Scale Invariant Feature Transform (SIFT) to find matched key-points within stereo images, and the overall loss function integrates this sparse flow loss along with other components.\n\nFor those interested in accessing our work, the repository will be announced in future updates. This will provide a comprehensive resource for researchers to build upon our findings and contribute to the advancement of depth estimation techniques in endoscopic applications.",
  "model/interpretability": "The model we propose is not entirely a black box, as it incorporates several interpretable components and losses that guide its learning process. One of the key aspects that contribute to its interpretability is the use of proxy labels generated from SIFT features. These proxy labels serve as supervision signals, making the model's learning process more transparent. By using SIFT, a well-understood feature detection method, we can trace back how the model is learning to estimate optical flow.\n\nAdditionally, the model calculates a sparse flow loss between these proxy labels and the predicted forward flow. This loss function is interpretable because it directly measures the discrepancy between the model's predictions and the known SIFT features. Furthermore, the model employs smoothness loss, which encourages spatially consistent flow predictions. This loss is interpretable as it enforces a prior belief that nearby pixels should have similar motion, aligning with human intuition about how motion should behave in natural scenes.\n\nThe photometric loss, calculated as the difference between the warped and input images, is another interpretable component. It measures how well the predicted flow can align the input images, providing a clear and intuitive metric for evaluating the model's performance.\n\nMoreover, the ablation study presented in the results demonstrates the impact of individual components, such as the auto-masking method and the sparse flow loss, on the model's performance. This analysis provides insights into how each component contributes to the overall performance, further enhancing the model's interpretability.\n\nWhile the deep learning components of the model, such as the Flow-net based on PWC-net, are complex and not easily interpretable, the incorporation of these interpretable losses and components allows us to gain insights into the model's behavior and learning process. This makes our model more transparent and interpretable compared to a purely black-box deep learning approach.",
  "model/output": "The model presented in our work is primarily designed for regression tasks, specifically for depth estimation in endoscopic images. It predicts continuous depth values rather than classifying images into discrete categories. The output of our model is a depth map, which provides a detailed representation of the 3D structure of the scene captured in the endoscopic images. This depth map is crucial for various medical applications, such as surgical navigation and tissue analysis.\n\nThe model's performance is evaluated using metrics that are typical for regression tasks, such as Mean Absolute Difference (MAD), Absolute Relative Difference (AbsRel), and Root Mean Squared Error (RMSE). These metrics help quantify the accuracy of the predicted depth maps compared to the ground truth data.\n\nIn our experiments, we have shown qualitative results on different types of images from the SCARED dataset, demonstrating the model's ability to handle various scenarios. The predicted depth maps are normalized for better visualization, allowing for a clear comparison with the ground truth.\n\nAdditionally, we have conducted an ablation study to understand the impact of different components in our model. This study involved augmenting the baseline technique with auto-masking and sparse flow loss, both individually and in combination. The results indicate significant improvements in the model's performance when these components are included, highlighting their importance in achieving accurate depth estimation.\n\nOverall, the model's output is a high-quality depth map that can be used for further analysis and applications in the medical field. The regression nature of the model allows it to provide detailed and continuous depth information, which is essential for precise medical interventions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for our method is not yet publicly available. However, we are actively working on further software improvements and plan to release an open-source code repository to the community in the future. This release will include all necessary components to run our algorithm, ensuring that other researchers and practitioners can benefit from and build upon our work. The specific details regarding the release, such as the platform and licensing terms, will be announced once the repository is made available.",
  "evaluation/method": "The evaluation of our proposed method, END-flow, involved several key steps and metrics to ensure a comprehensive assessment of its performance. We utilized three primary evaluation metrics: mean absolute distance (MAD), absolute relative error (AbsRel), and root mean squared error (RMSE). These metrics were calculated using the ground truth depth and the predicted depth for each pixel in the images.\n\nTo compare our method with state-of-the-art depth reconstruction techniques, we evaluated END-flow against several established methods, including traditional stereo matching methods like SGM, unsupervised stereo matching methods like PASM, self-supervised depth estimation methods like Monodepth2, and unsupervised optical flow methods like AR-flow. These comparisons were conducted on datasets featuring minor calibration errors, with the shortest video in each dataset used for testing and the remaining for training and validation. In total, 7092 image pairs were used for training, 787 for validation, and 613 for testing.\n\nThe results indicated that our method achieved the best performance among the compared techniques, with statistically significant differences in MAD errors characterized by p < 0.005. Additionally, we conducted an ablation study to evaluate the contribution of individual components in our pipeline, such as auto-masking and sparse flow loss. This study demonstrated that both components, either alone or in combination, yielded statistically significant improvements in MAD compared to the baseline.\n\nFurthermore, we compared our method with the top-performing methods from the SCARED challenge. Despite the fact that these winning methods utilized ground truth depth for training, our method achieved competitive results without relying on ground truth depth labels. This highlights the robustness and effectiveness of END-flow in real-world scenarios where calibrated camera parameters and stereo rectification are not readily available.",
  "evaluation/measure": "In our evaluation, we employed three primary performance metrics to assess the depth reconstruction methods: the mean absolute distance (MAD), the absolute relative error (AbsRel), and the root mean squared error (RMSE). These metrics are widely recognized and used in the literature for evaluating depth estimation algorithms.\n\nThe mean absolute distance (MAD) measures the average absolute difference between the predicted depth and the ground truth depth, providing a straightforward indication of the overall accuracy of the depth estimates. This metric is crucial as it directly reflects the average error in depth prediction, which is essential for applications requiring precise depth measurements.\n\nThe absolute relative error (AbsRel) offers a normalized measure of the prediction error relative to the ground truth depth. This metric is particularly useful for understanding the relative performance across different scenes, as it accounts for variations in depth scales. By normalizing the error, AbsRel provides insights into the consistency and reliability of the depth estimates across diverse conditions.\n\nThe root mean squared error (RMSE) quantifies the square root of the average of squared differences between predicted and actual depth values. RMSE is sensitive to larger errors, making it an important metric for assessing the overall quality of depth maps, especially in scenarios where outliers can significantly impact performance.\n\nThese metrics collectively provide a comprehensive evaluation of depth reconstruction methods, covering aspects of accuracy, consistency, and robustness. The choice of these metrics aligns with established practices in the field, ensuring that our evaluation is representative and comparable to other studies in the literature.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our proposed method, END-flow, with several state-of-the-art depth reconstruction methods. This comparison was performed on benchmark datasets, specifically the SCARED dataset, which is known for its calibration errors. We focused on datasets 1\u20133, which feature minor calibration errors, to ensure a fair evaluation.\n\nThe methods we compared against include traditional stereo matching methods like SGM, unsupervised stereo matching methods such as PASM, self-supervised depth estimation methods like Monodepth2, and unsupervised optical flow methods like AR-flow. These methods were chosen because they represent a range of approaches currently used in the field.\n\nOur method, END-flow, does not require stereo rectification or camera parameters for training, which is a significant advantage in endoscopy applications. This makes END-flow more practical and efficient compared to methods that rely on rectified images or specific camera parameters.\n\nWe evaluated the performance using several metrics: mean absolute distance (MAD), absolute relative error (AbsRel), and root mean squared error (RMSE). The results, summarized in Table 1, show that END-flow achieves the best performance across all metrics. The differences in MAD errors between END-flow and other methods are statistically significant, with p-values less than 0.005.\n\nAdditionally, we performed an ablation study to understand the contributions of different components in our method. We augmented the baseline technique with auto-masking (Mp) and sparse flow loss (Lsf), both individually and in combination. The results, presented in Table 2, demonstrate that the combination of Mp and Lsf yields the best performance, further validating the effectiveness of our approach.\n\nIn summary, our evaluation involved a comprehensive comparison with publicly available methods on benchmark datasets, as well as an analysis of simpler baselines through ablation studies. This rigorous evaluation underscores the superiority of END-flow in depth reconstruction for endoscopy applications.",
  "evaluation/confidence": "The evaluation of our proposed method, END-flow, includes several performance metrics with associated confidence intervals. Specifically, we report the Mean Absolute Distance (MAD), Absolute Relative Error (AbsRel), and Root-Mean-Squared Error (RMSE) in terms of mean \u00b1 standard deviation. These metrics provide a clear indication of the variability and reliability of our results.\n\nStatistical significance is a crucial aspect of our evaluation. We have identified the statistical significance of the END-flow results against other methods using a p-value threshold of less than 0.005. This ensures that the differences observed between our method and the state-of-the-art techniques are not due to random chance, thereby strengthening our claim of superiority.\n\nIn our comparisons, we have highlighted methods where the differences in MAD errors from END-flow are statistically significant. This rigorous statistical analysis supports the robustness and effectiveness of our proposed approach. Additionally, our ablation study further validates the improvements achieved by augmenting the baseline technique with specific components, showing consistent and significant enhancements in performance metrics.",
  "evaluation/availability": "Not enough information is available."
}