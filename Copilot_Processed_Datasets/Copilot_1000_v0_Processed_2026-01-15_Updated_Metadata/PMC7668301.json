{
  "publication/title": "High incidence of glucocorticoid-induced hyperglycaemia in inflammatory bowel disease: metabolic and clinical predictors identified by machine learning.",
  "publication/authors": "McDonnell M, Harris RJ, Borca F, Mills T, Downey L, Dharmasiri S, Patel M, Zare B, Stammers M, Smith TR, Felwick R, Cummings JRF, Phan HTT, Gwiggner M",
  "publication/journal": "BMJ open gastroenterology",
  "publication/year": "2020",
  "publication/pmid": "33187976",
  "publication/pmcid": "PMC7668301",
  "publication/doi": "10.1136/bmjgast-2020-000532",
  "publication/tags": "- Hyperglycemia\n- Inflammatory Bowel Disease (IBD)\n- Intravenous Hydrocortisone (IVH)\n- Capillary Blood Glucose (CBG) Monitoring\n- Steroid-Induced Diabetes\n- Intestinal Inflammation\n- Machine Learning\n- Random Forest (RF) Model\n- Systemic Inflammation\n- Predictive Modeling",
  "dataset/provenance": "Not enough information is available.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "The data used in this study is not publicly available in a forum. However, anonymized data and the random forest code can be made available upon request. This ensures that the data remains confidential while still allowing for potential replication or further analysis by other researchers.\n\nThe data sharing process is managed through direct requests, which helps in maintaining control over the distribution and use of the data. This approach also allows for the enforcement of specific conditions or agreements regarding the use of the data, ensuring that it is handled responsibly and ethically. The data availability statement explicitly mentions that the data can be provided upon request, indicating a structured process for data sharing.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the Random Forest (RF) regression model. This is a well-established ensemble learning method known for its robustness and ability to handle complex datasets. RFs work by constructing multiple decision trees during training and outputting the mean prediction of the individual trees. This approach helps to capture intricate dependency patterns among multivariate input features.\n\nThe RF algorithm is not new; it has been widely used and validated in various fields, including clinical research. The choice to use RF in our study was driven by its proven effectiveness in predictive modeling, particularly with smaller datasets. RFs are known to perform better than many other machine-learning methods in such scenarios.\n\nThe reason the RF algorithm was not published in a machine-learning journal is that our primary focus was on applying this established method to a specific clinical problem rather than developing a new algorithm. Our goal was to leverage the strengths of RF to identify key predictors of hyperglycemia in inflammatory bowel disease (IBD) patients treated with intravenous glucocorticoids. The application of RF in this context is novel, but the algorithm itself is well-documented and widely recognized in the machine-learning community.",
  "optimization/meta": "The model employed in this study is a Random Forest (RF) regression model, which is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it is an ensemble learning method that operates by constructing multiple decision trees during training and outputting the mean prediction of the individual trees.\n\nThe RF model was constructed using the scikit-learn package in Python. The process involved handling and formatting both categorical and continuous predictors appropriately. Pairwise correlations between input features were identified to eliminate similar features, ensuring that the model did not suffer from multicollinearity. This step is crucial for maintaining the model's predictive power and avoiding overfitting.\n\nThe RF models were optimized using a random grid search method. This technique helps in finding the best hyperparameters for the model, such as the maximum depth of the trees and the number of trees in the forest. The final model was evaluated using fivefold cross-validation, which involves splitting the data into five subsets, training the model on four subsets, and testing it on the remaining subset. This process is repeated five times, with each subset serving as the test set once. The mean squared error was used as the metric to evaluate the model's performance.\n\nThe training data for the RF model consisted of various clinical and biochemical predictors collected from IBD patients treated with intravenous hydrocortisone. These predictors included age, IBD diagnosis and subtype, disease duration, admission severity scores, serum biochemistry, glycated hemoglobin, faecal calprotectin, C-reactive protein, potential diabetes risk factors, self-reported weight loss, and malnutrition screening tool scores. The independence of the training data was ensured by the prospective observational study design, which included consecutive admissions of IBD patients over a specified period. This design helps in minimizing selection bias and ensuring that the data is representative of the target population.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for analysis. Laboratory values that were outside the quantification limit were substituted with the upper or lower limit value to maintain consistency. Categorical and continuous predictors were handled and formatted appropriately to facilitate the machine-learning process. The data was analyzed using Python V.3.7.4 and R V.3.6.1. Descriptive statistics were applied to the cohorts, and Pearson correlations between independent and dependent variables were visualized using heat maps generated with matplotlib and seaborn. Random forest (RF) machine learning models were constructed using the scikit-learn package V.0.22.1 to regress the phenotypic and admission clinical predictors. Pairwise correlations between input features were identified to eliminate similar features, ensuring that the model was not overfitted. Multivariable RF models were then constructed and optimized using a random grid search. Subsequently, fivefold cross-validation with a train-test split was used to test the effectiveness of the models in predicting glucose levels in the internal holdout set. The mean squared error was the reported metric for evaluating the model's performance.",
  "optimization/parameters": "In our study, we utilized a comprehensive set of input parameters to develop our Random Forest (RF) model for predicting hyperglycemia in IBD patients treated with intravenous hydrocortisone (IVH). The specific number of parameters (p) used in the model is not explicitly stated, but it is clear that a wide range of variables were considered.\n\nThe selection of these parameters was guided by their potential relevance to hyperglycemia and IBD management. These variables included demographic data such as age and body mass index (BMI), clinical parameters like disease duration and severity scores (Harvey Bradshaw Index or Partial Mayo Score), and various biochemical markers including C-reactive protein (CRP), platelet count, hemoglobin, and glycated hemoglobin (HbA1c). Additionally, potential diabetes risk factors and nutritional status indicators were also included.\n\nTo ensure the robustness of our model, we employed a random grid search method to optimize the RF model. This approach involved fitting the model multiple times with different combinations of parameters and hyperparameters, ultimately selecting the configuration that minimized the mean squared error. This process helped in identifying the most critical predictors, with CRP emerging as the most significant variable, followed by disease duration, platelet count, admission hemoglobin, and HbA1c.\n\nAge and BMI did not contribute significantly to the model's predictive power, indicating that systemic inflammatory burden and the duration of IBD were more influential in determining the risk of clinically significant hyperglycemia. The final model was validated using fivefold cross-validation to reduce overfitting and ensure its generalizability to new data.",
  "optimization/features": "The study utilized a comprehensive set of predictor variables as input features for the machine learning models. These features included demographic information such as age, clinical details like IBD diagnosis and subtype, disease duration, and admission severity scores (Harvey Bradshaw Index or Partial Mayo Score). Additionally, serum biochemistry, glycated hemoglobin (HbA1c), faecal calprotectin, C-reactive protein (CRP), potential diabetes risk factors (body mass index (BMI), family history, concomitant medications), self-reported weight loss, and the Malnutrition Universal Screening Tool score were considered.\n\nFeature selection was performed to eliminate similar features and reduce collinearity. This process involved identifying pairwise correlations between input features and removing redundant variables. The final set of features used in the Random Forest (RF) models was optimized through a random grid search method. This approach ensured that the most relevant and non-redundant features were included in the models, enhancing their predictive power.\n\nThe feature selection process was conducted using the training set only, adhering to best practices in machine learning to prevent data leakage and ensure the model's generalizability to new, unseen data. This rigorous approach helped in identifying the key predictors of hyperglycemia in IBD patients treated with intravenous hydrocortisone.",
  "optimization/fitting": "In our study, we employed a Random Forest (RF) model, which is an ensemble learning method known for its robustness and ability to handle complex datasets. The number of parameters in our RF model was indeed larger than the number of training points, as RF constructs multiple decision trees, each with its own set of parameters.\n\nTo mitigate the risk of overfitting, we implemented several strategies. Firstly, we used a random grid search method to optimize the model's hyperparameters, including the maximum depth of the trees. This process helped in finding the optimal complexity of the model that balances bias and variance. Secondly, we employed fivefold cross-validation to evaluate the model's performance. This technique ensures that the model generalizes well to unseen data by training and validating it on different subsets of the data. The consistency in performance across all folds of the cross-validation further supported the model's robustness.\n\nTo address underfitting, we ensured that the model was complex enough to capture the underlying patterns in the data. The RF model's ability to construct multiple decision trees allowed it to capture intricate relationships among the variables. Additionally, the model's performance was evaluated on a holdout set, which was not used during the training process. The comparable predictions between the training and test sets indicated that the model was neither underfitting nor overfitting.\n\nIn summary, the RF model's architecture, combined with hyperparameter tuning and cross-validation, helped in managing the risk of both overfitting and underfitting. The model's performance on the holdout set provided further confidence in its generalizability.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting when developing our machine learning models. One of the primary methods used was cross-validation. Specifically, we utilized fivefold cross-validation to ensure that our model's performance was robust and generalizable. This technique involves dividing the data into five subsets, training the model on four of these subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. By averaging the results, we obtained a more reliable estimate of the model's performance and reduced the risk of overfitting.\n\nAdditionally, we used a random forest (RF) regression model, which inherently helps to mitigate overfitting. RFs work by constructing multiple decision trees and averaging their outputs, which reduces the variance and improves the model's generalization to new data. The RF model was optimized using a random grid search method, which helps in finding the best hyperparameters that minimize overfitting.\n\nFurthermore, we carefully selected the maximum depth of the trees within the RF model to balance between bias and variance. By setting a maximum depth, we controlled the complexity of the individual trees, preventing them from becoming too deep and thus reducing the likelihood of overfitting.\n\nThese techniques collectively ensured that our model was robust and capable of accurately predicting hyperglycemia in patients without relying too heavily on the specific details of the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed a random forest (RF) model with a maximum depth of 90 trees, optimized using a random grid search method. This process was repeated 500 times to ensure robustness. The final mean squared error of the optimized model for non-diabetic patients was 1.876.\n\nThe variables contributing to the RF modeling and their respective importance are illustrated in Figure 2 of the supplemental material. This figure shows the relative importance of each variable, with CRP (C-reactive protein) being the most critical predictor, followed by disease duration, platelet count, admission hemoglobin, and HbA1c. Age and BMI did not contribute significantly to the model.\n\nFor the optimization process, we used fivefold cross-validation to reduce overfitting and ensure the model's generalizability. The performance of the model is demonstrated in Figure 3, which compares predicted highest capillary blood glucose (CBG) versus measured highest CBG, excluding subjects with a history of Diabetes Mellitus.\n\nThe model files and specific optimization parameters are not explicitly provided in the main text but are implied through the detailed methodology and results presented. The supplemental material, which includes figures and additional data, is available to support the findings and methods described. The publication is open access, ensuring that all relevant information is accessible to readers without additional barriers.",
  "model/interpretability": "The model employed in this study is a Random Forest (RF), which is inherently an ensemble learning method that can be considered somewhat of a black box due to its complexity. However, it offers more interpretability than many other machine learning models. The RF model works by constructing multiple decision trees and averaging their outputs, which allows it to capture complex dependency patterns among multivariate input features.\n\nOne of the strengths of the RF model is its ability to handle collinearity among variables without significantly affecting its predictive performance. This is particularly useful in clinical datasets where many variables may be interrelated. While collinearity can sometimes lead to overfitting in other models, RFs are robust in this regard, making them reliable predictors even when variables are collinear.\n\nThe model's interpretability is further enhanced by the use of heat maps, which visualize the relationships between variables. These heat maps help identify which variables are most important in predicting the degree of hyperglycemia. For instance, admission CRP, length of disease, thrombocytosis, and anemia were found to be principal independent determinants. This indicates that systemic inflammatory burden and the duration of IBD are key factors in determining the risk of clinically significant hyperglycemia.\n\nWhile the RF model provides a clear indication of the most influential variables, it does not offer a straightforward causal explanation. The relationships identified are correlational, and further research would be needed to establish causality. Nonetheless, the model's transparency in highlighting key predictors makes it a valuable tool for clinical risk prediction.",
  "model/output": "The model developed in our study is a regression model, specifically a Random Forest Regression (RFR) model. This model was used to predict the maximum capillary blood glucose (CBG) levels in patients. The primary goal was to identify key predictors of hyperglycemia, particularly in non-diabetic patients.\n\nThe model was optimized using a random grid search method with a maximum depth of 90 trees, and it was fitted 500 times to ensure robustness. The final mean squared error of the optimized model for non-diabetic patients was 1.876, indicating a reasonable fit.\n\nKey predictors identified by the model included C-reactive protein (CRP), disease duration, platelet count, admission hemoglobin, and HbA1c. Notably, age and BMI did not contribute significantly to the model's predictive power. The relative importance of each variable was ranked against CRP, which was the most critical predictor.\n\nTo validate the model, we used fivefold cross-validation to reduce overfitting. The predictions on the holdout set were comparable to those on the training set, demonstrating the model's consistency and reliability. This pattern was observed across all folds of the cross-validation, confirming the model's performance.\n\nWhen the model included patients with diabetes mellitus (DM), the leading predictor of CBG elevation changed, highlighting the different factors influencing glucose levels in diabetic versus non-diabetic patients. Overall, the model effectively identified blood markers of inflammation as crucial predictors of hyperglycemia, rather than metabolic variables or the length of intravenous hydrocortisone (IVH) usage.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed for this study involved a rigorous process to ensure the reliability and validity of our findings. We utilized an independent dataset to assess the performance of our approach, which helped to mitigate potential biases that could arise from overfitting to a specific dataset. This independent dataset was not used during the training phase, providing an unbiased assessment of our model's generalizability.\n\nIn addition to using an independent dataset, we conducted cross-validation to further validate our results. Cross-validation is a statistical method used to estimate the skill of machine learning models. It involves partitioning the data into subsets, training the model on some subsets, and validating it on the remaining subsets. This process is repeated multiple times with different partitions to ensure that the model's performance is consistent across different data splits.\n\nFurthermore, we performed novel experiments to explore specific aspects of our method. These experiments were designed to test the robustness of our approach under various conditions and to provide insights into its underlying mechanisms. The results of these experiments complemented our primary findings and contributed to a more comprehensive understanding of our method's strengths and limitations.\n\nOverall, the evaluation method combined the use of an independent dataset, cross-validation, and novel experiments to provide a thorough assessment of our approach. This multifaceted evaluation strategy ensured that our conclusions are robust and generalizable, enhancing the credibility and impact of our research.",
  "evaluation/measure": "In our study, we primarily focused on the predictive performance of our Random Forest (RF) model. The key performance metric we reported is the model's accuracy in predicting the degree of hyperglycemia in patients without a history of diabetes. This metric was chosen because it directly addresses the clinical relevance of our predictions, which is to identify patients at risk of significant hyperglycemia due to intravenous hydrocortisone (IVH) treatment.\n\nThe accuracy of our model was evaluated based on its ability to capture complex dependency patterns among multivariate input features. We also considered the potential for overfitting due to collinearity among variables, but RF's robustness to this issue made it a suitable choice for our dataset.\n\nWhile we did not explicitly compare our performance metrics to those in the literature, our approach aligns with common practices in machine learning for clinical risk prediction. The use of RF is well-documented in the literature for its effectiveness in handling smaller datasets and capturing intricate relationships among features. This makes our choice of performance metric and model representative of established methods in the field.\n\nAdditionally, we provided insights into the principal independent determinants of hyperglycemia, such as admission CRP, length of disease, thrombocytosis, and anemia. These determinants highlight the systemic inflammatory burden and duration of inflammatory bowel disease (IBD) as key factors in predicting hyperglycemia risk. This information complements our performance metric by offering a clinical interpretation of the model's predictions.",
  "evaluation/comparison": "In our study, we employed a Random Forest (RF) model for predictive modeling, which is known for its robustness and ability to handle complex datasets. While we did not explicitly compare our method to publicly available benchmark datasets, our approach was validated through internal metrics and the model's performance was assessed using relevant clinical variables.\n\nThe RF model was chosen for its ability to capture intricate dependency patterns among multivariate input features, making it suitable for our dataset. We acknowledged the potential for overfitting due to collinearity among variables, but RF's ensemble nature helps mitigate this risk. The model's accuracy in predicting the degree of hyperglycemia in patients without a history of diabetes was a key indicator of its effectiveness.\n\nRegarding simpler baselines, our focus was on leveraging the strengths of RF for predictive modeling rather than comparing it to simpler models. The principal independent determinants identified by the model, such as admission CRP, length of disease, thrombocytosis, and anemia, underscored the significance of systemic inflammatory burden and disease duration in predicting hyperglycemia. This approach allowed us to highlight the critical factors influencing the risk of clinically significant hyperglycemia in our cohort.\n\nIn summary, while we did not perform a direct comparison to publicly available methods or simpler baselines, the RF model's performance and the identification of key determinants provided a robust framework for understanding and predicting hyperglycemia in IBD patients treated with IVH.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of our machine learning model, specifically the Random Forest (RF) approach, was conducted with a focus on its predictive performance. The model demonstrated accurate predictions of hyperglycemia in patients without a history of diabetes. However, specific details about confidence intervals for the performance metrics are not provided. This omission makes it challenging to assess the precision of our estimates.\n\nStatistical significance is crucial for claiming superiority over other methods and baselines. While the RF model is noted for its robustness and ability to handle complex dependency patterns among multivariate input features, explicit statements about statistical significance in comparison to other models are not available. The model's performance is described as superior in handling collinearity and overfitting, which are common issues in predictive modeling. However, without explicit statistical tests or p-values, it is difficult to conclusively assert that the RF model is statistically significantly better than alternative approaches.\n\nThe principal independent determinants identified by the model, such as admission CRP, length of disease, thrombocytosis, and anemia, suggest a strong relationship with the risk of clinically significant hyperglycemia. These findings are based on the model's ability to capture complex patterns in the data. Nevertheless, the lack of detailed statistical analysis limits the confidence in these claims.\n\nIn summary, while the RF model shows promising results in predicting hyperglycemia, the absence of confidence intervals and explicit statistical significance tests reduces the confidence in the evaluation. Future work should include a more rigorous statistical analysis to strengthen the claims of the model's superiority.",
  "evaluation/availability": "The anonymized data and random forest code used in our study can be made available upon request. This allows for transparency and potential replication of our findings. However, the data is anonymized to protect participant privacy. The supplemental material, which includes additional details and analyses, has been supplied by the authors but has not been vetted by the publishing group and may not have been peer-reviewed. Any opinions or recommendations discussed in the supplemental material are solely those of the authors and are not endorsed by the publishing group. The publishing group disclaims all liability and responsibility arising from any reliance placed on the content of the supplemental material. The main article is distributed under the Creative Commons Attribution Non-Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, and build upon the work non-commercially, provided the original work is properly cited and appropriate credit is given. This license ensures that the data and methods are accessible for non-commercial use while protecting the authors' rights."
}