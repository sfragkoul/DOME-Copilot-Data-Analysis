{
  "publication/title": "A paradigm for high-throughput screening of cell-selective surfaces coupling orthogonal gradients and machine learning-based cell recognition.",
  "publication/authors": "Hao H, Xue Y, Wu Y, Wang C, Chen Y, Wang X, Zhang P, Ji J",
  "publication/journal": "Bioactive materials",
  "publication/year": "2023",
  "publication/pmid": "37214260",
  "publication/pmcid": "PMC10192934",
  "publication/doi": "10.1016/j.bioactmat.2023.04.022",
  "publication/tags": "- Bioactive Materials\n- Cell Adhesion\n- Machine Learning\n- Cell Culture\n- PEG Gradients\n- REDV Peptides\n- Endothelial Cells\n- Smooth Muscle Cells\n- High-Throughput Screening\n- Competitive Coefficient\n- Cell Proliferation\n- Cell Recognition\n- Fluorescence Microscopy\n- Statistical Analysis\n- Ethics Approval",
  "dataset/provenance": "The dataset used in our study was derived from images captured using an inverted microscope. Specifically, large images of 100 \u00d7 were collected from PEG gradients and then cut into smaller images of 512 \u00d7 512 pixels for use with the ResUNet model. Additionally, single-cell images of 128 \u00d7 128 pixels were extracted from these large images for the ResNet50V2 model, based on the locations of cell nuclei identified through clustering algorithms applied on the fluorescent channel.\n\nThe dataset was divided into training, validation, and testing sets in a ratio of 8:1:1. The specific numbers of images in each set are detailed in supplementary material. The training sets were used to develop and optimize our machine learning models, while the validation sets were employed to tune hyperparameters and prevent overfitting. The testing sets were reserved for evaluating the final performance of the models.\n\nOur previous publication provides detailed information on the model architectures and the design of the methods used. The dataset includes images captured under both phase contrast and fluorescent channels, ensuring a comprehensive analysis of cell behaviors. The images were preprocessed to ensure consistency and quality, which is crucial for the accurate training and testing of our models.\n\nNot sure about the number of data points in the dataset.",
  "dataset/splits": "The dataset was divided into three splits: training, validation, and testing. The ratio for this division was 8:1:1. The specific numbers of images in each set are presented in supplementary material, specifically in Table S2. This division ensures that the model is trained on a substantial portion of the data, validated on a smaller set to tune hyperparameters, and finally tested on an independent set to evaluate its performance.",
  "dataset/redundancy": "The datasets used in our study were divided into training, validation, and testing sets with a ratio of 8:1:1. This split was done randomly to ensure that the datasets were independent and to prevent any potential bias. The random division helped in maintaining the integrity of the model's performance evaluation by ensuring that the training set did not overlap with the testing set.\n\nThe training set was used to train the machine learning models, specifically ResUNet and ResNet50V2. The validation set was employed to tune the hyperparameters and monitor the model's performance during training, helping to prevent overfitting. The testing set was reserved for the final evaluation of the models to assess their generalization capability on unseen data.\n\nThe distribution of the datasets in our study is comparable to previously published machine learning datasets in the field of cell imaging and analysis. The use of a large number of images and the random splitting of datasets are standard practices to ensure robust and reliable model performance. The specific numbers of images in each set were presented in supplementary materials to provide transparency and reproducibility.\n\nTo enforce the independence of the training and testing sets, we ensured that the images used in the training phase were not included in the testing phase. This was achieved through the random splitting process, which was carefully implemented to avoid any overlap between the sets. Additionally, the models were trained and validated on images collected from single gradients of PEG, and then applied to orthogonal gradient samples, further ensuring the independence and generalizability of the datasets.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this work is convolutional neural networks (CNNs). Specifically, two models were employed: a modified UNet model, referred to as ResUNet, and a ResNet model, specifically ResNet50V2.\n\nThe ResUNet model is used for predicting binary images of cell nuclei based on brightfield images. It is a type of UNet, which is a well-known architecture for biomedical image segmentation. The modification involves incorporating residual connections, which are characteristic of ResNet architectures, to improve the model's performance.\n\nThe ResNet50V2 model is used for classifying single-cell images into different cell types. ResNet50V2 is a variant of the ResNet50 architecture, which is a deep residual network known for its effectiveness in image classification tasks.\n\nThese algorithms are not entirely new but have been adapted and applied in a novel context. The combination of these models for label-free, high-throughput cell recognition in a co-culture system is a significant contribution. The focus of this work is on the application of these models to solve a specific biological problem, rather than the development of new machine-learning algorithms. Therefore, it is published in a materials science journal rather than a machine-learning journal. The development and training of these models are described in detail, including the use of specific optimizers, loss functions, and training strategies tailored to the task at hand.",
  "optimization/meta": "The optimization process involves a combination of machine learning models to analyze cell images and behaviors. The workflow includes a modified UNet model, referred to as ResUNet, which is used to predict binary images of cell nuclei based on brightfield images. This model is trained using images collected from single gradients of PEG and is then applied to orthogonal gradient samples.\n\nIn addition to ResUNet, the workflow also employs a convolutional neural network with a skip connection, specifically ResNet50V2, for cell classification. This model takes the coordinates of cell nuclei and classifies each cell in brightfield images, allowing for the identification and location of different cell types.\n\nThe training data for these models is derived from images obtained under a microscope at a magnification of 100\u00d7. The images are divided into training, validation, and testing sets in a ratio of 8:1:1. The models are trained using supervised learning, with binary training labels for ResUNet obtained from the original DAPI channel and categorical cross-entropy minimized for ResNet50V2.\n\nThe application stage involves adjusting the input size of ResUNet to 1536 \u00d7 1536 px\u00b2, which is close to the size of independently captured normal images using the microscope. The images are divided into 255 subareas, each processed separately by the models for prediction. The output images with markers are then stitched together using a Python script to form a large image. This method also generates an Excel file containing the predicted numbers of endothelial cells (EC) and smooth muscle cells (SMC) in each subarea.\n\nThe competitive coefficient is defined to reflect the adhesion advantage of EC over SMC and the absolute cell density. It is calculated using the densities of EC and SMC, with a penalty term to avoid division by zero. The constant \u03b4 is set to 1.05 based on the observed density of SMC in the study.\n\nThe models achieve high accuracy and low dice loss on the testing set, indicating their reliability in analyzing cell images. The method avoids the impacts of fluorescence labeling on cell conditions, potentially enabling real-time monitoring of cell behaviors such as adhesion, proliferation, and migration in a co-culture system.",
  "optimization/encoding": "In our study, we employed a meticulous data encoding and preprocessing pipeline to ensure the efficacy of our machine-learning models. Initially, large images captured at 100\u00d7 magnification were segmented into smaller, manageable images. For the ResUNet model, these images were cropped into 512 \u00d7 512 pixel squares. For the ResNet50V2 model, single-cell images of 128 \u00d7 128 pixels were extracted based on the locations of cell nuclei, which were identified using clustering algorithms applied to fluorescent channel data.\n\nThe training, validation, and testing datasets were randomly divided in an 8:1:1 ratio. This division ensured that the models were trained on a substantial amount of data while maintaining separate datasets for validation and testing to evaluate performance accurately.\n\nFor the ResUNet model, binary training labels were derived from the original DAPI channel using the `cv2.adaptiveThreshold` function. This step was crucial for segmenting cell nuclei in the brightfield images. The model was trained using an Adam optimizer to minimize the dice loss between the binary labels and predictions. Training was conducted over 40 epochs with a batch size of 2, and the model that achieved the lowest loss on the validation set was saved for further testing and application.\n\nIn the case of the ResNet50V2 model, an SGD optimizer with a momentum of 0.9 was used to minimize the categorical cross-entropy. The initial learning rate was set at 0.0001 and was reduced by 50% every 15 epochs. The training process spanned 60 epochs with a batch size of 32. The model that achieved the highest accuracy on the validation set was selected for testing and application.\n\nDuring the application stage, the input size for ResUNet was adjusted to 1536 \u00d7 1536 pixels, which is close to the size of an independently captured normal image using our microscope. The large images were divided into 255 subareas, each processed separately by the model. The resulting output images with markers were then stitched together using a Python script to form a comprehensive large image. This method also generated an Excel file containing the predicted numbers of endothelial cells (ECs) and smooth muscle cells (SMCs) in each subarea, facilitating detailed analysis.",
  "optimization/parameters": "In our study, the models utilized several key parameters that were carefully selected to optimize performance. For the ResUNet model, the input size was adjusted to 1536 \u00d7 1536 pixels, which is close to the resolution of images captured using our microscope. This size was chosen to match the dimensions of independently captured normal images, ensuring that the model could effectively process and analyze the data.\n\nThe training process for ResUNet involved setting the initial learning rate at 0.0001, which was reduced by 50% every 15 epochs. This learning rate schedule was designed to allow the model to converge more smoothly. The training ran for 60 epochs with a batch size of 32, and the model that achieved the highest accuracy on the validation set was saved for testing and application.\n\nFor the ResNet50V2 model, the input size for single cell images was set to 128 \u00d7 128 pixels. These images were cut from larger images according to the locations of cell nuclei, which were identified using clustering algorithms applied on the fluorescent channel. The training sets, validation sets, and testing sets were divided randomly at a ratio of 8:1:1. An SGD optimizer with a momentum of 0.9 was used to minimize the categorical cross-entropy. The initial learning rate was also set at 0.0001, with a 50% reduction every 15 epochs. The training ran for 60 epochs with a batch size of 32, and the model with the highest accuracy on the validation set was selected for further use.\n\nAdditionally, the competitive coefficient, which reflects the adhesion advantage of endothelial cells (ECs) over smooth muscle cells (SMCs) and the absolute cell density, was defined with specific parameters. The coefficient is given by the formula (EC - SMC) / (SMC + \u03b4), where \u03b4 is a constant set to 1.05 to control the change rate of the penalty term. This formula ensures that the coefficient increases with the density of ECs and decreases with the density of SMCs, while avoiding situations where 0 is a divisor.\n\nIn summary, the models were optimized using carefully selected parameters, including input sizes, learning rates, batch sizes, and optimization algorithms. These parameters were chosen to ensure that the models could effectively analyze cell images and provide reliable predictions.",
  "optimization/features": "The input features for the machine learning models used in this study are derived from images captured under a microscope. Specifically, the images were obtained at a magnification of 100\u00d7. For the ResUNet model, the input size was adjusted to 1536 \u00d7 1536 pixels, which is close to the size of an independently captured normal image using the microscope (1608 \u00d7 1608 pixels). These images were divided into 255 subareas, each of which was separately processed by the model. For the ResNet50V2 model, single cell images of 128 \u00d7 128 pixels were used, cut from larger images according to the locations of cell nuclei identified by clustering algorithms applied on the fluorescent channel.\n\nFeature selection was implicitly performed by focusing on specific image regions and channels. The training labels for ResUNet were obtained from the original DAPI channel using adaptive thresholding. This process effectively selects relevant features by highlighting cell nuclei, which are crucial for cell identification and counting. The models were trained using these selected features to ensure that the most relevant information was used for prediction.\n\nThe feature selection process was conducted using the training set only, ensuring that the validation and testing sets remained unbiased. This approach helps in evaluating the models' performance on unseen data, providing a reliable assessment of their generalization capabilities. The models were trained with a specific focus on minimizing dice loss for ResUNet and categorical cross-entropy for ResNet50V2, which further refines the selection of relevant features during the training process.",
  "optimization/fitting": "The fitting method employed in this study involved training two distinct machine learning models, ResUNet and ResNet50V2, on cell images captured under specific conditions. The training process for ResUNet utilized binary labels derived from the DAPI channel, with an Adam optimizer minimizing the dice loss between the binary labels and predictions. The training was conducted over 40 epochs with a batch size of 2. For ResNet50V2, an SGD optimizer with a momentum of 0.9 was used to minimize the categorical cross-entropy, with the initial learning rate set to 0.0001 and decreased by 50% every 15 epochs. The training spanned 60 epochs with a batch size of 32.\n\nTo address the potential issue of overfitting, given the large number of parameters relative to the training points, several strategies were implemented. The models were trained and validated on separate datasets, with the model achieving the lowest loss on the validation set saved for testing and application. This approach ensured that the models generalized well to unseen data. Additionally, the input size of ResUNet was adjusted to 1536 \u00d7 1536 pixels, which is close to the size of independently captured normal images, further aiding in the generalization of the model.\n\nUnderfitting was mitigated by ensuring that the models were sufficiently complex to capture the underlying patterns in the data. The use of advanced architectures like ResUNet and ResNet50V2, along with appropriate optimization techniques, helped in achieving high accuracy and low loss on the validation set. The classification accuracy of ResNet50V2 exceeded 0.95, and ResUNet achieved a dice loss of 0.11 on the testing set, indicating that the models were well-fitted to the data without being overly simplistic.",
  "optimization/regularization": "In our study, we employed several regularization methods to prevent overfitting and ensure the robustness of our machine learning models. For the ResUNet model, we used an adaptive thresholding technique to obtain binary training labels from the original DAPI channel. This approach helped in creating precise segmentation masks, which are crucial for training the model to accurately predict cell nuclei in brightfield images. Additionally, we utilized the dice loss function, which is particularly effective for segmentation tasks as it focuses on the overlap between the predicted and ground truth masks, thereby encouraging the model to learn more precise boundaries.\n\nFor the ResNet50V2 model, we implemented an SGD optimizer with momentum, which helps in accelerating gradients vectors in the right directions, thus leading to faster converging. We also employed a learning rate schedule that decreased the learning rate by 50% every 15 epochs. This strategy allows the model to make larger updates initially and finer adjustments later, which helps in escaping local minima and improving generalization.\n\nFurthermore, we divided our dataset into training, validation, and testing sets in an 8:1:1 ratio. This division ensured that the model was trained on a substantial amount of data while also having a separate validation set to tune hyperparameters and a testing set to evaluate the final performance. The use of a validation set during training helped in monitoring the model's performance on unseen data and in making necessary adjustments to prevent overfitting.\n\nIn summary, our regularization techniques included adaptive thresholding, dice loss, momentum in the optimizer, learning rate scheduling, and a proper train-validation-test split. These methods collectively contributed to the robustness and generalization capability of our models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules for the machine learning models used in our study are reported in detail within the publication. Specifically, for the ResUNet model, we utilized an Adam optimizer to minimize the dice loss between binary labels and predictions. The training process involved 40 epochs with a batch size of 2. The model that achieved the lowest loss on the validation set was saved for testing and application.\n\nFor the ResNet50V2 model, an SGD optimizer with a momentum of 0.9 was employed to minimize the categorical cross-entropy. The initial learning rate was set to 0.0001 and was reduced by 50% every 15 epochs. The training lasted for 60 epochs with a batch size of 32. The model with the highest accuracy on the validation set was selected for further testing and application.\n\nThe specific numbers of images in each set (training, validation, and testing) are presented in supplementary material, specifically in Table S2. The detailed model architectures and the design of the methods are elaborated in a previous publication referenced within the text.\n\nRegarding the availability of model files and optimization parameters, these are not explicitly mentioned as being publicly accessible. However, the methods and configurations are thoroughly described, allowing for replication by other researchers. The publication does not specify the licensing terms for the use of these configurations or models, but standard academic practices for sharing and citing research would apply.",
  "model/interpretability": "The models employed in our study, specifically ResUNet and ResNet50V2, are primarily convolutional neural networks (CNNs) which are often considered black-box models due to their complex, multi-layered architectures. These models do not inherently provide clear, interpretable insights into their decision-making processes. However, efforts were made to ensure some level of transparency and reliability in our approach.\n\nResUNet, a variant of U-Net, is used for predicting binary images of cell nuclei based on brightfield images. This model's architecture includes skip connections that help in preserving spatial information, which aids in the accurate segmentation of cell nuclei. The use of brightfield images for cell recognition avoids the impacts of fluorescence labeling on cell conditions, allowing for real-time monitoring of cell behaviors such as adhesion, proliferation, and migration.\n\nResNet50V2, another CNN with skip connections, is utilized for classifying individual cells in brightfield images. The coordinates of each nucleus, obtained through clustering algorithms like DBSCAN and K-means, are fed into ResNet50V2 for classification. This process enables the identification and counting of different cell types in a co-culture system without the need for fluorescent labeling.\n\nTo validate the reliability of these models, we compared the cell counting results obtained from the machine learning method with manual counts in randomly selected areas. The consistency between these two approaches suggests that the models are effective in identifying and counting cells accurately. Additionally, the models achieved high performance metrics on the testing set, with ResNet50V2 attaining a classification accuracy above 0.95 and ResUNet achieving a dice loss of 0.11.\n\nWhile the models themselves are not fully transparent, the workflow and validation steps provide confidence in their interpretability and reliability. The use of brightfield images and the avoidance of fluorescent labeling further enhance the practical applicability of the models in real-time cell behavior monitoring.",
  "model/output": "The model employed in our study is primarily designed for classification tasks. Specifically, we utilized a convolutional neural network with a skip connection, known as ResNet50V2, for classifying cells in brightfield images. This model was trained to identify and locate different types of cells, such as endothelial cells (ECs) and smooth muscle cells (SMCs), within the images. The classification accuracy achieved by ResNet50V2 on the testing set was above 0.95, indicating its reliability in analyzing cell images.\n\nAdditionally, we used a modified UNet model, referred to as ResUNet, for predicting binary images of cell nuclei based on brightfield images. This model was trained to minimize the dice loss between the binary labels and predictions, focusing on segmenting cell nuclei rather than classifying them. The ResUNet model achieved a dice loss of 0.11 on the testing set, demonstrating its effectiveness in nuclear segmentation.\n\nIn summary, the models used in our study are primarily classification models, with ResNet50V2 being used for cell classification and ResUNet for nuclear segmentation. The high accuracy and low dice loss achieved by these models indicate their reliability in analyzing cell images and segmenting cell nuclei, respectively.",
  "model/duration": "The training process for the ResUNet model involved 40 epochs with a batch size of 2. For the ResNet50V2 model, the training lasted for 60 epochs with a batch size of 32. The initial learning rate for both models was set at 0.0001, with a 50% decrease every 15 epochs. The model that achieved the highest accuracy on the validation set was saved for testing and application. During the application stage, the input size of the ResUNet was adjusted to 1536 \u00d7 1536 pixels, which is close to the size of images captured independently using our microscope. The images were divided into 255 subareas, each processed separately by the model. The output images with markers were then stitched together using a Python script. This method also generated an Excel file containing the predicted numbers of endothelial cells (EC) and smooth muscle cells (SMC) in each subarea. The specific execution time for the model to run is not detailed, but the process involved significant computational effort due to the large number of epochs and the size of the images processed.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a combination of machine learning model performance metrics and biological validation experiments. For the machine learning models, ResNet50V2 and ResUNet, the performance was assessed using a testing set that was independent of the training and validation sets. ResNet50V2 achieved a classification accuracy of above 0.95, indicating high reliability in identifying different cell types. ResUNet demonstrated a dice loss of 0.11, suggesting effective segmentation of cell images. These metrics were calculated on a testing set that was randomly divided from the original dataset, ensuring an unbiased evaluation of the models' performance.\n\nIn addition to the model performance metrics, the method was further validated through biological experiments. The cell counting results obtained from the machine learning models were compared with manual counts in randomly selected areas. The consistency between the two approaches confirmed the reliability of the automated cell identification and counting process. This validation step is crucial as it bridges the gap between computational predictions and actual biological outcomes.\n\nThe method was also evaluated in the context of high-throughput screening experiments. The combinational densities of PEG and REDV were studied to understand their effect on cell competitiveness. The results showed that the method could effectively differentiate between areas with and without cell selectivity, demonstrating its practical applicability in real-world scenarios. The competitive coefficient, a metric designed to reflect the adhesion advantage of endothelial cells (ECs) over smooth muscle cells (SMCs), was used to quantify the cell selectivity observed in the experiments.\n\nOverall, the evaluation method combined computational performance metrics with biological validation experiments, ensuring a comprehensive assessment of the method's effectiveness and reliability. The high accuracy of the machine learning models and the consistency with manual counts provide strong evidence supporting the method's potential for real-time monitoring of cell behaviors in co-culture systems.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our machine learning models. For the ResNet50V2 model, which was used for cell classification, we reported the classification accuracy. This metric indicates the proportion of correctly identified cells out of the total number of cells. The model achieved a classification accuracy of above 0.95 on the testing set, demonstrating its high reliability in distinguishing between different cell types.\n\nFor the ResUNet model, which was used for cell nucleus segmentation, we reported the dice loss. The dice loss measures the overlap between the predicted segmentation and the ground truth, with lower values indicating better performance. The ResUNet model achieved a dice loss of 0.11 on the testing set, suggesting its effectiveness in accurately segmenting cell nuclei from brightfield images.\n\nThese performance metrics are widely used in the literature for evaluating segmentation and classification tasks in cell imaging. The high accuracy of ResNet50V2 and the low dice loss of ResUNet indicate that our models are robust and reliable for analyzing cell images in a co-culture system. The use of these metrics allows for a comprehensive evaluation of our models' performance, ensuring that they meet the standards set by previous studies in the field.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, we focused on developing and validating our own machine learning models tailored to our specific experimental setup.\n\nWe did, however, compare our results to simpler baselines to ensure the reliability of our approach. For instance, we manually counted cell numbers in five randomly selected areas after fluorescent labeling and compared these counts with the results obtained from our machine learning method. The consistency between these two approaches suggested the reliability of our cell identification and counting results.\n\nAdditionally, we evaluated the performance of our models on a testing set. The ResNet50V2 model achieved a classification accuracy of above 0.95, while the ResUNet model had a dice loss of 0.11. These results indicated the robustness of our models in analyzing cell images.\n\nOur method's ability to avoid the impacts of fluorescence labeling on cell conditions also sets it apart from simpler baselines, as it allows for real-time monitoring of cell behaviors. This includes adhesion, proliferation, and migration of different cell types in a co-culture system.",
  "evaluation/confidence": "The evaluation of our method's performance includes statistical significance assessments to ensure the reliability of our claims. We used the ANOVA test to evaluate statistical significance, with a probability value of p < 0.05 considered significant. This threshold is clearly indicated in our results, with significance levels marked as *P < 0.05, **P < 0.01, and ***P < 0.001. These markers help to highlight where our findings are statistically significant, providing confidence in the superiority of our method over baselines.\n\nThe error bars in our experiments represent the standard deviation of the mean value for each type of experiment, offering a visual indication of the variability and precision of our measurements. This information is crucial for understanding the confidence intervals around our performance metrics.\n\nIn our study, we also compared the cell adhesion densities obtained through our machine learning method with manual counts in five randomly selected areas. The consistency between these two approaches further validates the reliability of our cell identification and counting results, reinforcing the confidence in our method's performance.\n\nAdditionally, the high accuracy of our ResNet50V2 model, achieving above 0.95 on the testing set, and the low dice loss of 0.11 for ResUNet, suggest the robustness and reliability of our models in analyzing cell images. These metrics, combined with our statistical significance assessments, provide a strong foundation for claiming the superiority of our method.",
  "evaluation/availability": "Not enough information is available."
}