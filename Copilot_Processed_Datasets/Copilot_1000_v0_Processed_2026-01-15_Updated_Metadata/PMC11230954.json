{
  "publication/title": "Pathomic model based on histopathological features and machine learning to predict IDO1 status and its association with breast cancer prognosis.",
  "publication/authors": "Zhuo X, Deng H, Qiu M, Qiu X",
  "publication/journal": "Breast cancer research and treatment",
  "publication/year": "2024",
  "publication/pmid": "38780888",
  "publication/pmcid": "PMC11230954",
  "publication/doi": "10.1007/s10549-024-07350-6",
  "publication/tags": "- Breast Cancer\n- Pathomic Model\n- IDO1 Expression\n- Survival Analysis\n- Gene Set Enrichment Analysis\n- Immune Microenvironment\n- Tumor Mutational Burden\n- Machine Learning\n- Histopathological Images\n- Prognostic Factors",
  "dataset/provenance": "The dataset used in this study was sourced from the TCGA database. Initially, 928 patients were included after applying exclusion criteria. From this group, 1062 H&E histopathological images were obtained. After eliminating low-quality images, 942 patients remained. The final dataset consisted of 791 patients, each with RNA-seq data, complete clinical information, and qualified pathological images. This dataset was used to construct a predictive model based on pathological imaging features, which was then validated on a separate validation set. The TCGA database is a public resource, and the data used in this study is available from the corresponding author upon reasonable request. The dataset has been utilized in various past investigations for survival prediction in different cancers, demonstrating its value and relevance in the scientific community.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a validation set. The training set consisted of 555 data points, which accounted for 70% of the total dataset. The validation set comprised 236 data points, making up the remaining 30%. Each feature in the training set was standardized using a z-score, while the validation set was standardized using the average and standard deviation values derived from the training set. This approach ensured that the model's performance could be reliably evaluated on unseen data.",
  "dataset/redundancy": "The dataset used in this study consisted of 791 patients, with their data randomly split into training and validation sets. The training set comprised 555 patients, accounting for 70% of the total, while the validation set included 236 patients, making up the remaining 30%. This split was done to ensure that the training and validation sets were independent, allowing for an unbiased evaluation of the model's performance.\n\nTo enforce independence between the training and validation sets, each feature in the training set was standardized using a z-score. For the validation set, standardization was performed using the average and standard deviation values derived from the training set. This approach ensured that the validation set remained independent and was not influenced by the training process.\n\nThe distribution of clinical variables among the patients was analyzed to ensure that the training and validation sets were comparable. This step was crucial to maintain the integrity of the model evaluation process.\n\nIn comparison to previously published machine learning datasets, the approach taken in this study aligns with standard practices in the field. The random split and independent standardization of features are common methods used to prevent data leakage and ensure that the model's performance is generalizable to new, unseen data. This methodology helps in achieving robust and reliable results, which are essential for the validity of the study's findings.",
  "dataset/availability": "The datasets used in this study are not publicly available. They can be obtained from the corresponding author upon reasonable request. This approach ensures that the data is shared responsibly and in accordance with ethical guidelines. The datasets include histopathological images and RNA-seq data, which were carefully curated and processed to maintain patient privacy and data integrity. The specific data splits used for training and validation are not released in a public forum. This decision was made to prevent potential misuse of the data and to comply with the ethical standards of the study. The datasets were used under the terms of the TCGA database, which allows for the download and use of relevant data for research purposes, provided that appropriate credit is given to the original authors and the source. The study adheres to the principles of the Creative Commons Attribution 4.0 International License, which permits unrestricted use, distribution, and reproduction of the article, as long as the original authors and the source are credited. However, the actual datasets themselves are not publicly available and must be requested directly from the corresponding author.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is gradient boosting machines (GBM). This approach is not new; it is a well-established ensemble learning method that combines multiple weak decision tree learners through boosting to develop a robust predictive model.\n\nThe GBM algorithm was chosen for its ability to handle complex relationships in the data and provide accurate predictions. It was implemented using the GBM package in R, which is a widely used and reliable tool for this purpose.\n\nThe focus of this study is on the application of machine learning to breast cancer research, specifically in predicting IDO1 status and its relationship with prognosis from pathological imaging features. The GBM algorithm was selected for its effectiveness in this context, rather than for the development of a new machine-learning algorithm. Therefore, it was not published in a machine-learning journal but rather in a journal focused on breast cancer research and treatment.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it employs a gradient boosting machine (GBM) algorithm to construct a predictive model using selected pathomic features. The process involves several steps to ensure the robustness and accuracy of the model.\n\nInitially, the maximum-relevance minimum-redundancy (mRMR) algorithm is used to eliminate redundant and irrelevant features, focusing on maximizing predictive ability while minimizing mutual information among features. Following this, the recursive feature elimination (RFE) algorithm is applied to select important features and eliminate unimportant ones, ranking them according to their importance in model prediction.\n\nThe selected important features are then used to build the machine learning prediction model using the GBM algorithm. This algorithm iteratively combines multiple weak decision tree learners through boosting to develop a robust predictive model.\n\nThe model's performance is evaluated using data from 791 patients, which is randomly divided into training and validation sets. The training set consists of 555 patients (70%), while the validation set includes 236 patients (30%). Each feature in the training set is standardized using a z-score, and the same standardization is applied to the validation set using the average and standard deviation values obtained from the training set.\n\nThe predictive model is constructed using pathological imaging features and validated on the validation set. Its accuracy is evaluated using the area under the curve (AUC). Additionally, a calibration curve is used to assess its calibration, and a decision curve is generated to estimate its net benefit.\n\nIn summary, the model does not rely on data from other machine-learning algorithms as input. It is built using a single GBM algorithm, which is trained and validated on independent datasets to ensure the reliability of the results.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the features were optimized for model training. Initially, histopathological images were segmented using Otsu's thresholding algorithm, dividing them into smaller sub-images. These sub-images were then reviewed by pathologists to remove any of poor quality. For each patient, 10 sub-images were randomly selected for further analysis.\n\nFeature extraction was performed using the PyRadiomics library, which yielded a comprehensive set of image features. These features included first- and second-order statistics, as well as higher-order features derived from various transformations such as Wavelet, LoG, Square, SquareRoot, Logarithm, Exponential, Gradient, and LBP2D. This process resulted in 1,488 image features per sub-image.\n\nTo obtain a representative feature set for each patient, the mean value of the 10 sub-images was calculated for each feature. This step ensured that the features were consistent and representative of the entire image set for each patient.\n\nBefore model training, the data was split into training and validation sets, with 70% of the data used for training and 30% for validation. Each feature in the training set was standardized using a z-score, which transforms the data to have a mean of zero and a standard deviation of one. This standardization helps in improving the performance and convergence of the machine-learning algorithm. The validation set was standardized using the mean and standard deviation values obtained from the training set to maintain consistency between the two datasets.\n\nThe preprocessing steps also included the elimination of redundant and irrelevant features using the maximum-relevance minimum-redundancy (mRMR) algorithm. This algorithm ranked the features by maximizing their predictive ability while minimizing mutual information among them. The top 20 features were retained for further selection.\n\nSubsequently, recursive feature elimination (RFE) was applied to select the optimal features among the 20 mRMR features. This process identified six key features that were most important for model prediction. These selected features were then used to build the predictive model using a gradient boosting machine (GBM) algorithm. The GBM algorithm iteratively combined multiple weak decision tree learners through boosting to develop a robust predictive model.",
  "optimization/parameters": "In our study, we utilized a total of six features as input parameters for our predictive model. These features were selected through a rigorous process involving the maximum-relevance minimum-redundancy (mRMR) algorithm and recursive feature elimination (RFE). The mRMR algorithm was first employed to rank the input pathomic features by maximizing their predictive ability while minimizing mutual information among features. This step helped in eliminating redundant and irrelevant features. Subsequently, the RFE algorithm was applied to further select the most important features from the top 20 features identified by mRMR. This process ensured that only the most relevant and non-redundant features were retained for model construction. The final set of six features was then used to build our gradient boosting machine (GBM) model, which demonstrated robust predictive performance.",
  "optimization/features": "In the optimization process, we initially extracted a comprehensive set of features from histopathological images. Specifically, 1,488 image features were derived from each sub-image. To ensure the robustness and efficiency of our predictive model, feature selection was performed using two algorithms: the maximum-relevance minimum-redundancy (mRMR) algorithm and the recursive feature elimination (RFE) algorithm. The mRMR algorithm was employed first to eliminate redundant and irrelevant features, retaining the top 20 features. Subsequently, the RFE algorithm was applied to further refine this set, ultimately selecting six optimal features. This feature selection process was conducted exclusively using the training set, ensuring that the validation set remained independent and unbiased. The selected features were then used to build the predictive model, which demonstrated strong performance in predicting IDO1 expression.",
  "optimization/fitting": "The fitting method employed in this study involved a gradient boosting machine (GBM) algorithm, which is known for its ability to handle high-dimensional data and complex relationships. The number of parameters, derived from image features, was indeed much larger than the number of training points. To address potential overfitting, several strategies were implemented.\n\nFirst, feature selection techniques were used to reduce the dimensionality of the data. The maximum-relevance minimum-redundancy (mRMR) algorithm was employed to eliminate redundant and irrelevant features, ensuring that the selected features had high predictive ability while minimizing mutual information. Following this, the recursive feature elimination (RFE) algorithm was applied to further select important features and eliminate unimportant ones, based on their importance in model prediction.\n\nAdditionally, the data was split into training and validation sets, with 70% of the data used for training and 30% for validation. Each feature in the training set was standardized using a z-score, and the same standardization parameters were applied to the validation set. This approach helped to ensure that the model generalized well to unseen data.\n\nTo evaluate the model's performance and rule out underfitting, the area under the curve (AUC) was used as a primary metric. Moreover, a calibration curve was employed to assess the model's calibration, and a decision curve was generated to estimate its net benefit. These evaluations provided a comprehensive assessment of the model's predictive performance and generalizability.\n\nIn summary, the fitting method involved rigorous feature selection, data standardization, and thorough performance evaluation to address both overfitting and underfitting concerns.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our predictive model. One of the key methods used was feature selection. We initially extracted a large number of features from the histopathological images. To reduce the dimensionality and eliminate irrelevant or redundant features, we applied the minimum Redundancy Maximum Relevance (mRMR) technique. This method helped us retain the top 20 features that were most relevant to the prediction task while minimizing redundancy. Subsequently, we used Recursive Feature Elimination (RFE) to further refine this set, ultimately selecting the six most optimal features for model construction.\n\nAdditionally, we split our dataset into training and validation sets, with 70% of the data used for training and 30% reserved for validation. This split allowed us to train our model on one subset and evaluate its performance on an independent subset, thereby reducing the risk of overfitting to the training data.\n\nWe also standardized the features using z-scores in the training set and applied the same standardization parameters to the validation set. This ensured that the model generalizes well to new, unseen data.\n\nFurthermore, we used the Gradient Boosting Machine (GBM) algorithm, which is known for its ability to handle overfitting through techniques like regularization and subsampling. The GBM algorithm builds the model in a stage-wise fashion and optimizes for both accuracy and generalization.\n\nTo assess the model's performance, we evaluated it using the area under the curve (AUC) for the receiver operating characteristic (ROC) curve, calibration curves, and decision curve analysis (DCA). These evaluations provided a comprehensive view of the model's predictive accuracy and its potential net benefit in clinical settings.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not entirely a black box, as it incorporates several steps that enhance its interpretability. The process began with the use of the maximum-relevance minimum-redundancy (mRMR) algorithm to rank pathomic features by their predictive ability while minimizing redundancy. This step helps in understanding which features are most relevant for the model's predictions.\n\nFollowing mRMR, recursive feature elimination (RFE) was applied to further select the most important features. This algorithm assesses the importance of each feature and ranks them according to their contribution to the model's predictive power. The top six features identified through this process were used to build the final model using the gradient boosting machine (GBM) algorithm. The importance of these six features in the GBM algorithm is visually represented, providing insights into which features are driving the model's decisions.\n\nAdditionally, the model's performance was evaluated using various metrics such as the area under the curve (AUC), calibration curves, and decision curves. These evaluations help in understanding how well the model generalizes to new data and its clinical utility. The calibration curves, in particular, show how well the predicted probabilities match the actual outcomes, providing a measure of the model's reliability.\n\nThe model's predictions were also analyzed in the context of clinical variables and survival outcomes. For instance, patients were classified into high and low prediction score (PS) groups based on the model's outputs. Significant differences in clinical variables such as age, hormone receptor status, and treatment types were observed between these groups, indicating that the model captures relevant clinical information.\n\nFurthermore, the model's predictions were linked to molecular pathways and the immune microenvironment. Gene set enrichment analysis (GSEA) identified several pathways that were differentially expressed between high and low PS groups, providing biological insights into the model's predictions. The model also showed correlations with immune cell infiltration, suggesting its potential to guide immunotherapy decisions.\n\nIn summary, while the model leverages complex machine learning techniques, several steps and evaluations were conducted to enhance its interpretability. The use of feature selection algorithms, visualization of feature importance, and linkage to clinical and biological data all contribute to a better understanding of the model's predictions.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict IDO1 expression levels in breast cancer patients, categorizing them into high or low expression groups. The model utilizes pathological imaging features extracted from H&E-stained images and employs a gradient boosting machine (GBM) algorithm for prediction. The performance of the model was evaluated using metrics such as the area under the curve (AUC), calibration curves, and decision curve analysis (DCA). The AUC values for the training and validation sets were 0.809 and 0.711, respectively, indicating strong predictive performance. Additionally, the model's predictions were found to be significantly beneficial, as shown by the decision curve analysis. The model also demonstrated a high degree of fit in calibration curves, suggesting reliable prediction of IDO1 expression levels. Furthermore, the model's predictions were associated with overall survival (OS), with higher prediction scores (PS) indicating favorable OS. This suggests that the model not only predicts IDO1 expression but also has prognostic value for breast cancer patients.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its robustness and predictive performance. Initially, data from 791 patients were randomly divided into training and validation sets, with 70% of the data used for training and 30% for validation. Each feature in the training set was standardized using a z-score, and the same standardization was applied to the validation set using the mean and standard deviation from the training set.\n\nA predictive model was constructed using pathological imaging features and validated on the validation set. The model's accuracy was assessed using the area under the curve (AUC). Additionally, calibration curves were used to evaluate the model's calibration, and decision curves were generated to estimate its net benefit.\n\nSurvival analysis, gene set enrichment analysis (GSEA), immune microenvironment analysis, and tumor mutational burden (TMB) analysis were conducted using the proposed model. Prediction scores (PSes) were generated for all H&E-stained images, and patients were classified into high- and low-PS groups using the survminer R package and Cutoff Finder web application. Kaplan\u2013Meier survival curves were plotted to analyze survival differences, and GSEA was performed against the KEGG and Hallmark Gene Set Collections. Immune infiltration was quantified using the CIBERSORTx algorithm, and TMB analysis was conducted using the maftools package.\n\nStatistical analyses included the use of the \u03a7-square test or Fisher's exact test to evaluate associations between variables, the Wilcoxon rank-sum test to determine differences between groups, and the log-rank test for Kaplan\u2013Meier survival analysis. Univariate and multivariate Cox regression analyses were performed to assess the impact of selected variables on overall survival (OS). Spearman-rank correlation analysis was used to calculate correlations, with a p-value of less than 0.05 considered statistically significant.",
  "evaluation/measure": "In the evaluation of our predictive model, several performance metrics were employed to ensure a comprehensive assessment. The primary metric used was the area under the curve (AUC) of the receiver operating characteristic (ROC) curve, which provides a measure of the model's ability to distinguish between different classes. The AUC values were reported for both the training and validation sets, demonstrating the model's performance in predicting IDO1 expression.\n\nIn addition to the AUC, calibration curves were utilized to evaluate the model's calibration, ensuring that the predicted probabilities align well with the actual outcomes. This is crucial for assessing the reliability of the model's predictions.\n\nDecision curve analysis (DCA) was also conducted to estimate the net benefit of using the model at various threshold probabilities. This analysis helps in understanding the clinical utility of the model by comparing it to the strategies of treating all patients or treating none.\n\nThese metrics collectively provide a robust evaluation of the model's performance, ensuring that it is both accurate and clinically relevant. The use of AUC, calibration curves, and DCA is consistent with standard practices in the literature, making our evaluation representative and reliable.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "The evaluation of our predictive model for IDO1 expression in breast cancer involved several key performance metrics. The area under the curve (AUC) was used to assess the model's accuracy, with values of 0.809 for the training set and 0.711 for the validation set. These metrics indicate the model's strong predictive performance.\n\nStatistical significance was a crucial aspect of our evaluation. We employed the log-rank test for Kaplan\u2013Meier survival analysis, which showed that the differences in overall survival (OS) between high and low prediction score (PS) groups were statistically significant (p = 0.015). Additionally, univariate and multivariate Cox regression analyses revealed that PS was an independent favorable factor for OS (HR = 0.616; 95% CI 0.407\u20130.933; p = 0.022). This provides strong evidence that our model's predictions are reliable and clinically relevant.\n\nCalibration curves were used to assess the model's fit, showing a high degree of agreement between predicted and actual IDO1 expression levels (p > 0.05). Decision curve analysis (DCA) further demonstrated that the model offers a significant net benefit for predictions, reinforcing its practical utility.\n\nThe differences in clinical variables among patients, such as age, hormone receptor status, histological types, and treatment types, were analyzed using the Chi-square test or Fisher's exact test, with significant differences observed (all p < 0.05). This statistical rigor ensures that our findings are robust and not due to chance.\n\nOverall, the performance metrics and statistical analyses provide a high level of confidence in the model's predictive capabilities and its potential to guide clinical decisions in breast cancer treatment.",
  "evaluation/availability": "The datasets used in this study are available from the corresponding author upon reasonable request. This ensures that other researchers can access the data for further analysis or validation of our findings. The study employed open-source data from the TCGA database, which is publicly accessible and can be downloaded for research purposes. This adherence to open access principles allows for transparency and reproducibility in scientific research. The article is distributed under the terms of the Creative Commons Attribution 4.0 International License, which permits unrestricted use, distribution, and reproduction in any medium, provided appropriate credit is given to the original authors and the source. This licensing ensures that the data and findings can be widely shared and utilized by the scientific community."
}