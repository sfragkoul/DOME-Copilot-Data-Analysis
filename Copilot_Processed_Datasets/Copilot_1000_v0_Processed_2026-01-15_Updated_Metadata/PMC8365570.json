{
  "publication/title": "Computer-aided detection of COVID-19 from CT scans using an ensemble of CNNs and KSVM classifier.",
  "publication/authors": "Abraham B, Nair MS",
  "publication/journal": "Signal, image and video processing",
  "publication/year": "2022",
  "publication/pmid": "34422120",
  "publication/pmcid": "PMC8365570",
  "publication/doi": "10.1007/s11760-021-01991-6",
  "publication/tags": "- COVID-19\n- CT scans\n- Deep learning\n- Convolutional neural networks\n- Classi\ufb01cation\n- Medical imaging\n- Machine learning\n- Ensemble methods\n- Feature extraction\n- Performance metrics",
  "dataset/provenance": "The dataset used in this study is publicly available and consists of CT scans. Specifically, it includes 349 CT scans diagnosed with COVID-19 and 397 CT scans confirmed as non-COVID. This dataset has been utilized in previous research, notably by He et al. in their work. The use of a publicly available dataset ensures reproducibility and allows for comparisons with other state-of-the-art methods that have employed the same data. The dataset's size and diversity contribute to the robustness of the experimental results, providing a solid foundation for evaluating the performance of the proposed ensemble of CNNs combined with the KSVM classifier.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "In our study, we employed a public dataset to ensure reproducibility and comparability with other state-of-the-art methods. To validate the performance of our proposed method, we used 10-fold cross-validation. This technique involves splitting the dataset into 10 equal parts, or folds, and then training the model on 9 folds while testing it on the remaining fold. This process is repeated 10 times, with each fold serving as the test set once. To ensure consistency across experiments, a seed value of 1 was used to generate the folds, guaranteeing that the same data partitions were created for each run.\n\nAdditionally, we performed further validations to ensure the robustness of our method. We created partitions using different seed values ranging from 1 to 10 and repeated the experiments 10 times. This approach helped us to assess the stability and generalizability of our model. Furthermore, we conducted validation by dividing the data into a 70% training set and a 30% test set, which is a common practice in machine learning to ensure that the training and test sets are independent.\n\nThe results achieved using these different validation techniques were comparable, demonstrating the reliability of our method. The distribution of our dataset aligns with previously published machine learning datasets used for similar tasks, ensuring that our findings are relevant and applicable to the broader research community.",
  "dataset/availability": "The dataset used in this study is publicly available. It consists of 349 CT scans diagnosed with COVID-19 and 397 CT scans confirmed as non-COVID. This dataset was utilized by several state-of-the-art methods, ensuring a standardized comparison. The dataset is accessible to the public, allowing other researchers to replicate and build upon the findings presented in this work. The specific details and access to the dataset can be found in the referenced literature. The use of a public dataset promotes transparency and reproducibility in research, which is crucial for advancing the field. The dataset is available under a license that permits its use for research purposes, ensuring that it can be accessed and utilized by the scientific community. The availability of this dataset in a public forum facilitates the validation and comparison of different methods, contributing to the progress in COVID-19 diagnosis using CT scans.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a Support Vector Machine (SVM), specifically a Kernel Support Vector Machine (KSVM). This class of algorithms is well-established in the field of machine learning and is known for its effectiveness in classification tasks.\n\nThe KSVM algorithm used in our work is not new; it has been extensively studied and applied in various domains. The reason it was not published in a machine-learning journal is that our focus was on applying this established algorithm to a specific problem\u2014classifying COVID-19 from CT scans\u2014rather than developing a new machine-learning algorithm. Our contribution lies in the innovative application of KSVM in conjunction with an ensemble of pre-trained Convolutional Neural Networks (CNNs) to achieve high accuracy in medical image classification.\n\nThe KSVM was chosen empirically after experimenting with other major classifiers, such as AdaBoostM1, Random Forest, Naive Bayes, K-Nearest Neighbors (KNN), and Bayesnet. The results demonstrated that KSVM, when used with the proposed ensemble of CNNs, achieved superior performance metrics, including Positive Predictive Value (PPV), sensitivity, F-score, kappa score, Area Under the Receiver Operating Characteristic Curve (AUROC), and accuracy. This empirical selection process ensured that the chosen classifier was the most effective for our specific task.",
  "optimization/meta": "The proposed method does not use data from other machine-learning algorithms as input. Instead, it leverages features extracted from multiple pre-trained convolutional neural networks (CNNs) to enhance the performance of COVID-19 detection from CT scans. The ensemble of CNNs includes MobilenetV2, Shufflenet, Xception, Darknet53, and EfficientnetB0. These CNNs are used as feature extractors, where the activations from a specific layer are utilized as features to train a kernel support vector machine (KSVM) classifier.\n\nThe method does not constitute a traditional meta-predictor, as it does not combine the predictions of multiple machine-learning models. Instead, it focuses on combining features from multiple CNNs to improve the classification performance. The training data used for the CNNs and the KSVM classifier is independent, as the CNNs are pre-trained on the Imagenet dataset, and the KSVM is trained on the features extracted from these CNNs using a specific COVID-19 dataset. The independence of the training data ensures that the model's performance is not biased by overlapping data.",
  "optimization/encoding": "In our study, the data encoding and preprocessing involved using pre-trained Convolutional Neural Networks (CNNs) as feature extractors. Specifically, we utilized five pre-trained CNNs: MobilenetV2, Shufflenet, Xception, Darknet53, and EfficientnetB0. These networks were pre-trained on the Imagenet dataset, which contains millions of images categorized into 1000 different classes. The pre-trained CNNs were employed to extract features from the CT scan images, leveraging their ability to classify objects into various categories.\n\nThe feature extraction process involved obtaining activations from the last fully connected (FC) layer of each CNN. For Darknet53, activations from the last convolutional layer were used. This resulted in a feature vector of dimension 746\u00d71000 for each CNN, where 746 corresponds to the number of images in the dataset. These feature vectors were then concatenated to form a combined feature vector of size 746\u00d75000. This concatenated feature vector was used as input for the Kernel Support Vector Machine (KSVM) classifier.\n\nThe preprocessing steps ensured that the data was in a suitable format for the machine-learning algorithm. The use of pre-trained CNNs allowed for efficient feature extraction without the need for fine-tuning, making the process faster and more effective. The concatenated feature vectors provided a comprehensive representation of the input images, enabling the KSVM classifier to achieve high accuracy in distinguishing between COVID-19 and non-COVID-19 CT scans.",
  "optimization/parameters": "In our study, we utilized a set of parameters to optimize the performance of our model. Specifically, we employed five key parameters: cost, degree, epsilon (eps), kernel type, and loss. The cost parameter was set to 4.5, the degree to 3, and epsilon to 0.001. We chose the Radial Basis Function (RBF) as our kernel type, and the loss was set to 0.1. These parameters were selected based on empirical analysis and previous literature to ensure optimal performance in classifying COVID-19 versus non-COVID-19 cases from CT scans. The selection of these parameters was crucial in achieving high accuracy and robustness in our classification model.",
  "optimization/features": "In the proposed method, the input features are derived from the activations of the last fully connected layer of an ensemble of five pre-trained convolutional neural networks (CNNs). These CNNs are MobilenetV2, Shufflenet, Xception, Darknet53, and EfficientnetB0. Each CNN generates a feature vector of dimension 1000 for each image in the dataset, resulting in a total of 5000 features when concatenated.\n\nThe dataset consists of 746 CT scan images, so the feature matrix has dimensions 746 \u00d7 5000. This approach leverages the pre-trained networks' ability to extract rich, high-dimensional features from the images, which are then used to train a kernel support vector machine (KSVM) classifier.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the method relies on the empirical selection of the best-performing CNNs and their concatenated features. The choice of CNNs was based on their individual performance and the combined effectiveness of their features in the classification task. This ensemble approach aims to capture diverse and complementary information from the images, enhancing the overall classification performance.\n\nThe feature extraction process was conducted using the same training and test sets across all experiments to ensure comparability. This consistency in data partitioning helps in evaluating the robustness and generalizability of the proposed method. The use of pre-trained CNNs as feature extractors allows for efficient and effective feature generation without the need for extensive fine-tuning or additional feature selection steps.",
  "optimization/fitting": "The fitting method employed in this study utilized an ensemble of pre-trained Convolutional Neural Networks (CNNs) as feature extractors, combined with a Kernel Support Vector Machine (KSVM) classifier. The CNNs used included MobilenetV2, Shufflenet, Xception, Darknet53, and EfficientnetB0. These networks were pre-trained on large datasets and fine-tuned on the specific dataset of CT scans for COVID-19 classification.\n\nThe number of parameters in the CNNs is indeed much larger than the number of training points. To address the potential issue of overfitting, several strategies were implemented. Firstly, 10-fold cross-validation was performed to ensure that the model's performance was consistent across different subsets of the data. This technique helps in assessing the model's generalization capability by training and testing on different data partitions. Additionally, the use of an ensemble of CNNs helped in reducing overfitting by averaging the predictions from multiple models, which tends to improve robustness and generalization.\n\nTo further validate the model's performance, experiments were repeated with different seed values for creating data partitions, ensuring that the results were not dependent on a specific random split. Moreover, the model's performance was evaluated using multiple metrics, including accuracy, AUROC, PPV, sensitivity, F-score, and kappa score, providing a comprehensive assessment of its effectiveness.\n\nUnderfitting was addressed by ensuring that the CNNs were adequately trained and that the features extracted were rich and informative. The use of pre-trained networks, which have already learned relevant features from large datasets, helped in capturing complex patterns in the data. Additionally, the KSVM classifier, with its RBF kernel, provided a flexible and powerful way to separate the classes, further mitigating the risk of underfitting. The choice of parameters for the KSVM, such as the cost and epsilon values, was carefully selected to balance the trade-off between bias and variance, ensuring that the model neither overfits nor underfits the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One key method involved the use of a slack variable in our Kernel Support Vector Machine (KSVM) implementation. This slack variable allows for some misclassifications during training, which helps to create a more generalizable model by preventing the classifier from fitting too closely to the training data.\n\nAdditionally, we utilized cross-validation techniques to further mitigate overfitting. Specifically, we performed 10-fold cross-validation, which involves dividing the dataset into 10 subsets and training the model on 9 of these subsets while validating on the remaining one. This process is repeated 10 times, with each subset serving as the validation set once. This approach ensures that the model is evaluated on different portions of the data, reducing the likelihood of overfitting to any particular subset.\n\nFurthermore, we experimented with different seed values for generating the folds in our cross-validation process. By using seed values ranging from 1 to 10 and repeating the experiments, we ensured that our results were consistent and not dependent on a single random partition of the data. This method helps in validating the stability and generalizability of the model across various data splits.\n\nIn summary, our regularization methods included the use of slack variables in the KSVM, extensive cross-validation, and the use of multiple seed values to ensure robust and generalizable model performance.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in detail within the publication. Specifically, the parameter settings for the kernel support vector machine (KSVM) classifier are provided in Table 2, which includes values for cost, degree, epsilon, kernel type, and loss. Additionally, the configuration details for the convolutional neural networks (CNNs) used in the ensemble, such as Darknet53, ShuffleNet, Xception, and EfficientNetB0, are described in the text. The optimization schedule, including the number of epochs, mini-batch size, and learning rate, is also mentioned when discussing the transfer learning approach.\n\nRegarding the availability of model files, these are not explicitly detailed in the publication. However, the methods and configurations are described comprehensively, allowing for replication of the experiments. The license under which these configurations and parameters are made available is not specified in the text, but standard academic publishing practices typically allow for the use of such information for research purposes.\n\nFor those interested in replicating the study, the provided details should be sufficient to configure the models and optimization processes accordingly. The dataset used, consisting of CT scans diagnosed with COVID-19 and non-COVID cases, is publicly available, further facilitating the reproducibility of the results.",
  "model/interpretability": "The model presented in this work leverages an ensemble of pre-trained Convolutional Neural Networks (CNNs) as feature extractors, combined with a Kernel Support Vector Machine (KSVM) classifier. This approach inherently introduces a level of interpretability that is often lacking in purely deep learning-based models.\n\nThe use of pre-trained CNNs, such as MobilenetV2, Shufflenet, Xception, Darknet53, and EfficientnetB0, allows for the extraction of meaningful features from the input CT scans. These features are then used to train the KSVM classifier, which is a well-understood and interpretable model. The KSVM classifier determines the optimal hyperplane that separates the positive and negative instances of the training data, providing a clear decision boundary.\n\nThe decision function of the KSVM, which is specified as a weighted sum of the kernel evaluations, can be examined to understand the contribution of each training instance to the final classification. This makes the model more transparent compared to black-box models like deep neural networks, where the decision-making process is often opaque.\n\nAdditionally, the use of an ensemble of CNNs adds robustness to the feature extraction process. By combining features from multiple networks, the model can capture a more comprehensive representation of the input data, leading to improved classification performance. The empirical selection of the CNNs and the KSVM classifier was based on extensive experimentation, ensuring that the chosen combination provides the best performance.\n\nIn summary, the model is not a black-box but rather a transparent system that combines the strengths of pre-trained CNNs for feature extraction with the interpretability of the KSVM classifier. This approach allows for a clearer understanding of the decision-making process, making it more suitable for critical applications such as medical diagnosis.",
  "model/output": "The model presented in this publication is a classification model. It is designed to distinguish between COVID-19 and non-COVID-19 cases using CT scan images. The model employs an ensemble of pre-trained Convolutional Neural Networks (CNNs) to extract features from the CT scans, which are then fed into a Kernel Support Vector Machine (KSVM) classifier. The KSVM classifier determines the optimal hyperplane to separate the positive and negative instances of the training data, effectively classifying the CT scans into COVID-19 or non-COVID-19 categories.\n\nThe performance of the model is evaluated using several metrics, including accuracy, sensitivity, positive predictive value (PPV), F-score, kappa score, and the area under the receiver operating characteristic curve (AUROC). The model achieved an accuracy of 91.6% and an AUROC of 0.963, indicating its effectiveness in classifying COVID-19 cases from CT scans.\n\nThe model's output is a binary classification, where each CT scan is labeled as either COVID-19 or non-COVID-19. The confusion matrix and ROC curves provide visual representations of the model's performance, showing the true positive, true negative, false positive, and false negative rates. The model's decision function, which incorporates the RBF kernel, plays a crucial role in making these classifications.\n\nThe experimental results demonstrate that the proposed ensemble of CNNs combined with the KSVM classifier outperforms other state-of-the-art methods that use the same dataset. The model's robustness is further validated through different types of validation, including 10-fold cross-validation and hold-out validation, ensuring consistent and reliable performance.",
  "model/duration": "The execution time for the proposed method was notably efficient, completing 10-fold cross-validation in just 10.79 minutes. This is significantly faster compared to transfer learning approaches using various pre-trained CNNs. For instance, MobilenetV2 took 146.52 minutes, Shufflenet took 70.08 minutes, Xception took 312.78 minutes, Darknet53 took 657.35 minutes, and EfficientnetB0 took 298.99 minutes. Additionally, the time required for feature extraction and classification of a single instance was 24.315 seconds. This efficiency underscores the practicality of the proposed method for real-world applications where quick processing times are crucial.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method involved several rigorous steps to ensure its effectiveness and robustness. A publicly available dataset consisting of 349 CT scans diagnosed with COVID-19 and 397 CT scans confirmed as non-COVID was utilized. The performance metrics employed included the area under the receiver operating characteristic curve (AUROC), accuracy, kappa score, positive predictive value (PPV), sensitivity, and F-score.\n\nTo validate the method, a 10-fold cross-validation (CV) was performed on the dataset, and the average results of the 10 folds were considered. This approach ensured that the same data partitions were created for each experiment, making the results comparable. Additionally, a seed value of 1 was used to generate the folds, further standardizing the validation process.\n\nThe proposed method achieved an accuracy of 91.6% and an AUROC of 0.963. To ensure the reliability of these results, two additional types of validation were conducted. First, partitions were created using different seed values from 1 to 10, and the experiments were repeated 10 times. The average performance metrics across these repetitions were calculated, showing consistent results. Second, the data was divided into a 70% training set and a 30% test set, achieving comparable performance metrics.\n\nThe confusion matrix and ROC curves corresponding to the COVID-19 vs. non-COVID-19 classification were also analyzed. The confusion matrix provided a visual representation of the classification performance, with the diagonal element indicating accuracy. The ROC curves further illustrated the method's ability to distinguish between the two classes.\n\nStatistical significance was determined using the Chi-square statistic, with a p-value of less than 0.00001, indicating that the results were significant at the p < 0.05 level. This comprehensive evaluation process demonstrated the effectiveness and reliability of the proposed method in predicting COVID-19 from CT scans.",
  "evaluation/measure": "In our evaluation, we reported several key performance metrics to comprehensively assess the effectiveness of our proposed method. These metrics include Positive Predictive Value (PPV), Sensitivity, F-Score, Kappa score, Area Under the Receiver Operating Characteristic Curve (AUROC), and Accuracy. PPV measures the proportion of positive identifications that are actually correct, while Sensitivity, also known as Recall, indicates the proportion of actual positives that are correctly identified. The F-Score is the harmonic mean of PPV and Sensitivity, providing a single metric that balances both concerns. The Kappa score assesses the agreement between the predicted and actual classifications, adjusted for the agreement that could be expected by chance. AUROC evaluates the model's ability to distinguish between classes across all threshold levels, and Accuracy represents the overall proportion of correct predictions.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in medical imaging tasks. They provide a robust and representative set of measures that allow for a thorough comparison with other state-of-the-art methods. By including these metrics, we ensure that our evaluation is comprehensive and aligned with standard practices in the field.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our proposed method against several state-of-the-art techniques. We specifically compared our approach with methods that utilized the same public dataset, ensuring a fair benchmarking process. These methods included those by He et al., Anwar and Zakir, Sakagianni et al., Polsinelli et al., and Yener and Oktay. Our proposed method, which employs an ensemble of features extracted using MobilenetV2, Shufflenet, Xception, Darknet53, and EfficientnetB0 in combination with a KSVM classifier, demonstrated superior results compared to these existing methods.\n\nWe also conducted a comparison with simpler baselines, such as AdaBoostM1, Random Forest, Naive Bayes, KNN, and Bayesnet, to assess the effectiveness of our chosen classifier. The results, presented in Table 5, show that while these classifiers produced statistically significant results, their performance was considerably lower than that of KSVM. This empirical analysis underscored the superiority of KSVM in conjunction with our ensemble of CNNs for the classification task.\n\nAdditionally, we compared our method with transfer learning approaches using the same pre-trained CNNs. The proposed method outperformed these transfer learning techniques in terms of accuracy and kappa score, as detailed in Table 4. This comparison highlights the efficiency and effectiveness of using pre-trained CNNs as feature extractors rather than fine-tuning them for the specific task.\n\nIn summary, our evaluation included a thorough comparison with both publicly available methods on benchmark datasets and simpler baselines, providing a comprehensive assessment of our proposed method's performance.",
  "evaluation/confidence": "The evaluation of our proposed method includes a thorough assessment of its statistical significance. We employed a chi-square statistic to compute the p-value, which was found to be less than 0.00001. This p-value is significant at the 0.05 level, indicating that our method's performance is statistically significant.\n\nTo ensure the robustness of our results, we performed multiple types of validation. We used 10-fold cross-validation with different seed values ranging from 1 to 10, repeating the experiments 10 times. This approach helped us to create consistent data partitions and achieve reliable results. Additionally, we validated our method by dividing the data into a 70% training set and a 30% test set. The results from these different validation techniques were comparable, further confirming the reliability of our method.\n\nWe also compared our method with various state-of-the-art techniques. Our proposed ensemble of CNNs combined with a KSVM classifier outperformed other methods that used the same public dataset. This comparison included techniques that employed cross-validation and hold-out data validation. The superior performance of our method was evident in metrics such as accuracy, AUROC, and kappa score.\n\nIn summary, the statistical significance of our results, along with the consistency across different validation methods and superior performance compared to other techniques, provides strong confidence in the effectiveness of our proposed method.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The dataset consisted of 349 CT scans diagnosed with COVID-19 and 397 CT scans confirmed as non-COVID. This dataset was used to evaluate the performance of our proposed method, which achieved an accuracy of 91.6% and an AUROC of 0.963. While the specific dataset is not publicly released, the methods and results are thoroughly documented in the publication, allowing for reproducibility. The performance metrics used include AUROC, accuracy, kappa score, positive predictive value (PPV), sensitivity, and F-score. The experiments were conducted using MATLAB 2020b for feature extraction and the LibSVM package of Weka 3.6 for classification. The parameter settings for the classifier are also provided, ensuring that the evaluation process can be replicated by other researchers."
}