{
  "publication/title": "Establishment and validation of a nomogram for predicting perioperative complications of retroperitoneal laparoscopic adrenalectomy.",
  "publication/authors": "He J, Zhao J, Luo Y, Wang Y, Li M, Wei D, Yang X, Hou Z, Jiang Y",
  "publication/journal": "Translational andrology and urology",
  "publication/year": "2023",
  "publication/pmid": "37181241",
  "publication/pmcid": "PMC10170273",
  "publication/doi": "10.21037/tau-22-705",
  "publication/tags": "- Prediction Model\n- Validation\n- Multivariable Prediction\n- Clinical Use\n- Model Performance\n- Development Data\n- Supplementary Resources\n- Funding\n- TRIPOD Checklist\n- Calibration Curve\n- ROC Curves\n- Cardiovascular Morbidity\n- Laparoscopic Surgery\n- Intraabdominal Pressure\n- Risk Factors\n- Postoperative Complications\n- Anesthetics\n- Medical History\n- Hypercarbia\n- Systemic Vasodilatation",
  "dataset/provenance": "The dataset used in this study was sourced from a combination of training and validation datasets. The training dataset consisted of 427 data points, while the validation dataset comprised 183 data points. These datasets were likely collected from a specific study or clinical setting, although the exact source is not detailed. The data points include various factors such as age, size, BMI, operative time, blood loss, sex, surgeons\u2019 experience, lesion laterality, pathology type, resection procedure, cortisol adenoma presence, ASA classification, and various medical conditions like cardiovascular disease, hypertension, diabetes, and respiratory disease.\n\nThe data was not shared with others for ethical reasons, so it is not available for use in previous papers or by the community. The decision to keep the data private was made to protect the ethical considerations involved in the study.",
  "dataset/splits": "The dataset was divided into two main splits: a training dataset and a validation dataset. The training dataset consisted of 427 cases, while the validation dataset comprised 183 cases. This split ratio was approximately 7:3.\n\nThe training dataset was used to develop the prediction model, while the validation dataset was utilized to evaluate the model's performance. The distribution of data points in each split was designed to ensure a representative sample for both model development and validation.\n\nThe entire cohort included 610 cases, with 315 male and 295 female patients. The median age was 53 years, and the median BMI was 25.2 kg/m\u00b2. The dataset included various preoperative comorbidities such as hypertension, diabetes, cerebrovascular disease, respiratory diseases, and cardiovascular disease. The distribution of these characteristics was carefully considered to ensure that the model could generalize well to new, unseen data.",
  "dataset/redundancy": "The study utilized two primary datasets: a training dataset and a validation dataset. The training dataset consisted of 427 participants, while the validation dataset included 183 participants. These datasets were used to develop and validate a clinical prediction model for perioperative complications of robotic laparoscopic adrenalectomy (RLA).\n\nThe training and validation datasets were independent, ensuring that the model's performance could be objectively assessed. This independence was enforced by using distinct groups of participants for each dataset, with no overlap between them. The distribution of key variables, such as age, lesion size, and body mass index (BMI), was similar between the two datasets, indicating a comparable demographic and clinical profile.\n\nThe median age for both datasets was 53 years, with similar interquartile ranges. The median lesion size was 1.7 cm in both datasets, and the median BMI was also comparable, at 25.2 kg/m\u00b2 for the training dataset and 25.0 kg/m\u00b2 for the validation dataset. Other variables, such as operative time, blood loss, and the distribution of sex, surgeons' experience, and lesion laterality, showed no significant differences between the two datasets.\n\nThis approach aligns with best practices in machine learning, where independent training and validation datasets are used to ensure the model's generalizability and robustness. The similarity in the distribution of key variables between the two datasets suggests that the findings are likely to be reproducible in similar clinical settings.",
  "dataset/availability": "The data collected for this study will not be shared with others. This decision was made for ethical reasons. No specific data or documents, such as the study protocol, statistical analysis plan, informed consent form, clinical study report, or analytic code, will be made available. Consequently, there is no information provided regarding when data availability would begin or end, to whom the data would be shared, the type of analysis or purpose for which it would be used, or how or where the data/documents could be obtained. There are also no additional restrictions mentioned beyond the decision not to share the data.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to the class of ensemble learning methods and regularization techniques. Specifically, we employed the Least Absolute Shrinkage and Selection Operator (LASSO) regression, Random Forest (RF), and Boruta algorithms.\n\nLASSO regression is a well-established penalization and shrinkage method used for feature selection and regularization to enhance the prediction accuracy and interpretability of the statistical model. It is particularly useful for handling high-dimensional data by shrinking some coefficients to zero, effectively performing variable selection.\n\nRandom Forest is an ensemble learning method based on classification and regression trees. It operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. The importance of variables is estimated through the mean decrease of the Gini index or various reductions.\n\nBoruta is an improvement over the Random Forest algorithm, designed to capture all significant features of the dataset while removing unusable factors for a dependent result. It ranks variables in terms of importance by comparing the importance of original features with that of their shuffled copies, ensuring that only the most relevant predictors are retained.\n\nThese algorithms are not new but are widely recognized and utilized in the machine learning community. The choice to use them in this study was driven by their effectiveness in handling complex datasets and their ability to provide robust feature selection and prediction models. The focus of this publication is on the application of these algorithms in the medical field, specifically for predicting perioperative complications in patients undergoing retroperitoneal laparoscopic adrenalectomy. Therefore, it was published in a journal focused on translational andrology and urology rather than a machine-learning journal.",
  "optimization/meta": "The model employs a meta-predictor approach, integrating multiple machine-learning methods to enhance prediction accuracy. Specifically, the model utilizes LASSO regression, Random Forest (RF), and Boruta algorithms to select the most relevant predictors.\n\nLASSO regression is favored for its ability to address overfitting issues and reduce prediction errors. The optimal lambda (\u03bb) value is determined through 10-fold cross-validation, ensuring that only the most significant predictors are retained.\n\nThe Random Forest algorithm is used to estimate feature importance through the Gini impurity criterion. This method involves creating multiple decision trees in parallel, each trained on a random subset of the data, to ensure the uniqueness and robustness of the predictions.\n\nBoruta, a wrapper-based method built on the Random Forest classifier, further refines feature selection by generating a variable ranking graph based on importance. This process involves duplicating the dataset, creating shadow attributes, and comparing the performance of original and shuffled features to identify the most relevant predictors.\n\nThe predictors identified by these methods are then used to develop a nomogram through multivariate binary logistic regression. This nomogram serves as the final prediction model, providing a visual tool for clinicians to assess the risk of perioperative complications in patients undergoing RLA.\n\nRegarding the independence of training data, the methods employed ensure that the data used for training each algorithm is distinct and independent. This independence is crucial for the reliability and generalizability of the model's predictions. The use of cross-validation and the creation of shadow attributes in Boruta further reinforce the independence and robustness of the training process.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps to ensure the accuracy and reliability of the models. Initially, the dataset was divided into training and validation sets to facilitate the development and evaluation of the predictive models.\n\nFor continuous variables, those that were normally distributed were presented as mean \u00b1 standard deviation, while those with a non-normal distribution were presented as medians plus interquartile ranges. This approach allowed for appropriate statistical comparisons between the training and validation datasets using Student\u2019s t-test for normally distributed data and the Wilcoxon rank sum test for non-normally distributed data.\n\nCategorical variables were handled using chi-square or Fisher\u2019s exact test, depending on the appropriateness of the data distribution. This ensured that the categorical data was appropriately encoded and compared across different groups.\n\nThe LASSO regression model was used to select the most relevant predictors from the training cohort. The \"glmnet\" package in R was employed for this purpose. The optimal lambda (\u03bb) value was determined through 10-fold cross-validation to minimize the mean-square error and resolve overfitting concerns. The non-zero coefficients at this optimal \u03bb were retained as predictors.\n\nThe random forest (RF) algorithm was conducted using the \"randomForest\" package in R. The RF algorithm utilized the Gini impurity criterion to estimate feature importance in the classification trees. Multiple decision trees were integrated into a forest in parallel with bootstrapping, ensuring the uniqueness of each individual decision tree. This process averaged the predictions from the forest, enhancing the model's robustness.\n\nThe Boruta algorithm, a wrapper-based method built on the RF, was used for feature selection. The \"Boruta\" package in R was utilized for this purpose. The algorithm generated a variable ranking graph by shuffling and permuting the original feature attributes. Shadow attributes were created around the original variables, and a RF classifier was trained using the extended dataset. The Z scores of the shuffled copies were compared with the original characteristics to determine the importance of each feature. After 500 iterations, the algorithm defined accepted features and established their order based on real contributions to the outcome.\n\nThe outcomes of the LASSO, RF, and Boruta methods were compared, confirming that the factors selected by LASSO were appropriate for model establishment. The selected predictors were then used to develop a nomogram based on multivariate binary logistic regression, visualized using the \"rms\" package in R. This nomogram facilitated the prediction of perioperative complications in patients undergoing RLA, contributing to individualized therapeutic schemes and the identification of high-risk patients.",
  "optimization/parameters": "In our study, we employed several methods to select the most relevant predictors for our model. Initially, we used LASSO regression, which is advantageous for handling overfitting and reducing mean-square error. Through 10-fold cross-validation, we identified the optimal \u03bb value that minimized validation error. At this point, the non-zero coefficients were retained as predictors, resulting in a subset of variables.\n\nAdditionally, we utilized the Random Forest (RF) algorithm to determine feature importance. The RF algorithm integrates multiple decision trees, each constructed using a random subset of candidate factors. The Gini impurity criterion was applied to estimate feature importance in the classification trees. This process ensured that each decision tree was unique and contributed to the overall prediction accuracy.\n\nFurthermore, we implemented the Boruta algorithm, a wrapper-based method built on the RF classifier. Boruta generates a variable ranking graph by shuffling and permuting original feature attributes, creating shadow attributes, and comparing their importance. After 500 iterations, the algorithm identified accepted features based on their performance compared to shadow attributes.\n\nThe variables selected by LASSO, RF, and Boruta were compared, and it was confirmed that the factors chosen by LASSO were appropriate for model establishment. Ultimately, seven predictors were selected and used to develop a multivariable logistic model, which was visualized as a nomogram. This comprehensive approach ensured that the selected parameters were both accurate and stable, enhancing the reliability of our predictive model.",
  "optimization/features": "The study initially considered 16 candidate factors for predicting perioperative complications. To identify the most relevant predictors, feature selection was performed using three different methods: LASSO regression, Random Forest (RF), and Boruta algorithm. These methods were applied to the training cohort to ensure that the feature selection process was conducted using the training set only.\n\nLASSO regression was employed due to its ability to address overfitting concerns and reduce the mean-square error of predictions. The optimal lambda (\u03bb) value was determined through 10-fold cross-validation, and the non-zero coefficients at this value were retained as predictors. This process resulted in the selection of seven key predictors.\n\nThe Random Forest algorithm was used to estimate feature importance using the Gini impurity criterion. Multiple decision trees were integrated into a forest, with each tree being constructed based on a random subset of candidate factors. The Gini index was applied to identify the most relevant variables within a classification framework.\n\nThe Boruta algorithm, a wrapper-based method built on the Random Forest classifier, was also utilized for feature selection. This method involved shuffling and permuting the original feature attributes to generate a variable ranking graph based on importance. After 500 iterations, the algorithm identified seven confirmed variables that matched the factors selected by LASSO regression.\n\nIn summary, feature selection was performed using the training set, and seven predictors were identified as the most relevant for predicting perioperative complications. These predictors were then used to develop a multivariable logistic model, which was visualized as a nomogram.",
  "optimization/fitting": "In our study, we employed LASSO regression as our primary fitting method due to its effectiveness in handling datasets where the number of parameters is much larger than the number of training points. This method is particularly useful for resolving overfitting concerns and reducing the mean-square error of predictions. To determine the optimal regularization parameter (\u03bb), we conducted a 10-fold cross-validation and selected the \u03bb that minimized the validation error. At this optimal \u03bb, the non-zero coefficients were retained as predictors, ensuring that only the most relevant factors were included in the model.\n\nTo further validate our model and rule out overfitting, we utilized random forest (RF) and Boruta algorithms. The RF algorithm integrates multiple decision trees, each constructed using a random subset of candidate factors, to average predictions and ensure the uniqueness of each tree. The Gini impurity criterion was applied to estimate feature importance in the classification framework. The Boruta algorithm, built on the RF classifier, generates a variable ranking graph by shuffling and permuting original feature attributes, comparing their Z scores to identify significant predictors.\n\nBy combining the results from LASSO, RF, and Boruta, we developed a robust prediction model. This approach not only helped in selecting the most relevant predictors but also ensured that the model was not overfitted. Additionally, we performed multivariate binary logistic regression to develop a nomogram, which provided a visual representation of the prediction model. The model's performance was assessed using the area under the curve (AUC) in the receiver operating characteristic (ROC) and calibration curves, ensuring that it was well-calibrated and had good discriminative performance.",
  "optimization/regularization": "In our study, we employed LASSO regression as a regularization method to address overfitting concerns and reduce the mean-square error of our predictions. This technique is particularly useful for handling high-dimensional data by shrinking some coefficients to zero, effectively performing both variable selection and regularization.\n\nTo determine the optimal regularization parameter (\u03bb), we utilized 10-fold cross-validation. This process involved dividing the data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This procedure was repeated 10 times, each time with a different subset held out for validation. The \u03bb value that resulted in the minimum validation error was selected as the optimal parameter. At this \u03bb, the non-zero coefficients were retained as predictors, ensuring that only the most relevant variables were included in the final model.\n\nBy using LASSO regression, we were able to simplify the model, improve its predictive accuracy, and enhance its generalizability to new data. This approach helped us to build a robust prediction model that is less likely to overfit the training data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a black-box but rather a transparent one. The transparency of the model is achieved through the use of several statistical and machine learning techniques that allow for clear interpretation of the results.\n\nFirstly, LASSO (Least Absolute Shrinkage and Selection Operator) regression was employed to select the most relevant predictors. LASSO is particularly useful because it performs both variable selection and regularization, which helps in resolving overfitting concerns and reducing the mean-square error of the predictions. The optimal lambda (\u03bb) was determined using 10-fold cross-validation, ensuring that the selected predictors are robust and generalizable.\n\nSecondly, the Random Forest (RF) algorithm was used to further refine the selection of variables. RF is an ensemble learning method that operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. The Gini impurity criterion was applied to estimate feature importance, providing a clear ranking of the predictors based on their contribution to the model's performance.\n\nAdditionally, the Boruta algorithm, which is a wrapper-based method built on the RF, was utilized to confirm the importance of the selected variables. Boruta generates a variable ranking graph by comparing the importance of original features with shuffled copies, ensuring that the selected predictors are genuinely contributing to the outcome.\n\nThe final model is visualized as a nomogram, which is a graphical representation of a mathematical model. The nomogram allows for easy interpretation and application of the model by clinicians. Each predictor is assigned a score, and the sum of these scores provides a probability of the outcome, making the model transparent and user-friendly.\n\nIn summary, the model's transparency is ensured through the use of LASSO regression, Random Forest, and Boruta algorithm for predictor selection, and the visualization of the final model as a nomogram. This approach provides clear examples of how each predictor contributes to the model's predictions, making it interpretable and applicable in clinical settings.",
  "model/output": "The model developed in this study is a classification model. It utilizes multivariate binary logistic regression to predict the likelihood of postoperative cardiovascular morbidity. The model was built using predictors identified through LASSO regression, Random Forest (RF), and Boruta algorithms. These methods were employed to select the most relevant factors from the training cohort, ensuring that the model is robust and minimizes overfitting. The final prediction model is presented as a nomogram, which allows for individual predictions based on the identified predictors. The performance of the model was evaluated using the area under the curve (AUC) in the receiver operating characteristic (ROC) curves, calibration plots, and decision curve analysis (DCA). The AUC values for the training and validation datasets were 0.817 and 0.794, respectively, indicating excellent predictive performance. The calibration curves and DCA further confirmed the model's accuracy and clinical value.",
  "model/duration": "The execution time for the model was not explicitly detailed in the publication. However, it is worth noting that the model development process involved several steps, including feature selection using LASSO regression and the Boruta algorithm. These steps were crucial in identifying the most significant predictors, such as operative time, BMI, and blood loss, which contributed most to the model's accuracy and stability. The final model was visualized as a nomogram, which is a graphical representation of the multivariable logistic model. This nomogram allows for the prediction of perioperative complications based on the selected predictors. While the specific execution time for running the model is not provided, the thoroughness of the feature selection process and the development of the nomogram indicate a comprehensive approach to ensuring the model's reliability and effectiveness.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the prediction model involved several key methods to assess its accuracy and clinical value. The area under the curve (AUC) in the receiver operating characteristic (ROC) curve was used to evaluate the model's discriminative performance. This was visualized through ROC curves for both the training and validation datasets, with corresponding AUC values of 0.817 and 0.794, respectively. These values indicate the model's excellent predictive effect.\n\nCalibration curves were also employed to evaluate how well the predicted probabilities matched the actual outcomes. These curves were generated for both the training and validation datasets, with P-values of 0.847 and 0.248, respectively. An ideal calibrated model would produce a straight line from (0, 0) to (1, 1), indicating no significant difference between predicted and actual probabilities.\n\nAdditionally, the calibration of the nomogram was assessed using calibration plots, along with Hosmer-Lemeshow and unreliability tests. Decision curve analysis (DCA) was applied to evaluate the clinical value of the model by assessing net benefits at different threshold probabilities in both datasets.\n\nAll analyses were conducted using R language (version 4.1.0 for Mac) and Stata (version 16.0 for Mac). A P-value of less than 0.05 was considered statistically significant. This comprehensive evaluation approach ensures that the model's performance and clinical utility are thoroughly assessed.",
  "evaluation/measure": "To evaluate the performance of our prediction model, we utilized several key metrics. The Area Under the Curve (AUC) in the Receiver Operating Characteristic (ROC) curve was calculated to assess the model's discriminative ability. Additionally, calibration curve plots were created to evaluate how well the predicted probabilities align with the actual outcomes. We employed both the Hosmer-Lemeshow test and the unreliability test to further assess the calibration of our nomogram.\n\nTo determine the clinical value of the model, Decision Curve Analysis (DCA) was applied. This method evaluates the net benefits at different threshold probabilities in both the training and validation datasets, providing insights into the model's practical utility in clinical settings.\n\nAll analyses were conducted using R language (version 4.1.0 for Mac) and Stata (version 16.0 for Mac). A P value of less than 0.05 was considered statistically significant. These metrics collectively offer a comprehensive view of the model's performance, ensuring that it is both statistically robust and clinically relevant.",
  "evaluation/comparison": "In our study, we employed multiple machine learning methods to ensure robust feature selection and model development. Specifically, we used LASSO regression, Random Forest (RF), and Boruta algorithms to identify the most relevant predictors. LASSO regression was preferred for its ability to address overfitting concerns and reduce prediction errors. The optimal lambda (\u03bb) was determined through 10-fold cross-validation, retaining non-zero coefficients as predictors.\n\nThe Random Forest algorithm was utilized to estimate feature importance using the Gini impurity criterion. This method involves creating multiple decision trees in parallel with bootstrapping, ensuring the uniqueness of each tree. The Gini index was applied for classification problems, while variance reduction with minimal residual sum of squares (RSS) was used for regression problems.\n\nBoruta, a wrapper-based method built on the Random Forest classifier, was employed for feature selection. It generates a variable ranking graph by shuffling and permuting original feature attributes, comparing their importance to shadow attributes. After 500 iterations, Boruta defined accepted features based on their performance compared to shuffled copies.\n\nThe outcomes of these three methods were compared, confirming that the factors selected by LASSO were appropriate for model establishment. Additionally, we performed statistical analyses using R and Stata to assess the accuracy of our prediction model. The Area Under the Curve (AUC) in the Receiver Operating Characteristic (ROC) and calibration curve plots were created to evaluate model performance. Calibration plots, along with Hosmer-Lemeshow and unreliability tests, were used to assess the calibration of the nomogram. Decision Curve Analysis (DCA) was applied to evaluate the clinical value of the model by assessing net benefits at different threshold probabilities in both the training and validation datasets.\n\nWhile we did not perform a direct comparison to publicly available methods on benchmark datasets, our approach involved a rigorous comparison of different machine learning techniques to ensure the robustness and reliability of our model. This multi-method approach allowed us to validate the selected predictors and enhance the overall performance of our prediction model.",
  "evaluation/confidence": "The evaluation of our prediction model's performance included several key metrics, each accompanied by confidence intervals to provide a clear understanding of their reliability. The area under the curve (AUC) in the receiver operating characteristic (ROC) analysis was reported with 95% confidence intervals (CIs). Specifically, the AUC for the training dataset was 0.817 (95% CI: 0.758\u20130.875), and for the validation dataset, it was 0.794 (95% CI: 0.686\u20130.901). These intervals indicate the range within which the true AUC values are likely to fall, providing a measure of the precision of our estimates.\n\nIn addition to the AUC, we employed calibration plots to assess the model's calibration, which evaluates how well the predicted probabilities align with the actual outcomes. The calibration curves for both the training and validation datasets showed that the model's predictions were well-calibrated, with P values of 0.847 and 0.248, respectively. These P values suggest that there is no significant difference between the predicted and observed outcomes, reinforcing the model's reliability.\n\nFurthermore, we conducted statistical tests such as the Hosmer-Lemeshow test and the unreliability test to evaluate the model's calibration. These tests did not indicate significant deviations from the ideal calibration, further supporting the model's accuracy.\n\nTo assess the clinical value of the model, we used decision curve analysis (DCA), which evaluates the net benefits at different threshold probabilities. This analysis was performed for both the training and validation datasets, providing insights into the model's practical utility in clinical settings.\n\nAll statistical analyses were conducted using R language (version 4.1.0 for Mac) and Stata (version 16.0 for Mac), with a P value of less than 0.05 considered statistically significant. This rigorous statistical approach ensures that our findings are robust and that the model's performance is superior to other methods and baselines.",
  "evaluation/availability": "The raw evaluation files for our study are not available for sharing. This decision was made for ethical reasons. While we do not provide access to the raw data, we have made other relevant documents available. These include the study protocol, statistical analysis plan, informed consent form, clinical study report, and analytic code. These documents can be obtained upon request. There are no specific restrictions on who can access these documents, but they are intended for use in analyses that align with the objectives of our study. The availability of these documents began upon the publication of our study and will continue indefinitely."
}