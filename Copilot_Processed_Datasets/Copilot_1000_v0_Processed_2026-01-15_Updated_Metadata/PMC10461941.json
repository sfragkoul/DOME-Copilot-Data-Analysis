{
  "publication/title": "The Gene Expression Classifier ALLCatchR Identifies B-cell Precursor ALL Subtypes and Underlying Developmental Trajectories Across Age.",
  "publication/authors": "Beder T, Hansen BT, Hartmann AM, Zimmermann J, Amelunxen E, Wolgast N, Walter W, Zaliova M, Anti\u0107 \u017d, Chouvarine P, Bartsch L, Barz MJ, Bultmann M, Horns J, Bendig S, K\u00e4ssens J, Kaleta C, Cario G, Schrappe M, Neumann M, G\u00f6kbuget N, Bergmann AK, Trka J, Haferlach C, Br\u00fcggemann M, Baldus CD, Bastian L",
  "publication/journal": "HemaSphere",
  "publication/year": "2023",
  "publication/pmid": "37645423",
  "publication/pmcid": "PMC10461941",
  "publication/doi": "10.1097/hs9.0000000000000939",
  "publication/tags": "- B-cell precursor acute lymphoblastic leukemia\n- Gene expression classifier\n- Machine learning algorithms\n- Subtype prediction\n- Linear SVM\n- Feature selection methods\n- LASSO\n- Boruta\n- Classification performance\n- Molecular subtypes\n- RNA-Seq experiments\n- Pediatric oncology\n- Deterministic linear SVM\n- Sample-to-sample distances\n- Gene expression signatures\n- Genomic driver aberrations\n- Classification accuracy\n- Immunophenotype\n- Patient sex classification\n- Blast count predictions\n- Root mean squared error\n- Validation datasets\n- Clinical trials in oncology\n- Leukemia research\n- Molecular subtype classification\n- Developmental trajectories\n- Age-related gene expression",
  "dataset/provenance": "The dataset utilized in our study comprises gene expression count data from RNA-Seq experiments, focusing on B-cell precursor acute lymphoblastic leukemia (BCP-ALL). A total of 3532 BCP-ALL patients were included, drawn from six distinct datasets. These datasets encompass a diverse range of patient cohorts, including those from St Jude Children\u2019s Research Hospital, Children\u2019s Oncology Group, ECOG-ACRIN Cancer Research Group, the Alliance for Clinical Trials in Oncology, M.D. Anderson Cancer Center, University of Toronto, Northern Italian Leukemia Group, Southwestern Oncology Group, Medical Research Council UK, and City of Hope.\n\nThe largest dataset within our study is the St Jude dataset, which includes 1988 patients. This dataset is particularly notable for its inclusion of pediatric patients, with 501 samples specifically marked as St Jude, all of which are pediatric cases. These samples were considered an individual cohort for validation purposes.\n\nFor the training and validation of our classifier, ALLCatchR, four datasets comprising 1869 samples were used for training, while validation was performed on three hold-out datasets totaling 1129 samples. Additionally, 111 samples that were originally defined as \u2018unassigned\u2019 or B-other in the original studies were included to evaluate the predictive capabilities of ALLCatchR.\n\nThe data used in this study has been previously utilized in various original studies, including GMALL, St Jude, CLIP, MLL, AIEOP-BFM, and RCH/PM. These studies defined molecular subtypes based on genomic driver aberrations and corresponding gene expression signatures in 2887 cases, which served as the ground truth for our analysis. The remaining cases were deemed \u2018unassigned\u2019 or B-other.",
  "dataset/splits": "In our study, we utilized gene expression count data from a total of 3532 B-cell precursor acute lymphoblastic leukemia (BCP-ALL) patients across six datasets. The data was divided into four main splits: three hold-out datasets and one training dataset.\n\nThe training dataset consisted of 1869 samples, which were used to develop and validate our model internally. The hold-out datasets, comprising 1129 samples, were used for external validation to assess the generalizability of our model. Among these hold-out datasets, the largest was from St. Jude Children's Research Hospital, which included 501 pediatric samples. Additionally, there were 111 samples that were originally defined as 'unassigned' or B-other in the original studies, and these were included to evaluate our model's predictions.\n\nThe distribution of data points across the datasets was as follows:\n\n* Training dataset: 1869 samples\n* Hold-out datasets: 1129 samples\n  * St. Jude dataset: 501 samples\n  * Other hold-out datasets: 628 samples\n* Unassigned/B-other samples: 111 samples\n\nThis split allowed us to thoroughly train and validate our model, ensuring its robustness and accuracy in predicting BCP-ALL molecular subtypes.",
  "dataset/redundancy": "The dataset used in this study comprised gene expression count data from a total of 3532 B-cell precursor acute lymphoblastic leukemia (BCP-ALL) patients across 6 different datasets. To ensure robust validation and generalization of our classifier, ALLCatchR, the data was split into training and hold-out sets. Four datasets, encompassing 1869 samples, were designated for training. Validation was performed on three independent hold-out datasets, totaling 1129 samples. This split was designed to mimic real-world applications by challenging the classifier with new, independent data structures.\n\nThe independence of the training and test sets was enforced by ensuring that the hold-out datasets were completely separate from the training data. The selection of hold-out datasets was based on their representation of all subtypes and age groups, ensuring a comprehensive evaluation of the classifier's performance. Additionally, samples marked as 'unassigned' or B-other in the original studies were included in the hold-out sets to evaluate the classifier's predictions on these challenging cases.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the field. The inclusion of a large and diverse cohort of BCP-ALL patients, along with the careful selection of hold-out datasets, ensures that the results are generalizable and robust. The dataset includes a wide range of molecular subtypes, as defined by the WHO-HAEM5/ICC classification, and represents various sequencing approaches and read count quantification methods. This diversity enhances the classifier's ability to handle real-world data variability.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages machine learning techniques to enhance the prediction of B-cell precursor acute lymphoblastic leukemia (BCP-ALL) subtypes. The primary machine-learning algorithm class used is the Support Vector Machine (SVM), specifically the linear SVM. This choice was driven by its superior performance on the training data, achieving an overall accuracy of 0.963. Other algorithms such as random forest (rf), ranger, radial SVM (svmRadial), and k-nearest neighbors (kknn) were also evaluated, but linear SVM outperformed them.\n\nThe linear SVM was selected for its stability and effectiveness in handling the complex interactions within the gene expression data. Additionally, feature selection methods like LASSO and Boruta were applied to refine the model further. LASSO, with different alpha parameters, helped in selecting a stringent set of features, resulting in a more accurate and efficient model. The combination of these techniques ensured that the classifier could generalize well to new, independent datasets.\n\nThe integration of linear SVM with nearest-neighbor association models created a robust compound classifier, ALLCatchR. This classifier not only predicts subtypes with high accuracy but also provides dynamic ranges of subtype-specific scores, addressing the limitations of linear SVM in handling unassigned or ambiguous cases. The development of ALLCatchR was motivated by the need for a systematic approach to gene expression analysis in BCP-ALL diagnostics, rather than the novelty of the machine-learning algorithm itself. Therefore, it was published in a relevant scientific journal focusing on hematology and oncology.",
  "optimization/meta": "The ALLCatchR classifier is designed as a compound model that integrates multiple machine learning approaches to enhance the prediction of B-cell precursor acute lymphoblastic leukemia (BCP-ALL) subtypes. This model leverages both linear support vector machine (SVM) predictions and a nearest-neighbor association model based on gene expression data.\n\nThe linear SVM component of ALLCatchR is trained using a deterministic approach, providing high accuracy in subtype prediction. However, it is limited to predefined classes and does not compute probabilities for individual subtype predictions, which can be a drawback for handling unassigned or ambiguous cases. To address this, a probabilistic compound model was developed by incorporating single-sample gene set enrichment analyses (ssGSEA). This approach involves computing the Euclidean distance of each test sample to each training sample and considering the 10 nearest neighbors for subtype allocations. The integration of these two models allows ALLCatchR to provide dynamic ranges of subtype-specific scores, improving its ability to handle complex and novel cases.\n\nThe training data for ALLCatchR is split into a training set and hold-out studies to ensure independence and to mimic real-world applications. The training set consists of 1,869 samples, while the hold-out studies include 1,129 samples. This separation ensures that the model is validated on independent data structures, enhancing its generalizability and robustness. The hold-out data sets are selected to represent all subtypes and age groups, providing a comprehensive evaluation of the classifier's performance.\n\nIn summary, ALLCatchR is a meta-predictor that combines linear SVM and nearest-neighbor models, utilizing independent training and validation data sets to achieve high accuracy and reliability in BCP-ALL subtype prediction.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the gene expression data was suitable for training and validation. Initially, raw read counts for 15,728 protein-coding genes were obtained from various sequencing approaches, including poly-A selection and ribosomal RNA depletion, across different sequencing depths and read count quantification methods. These counts were normalized using a log10(count + 1) transformation, followed by z-transformation and scaling between 0 and 1. This normalization process helped to standardize the data, making it comparable across different samples and cohorts. The preprocessing steps were crucial for reducing batch effects and ensuring that the gene expression signatures were accurately represented. This prepared the data for feature selection methods like LASSO and Boruta, which were used to identify the most discriminative genes for subtype prediction. The final dataset consisted of 2998 samples from six cohorts, which were used to develop and validate the ALLCatchR classifier.",
  "optimization/parameters": "In the development of our classifier, we employed feature selection methods to determine the optimal number of parameters for our model. Specifically, we used LASSO regression with four different alpha parameters (0.1, 0.3, 0.5, and 1), where higher alpha values result in a more stringent selection of features. This process yielded different numbers of selected genes for machine learning, ranging from 2,802 genes when using LASSO with an alpha of 0.1 to 973 genes with an alpha of 1. Additionally, we utilized Boruta, a Random Forest-based feature selection method, to account for non-linear feature-to-class associations.\n\nThe best-performing feature selection method was found to be LASSO with an alpha of 0.1, resulting in 2,802 genes with high discriminative power for the 21 molecular subtypes we considered. This selection was integrated into our linear Support Vector Machine (SVM) model, which demonstrated superior performance in subtype prediction on the training data. The linear SVM model achieved an accuracy of 0.963, outperforming other machine learning methods tested. However, to handle unassigned or ambiguous cases and to provide probabilistic predictions, we also incorporated single-sample gene set enrichment analyses (ssGSEA) using the same subtype-defining LASSO gene sets. This approach allowed for the removal of batch effects between cohorts and the computation of Euclidean distances to nearest neighbors for subtype allocations. The final model, ALLCatchR, integrates both SVM linear predictions and sample-to-sample distances in subtype-defining gene sets, providing dynamic ranges of subtype-specific scores.",
  "optimization/features": "In the optimization process of our classifier, feature selection was indeed performed using the training set only. We utilized two primary methods for feature selection: LASSO (Least Absolute Shrinkage and Selection Operator) regression and Boruta, a Random Forest-based feature selection method. LASSO regression was applied with four different alpha parameters (0.1, 0.3, 0.5, and 1), where higher alpha values result in a more stringent selection of features. This process yielded different numbers of selected genes for machine training, ranging from 2,802 genes (using LASSO with alpha = 0.1) to 973 genes (using LASSO with alpha = 1). The best-performing feature selection method was determined to be LASSO with alpha = 0.1, resulting in 2,802 genes with high discriminative power for the 21 molecular subtypes considered in our study. These selected genes were then used as input features for training our machine learning algorithms.",
  "optimization/fitting": "The fitting method employed in our study involved a comprehensive approach to ensure both overfitting and underfitting were adequately addressed. The number of parameters, specifically the number of genes selected for feature training, was indeed larger than the number of training points. To mitigate overfitting, we utilized feature selection methods such as LASSO and Boruta. LASSO regression with varying alpha parameters was applied to select a stringent set of features, resulting in different numbers of genes for training. This method helped in reducing the dimensionality of the data and focusing on the most relevant features, thereby preventing the model from becoming too complex and overfitting the training data.\n\nAdditionally, we employed a 10-fold randomized stratified cross-validation scheme during training. This technique ensured that the model's performance was evaluated on multiple subsets of the data, providing a robust estimate of its generalization capability. The use of cross-validation helped in assessing the model's ability to perform well on unseen data, thus ruling out overfitting.\n\nTo address underfitting, we compared the performance of different machine learning algorithms, including linear SVM, random forest, and k-nearest neighbors. Linear SVM was selected due to its superior performance on the training data, achieving an overall accuracy of 0.963. This high accuracy indicated that the model was capable of capturing the underlying patterns in the data without being too simplistic.\n\nFurthermore, we integrated a nearest-neighbor association model with the linear SVM to handle cases that were unassigned or ambiguous. This compound classifier approach provided dynamic ranges of subtype-specific scores, enhancing the model's ability to make accurate predictions even for complex cases. The combination of these methods ensured that the model was neither too simple nor too complex, striking a balance between overfitting and underfitting.",
  "optimization/regularization": "In our study, we employed several regularization methods to prevent overfitting and enhance the robustness of our machine learning models. One of the key techniques used was the Least Absolute Shrinkage and Selection Operator (LASSO) regression. LASSO is particularly effective for feature selection and regularization, as it adds a penalty equal to the absolute value of the magnitude of coefficients. This process encourages sparsity in the model, effectively shrinking some coefficients to zero and thus selecting a subset of the most relevant features. We applied LASSO with different alpha parameters, where higher values result in more stringent feature selection. This approach helped in identifying a set of genes with high discriminative power for the molecular subtypes we were studying.\n\nAdditionally, we utilized Boruta, a Random Forest-based feature selection method. Boruta is capable of handling non-linear feature-to-class associations, providing a more comprehensive feature selection process. By combining LASSO and Boruta, we ensured that our models were not only robust but also capable of capturing both linear and non-linear relationships in the data.\n\nFurthermore, we implemented a 10-fold randomized stratified cross-validation scheme during the training process. This technique helps in assessing the model's performance and generalizability by dividing the data into training and validation sets multiple times, ensuring that the model does not overfit to any particular subset of the data.\n\nThese regularization methods, along with the cross-validation strategy, played a crucial role in developing a reliable and accurate classifier for BCP-ALL subtype allocation.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in the supplementary figures and the main text. Specifically, the performance of different machine learning algorithms, including their hyper-parameters, is detailed in the supplementary figures. For instance, the choice of machine learning algorithm and its impact on subtype prediction performance is illustrated, with a focus on the superior performance of linear SVM. The features selection methods, such as LASSO and Boruta, and their parameters are also described, showing how different alpha parameters in LASSO affect the number of selected genes.\n\nThe optimization schedule and model files are not explicitly detailed in the provided information. However, the integration of linear SVM predictions with sample-to-sample distances in subtype-defining gene sets is mentioned, indicating a compound classifier approach. This suggests a structured optimization process, although the specific schedules and files are not outlined.\n\nRegarding the availability and licensing of these configurations and parameters, the information provided does not specify where these details can be accessed or under what license. Therefore, it is not clear whether the hyper-parameter configurations, optimization schedule, model files, and optimization parameters are publicly available or under what terms they might be shared.",
  "model/interpretability": "The model employed in our study, ALLCatchR, incorporates both transparent and interpretable components alongside more complex machine learning algorithms. The core of our approach utilizes a linear Support Vector Machine (SVM), which is inherently more interpretable than many other machine learning models. Linear SVMs provide a clear decision boundary defined by a subset of the input features, making it easier to understand which features are most influential in the classification process.\n\nIn addition to the linear SVM, we integrated single-sample gene set enrichment analyses (ssGSEA) using sing-score. This method allows for the computation of enrichment scores for predefined gene sets, providing a probabilistic framework that can handle cases with multiple drivers or novel candidates more effectively. The use of ssGSEA adds a layer of interpretability by linking the model's predictions to biological pathways and gene sets, which are more readily understandable by domain experts.\n\nFurthermore, we employed feature selection methods such as LASSO and Boruta. LASSO, in particular, is known for its ability to perform variable selection and regularization, which can highlight the most relevant genes for subtype prediction. By setting different alpha parameters in LASSO, we can control the stringency of feature selection, resulting in different numbers of selected genes for machine training. This process not only improves model performance but also enhances interpretability by focusing on a manageable set of biologically relevant features.\n\nThe combination of these methods in ALLCatchR ensures that while the model benefits from the predictive power of advanced machine learning techniques, it remains interpretable. This balance is crucial for gaining insights into the biological mechanisms underlying the subtypes being predicted, making the model a valuable tool for both research and clinical applications.",
  "model/output": "The model, ALLCatchR, is primarily designed for classification tasks, specifically for the allocation of B-cell precursor acute lymphoblastic leukemia (BCP-ALL) subtypes based on gene expression data. It integrates linear support vector machine (SVM) and nearest-neighbor association models to achieve this. The model was trained using a 10-fold randomized stratified cross-validation scheme, and it demonstrated remarkable accuracy in subtype prediction on the training data, with an overall accuracy of 0.963 for the linear SVM. Additionally, the model incorporates single-sample gene set enrichment analyses (ssGSEA) to handle cases that are unassigned or ambiguous, providing a probabilistic compound model that offers dynamic ranges of subtype-specific scores. This approach allows for better separation between highly similar subtypes, such as high hyperdiploid and near haploid ALL. The model's performance was validated on hold-out datasets, mimicking real-world applications, and it showed good generalization capabilities. The final predictions combine outputs from classifiers trained on independent datasets, ensuring robustness and reliability.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a comprehensive approach to ensure its robustness and generalizability. The classifiers were trained on independent datasets, specifically GMALL and MLL, and validated on each other, as well as on the RCH/PM data. This cross-validation strategy allowed for a rigorous assessment of the classifiers' performance.\n\nThe training process utilized a 10-fold randomized stratified cross-validation scheme, which helps in providing a more reliable estimate of the model's performance by ensuring that each fold is representative of the overall dataset. For feature selection, LASSO regression with varying alpha parameters was employed, along with the Boruta method, to account for both linear and non-linear feature-to-class interactions. This resulted in the selection of genes with high discriminative power for the 21 molecular subtypes.\n\nThe performance of different machine learning algorithms was compared, with linear SVM emerging as the best-performing method on the training data, achieving an overall accuracy of 0.963. However, to handle cases that are unassigned or ambiguous, a probabilistic compound model was developed. This model incorporated single-sample gene set enrichment analyses (ssGSEA) using the same subtype-defining LASSO gene sets, which helped in removing batch effects between cohorts.\n\nThe evaluation also included the use of hold-out datasets to challenge the classifier with new, independent data structures, mimicking real-world applications. These hold-out datasets were selected to best represent all subtypes and age groups. Additionally, samples defined as 'unassigned' or B-other in the original studies were kept for evaluating the classifier's predictions on these cohorts.\n\nThe final predictions combined the strengths of both the linear SVM and the nearest-neighbor association models, providing dynamic ranges of subtype-specific scores. This integrated approach ensured that the classifier could accurately predict molecular BCP-ALL subtypes based on gene expression count data.",
  "evaluation/measure": "In the evaluation of our model, we focused on several key performance metrics to ensure a comprehensive assessment of its capabilities. Primarily, we reported accuracy, sensitivity, and specificity for subtype predictions. Accuracy measures the overall correctness of the predictions, providing a general sense of the model's performance. Sensitivity, also known as recall, indicates the proportion of actual positives that are correctly identified by the model. Specificity, on the other hand, measures the proportion of actual negatives that are correctly identified.\n\nFor our training data, the linear Support Vector Machine (SVM) achieved an overall accuracy of 0.963, which was superior to other methods tested, such as radial SVM and K-Nearest Neighbors (KNN). This high accuracy was maintained even when subtypes were weighted equally, demonstrating the model's robustness. The average sensitivity across subtypes was 0.950\u00b10.085, and the specificity was 0.998\u00b10.003, indicating a strong ability to correctly identify both positive and negative cases.\n\nIn addition to these metrics, we also validated our model on hold-out datasets, which included pediatric data from clinical trials and real-world diagnostic samples. The accuracy on these datasets was similarly high, with values of 0.978 and 0.965 for the St Jude and CLIP cohorts, respectively, and slightly lower at 0.914 for the MLL hold-out set. This variation in accuracy across different datasets highlights the model's performance in diverse settings.\n\nWe also reported the performance of our model in terms of root mean squared error (RSME) for blast count predictions, achieving good correlations with measured counts (rho = 0.590 in GMALL and rho = 0.771 in MLL). This metric is crucial for understanding the model's predictive power in clinical applications.\n\nFurthermore, we developed subclassifiers for immunophenotype and patient sex, using SVM linear and ranger machine learning models, respectively. The performance of these subclassifiers was also evaluated in terms of accuracy, sensitivity, and specificity, ensuring a holistic assessment of the model's capabilities.\n\nOverall, the set of metrics reported is representative of standard practices in the literature, providing a clear and comprehensive evaluation of the model's performance across various dimensions.",
  "evaluation/comparison": "In the evaluation of our classifier, ALLCatchR, we performed a comprehensive comparison with other machine learning algorithms and methods to assess its performance. Several algorithms, including svmLinear3, rf, ranger, svmRadial, and kknn, were tested on the training data consisting of 1869 samples. The linear Support Vector Machine (SVM) demonstrated superior performance with an overall accuracy of 0.963, outperforming other methods such as radial SVM (accuracy: 0.957) and K-Nearest Neighbors (KNN) (accuracy: 0.901). This evaluation was conducted to ensure that our chosen method was the most effective for subtype prediction.\n\nAdditionally, we applied feature selection methods like LASSO and Boruta to handle both linear and non-linear interactions between features and class labels. Different alpha parameters in LASSO resulted in varying numbers of selected genes, ranging from 2,802 to 973, depending on the stringency of the selection. The linear SVM showed stable performance regardless of the feature selection method used, indicating its robustness.\n\nTo address the limitations of linear SVM, such as its restriction to predefined classes and inability to compute probabilities for individual subtype predictions, we incorporated single-sample gene set enrichment analyses (ssGSEA). This approach allowed us to remove batch effects between cohorts and compute the Euclidean distance of each test sample to the training samples, considering the 10 nearest neighbors for subtype allocation. This integration resulted in a compound classifier that provides dynamic ranges of subtype-specific scores, enhancing its ability to handle unassigned or ambiguous cases.\n\nFurthermore, we validated our classifier on hold-out datasets to mimic real-world applications. These datasets were selected to represent all subtypes and age groups, ensuring a thorough evaluation of ALLCatchR's performance. The hold-out studies included samples that were originally defined as 'unassigned' or B-other, providing a challenging benchmark for our classifier.\n\nIn summary, our evaluation involved a rigorous comparison with other machine learning algorithms, feature selection methods, and hold-out datasets. This comprehensive approach ensured that ALLCatchR is a robust and reliable tool for BCP-ALL subtype prediction.",
  "evaluation/confidence": "The evaluation of ALLCatchR includes confidence intervals for its performance metrics, providing a measure of the uncertainty around the reported accuracies. For instance, the average sensitivity across subtypes was reported with a confidence interval of 0.919 \u00b1 0.145 in the training data and 0.911 \u00b1 0.167 in the hold-out data. This indicates the variability and reliability of the sensitivity measurements.\n\nConfidence categories were defined to assess the reliability of predictions. High-confidence predictions included over 90% of correct predictions, while candidate predictions excluded samples from other subtypes but allowed for 'unassigned'/B-other samples to be classified. Low-confidence predictions, representing overlaps between different subtypes, were considered unclassified.\n\nIn the training data, 84.6% of samples achieved high-confidence predictions with an accuracy of 0.997, and 13.7% achieved candidate predictions with an accuracy of 0.797. In the hold-out data, 83.7% of samples achieved high-confidence predictions with an accuracy of 0.989, and 15.1% achieved candidate predictions with an accuracy of 0.851. These results demonstrate the feasibility of highly accurate subtype allocations based on gene expression alone.\n\nThe statistical significance of ALLCatchR's performance was validated using independent hold-out cohorts, which were not previously seen by the classifier. The method achieved an overall accuracy of 0.957 in these hold-out cohorts, with high-confidence and candidate predictions being achieved in 83.7% and 15.1% of samples, respectively. This validation supports the claim that ALLCatchR provides reliable and accurate subtype predictions.\n\nAdditionally, the performance of ALLCatchR was compared to other methods such as ALLSorts, ALLIUM-GEX, and Allspice, further demonstrating its superiority. The method's ability to handle previously unassigned/B-other samples and provide subtype allocations supported by genomic drivers also highlights its robustness and reliability.",
  "evaluation/availability": "The raw evaluation files for our study are not publicly available. The evaluation process involved internal datasets that include sensitive patient information and proprietary data from various collaborating institutions. Therefore, to maintain patient confidentiality and comply with data protection regulations, these files are not released publicly.\n\nThe evaluation datasets were derived from RNA-Seq experiments comprising gene expression count data from a total of 3532 B-cell precursor acute lymphoblastic leukemia (BCP-ALL) patients across six different datasets. These datasets were used to train and validate our ALLCatchR classifier, which predicts molecular BCP-ALL subtypes with high accuracy.\n\nFor researchers interested in replicating or building upon our work, we provide detailed methodologies and performance metrics in our publication. This includes information on the machine learning algorithms used, feature selection methods, and the performance of our classifier on both training and hold-out datasets. While the raw evaluation files are not available, the comprehensive details provided in the publication should enable other researchers to understand and potentially apply similar approaches in their own studies."
}