{
  "publication/title": "Prediction of extubation failure among low birthweight neonates using machine learning.",
  "publication/authors": "Natarajan A, Lam G, Liu J, Beam AL, Beam KS, Levin JC",
  "publication/journal": "Journal of perinatology : official journal of the California Perinatal Association",
  "publication/year": "2023",
  "publication/pmid": "36611107",
  "publication/pmcid": "PMC10348822",
  "publication/doi": "10.1038/s41372-022-01591-3",
  "publication/tags": "- Extubation failure\n- Neonates\n- Low birthweight\n- Machine learning\n- Predictive modeling\n- Neonatal intensive care unit\n- Respiratory distress syndrome\n- Mechanical ventilation\n- Clinical data\n- Logistic regression\n- XGBoost\n- Vital signs\n- Ventilator parameters\n- Demographic data\n- Retrospective cohort study\n- Neonatal outcomes\n- Pediatrics\n- Medical informatics\n- Data science\n- Clinical prediction models",
  "dataset/provenance": "The dataset utilized in this study is sourced from the MIMIC-III (Medical Information Mart for Intensive Care III) clinical database. This database is a freely accessible critical care database that contains de-identified health-related data associated with over forty thousand patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012. The MIMIC-III database is widely used by the research community for various studies in critical care and has been a valuable resource for developing and validating prediction models.\n\nIn our study, we focused on a subset of this database. Specifically, we selected neonates with a birthweight of \u22642500 grams who were admitted to the neonatal intensive care unit within 24 hours of birth and required mechanical ventilation during the first 7 days after admission. This selection criterion resulted in a cohort of 1350 infants, which represents approximately 17% of the initial population of 7,870 neonates in the MIMIC-III database. The dataset includes a variety of features categorized into demographics, medications, and vital signs and respiratory support readings, which were used to predict extubation failure in these neonates.\n\nThe MIMIC-III database has been previously used in various studies, including those that predict extubation failure among preterm infants. For instance, a previous report using the MIMIC-II clinical database (an earlier version of MIMIC) employed logistic regression to predict extubation failure in preterm infants with respiratory distress syndrome. The features used in that study included FiO2, monocytes, total rapid shallow breathing index, heart rate, arterial pO2 / FIO2 ratio, and work of breathing. The area under the receiver operating characteristic curve (AUROC) reported in that study was 0.87124. Our study builds upon this work by using both standard logistic regression and machine learning techniques to enhance the prediction of extubation failure, incorporating a broader and more heterogeneous group of infants.",
  "dataset/splits": "In our study, we employed a 5-fold nested cross-validation procedure. This approach involved dividing the dataset into five distinct splits, or folds. Each fold served as a test set once, while the remaining four folds were used for training. This process was repeated five times, ensuring that each data point was used for both training and testing.\n\nThe dataset consisted of 1,350 infants who met the inclusion criteria. Given the 5-fold cross-validation, each fold contained approximately 270 data points for testing, while the training set for each iteration comprised around 1,080 data points. This method helped in evaluating the performance of our models more robustly by ensuring that each data point was used for validation and that the models were trained on a diverse set of data.\n\nAdditionally, within each training set, we performed another 4-fold cross-validation to tune the hyperparameters of our models. This nested cross-validation approach helped in preventing overfitting and provided a more reliable estimate of the models' performance. The distribution of data points in each split was designed to be as balanced as possible, ensuring that each fold was representative of the overall dataset.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data sets utilized in this study are publicly accessible. They can be found at the provided URL. The data is part of a widely used clinical database, which is freely available for research purposes. This ensures that other researchers can replicate and build upon our findings. The data is released under a license that permits its use for academic and research purposes, facilitating transparency and reproducibility in the scientific community. The availability of this data is enforced through the terms of use outlined by the database maintainers, ensuring that users adhere to ethical guidelines and data protection regulations. This open access approach promotes collaboration and advancement in the field of neonatal intensive care research.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is gradient boosted-trees, specifically XGBoost. This is an ensemble method that builds multiple decision trees in a sequential manner, with each new tree aiming to correct the errors of the previous ones. The objective is to minimize the binary cross-entropy loss function.\n\nThe XGBoost algorithm is not new; it has been previously developed and is widely used in various machine learning applications. It was chosen for this study due to its effectiveness in handling structured/tabular data and its ability to capture complex, non-linear relationships. The algorithm's performance and efficiency make it suitable for predictive modeling tasks in healthcare, including the prediction of extubation failure in low birthweight neonates.\n\nGiven that XGBoost is an established algorithm, it was not necessary to publish it in a machine-learning journal. Instead, our focus was on applying this well-known algorithm to a specific healthcare problem and demonstrating its utility in predicting extubation failure. The innovation lies in the application of XGBoost to this particular clinical scenario, rather than in the development of a new algorithm.",
  "optimization/meta": "The models evaluated in this study do not use data from other machine-learning algorithms as input. Instead, they directly utilize clinical data from the MIMIC-III database. The study focuses on two primary models: a logistic regression model with an l1 penalty (lasso) and a gradient boosted-tree model (XGBoost). These models are trained independently on the same dataset, but they do not serve as inputs to each other.\n\nThe logistic regression model is implemented using the glmnet Python package, with hyperparameters tuned via 4-fold cross-validation. The XGBoost model is an ensemble of decision trees, where each iteration adds a new tree to correct errors from the previous iteration, aiming to minimize the binary cross-entropy loss function. Hyperparameters for the XGBoost model, including the regularization parameter, learning rate, and depth of decision trees, are also tuned using cross-validation.\n\nThe study employs a 5-fold nested cross-validation procedure. For each prediction model, hyperparameters are tuned using another 4-fold cross-validation on the training data. This approach ensures that the training data for each fold is independent, maintaining the integrity of the cross-validation process. The mean area under the receiver operating characteristics curve (AUROC) is reported over five folds, along with standard errors, to assess the models' performance.\n\nIn summary, the models are standalone and do not rely on each other's outputs. The training data for each fold in the cross-validation is independent, ensuring robust and unbiased model evaluation.",
  "optimization/encoding": "For our study, we employed several data encoding and preprocessing techniques to ensure the machine-learning algorithms could effectively utilize the clinical data. We computed various statistical measures for each time series, including the mean, standard deviation, minimum value, maximum value, and the last valid entry. Additionally, we fitted a least squares polynomial with one degree of freedom to capture trends in these time series, calculating the slope and intercept on the mean-subtracted time series. This approach accounted for differences in units of vital signs and ventilator data, as well as variations between patients.\n\nTo handle missing data, we performed median imputation. Specifically, for each fold in the cross-validation process, we computed the median of all features in the training partition and then applied this median to impute missing values in both the training and test partitions. This method ensured that the models were robust to missing data, which is common in clinical datasets.\n\nWe evaluated two primary models: a logistic regression model with an l1 penalty (lasso) and a gradient boosted-tree model (XGBoost). For the logistic regression model, we treated the regularization parameter as a hyperparameter and tuned it using 4-fold cross-validation on the training dataset. The range for the regularization parameter was determined by the glmnet model based on the training data. For each fold in the cross-validation, we selected the regularization parameter that minimized the classification error within one standard deviation away from the lambda.\n\nFor the XGBoost model, we tuned three hyperparameters: the regularization parameter, learning rate, and depth of decision trees. We performed a 5-fold nested cross-validation procedure, where for each prediction model, we tuned the hyperparameters using another 4-fold cross-validation on the training data. The hyperparameter combination that maximized the area under the receiver operating characteristics curve (AUROC) was chosen for each fold.\n\nWe also compared the performance of the models using different groupings of features, including demographics, vital signs, ventilator settings, medications, and combinations thereof. This approach allowed us to assess the contribution of each feature group to the prediction of extubation failure. For the logistic regression model, we reported non-zero coefficients and their corresponding odds ratios. For the XGBoost model, we used Shapley additive explanations (SHAP) to capture the contributions of each covariate when making predictions for individual patients, which were then averaged over all patients to report the overall contribution to the prediction model. We utilized TreeSHAP, a fast and efficient method to compute SHAP values.",
  "optimization/parameters": "In our study, we evaluated two models to predict extubation failure in neonates. The first model was a logistic regression with an l1 penalty (lasso). For this model, the number of parameters (p) was determined by the regularization parameter, which was treated as a hyperparameter and tuned using 4-fold cross-validation. The range for this parameter was determined by the model itself based on the training dataset. The optimal regularization parameter was selected as the one with the minimum classification error within one standard deviation away from the lambda.\n\nThe second model was a gradient boosted-tree (XGBoost) model. For this model, three hyperparameters were tuned: the regularization parameter, the learning rate, and the depth of decision trees. The regularization parameter ranged from 1e-4 to 1, the learning rate ranged from 1e-3 to 0.3, and the depth of decision trees ranged from 1 to 5. These hyperparameters were tuned using 4-fold cross-validation, and the combination that gave the maximum area under the receiver operating characteristics curve (AUROC) was selected.\n\nIn summary, the number of parameters in our models was determined through a process of hyperparameter tuning using cross-validation. This approach allowed us to select the optimal parameters for each model based on their performance on the training data.",
  "optimization/features": "In our study, we utilized a comprehensive set of features to predict extubation failure in low birthweight neonates. The features were categorized into three main groups: demographics, medications, and vital signs and ventilator readings.\n\nThe demographic features included gestational age, sex, ethnicity, birth weight, extubation age, mode of delivery, multiplicity, and hours on ventilator. For medications, we considered ampicillin, gentamicin, vancomycin, and caffeine, which were used in more than 5% of subjects prior to the first extubation event. The vital signs and ventilator readings included heart rate, systolic blood pressure, diastolic blood pressure, respiratory rate, oxygen saturation, fraction of inspired oxygen, mean airway pressure, and positive end-expiratory pressure, all measured 12 hours prior to the first extubation event.\n\nTo handle the sparse and irregularly sampled time series data, we derived seven descriptive statistics for each vital sign and ventilator reading: mean, standard deviation, minimum value, maximum value, last valid entry, slope, and intercept. This approach allowed us to effectively summarize the time series data and capture trends over time.\n\nFeature selection was not explicitly performed as a separate step. Instead, we evaluated the performance of our models using different combinations of feature groups. These combinations included demographics alone, medications alone, vital signs and ventilator readings alone, demographics plus medications, and all features combined. By comparing the performance of these different feature sets, we were able to assess the importance of each group of features in predicting extubation failure.\n\nThe hyperparameter tuning process, which was done using cross-validation on the training set, inherently performed feature selection by identifying the most relevant features for each model. For the logistic regression model, we reported non-zero coefficients and their corresponding odds ratios, indicating the features that contributed significantly to the prediction. For the XGBoost model, we used SHAP values to determine the contribution of each feature to the final prediction. This approach ensured that feature selection was done using the training set only, maintaining the integrity of the validation process.",
  "optimization/fitting": "In our study, we employed two distinct models to predict extubation failure in neonates: a logistic regression model with an l1 penalty (lasso) and a gradient boosted-tree (XGBoost) model. Both models were subjected to rigorous optimization procedures to ensure robust performance.\n\nFor the logistic regression model, we treated the regularization parameter as a hyperparameter and tuned it using 4-fold cross-validation on the training dataset. The range for this parameter was determined by the model itself, given the training data. To mitigate overfitting, we selected the regularization parameter that yielded the minimum classification error within one standard deviation away from the optimal lambda. This approach helped in balancing the model complexity and preventing it from fitting the noise in the data.\n\nThe XGBoost model, being an ensemble of decision trees, inherently reduces the risk of overfitting through its iterative process of adding trees to correct errors from previous iterations. We tuned three hyperparameters: the regularization parameter, learning rate, and depth of decision trees. These were optimized using 4-fold cross-validation, with the objective of maximizing the area under the receiver operating characteristics curve (AUROC). The use of cross-validation ensured that the model generalized well to unseen data, thus ruling out overfitting.\n\nTo address underfitting, we performed a 5-fold nested cross-validation procedure. This involved tuning the hyperparameters using another 4-fold cross-validation on the training data within each of the five outer folds. This nested approach ensured that the model was neither too simple to capture the underlying patterns nor too complex to overfit the training data.\n\nAdditionally, we handled missing data through median imputation, which is a robust method for dealing with missing values without introducing bias. This step further ensured that the models were not underfitting due to incomplete data.\n\nIn summary, our optimization strategies, including cross-validation, regularization, and hyperparameter tuning, effectively ruled out both overfitting and underfitting, ensuring that our models were well-calibrated and generalizable to new data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. For the logistic regression model, we used l1 regularization, also known as Lasso, which helps in feature selection by driving some coefficients to zero. This not only simplifies the model but also reduces the risk of overfitting by penalizing the absolute size of the regression coefficients.\n\nFor the gradient boosted-tree (XGBoost) model, we implemented regularization by tuning the regularization parameter. This parameter controls the complexity of the model by penalizing the sum of the squared weights, thereby preventing the model from becoming too complex and overfitting the training data.\n\nAdditionally, we performed hyperparameter tuning using a 4-fold cross-validation procedure. This involved selecting the optimal hyperparameters that minimized classification error for the logistic regression model and maximized the area under the receiver operating characteristics curve (AUROC) for the XGBoost model. By doing so, we ensured that our models generalized well to unseen data.\n\nFurthermore, we handled missing data through median imputation, which is a robust method that helps in maintaining the integrity of the dataset and prevents the introduction of bias that could lead to overfitting. This approach was applied consistently across all folds of the cross-validation process.\n\nOverall, these techniques collectively helped in building models that were not only accurate but also generalizable to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules used in our study are detailed within the publication. Specifically, for the logistic regression model, we employed an l1 penalty (lasso) and tuned the regularization parameter using 4-fold cross-validation on the training dataset. The range for this parameter was determined by the glmnet model based on the training data. For each fold, the regularization parameter with the minimum classification error within one standard deviation from the lambda was selected.\n\nFor the gradient boosted-tree (XGBoost) model, we tuned three hyperparameters: the regularization parameter, learning rate, and depth of decision trees. These were optimized within specified ranges using 4-fold cross-validation, with the objective of maximizing the area under the receiver operating characteristics curve (AUROC). The specific ranges and selection criteria for these hyperparameters are outlined in the methods section.\n\nModel files and optimization parameters are not explicitly provided in the publication. However, the logistic regression equation is available in the online-only supplement, along with details on how to use the XGBoost model. This supplementary material can be accessed through the journal's website, ensuring that readers have the necessary information to replicate or build upon our findings.\n\nThe data used in this study is from the MIMIC-III clinical database, which is freely accessible. The methods and configurations described are intended to be reproducible, and the supplementary material provides additional context for implementing the models. While the exact model files are not shared, the detailed descriptions and supplementary information should enable researchers to recreate the models and optimization processes described in the study.",
  "model/interpretability": "In our study, we employed two distinct models to predict extubation failure in low birthweight neonates: a logistic regression model with an l1 penalty (lasso) and a gradient boosted-tree model (XGBoost). The interpretability of these models varies significantly.\n\nThe logistic regression model is relatively transparent. It provides clear insights into the relationship between the features and the outcome through its coefficients. For instance, the magnitude of these coefficients indicates the strength and direction of the association between each feature and the likelihood of extubation failure. In our analysis, features like birthweight and gestational age were identified as highly important, with specific odds ratios indicating their impact on the prediction. This transparency allows for straightforward interpretation and communication of the model's decisions.\n\nOn the other hand, the XGBoost model is more of a blackbox model. It is an ensemble of decision trees, which makes it powerful but less interpretable. To address this, we used Shapley Additive Explanations (SHAP) values, specifically TreeSHAP, to quantify the contribution of each feature to the model's predictions. SHAP values provide a way to understand the impact of individual features on the model's output for each patient, which can then be averaged to show overall feature importance. For example, in our XGBoost model, the last FiO2 entry prior to extubation, mean MAP, and gestational age were among the top features contributing to the prediction of extubation failure. This approach helps in making the model's decisions more interpretable without sacrificing its predictive power.",
  "model/output": "The models developed in this study are classification models. Specifically, they are designed to predict extubation failure, which is a binary outcome. The models classify each neonate as either likely to fail extubation or not, based on various clinical features.\n\nTwo types of models were employed: logistic regression with an l1 penalty (lasso) and a gradient boosted-tree model (XGBoost). Both models were trained to predict the probability of extubation failure, defined as reintubation within 7 days. The performance of these models was evaluated using the area under the receiver operating characteristic curve (AUROC), which is a common metric for assessing the performance of binary classification models.\n\nThe logistic regression model used a regularization parameter that was tuned via 4-fold cross-validation to minimize classification error. The XGBoost model, an ensemble of decision trees, was tuned using three hyperparameters: the regularization parameter, learning rate, and depth of decision trees. The objective was to minimize the binary cross-entropy loss function.\n\nThe models were evaluated using different groupings of features, including demographics alone, vital signs and ventilator settings, and all features combined. The best performance was observed when all features were included, with the XGBoost model achieving an AUROC of 0.82. This indicates that the model is highly effective in distinguishing between neonates who will fail extubation and those who will not.\n\nIn addition to the AUROC, the models' performance was also assessed using calibration plots and the Brier score. The calibration plots showed that adding vital signs and ventilator readings to demographics improved the models' calibration. The Brier score, which measures the accuracy of probabilistic predictions, was lowest when all features were used, further confirming the models' effectiveness.\n\nThe most important features identified by the models included birthweight, gestational age, caffeine use, and various vital signs and ventilator parameters. These features were found to have the greatest impact on the models' predictions of extubation failure.\n\nOverall, the models demonstrated strong classification performance, with the XGBoost model outperforming the logistic regression model when all features were included. This suggests that machine learning techniques can be effectively used to predict extubation failure in low birthweight neonates, providing valuable insights for clinical decision-making.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "We evaluated two models to predict extubation failure using a 5-fold nested cross-validation procedure. For each prediction model, we tuned the hyperparameters using another 4-fold cross-validation on the training data. This approach helps to ensure that the model's performance is robust and generalizable.\n\nFor the logistic regression model, we used an l1 penalty (lasso) and treated the regularization parameter as a hyperparameter. We tuned it on the training dataset via 4-fold cross-validation, selecting the regularization parameter with the minimum classification error within one standard deviation away from the lambda.\n\nThe second model was a gradient boosted-tree (XGBoost) model, which is an ensemble of decision trees. We tuned three hyperparameters for the XGBoost model: the regularization parameter, learning rate, and depth of decision trees. For each fold in the cross-validation, we chose the hyperparameter combination that gave us the maximum area under the receiver operating characteristics curve (AUROC).\n\nWe reported the mean AUROC over five folds along with standard errors. To handle missing data, we performed median imputation. Specifically, in each fold of the cross-validation, we computed the median of all features in the training partition and performed median imputation on both the training and test partitions.\n\nWe compared the performance of the models using different groupings of features, including demographics, vital signs, ventilator settings, medications, and combinations of these groupings. We also reported important features for each prediction model and their contributions to the final prediction towards extubation failure. For the logistic regression model, we reported non-zero coefficients and their corresponding odds ratios. For the XGBoost model, we reported the Shapley additive explanations (SHAP) values, which capture the contributions of each covariate when making a prediction for an individual patient. These values are then averaged over all patients and reported as overall contributions to the prediction model.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our prediction models for extubation failure in neonates. The primary metric reported is the Area Under the Receiver Operating Characteristic Curve (AUROC), which provides a comprehensive measure of the model's ability to discriminate between successful and failed extubations. We calculated the mean AUROC over fivefold cross-validation, along with standard error bars, to ensure robustness and reliability of our results.\n\nAdditionally, we used the Brier score to assess the calibration of our models. The Brier score measures the accuracy of probabilistic predictions, with a perfectly calibrated model achieving a score of 0.0 and a perfectly uncalibrated model achieving a score of 1.0. This metric helps us understand how well the predicted probabilities align with the actual outcomes.\n\nWe also examined the actual versus predicted outcomes from our best-performing model, the XGBoost model using all variables. This analysis provided us with the number of true positives, false positives, true negatives, and false negatives, allowing us to calculate the false positive rate and false negative rate. These metrics are crucial for understanding the practical implications of our model's predictions in a clinical setting.\n\nFurthermore, we constructed calibration plots to visually assess the degree to which the probabilistic predictions of extubation failure reflect the true underlying probability. These plots complement the Brier score by providing a graphical representation of model calibration.\n\nThe set of metrics we reported is representative of the literature in the field of predictive modeling for clinical outcomes. AUROC is a widely used metric for evaluating the discriminative power of models, while the Brier score and calibration plots are standard for assessing model calibration. By including these metrics, we ensure that our evaluation is comprehensive and comparable to other studies in the domain.",
  "evaluation/comparison": "In our study, we evaluated two distinct models to predict extubation failure in neonates: a logistic regression model with an l1 penalty (lasso) and a gradient boosted-tree model (XGBoost). The logistic regression model was implemented using the glmnet Python package, with hyperparameter tuning performed via 4-fold cross-validation on the training dataset. The range for the regularization parameter was determined by the glmnet model based on the training data.\n\nThe XGBoost model, an ensemble of decision trees, was tuned using three hyperparameters: the regularization parameter, learning rate, and depth of decision trees. These hyperparameters were optimized through a 5-fold nested cross-validation procedure, with the objective of maximizing the area under the receiver operating characteristics curve (AUROC).\n\nTo handle missing data, we employed median imputation. For each fold in the cross-validation, the median of all features in the training partition was computed and used to impute missing values in both the training and test partitions. This approach ensured that the models were robust to missing data, which is a common issue in clinical datasets.\n\nWe compared the performance of these models using different groupings of features, including demographics, medications, vital signs, and ventilator readings. The models were evaluated based on their mean AUROC over five folds, along with standard errors. Calibration plots and Brier scores were used to assess the calibration of the prediction models.\n\nIn addition to comparing the models to each other, we also referenced a previous study that used logistic regression to predict extubation failure among preterm infants. That study reported an AUROC of 0.87, which was slightly higher than the AUROCs reported in our study. This difference may be attributed to the broader and more heterogeneous group of infants included in our study, as well as practice changes that have occurred in the NICU over time.\n\nOverall, our study demonstrates that machine learning models, particularly XGBoost, can effectively predict extubation failure in neonates by leveraging large amounts of clinical data. The comparison to simpler baselines and publicly available methods highlights the strengths and limitations of these approaches in a clinical setting.",
  "evaluation/confidence": "The evaluation of our models included a rigorous assessment of performance metrics with confidence intervals. Specifically, we reported the mean area under the receiver operating characteristic curve (AUROC) along with standard error bars, calculated over fivefold cross-validation. This approach provides a measure of the variability and reliability of our model's performance.\n\nStatistical significance was considered in our hyperparameter tuning process. For the logistic regression model, we treated the regularization parameter as a hyperparameter and tuned it on the training dataset via 4-fold cross-validation. We selected the regularization parameter with the minimum classification error within one standard deviation away from the lambda, ensuring that our model's performance was statistically significant.\n\nFor the XGBoost model, we tuned three hyperparameters: the regularization parameter, learning rate, and depth of decision trees. We chose the hyperparameter combination that gave us the maximum AUROC for each fold in the cross-validation, again ensuring statistical significance.\n\nAdditionally, we performed a sensitivity analysis on a subset of very low birthweight (VLBW) infants, which showed similar but slightly lower performance. This analysis further supports the robustness and generalizability of our models.\n\nOverall, the inclusion of confidence intervals and the rigorous tuning of hyperparameters provide a strong basis for claiming that our methods are superior to baselines and other models.",
  "evaluation/availability": "The raw evaluation files used in our study are not directly available. However, the dataset we utilized, MIMIC-III, is publicly accessible. This dataset can be found at https://physionet.org/content/mimiciii/1.4/. The models described in our study are available upon request to the corresponding author. This approach ensures that researchers interested in replicating or building upon our work can access the necessary tools and data, promoting transparency and further advancements in the field."
}