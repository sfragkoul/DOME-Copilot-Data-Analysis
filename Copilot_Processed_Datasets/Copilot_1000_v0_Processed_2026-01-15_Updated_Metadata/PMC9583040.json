{
  "publication/title": "Machine learning models for predicting survival in patients with ampullary adenocarcinoma.",
  "publication/authors": "Huang T, Huang L, Yang R, Li S, He N, Feng A, Li L, Lyu J",
  "publication/journal": "Asia-Pacific journal of oncology nursing",
  "publication/year": "2022",
  "publication/pmid": "36276885",
  "publication/pmcid": "PMC9583040",
  "publication/doi": "10.1016/j.apjon.2022.100141",
  "publication/tags": "- Ampullary adenocarcinoma\n- Survival analysis\n- Machine learning\n- Risk factor\n- SEER\n- DeepSurv\n- Cox Proportional Hazards regression\n- XGBoost Survival Embeddings\n- Random Survival Forest\n- Predictive modeling",
  "dataset/provenance": "The dataset used in this study was sourced from the Surveillance, Epidemiology, and End Results (SEER) database, specifically the SEER 17 database. This database collects and publishes cancer incidence and survival data from population-based cancer registries that cover approximately 26.5% of the US population. The data spans from 2004 to 2015 and was accessed using the SEER*Stat software (version 8.4.0.1). The dataset includes information on 2,935 patients diagnosed with ampullary adenocarcinoma (AAC). This dataset has been used in previous research to investigate various aspects of cancer prognosis and treatment.\n\nThe dataset contains a wide range of variables, including age, sex, race, marital status at diagnosis, scope of regional lymph node surgery, tumor grade, summary stage, AJCC TNM stage, surgery status, radiotherapy, chemotherapy, tumor extent, regional lymph node involvement and metastasis, primary indicator of first malignancy, vital status, and survival time. These variables were collected after obtaining permission to access the SEER 17 database through a multiple-step request process. The patients were randomly divided into training and testing cohorts with a ratio of 7:3.",
  "dataset/splits": "The dataset was divided into two main splits: a training cohort and a testing cohort. The training cohort consisted of 2,054 patients, which accounted for 70% of the total dataset. The testing cohort comprised 881 patients, making up the remaining 30%. The distribution of data points in each split was designed to ensure a representative sample for both training and testing purposes. The log-rank test was used to assess the difference between the two cohorts, yielding a P-value of 0.736, indicating that the survival curves did not differ significantly between the training and testing cohorts. This split was chosen to validate the models' performance and ensure that the results were generalizable to new, unseen data.",
  "dataset/redundancy": "The dataset used in this study was collected from the Surveillance, Epidemiology, and End Results (SEER) database, specifically the SEER 17 database, which covers approximately 26.5% of the US population. The data spans from 2004 to 2015 and includes information on patients diagnosed with ampullary adenocarcinoma (AAC).\n\nThe dataset was split into training and testing cohorts with a ratio of 7:3. This means that 70% of the data was used for training the models, while the remaining 30% was used for testing. The split was done randomly, ensuring that the training and testing sets were independent. The independence of the sets was enforced by ensuring that there was no overlap between the patients included in the training and testing cohorts.\n\nThe distribution of the data in the training and testing cohorts was compared using the log-rank test. The results showed that there was no significant difference between the two cohorts (P = 0.736), indicating that the split was done in a way that maintained the overall distribution of the data.\n\nCompared to previously published machine learning datasets, the dataset used in this study is relatively large, with a total of 2,935 patients. This large sample size allows for more robust and reliable model training and testing. Additionally, the dataset includes a wide range of variables, such as age, sex, race, marital status, tumor grade, and treatment information, which provides a comprehensive view of the patient population and allows for more accurate survival predictions.",
  "dataset/availability": "The data used in this study were obtained from the Surveillance, Epidemiology, and End Results (SEER) database, specifically the SEER 17 database. This database is a publicly available resource developed by the National Cancer Institute of the United States. It provides research data for free to approved researchers. The SEER database collects and publishes cancer incidence and survival data from population-based cancer registries that cover approximately 26.5% of the US population.\n\nThe data from 2004 to 2015 were collected using the SEER*Stat software (version 8.4.0.1). The study included information on patients diagnosed with ampullary adenocarcinoma (AAC) after receiving permission to access the SEER 17 database through a multiple-step request process. The dataset comprises 2,935 patients with AAC, including various clinical and demographic variables such as age, sex, race, marital status at diagnosis, scope of regional lymph node surgery, tumor grade, summary stage, AJCC TNM stage, surgery status, radiotherapy, chemotherapy, tumor extent, regional lymph node involvement and metastasis, primary indicator of first malignancy, vital status, and survival time.\n\nThe data were randomly divided into training and testing cohorts with a ratio of 7:3. The training cohort consisted of 2,054 patients, and the testing cohort consisted of 881 patients. The log-rank test was used to assess the difference between the two cohorts, yielding a P-value of 0.736, indicating no significant difference in survival curves between the two cohorts.\n\nThe SEER database follows the National Cancer Institute's data use statement and guidelines, ensuring that all data usage complies with ethical standards. The informed consent was obtained from all patients or, if patients are under 18, from a parent and/or legal guardian. The research content adheres to the National Cancer Institute's guidelines, ensuring the ethical and responsible use of the data.",
  "optimization/algorithm": "The optimization algorithm used in this study is the Bayesian optimizer. This is not a new machine-learning algorithm. It is a well-established technique used for hyperparameter tuning and optimization in various machine learning models. The Bayesian optimizer was chosen for its efficiency in searching the hyperparameter space and finding the optimal settings for the models used in this study.\n\nThe models that were optimized using the Bayesian optimizer include both decision-tree-based ensemble machine learning models and deep learning models. The decision-tree-based models are XGBoost Survival Embeddings (XGBSE) and Random Survival Forest (RSF). The deep learning models are CoxTime and DeepSurv. These models were implemented using specific packages in Python, such as XGBSE (version 0.2.3) and random survival forest (version 0.8.0) for the decision-tree-based models, and pycox (version 0.2.3) for the deep learning models.\n\nThe Bayesian optimizer was selected because it is effective in handling the complex and high-dimensional hyperparameter spaces that are common in machine learning models, particularly in deep learning. It uses a probabilistic model to balance exploration and exploitation, which helps in finding the optimal hyperparameters efficiently. This is crucial for improving the performance of the models in predicting the survival outcomes of patients with ampullary adenocarcinoma.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data used in this study was collected from the Surveillance, Epidemiology, and End Results (SEER) database, specifically from the SEER 17 database, which covers approximately 26.5% of the US population. The data spanned from 2004 to 2015 and included information on patients diagnosed with ampullary adenocarcinoma (AAC).\n\nThe dataset comprised various patient indicators such as age, sex, race, marital status at diagnosis, scope of regional lymph node surgery, tumor grade, summary stage, AJCC TNM stage, surgery status, radiotherapy, chemotherapy, tumor extent, regional lymph node involvement and metastasis, primary indicator of first malignancy, vital status, and survival time.\n\nFor the machine learning models, the data was randomly divided into training and testing cohorts with a ratio of 7:3. This division ensured that the models were trained on a substantial amount of data while leaving a sufficient portion for testing and validation.\n\nThe data was pre-processed to handle missing values and to encode categorical variables appropriately. Categorical variables, such as race, marital status, and tumor grade, were likely encoded using techniques like one-hot encoding or label encoding to convert them into a format suitable for machine learning algorithms.\n\nNumerical variables, such as age and survival time, were likely normalized or standardized to ensure that they were on a similar scale, which is crucial for the performance of many machine learning models.\n\nThe pre-processed data was then used to train and evaluate several survival analysis models, including the Cox proportional hazards (CoxPH) model, XGBoost Survival Embeddings (XGBSE), random survival forest (RSF), CoxTime, and DeepSurv. The Bayesian optimizer was employed to optimize the model parameters, ensuring that the models achieved the best possible performance.",
  "optimization/parameters": "In our study, we utilized several survival analysis models, each with its own set of parameters. The traditional Cox proportional hazards (CoxPH) model, for instance, involves parameters related to the covariates included in the analysis. We initially performed univariate analyses to screen out meaningful indicators (P < 0.05) and then used multivariate analysis to determine the survival predictive ability of the Cox model.\n\nFor the machine learning models, such as XGBoost Survival Embeddings (XGBSE) and random survival forest (RSF), the number of parameters can vary based on the specific configurations and optimizations applied. Similarly, the deep learning models, CoxTime and DeepSurv, have their own sets of parameters that were optimized using the Bayesian optimizer.\n\nThe selection of parameters was guided by the Bayesian optimizer, which is a tool used to optimize the model parameters. This process involved simulating the models using Python (version 3.9) and adjusting the parameters to achieve the best possible performance. The specific packages used for XGBSE and RSF were version 0.2.3 and version 0.8.0, respectively, while both CoxTime and DeepSurv were implemented using pycox (version 0.2.3). The optimization aimed to enhance the predictive accuracy and reliability of the models, ensuring that they could effectively handle the complexities of the data.",
  "optimization/features": "The study utilized a total of 13 features as input for the survival analysis models. These features included race, marital status at diagnosis, scope of regional lymph node surgery, tumor grade, summary stage, AJCC stage, TNM stage T, and TNM stage N, among others.\n\nFeature selection was performed using univariate Cox proportional hazards (CoxPH) regression analysis on the training cohort. This process identified meaningful indicators with a significance level of P < 0.05. Subsequently, multivariate analysis was conducted to determine the survival predictive ability of the Cox model. This approach ensured that the feature selection was done using the training set only, maintaining the integrity of the testing cohort for unbiased evaluation.",
  "optimization/fitting": "The study employed several survival analysis models, including traditional statistical methods and advanced machine learning techniques. The traditional Cox Proportional Hazards (CoxPH) regression model was used initially to identify meaningful indicators affecting patient outcomes. This model, however, has constraints that can limit its predictive ability.\n\nTo address these limitations, more sophisticated models were utilized. These included decision-tree-based ensemble machine learning models such as XGBoost Survival Embeddings (XGBSE) and Random Survival Forest (RSF), as well as deep learning models like CoxTime and DeepSurv. These models were chosen for their ability to handle complex, high-dimensional data and to capture non-linear relationships, which are often present in medical datasets.\n\nThe deep learning models, in particular, have a large number of parameters relative to the number of training points. To mitigate the risk of overfitting, a Bayesian optimizer was used to optimize the model parameters. This optimization process helps in finding the best hyperparameters that improve the model's performance and generalization to unseen data.\n\nAdditionally, the models were evaluated using multiple metrics, including the C-index, receiver operating characteristic (ROC) curves, and calibration plots. These evaluations ensured that the models were not only fitting the training data well but also generalizing to the testing data, thus ruling out both overfitting and underfitting. The DeepSurv model, for instance, showed the highest C-index and performed well across different time points, indicating its robustness and reliability in predicting survival outcomes.\n\nIn summary, the study carefully managed the balance between model complexity and generalization by using advanced optimization techniques and thorough evaluation metrics. This approach helped in ensuring that the models were neither overfitting nor underfitting the data, providing reliable predictions for the survival outcomes of patients with ampullary adenocarcinoma.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was the Bayesian optimizer, which helped in fine-tuning the model parameters. This optimization process is crucial for preventing overfitting by ensuring that the models do not become too complex and start to fit the noise in the training data.\n\nAdditionally, we utilized decision-tree-based ensemble machine learning models, such as XGBoost Survival Embeddings (XGBSE) and random survival forest (RSF). These models inherently include mechanisms to prevent overfitting. For instance, XGBSE incorporates regularization parameters that penalize complex models, thereby reducing the risk of overfitting. Similarly, RSF uses techniques like bootstrapping and averaging multiple trees to improve generalization and reduce overfitting.\n\nFor the deep learning models, CoxTime and DeepSurv, we leveraged the powerful non-linear fitting ability of neural networks. These models were trained with careful consideration of the data size and complexity, ensuring that they did not overfit to the training data. The use of a large dataset from the SEER database also helped in mitigating overfitting, as more data generally leads to better model performance and generalization.\n\nOverall, our approach combined traditional statistical methods with advanced machine learning techniques to ensure that our models were robust and generalizable, thereby minimizing the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in this study are available. The models were simulated using Python (version 3.9) software, and the Bayesian optimizer (version 1.2.0) was used to optimize the model parameters. Specifically, the XGBSE (version 0.2.3) and random survival forest (version 0.8.0) packages were used for the XGBSE and RSF models, respectively. Both CoxTime and DeepSurv were implemented using pycox (version 0.2.3). The study was published under the CC BY-NC-ND license, which allows for the sharing and redistribution of the article, including the supplementary data, under certain conditions. The supplementary data, which may include detailed configurations and parameters, can be found online at the provided DOI link. This ensures that the configurations and optimization details are accessible to researchers for further validation and application.",
  "model/interpretability": "The models used in this study vary in their interpretability. The Cox proportional hazards (CoxPH) model is relatively transparent, as it provides hazard ratios for each covariate, indicating the relative risk of death associated with each factor. This allows for a clear understanding of how each variable influences patient survival.\n\nIn contrast, the decision-tree-based ensemble models, such as XGBoost Survival Embeddings (XGBSE) and random survival forest (RSF), are less interpretable. These models are considered black-box models, meaning their internal workings are not easily understood. They can capture complex interactions between variables but do not provide straightforward interpretations of how individual factors contribute to the predictions.\n\nThe deep learning models, CoxTime and DeepSurv, are also black-box models. These models use multilayer neural networks to make predictions, which makes it difficult to interpret the internal computations. While they offer powerful predictive capabilities due to their ability to handle non-linear relationships, the lack of interpretability is a significant drawback. Future research should focus on developing methods to make these models more interpretable, ensuring that clinicians can understand and trust the predictions made by these advanced models.",
  "model/output": "The model is a regression model, specifically designed for survival analysis. It predicts the survival outcomes and times of patients with ampullary adenocarcinoma (AAC). The study employed several survival analysis models, including the Cox proportional hazards (CoxPH) model, decision-tree-based ensemble machine learning models like XGBoost Survival Embeddings (XGBSE) and random survival forest (RSF), and deep learning models such as CoxTime and DeepSurv. These models were used to determine the risk factors affecting patient prognosis and to predict survival times.\n\nThe performance of these models was evaluated using Harrell's C-index, which measures the concordance between predicted and observed survival times. Additionally, the area under the receiver operating characteristic (ROC) curve (AUC) was calculated at different time points (1-year, 3-year, 5-year, and 10-year) to assess the models' recognition ability. The DeepSurv model, in particular, demonstrated the highest predictive accuracy and was found to be the most accurate in predicting the prognoses and survival times of patients with AAC.\n\nThe study also highlighted the limitations of the models, such as the difficulty in interpreting deep learning survival analysis models due to their complex internal computing processes. Future research should aim to address these issues to enhance the interpretability and robustness of the models. Overall, the models provided valuable insights into the survival outcomes of patients with AAC, aiding in specific treatment decisions and personalized nursing planning.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the models used in this study is not publicly released. However, the models were implemented using specific packages and software versions that are publicly available. The decision-tree-based ensemble machine learning models, XGBSE and RSF, were implemented using the XGBSE (version 0.2.3) and random survival forest (version 0.8.0) packages, respectively. The deep learning models, CoxTime and DeepSurv, were implemented using pycox (version 0.2.3). All models were simulated using Python (version 3.9) software, and the Bayesian optimizer (version 1.2.0) was used to optimize the model parameters. The specific details and parameters used in the models are described in the methods section of the study.",
  "evaluation/method": "The evaluation of the survival analysis models in this study involved a comprehensive approach to ensure the robustness and accuracy of the predictions. The dataset was divided into training and testing cohorts with a 7:3 ratio, ensuring that the testing cohort was completely isolated from the training process. This division allowed for an unbiased evaluation of the models' performance.\n\nSeveral metrics were used to evaluate the models. Harrell's C-index was employed to measure the relationship between the model-predicted risk profiles and actual patient survival, reflecting the predictive power of the models. Additionally, the area under the receiver operating characteristic (ROC) curve (AUC) was calculated for 1-year, 3-year, 5-year, and 10-year survival predictions to assess the models' recognition ability at different time points.\n\nThe models compared included the AJCC TNM stage model, the Cox proportional hazards (CoxPH) model, decision-tree-based ensemble machine learning models (XGBSE and RSF), and deep learning models based on neural network structures (CoxTime and DeepSurv). The performance of these models was evaluated using the testing cohort, and the results were compared to determine the most accurate model for predicting the prognoses and survival times of patients with ampullary adenocarcinoma (AAC).\n\nThe evaluation process also involved optimizing the model parameters using the Bayesian optimizer to ensure that each model was tuned to its best state. This rigorous evaluation method provided a clear comparison of the models' predictive abilities, highlighting the strengths and weaknesses of each approach.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our survival analysis models. The primary metrics used were Harrell's C-index and the area under the receiver operating characteristic curve (AUC).\n\nHarrell's C-index was utilized to measure the concordance between the model-predicted risk profiles and the actual patient survival outcomes. This metric reflects the predictive power of the models, with higher values indicating better performance. We calculated the C-index for each of the six models we constructed, providing a clear comparison of their predictive abilities.\n\nAdditionally, we computed the AUC for the 1-year, 3-year, 5-year, and 10-year ROC curves of all models. The ROC curves represent the overall performance of the models at different time points, offering a comprehensive view of their recognition ability. The AUC values at these specific time intervals allowed us to assess how well each model discriminates between patients who will survive and those who will not, over various time horizons.\n\nThese metrics are widely recognized in the literature for evaluating survival models, ensuring that our evaluation is both rigorous and comparable to other studies in the field. By using Harrell's C-index and AUC, we were able to provide a thorough assessment of the models' predictive accuracy and reliability.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of various survival analysis models to predict the outcomes of patients with ampullary adenocarcinoma (AAC). We evaluated six different models, including both traditional and advanced machine learning techniques.\n\nThe AJCC TNM staging system served as our baseline model. This conventional diagnostic model provided a foundational comparison point for assessing the performance of more sophisticated methods.\n\nWe also employed the traditional Cox proportional hazards (CoxPH) regression model. This model was used to perform univariate and multivariate analyses of patient indicators, helping us identify meaningful factors that influence survival outcomes.\n\nIn addition to these traditional methods, we explored two decision-tree-based ensemble machine learning models: XGBoost Survival Embeddings (XGBSE) and random survival forest (RSF). These models are known for their ability to handle complex data structures and provide robust predictions.\n\nFurthermore, we implemented two deep learning models based on neural network structures: CoxTime and DeepSurv. These models leverage the powerful non-linear fitting capabilities of multilayer neural networks to achieve high predictive accuracy.\n\nTo ensure a fair and rigorous comparison, we divided our dataset into training and testing cohorts with a 7:3 ratio. The models were trained on the training cohort and their performance was evaluated on the completely isolated testing cohort. This approach helped us assess the generalizability and robustness of each model.\n\nWe used Harrell's C-index to measure the predictive power of the models, which reflects the relationship between predicted risk profiles and actual patient survival. Additionally, we calculated the 1-year, 3-year, 5-year, and 10-year ROC curves for all models to verify their recognition abilities at different time points.\n\nThe results showed that the deep learning models, particularly DeepSurv, achieved the highest predictive accuracy, outperforming both the traditional CoxPH model and the decision-tree-based ensemble models. This comparison highlights the potential of advanced machine learning techniques in improving survival predictions for AAC patients.",
  "evaluation/confidence": "The evaluation of the models in this study was conducted using several performance metrics, including Harrell's C-index and the area under the receiver operating characteristic (ROC) curve (AUC). These metrics were used to assess the predictive abilities of the models.\n\nHarrell's C-index was employed to measure the relationship between the model-predicted risk profiles and actual patient survival, reflecting the predictive power of the models. The C-index values for the models were reported, with the AJCC TNM stage model having the lowest C-index of 0.606, indicating the worst performance. The CoxPH model had a C-index of 0.693, while the decision-tree-based ensemble machine learning models, XGBSE and RSF, had C-indexes of 0.709 and 0.716, respectively. The deep learning models, CoxTime and DeepSurv, achieved higher C-indexes of 0.714 and 0.731, respectively, indicating better predictive performance.\n\nThe ROC curves at different time points (1-year, 3-years, 5-years, and 10-years) were calculated to verify the recognition ability of the models. The AUC values for the AJCC TNM stage model were the lowest across all time points, with values of 0.622, 0.664, 0.674, and 0.655 at 1 year, 3 years, 5 years, and 10 years, respectively. In contrast, the DeepSurv model demonstrated superior performance with higher AUC values, indicating better predictive accuracy.\n\nStatistical significance was assessed using the log-rank test, which showed no significant difference between the survival curves of the training and testing cohorts (P = 0.764). This suggests that the models were robust and generalizable to new data.\n\nOverall, the performance metrics and statistical tests provide confidence in the superiority of the DeepSurv model over the other models and baselines evaluated in this study. The reported C-indexes and AUC values, along with the statistical significance of the results, support the claim that DeepSurv is the most accurate model for predicting the prognoses and survival times of patients with AAC.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study utilized data from the Surveillance, Epidemiology, and End Results (SEER) database, which is accessible through a multiple-step request process. The SEER database provides cancer incidence and survival data from population-based cancer registries, covering approximately 26.5% of the US population. Access to this database requires permission and follows specific guidelines set by the National Cancer Institute. The data used in this study was collected from 2004 to 2015 and was submitted in November 2021 and published in April 2022. The study adheres to the data use statement of the National Cancer Institute, ensuring ethical approval and informed consent from all patients or their legal guardians."
}