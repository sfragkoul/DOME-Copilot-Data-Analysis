{
  "publication/title": "Automated segmentation and source prediction of bone tumors using ConvNeXtv2 Fusion based Mask R-CNN to identify lung cancer metastasis.",
  "publication/authors": "Zhao K, Dai P, Xiao P, Pan Y, Liao L, Liu J, Yang X, Li Z, Ma Y, Liu J, Zhang Z, Li S, Zhang H, Chen S, Cai F, Tan Z",
  "publication/journal": "Journal of bone oncology",
  "publication/year": "2024",
  "publication/pmid": "39430914",
  "publication/pmcid": "PMC11488409",
  "publication/doi": "10.1016/j.jbo.2024.100637",
  "publication/tags": "- Bone Metastases\n- Lung Cancer\n- AI in Medicine\n- Medical Imaging\n- CT Scans\n- Mask R-CNN\n- ConvNeXt-V2\n- Tumor Segmentation\n- Diagnostic Accuracy\n- Personalized Treatment",
  "dataset/provenance": "The dataset utilized in this study was sourced from a dual-center experiment involving patients with bone metastases from two hospitals, referred to as Center A and Center B. Center A contributed a total of 106 patients, with 56 of these patients having metastases originating from lung cancer and the remaining 50 patients having bone metastases from other primary cancers. Center B provided a larger cohort of 265 patients with bone metastases, out of which 89 patients had lung cancer as the primary source of their metastases, and the remaining 176 patients had bone metastases from other types of cancers.\n\nThe data from Center B was used as the training set, allowing the model to learn from a diverse and extensive dataset. The data from Center A was utilized as the external validation set, ensuring an unbiased evaluation of the model's performance. This strategic approach in data utilization enhances the robustness of the model by preventing overfitting and ensuring scientific validity. The dataset consists of CT scan images with a slice thickness of 1 mm and no inter-slice gap, ensuring high-quality and consistent data for analysis. The segmentation of these images was meticulously performed by experienced orthopedic radiologists, ensuring accurate and precise annotations. This dataset has not been used in previous papers or by the community.",
  "dataset/splits": "The dataset utilized in this study was divided into three distinct splits: training, validation, and testing sets. The training set comprised 265 patients, which included 89 patients with lung cancer metastases and 176 patients with metastases from other types of cancers. This set was used to train the model, allowing it to learn from a diverse and extensive dataset.\n\nThe validation set was not explicitly detailed in terms of the number of patients, but it was allocated 15% of the total data. This set was used to tune hyperparameters and prevent overfitting during the training process.\n\nThe testing set, which was used to evaluate the model's generalization performance, consisted of 106 patients. Within this set, 56 patients had lung cancer metastases, and 50 patients had metastases from other primary cancers. This independent dataset ensured an unbiased evaluation of the model's performance.\n\nThe strategic division of the dataset into these three splits was crucial for ensuring the robustness and generalizability of the model. By training on one dataset and validating on separate datasets, the risk of overfitting was minimized, and the model's performance in real-world settings was more rigorously tested.",
  "dataset/redundancy": "The datasets were split into training, validation, and testing sets in a 70:15:15 ratio. This allocation ensures sufficient data for model training while reserving a validation set for tuning hyperparameters and a testing set for evaluating model generalization.\n\nThe training and test sets are independent. This independence was enforced by using data from different centers for training and testing. Specifically, data from Center B was used as the training set, while data from Center A was utilized as the external validation set. This approach prevents overfitting and enhances the generalizability of the model by ensuring that the model is trained on one dataset and validated on a separate dataset.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the medical field. The training set included 265 patients, with 89 having lung cancer metastases and 176 having metastases from other cancers. The external validation set comprised 106 patients, with 56 having lung cancer metastases and 50 having metastases from other cancers. This distribution ensures a diverse and extensive dataset for training, while the external validation set provides a rigorous test of the model's performance in real-world settings.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the AdamW optimizer. This optimizer is part of the class of adaptive learning rate optimization algorithms, which are widely used in deep learning due to their efficiency and effectiveness in handling large datasets and reducing overfitting.\n\nAdamW is not a new algorithm; it is an extension of the Adam optimizer, which has been extensively studied and used in the machine learning community. The \"W\" in AdamW stands for \"weight decay,\" which is a regularization technique that helps prevent overfitting by penalizing large weights. This modification makes AdamW particularly suitable for training deep neural networks.\n\nThe reason AdamW was not published in a machine-learning journal is that it is an improvement over the existing Adam optimizer, rather than a completely novel algorithm. The original Adam optimizer was introduced in a machine-learning journal, and subsequent improvements, like AdamW, are often shared through technical reports, arXiv preprints, or integrated into popular deep learning frameworks without necessitating a separate publication in a machine-learning journal. These improvements are widely adopted and validated through community usage and empirical results, making formal publication in a journal less critical.\n\nIn our work, AdamW was chosen for its superior performance in managing large datasets and reducing overfitting, which are crucial for training complex models like the 3D Mask R-CNN used for bone tumor detection. The initial learning rate was set to 1e-4, with a decay schedule applied to gradually reduce the learning rate, ensuring fine-tuning as the model approached convergence. This approach helped in achieving robust performance in both detecting and segmenting bone tumors from CT scans.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing steps were meticulously designed to ensure consistency and robustness in the machine-learning algorithm. The dataset consisted of CT scan images with a slice thickness of 1 mm and no inter-slice gap. The preprocessing involved several key steps.\n\nFirst, the CT imaging data was normalized to ensure uniformity across different scans. This normalization process was crucial for minimizing variations in image quality that could affect the model's performance.\n\nNext, data augmentation techniques were applied to increase the diversity of the training samples. These techniques included random rotations (up to 15 degrees), scaling (ranging from 0.8 to 1.2 times the original size), and flipping along the sagittal, coronal, and axial planes. These augmentations helped simulate variations in tumor positioning and orientation, thereby enhancing the model's ability to generalize to new, unseen data.\n\nThe images were then segmented to isolate the regions of interest (ROIs) for bone metastases. This segmentation was performed using specialized software by two orthopedic radiologists, each with over 15 years of experience in bone imaging diagnosis. The segmentation masks were mutually validated by these experts to ensure high-quality and precise annotations. This dual-expert approach guaranteed the accuracy and reliability of the segmented data.\n\nAdditionally, the resolution of all CT scans was standardized to a uniform voxel size of 1 mm \u00d7 1 mm \u00d7 1 mm. This standardization ensured consistency across the dataset, which is essential for the model to learn effectively from the data.\n\nIntensity normalization was also applied to bring all pixel values to a zero mean and unit variance. This step was crucial for minimizing variations in image quality that could affect model performance.\n\nThe dataset was then randomly divided into training, validation, and testing sets in a 70:15:15 ratio. This allocation ensured sufficient data for model training while reserving a validation set for tuning hyperparameters and a testing set for evaluating model generalization.\n\nBy adopting these preprocessing and data encoding techniques, the model was able to achieve robust and accurate segmentation of bone tumors, providing a valuable tool for clinical applications.",
  "optimization/parameters": "The model utilizes a 3D Mask R-CNN architecture with a ConvNeXt-V2 backbone, which is designed to enhance feature extraction through deeper convolutional layers and a Global Response Normalization (GRN) layer. This backbone is pre-trained on large-scale medical imaging datasets, enabling it to capture spatial and contextual details in CT scans more effectively than traditional ResNet-50 models. The Region Proposal Network (RPN) within the model employs specific anchor scales and ratios to improve the detection of objects at varying sizes and shapes. The anchor scales used are [4, 8, 16, 32, 64], and the anchor ratios are [0.5, 1, 2]. These parameters were selected to optimize the balance between precision and recall during positive anchor classification, with an IoU threshold of 0.95.\n\nThe model's training parameters include the use of the AdamW optimizer, which is chosen for its superior performance in handling large datasets and reducing overfitting. The initial learning rate is set to 1e-4, with a decay rate of 0.05 per epoch to gradually reduce the learning rate as training progresses. A batch size of 8 is used to ensure efficient utilization of GPU memory without compromising performance. The loss functions employed are a combination of classification loss (cross-entropy), bounding box regression loss (smooth L1), and mask prediction loss (binary cross-entropy). These loss functions ensure that the model accurately predicts the class, bounding box, and segmentation mask for each region of interest.\n\nData augmentation techniques, such as random rotation (up to 15 degrees), random scaling (between 0.8 and 1.2 times the original size), and random flipping along the sagittal, coronal, and axial planes, are applied to improve the generalization of the model. The dataset used for training consists of 265 CT scans from patients with confirmed bone metastases, standardized to a uniform voxel size of 1 mm \u00d7 1 mm \u00d7 1 mm and intensity-normalized to zero mean and unit variance. The dataset is divided into training, validation, and testing sets in a 70:15:15 ratio to ensure sufficient data for model training and evaluation. The model is trained for 50 epochs with early stopping based on validation loss to prevent overfitting and ensure optimal performance.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The fitting method employed in our study utilized a 3D Mask R-CNN model, which inherently involves a large number of parameters due to its complex architecture. The model's backbone, ConvNeXt-V2, is designed with deep convolutional layers, and the overall architecture includes multiple components such as the Region Proposal Network (RPN), RoI Align layer, fully connected layers, and mask head. This complexity ensures that the model can capture intricate details in the CT scans, but it also means that the number of parameters is significantly larger than the number of training points.\n\nTo address the risk of overfitting, several strategies were implemented. Firstly, the dataset was divided into training, validation, and testing sets in a 70:15:15 ratio. This division ensured that the model was trained on a substantial portion of the data while reserving independent sets for validation and testing. Additionally, data augmentation techniques were applied, including random rotations, translations, scaling, and flipping. These augmentations increased the diversity of the training data, helping the model generalize better to unseen data.\n\nThe AdamW optimizer was used, which is known for its effectiveness in managing large datasets and reducing overfitting. The learning rate was set to 1e-4 with a decay schedule, reducing the learning rate by a factor of 0.1 after 40 epochs. Early stopping based on validation loss was also employed to prevent the model from overfitting to the training data.\n\nTo rule out underfitting, the model's performance was thoroughly evaluated using a comprehensive set of metrics, including the Dice Similarity Coefficient (DSC), sensitivity, specificity, and accuracy. These metrics provided a detailed assessment of the model's ability to segment bone tumors and predict their source accurately. The Receiver Operating Characteristic (ROC) curve and Area Under the Curve (AUC) were also used to evaluate the model's classification performance, ensuring that it could distinguish between tumor and non-tumor regions effectively.\n\nOverall, the combination of a robust model architecture, strategic data utilization, and rigorous evaluation metrics ensured that the model neither overfitted nor underfitted the data, providing reliable and accurate results for clinical applications.",
  "optimization/regularization": "In our study, several regularization methods were employed to prevent overfitting and enhance the model's generalization capabilities.\n\nFirstly, data augmentation techniques were extensively used. These included random rotations up to 15 degrees, translations, and scaling ranging from 0.8 to 1.2 times the original size. Additionally, random flipping along the sagittal, coronal, and axial planes was applied to simulate variations in tumor positioning. These augmentations increased the diversity of the training data, making the model more robust and less likely to overfit to specific patterns in the training set.\n\nSecondly, early stopping was implemented during the training process. This technique monitors the validation loss and stops the training process when the loss stops improving, thereby preventing the model from overfitting to the training data.\n\nFurthermore, the AdamW optimizer was chosen for its effectiveness in managing large datasets and reducing overfitting. The learning rate was initially set to 1e-4 and decayed by a factor of 0.1 after 40 epochs. This decay schedule helps in fine-tuning the model as it approaches convergence, further aiding in the prevention of overfitting.\n\nLastly, the model was trained using a composite loss function that combined classification loss and segmentation loss. This multi-component loss function ensured that the model accurately predicted both the tumor's class and its exact location within the CT scan, thereby improving the overall performance and reducing the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are thoroughly detailed within the publication. These include specific settings such as the learning rate, batch size, and the decay schedule, which are crucial for replicating our experiments. The model architecture, particularly the use of the ConvNeXt-V2 backbone and the 3D Mask R-CNN framework, is also described in detail, providing a clear roadmap for implementation.\n\nThe optimization parameters, including the choice of the AdamW optimizer and the composite loss function, are explicitly mentioned. This information is essential for understanding how the model was trained and optimized to achieve high performance in segmenting bone tumors and predicting their origin.\n\nRegarding the availability of model files, while the specific files are not directly provided in the publication, the detailed descriptions of the model architecture and training procedures allow for the reconstruction of the model. This ensures that researchers can implement and validate our findings independently.\n\nThe publication adheres to standard academic practices, making the methodologies and configurations openly accessible. This transparency is vital for reproducibility and further advancements in the field. However, for direct access to model files or additional resources, readers may need to contact the authors or refer to supplementary materials that might be available through the journal's website or associated repositories.",
  "model/interpretability": "The model we developed, a 3D Mask R-CNN with a ConvNeXt-V2 backbone, is inherently more interpretable than many traditional black-box models. This architecture allows for a clear understanding of how decisions are made at various stages of the process.\n\nThe model's architecture includes several key components that enhance its transparency. The Region Proposal Network (RPN) generates object proposals by assigning probabilities to anchor boxes, indicating the likelihood of containing an object. This step provides insights into which regions of the CT scan are considered potential areas of interest. The RoI Align layer ensures accurate spatial alignment of features, which is crucial for precise segmentation. This layer helps in understanding how the model aligns and processes regions of interest, making it easier to trace back the decisions made during segmentation.\n\nThe model then processes these aligned features through two parallel networks: a classifier and a segmentation network. The classifier predicts the probability that a given region contains a tumor, providing a clear indication of the model's confidence in identifying metastatic regions. Simultaneously, the segmentation network generates binary masks, which precisely locate the tumor within the CT scan volume. These masks offer a visual representation of the model's segmentation decisions, making it easier to interpret and validate the results.\n\nThe use of the ConvNeXt-V2 backbone further enhances the model's interpretability. This backbone is designed to capture spatial and contextual details more effectively, reducing feature loss in deeper layers. The Global Response Normalization (GRN) layer within ConvNeXt-V2 helps in increasing feature diversity during training, which can be visualized and analyzed to understand how different features contribute to the final output.\n\nAdditionally, the model's performance metrics, such as the Dice Similarity Coefficient (DSC), sensitivity, specificity, and accuracy, provide a comprehensive evaluation of its effectiveness. The ROC curve and Area Under the Curve (AUC) offer insights into the model's ability to distinguish between metastatic and non-metastatic regions, further aiding in its interpretability.\n\nIn summary, the 3D Mask R-CNN model with the ConvNeXt-V2 backbone is designed to be more transparent and interpretable. The clear separation of tasks into region proposal, classification, and segmentation, along with the use of advanced feature extraction techniques, allows for a better understanding of how the model makes its predictions. This transparency is crucial for clinical applications, where interpretability is essential for trust and validation.",
  "model/output": "The model is a classification model. It is designed to automatically segment bone tumors from CT scans and classify whether the metastasis originates from lung cancer. The model's architecture, specifically the 3D Mask R-CNN with the ConvNeXt-V2 backbone, is tailored for this classification task. It processes input CT images to generate detailed feature maps, which are then used to create region proposals. These proposals are refined through a classification branch that predicts the class of the tumor and a segmentation branch that generates binary masks to localize the tumor regions. The model's performance is evaluated using metrics such as Area Under the Curve (AUC), accuracy, sensitivity, and specificity, which are all relevant to classification tasks. The high AUC values, particularly on the test set, indicate the model's proficiency in distinguishing between metastatic bone tumors and other regions, confirming its effectiveness as a classification model.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our model was conducted using a comprehensive set of metrics to ensure a thorough assessment of its performance in both segmentation and classification tasks. We utilized the Dice Similarity Coefficient (DSC) to measure the spatial overlap between the predicted segmentation masks and the ground truth, providing a direct reflection of the segmentation quality. Sensitivity, or the true positive rate, was employed to evaluate the model's ability to detect actual positive cases, ensuring that few metastatic regions were missed. Specificity, or the true negative rate, assessed the model's capability to correctly identify non-tumor regions, minimizing false positives. Accuracy was used to provide an overall assessment of the model's performance by balancing the detection of tumors with the correct identification of non-tumor regions.\n\nAdditionally, the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) were used to evaluate the model's classification performance. The ROC curve visualizes the trade-off between sensitivity and specificity across various decision thresholds, offering insights into the model's ability to distinguish between different classes. The AUC quantifies the overall performance of the model, with values closer to 1 indicating superior performance.\n\nThe model was evaluated on an independent dataset from a different center to ensure unbiased results and enhance the generalizability of the findings. This dual-center study design, with data from Center A used for external validation and data from Center B used for training, prevented overfitting and ensured that the model's performance was rigorously tested in real-world settings. The high DSC values (0.956 for training and 0.929 for testing) and strong AUC values (0.991 for training and 0.955 for testing) demonstrated the model's robust performance in both segmentation and classification tasks, making it a valuable tool for clinical applications in detecting and managing bone tumors.",
  "evaluation/measure": "In our evaluation of the 3D Mask R-CNN model, we employed a comprehensive set of performance metrics to thoroughly assess its effectiveness in segmenting bone tumors and predicting their source. The primary metrics reported include the Dice Similarity Coefficient (DSC), sensitivity, specificity, and accuracy. These metrics collectively provide a robust understanding of the model's segmentation and classification capabilities.\n\nThe Dice Similarity Coefficient (DSC) is a crucial metric for evaluating the overlap between the predicted segmentation masks and the ground truth. It measures spatial accuracy, with values ranging from 0 (no overlap) to 1 (perfect overlap). This metric is particularly useful in medical imaging as it quantifies the similarity between the predicted and actual tumor regions, directly reflecting the segmentation quality.\n\nSensitivity, also known as the True Positive Rate, measures the proportion of actual positive cases (e.g., tumors) that were correctly identified by the model. A high sensitivity indicates that the model is adept at detecting tumors, ensuring that few metastatic regions are missed during diagnosis.\n\nSpecificity, or the True Negative Rate, reflects the proportion of true negative cases (e.g., non-tumor regions) that the model correctly identified. High specificity ensures that healthy tissue is not mistakenly labeled as tumor, thus minimizing false positives and reducing unnecessary interventions.\n\nAccuracy provides an overall assessment of the model\u2019s performance by measuring the proportion of correct predictions (both true positives and true negatives) relative to all predictions made. It balances the detection of tumors with the correct identification of non-tumor regions, making it a comprehensive indicator of model reliability.\n\nIn addition to these core metrics, we utilized the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) to evaluate the model\u2019s classification performance. The ROC curve visualizes the trade-off between sensitivity and specificity across various decision thresholds, offering insight into the model\u2019s ability to distinguish between different classes (tumor vs. non-tumor). The AUC quantifies the overall performance of the model, with values closer to 1 indicating near-perfect classification performance. A higher AUC signifies that the model is proficient at distinguishing between metastatic bone tumors and other regions, even under varying thresholds.\n\nThese metrics are representative of the standards used in the literature for evaluating medical imaging models. They provide a multi-dimensional evaluation of the model\u2019s performance, ensuring a robust and reliable analysis of its segmentation and classification tasks. This comprehensive approach makes the model a valuable tool for clinical applications in detecting and managing bone tumors.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not enough information is available."
}