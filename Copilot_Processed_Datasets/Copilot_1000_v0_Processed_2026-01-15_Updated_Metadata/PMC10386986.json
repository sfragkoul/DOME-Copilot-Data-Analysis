{
  "publication/title": "Development of a deep pathomics score for predicting hepatocellular carcinoma recurrence after liver transplantation.",
  "publication/authors": "Qu WF, Tian MX, Lu HW, Zhou YF, Liu WR, Tang Z, Yao Z, Huang R, Zhu GQ, Jiang XF, Tao CY, Fang Y, Gao J, Wu XL, Chen JF, Zhao QF, Yang R, Chu TH, Zhou J, Fan J, Yu JH, Shi YH",
  "publication/journal": "Hepatology international",
  "publication/year": "2023",
  "publication/pmid": "37031334",
  "publication/pmcid": "PMC10386986",
  "publication/doi": "10.1007/s12072-023-10511-2",
  "publication/tags": "- Hepatocellular carcinoma (HCC)\n- Prognostic network\n- DeepSurv\n- Multiplex immunofluorescence\n- Tissue categories\n- Recurrence-free survival (RFS)\n- Cox proportional hazards\n- Attention machine\n- Digital whole slide images (WSIs)\n- Pathological signatures\n- Immune cells\n- Tumor nest\n- Invasive margin\n- Normal liver tissue\n- Classification network\n- ResNet-50\n- T-distributed stochastic neighbor embedding (t-SNE)\n- Risk score\n- Concordance index (C-index)\n- Receiver operating characteristic (ROC) curves",
  "dataset/provenance": "The dataset used in this study consists of whole slide images (WSIs) from hepatocellular carcinoma (HCC) patients who underwent liver transplantation. A total of 395 patients were enrolled, with 199 patients from a previous study and an additional 181 patients from a more recent cohort. This resulted in a total of 495 WSIs. The patients were selected based on specific inclusion and exclusion criteria, ensuring that they had pathologically proven HCC, no other concomitant tumors or extrahepatic metastasis, and complete clinical information. The dataset was divided into training and validation cohorts at a ratio of 7:3. The training cohort consisted of 276 patients, while the validation cohort included 119 patients. This division was done to construct and evaluate a prognostic network aimed at predicting tumor recurrence after liver transplantation. The dataset was used to build a classification network that automatically segmented the WSIs into different tissue categories, which were then analyzed to construct a deep pathomics score (DPS) for prognostic purposes.",
  "dataset/splits": "The dataset was divided into two main splits: the training cohort and the validation cohort. The division was done at a ratio of 7:3, resulting in 380 patients being split across these two cohorts. This means that approximately 266 patients were included in the training cohort, and around 114 patients were in the validation cohort. The follow-up for the study was censored in June 2021, with the primary endpoints being recurrence condition and time to recurrence (TTR). The secondary endpoint was recurrence-free survival (RFS), defined as the time from the date of hepatectomy to the date of recurrence, metastasis, death, or the last follow-up. The study obtained ethical approval and complied with the standards of the Declaration of Helsinki, with informed consent received from each patient before surgery.",
  "dataset/redundancy": "The study utilized two datasets of patients who underwent liver transplantation. The first dataset consisted of 199 hepatocellular carcinoma (HCC) patients and 204 corresponding whole slide images (WSIs), while the second dataset included 181 patients and 291 WSIs. These datasets were combined and then split into training and validation cohorts at a ratio of 7:3. This split ensures that the training and validation sets are independent, with no overlap of patients between them.\n\nTo enforce independence, strict inclusion and exclusion criteria were applied. Patients were included if they had pathologically proven HCC, no other concomitant tumors, and no extrahepatic metastasis. Exclusions were made for patients with other pathological types, missing qualified WSIs, missing clinical information, or those who experienced death or disease recurrence within one month after liver transplantation.\n\nThe distribution of the datasets aligns with previously published machine learning datasets in terms of ensuring a representative and independent split for training and validation purposes. This approach helps in building a robust classification and prognostic network, as it allows for the evaluation of model performance on unseen data, thereby enhancing the generalizability and reliability of the results.",
  "dataset/availability": "The data used in this study is not publicly available. The study utilized two datasets of hepatocellular carcinoma (HCC) patients who underwent liver transplantation. The first dataset included 199 patients and 204 corresponding whole slide images (WSIs) from a previous study. The second dataset consisted of 181 patients and 291 WSIs from a different time period. These datasets were combined for analysis, but they are not released in a public forum. The data splits used for training and validation cohorts were randomly assigned at a ratio of 7:3, but this specific split is not publicly disclosed. The study obtained ethical approval and complied with the standards of the Declaration of Helsinki, ensuring that informed consent was received from each patient. However, the datasets themselves are not made available to the public, and there is no information provided on a specific license for data access.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages a deep learning approach, specifically utilizing a convolutional neural network (CNN) architecture. The CNN used is based on ResNet-50, which is a well-established and widely used model in the field of computer vision. To enhance its performance, a Squeeze-and-Excitation Module was integrated into the residual structure of the ResNet-50. This module helps to improve the representational power of the network by allowing it to perform dynamic channel-wise feature recalibration.\n\nThe prognostic network was constructed using the DeepSurv network structure. This structure is designed to handle survival analysis tasks and is particularly suited for analyzing the pathological signatures of different tissue categories. The loss function for the model was jointly built using the Cox proportional hazards and binary cross-entropy, which allows the model to incorporate both survival information and classification accuracy.\n\nThe choice of these specific algorithms and architectures was driven by their proven effectiveness in similar tasks and their ability to handle the complex and high-dimensional data associated with whole slide images (WSIs). While these algorithms are not new, their application in the context of hepatocellular carcinoma (HCC) recurrence prediction is innovative. The integration of the Squeeze-and-Excitation Module and the use of the DeepSurv structure for prognostic modeling represent advancements in how these algorithms are applied to medical imaging and survival analysis.\n\nThe focus of our publication is on the application of these algorithms to improve the prediction of HCC recurrence rather than the development of new machine-learning algorithms. Therefore, the algorithms were not published in a machine-learning journal but rather in a specialized medical journal to highlight their clinical relevance and impact. The emphasis is on demonstrating the practical benefits of these algorithms in a medical context, showcasing their ability to provide accurate and reliable predictions for patient outcomes.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on a deep learning algorithm to establish and validate the Deep Pathomics Score (DPS) with high accuracy. The neural network evaluates the prognostic significance of each histological structure, highlighting the dominant position of immune cells. The model is trained using pathological signatures of six tissue categories, and the loss function is jointly built with the Cox proportional hazards and binary cross-entropy. This approach allows for the automatic calculation of individual recurrence risk via digital identification of each whole slide image (WSI), facilitating pathological diagnosis and recurrence evaluation in liver transplantation (LT) patients. The model's performance is assessed using the overall concordance index (C-index) and receiver operating characteristic (ROC) curves, demonstrating its effectiveness and simplicity in predicting post-LT recurrence.",
  "optimization/encoding": "The data encoding process involved several steps to prepare the whole slide images (WSIs) for the machine-learning algorithm. Initially, the WSIs were converted from stained slides using a white light scanner. Sixty WSIs were selected for annotation based on specific criteria, including similar tumor stages and the abundance of six tissue categories confirmed by pathologists. These categories included tumor region, normal liver tissue, portal area, fibrous tissue, hemorrhagic and necrotic tissue, and immune cells.\n\nThe annotated WSIs were then used to extract patches of each tissue category. These patches were taken at 40\u00d7 magnification and cropped into 512 \u00d7 512 pixel images, each labeled with the corresponding tissue category. Data augmentation techniques, such as random flips, rotations, translations, and contrast adjustments, were applied to enhance the generality and robustness of the dataset.\n\nTo separate the H&E-stained tissue from the background, Otsu's binarization method was employed. This step was crucial for extracting the pathological regions of interest (ROIs) from the WSIs. The classification network, built using a ResNet-50 convolutional neural network with a Squeeze-and-Excitation Module, was trained on these annotated patches. The network outputted predicted structural labels for each patch, which were then used to derive classification maps.\n\nThe t-distributed stochastic neighbor embedding (t-SNE) algorithm was utilized to visualize the segmental results, ensuring good discrimination of the pathological structures. The classification network achieved high recognition accuracy, with an area under the curve (AUC) value of 0.97 for both micro-average and macro-average recognition. This accuracy was further validated through a confusion matrix, which revealed high precision for each tissue category.\n\nThe classified tiles were then used as inputs for the prognostic network, with recurrence condition and time to recurrence (TTR) as the labels. The DeepSurv network structure was employed to construct the prognostic models, analyzing the pathological signatures of the six tissue categories. The loss function of the model was jointly built with the Cox proportional hazards and binary cross-entropy to avoid overfitting. The optimal risk score for each tissue category was output based on the recurrence status and TTR, leading to the construction of the digital pathology score (DPS) according to the proportional hazards model.",
  "optimization/parameters": "In our study, the model utilized pathological signatures from six distinct tissue categories. The specific details of these categories are provided in the supplementary methods.\n\nThe selection of these parameters was guided by a comprehensive analysis of the pathological data. To ensure the robustness of our model, we employed a strategy to avoid overfitting during the training process. The model was trained until the error in the validation set began to rise, at which point the training was halted. This approach helped in identifying the optimal risk score for each tissue category based on recurrence status and time to recurrence (TTR).\n\nThe loss function of the model was constructed using a combination of the Cox proportional hazards and binary cross-entropy, which allowed for a more nuanced and accurate prediction of outcomes. This dual approach ensured that the model could effectively capture both the time-to-event data and the binary classification of recurrence.\n\nThe predictive power of the model was assessed using the overall concordance index (C-index) and receiver operating characteristic (ROC) curves. These metrics provided a comprehensive evaluation of the model's performance in predicting recurrence and survival outcomes.\n\nAdditionally, an attention mechanism was integrated into the model to highlight critical regions in the images that were significant for model predictions. This feature enhanced the interpretability of the model by focusing on the most relevant areas within the tissue samples.\n\nThe final model, referred to as the Deep Pathological Signature (DPS), was derived from a weighted algorithm that considered all tissue categories except for the normal tissue area (NLT). This approach ensured that the model could effectively capture the prognostic value of the different tissue categories, leading to improved predictive accuracy.",
  "optimization/features": "The input features for our prognostic network are derived from the pathological signatures of six distinct tissue categories. These categories include tumor region, normal liver tissue, portal area, fibrous tissue, hemorrhagic and necrotic tissue, and immune cells. Each of these categories is analyzed to extract relevant features that contribute to the prediction of recurrence status and time to recurrence.\n\nFeature selection was inherently performed through the use of a classification network. This network, built using a ResNet-50 convolutional neural network with a Squeeze-and-Excitation Module, was trained to classify images into the six tissue categories. The classification network's output, which includes the predicted structural labels for each patch, serves as the input features for the prognostic network. This process ensures that only the most relevant features, as determined by the classification network, are used in the prognostic model.\n\nThe feature selection process was conducted using the training set only. This approach helps to prevent data leakage and ensures that the model's performance is evaluated on unseen data, thereby providing a more accurate assessment of its generalizability. The classification network was trained on a subset of annotated whole slide images (WSIs), and the resulting features were used to train the prognostic network. This method helps to maintain the integrity of the validation process and ensures that the model's performance is not overestimated.",
  "optimization/fitting": "In the development of our prognostic network models, we employed the DeepSurv network structure to analyze pathological signatures across six tissue categories. The loss function was designed to incorporate both Cox proportional hazards and binary cross-entropy, ensuring a comprehensive approach to model training.\n\nTo address the potential issue of overfitting, given that the number of parameters in our deep learning model was indeed larger than the number of training points, we implemented several strategies. Firstly, we utilized a validation set to monitor the model's performance during training. The training process was halted once the error in the validation set began to rise, indicating that the model was no longer generalizing well to unseen data. This early stopping technique helped in preventing overfitting by ensuring that the model did not become too complex and instead focused on capturing the underlying patterns in the data.\n\nAdditionally, data augmentation techniques such as random flips, rotations, translations, and contrast adjustments were applied to enhance the generality and robustness of the model. These techniques increased the effective size of the training dataset, making it more difficult for the model to memorize the training data and thereby reducing the risk of overfitting.\n\nTo rule out underfitting, we ensured that our model had sufficient capacity to learn the complex relationships in the data. The use of a ResNet-50 convolutional neural network, augmented with a Squeeze-and-Excitation Module, provided a robust architecture capable of capturing intricate features in the pathological images. Furthermore, the inclusion of the attention mechanism helped in highlighting critical regions in the images, ensuring that the model focused on the most relevant information for prediction.\n\nThe predictive power of our model was assessed using the overall concordance index (C-index) and receiver operating characteristic (ROC) curves, which provided a quantitative measure of the model's performance. These metrics, along with the calibration curves, demonstrated that our model achieved a good balance between bias and variance, avoiding both overfitting and underfitting.",
  "optimization/regularization": "In the optimization process of our prognostic network models, several techniques were employed to prevent overfitting. One key method involved monitoring the error rates on a validation set during training. The model training was halted once the error rates began to increase, ensuring that the model did not become overly specialized to the training data. This early stopping technique is crucial for maintaining the model's generalization capability.\n\nAdditionally, data augmentation strategies were implemented. These included random flips, rotations, translations, and contrast adjustments. By artificially expanding the training dataset with these variations, the model's robustness and ability to generalize to unseen data were enhanced.\n\nThe use of a validation set distinct from the training set also played a significant role in preventing overfitting. This separation allowed for an unbiased evaluation of the model's performance, ensuring that the model's parameters were tuned to improve performance on both the training and validation datasets.\n\nFurthermore, the incorporation of a Squeeze-and-Excitation Module within the ResNet-50 convolutional neural network helped in focusing on important features, thereby improving the model's efficiency and reducing the risk of overfitting.\n\nOverall, these regularization methods collectively contributed to the development of a robust and generalizable prognostic network model.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the supplementary methods. These methods provide a comprehensive overview of the parameters and schedules employed during the training and validation of our models. However, specific model files and optimization parameters are not explicitly reported in the main text or supplementary materials. The study adheres to ethical guidelines and standards, ensuring that all methodologies and findings are reproducible within the constraints provided. For access to detailed methodologies and to reproduce the results, researchers can refer to the supplementary materials, which outline the steps and parameters used in the development of our prognostic network models. The study complies with the standards of the Declaration of Helsinki, and informed consent was obtained from each patient, ensuring ethical considerations are met.",
  "model/interpretability": "The model employed in this study is not entirely a black box, as efforts have been made to enhance its interpretability. To achieve this, an attention mechanism was integrated into the prognostic network. This mechanism highlights critical regions within the images that are significant for model predictions. The attention heatmaps generated by this process visually indicate areas with higher attention scores, which are shown in red and suggest a closer relationship to cancer recurrence. This approach allows for a better understanding of which tissue categories and regions are most influential in the model's predictions.\n\nAdditionally, the model's structure and training process were designed to avoid overfitting, ensuring that the predictions are robust and generalizable. The use of the DeepSurv network, combined with the Cox proportional hazards and binary cross-entropy loss functions, provides a transparent framework for constructing prognostic models. The model's predictive power was assessed using the overall concordance index (C-index) and receiver operating characteristic (ROC) curves, further contributing to its interpretability.\n\nThe attention heatmaps serve as a clear example of how the model's decisions can be interpreted. By visualizing the attention scores, researchers and clinicians can gain insights into the specific tissue categories and regions that the model deems important for predicting recurrence. This transparency is crucial for building trust in the model's predictions and for facilitating its practical application in clinical settings.",
  "model/output": "The model developed in this study is primarily a classification model, but it also incorporates regression elements for prognostic purposes. The classification network is based on a ResNet-50 convolutional neural network, enhanced with a Squeeze-and-Excitation Module, and is trained to segment and classify different tissue categories in histopathological images. This network outputs predicted structural labels for each image patch, effectively categorizing them into six distinct tissue types.\n\nIn addition to classification, the model includes a prognostic network constructed using the DeepSurv structure. This network analyzes the pathological signatures of the six tissue categories to predict recurrence status and time to recurrence (TTR). The loss function for this network is jointly built with the Cox proportional hazards and binary cross-entropy, allowing it to handle both classification and survival analysis tasks. The model's predictive power is evaluated using the overall concordance index (C-index) and receiver operating characteristic (ROC) curves, providing a comprehensive assessment of its performance in both classification and regression contexts.\n\nThe attention machine is also applied to highlight critical regions in the images that are crucial for the model's predictions, further enhancing the interpretability of the results. This dual approach of classification and regression enables the model to not only identify different tissue types but also to provide valuable prognostic information based on these classifications.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the prognostic network models involved several key metrics and methods to assess their predictive power. The overall concordance index (C-index) and receiver operating characteristic (ROC) curves were used to evaluate the predictive performance. The C-index provides a measure of the model's ability to correctly order pairs of patients with respect to their survival times, while the ROC curves illustrate the trade-off between sensitivity and specificity at various threshold settings.\n\nThe area under the curve (AUC) was calculated at different time points, specifically at 1 year, 2 years, and 5 years, to assess the model's performance over time. Additionally, calibration curves were used to evaluate how well the predicted probabilities matched the observed outcomes at 1 year, 3 years, and 5 years.\n\nThe attention machine was employed to highlight critical regions in the images that were important for the model's predictions. This helped in understanding which parts of the tissue images were most influential in determining the prognostic outcomes.\n\nThe predictive power of the Deep Pathological Signature (DPS) was compared with various clinical features and staging systems, such as the Barcelona Clinic Liver Cancer (BCLC) stage, Milan criteria, University of California San Francisco (UCSF) criteria, Tumor-Node-Metastasis (TNM) stage, and ERASL-post. The DPS demonstrated superior performance in terms of the C-index and AUC compared to these clinical features.\n\nThe evaluation also included the use of a training cohort and a validation cohort, divided at a ratio of 7:3, to construct and validate the prognostic network. This approach helped in ensuring that the model was robust and generalizable. The follow-up data, including recurrence condition and time to recurrence (TTR), were used as primary endpoints to assess the model's performance. Recurrence-free survival (RFS) was also considered as a secondary endpoint.\n\nIn summary, the evaluation method involved a comprehensive assessment using multiple metrics and comparisons with established clinical features, ensuring a thorough validation of the prognostic network models.",
  "evaluation/measure": "In the evaluation of our prognostic models, several performance metrics were employed to comprehensively assess their predictive power. The primary metrics reported include the Area Under the Curve (AUC) for Receiver Operating Characteristic (ROC) curves and the concordance index (C-index).\n\nThe AUC values were calculated at different time points, specifically at 1 year, 2 years, and 5 years, providing a temporal assessment of the model's predictive accuracy. These time-dependent ROC curves offer insights into how well the model discriminates between patients who will experience recurrence and those who will not, over various time horizons.\n\nAdditionally, the C-index was used to evaluate the overall concordance between predicted and observed outcomes. This metric ranges from 0 to 1, where a higher value indicates better predictive performance. The C-index was reported for different configurations of the model, including when it was used alone and in combination with clinical features.\n\nThe comparison of our Deep Pathomics Score (DPS) with traditional predictive staging systems, such as RETREAT, BCLC stage, Milan criteria, UCSF criteria, TNM stage, and ERASL-post, was also conducted using AUC values. This comparison highlights the relative performance of our model against established methods in the literature.\n\nCalibration curves for Time to Recurrence (TTR) and Recurrence-Free Survival (RFS) were also presented. These curves assess how well the predicted probabilities align with the actual observed outcomes, providing a measure of the model's calibration.\n\nThe set of metrics reported is representative of standard practices in the field, ensuring that our model's performance can be compared with other studies in the literature. The use of AUC, C-index, and calibration curves provides a thorough evaluation of both the discriminative ability and the calibration of our prognostic models.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our proposed method, the Deep Pathomics Score (DPS), with several publicly available and traditional predictive staging systems. These comparisons were performed on benchmark datasets to ensure the robustness and generalizability of our findings.\n\nWe evaluated the performance of DPS against established methods such as RETREAT, BCLC stage, Milan criteria, UCSF criteria, TNM stage, and ERASL-post. The comparison was facilitated using receiver operating characteristic (ROC) curves and the area under the curve (AUC) metric. The AUC values for these methods were reported at different time points, including 1 year, 2 years, and 5 years, providing a comprehensive assessment of their predictive power over time.\n\nAdditionally, we compared DPS with simpler baselines, such as clinical features alone. The concordance index (C-index) was used to quantify the predictive accuracy of these models. The results indicated that DPS, both alone and in combination with clinical features, outperformed the simpler baselines. Specifically, the C-index for DPS combined with clinical features was 0.849, which was higher than the C-index for clinical features alone, which was 0.732. This demonstrates the added value of incorporating DPS into the predictive model.\n\nFurthermore, we assessed the calibration of our models using calibration curves for time to recurrence (TTR) and recurrence-free survival (RFS). These curves showed that DPS provided well-calibrated predictions, indicating that the predicted probabilities closely matched the observed outcomes.\n\nIn summary, our evaluation included comparisons with both publicly available methods and simpler baselines, ensuring a rigorous assessment of DPS's performance. The results consistently showed that DPS offers superior predictive accuracy and calibration, making it a valuable tool for prognostic modeling.",
  "evaluation/confidence": "The evaluation of our prognostic models includes several performance metrics, each accompanied by confidence intervals to provide a measure of uncertainty. For instance, the concordance index (C-index) for different models, such as the DPS and clinical features combined, is reported with 95% confidence intervals. This allows for a clear understanding of the reliability of these estimates.\n\nStatistical significance is a crucial aspect of our evaluation. We have provided p-values for various comparisons, indicating whether the observed differences in performance are likely due to chance. Many of these p-values are less than 0.001, suggesting strong evidence against the null hypothesis and supporting the claim that our methods are superior to others and baselines.\n\nThe area under the curve (AUC) values for different models at various time points (1 year, 2 years, 5 years) are also reported. These AUC values, along with their confidence intervals, help in assessing the discriminative ability of the models over time. The consistent performance across different time points, along with statistically significant improvements over baseline methods, strengthens the confidence in our results.\n\nIn summary, the performance metrics are robust, with confidence intervals providing a measure of uncertainty, and the results are statistically significant, supporting the superiority of our methods over existing baselines.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study utilized specific datasets and models that were developed and validated internally. These include the use of annotated whole slide images (WSIs) and the application of machine learning models such as the DeepSurv network and ResNet-50 for classification and prognostic analysis. The evaluation metrics, such as the concordance index (C-index) and area under the receiver operating characteristic curve (AUC), were derived from these internal datasets. While the methods and results are detailed in the publication, the raw data and evaluation files themselves are not released to the public. This approach ensures the integrity and confidentiality of the patient data used in the study."
}