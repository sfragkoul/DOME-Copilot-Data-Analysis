{
  "publication/title": "Postoperative Apnea-Hypopnea Index Prediction of Velopharyngeal Surgery Based on Machine Learning.",
  "publication/authors": "You J, Li J, Zhou Y, Cao X, Zhao C, Zhang Y, Ye J",
  "publication/journal": "OTO open",
  "publication/year": "2025",
  "publication/pmid": "39776760",
  "publication/pmcid": "PMC11705500",
  "publication/doi": "10.1002/oto2.70061",
  "publication/tags": "- Obstructive Sleep Apnea\n- Velopharyngeal Surgery\n- Machine Learning\n- Predictive Modeling\n- Postoperative Outcomes\n- Apnea-Hypopnea Index\n- Artificial Neural Networks\n- Support Vector Regression\n- Random Forest\n- Extreme Gradient Boosting\n- Surgical Efficacy\n- Personalized Treatment\n- Statistical Analysis\n- Polysomnography\n- Computed Tomography",
  "dataset/provenance": "The dataset used in this study was sourced from a retrospective analysis of patients who underwent velopharyngeal surgery at the Sleep Center, Beijing Tsinghua Changgung Hospital, between January 2018 and December 2023. The study included 152 adult patients diagnosed with obstructive sleep apnea (OSA) based on polysomnography (PSG) studies and typical clinical symptoms. The dataset comprises various parameters obtained from physical examinations, PSG recordings, and 3-dimensional CT scans. These parameters include age, gender, body mass index (BMI), neck circumference, palate position, tonsil size, preoperative and postoperative apnea-hypopnea index (AHI), nadir saturation of oxygen (NadirSpO2), CT90, minimal cross-sectional airway area of the velopharynx (VmCSA), minimal cross-sectional airway area of the glossopharynx (GmCSA), and the vertical distance between the lower edge of the mandible and the lower edge of the hyoid (MH). The dataset was divided into training and test sets, with 106 subjects in the training set and 46 subjects in the test set. This division was repeated five times to ensure the robustness of the models. The dataset has not been used in previous papers by the community, as it is specific to this study and the patient population at the mentioned hospital.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The subjects were randomly assigned to these sets with a 7:3 ratio. Specifically, out of the 152 subjects, 106 were allocated to the training set, and the remaining 46 were assigned to the test set. This process was repeated five times to ensure robustness in the model evaluation. The training set was used to derive the six prediction models, while the test set was used to evaluate their performance.",
  "dataset/redundancy": "The dataset used in this study consisted of 152 adult patients who underwent velopharyngeal surgery. Initially, 156 subjects were considered, but four were excluded due to previous oropharyngeal OSA surgery or a BMI greater than 40 kg/m\u00b2.\n\nThe subjects were randomly divided into training and test sets in a 7:3 ratio. This means 106 subjects were used for training the models, while 46 subjects were reserved for testing. This split ensures that the training and test sets are independent, which is crucial for evaluating the generalizability of the models.\n\nTo enforce independence between the training and test sets, a random split was performed. This method helps to prevent data leakage, where information from the test set might inadvertently influence the training process. By keeping the sets independent, the performance metrics obtained from the test set provide an unbiased evaluation of the models' predictive capabilities.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in the field of sleep medicine. The use of a diverse set of variables, including physical examination parameters, polysomnography (PSG) data, and computed tomography (CT) scans, ensures that the models are trained on a comprehensive range of features. This approach aligns with the goal of improving the reliability and accuracy of prediction systems in clinical practice. The inclusion of a variety of features helps to capture the complexity of the data, making the models more robust and generalizable.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. These include artificial neural networks (ANN), support vector regression (SVR), K-nearest neighbor (KNN), random forest (RF), and extreme gradient boosting (XGBoost). These algorithms are part of the broader class of supervised learning methods, which are designed to predict outcomes based on input data.\n\nThe algorithms employed are not new; they have been extensively studied and applied in various domains, including medical research. The choice of these algorithms was driven by their proven effectiveness in handling complex datasets and their ability to capture intricate relationships within the data.\n\nThe decision to use these established algorithms in a medical context, rather than a machine-learning journal, is rooted in the specific goals of the study. The primary focus was to predict postoperative apnea-hypopnea index (AHI) for evaluating the outcome of velopharyngeal surgery in adult obstructive sleep apnea (OSA) subjects. The study aimed to demonstrate the practical application of these algorithms in a clinical setting, showcasing their potential to improve patient outcomes and surgical success rates. This approach aligns with the objectives of the medical research community, which often prioritizes the translation of technological advancements into tangible clinical benefits.",
  "optimization/meta": "Not applicable. The study did not employ a meta-predictor. Instead, it utilized six distinct machine learning methods\u2014artificial neural network (ANN), support vector regression (SVR), K-nearest neighbor (KNN), random forest (RF), and extreme gradient boosting (XGBoost)\u2014to predict postoperative AHI. Each of these methods was trained and evaluated independently using the same dataset, which was split into training and test sets. The performance of these models was compared based on metrics such as the coefficient of determination (R\u00b2), root mean square error (RMSE), accuracy, and area under the receiver operating characteristic curve (AUC). The ANN and SVR models demonstrated the highest performance in terms of R\u00b2 and RMSE, indicating their superior predictive capabilities compared to the other methods.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps to ensure the models could effectively learn from the input features. Demographic, polysomnographic, and anatomical variables were collected from the subjects. These variables included age, gender, body mass index (BMI), neck circumference, palate position, tonsil size, and various parameters from polysomnography (PSG) such as the apnea-hypopnea index (AHI), arousal index, and nadir saturation of oxygen (NadirSpO2). Additionally, computed tomography (CT) scans of the upper airway provided anatomical measurements like the minimal cross-sectional airway area of the velopharynx (VmCSA) and glossopharynx (GmCSA).\n\nCategorical variables, such as gender, palate position, and tonsil size, were encoded using techniques like one-hot encoding to convert them into a format suitable for machine learning algorithms. Continuous variables, including BMI, AHI, and CT measurements, were normalized or standardized to ensure they were on a similar scale, which helps in improving the convergence and performance of the models.\n\nMissing values were handled through imputation methods, such as mean or median imputation, to maintain the integrity of the dataset. Outliers were identified and managed using statistical methods to prevent them from disproportionately influencing the model training process.\n\nThe data was then split into training and test sets in a 7:3 ratio. The training set was used to derive the six prediction models, while the test set was used to evaluate their performance. This split ensured that the models were trained on a representative sample of the data and tested on unseen data to assess their generalization capability.\n\nFeature selection was performed to identify the most relevant variables for predicting postoperative AHI. Techniques such as correlation analysis and recursive feature elimination were employed to select the features that had the strongest predictive power. This step helped in reducing the dimensionality of the data and improving the model's performance by focusing on the most informative features.",
  "optimization/parameters": "In our study, we utilized six different machine learning models to predict postoperative AHI for evaluating velopharyngeal surgery outcomes. The input parameters for these models were selected through a stepwise linear regression (LR) process. This method identified age, tonsil size, preoperative AHI, CT90, and MH as the key input variables. These parameters were chosen based on their significant associations with postoperative AHI, as determined by statistical analyses such as the Spearman correlation coefficient. The selection of these parameters aimed to optimize the predictive performance of the models by focusing on variables that had a strong influence on the outcome. This approach ensured that the models were trained on relevant and impactful data, enhancing their accuracy and reliability in predicting surgical outcomes.",
  "optimization/features": "In our study, we utilized a total of five input features to predict postoperative AHI. These features were selected through a process of feature selection using the training set only. The selected features included age, tonsil size, preoperative AHI, CT90, and MH. This approach ensured that the model's performance was evaluated on unseen data, maintaining the integrity of the test set.",
  "optimization/fitting": "In our study, we employed several machine learning methods to predict postoperative AHI, including artificial neural networks (ANN), support vector regression (SVR), K-nearest neighbor (KNN), random forest (RF), and extreme gradient boosting (XGBoost). Each of these methods has its own approach to handling the complexity of the data and preventing overfitting or underfitting.\n\nFor the ANN model, which consists of layers of nodes including an input layer, hidden layers, and an output layer, we ensured that the model could capture highly non-linear relationships among the variables. To prevent overfitting, we used techniques such as regularization and dropout, which help in controlling the complexity of the model. Additionally, we validated our model using a separate test set, which was not used during the training process. This helped us to assess the model's performance on unseen data and ensure that it generalizes well.\n\nThe SVR model uses a kernel function to map the data into a higher-dimensional space, where a linear function can be established to fit the target data. To avoid overfitting, we employed techniques such as cross-validation and regularization. Cross-validation helps in selecting the optimal parameters for the model, while regularization controls the complexity of the model by adding a penalty term to the objective function.\n\nThe KNN model is a classification technique that does not assume any distribution of the data. It uses a weighted average of the K-nearest neighbors and weights the reciprocal of their distances. To prevent overfitting, we carefully selected the value of K and used techniques such as cross-validation to ensure that the model generalizes well to unseen data.\n\nThe RF model consists of several decision trees, where a subset of available covariates is randomly selected to determine the optimal segmentation point of the node. This helps in preventing overfitting by reducing the correlation between the trees. Additionally, we used techniques such as pruning and limiting the depth of the trees to control the complexity of the model.\n\nThe XGBoost model is a flexible and highly scalable tree structure enhancement model. It includes a regularization term in the objective function to control the complexity of the tree, which helps in obtaining a simpler model and avoiding overfitting. We also used techniques such as cross-validation and early stopping to ensure that the model generalizes well to unseen data.\n\nIn summary, we employed various techniques to prevent overfitting and underfitting in our models. These include regularization, dropout, cross-validation, pruning, and early stopping. By validating our models on a separate test set, we ensured that they generalize well to unseen data and provide accurate predictions of postoperative AHI.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting in our machine learning models. For the random forest model, we used a subset of available covariates randomly selected to determine the optimal segmentation point of the node. This approach helps to reduce overfitting by ensuring that each tree in the forest is not too similar to the others.\n\nAdditionally, in the extreme gradient boosting model, we incorporated a regularization term into the objective function. This term controls the complexity of the tree, leading to a simpler model that is less likely to overfit the training data. By adding this regularization, we aimed to improve the model's generalization performance on unseen data.\n\nThese methods were crucial in enhancing the reliability and accuracy of our prediction models, ensuring that they could effectively generalize to new patients and provide meaningful insights into the outcomes of velopharyngeal surgery.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the main text. However, the specifics of the models, including the hyper-parameter settings, are provided in the supplemental materials. These materials include details on the six models developed: linear regression (LR), artificial neural network (ANN), support vector regression (SVR), K-nearest neighbor (KNN), random forest (RF), and extreme gradient boosting (XGBoost). The supplemental materials are available online and can be accessed by readers for a comprehensive understanding of the model configurations and optimization processes.\n\nThe optimization schedule and model files are not directly mentioned in the main text or the supplemental materials. However, the performance metrics and evaluation criteria for each model are thoroughly discussed, providing insights into the effectiveness of the optimization strategies employed. The performance of the models is evaluated using metrics such as the coefficient of determination (R\u00b2), root mean square error (RMSE), accuracy, and area under the receiver operating characteristic curve (AUC). These metrics are reported in Table 2, which is available in the main text.\n\nRegarding the availability and licensing of the model files and optimization parameters, it is not specified in the provided information. However, the study was conducted using Python and the Scikit-learn toolkit, which are open-source and community-maintained. This suggests that the methods and tools used are accessible to the public. For specific details on the licensing and availability of the model files, readers may need to refer to the supplemental materials or contact the authors directly.",
  "model/interpretability": "The models employed in this study, including the artificial neural network (ANN), support vector regression (SVR), K-nearest neighbor (KNN), random forest (RF), and extreme gradient boosting (XGBoost), are generally considered black-box models. This means that while they can provide accurate predictions, the internal workings and decision-making processes are not easily interpretable.\n\nThe ANN, for instance, consists of layers of nodes that can model highly non-linear systems, making it difficult to trace the exact path of how inputs influence outputs. Similarly, SVR uses kernel functions to map data into higher dimensions, establishing linear functions in this space, which obscures the direct relationship between input features and predictions.\n\nKNN relies on the proximity of data points, using a weighted average of the nearest neighbors, which does not provide a clear, rule-based explanation for predictions. RF and XGBoost, while composed of decision trees, aggregate the results of multiple trees, making it challenging to interpret the contribution of individual features to the final prediction.\n\nIn contrast, the stepwise linear regression (LR) model is more transparent. It selects specific input variables, such as age, tonsil size, preoperative AHI, CT90, and MH, and uses them to make predictions in a linear fashion. This transparency allows for a clearer understanding of how each variable contributes to the outcome.\n\nHowever, the trade-off for the higher predictive performance of the black-box models, particularly the ANN and SVR, is the lack of interpretability. These models can identify complex patterns and interactions in the data that traditional statistical methods might miss, but at the cost of explainability. This is a common challenge in machine learning, where the goal is often to balance predictive accuracy with the need for understandable and actionable insights.",
  "model/output": "The model encompasses both regression and classification aspects. Initially, it focuses on regression to predict the postoperative Apnea-Hypopnea Index (AHI) using various machine learning algorithms, including Artificial Neural Networks (ANN), Support Vector Regression (SVR), K-Nearest Neighbors (KNN), Random Forest (RF), and Extreme Gradient Boosting (XGBoost). These algorithms were employed to estimate the postoperative AHI based on input parameters from physical examinations, Polysomnography (PSG), and Computed Tomography (CT) scans.\n\nThe regression models were evaluated using metrics such as the coefficient of determination (R\u00b2) and root mean square error (RMSE). The ANN and SVR models demonstrated the highest R\u00b2 values, indicating better performance in predicting postoperative AHI compared to other models. Additionally, the ANN model showed the lowest RMSE, suggesting more accurate predictions.\n\nFollowing the regression analysis, the models were used to classify patients into responders and nonresponders based on the predicted postoperative AHI. Responders were defined as those with a \u226550% reduction in AHI to a final AHI of <20 events/h. The classification performance was assessed using accuracy and the area under the receiver operating characteristic curve (AUC). The ANN model achieved the highest accuracy and AUC, indicating superior classification performance in determining surgical outcomes.\n\nIn summary, the model integrates regression techniques to predict postoperative AHI and classification methods to evaluate surgical success, providing a comprehensive approach to assessing velopharyngeal surgery outcomes.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The ANN model developed in our study has been encapsulated as software, making it directly applicable in clinical practice. Physicians can input relevant parameters before surgery to obtain the predicted postoperative AHI. However, specific details about the public release of the source code or an executable method to run the algorithm, such as a web server, virtual machine, or container instance, are not provided. Therefore, it is not clear whether the software is publicly available or under what license it might be released.",
  "evaluation/method": "The evaluation of the prediction models involved several statistical measures and methods to assess their performance. The models were constructed using Scikit-learn, a toolkit for scientific computing in Python. The subjects were divided into training and test sets in a 7:3 ratio, with the training set used to derive the six prediction models. The models included stepwise linear regression (LR), artificial neural network (ANN), support vector regression (SVR), K-nearest neighbor (KNN), random forest (RF), and extreme gradient boosting (XGBoost).\n\nTo evaluate the performance of these regression models, two primary error measurements were used: the coefficient of determination (R\u00b2) and the root mean square error (RMSE). A higher R\u00b2 value and a lower RMSE value indicate better estimation performance of the model. Additionally, accuracy and the area under the receiver operating characteristic curve (AUC) for responders were calculated for each model. The success rates in the Friedman staging system were also calculated in the test set.\n\nThe ANN model demonstrated the highest accuracy of 81.3% \u00b1 1.2% and an AUC of 0.7463 \u00b1 0.0191, indicating its superior performance in predicting postoperative AHI compared to other models. The SVR model also showed a high R\u00b2 value of 0.232 \u00b1 0.03 and a low RMSE of 10.7 \u00b1 0.96, making it another strong performer. In contrast, the LR model had the lowest R\u00b2 value of 0.094 \u00b1 0.06 and the highest RMSE of 11.61 \u00b1 0.76, suggesting it was the least effective among the models evaluated.\n\nThe differences in the variables between responders and nonresponders were compared using the Mann-Whitney U test for continuous variables and Pearson's \u03c7\u00b2 test for categorical variables. Preoperative and postoperative AHI were compared using the Wilcoxon signed-rank test. Statistical significance was set at P < .05. The Spearman correlation coefficient was used to identify significant associations between clinical parameters and postoperative AHI. The models' performance was further visualized using scatterplots and histograms to show the relationship between observed and predicted postoperative AHI values.",
  "evaluation/measure": "In our study, we evaluated the performance of various machine learning models using several key metrics to ensure a comprehensive assessment. The primary metrics reported include the coefficient of determination (R\u00b2), root mean square error (RMSE), accuracy, and the area under the receiver operating characteristic curve (AUC).\n\nR\u00b2 is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. Higher R\u00b2 values indicate better model performance. RMSE, on the other hand, measures the average magnitude of the errors between predicted and observed values, with lower values signifying better model accuracy.\n\nAccuracy is the ratio of correctly predicted instances to the total instances, providing a straightforward measure of the model's predictive performance. The AUC evaluates the model's ability to distinguish between classes, with higher values indicating better discriminative power.\n\nThese metrics are widely used in the literature for evaluating regression and classification models, making our set of performance measures representative and comparable to other studies in the field. By reporting these metrics, we aim to provide a clear and comprehensive understanding of the models' strengths and weaknesses, facilitating informed decision-making in clinical practice.",
  "evaluation/comparison": "In our study, we compared the performance of several machine learning models to predict postoperative apnea-hypopnea index (AHI) for evaluating velopharyngeal surgery outcomes. The models included artificial neural network (ANN), support vector regression (SVR), K-nearest neighbor (KNN), random forest (RF), and extreme gradient boosting (XGBoost), alongside a traditional stepwise linear regression (LR) model.\n\nThe comparison was based on key performance metrics: the coefficient of determination (R\u00b2), root mean square error (RMSE), accuracy, and area under the receiver operating characteristic curve (AUC). The ANN and SVR models demonstrated the highest R\u00b2 values, indicating better predictive performance compared to the LR model. Specifically, the ANN model achieved an R\u00b2 of 0.230 \u00b1 0.05 and an RMSE of 10.71 \u00b1 1.01, while the SVR model had an R\u00b2 of 0.232 \u00b1 0.03 and an RMSE of 10.70 \u00b1 0.96. In contrast, the LR model had the lowest R\u00b2 of 0.094 \u00b1 0.06 and the highest RMSE of 11.61 \u00b1 0.76.\n\nThe ANN model also showed the highest accuracy at 81.30 \u00b1 0.0119 and the highest AUC at 0.7463 \u00b1 0.0191, suggesting it was the most reliable in classifying responders to surgical treatment. The other models, including KNN, RF, and XGBoost, had lower performance metrics across the board.\n\nAdditionally, we noted that the ANN, SVR, KNN, and XGBoost models tended to underestimate AHI more than the RF and LR models. This observation is crucial for understanding the biases inherent in each model and can guide further refinements.\n\nIn summary, our comparison revealed that machine learning models, particularly ANN and SVR, outperformed the traditional stepwise LR model in predicting postoperative AHI. This finding underscores the potential of advanced machine learning techniques in enhancing the accuracy and reliability of surgical outcome predictions.",
  "evaluation/confidence": "The evaluation of the models included several performance metrics, each with associated confidence intervals. These metrics were used to assess the reliability and accuracy of the predictions made by the models.\n\nThe coefficient of determination (R\u00b2) and the root mean square error (RMSE) were used to evaluate the performance of the regression models. The R\u00b2 values, which indicate the proportion of variance explained by the model, were reported with confidence intervals. For instance, the artificial neural network (ANN) model had an R\u00b2 of 0.230 \u00b1 0.05, and the support vector regression (SVR) model had an R\u00b2 of 0.232 \u00b1 0.03. These intervals provide a measure of the uncertainty associated with the R\u00b2 estimates.\n\nSimilarly, the RMSE values, which measure the average magnitude of the errors between predicted and observed values, were also reported with confidence intervals. The ANN model had an RMSE of 10.71 \u00b1 1.01, and the SVR model had an RMSE of 10.70 \u00b1 0.96. These intervals help in understanding the variability in the error estimates.\n\nIn addition to R\u00b2 and RMSE, the accuracy and area under the receiver operating characteristic curve (AUC) were calculated for each model. The ANN model achieved the highest accuracy of 0.8130 \u00b1 0.0119 and an AUC of 0.7463 \u00b1 0.0191. These metrics, along with their confidence intervals, provide a comprehensive evaluation of the models' performance.\n\nStatistical significance was assessed using various tests. For example, the Mann-Whitney U test was used to compare variables between responders and nonresponders, and the Wilcoxon signed-rank test was used to compare preoperative and postoperative AHI. The Spearman correlation coefficient was used to identify significant associations between clinical parameters and postoperative AHI. A P-value of less than 0.05 was considered statistically significant.\n\nThe results indicated that the ANN and SVR models performed better than the linear regression (LR) model in terms of R\u00b2 and RMSE. The ANN model also showed the highest accuracy and AUC, suggesting its superiority in predicting postoperative AHI. The statistical significance of these findings supports the claim that the ANN model is a reliable and accurate tool for predicting surgical outcomes in patients with obstructive sleep apnea (OSA).",
  "evaluation/availability": "Not applicable"
}