{
  "publication/title": "Prediction of Acute Kidney Injury With a Machine Learning Algorithm Using Electronic Health Record Data.",
  "publication/authors": "Mohamadlou H, Lynn-Palevsky A, Barton C, Chettipally U, Shieh L, Calvert J, Saber NR, Das R",
  "publication/journal": "Canadian journal of kidney health and disease",
  "publication/year": "2018",
  "publication/pmid": "30094049",
  "publication/pmcid": "PMC6080076",
  "publication/doi": "10.1177/2054358118776326",
  "publication/tags": "- acute kidney injury\n- machine learning\n- electronic health record data\n- prediction\n- early detection\n- algorithm\n- AKI\n- patient outcomes\n- clinical intervention\n- retrospective study",
  "dataset/provenance": "The datasets used in this study were sourced from two major medical centers: the Beth Israel Deaconess Medical Center (BIDMC) in Boston, Massachusetts, and the Stanford University Medical Center in Stanford, California. The BIDMC data were collected from the Medical Information Mart for Intensive Care III (MIMIC-III) version 1.3 database, which was compiled by the MIT Laboratory for Computational Physiology. This database contains 61,532 inpatient ICU encounters collected between 2001 and 2012. The Stanford University dataset includes 286,797 inpatient encounters from all hospital wards, spanning from December 2008 to May 2017.\n\nFor our analysis, we focused on patients whose hospital stays lasted between 5 and 1000 hours. From the BIDMC dataset, 50,219 patients met this criterion, while 138,956 patients from the Stanford dataset were included. Further filtering was applied to ensure that patients had at least one measurement of the required variables, including heart rate, respiratory rate, temperature, Glasgow Coma Scale, serum creatinine, and urine output. Additionally, only patients with available age data and who were 18 years or older were considered. This resulted in 583 patients from BIDMC and 10,162 patients from Stanford being used to train and test the classifier.\n\nThe data collection process was passive and did not impact patient safety. Both datasets were deidentified in compliance with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule, ensuring that the studies performed on this deidentified data constituted nonhuman subject research. Therefore, no institutional or ethical approvals were required for this study. The datasets have been utilized in previous research and by the community, particularly the MIMIC-III database, which is widely used for medical research and machine learning applications.",
  "dataset/splits": "In our study, we utilized data from two distinct medical centers: Beth Israel Deaconess Medical Center (BIDMC) and Stanford University Medical Center. For the BIDMC dataset, we initially had 52,917 patients, but after applying inclusion criteria, we narrowed it down to 583 patients who had the required measurements and were at least 18 years old. These 583 patients were used for training and testing the classifier.\n\nFor the Stanford dataset, we started with 286,797 patients. After applying the same inclusion criteria, we ended up with 10,162 patients who had the required measurements and were at least 18 years old. These 10,162 patients were also used for training and testing the classifier.\n\nThe data sets were randomly divided, with randomization based on patient identification number. We employed 3-fold cross-validation for training the models, resulting in 30 independently trained models. Each model was trained using different splits of the data, ensuring a robust evaluation of the algorithm's performance.\n\nAdditionally, for assessing the algorithm under the KDIGO criteria, we used 10-fold cross-validation. This involved separately training the algorithm on the BIDMC and Stanford datasets and then evaluating its performance on test sets from the BIDMC dataset. This approach helped in validating the algorithm's generalizability and performance across different patient populations.",
  "dataset/redundancy": "The datasets used in this study were split randomly, with the randomization process based on patient identification numbers. This ensured that the training and test sets were independent. To enforce this independence, randomization was performed before the training of each model. The datasets were divided into training and test sets using cross-validation techniques. Specifically, for the main analysis, 30 independently trained models were used, each trained using 3-fold cross-validation. The reported metrics are the average of these 30 models. Additionally, for assessing the algorithm under the KDIGO criteria, 10-fold cross-validation was employed.\n\nThe datasets included patients from two sources: the Beth Israel Deaconess Medical Center (BIDMC) and Stanford University Medical Center. The BIDMC dataset contains only patients admitted to the ICU, representing a more critically ill population, while the Stanford dataset includes all inpatients. This difference in patient populations is a notable aspect compared to previously published machine learning datasets, which often focus on more homogeneous groups such as ICU patients or specific surgical populations. The BIDMC dataset skewed older and more male, with a higher prevalence of acute kidney injury (AKI) compared to the Stanford dataset. These demographic differences highlight the variability in patient populations and the robustness of the machine learning algorithm in handling diverse data.",
  "dataset/availability": "The deidentified patient data used in this study is publicly available. It comes from the Medical Information Mart for Intensive Care III (MIMIC-III) version 1.3 database. This database can be accessed at https://mimic.physionet.org/. The data is provided under a license that ensures it is deidentified and compliant with the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule. This compliance means that the data constitutes nonhuman subject research, thus no institutional or ethical approvals were required for this study. The availability of this data allows for reproducibility and further research by other scientists in the field.",
  "optimization/algorithm": "The machine-learning algorithm used in this study is not a new class of algorithm. It is a machine learning approach that has been evaluated and tested on a mixed-ward population, including adults of all ages. This method provides advantages over currently used systems, such as the SOFA score, which is a generalized disease severity score. The machine learning algorithm is specific to acute kidney injury (AKI) prediction, allowing clinicians to more rapidly determine the cause of patient deterioration and administer appropriate treatments in a timely manner.\n\nThe flexibility of the machine learning algorithm (MLA) allows it to operate at a continuous range of sensitivity-specificity pairs. This means that if fewer alerts, greater specificity, and 72-hour notice were preferable over more alerts, greater sensitivity, and nearer-onset notice, the MLA could function accordingly. This flexibility is not available for a rules-based score like SOFA.\n\nThe algorithm was developed and validated using data from two different hospital settings: the Beth Israel Deaconess Medical Center (BIDMC) and Stanford Medical Center. The BIDMC data included only patients admitted to the ICU, while the Stanford data set contained information about inpatient stays from all hospital wards. This diversity in data sets suggests that the algorithm can identify patients at risk of AKI onset in a variety of hospital settings.\n\nThe performance of the MLA was compared with that of the SOFA score, and the MLA demonstrated superior performance in terms of AUROC, accuracy, and diagnostic odds ratio (DOR) at all prediction windows and for each data set. The MLA also had higher or comparable positive likelihood ratios (LR+) and comparable negative likelihood ratios (LR\u2212) at onset and for all prediction windows.\n\nThe algorithm's performance was assessed using 10-fold cross-validation, and the reported metrics are the average of each of the 10 models generated by this process. The algorithm demonstrated high AUROC, sensitivity, and specificity for detecting stage 2 or stage 3 AKI under the KDIGO criteria. When trained on patient data from Stanford and tested on data from BIDMC, the algorithm demonstrated AUROC above 0.75 for AKI detection up to 24 hours in advance of onset.\n\nThe machine learning approach described here results in a prediction tool that demonstrates strong predictive performance up to 72 hours in advance of stage 2 or stage 3 AKI onset, under both the NHS and KDIGO criteria for AKI. The algorithm requires only five commonly collected patient measurements as inputs, making it feasible for use in a large portion of the hospital population. This tool could provide clinicians with the opportunity to improve patient outcomes through earlier AKI detection and subsequent intervention.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding process involved several steps to ensure that the machine-learning algorithm could effectively utilize the patient data. Initially, all data from both datasets were processed using custom database queries, which retrieved the necessary information. These data were then converted into flat .csv files, facilitating easy manipulation and analysis.\n\nEach measurement or observation was associated with a timestamp and a measurement type key. This approach ensured that the data were structured in a way that allowed for temporal analysis, which is crucial for predicting acute kidney injury (AKI) onset. Demographics and other patient characteristics, such as age, were stored using a similar keyed retrieval mechanism, enabling efficient access and integration into the algorithm.\n\nThe data were discretized into 1-hour intervals starting from the time of the first recorded patient measurement. If multiple observations of the same patient measurement were taken within a given hour, those measurements were averaged to produce a single value for that hour. This standardization ensured that the rate at which measurements were fed into the algorithm was consistent across all patients.\n\nIn cases where no measurement of a clinical variable was available for a given hour, a carry-forward imputation method was employed. This method filled the missing measurement with the most recently available previous measurement, ensuring that the data remained causal and temporally coherent. This imputation technique is particularly important for maintaining the integrity of the data when dealing with time-series predictions.\n\nThe required measurements for inclusion in the study were heart rate, respiratory rate, temperature, Glasgow Coma Scale, and serum creatinine. These measurements were chosen because they are commonly collected in clinical settings, making the algorithm practical for widespread use.\n\nThe data were then divided randomly, with randomization based on patient identification number. This step was crucial for ensuring that the training and testing datasets were representative of the overall patient population. The random division helped to mitigate any potential biases that could arise from non-random selection processes.\n\nIn summary, the data encoding process involved converting raw data into a structured format, standardizing the measurement intervals, and handling missing data through imputation. These steps were essential for preparing the data for the machine-learning algorithm, which aimed to predict AKI onset with high accuracy and reliability.",
  "optimization/parameters": "In our study, we utilized a set of five commonly collected patient measurements as input parameters for our machine learning algorithm. These parameters were chosen because they are frequently and easily collected at the bedside, even before clinical suspicion of acute kidney injury (AKI) is present. The specific measurements included heart rate, respiratory rate, temperature, Glasgow Coma Scale (GCS), and serum creatinine (SCr). Additionally, the patient's age was included in the causal feature vector.\n\nFor each prediction time, we considered the previous five hourly values of each of these measurements. This approach allowed us to capture temporal dynamics and trends in the patient's physiological state, which are crucial for predicting AKI onset.\n\nThe selection of these parameters was driven by their availability and relevance to AKI prediction. By focusing on these five measurements, we aimed to create a practical and widely applicable prediction tool that does not rely on less frequently collected or more invasive data. This choice also aligns with the goal of early AKI detection and the generation of electronic alerts for affected patients, as outlined in the National Health Service (NHS) England AKI Algorithm, which we implemented as our gold standard.",
  "optimization/features": "The input features used in our machine learning algorithm (MLA) were selected based on their frequent and easy collection at the bedside, even before clinical suspicion of acute kidney injury (AKI) is present. Specifically, the features used were heart rate, respiratory rate, temperature, serum creatinine (SCr), and Glasgow Coma Scale (GCS). These measurements were chosen for their availability and relevance to AKI detection.\n\nFor each prediction time, the feature vector included the previous 5 hourly values of each of these measurements, along with the patient\u2019s age. This resulted in a total of 26 features (5 measurements \u00d7 5 hourly values + age).\n\nFeature selection was not performed in the traditional sense of choosing a subset of features from a larger set. Instead, the features were selected a priori based on clinical relevance and data availability. The selection process was informed by previous research and the need for features that could be easily and frequently collected.\n\nThe data processing methods ensured that the rate at which measurements were fed into the algorithm was standardized across patients. If multiple observations of the same patient measurement were taken within a given hour, those measurements were averaged to produce a single value for that hour. If no measurement of a clinical variable was available for a given hour, a carry-forward imputation method was employed to fill the missing measurement with the most recently available previous measurement.\n\nThe use of these specific features and the method of handling missing data were designed to ensure that the algorithm could be applied in real-world settings where data collection may not be continuous or complete. The features were selected and processed in a manner that would allow for robust and reliable predictions of AKI.",
  "optimization/fitting": "The fitting method employed in this study involved a machine learning algorithm (MLA) that was trained and tested using cross-validation techniques. To address the potential issue of overfitting, given the large number of parameters relative to the training points, several measures were taken.\n\nFirstly, the data sets were randomly divided based on patient identification numbers, ensuring that the training and testing sets were independent. This randomization was performed before the training of each model, which helps in mitigating the risk of overfitting by ensuring that the model generalizes well to unseen data.\n\nSecondly, the reported metrics are the average of 30 independently trained models, each using 3-fold cross-validation. This approach not only provides a robust estimate of the model's performance but also helps in reducing the variance and preventing overfitting. Additionally, for assessing the algorithm under the KDIGO criteria, 10-fold cross-validation was used, further ensuring that the model's performance is consistent across different subsets of the data.\n\nTo rule out underfitting, the performance of the MLA was compared with that of the SOFA score, a widely used clinical scoring system. The MLA demonstrated superior performance in terms of AUROC, accuracy, and diagnostic odds ratio (DOR) across various prediction windows and data sets. This comparison indicates that the MLA is capable of capturing the underlying patterns in the data effectively, thus avoiding underfitting.\n\nMoreover, the algorithm was tested on two different data sets (BIDMC and Stanford), which have distinct demographic characteristics. The consistent performance across these diverse data sets suggests that the model is generalizable and not underfitted to any specific data set.\n\nIn summary, the use of cross-validation, independent training sets, and comparison with established clinical scores ensures that the fitting method is robust, addressing both overfitting and underfitting concerns.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study is based on an ensemble of decision trees, specifically boosted decision tree ensembles. This type of model is generally considered to be a \"gray box\" rather than a completely transparent model. While decision trees themselves are interpretable, as they provide a clear, rule-based structure that can be easily visualized and understood, the ensemble nature of boosted decision trees can make the overall model more complex and less straightforward to interpret directly.\n\nBoosted decision tree ensembles work by combining the predictions of multiple decision trees, each of which is trained to correct the errors of the previous ones. This process can lead to a model that is highly accurate but also more opaque, as the contributions of individual trees to the final prediction are not always immediately clear.\n\nHowever, there are techniques available to gain insights into the model's decision-making process. Feature importance scores, for instance, can be derived from the ensemble to understand which input variables (such as heart rate, respiratory rate, temperature, Glasgow Coma Scale, and serum creatinine) have the most significant impact on the model's predictions. Additionally, tools like SHAP (SHapley Additive exPlanations) values can be used to provide a more granular understanding of how each feature contributes to individual predictions.\n\nIn summary, while the model is not entirely transparent due to its ensemble nature, it is possible to extract interpretable information through various techniques. This allows clinicians and researchers to gain insights into the factors driving the model's predictions, even if the model itself is not as straightforward to interpret as a single decision tree.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the occurrence of acute kidney injury (AKI) in patients. Specifically, it focuses on detecting stage 2 or stage 3 AKI, which are severe forms of the condition. The model uses a machine learning approach, particularly an ensemble of decision trees, to classify patients based on their likelihood of developing AKI within specified time windows (0, 12, 24, 48, and 72 hours in advance).\n\nThe performance of the model is evaluated using metrics such as the area under the receiver operating characteristic curve (AUROC), sensitivity, and specificity. For instance, the model achieves an AUROC of 0.795 for 24-hour predictions, 0.761 for 48-hour predictions, and 0.728 for 72-hour predictions. These metrics indicate the model's ability to distinguish between patients who will develop AKI and those who will not.\n\nThe model's output provides a continuous range of sensitivity-specificity pairs, allowing clinicians to adjust the operating point based on their preferences for fewer alerts with higher specificity or more alerts with higher sensitivity. This flexibility is a significant advantage over traditional rules-based scores like the SOFA score, which do not offer such adaptability.\n\nThe model's performance was tested on two different datasets: one from Beth Israel Deaconess Medical Center (BIDMC) and another from Stanford Medical Center. The results show that the model maintains high AUROC, sensitivity, and specificity across both datasets, demonstrating its robustness and generalizability. However, it is important to note that the model's performance may vary when applied to different patient populations or clinical settings, as the study was retrospective and focused on adult patients older than 18 years.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the machine learning algorithm (MLA) involved several rigorous methods to ensure its robustness and generalizability. The data sets were randomly divided based on patient identification numbers, and the algorithm's performance was measured using various metrics, including area under the receiver operating characteristic (AUROC), accuracy, diagnostic odds ratio (DOR), and positive and negative likelihood ratios (LR+ and LR\u2212). These metrics were averaged over 30 independently trained models, each utilizing 3-fold cross-validation. Randomization was performed before training each model to ensure unbiased results.\n\nTo compare the MLA's performance, the same metrics were obtained using the Sequential Organ Failure Assessment (SOFA) organ dysfunction score. The SOFA score was calculated using SpO2/FiO2 ratios instead of PaO2/FiO2 ratios due to data availability. Statistical comparisons were conducted using pairwise, single-tailed t-tests with a significance level set at P < .01.\n\nAdditionally, the algorithm was evaluated under the Kidney Disease: Improving Global Outcomes (KDIGO) criteria using 10-fold cross-validation. The algorithm was separately trained on data from Beth Israel Deaconess Medical Center (BIDMC) and Stanford Medical Center, and its performance was assessed on test sets from the BIDMC data set. This approach allowed for a thorough evaluation of the algorithm's ability to predict acute kidney injury (AKI) across different patient populations and settings.",
  "evaluation/measure": "The performance metrics reported in this study include the area under the receiver operating characteristic curve (AUROC), accuracy, diagnostic odds ratio (DOR), and positive and negative likelihood ratios (LR+ and LR\u2212). These metrics were obtained by the machine learning algorithm (MLA) via a method involving 30 independently trained models, each using 3-fold cross-validation. The reported metrics are the average of these models.\n\nThe AUROC is a widely used metric in the literature for evaluating the performance of predictive models, particularly in medical diagnostics. It provides a single scalar value that represents the ability of the model to distinguish between positive and negative classes across all possible classification thresholds. Accuracy, DOR, and likelihood ratios are also commonly reported metrics that offer additional insights into the model's performance.\n\nThe use of these metrics is representative of the literature, as they are standard in evaluating the performance of predictive models in medical research. The AUROC, in particular, is a robust metric that is less sensitive to class imbalances compared to accuracy, making it a preferred choice for evaluating models in medical diagnostics. The inclusion of DOR and likelihood ratios provides a more comprehensive evaluation of the model's diagnostic performance.\n\nThe metrics were compared with those obtained by the Sequential Organ Failure Assessment (SOFA) score, a commonly used clinical scoring system for assessing organ dysfunction. The SOFA score was calculated using SpO2/FiO2 ratios instead of PaO2/FiO2 ratios due to data availability. Statistical comparisons were performed using pairwise, single-tailed t-tests with a significance level set at P < .01.\n\nIn summary, the reported performance metrics are comprehensive and representative of the literature. They provide a thorough evaluation of the MLA's predictive performance compared to the SOFA score, using standard metrics that are widely accepted in the field of medical diagnostics.",
  "evaluation/comparison": "In our evaluation, we performed a comprehensive comparison of our machine learning algorithm (MLA) with the Sequential Organ Failure Assessment (SOFA) score, which is a widely used and publicly available method for assessing organ dysfunction. This comparison was conducted on two benchmark datasets: one from Beth Israel Deaconess Medical Center (BIDMC) and another from Stanford Medical Center.\n\nThe SOFA score was calculated using the methodology described by Pandharipande et al., with a modification to use SpO2/FiO2 ratios instead of PaO2/FiO2 ratios due to data availability. This adjustment ensured that the comparison was fair and relevant to the data at hand.\n\nWe measured several performance metrics, including the area under the receiver operating characteristic curve (AUROC), accuracy, diagnostic odds ratio (DOR), and positive and negative likelihood ratios (LR+ and LR\u2212). These metrics were obtained through a rigorous process involving 30 independently trained models, each using 3-fold cross-validation. Randomization was performed before training each model to ensure the robustness of our results.\n\nStatistical comparisons were performed using pairwise, single-tailed t-tests with a significance level set at P < .01. This stringent statistical approach allowed us to confidently assess the performance differences between our MLA and the SOFA score.\n\nIn addition to comparing with the SOFA score, we also evaluated our algorithm under the Kidney Disease: Improving Global Outcomes (KDIGO) criteria. For this evaluation, we used 10-fold cross-validation to train the algorithm separately on the BIDMC and Stanford datasets. The algorithm's performance was then assessed on test sets from the BIDMC dataset.\n\nOverall, our comparison with the SOFA score and the evaluation under the KDIGO criteria provide a thorough assessment of our MLA's performance relative to established methods and benchmarks.",
  "evaluation/confidence": "Confidence intervals were calculated for the area under the receiver operating characteristic (AUROC) of the machine learning algorithm (MLA). These intervals provide a range within which the true AUROC value is expected to lie, giving an indication of the precision of the estimates.\n\nStatistical comparisons were performed using pairwise, single-tailed t-tests with a significance level set at P < .01. This rigorous threshold ensures that the results are statistically significant, allowing for a confident claim that the MLA outperforms the Sequential Organ Failure Assessment (SOFA) score. The MLA demonstrated superior performance metrics, including higher AUROC, accuracy, and diagnostic odds ratio (DOR), across various prediction windows and datasets. These findings were consistent across different prediction times, reinforcing the reliability of the results. The use of cross-validation techniques, including 3-fold and 10-fold cross-validation, further strengthens the evaluation confidence by ensuring that the model's performance is robust and generalizable.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data sets were drawn from the Beth Israel Deaconess Medical Center (BIDMC) and Stanford University Medical Center, and they contain sensitive patient information. To protect patient privacy and comply with regulations such as the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule, the data were deidentified and used for nonhuman subject research. Therefore, the specific evaluation files cannot be released to the public. However, the methods and processes used for data processing, imputation, and feature creation are detailed in the publication, allowing for reproducibility of the study's findings."
}