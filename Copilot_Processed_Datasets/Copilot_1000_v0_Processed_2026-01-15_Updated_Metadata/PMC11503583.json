{
  "publication/title": "Identifying factors associated with locomotive syndrome using machine learning methods: The third survey of the research on osteoarthritis/osteoporosis against disability study.",
  "publication/authors": "Nakahara E, Iidaka T, Chiba A, Kurasawa H, Fujino A, Shiomi N, Maruyama H, Horii C, Muraki S, Oka H, Kawaguchi H, Nakamura K, Akune T, Tanaka S, Yoshimura N",
  "publication/journal": "Geriatrics & gerontology international",
  "publication/year": "2024",
  "publication/pmid": "38943538",
  "publication/pmcid": "PMC11503583",
  "publication/doi": "10.1111/ggi.14923",
  "publication/tags": "- Associated factor\n- Cohort study\n- Locomotive syndrome\n- Machine learning\n- Prevalence\n- Medical questionnaires\n- Data analysis\n- Statistical methods\n- Geriatric assessment\n- Health outcomes\n- Risk factors\n- Predictive modeling\n- Data cleaning\n- Feature selection\n- Performance metrics",
  "dataset/provenance": "The dataset used in this study originates from the Research on Osteoarthritis/Osteoporosis Against Disability (ROAD) study. This study involved a comprehensive medical questionnaire based on the male osteoporotic fracture study, with additional items tailored for the ROAD study, resulting in a questionnaire consisting of 1335 items. Through data cleaning processes, the number of items was reduced to 332 for analysis. The dataset includes 1575 participants, with a prevalence of locomotive syndrome (LS) at 67.7%. The participants were randomly divided into training, validation, and test datasets, with 1008, 252, and 315 participants respectively, ensuring no overlap between the datasets. The basic attributes included in the dataset are age, sex, weight, and height. Additionally, seven medical questionnaires were used: the Physical Activity Scale for the Elderly (PASE), Life function checklist, European Quality Of Life (QOL)-5 dimensions instrument (EQ5D), Medical Outcomes Study 8-item Short Form (SF-8), Oswestry Disability Index 2.0 (ODI), Western Ontario and McMaster University Osteoarthritis Index (WOMAC), and Loco-check. The dataset has been used to identify factors associated with the presence of LS using machine learning techniques, specifically the LightGBM algorithm in conjunction with the RFECV feature selection method. The dataset has not been shared publicly, and research data are not available for community use.",
  "dataset/splits": "The dataset was divided into three distinct splits: training, validation, and test datasets. The total number of participants was 1575.\n\nThe training dataset comprised 64% of the participants, totaling 1008 individuals. The validation dataset included 16% of the participants, amounting to 252 individuals. The test dataset consisted of 20% of the participants, which is 315 individuals.\n\nThere was no overlap of participants between these datasets, ensuring that each participant was included in only one of the splits. This division was done to address the imbalanced distribution of outcomes, maintaining the same rate of outcome across all splits.",
  "dataset/redundancy": "The dataset consisted of 1575 participants, with a prevalence of locomotive syndrome (LS) at 67.7%. To handle the imbalanced distribution of outcomes, the participants were split into three independent datasets: training, validation, and test. The training dataset comprised 64% of the participants (1008 individuals), the validation dataset included 16% (252 participants), and the test dataset contained 20% (315 participants). This split ensured that each dataset had the same rate of outcome distribution, maintaining the imbalance present in the original data.\n\nTo ensure the independence of these datasets, there was no overlap of participants between the training, validation, and test sets. This independence is crucial for evaluating the model's performance accurately, as it prevents data leakage and ensures that the model's predictions are generalized to unseen data.\n\nComparing this dataset split to previously published machine learning datasets, the approach aligns with common practices in handling imbalanced datasets. The use of separate training, validation, and test sets is standard, ensuring that the model's performance can be reliably assessed. The specific proportions used (64% for training, 16% for validation, and 20% for testing) are somewhat unconventional, as many studies use an 80-20 or 70-30 split. However, the rationale behind this split is to maintain the same rate of outcome distribution across all datasets, which is a robust method for dealing with imbalanced data.",
  "dataset/availability": "The data used in this study is not publicly available. The research data are not shared, as explicitly stated. This decision aligns with ethical considerations and participant consent, ensuring that sensitive information remains confidential. The study was approved by the ethics committees of the University of Tokyo and the Tokyo Metropolitan Institute of Gerontology, and written informed consent was provided by all participants. This approach ensures that the privacy and rights of the participants are protected.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the Light Gradient Boosting Machine (LightGBM) algorithm, which is a type of gradient boosting framework. This algorithm is not new; it has been established and is widely used in the machine learning community for handling large, multidimensional datasets, particularly in medical and healthcare applications.\n\nLightGBM was chosen for its efficiency and effectiveness in managing extensive datasets, making it suitable for our analysis involving 331 items from medical questionnaires. The algorithm's ability to handle high-dimensional data and its computational efficiency were crucial for our feature selection process using the Recursive Feature Elimination with Cross-Validation (RFECV) method.\n\nThe hyperparameters for the LightGBM model were optimized using Optuna, a next-generation hyperparameter optimization framework. This ensured that the model's performance was maximized by fine-tuning the parameters.\n\nThe decision to use LightGBM in this context, rather than publishing it in a machine-learning journal, is due to its established reputation and widespread use in practical applications. The focus of our publication is on identifying factors associated with locomotive syndrome using machine learning methods, rather than introducing a new algorithm. The use of LightGBM aligns with our goal of leveraging proven techniques to achieve reliable and interpretable results in the medical field.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor.\n\nThe machine-learning methods used in the study include LightGBM, a gradient boosting framework that uses tree-based learning algorithms. The LightGBM algorithm was employed in conjunction with Recursive Feature Elimination with Cross-Validation (RFECV), a feature selection method that recursively removes the least important features and builds the model on those remaining features. This process continued until a set of five items remained, which included four basic attributes (sex, age, weight, and height) and one item selected by LightGBM-RFECV.\n\nThe training data was split into training, validation, and test datasets with the same rate of outcome to address the imbalanced distribution of outcomes. The 1575 participants were randomly divided into the training dataset (64%, 1008 participants), the validation dataset (16%, 252 participants), and the test dataset (20%, 315 participants). There was no overlap of participants between the training, validation, and test datasets, ensuring that the training data was independent.",
  "optimization/encoding": "The data used in our study originated from medical questionnaires, which were initially composed of 1335 items. These items underwent a rigorous data cleaning process to reduce redundancy and ensure relevance. This process involved evaluating content, missing value rates, and statistical methods, ultimately leaving us with 332 items for analysis.\n\nThe basic attributes included in the dataset were age, sex, weight, and height. Body mass index was excluded as an explanatory variable due to its strong dependence on height. This left us with 331 items for further analysis. Additionally, seven medical questionnaires were utilized: the Physical Activity Scale for the Elderly (PASE), Life function checklist, European Quality Of Life (QOL)-5 dimensions instrument (EQ5D), Medical Outcomes Study 8-item Short Form (SF-8), Oswestry Disability Index 2.0 (ODI), Western Ontario and McMaster University Osteoarthritis Index (WOMAC), and Loco-check. Missing values in the participants' answers were not filled in.\n\nTo address the imbalanced distribution of outcomes, the dataset was split into training, validation, and test datasets while maintaining the same rate of outcome prevalence. Specifically, 1575 participants were randomly divided into a training dataset (64%, 1008 participants), a validation dataset (16%, 252 participants), and a test dataset (20%, 315 participants). There was no overlap of participants between these datasets.\n\nThe LightGBM algorithm, known for its ability to handle large, multidimensional medical datasets, was employed in conjunction with the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm. This feature selection method recursively removes items based on their importance, ensuring that the most relevant factors are retained. The process continued until a set of five items remained: four basic attributes (sex, age, weight, and height) and one item selected by LightGBM-RFECV. This smallest set of items with the highest receiver operating characteristic area under the curve (ROC-AUC) under 20 items was determined to be the association factors for the presence of locomotive syndrome (LS).\n\nSHAP, a machine learning model interpretation technique, was used to calculate and visualize the effects of these association factors on the presence of LS. This visualization helped in understanding the importance and impact of each factor on the outcome.",
  "optimization/parameters": "In our study, we initially considered 331 parameters, which were derived from various medical questionnaires and basic attributes. To identify the most relevant factors associated with locomotive syndrome (LS), we employed the LightGBM-based Recursive Feature Elimination with Cross-Validation (RFECV) algorithm. This method recursively removes less important features, allowing us to determine the optimal set of parameters.\n\nThe selection process continued until we identified a set of nine items that provided the highest receiver operating characteristic area under the curve (ROC-AUC) under 20 items. This set included four basic attributes (age, sex, weight, and height) and five additional items selected from the Oswestry Disability Index (ODI), Western Ontario and McMaster Universities Osteoarthritis Index (WOMAC), and Loco-check questionnaires.\n\nThe final model used these nine parameters to estimate the presence of LS, demonstrating robust performance metrics. This approach ensured that we focused on the most significant factors, enhancing the model's efficiency and interpretability.",
  "optimization/features": "In our study, we initially considered 331 features as input. These features were derived from a comprehensive medical questionnaire consisting of 1335 items, which was reduced through a data cleaning process that involved assessing content, missing value rates, and statistical methods.\n\nFeature selection was indeed performed using the LightGBM-based Recursive Feature Elimination with Cross-Validation (RFECV) algorithm. This method recursively removes less important features based on their impact on the model's performance. The feature selection process was conducted using only the training dataset to ensure that the validation and test datasets remained unbiased. This approach helped us identify the most relevant features associated with the presence of locomotive syndrome (LS).\n\nThe final model utilized a set of nine key features, which included basic attributes such as age, sex, weight, and height, along with five additional items selected from the Oswestry Disability Index (ODI), Western Ontario and McMaster Universities Osteoarthritis Index (WOMAC), and Loco-check questionnaires. These nine features were determined to have the highest receiver operating characteristic area under the curve (ROC-AUC) among sets of up to 20 items, indicating their strong association with LS.",
  "optimization/fitting": "The study utilized a LightGBM algorithm in conjunction with the RFECV feature selection method to identify key factors associated with the presence of locomotive syndrome (LS). The dataset consisted of 331 explanatory variables derived from participant responses to medical questionnaires. The number of parameters was indeed larger than the number of training points, as the initial dataset included 331 items and 1008 participants in the training dataset.\n\nTo address the risk of overfitting, several strategies were employed. First, the dataset was split into training, validation, and test sets with the same rate of outcome to ensure a balanced distribution of LS cases. This splitting helped in evaluating the model's performance on unseen data. Second, the RFECV algorithm was used to recursively remove less important features, reducing the model complexity and focusing on the most relevant predictors. Additionally, the performance of the model was evaluated using multiple metrics, including ROC-AUC, precision-recall AUC, accuracy, precision, recall, specificity, gmean, and positive predictive value, calculated with 95% confidence intervals using the bootstrap method. This comprehensive evaluation ensured that the model's performance was robust and not merely a result of overfitting.\n\nTo rule out underfitting, the model's performance was compared against established LS risk tests and questionnaires, such as the two-step test, stand-up test, GLFS-25, and Loco-check. The nine-item model, which included basic attributes and selected items from ODI, WOMAC, and Loco-check, showed competitive performance metrics, particularly in ROC-AUC, precision-recall AUC, accuracy, and gmean. This comparison demonstrated that the model was capable of capturing the essential patterns in the data without being too simplistic. Furthermore, the use of SHAP values to visualize the importance of each feature provided insights into how different factors contributed to the presence of LS, ensuring that the model was not underfitting by ignoring critical variables.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our machine learning models. One of the key methods used was the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm. This technique helps in selecting the most relevant features by recursively removing the least important ones and building the model again. By doing so, it helps in reducing the complexity of the model and prevents overfitting.\n\nAdditionally, we utilized the Light Gradient Boosting Machine (LightGBM) algorithm, which is designed to handle large, multidimensional datasets efficiently. LightGBM incorporates regularization parameters that help in controlling the model's complexity and preventing overfitting. These parameters include learning rate, number of trees, and maximum depth of trees, among others. We optimized these hyperparameters using Optuna, a next-generation hyperparameter optimization framework, to find the best configuration that balances model performance and generalization.\n\nFurthermore, we split our dataset into training, validation, and test sets with the same rate of outcome to address the imbalanced distribution of outcomes. This splitting ensures that the model is trained and validated on different subsets of data, reducing the risk of overfitting to the training data. We also calculated performance metrics using the bootstrap method, which involves repeatedly resampling with replacement from the test dataset to generate multiple samples. This method provides a more reliable assessment of the model's performance and helps in estimating the confidence intervals for the metrics.\n\nIn summary, we implemented RFECV for feature selection, LightGBM with regularization parameters, dataset splitting, and the bootstrap method for performance evaluation to prevent overfitting and ensure the generalizability of our models.",
  "optimization/config": "The hyperparameter configurations and optimization parameters used in our study are available and have been reported. We utilized Optuna, a next-generation hyperparameter optimization framework, to determine the optimal hyperparameters for our models. The specific hyperparameters provided by Optuna are listed in the supporting information Table S3.\n\nThe optimization schedule and model files are not explicitly detailed in the main text, but the methods and tools used for optimization are well-documented. We employed LightGBM 3.3.1, Python 3.8.5, Optuna 2.10.0, SHAP 0.41.0, and Scikit-learn 0.23.2 for our experiments. These tools and their versions are standard in the machine learning community and are freely available under open-source licenses.\n\nFor statistical analysis, we calculated seven performance metrics: ROC-AUC, precision-recall AUC, accuracy, precision, recall, specificity, gmean, and positive predictive value. The averages and 95% confidence intervals for these metrics were determined using the bootstrap method, which involved resampling with replacement from the test dataset 1000 times to generate 1000 samples.\n\nThe data and code used in this study are not explicitly mentioned as being available for public access, but the methods and tools are well-documented and can be replicated using the information provided. The use of open-source tools ensures that the optimization process and model configurations can be reproduced by other researchers.",
  "model/interpretability": "The model employed in this study is not a black box. To ensure interpretability, we utilized SHAP (SHapley Additive exPlanations), a machine learning model interpretation technique. SHAP was used to calculate and visualize the effects of the association factors on the presence of locomotive syndrome (LS). This approach allowed us to understand how each feature contributes to the model's predictions, making the model more transparent.\n\nFor instance, the importance of various factors in estimating the presence of LS was visualized. The clustering of red dots on the right side of the SHAP summary plot indicates that higher values in certain items, such as age and low back pain affecting walking ability, increase the likelihood of LS. This visualization helps in identifying which factors are most influential in the model's decisions.\n\nAdditionally, the feature selection process using LightGBM-RFECV (Light Gradient Boosting Machine-based Recursive Feature Elimination with Cross-Validation) ensured that the most relevant features were retained. This method recursively removes less important features, focusing on the most significant ones. The final set of nine items, which includes basic attributes like age, sex, weight, and height, along with specific items from medical questionnaires, provides a clear and interpretable model.\n\nThe use of SHAP and the feature selection process together make the model more understandable and trustworthy, as it is possible to trace back the model's predictions to specific input features. This transparency is crucial for medical applications, where understanding the underlying factors is essential for clinical decision-making.",
  "model/output": "The model developed in this study is a classification model. It is designed to identify factors associated with the presence of locomotive syndrome (LS). The model uses a light gradient boosting machine (LightGBM) algorithm in conjunction with recursive feature elimination with cross-validation (RFECV) to select important features from participant data. The goal is to classify participants as having LS or not, based on various attributes and questionnaire responses.\n\nThe model's performance was evaluated using several metrics, including the receiver operating characteristic area under the curve (ROC-AUC), precision-recall AUC, accuracy, precision, recall, specificity, geometric mean (gmean), and positive predictive value. These metrics help assess the model's ability to correctly classify participants into the LS and non-LS categories.\n\nThe final model includes a set of nine items that were determined to be key associated factors of LS. These items include basic attributes such as age, sex, weight, and height, as well as specific questions from medical questionnaires like the Oswestry Disability Index (ODI), Western Ontario and McMaster University Osteoarthritis Index (WOMAC), and Loco-check. The model's performance was compared with other LS risk tests, such as the two-step test, stand-up test, and Geriatric Locomotive Function Scale (GLFS-25), to validate its effectiveness.",
  "model/duration": "The execution time for the model is not explicitly mentioned. However, the experiments were carried out using LightGBM 3.3.1, Python 3.8.5, Optuna 2.10.0, SHAP 0.41.0, and Scikit-learn 0.23.2. The model involved feature selection using the RFECV algorithm with LightGBM, which is known for its efficiency in handling large, multidimensional datasets. The dataset consisted of 1575 participants, divided into training, validation, and test sets. The training dataset included 1008 participants, the validation dataset 252 participants, and the test dataset 315 participants. The model's performance was evaluated using seven metrics, including ROC-AUC and precision-recall AUC, with 95% confidence intervals calculated using the bootstrap method. The feature selection process continued until a set of nine items was determined, which included basic attributes and items from the ODI, WOMAC, and Loco-check questionnaires. The importance of these items was visualized using SHAP. The model's performance was compared with other LS risk tests and questionnaires, showing competitive results in terms of ROC-AUC and other metrics.",
  "model/availability": "The source code for the models and algorithms used in this study is not publicly released. However, the specific tools and libraries utilized in the experiments are openly available. The experiments were conducted using LightGBM version 3.3.1, Python 3.8.5, Optuna 2.10.0, SHAP 0.41.0, and Scikit-learn 0.23.2. These libraries can be accessed and used under their respective open-source licenses, which typically allow for free use, modification, and distribution.\n\nThe hyperparameters for the models were optimized using Optuna, and the feature selection process involved the LightGBM-RFECV algorithm. The importance of the features was visualized using SHAP, a model interpretation technique. While the exact implementations and configurations specific to this study are not provided, the general methodologies and tools are well-documented and can be replicated using the mentioned versions of the software.\n\nFor those interested in replicating the study or using similar methodologies, the referenced libraries and their documentation should serve as a comprehensive guide. The use of these tools ensures that the experiments are reproducible, given the same datasets and configurations.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive assessment of the performance metrics for the machine learning models developed to predict the presence of locomotive syndrome (LS). The dataset was divided into training, validation, and test datasets, ensuring no overlap of participants between these sets. The training dataset comprised 64% of the participants, the validation dataset 16%, and the test dataset 20%.\n\nTo address the imbalanced distribution of outcomes, the datasets were split to maintain the same rate of LS prevalence. The performance of the models was evaluated using seven key metrics: ROC-AUC, precision-recall AUC, accuracy, precision, recall, specificity, gmean, and positive predictive value. These metrics were calculated based on the estimation results from the test dataset.\n\nTo ensure the reliability of the assessment, the averages and 95% confidence intervals (CIs) for these performance metrics were determined. The bootstrap method was utilized, involving repeated resampling with replacement from the test dataset 1000 times to generate 1000 samples. This method allowed for the calculation of predictive accuracy for each sample, thereby determining the 95% CIs.\n\nAdditionally, the validity of the items selected by LightGBM-RFECV was assessed by comparing the performance metrics against established LS risk tests, including the two-step test, stand-up test, GLFS-25, and Loco-check. The thresholds for these tests were used as clinical decision limits for stage 1 LS. The ROC-AUC and precision-recall AUC for GLFS-25 and Loco-check were calculated from the total scores.\n\nFurthermore, the study evaluated whether the selected items could also be used to assess the severity of LS by developing machine learning models for stages higher than stage 2 LS and stage 3 LS. The methodology for this evaluation is detailed in the supporting information. This comprehensive evaluation approach ensured a robust assessment of the models' performance and their potential application in clinical settings.",
  "evaluation/measure": "In our evaluation, we calculated seven performance metrics to assess the effectiveness of our models. These metrics include ROC-AUC, precision-recall AUC, accuracy, precision, recall, specificity, gmean, and positive predictive value. These metrics provide a comprehensive view of the model's performance, covering aspects such as the trade-off between true positive and false positive rates (ROC-AUC), the performance on imbalanced datasets (precision-recall AUC), and the overall correctness of the predictions (accuracy).\n\nThe choice of these metrics is representative of standard practices in the literature for evaluating classification models, particularly in medical and health-related studies. ROC-AUC and precision-recall AUC are crucial for understanding the model's ability to distinguish between classes, especially in the presence of class imbalances. Accuracy provides a straightforward measure of correct predictions, while precision, recall, and specificity offer detailed insights into the types of errors the model makes. The gmean score is particularly useful for balancing sensitivity and specificity, which is essential for clinical decision-making. The positive predictive value helps in understanding the probability that a positive prediction is a true positive, which is vital for practical applications.\n\nTo ensure the reliability of these metrics, we calculated their averages and 95% confidence intervals using the bootstrap method. This involved resampling with replacement from the test dataset 1000 times to generate 1000 samples, providing a robust estimate of the model's performance. This approach is widely accepted in the field and ensures that our reported metrics are statistically sound and representative of the model's true performance.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of our machine learning model's performance against several established methods and simpler baselines. We assessed the performance of our model using nine key items against a set of 331 items, as well as against traditional clinical tests such as the two-step test, stand-up test, and the 25-question Geriatric Locomotive Function Scale (GLFS-25). Additionally, we compared our model to the Loco-check, a simpler questionnaire-based assessment.\n\nThe performance metrics we used included ROC-AUC, precision-recall AUC, accuracy, precision, recall, specificity, gmean, and positive predictive value. These metrics were calculated for each method to provide a thorough evaluation. The results showed that our model with nine items achieved an ROC-AUC of 0.858, which was higher than the stand-up test (0.772), GLFS-25 (0.716), and Loco-check (0.409), but lower than the two-step test (0.927). This comparison highlights the effectiveness of our model in identifying the presence of locomotive syndrome (LS) while being more practical for daily use compared to the two-step test.\n\nFurthermore, we evaluated the performance of our model for higher stages of LS, specifically stages 2 and 3. The ROC-AUC values for these stages were 0.888 and 0.885, respectively, indicating that our model can also be used to assess the severity of LS. This comprehensive comparison demonstrates the robustness and practicality of our approach, making it a valuable tool for clinical assessment and monitoring of LS.",
  "evaluation/confidence": "The performance metrics in our study include confidence intervals, specifically 95% confidence intervals (CIs). These intervals were calculated using the bootstrap method, which involves repeatedly resampling with replacement from the test dataset 1000 times to generate 1000 samples. This approach ensures a reliable assessment of the metrics' variability and precision.\n\nThe metrics evaluated include ROC-AUC, precision-recall AUC, accuracy, precision, recall, specificity, gmean, and positive predictive value. Each of these metrics has associated 95% CIs, providing a range within which the true metric value is expected to lie with 95% confidence.\n\nTo determine statistical significance, we compared the performance of our method against established baselines such as the two-step test, stand-up test, GLFS-25, and Loco-check. The results indicate that our method, which uses nine key items, shows competitive performance in several metrics. For instance, the ROC-AUC for the nine items is 0.858 (95% CI 0.816\u20130.898), which is lower than the two-step test but higher than the stand-up test, GLFS-25, and Loco-check. This suggests that while our method may not outperform the two-step test in all metrics, it offers a practical alternative that is more suitable for daily use due to its questionnaire-based nature.\n\nThe gmean score, which balances sensitivity and specificity, underscores the advantage of our method. However, it is important to note that while the nine items show higher average values in ROC-AUC, precision-recall AUC, accuracy, and gmean compared to GLFS-25 and Loco-check, they have lower specificity and positive predictive value compared to GLFS-25, and lower sensitivity than Loco-check. This highlights the trade-offs involved in choosing a method for assessing the presence of locomotive syndrome (LS).\n\nIn summary, the performance metrics are robustly evaluated with confidence intervals, and the results suggest that our method is statistically significant and competitive with existing baselines. The choice of method should consider the practicality and the specific metrics that are most important for the intended application.",
  "evaluation/availability": "Not enough information is available."
}