{
  "publication/title": "Multiomics-Based Deep Learning Prediction of Prognosis and Therapeutic Response in Patients With Extensive-Stage Small Cell Lung Cancer Receiving Chemoimmunotherapy: A Retrospective Cohort Study.",
  "publication/authors": "Nie F, Pei X, Du J, Shi W, Wang J, Feng L, Liu Y",
  "publication/journal": "International journal of general medicine",
  "publication/year": "2025",
  "publication/pmid": "40026810",
  "publication/pmcid": "PMC11869764",
  "publication/doi": "10.2147/ijgm.s506485",
  "publication/tags": "- Machine Learning\n- Predictive Modeling\n- Immunotherapy\n- Chemotherapy\n- Radiomics\n- Retrospective Study\n- LASSO Regression\n- Random Forest\n- Decision Curve Analysis\n- Receiver Operating Characteristic (ROC) Curve",
  "dataset/provenance": "The dataset utilized in this study is derived from a single-center cohort, which inherently limits the breadth of the sample population. The study population consists of 309 individuals, divided into a training cohort of 216 participants and a testing cohort of 93 participants. This division allows for robust model training and validation.\n\nThe dataset includes various demographic and clinical variables, such as age, sex, body mass index (BMI), smoking status, Eastern Cooperative Oncology Group (ECOG) performance status, tumor size, pleural effusion (PLE), Karnofsky Performance Status (KPS), platelet count (PLT), lactate dehydrogenase (LDH) levels, and neuron-specific enolase (NSE) levels. Additionally, radiomic features such as energy, contrast, correlation, and the speed of sound (SOS) are incorporated.\n\nThe data has been analyzed using statistical methods appropriate for both continuous and categorical variables. Continuous variables were assessed using independent sample t-tests or Mann\u2013Whitney U-tests, while categorical variables were evaluated using chi-square tests or Fisher\u2019s exact tests. This comprehensive approach ensures the reliability and validity of the findings.\n\nThe dataset has not been previously used in other published papers or by the broader community. The focus of this study is on predicting the response of extensive-stage small cell lung cancer (ES-SCLC) to immunotherapy combined with chemotherapy using radiomics features. The study acknowledges the need for future research to standardize chest CT image acquisition and reconstruction to improve the reproducibility and generalizability of radiomics features. Additionally, the study highlights the importance of collecting diverse population cohort samples and conducting high-level prospective clinical trials to validate the practicality of radiomics.",
  "dataset/splits": "The dataset was divided into two main cohorts: a training cohort and a testing cohort. The training cohort consisted of 216 data points, while the testing cohort had 93 data points. Both cohorts were further subdivided into response and non-response groups.\n\nIn the training cohort, there were 171 data points in the response group and 45 in the non-response group. For the testing cohort, the response group contained 77 data points, and the non-response group had 16 data points.\n\nThe distribution of data points in each split was analyzed for various variables, including age, sex, BMI, smoking status, ECOG performance status, location, tumor size, pleural effusion, Karnofsky Performance Score, platelet count, lactate dehydrogenase, neuro-specific enolase, energy, contrast, correlation, sum of squares, inverse difference, mean sum, sum variance, sum entropy, difference variance, difference entropy, and pathomics score. These variables were compared between the response and non-response groups within each cohort to understand the demographic and clinical characteristics of the study population.",
  "dataset/redundancy": "The dataset was divided into two main cohorts: a training cohort and a testing cohort. The training cohort consisted of 216 samples, while the testing cohort had 93 samples. This split was done to ensure that the training and testing sets were independent, allowing for an unbiased evaluation of the prediction models.\n\nTo enforce the independence of the training and testing sets, statistical methods such as independent sample t-tests or Mann\u2013Whitney U-tests were used for continuous variables, and chi-square tests or Fisher\u2019s exact tests were used for categorical variables. These methods helped in validating that the distributions of key variables were comparable between the two cohorts.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in the field of medical research. The training cohort was used to develop and train the prediction models, while the testing cohort was used to evaluate the performance and robustness of these models. This approach ensures that the models are generalizable and can be applied to new, unseen data.\n\nThe dataset includes various demographic and clinical variables, such as age, sex, BMI, smoking status, ECOG performance status, tumor size, pleural effusion, and Karnofsky Performance Score (KPS). These variables were carefully selected to represent the diversity of the study population and to ensure that the models could capture the relevant patterns and relationships in the data.\n\nIn summary, the dataset was split into independent training and testing cohorts, with statistical methods used to enforce independence and ensure comparable distributions. This approach aligns with best practices in machine learning and medical research, providing a robust foundation for developing and evaluating prediction models.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study include random forests, decision trees, artificial neural networks, and generalized linear models. These are well-established classes of algorithms in the field of machine learning.\n\nThe algorithms employed are not new; they have been extensively used and validated in various predictive modeling tasks. Random forests, for instance, are known for their ability to handle large datasets and provide robust predictions by aggregating the results of multiple decision trees. Artificial neural networks are powerful tools for capturing complex patterns in data, while generalized linear models offer a more traditional approach to regression and classification tasks.\n\nThe choice of these algorithms was driven by their proven effectiveness in predictive modeling and their ability to handle the specific challenges posed by the data. The study focuses on evaluating the performance of these models in the context of medical predictions, particularly in the area of cancer treatment response.\n\nThe decision to use these established algorithms rather than novel ones is rooted in the need for reliability and interpretability in clinical settings. While new algorithms might offer theoretical advantages, the established methods have been thoroughly tested and are widely accepted in the medical community. This ensures that the results are not only accurate but also reproducible and interpretable, which is crucial for clinical decision-making.\n\nThe publication in a general medicine journal rather than a machine-learning journal is due to the focus on the application of these algorithms in a medical context. The primary goal is to demonstrate the practical utility of these models in improving patient outcomes, rather than advancing the theoretical understanding of machine learning. This aligns with the journal's emphasis on clinical applications and the translation of research into practical medical tools.",
  "optimization/meta": "The meta-predictor discussed in this publication does not use data from other machine-learning algorithms as input. Instead, it relies on radiomics features and pathomics scores derived from imaging evaluations. These features are selected using methods like LASSO regression and random forest recursive feature elimination.\n\nThe machine learning methods that constitute the whole include random forest models, decision tree models, artificial neural network models, and generalized linear models. These models were constructed and compared based on their predictive performance, with the random forest model exhibiting the best results.\n\nRegarding the independence of the training data, it is clear that different datasets were used for training and validation. This ensures that the models' performance is evaluated on unseen data, providing a more reliable assessment of their predictive capabilities. The use of cross-validation further supports the independence and robustness of the training process.",
  "optimization/encoding": "For the machine-learning algorithm, data encoding and preprocessing were crucial steps to ensure the models' effectiveness. Initially, a comprehensive imaging evaluation was conducted on 309 patients with ES-SCLC. The data included various radiomics features such as Energy, sum of squares (SOS), inverse difference (IND), mean sum (MES), sum variance (SUV), sum entropy (SUE), and difference variance (DIV). These features were extracted and analyzed to identify their correlation with treatment outcomes.\n\nTo select the optimal radiomics features, LASSO regression was employed. This method effectively reduced some feature coefficients to zero, thereby selecting non-zero features as variables. The optimal parameter (\u03bb) for the LASSO model was determined through 10-fold cross-validation, ensuring robustness and generalizability. This process helped in identifying seven key radiomics features: Energy, SOS, MES, SUV, SUE, DIV, and pathomics score, which were predictive of response to immunotherapy combined with chemotherapy.\n\nAdditionally, univariate and multivariate logistic regression analyses were performed to confirm that these features are independent risk factors for treatment response. This step was essential to validate the significance of the selected features in predicting outcomes.\n\nThe preprocessing also involved handling continuous and categorical variables appropriately. Independent sample t-tests or Mann\u2013Whitney U-tests were used for continuous variables, while chi-square tests or Fisher\u2019s exact tests were applied for categorical variables. This ensured that the data was appropriately normalized and ready for input into the machine-learning models.\n\nFour machine-learning prediction models were constructed using the preprocessed data: random forest model, decision tree model, artificial neural network model, and generalized linear model. These models were evaluated using cross-validation and the area under the receiver operating characteristic (ROC) curve to assess their predictive performance. The random forest model, in particular, exhibited the best predictive performance with an AUC of 0.899 in the training set and 0.901 in the validation set. This model was further validated using decision curve analysis, which indicated its superior clinical net benefits within a risk threshold range of 10% to 90%.\n\nIn summary, the data encoding and preprocessing involved extracting and selecting key radiomics features, validating their significance, and ensuring appropriate statistical handling of variables. This meticulous process was essential for constructing robust and accurate machine-learning models for predicting treatment responses in ES-SCLC patients.",
  "optimization/parameters": "In our study, we utilized a combination of radiomics and pathomics features to construct predictive models for treatment response in patients with ES-SCLC. The selection of optimal parameters was a critical step in this process.\n\nWe initially extracted a comprehensive set of features from chest CT scans and pathological omics data. These features included various tumor characteristics such as morphological, texture, boundary, and intensity features from radiomics, as well as pathological features from omics data.\n\nTo identify the most relevant features, we employed the Least Absolute Shrinkage and Selection Operator (LASSO) regression method. This technique effectively reduces some feature coefficients to zero, thereby selecting only the most significant variables. Through 10-fold cross-validation, we determined the optimal value of the regularization parameter (\u03bb), which helped in selecting the non-zero features.\n\nAs a result, seven optimal radiomics features were retained: Energy, sum of squares (SOS), mean sum (MES), sum variance (SUV), sum entropy (SUE), difference variance (DIV), and the pathomics score. These features were found to be independent risk factors for response to immunotherapy combined with chemotherapy.\n\nSubsequently, these selected features were incorporated into various machine learning algorithms, including random forests, decision trees, artificial neural networks, and generalized linear models. The performance of these models was evaluated using metrics such as the area under the receiver operating characteristic (ROC) curve, decision curve analysis, and repeated iterations.\n\nThe random forest model, which utilized the seven selected features, demonstrated the best predictive performance with an area under the ROC curve (AUC) of 0.899 in the training set and 0.901 in the validation set. This model was further validated through decision curve analysis, which showed superior clinical net benefits within a risk threshold range of 10% to 90%.\n\nIn summary, the selection of parameters involved a rigorous process of feature extraction, LASSO regression for variable selection, and evaluation through multiple machine learning algorithms. The final model utilized seven key features, providing a robust framework for predicting treatment response in ES-SCLC patients.",
  "optimization/features": "In the optimization process, feature selection was indeed performed to identify the most relevant predictors. The Least Absolute Shrinkage and Selection Operator (LASSO) regression method was employed to select optimal variables from the risk factors. This method effectively reduces some feature coefficients to zero in the regression model, thereby selecting the LASSO regression model with non-zero features as the variables.\n\nThe final grayscale region size matrix and grayscale co-occurrence matrix retained seven optimal radiomics features predictive of response to immunotherapy combined with chemotherapy: Energy, sum of squares (SOS), mean sum (MES), sum variance (SUV), sum entropy (SUE), difference variance (DIV), and pathomics score.\n\nThese features were selected using the training set only, ensuring that the model's performance and robustness were evaluated independently. The prediction performance and robustness were assessed by calculating the area under the receiver operating characteristic (ROC) curve, analyzing the decision curve, and performing repeated iterations for each prediction model.",
  "optimization/fitting": "In our study, we employed several machine learning algorithms, including random forests, decision trees, artificial neural networks, and generalized linear models, to build predictive models. The number of parameters in these models can indeed be large, especially in the case of artificial neural networks and random forests, which can have a high number of features and decision paths.\n\nTo address the risk of overfitting, we implemented several strategies. First, we used cross-validation techniques, such as 10-fold cross-validation, to ensure that our models generalized well to unseen data. This involved splitting the data into training and validation sets multiple times and averaging the performance metrics. Additionally, for the LASSO regression model, we selected the optimal regularization parameter (\u03bb) through cross-validation, which helps in reducing the complexity of the model by shrinking some coefficients to zero.\n\nWe also evaluated the prediction performance and robustness of our models using the area under the receiver operating characteristic (ROC) curve and decision curve analysis. These metrics provided a comprehensive assessment of the models' ability to discriminate between different outcomes and their clinical utility.\n\nTo mitigate underfitting, we ensured that our models were complex enough to capture the underlying patterns in the data. For instance, random forests and artificial neural networks are capable of modeling non-linear relationships, which is crucial for capturing the complexity of medical data. Furthermore, we performed repeated iterations for each prediction model to fine-tune the parameters and improve the fit.\n\nIn summary, by using cross-validation, regularization techniques, and evaluating multiple performance metrics, we effectively managed the risks of both overfitting and underfitting in our predictive models.",
  "optimization/regularization": "In our study, we employed the Least Absolute Shrinkage and Selection Operator (LASSO) regression method to prevent overfitting and to select the most relevant features for our prediction models. LASSO regression is particularly effective in reducing some feature coefficients to zero within the regression model, thereby performing both variable selection and regularization. This technique helps in simplifying the model by excluding less important features, which in turn enhances the model's predictive performance and robustness.\n\nAdditionally, we incorporated advanced machine learning algorithms such as random forests and artificial neural networks, which are known for their ability to handle complex datasets and reduce overfitting. These algorithms were evaluated using the area under the receiver operating characteristic (ROC) curve, decision curve analysis, and repeated iterations to ensure the models' reliability and generalizability.\n\nBy using these techniques, we aimed to construct prediction models that are not only accurate but also interpretable, allowing clinicians to make informed decisions based on the visualized prediction processes.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is designed to be interpretable, rather than a black box. This transparency is achieved through the use of advanced machine learning algorithms, particularly the random forest model. The random forest model allows clinicians to visualize each patient's prediction process, which is crucial for evaluating risk factors more clearly. This visualization enables personalized decision-making assistance for targeted therapies.\n\nOne of the key features of the random forest model is its ability to provide insights into how different variables contribute to the final prediction. For instance, the model highlights specific radiomics features such as Energy, sum of squares (SOS), mean sum (MES), sum variance (SUV), sum entropy (SUE), and difference variance (DIV), along with a pathomics score. These features are identified as independent risk factors for response to immunotherapy combined with chemotherapy. By examining the importance of these features, clinicians can understand which factors are most influential in predicting treatment outcomes.\n\nAdditionally, the use of LASSO regression helps in selecting the optimal radiomics features, ensuring that the model is not overfitted and remains interpretable. The LASSO regression effectively reduces some feature coefficients to zero, focusing only on the most relevant predictors. This process enhances the model's transparency and makes it easier to interpret the results.\n\nFurthermore, the decision curve analysis (DCA) and the area under the receiver operating characteristic (ROC) curve provide additional layers of interpretability. These analyses help in assessing the clinical practicality and net benefits of the radiomics prediction model across different threshold probabilities. The DCA, in particular, shows that the random forest model predicts better clinical net benefits within a risk threshold range of 10% to 90%, compared to other prediction models.\n\nIn summary, the model's interpretability is a significant advantage, allowing clinicians to make informed decisions based on clear and understandable predictions. The use of visual tools and the focus on key radiomics features ensure that the model is transparent and provides valuable insights for clinical practice.",
  "model/output": "The models developed in this study are primarily classification models. They are designed to predict the response to immunotherapy combined with chemotherapy in patients with ES-SCLC. The models categorize patients into different response groups such as complete response, partial response, stable disease, and progressive disease. The performance of these models was evaluated using metrics suitable for classification tasks, such as the area under the receiver operating characteristic (ROC) curve, positive predictive value (PPV), and negative predictive value (NPV).\n\nThe random forest model, in particular, demonstrated the best predictive performance with an area under the ROC curve (AUC) of 0.899 in the training set and 0.901 in the validation set. This indicates its effectiveness in distinguishing between different response categories. Additionally, the decision curve analysis showed that the random forest model provides better clinical net benefits within a risk threshold range of 10% to 90%, further supporting its utility as a classification model.\n\nThe models were constructed using various machine learning algorithms, including random forests, decision trees, artificial neural networks, and generalized linear models. These algorithms were chosen for their ability to handle complex data and provide robust predictions. The use of LASSO regression helped in selecting the optimal radiomics features, which were then used to train and validate the models. The final models incorporate features such as Energy, sum of squares (SOS), mean sum (MES), sum variance (SUV), sum entropy (SUE), difference variance (DIV), and pathomics score, all of which are independent risk factors for response to the combined treatment.\n\nIn summary, the models developed are classification models aimed at predicting treatment responses in ES-SCLC patients. They utilize advanced machine learning techniques and radiomics features to provide accurate and interpretable predictions, aiding in clinical decision-making.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the prediction models involved several robust methods to ensure the reliability and performance of the models. The prediction performance and robustness were assessed by calculating the area under the receiver operating characteristic (ROC) curve. This metric provides a comprehensive measure of the model's ability to distinguish between different outcomes.\n\nAdditionally, decision curve analysis was performed to evaluate the net benefits of the prediction models at various threshold probabilities. This analysis helps in understanding the clinical utility of the models by quantifying the benefits of using the model to make decisions compared to treating all patients or treating none.\n\nTo further validate the models, repeated iterations were conducted for each prediction model. This iterative process helps in assessing the consistency and stability of the model's performance across different datasets and conditions.\n\nThe models were implemented using various machine learning algorithms, including random forests, decision trees, artificial neural networks, and generalized linear models. These algorithms were chosen for their ability to handle complex data and provide accurate predictions.\n\nThe statistical analysis was conducted using R software, version 4.2.3. Independent sample t-tests or Mann\u2013Whitney U-tests were used for continuous variables, while chi-square tests or Fisher\u2019s exact tests were used for categorical variables. These statistical methods ensure that the data analysis is rigorous and reliable.\n\nIn summary, the evaluation method involved a combination of ROC curve analysis, decision curve analysis, and repeated iterations to assess the performance and robustness of the prediction models. The use of advanced machine learning algorithms and rigorous statistical methods ensures that the models are reliable and clinically useful.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report several key metrics to evaluate the predictive performance of our machine learning models. These metrics include the area under the receiver operating characteristic (ROC) curve (AUC), positive predictive value (PPV), and negative predictive value (NPV). The AUC provides a comprehensive measure of the model's ability to distinguish between positive and negative classes, with values ranging from 0 to 1, where 1 indicates perfect discrimination. The PPV and NPV offer insights into the accuracy of positive and negative predictions, respectively.\n\nWe present these metrics for both the training and testing sets, ensuring a robust evaluation of model performance across different datasets. The 95% confidence intervals (CI) for the AUC are also provided to indicate the reliability of these estimates. This set of metrics is widely recognized in the literature and is representative of standard practices in evaluating machine learning models, particularly in medical and predictive analytics research. By including AUC, PPV, and NPV, we aim to provide a thorough assessment of our models' predictive capabilities, ensuring transparency and comparability with other studies in the field.",
  "evaluation/comparison": "In our study, we evaluated the performance of various machine learning algorithms for predicting the response of ES-SCLC to immunotherapy combined with chemotherapy. We compared several advanced algorithms, including random forests, decision trees, artificial neural networks, and generalized linear models. These models were assessed using metrics such as the area under the receiver operating characteristic (ROC) curve, decision curve analysis, and repeated iterations for each prediction model.\n\nThe random forest model demonstrated superior performance, with the highest area under the ROC curve (AUC) in both the training and testing sets. This indicates that the random forest model is more accurate and robust compared to the other models evaluated. The decision tree model and the artificial neural network model also showed competitive performance, but they did not surpass the random forest model in terms of AUC.\n\nGeneralized linear models, while providing valuable guidance for clinical diagnosis and treatment, were found to have limitations such as multicollinearity and overfitting. These traditional models derive independent risk factors through classic logical algorithms and construct risk prediction models using visual column charts. However, they lack the predictive accuracy and efficiency offered by more advanced algorithms like random forests.\n\nIn summary, our comparison of different machine learning models revealed that the random forest model is the most effective for predicting the response of ES-SCLC to immunotherapy combined with chemotherapy. This model offers technical support for addressing targeted drug resistance in patients and provides a visual prediction process that is interpretable for clinicians.",
  "evaluation/confidence": "The evaluation of the predictive models in this study includes several key performance metrics, each accompanied by confidence intervals to provide a measure of reliability. The area under the receiver operating characteristic (ROC) curve (AUC) is a primary metric used to assess the models' performance. For instance, the random forest model (RFM) achieved an AUC of 0.899 with a 95% confidence interval (CI) of 0.844 to 0.954 in the training set, and an AUC of 0.901 with a 95% CI of 0.846 to 0.956 in the testing set. This indicates a high level of confidence in the model's predictive accuracy.\n\nOther models, such as the generalized linear regression model (GLRM), decision tree model (DTM), and artificial neural network model (ANNM), also have their AUC values reported with corresponding confidence intervals. For example, the GLRM had an AUC of 0.764 (95% CI: 0.707 to 0.821) in the training set and 0.792 (95% CI: 0.735 to 0.849) in the testing set. These intervals help in understanding the variability and reliability of the performance metrics.\n\nStatistical significance is another crucial aspect of the evaluation. The p-values reported in the baseline and demographic comparisons provide insights into the statistical significance of the differences observed. For example, the median age difference between the response and non-response groups in the training cohort is statistically significant with a p-value of 0.027. Similarly, other variables like smoking status and Karnofsky Performance Status (KPS) also show statistically significant differences, indicating that the observed differences are unlikely to be due to chance.\n\nThe use of advanced algorithms like random forests and artificial neural networks has shown superior performance compared to traditional generalized linear models. The random forest model, in particular, demonstrates high accuracy and interpretability, making it a robust choice for predictive modeling in this context. The visual prediction model based on random forests allows clinicians to evaluate risk factors more clearly and implement personalized decision-making assistance for targeted therapies.\n\nIn summary, the performance metrics are accompanied by confidence intervals, and the results are statistically significant, supporting the claim that the methods used are superior to others and baselines. The evaluation provides a comprehensive assessment of the models' predictive abilities and their potential clinical applications.",
  "evaluation/availability": "Not enough information is available."
}