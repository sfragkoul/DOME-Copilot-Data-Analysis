{
  "publication/title": "Intelligent prediction of RBC demand in trauma patients using decision tree methods.",
  "publication/authors": "Feng YN, Xu ZH, Liu JT, Sun XL, Wang DQ, Yu Y",
  "publication/journal": "Military Medical Research",
  "publication/year": "2021",
  "publication/pmid": "34024283",
  "publication/pmcid": "PMC8142481",
  "publication/doi": "10.1186/s40779-021-00326-3",
  "publication/tags": "- Blood transfusion\n- Trauma patients\n- Predictive modeling\n- Machine learning\n- Logistic regression\n- Decision tree algorithms\n- XGBoost\n- Non-invasive parameters\n- Emergency medicine\n- Critical care\n\nNot sure if the tags provided in the article are exhaustive, but these tags should cover the main topics discussed in the publication.",
  "dataset/provenance": "The dataset used in this study is sourced from the Emergency Trauma Database of the First Medical Center of Chinese PLA General Hospital. This database is a comprehensive, unidentified dataset containing medical information on 22,491 critically ill patients from January 2014 to January 2018. For this specific study, the medical information of 1371 trauma patients who were triaged to a critical rescue room was extracted. The data related to blood transfusion were provided by the clinical blood transfusion intelligent management and evaluation system database established by the Department of Transfusion Medicine of the First Medical Center of Chinese PLA General Hospital. The patients' information in the two databases was uniquely identified with the outpatient number. The original data were completely consistent with the database data through quality control. The Medical Ethics Committee of the Chinese PLA General Hospital waived the requirement for written informed consent.\n\nThe dataset includes a variety of variables such as basic information (age, sex, height, weight), diagnosis, admission time, discharge time, after-department track, blood transfusion time, blood transfusion components, RBC infusion volume, vital signs (heart rate, respiration, shock index, systolic blood pressure, diastolic blood pressure, blood oxygen saturation, temperature), routine blood test parameters, coagulation indicators, blood gas test parameters, trauma severity classification, endotracheal intubation, and vasoactive drugs. The dataset has been used to establish an artificial intelligence mathematical model to assist doctors in quickly making decisions on whether a blood transfusion is needed after trauma and to improve the success rate of patient treatment.",
  "dataset/splits": "The dataset was randomly divided into two splits: a training set and a test set. The training set contained 80% of the data, while the test set contained the remaining 20%. This split was used to train and evaluate the models, including LR, CRT, and XGBoost. The training set was used to build the models, and the test set was used to assess their performance.",
  "dataset/redundancy": "The dataset used in this study was derived from the Emergency Trauma Database of the First Medical Center of Chinese PLA General Hospital, which contains medical information on 22,491 critically ill patients. For our analysis, we included 1,371 patients who met specific study criteria.\n\nThe dataset was randomly divided into an 80% training set and a 20% test set. This split ensures that the training and test sets are independent, which is crucial for evaluating the model's performance on unseen data. The random division helps to maintain the generalizability of the model by ensuring that the test set is not influenced by the training process.\n\nTo enforce the independence of the training and test sets, we used a random splitting method. This method ensures that each data point has an equal chance of being included in either the training or test set, thereby minimizing any potential bias.\n\nRegarding the distribution of the dataset, it is important to note that the dataset includes a variety of variables such as basic information (age, sex, height, weight), non-invasive detection parameters (vital signs, trauma location), and invasive detection parameters (routine blood test parameters, coagulation indicators, blood gas test parameters). The dataset also includes information on whether a blood transfusion was administered, which is the target variable for our models.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in the medical field. The inclusion of a diverse set of variables and the large number of patients ensure that the dataset is robust and representative of the population under study. This robustness is essential for building accurate and reliable machine learning models.",
  "dataset/availability": "The data used in this study is not publicly available. The dataset is from the emergency trauma database of the First Medical Center of Chinese PLA General Hospital. The data is not completely open and cannot be disclosed. However, the data is available from the authors upon reasonable request and with permission from the Chinese National Engineering Laboratory for Medical Big Data Application Technology. The Medical Ethics Committee of the Chinese PLA General Hospital waived the requirement for written informed consent. The authors declare that they have no conflicts of interest.",
  "optimization/algorithm": "The optimization algorithm employed in our research is the XGBoost algorithm, which belongs to the class of gradient boosting algorithms. This algorithm is not new; it has been widely used in various fields, including medicine, due to its robust performance and ability to handle large datasets with high dimensionality.\n\nThe XGBoost algorithm is composed of a loss function and a regular function. The loss function calculates the error between the prediction and the real result, aiming to minimize this error. The regular function helps to detect the complexity of the model, thereby preventing overfitting. These components work together to enhance the model's predictive accuracy and generalization ability.\n\nGiven its established reputation and widespread use, publishing the XGBoost algorithm in a machine-learning journal was not necessary. Instead, our focus was on applying this well-known algorithm to a specific medical context\u2014predicting the need for blood transfusions in trauma patients. This application demonstrates the practical value of XGBoost in clinical settings, where it can assist healthcare professionals in making informed decisions.\n\nThe algorithm's effectiveness was evaluated using historical datasets, which were divided into training and test sets. The model was trained on the training set and its performance was assessed on the test set. This approach ensured that the model's predictions were reliable and generalizable to new, unseen data.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The research compares traditional statistical methods with machine learning decision tree algorithms, specifically focusing on the XGBoost algorithm. The XGBoost algorithm is used independently to predict blood transfusion needs in trauma patients. The model is trained on historical datasets that include various physiological parameters, symptoms, and clinical experience. The training data is divided into an 80% training set and a 20% test set to evaluate the model's performance. The decision tree algorithm is chosen for its ability to handle incomplete and noisy data, making it suitable for real-world medical data. The model's accuracy improves with more data, ensuring incremental learning characteristics. The research does not combine multiple machine-learning methods into a meta-predictor. Instead, it highlights the advantages of using the XGBoost algorithm for predicting blood transfusion needs in trauma patients.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for model training. First, numerical variables were directly extracted from the database, including vital sign parameters, laboratory test results, and blood transfusion-related information. The results of the first examination upon entering the emergency department were used as predictive variables. For multiple tests, the results closest to the blood transfusion time were included in the analysis.\n\nUnstructured text variables, such as diagnoses and medical orders, were processed using natural language processing techniques. An automatic counting word segmentation algorithm was employed to transform words into numerical variables. This allowed for the integration of textual data into the model.\n\nVariable processing included three main approaches:\n\n1. **Classify variable processing**: Variables were converted into numerical vectors. For example, categorical variables like gender were transformed into a format suitable for model building.\n\n2. **Unstructured text variable processing**: Natural language processing techniques were used to segment and count words, converting textual data into numerical variables.\n\n3. **Construct new variables**: Diagnostic information, such as trauma location and type, was divided into phrases and fields. Different categories within the target variables were counted and scored. The model was then trained using these learned rules to construct new variables.\n\nAdditionally, variable dimensionality reduction was performed to simplify the model operation. Highly correlated variables were identified, and only one variable with a high correlation coefficient was retained. For instance, if both hemoglobin (Hb) and hematocrit (Hct) were highly correlated, only Hct was retained.\n\nData cleaning was also a crucial step. Duplicate data were removed, and retention principles were formulated. Invalid values were checked and criteria were established for logical relationships among data points, such as the timing of admission, laboratory examinations, and blood transfusion start times.\n\nThe processed data were then used to train the models, including logistic regression (LR), classification and regression tree (CRT), and eXtreme gradient boosting (XGBoost). The historical dataset was randomly divided into an 80% training set and a 20% test set. The models were trained on the training set and evaluated on the test set to assess their performance.",
  "optimization/parameters": "In our study, we utilized both non-invasive and invasive parameters to predict the need for blood transfusion in trauma patients. The non-invasive parameters included variables such as trauma location, shock index, systolic blood pressure, diastolic blood pressure, and heart rate. These parameters can be quickly obtained after trauma patients have accessed medical resources, providing a timely assessment.\n\nWhen considering all parameters, the model incorporated a broader range of variables, including invasive parameters like hematocrit, fibrinogen, C-reactive protein, and various blood gas measurements. The inclusion of these additional parameters enhanced the model's predictive accuracy.\n\nThe selection of parameters was guided by statistical significance and their relevance to the clinical context. Variables that showed significant differences between the transfusion and non-transfusion groups, as determined by univariate analysis, were included in the models. For instance, trauma location and shock index were identified as risk factors for predicting blood transfusion needs.\n\nThe decision tree algorithms, specifically the Classification and Regression Tree (CRT) and eXtreme Gradient Boosting (XGBoost) models, were used to rank the importance of these variables. The CRT model highlighted variables like hematocrit, fibrinogen, and C-reactive protein as crucial for prediction. Similarly, the XGBoost model identified hematocrit, total carbon dioxide, pH, partial pressure of carbon dioxide, and C-reactive protein as the top contributors when all parameters were considered.\n\nThe logistic regression (LR) model, which is a traditional statistical method, was also employed to screen significant variables. This method helped in establishing the relationship between variables and the occurrence of blood transfusion, further refining the selection of input parameters.\n\nIn summary, the number of parameters used in the model varied depending on whether non-invasive or all parameters were considered. The selection process involved statistical analysis and clinical relevance, ensuring that the most informative variables were included to enhance the model's predictive performance.",
  "optimization/features": "In our study, we utilized a comprehensive set of features to predict the need for blood transfusion in trauma patients. The features were categorized into non-invasive and invasive parameters.\n\nNon-invasive parameters included vital signs such as heart rate, respiration, shock index, systolic and diastolic blood pressure, blood oxygen saturation, and temperature. Additionally, trauma location and test time were considered.\n\nInvasive parameters encompassed routine blood test results like hemoglobin, hematocrit, platelet count, C-reactive protein, and interleukin-6. Coagulation indicators such as prothrombin time, activated partial thromboplastin time, international standardized ratio, prothrombin activity, and fibrinogen were also included. Blood gas test parameters like pH, partial pressure of oxygen, partial pressure of carbon dioxide, total carbon dioxide, lactate, actual bicarbonate, standard bicarbonate, and potassium were part of the invasive parameters. Trauma severity classification, endotracheal intubation, and the use of vasoactive drugs were also considered.\n\nTo manage the complexity and dimensionality of the data, we performed variable dimensionality reduction. This involved retaining only one variable with a high correlation coefficient when multiple correlated variables were present. For example, if both hemoglobin and hematocrit were highly correlated, only hematocrit was retained.\n\nFeature selection was performed using the training set only, ensuring that the model's performance on the test set was not biased. This approach helped in reducing the time and complexity of model operation while maintaining the predictive power of the model.",
  "optimization/fitting": "The study utilized three different models: logistic regression (LR), classification and regression tree (CRT), and eXtreme gradient boosting (XGBoost). The dataset consisted of 1371 trauma patients, with variables including vital signs, laboratory examination parameters, and blood transfusion volumes. The dataset was split into an 80% training set and a 20% test set to evaluate model performance.\n\nThe XGBoost algorithm, in particular, is designed to handle overfitting through its regularization parameters. These parameters control the complexity of the model by penalizing large weights, thereby preventing the model from becoming too complex and overfitting the training data. The loss function in XGBoost is optimized to minimize the error between predictions and actual results, while the regularization function ensures that the model remains simple enough to generalize well to unseen data.\n\nFor the CRT model, the importance of each variable was determined by its position in the decision tree (root node, child node). This hierarchical structure helps in identifying the most significant predictors, reducing the risk of overfitting by focusing on the most relevant features.\n\nThe LR model, while simpler, was used to screen significant variables with a P-value threshold of less than 0.05. This approach ensures that only the most relevant predictors are included in the model, mitigating the risk of overfitting.\n\nTo further validate the models, the area under the curve (AUC) was compared using the t-test method provided by the SciPy library in Python. Significant differences in AUC (P < 0.05) indicated that the models were not underfitting, as they demonstrated sufficient discriminatory power.\n\nIn summary, the study employed regularization techniques and feature selection methods to prevent overfitting and ensure that the models generalized well to new data. The comparison of AUC values and the use of a separate test set helped in ruling out underfitting, ensuring that the models were appropriately fitted to the data.",
  "optimization/regularization": "In our study, we employed regularization techniques to prevent overfitting in our models. Specifically, we used the XGBoost algorithm, which incorporates both a loss function and a regularization function. The loss function calculates the error between the predicted and actual results, and it is constrained to minimize this error. The regularization function, on the other hand, helps to control the complexity of the model. By doing so, it reduces the risk of overfitting, ensuring that the model generalizes well to new, unseen data. This approach allows us to build robust models that are less likely to overfit the training data, thereby improving their predictive performance in real-world applications.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters used in our study are not publicly available. The data and models are subject to certain restrictions due to the nature of the study and the institutions involved. The study data can be obtained from the authors upon reasonable request and with permission from the Chinese National Engineering Laboratory for Medical Big Data Application Technology. However, the database is not completely open and cannot be disclosed. This limitation is in place to ensure the privacy and security of the patient data used in the research. Therefore, while the methods and findings are thoroughly documented in the publication, the specific configurations and parameters are not readily accessible to the public.",
  "model/interpretability": "The models used in our study include logistic regression (LR), classification and regression tree (CRT), and eXtreme gradient boosting (XGBoost). Among these, the LR model is the most transparent, providing clear insights into the relationships between variables and the likelihood of blood transfusion. The LR model identifies specific risk factors, such as trauma location and shock index, and quantifies their impact through odds ratios and confidence intervals. This transparency allows clinicians to understand which factors are most influential in predicting the need for blood transfusion.\n\nThe CRT model also offers a degree of interpretability by ranking the importance of variables based on their position in the decision tree. For instance, variables like hematocrit and fibrinogen are highlighted as critical factors in predicting blood transfusion. The tree structure visually represents the decision-making process, making it easier to follow the logic behind the model's predictions.\n\nIn contrast, the XGBoost model is more of a black-box model, as it combines multiple decision trees to make predictions. While it provides feature importance rankings, the exact interactions between variables are less clear. For example, the top features in the XGBoost model include hematocrit, total carbon dioxide, and pH, but the model does not explicitly show how these features interact to influence the prediction.\n\nOverall, while the LR and CRT models offer more interpretability, the XGBoost model, despite being less transparent, demonstrates superior predictive performance, especially when all parameters are considered. This trade-off between interpretability and accuracy is a common challenge in machine learning, and the choice of model depends on the specific needs and priorities of the clinical application.",
  "model/output": "The models used in this study include both classification and regression types. The Classification and Regression Tree (CRT) model and the eXtreme Gradient Boosting (XGBoost) model are utilized for classification analysis, which processes discrete data. Additionally, the XGBoost algorithm is also employed for regression tree analysis, which processes continuous data. The Logistic Regression (LR) model is specifically used for classification tasks. The models were trained on historical datasets, which were randomly divided into an 80% training set and a 20% test set. The performance of these models was evaluated based on their ability to predict the need for blood transfusion after trauma, using various parameters such as non-invasive and invasive variables. The Area Under the Curve (AUC) and accuracy metrics were used to assess the models' predictive performance. The study found that the XGBoost model had the highest AUC when all parameters were included, indicating its superior performance in this context. The models were compared using statistical methods, and significant differences in AUC were noted among the models. The variable importance analysis highlighted key factors such as trauma location, shock index, and systolic blood pressure, which were crucial in predicting the need for blood transfusion.",
  "model/duration": "The execution time of the models varied depending on the parameters used. When using non-invasive parameters, the logistic regression (LR) model had an area under the curve (AUC) of 0.72, which was higher than the XGBoost model (0.71) and the classification and regression tree (CRT) model (0.69). The XGBoost model demonstrated the highest accuracy at 0.75, compared to the LR model (0.55) and the CRT model (0.48). These results indicate that while the XGBoost model was slightly slower in terms of execution time due to its complexity, it provided the best accuracy among the models when using non-invasive parameters.\n\nWhen all parameters were included, the XGBoost model again showed superior performance with an AUC of 0.94, outperforming the CRT model (0.82) and the LR model (0.80). The CRT model had the highest accuracy at 0.89, followed by the XGBoost model (0.83) and the LR model (0.72). The inclusion of all parameters increased the execution time for all models, but the XGBoost model maintained its lead in predictive performance.\n\nThe non-invasive parameters can be quickly obtained after trauma patients have accessed medical resources, allowing for rapid feedback on whether a blood transfusion is needed. This time advantage is crucial in trauma situations where vital signs are complex and changeable. Invasive parameters, while providing more detailed information, take approximately an hour to detect, which may not reflect the current physiological state of the patient. Therefore, the non-invasive parameters, combined with the decision tree models, offer a practical and efficient solution for real-time prediction of blood transfusion needs in trauma patients.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the models involved a comprehensive approach to ensure their predictive performance and reliability. The dataset was randomly divided into an 80% training set and a 20% test set. The models were trained on the training set and then evaluated on the test set to assess their effectiveness.\n\nTwo methods were used for model evaluation:\n\n1. **Method 1**: This method utilized basic information and non-invasive parameters to establish the models. The performance of the models was evaluated using the area under the curve (AUC) metric. The logistic regression (LR) model achieved an AUC of 0.72, which was higher than the XGBoost model (0.71) and the classification and regression tree (CRT) model (0.69). The accuracy of the XGBoost model was 0.75, surpassing both the LR model (0.55) and the CRT model (0.48).\n\n2. **Method 2**: This method incorporated all parameters, including invasive parameters, to predict the need for blood transfusion. The XGBoost model demonstrated the highest AUC of 0.94, outperforming the CRT model (0.82) and the LR model (0.80). The CRT model showed the highest accuracy at 0.89, followed by the XGBoost model (0.83) and the LR model (0.72).\n\nThe statistical significance of the differences in AUC among the models was determined using the t-test method provided by the SciPy library in Python. A P-value of less than 0.05 indicated a statistically significant difference.\n\nAdditionally, the importance of variables in the models was analyzed. For non-invasive detection parameters, the LR analysis identified trauma location and shock index (SI) as significant risk factors for predicting the need for blood transfusion. The models were compared based on their ability to predict blood transfusion using these variables, providing insights into their relative performance and reliability.",
  "evaluation/measure": "In our study, we evaluated the performance of our models using several key metrics to ensure a comprehensive assessment. The primary metric reported is the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, which provides a measure of the model's ability to distinguish between patients who require a blood transfusion and those who do not. We also reported the accuracy of each model, which indicates the proportion of true results (both true positives and true negatives) among the total number of cases examined.\n\nFor the model established with non-invasive parameters, the AUC values were 0.72 for the Logistic Regression (LR) model, 0.71 for the XGBoost model, and 0.69 for the Classification and Regression Tree (CRT) model. The accuracy was 0.55 for the LR model, 0.75 for the XGBoost model, and 0.48 for the CRT model. These metrics highlight the comparative performance of each model when using non-invasive data.\n\nWhen all parameters were included, the AUC values improved significantly. The XGBoost model achieved the highest AUC of 0.94, followed by the CRT model with 0.82 and the LR model with 0.80. The accuracy for this method was 0.83 for the XGBoost model, 0.89 for the CRT model, and 0.72 for the LR model. These results demonstrate the enhanced predictive power when incorporating both invasive and non-invasive parameters.\n\nThe set of metrics used in our study is representative of standard practices in the literature for evaluating predictive models, particularly in medical research. The AUC is widely recognized as a robust metric for assessing model performance, especially in binary classification problems. Accuracy, while a straightforward metric, provides additional insight into the model's overall effectiveness. Together, these metrics offer a balanced view of the models' strengths and weaknesses, ensuring that our findings are both reliable and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we compared the performance of three different models: Logistic Regression (LR), Classification and Regression Tree (CRT), and eXtreme Gradient Boosting (XGBoost). These models were evaluated using two different methods of parameter selection.\n\nFor Method 1, which used non-invasive parameters, the LR model demonstrated the highest Area Under the Curve (AUC) at 0.72, outperforming both the XGBoost model (AUC of 0.71) and the CRT model (AUC of 0.69). However, the XGBoost model showed higher accuracy at 0.75, compared to the LR model (0.55) and the CRT model (0.48).\n\nIn Method 2, which incorporated all parameters, the XGBoost model achieved the highest AUC of 0.94, significantly better than the CRT model (AUC of 0.82) and the LR model (AUC of 0.80). The CRT model, however, had the highest accuracy at 0.89, followed by the XGBoost model (0.83) and the LR model (0.72).\n\nThe comparisons were statistically significant, with P-values less than 0.05, indicating that the differences in performance among the models were not due to random chance. These results highlight the strengths and weaknesses of each model under different conditions, providing a comprehensive evaluation of their predictive capabilities for blood transfusion needs post-trauma.",
  "evaluation/confidence": "The evaluation of our models included the calculation of performance metrics with confidence intervals. For instance, the area under the curve (AUC) for the logistic regression (LR) model using non-invasive parameters was reported as 0.72 with a 95% confidence interval (CI) of 0.657 to 0.775. Similarly, the AUC for the XGBoost model was 0.71 with a 95% CI of 0.654 to 0.756, and for the classification and regression tree (CRT) model, it was 0.69 with a 95% CI of 0.633 to 0.751. These intervals provide a range within which the true AUC values are likely to fall, giving a sense of the precision of our estimates.\n\nStatistical significance was assessed using the t-test method provided by the SciPy library in Python. Differences in AUCs among the models were considered statistically significant if the p-value was less than 0.05. For example, when comparing the models using non-invasive parameters, there was a significant difference in the AUC among the three models (p < 0.05). This indicates that the observed differences in performance are unlikely to be due to chance, enhancing our confidence in the superiority of certain models over others.\n\nAdditionally, the accuracy of the models was reported with specific values. For non-invasive parameters, the XGBoost model had an accuracy of 0.75, which was higher than that of the LR model (0.55) and the CRT model (0.48). When all parameters were included, the XGBoost model had an AUC of 0.94, significantly higher than the CRT model (0.82) and the LR model (0.80), with a p-value less than 0.05, indicating statistical significance. The CRT model had the highest accuracy of 0.89, compared to the XGBoost model (0.83) and the LR model (0.72).\n\nThese evaluations provide a robust framework for assessing the performance and reliability of our models, ensuring that the claims of superiority are backed by statistically significant results and well-defined confidence intervals.",
  "evaluation/availability": "The study data are available from the authors upon reasonable request and with permission from the Chinese National Engineering Laboratory for Medical Big Data Application Technology. Therefore, the database is not completely open, and cannot be disclosed. The data made available in this article is under the Creative Commons Public Domain Dedication waiver, unless otherwise stated in a credit line to the data."
}