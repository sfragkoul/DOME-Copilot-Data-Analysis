{
  "publication/title": "Ten-Year Multicenter Retrospective Study Utilizing Machine Learning Algorithms to Identify Patients at High Risk of Venous Thromboembolism After Radical Gastrectomy.",
  "publication/authors": "Liu Y, Song C, Tian Z, Shen W",
  "publication/journal": "International journal of general medicine",
  "publication/year": "2023",
  "publication/pmid": "37228741",
  "publication/pmcid": "PMC10202705",
  "publication/doi": "10.2147/ijgm.s408770",
  "publication/tags": "- gastric neoplasms\n- gastrectomy\n- venous thromboembolism\n- risk factors\n- machine learning\n- prediction model\n- postoperative complications\n- surgical outcomes\n- gastric cancer\n- clinical decision-making",
  "dataset/provenance": "The dataset used in this study was sourced from the databases of Wuxi People\u2019s Hospital and Wuxi Second People\u2019s Hospital. It comprises clinical data on gastric cancer patients between 2010 and 2020. The dataset includes a total of 1239 patients diagnosed with gastric cancer, among whom 107 patients (8.64%) developed postoperative venous thromboembolism (VTE).\n\nThe data collected includes 42 preoperative variables (within 24 hours before surgery), intraoperative variables, and postoperative variables (occurring 48 hours after the initial surgery). Preoperative variables include patient demographic characteristics such as gender, age, history of smoking, alcohol abuse, and body mass index (BMI). Basic clinical characteristics include the American Society of Anesthesiologists score, nutrition risk screening 2002 score, history of surgery, adjuvant chemotherapy history, adjuvant radiotherapy history, and use of central venous catheters. Basic medical history includes conditions such as anemia, ileus, ulcerative colitis, Crohn\u2019s disease, diabetes mellitus, hypertension, chronic obstructive pulmonary disease, hyperlipidemia, and coronary artery disease. Laboratory tests include albumin, carcinoembryonic antigen, and carbohydrate antigen 19\u20139. Tumor characteristics include T-stage, N-stage, peripheral nerve invasion, tumor size, and tumor number.\n\nIntraoperative variables include the type of surgery, surgical approach, number of lymph nodes dissected, duration of surgery, intraoperative bleeding, intraoperative blood transfusion, intraoperative percutaneous arterial oxygen saturation status, abdominal drainage, whether the patient experienced intraoperative tachycardia, and whether the surgery was an emergency procedure. Postoperative variables include laboratory test indices such as neutrophil to lymphocyte ratio, procalcitonin, C-reactive protein, and serum amyloid A. The outcome variable of the study was postoperative VTE.\n\nThe dataset was divided into an establishment set and an external validation set. The establishment set was further randomly divided into a training set (70%) and a test set (30%). The external validation set consisted of a separate dataset of gastric cancer patients from Wuxi Second People\u2019s Hospital during the same period. This division allowed for the construction and evaluation of predictive models using both internal and external validation methods.",
  "dataset/splits": "The dataset used in this study was divided into three main splits: the establishment set, the training set, and the test set, and an external validation set.\n\nThe establishment set consisted of 873 data points, representing 70.53% of the overall dataset. This set was further randomly divided into a training set, which comprised 70% of the establishment set, and a test set, which comprised the remaining 30%. The training set therefore included approximately 611 data points, while the test set included around 262 data points.\n\nThe external validation set consisted of 366 data points, representing 29.47% of the overall dataset. This set was used to evaluate the model\u2019s performance and generalizability.\n\nThe overall dataset included 1239 data points, with the establishment set and the external validation set having distinct distributions across various variables such as sex, age, BMI, ASA score, smoking history, drinking history, surgical history, adjuvant chemotherapy, adjuvant radiotherapy, ALB levels, NRS2002 score, CEA level, CA19-9 level, anemia, ileus, CHD, and COPD. These distributions were analyzed to ensure the representativeness and balance of the dataset across different splits.",
  "dataset/redundancy": "The dataset used in this study comprised patients diagnosed with gastric cancer at Wuxi People\u2019s Hospital between January 2010 and January 2020. This dataset was employed for building the predictive model. The establishment set was randomly divided into a training set (70%) and a test set (30%). This random split ensured that the training and test sets were independent, reducing the risk of data leakage and overfitting.\n\nTo further validate the model's performance, a separate dataset of gastric cancer patients from Wuxi Second People\u2019s Hospital during the same period was used as an external validation set. This external validation set provided an additional layer of verification, ensuring that the model's predictive ability generalized well to new, unseen data.\n\nThe distribution of the dataset reflects real-world clinical scenarios, which is crucial for the development of robust predictive models. The establishment set and external validation set were compared using statistical tests to ensure that there were no significant differences in the distribution of key variables. This comparison helped to confirm that the datasets were representative of the broader population, enhancing the reliability and validity of the study's findings.\n\nThe use of both internal and external validation sets is a strength of this study, as it aligns with best practices in machine learning and statistical modeling. By ensuring the independence of the training and test sets and validating the model on an external dataset, the study provides a comprehensive evaluation of the model's performance and generalizability.",
  "dataset/availability": "The data used in this study were collected from the databases of Wuxi People\u2019s Hospital and Wuxi Second People\u2019s Hospital. The dataset included clinical data on gastric cancer patients between 2010 and 2020. This data comprised 42 preoperative variables, intraoperative variables, and postoperative variables. The dataset was divided into an establishment set and an external validation set. The establishment set was further split into a training set (70%) and a test set (30%).\n\nThe original data presented in the study are included in supplementary material, specifically in Table S1. However, it is not explicitly stated whether this data is publicly available or under what license it might be released. Therefore, it is not clear if the data, including the data splits used, are released in a public forum.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the ensemble learning method, specifically the extreme gradient boosting (XGBoost) algorithm. This algorithm is not new; it has been widely recognized and utilized in various fields for its effectiveness in predictive modeling.\n\nThe XGBoost algorithm was chosen for its superior performance in terms of accuracy, stability, and generalization ability compared to other algorithms evaluated in our study, such as random forest (RF), support vector machine (SVM), and k-nearest neighbor (KNN). Its ability to handle high-dimensional data and provide intuitive feature importance rankings made it particularly suitable for our predictive model of postoperative venous thromboembolism (VTE) in gastric cancer patients.\n\nWhile XGBoost is a well-established algorithm in the machine-learning community, our application of it in the clinical context of predicting postoperative VTE is novel. The focus of our publication is on the clinical utility and validation of this model, rather than the algorithm itself. Therefore, it is published in a medical journal to highlight its practical implications in clinical decision-making and patient care.",
  "optimization/meta": "The model developed in this study is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it directly utilizes clinical variables and employs four distinct machine learning algorithms\u2014extreme gradient boosting (XGBoost), random forest (RF), support vector machine (SVM), and k-nearest neighbor algorithm (KNN)\u2014to construct and evaluate predictive models.\n\nThe XGBoost algorithm was ultimately selected for its superior performance in terms of accuracy, stability, and generalization ability. This choice was made after a comprehensive comparison of the four algorithms, which considered their respective strengths and weaknesses.\n\nThe training data used for these models was derived from patients diagnosed with gastric cancer at Wuxi People\u2019s Hospital between January 2010 and January 2020. This dataset was randomly divided into a training set (70%) and a test set (30%). Additionally, a separate dataset from Wuxi Second People\u2019s Hospital during the same period was used as an external validation set to evaluate the model\u2019s performance. This ensures that the training data is independent and that the model's generalizability can be assessed effectively.",
  "optimization/encoding": "In our study, data preprocessing was a crucial step before applying machine learning algorithms. The dataset comprised patients diagnosed with gastric cancer, and it was divided into a training set (70%) and a test set (30%). Additionally, a separate dataset from another hospital served as an external validation set.\n\nFor categorical variables, we utilized the chi-square test to compare differences between groups. Continuous variables that followed a normal distribution were analyzed using the t-test, while those that did not conform to a normal distribution were assessed with the rank sum test. A p-value of less than 0.05 was considered statistically significant.\n\nLogistic regression analysis was performed on variables that showed significance in univariate analysis to identify independent influences on postoperative venous thromboembolism (VTE). Four machine learning algorithms\u2014extreme gradient boosting (XGBoost), random forest (RF), support vector machine (SVM), and k-nearest neighbor (KNN)\u2014were used to score the importance of each factor. Variables that ranked in the top ten across all four models and were meaningful in both univariate and multivariate analyses were selected for further modeling.\n\nThe filtered clinical variables were then incorporated into the four machine learning algorithms. The models were evaluated using criteria such as discrimination, calibration, and clinical utility. The receiver operating characteristic (ROC) curve was used to calculate the area under the curve (AUC) value, which gauged the model\u2019s predictive ability. Calibration curves were plotted to assess the agreement between predicted and actual results, and decision curve analysis (DCA) was performed to determine the benefit to patients from interventional treatment. Internal validation was conducted through k-fold cross-validation methodology.",
  "optimization/parameters": "In our study, we utilized four different machine learning algorithms to build predictive models for postoperative venous thromboembolism (VTE) in gastric cancer patients. The algorithms used were extreme gradient boosting (XGBoost), random forest (RF), support vector machine (SVM), and k-nearest neighbor (KNN). Each of these models was evaluated based on various criteria, including discrimination, calibration, and clinical utility.\n\nThe selection of input parameters was a meticulous process. Initially, we collected a comprehensive dataset that included a wide range of variables. These variables encompassed preoperative factors such as patient demographics, comorbidities, laboratory test results, and tumor characteristics. Intraoperative variables included details about the surgical procedure, such as the type of surgery, surgical approach, duration of surgery, and intraoperative complications. Postoperative variables consisted of laboratory test indices and other relevant clinical data.\n\nTo identify the most significant variables, we conducted univariate and multivariate regression analyses. The chi-square test was used for categorical variables, while the t-test and rank sum test were applied for continuous variables, depending on their distribution. Variables that showed statistical significance in these analyses were further evaluated using logistic regression to determine their independent influence on postoperative VTE.\n\nEach of the four models\u2014XGBoost, RF, SVM, and KNN\u2014was used to score the importance of these variables. The variables that ranked in the top ten in all four models and were meaningful in both univariate and multivariate analyses were selected for inclusion in the final models. This approach ensured that the most relevant and impactful parameters were used, enhancing the models' predictive accuracy and reliability.\n\nThe final models were then evaluated using receiver operating characteristic (ROC) curves, calibration plots, and decision curve analysis (DCA). The XGBoost model, in particular, demonstrated superior performance with the highest area under the curve (AUC) values in both the training and validation sets. This rigorous selection and evaluation process ensured that the models were optimized for predicting postoperative VTE in gastric cancer patients.",
  "optimization/features": "In our study, we utilized a comprehensive set of input features to build predictive models for postoperative venous thromboembolism (VTE) in gastric cancer patients. The features were carefully selected based on their clinical relevance and statistical significance.\n\nWe initially considered a wide range of variables, including patient demographics, comorbidities, laboratory test results, tumor characteristics, intraoperative variables, and postoperative indices. To ensure the robustness and generalizability of our models, we performed feature selection using both univariate and multivariate regression analyses. This process involved comparing differences between groups for categorical variables using the chi-square test and applying t-tests or rank sum tests for continuous variables, depending on their distribution.\n\nThe feature selection was conducted exclusively on the training set to prevent data leakage and maintain the integrity of the validation process. Variables that were significant in the univariate analysis and meaningful in the multivariate analysis were retained. Additionally, we used four machine learning algorithms\u2014extreme gradient boosting (XGBoost), random forest (RF), support vector machine (SVM), and k-nearest neighbor algorithm (KNN)\u2014to score the importance of each factor and rank them according to the weight of their influence. The top ten variables from each model's ranking, which were also clinically relevant, were selected for inclusion in the final models.\n\nThis rigorous feature selection process ensured that our models were built on a set of highly informative and non-redundant features, enhancing their predictive performance and clinical utility.",
  "optimization/fitting": "The study employed several machine learning algorithms, including XGBoost, SVM, KNN, and RF, to predict postoperative venous thromboembolism (VTE) in patients. The XGBoost algorithm was ultimately chosen due to its superior performance and lower model complexity, making it well-suited for multidimensional studies.\n\nRegarding the number of parameters, the SVM and KNN algorithms have high model complexity, which could potentially hinder performance on large datasets. However, the XGBoost algorithm, which was selected for the final model, has a lower model complexity. This characteristic helps in managing the number of parameters relative to the number of training points, thereby mitigating the risk of overfitting.\n\nTo ensure the model's robustness and generalizability, internal validation was conducted using a k-fold cross-validation methodology. This approach helps in assessing the model's performance across different subsets of the data, providing a more reliable estimate of its predictive accuracy. Additionally, external validation was performed by applying the model to an external validation set, further confirming its generalizability and predictive efficiency.\n\nThe calibration plots of the models showed that the predicted probabilities were closely aligned with the observed probabilities, indicating good calibration performance. This alignment suggests that the models, including the final XGBoost model, are not underfitting the data. The net benefit curves also demonstrated an \"S\" shaped pattern, indicating an increase in net benefit with an increase in the probability threshold, followed by a decline after reaching the highest point. The XGBoost model showed the highest net benefit among all models, further supporting its selection.\n\nIn summary, the study carefully managed the model complexity and validated the models thoroughly to ensure they neither overfit nor underfit the data. The XGBoost algorithm's lower complexity and superior performance made it the optimal choice for predicting postoperative VTE.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was k-fold cross-validation. This technique involves partitioning the data into k subsets, or \"folds,\" and then training the model on k-1 folds while validating it on the remaining fold. This process is repeated k times, with each fold serving as the validation set once. By averaging the results, we obtained a more reliable estimate of the model's performance and helped to prevent overfitting.\n\nAdditionally, we utilized regularization techniques inherent in the machine learning algorithms we employed. For instance, the extreme gradient boosting (XGBoost) algorithm includes regularization parameters that help to control the complexity of the model and prevent overfitting. These parameters include alpha (L1 regularization) and lambda (L2 regularization), which we tuned during the model training process.\n\nFurthermore, we evaluated the models using multiple criteria, including discrimination, calibration, and clinical utility. The receiver operating characteristic (ROC) curve and the area under the curve (AUC) were used to assess the model's predictive ability. The calibration curve was plotted to ensure that the predicted probabilities aligned well with the actual outcomes, and decision curve analysis (DCA) was performed to determine the net benefit of the model.\n\nBy combining these techniques, we aimed to build models that generalize well to new, unseen data and provide reliable predictions for postoperative venous thromboembolism (VTE) in patients with gastric cancer.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a black box. To ensure interpretability, we employed SHAP (SHapley Additive exPlanations) values, which provide a way to explain the output of machine learning models. This approach allows us to understand the contribution of each feature in the sample to the prediction.\n\nFor instance, in the case of predicting venous thromboembolism (VTE) in patients, the SHAP summary plot helped us rank the importance of various risk factors. Factors such as surgery time, use of central venous catheters, and neutrophil to lymphocyte ratio were identified as significant contributors to the model's predictions. Additionally, SHAP force plots were used to interpret the prediction results for individual patients, showing how each feature influenced the probability of VTE occurrence.\n\nThe XGBoost algorithm, which was determined to have the highest accuracy and stability, also facilitates interpretability by allowing for the assessment of feature importance. This ranking of features provides an intuitive understanding of which variables are most influential in the model's decisions. For example, for a patient with a high predicted probability of VTE, the force plot might show that factors like prolonged surgery time and the use of central venous catheters significantly increased the risk, while a history of adjuvant chemotherapy decreased it.\n\nOverall, the use of SHAP values and the inherent feature importance ranking in XGBoost make the model transparent and interpretable, enabling clinicians to understand the underlying factors contributing to the predictions.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the occurrence of postoperative venous thromboembolism (VTE) in patients with gastric cancer. The model uses various machine learning algorithms, including extreme gradient boosting (XGBoost), random forest (RF), support vector machine (SVM), and k-nearest neighbor (KNN), to classify patients into those likely to develop VTE and those who are not.\n\nThe output of the model provides probabilities of VTE occurrence for individual patients. For instance, the model predicted a disease occurrence probability of 0.029 for one patient, 0.374 for another, and 0.748 for a third patient. These probabilities are derived from the model's analysis of various risk factors, such as the use of central venous catheters, surgery time, and neutrophil to lymphocyte ratio.\n\nThe model's performance was evaluated using metrics such as the area under the curve (AUC), accuracy, sensitivity, specificity, and F1 score. The XGBoost algorithm demonstrated the highest accuracy and best generalization ability among the four algorithms tested. The model's predictions are intended to aid clinical decision-makers in identifying high-risk patients, thereby enabling more targeted and efficient interventions.\n\nThe SHAP (SHapley Additive exPlanations) force plot was used to present the results of the predictive analysis, showing how different factors contribute to the predicted probability of VTE occurrence for individual patients. This visualization helps in understanding the model's decisions and the importance of various risk factors.",
  "model/duration": "The execution time of the model was influenced by the computational effort and training time required by the algorithms considered. Among the four algorithms compared\u2014XGBoost, random forest (RF), support vector machine (SVM), and k-nearest neighbor (KNN)\u2014the XGBoost algorithm was ultimately chosen for constructing the model due to its superior performance. The selection process involved evaluating the algorithms based on their computational efficiency and training duration, ensuring that the chosen model could be effectively implemented in a clinical setting. The XGBoost model demonstrated high accuracy and reliability, making it the optimal choice for predicting postoperative venous thromboembolism (VTE) in patients.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the models involved several rigorous steps to ensure their robustness and generalizability. Initially, the dataset was divided into a training set (70%) and a test set (30%). The training set was further used for internal validation through a k-fold cross-validation methodology. This approach helps in assessing the model's performance and stability by training and validating it on different subsets of the data.\n\nThe models were evaluated using three main criteria: discrimination, calibration, and clinical utility. Discrimination was measured using the area under the curve (AUC) of the receiver operating characteristic (ROC) curve, which indicates the model's ability to distinguish between patients who developed postoperative venous thromboembolism (VTE) and those who did not. Calibration was assessed using calibration curves, which show the agreement between predicted probabilities and actual outcomes. Clinical utility was evaluated using decision curve analysis (DCA), which determines the net benefit of the model's predictions at various threshold probabilities.\n\nAdditionally, the best-performing model was subjected to external validation using a separate dataset from another hospital. This step is crucial for evaluating the model's generalizability and predictive efficiency in real-world scenarios. The external validation set yielded an AUC value of 0.85, indicating high accuracy in disease prediction.\n\nThe models were built using four different machine learning algorithms: extreme gradient boosting (XGBoost), random forest (RF), support vector machine (SVM), and k-nearest neighbor algorithm (KNN). Each model's performance was compared, and the XGBoost algorithm was selected for its superior performance in terms of AUC and other evaluation metrics. The XGBoost model showed an AUC value of 0.989 in the training set and 0.912 in the validation set, demonstrating its strong discriminative ability. The Brier score, which measures the accuracy of probabilistic predictions, was also considered, with lower scores indicating better performance. All models exhibited excellent calibration, as evidenced by their calibration curves closely following the diagonal line, suggesting reliable predicted probabilities.\n\nIn summary, the evaluation method involved a comprehensive approach, including internal and external validation, multiple performance metrics, and a comparison of different machine learning algorithms. This ensured that the selected model is robust, generalizable, and clinically useful for predicting postoperative VTE in gastric cancer patients.",
  "evaluation/measure": "In our study, we evaluated the performance of four different machine learning models\u2014XGBoost, Random Forest (RF), Support Vector Machine (SVM), and k-Nearest Neighbor (KNN)\u2014using a comprehensive set of metrics. These metrics included the Area Under the Curve (AUC) with 95% Confidence Intervals (CI), Accuracy with 95% CI, Sensitivity with 95% CI, Specificity with 95% CI, F1 Score with 95% CI, Cutoff with 95% CI, and Kappa with 95% CI. These metrics were calculated for both the training and validation sets, providing a robust assessment of each model's performance.\n\nThe AUC is a critical metric that measures the model's ability to distinguish between positive and negative classes, with higher values indicating better performance. Accuracy reflects the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall, measures the model's ability to identify positive cases, while specificity measures its ability to identify negative cases. The F1 Score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. The Cutoff value is the threshold probability at which the model classifies a case as positive or negative. Kappa measures the agreement between the predicted and observed classifications, adjusted for the agreement that could be expected by chance.\n\nAdditionally, we used the Brier score to evaluate the accuracy of the models' predictions, with lower scores indicating better performance. Calibration curves were plotted to assess the agreement between predicted probabilities and actual outcomes, and decision curve analysis (DCA) was performed to determine the net benefit of the models across different threshold probabilities.\n\nThe set of metrics used in this study is representative of standard practices in the literature, ensuring a thorough and unbiased evaluation of the models' performance. The inclusion of multiple metrics allows for a nuanced understanding of each model's strengths and weaknesses, facilitating informed decision-making in the selection of the most effective predictive model for postoperative venous thromboembolism (VTE) in gastric cancer patients.",
  "evaluation/comparison": "In our study, we evaluated and compared four different machine learning algorithms to predict postoperative venous thromboembolism (VTE) in patients with gastric cancer. The algorithms compared were extreme gradient boosting (XGBoost), random forest (RF), support vector machine (SVM), and k-nearest neighbor (KNN).\n\nThe comparison was conducted using several criteria to ensure a comprehensive evaluation. First, we assessed the discrimination ability of each model using the area under the curve (AUC) from the receiver operating characteristic (ROC) curves. This metric provided insights into how well each model could distinguish between patients who developed postoperative VTE and those who did not.\n\nSecond, we evaluated the calibration performance of the models using calibration plots. These plots helped us understand the agreement between the predicted probabilities and the actual outcomes, ensuring that the models' predictions were reliable.\n\nThird, we performed decision curve analysis (DCA) to determine the clinical utility of each model. This analysis helped us identify the range of threshold probabilities within which each model provided a net benefit, indicating its practical value in clinical decision-making.\n\nAdditionally, we conducted internal validation using k-fold cross-validation to assess the generalization ability of the models. This step ensured that the models could perform well on unseen data, which is crucial for their reliability in real-world applications.\n\nThe comparison also included an evaluation of model complexity. For instance, SVM and KNN algorithms were noted to have high model complexity, which could potentially hinder their performance on large datasets. Conversely, the XGBoost algorithm demonstrated lower model complexity and was better suited for multidimensional studies, making it a more efficient choice for our predictive model.\n\nAfter a thorough comparison, the XGBoost algorithm was selected for constructing the final predictive model due to its superior performance across the evaluated criteria. This algorithm offered more options for parameter tuning, enhancing the model\u2019s performance control and making it the most effective choice for predicting postoperative VTE in our study.",
  "evaluation/confidence": "The evaluation of the models in this study includes several performance metrics, each accompanied by confidence intervals. These metrics provide a clear indication of the models' predictive capabilities and their reliability. The area under the curve (AUC), accuracy, sensitivity, specificity, F1 score, cutoff, and Kappa values are all presented with 95% confidence intervals, offering a comprehensive view of the models' performance.\n\nThe AUC values, which measure the models' ability to distinguish between positive and negative classes, are particularly noteworthy. For instance, the XGBoost model achieved an AUC of 0.989 in the training set and 0.912 in the validation set, both with specified confidence intervals. This high AUC, along with the narrow confidence intervals, suggests strong discriminative power and consistency in performance.\n\nAccuracy, which reflects the proportion of true results (both true positives and true negatives) among the total number of cases examined, is also reported with confidence intervals. The XGBoost model, for example, demonstrated an accuracy of 0.944 in the training set and 0.901 in the validation set, indicating robust overall performance.\n\nSensitivity and specificity, which measure the true positive rate and true negative rate respectively, are crucial for understanding the models' diagnostic capabilities. The XGBoost model showed high sensitivity (0.978 in the training set and 0.898 in the validation set) and specificity (0.939 in the training set and 0.837 in the validation set), with corresponding confidence intervals that reinforce the reliability of these metrics.\n\nThe F1 score, which balances precision and recall, is another important metric. The XGBoost model achieved an F1 score of 0.752 in the training set and 0.636 in the validation set, with confidence intervals that provide insight into the variability of this measure.\n\nThe Kappa statistic, which assesses the agreement between the predicted and observed classifications while accounting for the possibility of chance agreement, is also included. The XGBoost model's Kappa values of 0.653 in the training set and 0.490 in the validation set, along with their confidence intervals, indicate a moderate to substantial level of agreement.\n\nIn summary, the inclusion of confidence intervals for all performance metrics allows for a thorough evaluation of the models' reliability and consistency. The statistical significance of these metrics, as evidenced by the narrow confidence intervals, supports the claim that the XGBoost model, in particular, demonstrates superior performance compared to other models and baselines. This comprehensive evaluation provides a strong foundation for the conclusions drawn in this study.",
  "evaluation/availability": "Not enough information is available."
}