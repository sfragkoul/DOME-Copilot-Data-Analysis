{
  "publication/title": "A prediction model for the risk of developing mild cognitive impairment in older adults with sarcopenia: evidence from the CHARLS.",
  "publication/authors": "Liu X, Ni J, Wang B, Yin R, Tang J, Chu Q, You L, Wu Z, Cao Y, Ji C",
  "publication/journal": "Aging clinical and experimental research",
  "publication/year": "2025",
  "publication/pmid": "40055290",
  "publication/pmcid": "PMC11889009",
  "publication/doi": "10.1007/s40520-025-02980-2",
  "publication/tags": "- Sarcopenia\n- Mild Cognitive Impairment\n- Machine Learning\n- Deep Learning\n- Neural Networks\n- Predictive Modeling\n- Aging\n- Health Status\n- Physical Measurements\n- Cognitive Status",
  "dataset/provenance": "The dataset used in this study is sourced from the China Health and Retirement Longitudinal Study (CHARLS). CHARLS has conducted five national surveys to date, and data from four prior surveys (2011, 2013, 2015, and 2018) were utilized. These surveys collected physical measures of patients with sarcopenia, focusing on individuals with normal cognitive function at baseline and including indicators of cognitive and activities of daily living (ADL) outcomes. Participants with severe physical impairments and psychiatric disorders were excluded from the analysis.\n\nA total of 570 patients with sarcopenia were included in the subsequent analysis. The CHARLS datasets are publicly available and can be downloaded from the CHARLS home page. The study was approved by the Biomedical Ethics Committee of Peking University, and all participants provided informed consent. Detailed information about CHARLS and the data screening process can be found in previous literature and supplementary materials.\n\nThe dataset has been used in various studies within the community, and its comprehensive nature makes it a valuable resource for research on sarcopenia and related conditions. The inclusion criteria and exclusion processes ensure that the data is robust and relevant for the study's objectives.",
  "dataset/splits": "The dataset was split into two main parts: a training and test set, and a validation set.\n\nFor the training and test set, 414 patients with sarcopenia were used. These were divided in an 8:2 ratio, resulting in 331 patients in the training set and 83 patients in the test set.\n\nThe validation set consisted of 156 patients with sarcopenia, of which 25 had a positive outcome. This set was used to independently validate the performance of the model.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "No datasets were generated or analyzed during the current study. Therefore, there is no data to release in a public forum.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is deep learning (DL), specifically a feed-forward neural network. This type of neural network is designed to learn and infer higher-order nonlinear associations between clinical features and patient outcomes in a data-driven manner.\n\nThe DL approach is not entirely new, but its application in the medical field, particularly for predicting mild cognitive impairment (MCI) in patients with sarcopenia, is innovative. The neural network we constructed consists of an input layer, two hidden layers, and an output layer, utilizing a sigmoid activation function for the neural nodes. This architecture allows the model to discover distributed feature representations of data by combining low-level features to form more abstract high-level representations.\n\nThe reason this DL model was not published in a machine-learning journal is that the focus of our research is on its application in the medical field rather than the development of new machine-learning algorithms. Our primary goal was to leverage the strengths of DL to improve the prediction of MCI in patients with sarcopenia, demonstrating the model's practical utility in a clinical setting. The model's performance, with an AUC of 0.708 on the test set, highlights its effectiveness in this specific medical context. Additionally, the development of an online calculation tool further facilitates the clinical application of our model, making it accessible for predicting the future risk of MCI in patients with sarcopenia.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model construction process involved machine learning techniques for feature selection, but the final model is a deep learning feed-forward neural network.\n\nThe feature selection process used a random forest model to rank the importance of features and exclude those with a mean decrease Gini (MDG) of less than 1. The remaining features were then subjected to recursive feature elimination using ten-fold cross-validation to avoid overfitting. This dual method validation resulted in eight features being selected for the final model.\n\nThe deep learning model was constructed using a feed-forward neural network with four layers: an input layer, two hidden layers, and an output layer. The activation function used was sigmoid. The model was trained and tested using data from 414 patients with sarcopenia, divided into an 8:2 ratio for training and testing, respectively.\n\nThe validation of the prediction model was performed using an independent set of 156 patients with sarcopenia from the CHARLS cohort 2015\u20132018. This ensures that the training data is independent from the validation data, providing a robust assessment of the model's performance.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for model training and validation. Initially, we focused on respondents' general information, health status, physical measurements, and cognitive status. We considered 30 drivers of mild cognitive impairment (MCI), all of which had 80% or more completeness of the data. The expression levels of all variables were standardized to ensure consistency.\n\nMachine learning techniques were employed for feature double filtering. A random forest model was constructed using the R software random forest package to rank the importance of features. Features with a mean decrease Gini (MDG) of less than 1 were excluded. The remaining 10 features underwent recursive feature elimination (RFE) using the caret package, with ten-fold cross-validation to prevent overfitting. This dual method validation resulted in the final selection of 8 features for the modeling stage. These features included appendicular skeletal muscle mass (ASM), skeletal muscle mass index (SMI), body mass index (BMI), grip strength, walk time, depression score, Short Physical Performance Battery (SPPB), and sleep time.\n\nThe data was merged and filtered using Stata software, and missing values were filled using the R software missforest package. A feed-forward neural network model was constructed using PyTorch. The Receiver Operating Characteristic (ROC) curve was used to represent the model's discrimination, assessed by the area under the curve (AUC) value. Statistical analyses were performed using Stata17, R.4.2.2, and PyTorch 2.2.1. A two-sided P value less than or equal to 0.05 was considered statistically significant.",
  "optimization/parameters": "The model utilized eight input parameters for predicting mild cognitive impairment (MCI) in patients with sarcopenia. These parameters were selected through a rigorous process involving machine learning techniques. Initially, 30 potential predictors were considered, all with at least 80% data completeness. These variables were standardized, and a machine learning feature double filtering method was applied. A random forest model, constructed using the R software random forest package, ranked the importance of these features based on the mean decrease Gini (MDG) criterion. Features with an MDG of less than 1 were excluded, leaving 10 features. These remaining features underwent recursive feature elimination (RFE) using the caret package, with ten-fold cross-validation to prevent overfitting. This dual validation method ensured that the final eight features\u2014ASM, SMI, BMI, grip strength, walk time, depression score, SPPB, and sleep time\u2014were robust and relevant for the model. Among these, muscle mass index, particularly ASM, played a crucial role in the model's prediction, showing a significant difference between the MCI and non-MCI groups.",
  "optimization/features": "In the optimization process of our model, feature selection was indeed performed to identify the most relevant predictors. Initially, we considered 30 potential drivers of mild cognitive impairment (MCI), all of which had at least 80% data completeness. To ensure robust feature selection, we employed a dual-filtering approach using machine learning techniques. First, a random forest model was constructed to rank the importance of features based on the mean decrease Gini (MDG) criterion. Features with an MDG of less than 1 were excluded, leaving us with 10 features. These remaining features were then subjected to recursive feature elimination (RFE) using ten-fold cross-validation to avoid overfitting. This dual-validation process resulted in the final selection of 8 features, which were used as input for the subsequent modeling stage. These features included appendicular skeletal muscle mass (ASM), skeletal muscle mass index (SMI), body mass index (BMI), grip strength, walk time, depression score, Short Physical Performance Battery (SPPB), and sleep time. The feature selection process was conducted using the training set only, ensuring that the test set remained independent for unbiased evaluation.",
  "optimization/fitting": "The fitting method employed in this study involved constructing a 4-layer feed-forward neural network using deep learning techniques. This network consisted of an input layer, two hidden layers, and an output layer, with sigmoid activation functions for the neural nodes. The model was trained and tested using a dataset of 414 patients with sarcopenia, divided into an 8:2 ratio for the training and test sets, respectively.\n\nThe number of parameters in the neural network was indeed larger than the number of training points. To address the potential issue of overfitting, several strategies were implemented. Firstly, recursive feature elimination (RFE) was used to select the most important features, reducing the dimensionality of the input data. This process involved ten-fold cross-validation to ensure that the selected features were generalizable and not overfitted to the training data. Secondly, the loss curve for both the training and test sets was monitored to ensure that the model was well-fitted and did not exhibit signs of overfitting or underfitting. The loss curve indicated that the model was appropriately fitted to the data without overfitting.\n\nTo further mitigate overfitting, the model underwent double validation using machine learning methods. This involved constructing a random forest model to rank the importance of features and exclude those with a mean decrease Gini (MDG) of less than 1. The remaining features were then subjected to recursive feature elimination using the caret package, with ten-fold cross-validation to avoid overfitting. This dual method validation ensured that the final model was robust and generalizable.\n\nUnderfitting was addressed by ensuring that the neural network had sufficient complexity to capture the underlying patterns in the data. The use of two hidden layers and sigmoid activation functions allowed the model to learn complex, nonlinear relationships between the input features and the outcome. Additionally, the model's performance was evaluated using the area under the receiver operating characteristic (ROC) curve (AUC), which provided a comprehensive measure of the model's discriminative ability. The AUC value for the deep learning model was 0.708, indicating strong predictive performance.\n\nIn summary, the fitting method involved a carefully designed neural network architecture, feature selection using recursive feature elimination with cross-validation, and monitoring of the loss curve to ensure proper fitting. These strategies collectively addressed the risks of overfitting and underfitting, resulting in a robust and generalizable model.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was recursive feature elimination (RFE) with ten-fold cross-validation. This process helped us to select the most relevant features for our model, reducing the risk of overfitting by eliminating less important variables. Additionally, we used a random forest model to rank the importance of features and excluded those with a mean decrease Gini (MDG) of less than 1. This dual method validation ensured that only the most significant features were included in the final model.\n\nFurthermore, we divided our dataset into training and test sets in an 8:2 ratio, which helped in evaluating the model's performance on unseen data. The loss curves for both the training and test sets indicated that our deep learning model was well-fitted and did not show signs of underfitting or overfitting. These measures collectively contributed to the reliability and generalizability of our predictive model for mild cognitive impairment in patients with sarcopenia.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study is a deep learning (DL) model, specifically a feed-forward neural network, which is often considered a black-box model due to its complex, multi-layered structure. This type of model learns intrinsic patterns and levels of representation of sample data by combining low-level features to form more abstract high-level representations. However, the model's design and training process allow for some level of interpretability.\n\nThe neural network discovers distributed feature representations of data, mimicking the pattern of transmitting and processing information between neurons in the brain. This involves designing and establishing appropriate neuron computation nodes and multi-computing hierarchies, selecting proper input and output layers, and through learning and tuning of the network, establishing the input-to-output functional relationship.\n\nOne of the strengths of the DL model is its ability to learn and infer higher-order nonlinear associations between clinical features and patient outcomes in an entirely data-driven manner. This allows the model to deeply analyze the effects of variables and interactions between variables on outcomes, which is something that cannot be achieved by ordinary regression methods.\n\nFor example, although age and gender were not directly included in the model, their interactions with other variables play a critical role in shaping the model. Factors such as appendicular skeletal muscle mass (ASM) and skeletal muscle mass index (SMI), which are calculated from variables like age and gender, were included in the model. Additionally, grip strength and gait speed, which are significant predictors of mild cognitive impairment (MCI), were consistent with the characteristics selected for the models.\n\nFurthermore, the model's ability to predict the effect of individual variables on the outcome and the effect of interactions between variables on MCI provides some level of interpretability. This is particularly useful in understanding the complex relationships between various clinical features and the risk of developing MCI in patients with sarcopenia.\n\nIn summary, while the DL model is a black-box model to some extent, its design and training process, along with its ability to analyze variable interactions, provide a level of interpretability that is crucial for understanding the model's predictions and their clinical implications.",
  "model/output": "The model developed is a classification model. It is designed to predict the risk of Mild Cognitive Impairment (MCI) in patients with sarcopenia. The output of the model is a binary classification, categorizing patients into either a high-risk or low-risk group for developing MCI. This classification is based on a risk threshold of 51.72%, which was determined to optimize the prediction of MCI or non-MCI outcomes.\n\nThe model's performance was evaluated using metrics such as the Area Under the Curve (AUC), accuracy, precision, and F1 score. The AUC value for the test set was 0.708, indicating a good level of discrimination between the two classes. The model's accuracy, precision, and F1 score were also reported, providing a comprehensive assessment of its predictive performance.\n\nThe output of the model is not a continuous value but rather a categorical prediction, making it a classification model. The use of a feed-forward neural network with sigmoid activation functions further supports this, as such networks are commonly used for binary classification tasks. The model's ability to handle complex, nonlinear relationships between input features and the output class is a key strength, allowing it to capture intricate patterns in the data that might be missed by simpler regression models.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the model is not publicly released.\n\nHowever, to facilitate clinical application, an online calculation tool has been developed. This tool is accessible via a web server at the URL http://47.115.214.16:8000/. This tool allows users to predict the future risk of mild cognitive impairment (MCI) in patients with sarcopenia. The tool is designed to be user-friendly and accessible, enabling healthcare professionals to utilize the model's predictive capabilities without needing to implement the underlying algorithms themselves.",
  "evaluation/method": "The evaluation of the method involved several key steps to ensure its robustness and generalizability. Initially, the model was trained and tested using a dataset of 414 patients with sarcopenia, divided into an 8:2 ratio for training and testing, respectively. The performance of the deep learning (DL) model was assessed using the area under the Receiver Operating Characteristic (ROC) curve (AUC), which provides a measure of the model's discriminative ability. The AUC for the test set was 0.708, indicating a strong predictive performance compared to logistic regression, which had an AUC of 0.557.\n\nTo further validate the model, an independent validation set consisting of 156 patients with sarcopenia from the CHARLS cohort (2015\u20132018) was used. The validation set included 25 patients with a positive outcome. The AUC for the validation set was 0.711, demonstrating the model's good performance in an independent dataset. Additionally, the model's accuracy, precision, and F1 score were calculated, with values of 0.628, 0.929, and 0.737, respectively.\n\nThe model's performance was also evaluated using a loss curve, which showed that the DL model was well-fitted and did not exhibit signs of underfitting or overfitting. The loss curve for both the training and test sets was visualized to ensure the model's stability and reliability.\n\nFurthermore, risk stratification was performed by calculating the risk for each individual in the entire training cohort. Patients were divided into low-risk and high-risk groups based on a 51.72% risk threshold. The actual risk probability of critical illness events was significantly different between the low-risk (14.15%) and high-risk (39.81%) groups, highlighting the model's ability to stratify patients effectively.\n\nIn summary, the evaluation method involved a combination of training and testing on a primary dataset, independent validation, and risk stratification. These steps ensured that the model's performance was thoroughly assessed and validated, demonstrating its potential for clinical application in predicting the future risk of mild cognitive impairment (MCI) in patients with sarcopenia.",
  "evaluation/measure": "To evaluate the performance of our prediction model, we primarily focused on several key metrics. The Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve was used to assess the model's discrimination ability. Our deep learning (DL) model demonstrated an AUC of 0.708 (95% CI: 0.544\u20130.844) on the test set, indicating strong predictive performance. For comparison, a logistic regression model using the same variables achieved an AUC of 0.557 (0.95 CI, 0.410\u20130.705), highlighting the superior performance of our DL approach.\n\nIn addition to the AUC, we reported other crucial performance metrics. The model's accuracy on the test set was 0.542, while the precision was 0.939. The F1 score, which balances precision and recall, was 0.633. These metrics provide a comprehensive view of the model's effectiveness in predicting mild cognitive impairment (MCI) in patients with sarcopenia.\n\nFor the validation set, which included 156 patients with sarcopenia from the CHARLS cohort 2015\u20132018, the AUC of the validation centralized model was 0.711 (0.95 CI, 0.588\u20130.823). The model's accuracy was 0.628, precision was 0.929, and the F1 score was 0.737. These results further validate the robustness and generalizability of our model.\n\nThe reported metrics are representative of standard practices in the literature for evaluating predictive models, particularly in the context of medical and health-related studies. The use of AUC, accuracy, precision, and F1 score ensures that our model's performance is thoroughly assessed and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we performed a comparison between our deep learning (DL) model and a simpler baseline method, specifically logistic regression. This comparison was conducted to evaluate the predictive performance of our model in determining the risk of mild cognitive impairment (MCI) in patients with sarcopenia.\n\nThe logistic regression model served as a baseline to assess the improvement provided by our DL approach. The area under the curve (AUC) for the logistic regression model was 0.557, indicating moderate predictive performance. In contrast, our DL model achieved an AUC of 0.708 on the test set, demonstrating a significant improvement in predictive accuracy.\n\nAdditionally, we validated our DL model using an independent validation set consisting of 156 patients with sarcopenia from the CHARLS cohort 2015\u20132018. The AUC for the validation set was 0.711, further confirming the robustness and generalizability of our model.\n\nThe comparison to logistic regression highlights the advantages of using DL for capturing complex, nonlinear relationships between variables, which are not easily discernible through simpler regression techniques. This comparison underscores the potential of DL in enhancing predictive models for clinical applications, particularly in the context of MCI risk assessment in sarcopenia patients.",
  "evaluation/confidence": "The evaluation of the prediction model's performance was conducted using several metrics, each accompanied by confidence intervals to provide a measure of uncertainty. The Area Under the Curve (AUC) for the validation set was reported as 0.711 with a 95% confidence interval (CI) of 0.588\u20130.823. For the test set, the AUC of the deep learning (DL) model was 0.708 with a 95% CI of 0.544\u20130.844, while the logistic regression model had an AUC of 0.557 with a 95% CI of 0.410\u20130.705. These intervals help in understanding the reliability of the AUC estimates.\n\nThe model's accuracy, precision, and F1 score were also evaluated. For the validation set, the accuracy was 0.628, precision was 0.929, and the F1 score was 0.737. On the test set, the DL model achieved an accuracy of 0.542, a precision of 0.939, and an F1 score of 0.633. These metrics provide a comprehensive view of the model's performance across different aspects.\n\nStatistical significance was assessed using a two-sided P value, with a threshold of 0.05 or less considered significant. The P value for the difference in muscle mass index (ASM) between the MCI and non-MCI groups was 0.02, indicating a statistically significant difference. This suggests that the model's predictions are robust and that the observed differences are unlikely to be due to chance.\n\nThe use of confidence intervals and statistical significance testing enhances the confidence in the model's performance and its superiority over baselines. The reported metrics and their associated confidence intervals provide a clear indication of the model's reliability and its potential for practical application.",
  "evaluation/availability": "No datasets were generated or analyzed during the current study. Therefore, no raw evaluation files are available for public release."
}