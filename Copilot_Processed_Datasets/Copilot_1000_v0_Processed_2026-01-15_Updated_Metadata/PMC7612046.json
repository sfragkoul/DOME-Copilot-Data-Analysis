{
  "publication/title": "Multiplex Serum Biomarker Assays Improve Prediction of Renal and Mortality Outcomes in Chronic Kidney Disease.",
  "publication/authors": "Martin WP, Conroy C, Naicker SD, Cormican S, Griffin TP, Islam MN, McCole EM, McConnell I, Lamont J, FitzGerald P, Ferguson JP, Richardson C, Logue SE, Griffin MD",
  "publication/journal": "Kidney360",
  "publication/year": "2021",
  "publication/pmid": "34849485",
  "publication/pmcid": "PMC7612046",
  "publication/doi": "10.34067/kid.0007552020",
  "publication/tags": "- Chronic Kidney Disease\n- Biomarkers\n- Multiplex Biochip Array\n- Renal Outcomes\n- Mortality Prediction\n- Logistic Regression\n- Random Forest Models\n- Cox Proportional Hazards\n- Clinical Variables\n- Prognostic Value\n- Serum Biomarkers\n- Predictive Modeling\n- Kidney Failure\n- Statistical Analysis\n- Machine Learning",
  "dataset/provenance": "The dataset used in this study was collected from patients who participated in a clinical study. The study cohort consisted of 139 individuals. The data included baseline characteristics and serum biomarker concentrations, which were stratified by the development of a composite renal and mortality end point. This end point was defined as a 40% decline in eGFR, doubling of serum creatinine, the need for renal replacement therapy, or death.\n\nThe dataset included various clinical parameters such as age, sex, presence of diabetes mellitus, hypertension, and coronary artery disease. Additionally, it contained laboratory data like serum creatinine levels, estimated glomerular filtration rate (eGFR), urine albumin-to-creatinine ratio (uACR), and urine protein-to-creatinine ratio (uPCR). The study also measured concentrations of multiple serum biomarkers, including sTNFR1, sTNFR2, NGAL, cystatin C, and others.\n\nThe data were analyzed using statistical methods and machine-learning techniques, including random forest models and Cox proportional hazards regression. The study aimed to evaluate the predictive value of these biomarkers in relation to renal and mortality outcomes. The dataset has not been previously used in other published papers or by the community, as it is specific to this particular study.",
  "dataset/splits": "Not applicable",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the random forest classifier, which is a type of supervised learning algorithm. Random forests are an ensemble learning method that operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe random forest algorithm is not new; it has been well-established in the machine-learning community for several decades. It was developed by Leo Breiman and Adele Cutler and has been extensively used in various fields due to its robustness and ability to handle large datasets with high dimensionality.\n\nThe reason the random forest algorithm was not published in a machine-learning journal in this context is that our primary focus is on the application of this algorithm to predict a composite renal and mortality end point in patients with chronic kidney disease. The innovation lies in the application of the algorithm to this specific medical problem, rather than in the development of a new machine-learning algorithm. Our study aims to demonstrate the added predictive value of multiple serum biomarkers when considered alone and in addition to conventional clinical variables, using the random forest classifier as a tool to achieve this.",
  "optimization/meta": "The models employed in this study do not use data from other machine-learning algorithms as input. Instead, they utilize clinical variables and biomarker concentrations directly.\n\nThe study primarily focuses on two types of models: random forest classification models and Cox proportional hazards regression models.\n\nRandom forest models were used to predict the composite renal and mortality end point. These models were trained on three different sets of variables: clinical variables alone (age, sex, hypertension, diabetes, and eGFR), biomarkers alone, and a combination of clinical variables and biomarkers. The random forest approach has several advantages, including handling regressor collinearity and automatically selecting and fitting nonlinear relationships and statistical interactions.\n\nCox proportional hazards regression models were constructed to investigate the relationships between biomarkers and time to renal and mortality end points. Two models were created: a clinical model adjusting for age, sex, hypertension, diabetes, and eGFR, and a clinical plus biomarker model that additionally incorporated all log-transformed biomarker values. Backward elimination was performed to create a parsimonious model.\n\nThe study did not explicitly mention the use of a meta-predictor that combines the outputs of different machine-learning algorithms. Instead, it used individual models and compared their performance. The training data for these models was independent, as indicated by the leave-one-out cross-validation approach used for the random forest models. This approach ensures that each individual's data is used for both training and validation, but not simultaneously, maintaining the independence of the training data.",
  "optimization/encoding": "For the machine-learning algorithms employed in this study, data encoding and preprocessing were crucial steps to ensure the models could effectively learn from the input features. Biomarkers were transformed using the natural logarithm to stabilize variance and make the data more normally distributed, which is beneficial for many statistical and machine-learning techniques. This transformation was applied to all biomarker concentrations before they were inputted into the models.\n\nClinical variables such as age, sex, hypertension, diabetes, and estimated glomerular filtration rate (eGFR) were included as they are known to be significant predictors of renal and mortality outcomes. These variables were used in their original form without further transformation, as they are categorical or already in a suitable numerical format.\n\nFor the random forest models, biomarkers were inputted as continuous variables. The models utilized recursive binary splitting to select biomarker thresholds that maximized node purity, which helps in creating more accurate and interpretable decision trees within the forest. This approach allowed the models to capture nonlinear relationships and interactions between variables effectively.\n\nIn the Cox proportional hazards regression models, biomarkers were also log-transformed to ensure that the hazard ratios could be interpreted per one unit change in the natural logarithm of biomarker concentrations. This transformation is standard practice in survival analysis to handle skewed data and to make the coefficients more interpretable.\n\nAdditionally, for sensitivity analyses, baseline urinary albumin-to-creatinine ratio (uACR) was included in the random forest models. Missing uACR data were imputed using the \"rfImpute\" function from the R package randomForest. This imputation method leverages the random forest algorithm to predict and fill in missing values based on the available data, ensuring that the models could utilize the full dataset without bias from missing information.\n\nOverall, the data encoding and preprocessing steps were designed to prepare the data in a way that would facilitate the learning process of the machine-learning models, ensuring that they could accurately predict the composite renal and mortality end point.",
  "optimization/parameters": "In our study, we utilized three types of random forest classification models to predict the composite renal and mortality end point. These models were based on different sets of input parameters:\n\n1. Clinical variables alone, which included age, sex, hypertension, diabetes, and baseline estimated glomerular filtration rate (eGFR).\n2. Serum biomarkers alone.\n3. A combination of clinical variables and serum biomarkers.\n\nThe selection of these parameters was guided by their known associations with renal and mortality outcomes in chronic kidney disease. For the random forest models, we did not perform a formal feature selection process to determine the optimal number of parameters (p). Instead, we included all available clinical variables and biomarkers that were deemed relevant based on prior literature and clinical expertise.\n\nThe random forest models were constructed using a leave-one-out cross-validation approach, which involved iteratively excluding one individual from the training dataset and using the trained model to predict the class of the excluded individual. This process was repeated for each individual in the dataset, ensuring that each participant had a predicted class assigned by each of the three model types.\n\nIn addition to the random forest models, we also constructed multivariable Cox proportional hazards regression models to investigate the relationships between biomarkers and time to renal and mortality end points. For these models, we initially included all log-transformed biomarker values along with clinical variables (age, sex, hypertension, diabetes, and eGFR). Backward elimination of nonsignificant biomarker effects was performed using the Akaike information criterion (AIC) to create a final parsimonious clinical plus biomarker model. Biomarkers with P-values greater than 0.05 were manually excluded from the AIC-selected model.\n\nThe final Cox model included three biomarkers: C-reactive protein, neutrophil gelatinase-associated lipocalin (NGAL), and C3a-desArg, along with the clinical variables. The selection of these biomarkers was based on their statistical significance and the model's performance, as assessed by the AIC and likelihood ratio chi-squared tests.",
  "optimization/features": "In the optimization process, three types of random forest classification models were implemented to evaluate the prediction of the composite renal and mortality end point. These models utilized different sets of input features:\n\n1. Clinical variables alone, which included age, sex, hypertension, diabetes, and baseline estimated glomerular filtration rate (eGFR).\n2. Serum biomarkers alone.\n3. A combination of clinical variables and serum biomarkers.\n\nThe total number of features (f) used as input varied depending on the model type. For the clinical variables alone, five features were used. For the serum biomarkers alone, the number of features depended on the specific biomarkers included in the analysis. For the combined model, the number of features was the sum of the clinical variables and the selected biomarkers.\n\nFeature selection was performed using a backward elimination process in the context of Cox proportional hazards regression models. This process involved stepwise backward elimination of nonsignificant biomarker effects from the clinical plus biomarker model using the Akaike Information Criterion (AIC). Biomarkers for which the P-values of their hazard ratios were greater than 0.05 were manually excluded to create a final parsimonious clinical plus biomarker model. This feature selection was done using the training set only, ensuring that the model's performance was not biased by the test data.\n\nAdditionally, the leave-one-out cross-validation approach was implemented for the random forest models. This procedure involved excluding one individual at a time from the training set to predict the class of the excluded individual. This process was repeated iteratively for each individual in the dataset, ensuring that the model's performance was evaluated on unseen data.",
  "optimization/fitting": "The study employed random forest models, which are known for their robustness against overfitting due to their ensemble nature and the use of bootstrap aggregating (bagging). The models were trained using a leave-one-out cross-validation approach, which is a stringent method that helps to ensure the model's generalizability and reduces the risk of overfitting. This approach involves training the model on all but one data point and then testing it on the excluded data point, repeating this process for each data point in the dataset. This method provides a thorough evaluation of the model's performance and helps to mitigate overfitting.\n\nAdditionally, the random forest models were evaluated using area under the curve (AUC) values and model performance metrics such as sensitivity, specificity, positive predictive value, and negative predictive value across three probability thresholds (10%, 30%, and 50%). These metrics provide a comprehensive assessment of the model's predictive accuracy and help to ensure that the models are not underfitting the data.\n\nThe study also included a series of sensitivity analyses to further evaluate the predictive value of serum biomarkers incorporated in the random forest models. These analyses help to validate the robustness of the models and ensure that they are not overly sensitive to specific subsets of the data.\n\nIn summary, the use of leave-one-out cross-validation, comprehensive performance metrics, and sensitivity analyses helps to rule out both overfitting and underfitting in the random forest models employed in this study.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method used was leave-one-out cross-validation, particularly for our random forest models. This approach involved iteratively excluding one individual from the training dataset, training the model on the remaining data, and then predicting the class of the excluded individual. This process was repeated for each individual in the dataset, ensuring that each participant's predicted class was assigned by the model.\n\nAdditionally, we utilized backward elimination in our Cox proportional hazards regression models. This involved starting with a full model that included all potential predictors and then iteratively removing the least significant variables based on the Akaike Information Criterion (AIC). This step helped in creating a more parsimonious model by retaining only the most relevant predictors, thereby reducing the risk of overfitting.\n\nFurthermore, we calculated the mean decrease in accuracy as an estimate of variable importance in our random forest models. This metric helped in identifying which variables contributed most to the predictive power of the model, allowing us to focus on the most relevant biomarkers.\n\nThese techniques collectively ensured that our models were robust and generalizable, minimizing the risk of overfitting.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models employed in this study include both transparent and black-box components. The random forest models, which are a type of ensemble learning method, are generally considered black-box models due to their complexity and the difficulty in interpreting the individual decision trees within the forest. However, these models offer some level of interpretability through variable importance measures. For instance, the mean decrease in accuracy can be calculated to estimate the importance of each variable in the prediction process. This provides insights into which clinical variables and biomarkers are most influential in predicting the composite renal and mortality endpoint.\n\nIn contrast, the Cox proportional hazards regression models provide a more transparent approach. These models explicitly show the relationship between each variable and the outcome through hazard ratios. For example, the final parsimonious Cox model includes biomarkers such as C-reactive protein, NGAL, and C3a-desArg, along with clinical variables like age, sex, hypertension, diabetes, and eGFR. The hazard ratios indicate the risk associated with each unit change in the natural logarithm of biomarker concentrations, making it easier to understand the impact of each variable on the outcome.\n\nAdditionally, the decision tree generated using the R function \"rpart\" illustrates how multiple biomarkers can be used to classify the composite renal and mortality endpoint. This tree provides a visual representation of the decision-making process, showing how different biomarker thresholds are used to split the data and classify individuals. This visual interpretability helps in understanding the complementary information provided by multiple biomarkers.\n\nOverall, while the random forest models offer some interpretability through variable importance, the Cox models and decision trees provide more transparent and easily interpretable results. This combination allows for a comprehensive understanding of the predictive factors involved in the composite renal and mortality endpoint.",
  "model/output": "The model employed in this study is a classification model. Specifically, it utilizes a supervised machine-learning approach with binary classification random forests. The primary goal of this model is to predict the occurrence of a composite renal and mortality endpoint. This endpoint is defined as a 40% decline in estimated glomerular filtration rate (eGFR), doubling of serum creatinine, requirement for renal replacement therapy (RRT), or death.\n\nThe random forest models were trained using three different sets of variables: clinical variables alone (age, sex, hypertension, diabetes, and baseline eGFR), serum biomarkers alone, and a combination of clinical variables and serum biomarkers. The models were evaluated using a leave-one-out cross-validation approach, which involved excluding one individual from the training dataset and then predicting the class of the excluded individual. This process was repeated iteratively for each individual in the dataset.\n\nModel performance was assessed using several metrics, including sensitivity, specificity, positive predictive value, and negative predictive value. These metrics were calculated across three probability thresholds (10%, 30%, and 50%) for labeling patients as having developed the composite renal and mortality endpoint. Additionally, the area under the curve (AUC) values were calculated for each model type to evaluate their predictive performance.\n\nThe random forest models demonstrated that incorporating serum biomarkers, either alone or in combination with clinical variables, improved the predictive accuracy for the composite renal and mortality endpoint. The highest AUC values were observed in models that included both clinical variables and serum biomarkers, indicating the added value of biomarkers in enhancing prognostic capabilities.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the statistical analyses and machine learning models used in this study is not publicly released. The analyses were performed using the R statistical programming language, with specific packages such as survival, survminer, and pROC. These packages are available on the Comprehensive R Archive Network (CRAN) and can be accessed by researchers interested in replicating the methods. The R code itself, however, is not provided in the publication.\n\nFor those looking to implement similar models, the R packages mentioned are freely available under open-source licenses, allowing for their use in various research and educational settings. The survival package, for example, is used for survival analysis, including Cox proportional hazards regression models. The survminer package aids in drawing survival curves using ggplot2, and the pROC package is utilized for calculating and visualizing receiver operating characteristic curves.\n\nWhile the specific R scripts used in this study are not shared, the methodologies and statistical techniques are thoroughly described, enabling other researchers to adapt and apply these approaches in their own work. Additionally, the use of well-documented R packages ensures that the tools required for similar analyses are accessible and reproducible.",
  "evaluation/method": "The evaluation of the models involved several key steps and methods to ensure robustness and accuracy. For the random forest models, a leave-one-out cross-validation procedure was employed. This approach involved excluding one individual at a time from the training dataset, training the model on the remaining data, and then predicting the class of the excluded individual. This process was repeated iteratively for each individual in the dataset, resulting in a predicted class for each study participant across three model types: clinical variables alone, biomarkers alone, and clinical variables plus biomarkers.\n\nArea under the curve (AUC) values were calculated for each model type using the predicted probability of developing the composite renal and mortality endpoint and the actual recorded status of the individuals. Receiver operating characteristic (ROC) curves were plotted to visualize the performance of the models. Additionally, model performance metrics such as sensitivity, specificity, positive predictive value, and negative predictive value were calculated across three probability thresholds (10%, 30%, and 50%) for labeling patients as having developed the composite endpoint.\n\nFor the Cox proportional hazards regression models, multivariable models were created to investigate the relationships between biomarkers and time to renal and mortality endpoints. The primary analysis involved constructing two models: a clinical model adjusting for age, sex, hypertension, diabetes, and eGFR, and a clinical plus biomarker model that additionally incorporated log-transformed biomarker values. Backward elimination of nonsignificant biomarker effects was performed using stepAIC, and biomarkers with P-values of their hazard ratios greater than 0.05 were manually excluded to create a final parsimonious model. The adequacy of the Cox models was assessed using likelihood ratio chi-squared tests.\n\nSensitivity analyses were conducted to further evaluate the predictive value of serum biomarkers. These analyses included random forest models trained on clinical variables alone or in combination with biomarkers. The performance of these models was also assessed using AUC values and other metrics. Overall, the evaluation methods ensured a comprehensive assessment of the models' predictive capabilities and the significance of the biomarkers in predicting renal and mortality outcomes.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to assess the effectiveness of our models in predicting the composite renal and mortality endpoint. These metrics included sensitivity, specificity, positive predictive value, and negative predictive value. These metrics were calculated across three different probability thresholds: 10%, 30%, and 50%. This approach allowed us to evaluate how well our models performed at different levels of predicted probability for the endpoint.\n\nSensitivity, also known as the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. The positive predictive value indicates the probability that subjects with a positive screening test truly have the condition, while the negative predictive value indicates the probability that subjects with a negative screening test truly do not have the condition.\n\nWe also calculated the area under the curve (AUC) values for our models. The AUC provides a single scalar value that summarizes the performance of the model across all possible classification thresholds. Higher AUC values indicate better model performance.\n\nAdditionally, we estimated variable importance to the random forest models using the mean decrease in accuracy. This metric helps identify which variables contribute most to the predictive power of the model.\n\nOur choice of performance metrics is representative of standard practices in the literature, ensuring that our evaluation is comprehensive and comparable to other studies in the field. These metrics provide a clear and concise way to assess the strengths and weaknesses of our models, helping us to understand their potential clinical utility.",
  "evaluation/comparison": "In our study, we employed several statistical and machine learning methods to analyze and predict the composite renal and mortality end point. We utilized logistic regression to investigate univariate relationships between serum biomarkers and the composite end point. This method provided a straightforward baseline for understanding the individual impact of each biomarker.\n\nTo explore the combined value of all biomarkers, we used a supervised machine-learning approach with binary classification random forests. Random forests offer several advantages over logistic regression, including the ability to handle regressor collinearity and automatically select and fit nonlinear relationships and statistical interactions. This method allowed us to assess the predictive power of multiple biomarkers collectively.\n\nIn addition to random forests, we generated a binary classification decision tree to illustrate the complementary information provided by multiple biomarkers. The decision tree used recursive binary splitting to maximize node purity, which helped in identifying key biomarker thresholds.\n\nWe also constructed multivariable Cox proportional hazards regression models to investigate the relationships between biomarkers and time to renal and mortality end points. These models allowed us to adjust for clinical variables and evaluate the predictive value of biomarkers in addition to these variables.\n\nTo validate our models, we implemented a leave-one-out cross-validation approach for the random forest models. This procedure involved excluding one individual at a time from the training dataset and using the trained model to predict the class of the excluded individual. This process was repeated iteratively for each individual in the dataset, ensuring robust model performance metrics.\n\nFurthermore, we performed sensitivity analyses to evaluate the predictive value of serum biomarkers in different subgroups and under various conditions. These analyses included adjusting for baseline urinary albumin-to-creatinine ratio (uACR) and evaluating the models in subgroups with chronic kidney disease (CKD) stages 3\u20135 and available uACR data.\n\nOverall, our methods provided a comprehensive comparison of different statistical and machine learning approaches, ensuring that we could reliably predict the composite renal and mortality end point using serum biomarkers and clinical variables.",
  "evaluation/confidence": "The evaluation of the models in this study includes several statistical analyses to ensure the confidence and significance of the results. The performance metrics for the random forest models, such as sensitivity, specificity, positive predictive value, and negative predictive value, were calculated across three probability thresholds (10%, 30%, and 50%). These metrics provide a comprehensive view of the model's performance in predicting the composite renal and mortality end point.\n\nThe study also employed leave-one-out cross-validation for the random forest models, which is a rigorous method to assess model performance. This approach involves training the model on all but one data point and then testing it on the excluded data point. This process is repeated for each data point in the dataset, ensuring that the model's performance is evaluated on unseen data.\n\nIn addition to the random forest models, Cox proportional hazards regression models were used to investigate the relationships between biomarkers and time to renal and mortality end points. The primary Cox model analysis included clinical variables and serum biomarkers, and backward elimination was performed to create a parsimonious model. The significance of the biomarkers in the Cox models was assessed using P-values, with a threshold of 0.05 for statistical significance.\n\nThe study also calculated the area under the curve (AUC) values for the random forest models, which provide a single metric to evaluate the model's discriminative ability. The AUC values were compared across different model types, including clinical variables alone, biomarkers alone, and a combination of both. The highest AUC values were observed in the models that included both clinical variables and serum biomarkers, indicating superior performance.\n\nThe statistical significance of the results was further supported by likelihood ratio chi-squared tests, which compared the adequacy of the clinical model versus the clinical plus biomarker model. The Akaike information criterion (AIC) values were also used to assess model fit, with lower AIC values indicating better model performance.\n\nOverall, the study provides robust statistical evidence to support the confidence and significance of the results. The use of multiple performance metrics, cross-validation, and statistical tests ensures that the findings are reliable and that the models are superior to baselines and other methods.",
  "evaluation/availability": "Not enough information is available."
}