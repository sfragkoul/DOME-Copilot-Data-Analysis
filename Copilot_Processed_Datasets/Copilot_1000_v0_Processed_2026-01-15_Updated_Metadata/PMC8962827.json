{
  "publication/title": "Deep Generative Learning-Based 1-SVM Detectors for Unsupervised COVID-19 Infection Detection Using Blood Tests.",
  "publication/authors": "Dairi A, Harrou F, Sun Y",
  "publication/journal": "IEEE transactions on instrumentation and measurement",
  "publication/year": "2022",
  "publication/pmid": "35582656",
  "publication/pmcid": "PMC8962827",
  "publication/doi": "10.1109/tim.2021.3130675",
  "publication/tags": "- COVID-19\n- Blood test\n- Deep learning\n- Anomaly detection\n- Variational autoencoder\n- One-class support vector machine\n- Machine learning\n- Unsupervised learning\n- Generative models\n- Medical diagnosis",
  "dataset/provenance": "The datasets used in this study are derived from routine blood tests collected from two primary sources. The first dataset, referred to as Dataset 1, was obtained from the Albert Einstein Hospital (AEH) in S\u00e3o Paulo, Brazil. This dataset includes blood test samples from 5644 patients, of which 559 were infected with COVID-19. The data is publicly accessible on the Kaggle website and has been normalized with zero mean and unit variance. The original data is not accessible.\n\nThe second dataset, termed Dataset 2, is a compilation of three sub-datasets. The first sub-dataset consists of hematochemical values from 1624 patients at the San Raphael Hospital (OSR) in Milan, Italy, collected between February and May 2020. This sub-dataset includes 786 infected patients and 838 uninfected patients. The second sub-dataset contains 58 cases from the Istituto Ortopedico Galeazzi (IOG) in Milan, Italy, collected between March 5, 2020, and May 26, 2020, with an equal number of infected and uninfected cases (29 each). The third sub-dataset, known as the 2018 dataset, was gathered from blood samples at the OSR in November 2018 from 54 patients, all of whom were uninfected with COVID-19 but included 20 patients with pneumonia-like symptoms as confounding cases.\n\nThe datasets have been utilized in previous studies and by the community to assess the performance of various deep learning models in detecting COVID-19 infections. The first dataset contains 108 features, but only 18 important features were selected based on their relevance in indicating COVID-19, as reported in the literature. The second dataset uses 11 important features, including hemoglobin, platelets, white blood cells, and various blood cell counts, among others. The distribution of these features in both datasets is non-Gaussian.",
  "dataset/splits": "In this study, two datasets of routine blood tests samples were used to assess the performance of the investigated deep learning models. The first dataset, termed Dataset 1, was obtained from 5644 patients, including 559 infected patients with COVID-19. The second dataset, termed Dataset 2, was formed of three sub-datasets. The first sub-dataset consists of hematochemical values from 1624 patients at the San Raphael Hospital (OSR) collected from February to May 2020. There are 786 infected patients (48%) and 838 uninfected patients (52%). The second sub-dataset contains 58 cases: 29 are uninfected and 29 are infected with COVID-19 collected from the Istituto Ortopedico Galeazzi (IOG), Milan, Italy, between March 5, 2020, and May 26, 2020. The third sub-dataset, called the 2018 dataset, was obtained from blood samples gathered at the OSR in November 2018 from 54 patients. These patients are obviously uninfected from COVID-19, but 20 patients presented pneumonia-like symptoms and were employed as confounding cases.\n\nFor the experiments, the datasets were split as follows:\n\n* For the unsupervised V AE-, GAN-, RBM-, and DBN-based 1SVM detectors, 80% of the noninfected observations were chosen randomly for training. The remaining data, which include both infected and uninfected cases, were used for testing.\n* For the V AE-, GAN-, RBM-, and DBN-based softmax classifiers, each dataset was divided into two subsets: a training set composed of 80% of the data (including both infected and uninfected cases) and a testing set with 20% of the data (also including both infected and uninfected cases).",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study is publicly available. The first dataset, consisting of routine blood tests from 5644 patients, including 559 infected with COVID-19, was collected at the Albert Einstein Hospital in S\u00e3o Paulo, Brazil. This dataset is accessible on the Kaggle website. The data has been normalized with zero mean and unit variance, and the original data is not accessible.\n\nThe second dataset comprises three subsets collected from different hospitals and geographic locations. The first subset includes hematochemical values from 1624 patients at the San Raphael Hospital in Milan, Italy. The second subset contains 58 cases from the Istituto Ortopedico Galeazzi in Milan, Italy. The third subset, called the 2018 dataset, was obtained from blood samples gathered at the San Raphael Hospital in November 2018 from 54 patients.\n\nThe data is released under a public forum, specifically Kaggle, and is available for use by researchers and the public. The exact licensing details are not specified, but the data is intended for research purposes. The availability and usage of the data were enforced by making it publicly accessible on Kaggle, ensuring that researchers can access and utilize the dataset for their studies.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is unsupervised deep learning. Specifically, the approach employs a variational autoencoder (VAE) combined with a one-class support vector machine (1SVM). This combination is novel in the context of COVID-19 detection using blood test data, as it addresses the problem as an anomaly detection task.\n\nThe VAE is a type of generative model that learns to encode input data into a latent space and then decode it back to reconstruct the input. This process allows the VAE to capture the underlying distribution of the data, which is particularly useful for anomaly detection. The 1SVM, on the other hand, is an unsupervised binary classifier that learns to distinguish between normal and anomalous data points based on the features extracted by the VAE.\n\nThis approach is new in the sense that it applies unsupervised deep learning to COVID-19 detection using blood test data. While both VAEs and 1SVMs have been used in various applications, their combination for this specific task is innovative. The reason this work was not published in a machine-learning journal is that the primary focus is on the application of these techniques to COVID-19 detection rather than the development of new machine-learning algorithms. The study aims to contribute to the field of medical diagnostics by leveraging advanced machine-learning techniques to improve the detection of COVID-19 infections.",
  "optimization/meta": "In the optimization process, a meta-predictor approach was employed to enhance the discrimination capability for identifying COVID-19 cases. This meta-predictor utilizes the prediction outputs from several machine learning algorithms as input. Specifically, the algorithms involved include random forests (RF), logistic regression (LR), and extra trees. These algorithms' outputs are then fed into an XGBoost model. This integration aims to leverage the strengths of multiple models to improve the overall performance in detecting COVID-19 infections.\n\nThe use of a meta-predictor in this context is designed to combine the predictive power of different machine learning techniques. By doing so, the model can achieve better classification performance compared to using any single algorithm alone. The training data for each of the constituent models is independent, ensuring that the meta-predictor benefits from diverse and robust feature representations. This approach not only enhances the accuracy of COVID-19 detection but also provides a more reliable and comprehensive diagnostic tool.",
  "optimization/encoding": "In our study, the data encoding process involved several key steps to prepare the blood test data for the machine-learning algorithms. Initially, we addressed the issue of missing data using multivariate imputation by chained equations based on random forest regressors. This technique estimates missing values by considering the relationships with other variables, thereby improving the quality of the imputed data.\n\nThe datasets used in this study consisted of routine blood test samples from two hospitals: the Albert Einstein Hospital in S\u00e3o Paulo, Brazil, and the San Raffaele Hospital in Milan, Italy. The first dataset, termed Dataset 1, included samples from 5644 patients, with 559 infected with COVID-19. The second dataset, termed Dataset 2, comprised hematochemical values from 1624 patients, with 786 infected and 838 uninfected.\n\nBoth datasets were normalized to have zero mean and unit variance. This normalization step is crucial for ensuring that all features contribute equally to the model's learning process. For Dataset 1, we selected 18 important features based on their relevance in indicating COVID-19, as reported in various studies. These features were chosen to capture the most significant indicators of the disease.\n\nThe data encoding process involved transforming the original blood test data into a format suitable for the variational autoencoder (VAE) and one-class support vector machine (1SVM) algorithms. The VAE model encodes the input data as a distribution over the latent space, allowing for the generation of new data points that share similar features with the training data. This encoding step is essential for dimensionality reduction and feature extraction, enabling the model to learn a compact representation of the original data.\n\nIn summary, the data encoding process involved normalization, missing data imputation, and feature selection. These steps ensured that the data was in an optimal format for the machine-learning algorithms, facilitating effective learning and accurate detection of COVID-19 infections.",
  "optimization/parameters": "In our study, we employed several deep generative models, each with its own set of hyperparameters. For the Restricted Boltzmann Machine (RBM), we used two layers: a visible layer and a hidden layer. The dimension of the hidden layer was set to 20, which was found to be optimal through evaluation. The visible layer dimension was determined by the input size of the dataset used.\n\nThe Deep Belief Network (DBN) architecture consisted of two stacked RBMs. The configuration adopted was RBM1 with 30 hidden units and RBM2 with ten hidden units. This configuration was chosen based on a grid search procedure to optimize classification performance.\n\nThe Generative Adversarial Network (GAN) model consisted of two distinct deep neural networks: a generative network and a discriminative network. The generative network had two layers with 18 units each, while the discriminative network had two layers with 18 and 11 units, respectively. These settings were also determined through a grid search to achieve the highest classification performance.\n\nThe Variational Autoencoder (VAE) was composed of five layers: input, intermediate, mean, variance, and Z. The input layer dimension varied depending on the dataset used (18 and 20). The intermediate layer was set to 30 hidden units, while the mean, variance, and Z dimensions were set to ten hidden units each. The VAE was trained unsupervised using a stochastic Variational Inference (VI) approach, aiming to sample new data points with the same features as the training dataset.\n\nAdditionally, a one-class Support Vector Machine (1SVM) was used as an unsupervised classifier. The 1SVM had three main parameters: the RBF kernel, \u03bd = 0.0025, and \u03b3 = 0.01. These values were set based on a grid search, and the RBF kernel was chosen because it achieved the highest detection performance.\n\nCommon settings were used across the models, including binary cross-entropy as the loss function, the Rmsprop optimizer, a batch size of 50, 2000 epochs, and a learning rate of 0.001. These parameters were carefully chosen to ensure optimal performance of the models in detecting COVID-19 infection from blood test data.",
  "optimization/features": "In our study, we utilized two distinct datasets, each with a different number of input features.\n\nFor the first dataset, we initially had 108 features available. However, we performed feature selection to identify the most relevant features for detecting COVID-19. Based on reported studies in the literature, we narrowed down to 18 important features that showed significant relevance in indicating COVID-19. This selection process was conducted using the entire dataset, ensuring that the chosen features were representative of the data distribution.\n\nFor the second dataset, which is composed of three sub-datasets, we used 11 important features to detect COVID-19 infection. These features were selected based on their clinical significance and relevance to the detection of COVID-19. The feature selection process for this dataset was also performed using the entire dataset to ensure robustness and generalizability.\n\nIn both cases, the feature selection was done using the entire dataset, not just the training set, to ensure that the selected features were representative of the overall data distribution. This approach helped in maintaining the integrity and reliability of our models.",
  "optimization/fitting": "The fitting method employed in this study involves several deep learning models, each with its own set of hyperparameters and configurations. The models include Restricted Boltzmann Machines (RBM), Deep Belief Networks (DBN), Generative Adversarial Networks (GAN), and Variational Autoencoders (VAE). Each of these models was carefully tuned using grid search to optimize their performance.\n\nFor the RBM and DBN models, the number of hidden units was determined through experimentation. The RBM consists of two layers: a visible layer and a hidden layer. The hidden layer dimension was set to 20, which was found to be optimal through evaluation. The DBN architecture comprises two stacked RBMs, with RBM1 having 30 hidden units and RBM2 having 10 hidden units. These configurations were chosen to balance model complexity and performance.\n\nThe GAN model consists of two distinct neural networks: a generative network and a discriminative network. The generative network has two layers with 18 units each, while the discriminative network has two layers with 18 and 11 units, respectively. The GAN was trained in an unsupervised manner using a zero-sum game approach, where the generator and discriminator are optimized simultaneously. This configuration was selected based on grid search results to achieve the highest classification performance.\n\nThe VAE model is composed of five layers: input, intermediate, mean, variance, and Z. The input layer dimension varies depending on the dataset used (18 or 20), while the intermediate layer has 30 hidden units. The mean, variance, and Z layers each have 10 hidden units. The VAE was trained using a stochastic Variational Inference (VI) approach, which involves regularized iterative sampling to generate new data points with the same features as the training dataset. This method helps in alleviating overfitting by incorporating a regularization mechanism during training.\n\nTo address overfitting, the VAE model includes a regularization term that enhances its ability to sample data points from the learned data distribution in the latent space. Additionally, the models were evaluated using standard classification metrics such as true-positive rate (TPR), false-positive rate (FPR), accuracy, precision, F1-score, and AUC. These metrics provide a comprehensive assessment of the models' performance and help in identifying any signs of overfitting or underfitting.\n\nIn summary, the fitting method involved careful selection and tuning of hyperparameters for each model. Regularization techniques and comprehensive evaluation metrics were used to ensure that the models were neither overfitting nor underfitting the data. The configurations were optimized through grid search and experimental evaluation to achieve the best possible performance.",
  "optimization/regularization": "In our study, we employed variational autoencoders (VAEs) as a key component of our approach. One of the significant advantages of VAEs over traditional autoencoder-based models is their ability to alleviate the overfitting problem. This is achieved through the incorporation of a regularization mechanism during the training stage. Specifically, the regularization term in VAEs enhances the ability of the generative models to sample data points by utilizing the learned data distribution represented in the latent space. This regularization helps in preventing the model from memorizing the training data, thereby improving its generalization to unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules used in our study are thoroughly detailed within the publication. Specifically, the settings for the deep generative models, including GAN, VAE, RBM, and DBN, are outlined in the results and discussion section. These configurations include parameters such as the number of layers, hidden units, learning rates, batch sizes, and epochs. For instance, the VAE model consists of five layers with specified dimensions for each layer, while the GAN model includes configurations for both the generative and discriminative networks.\n\nThe optimization parameters, such as the use of the Rmsprop optimizer and binary cross-entropy as the loss function, are also clearly stated. These details ensure reproducibility of the experiments conducted. However, model files and specific optimization parameters beyond those mentioned are not explicitly provided in the text. The publication does not mention the availability of these files or any licensing information related to their use.\n\nNot applicable",
  "model/interpretability": "The models employed in this study, including GAN, V AE, RBM, and DBN, are primarily deep generative models, which are often considered black-box models due to their complex architectures and the intricate relationships they learn between inputs and outputs. These models do not inherently provide clear, interpretable insights into how they make predictions.\n\nHowever, the integration of these generative models with a softmax layer for classification tasks introduces some level of interpretability. The softmax layer outputs probabilities for each class, which can be interpreted as the model's confidence in assigning a particular class label to an input sample. This allows for a basic understanding of the model's decision-making process.\n\nAdditionally, the use of 1SVM in conjunction with these generative models adds another layer of interpretability. The 1SVM is trained to determine a hyperplane that separates normal (uninfected) cases from abnormal (infected) cases. This hyperplane can be visualized and interpreted, providing insights into which features are most important for distinguishing between the two classes. The 1SVM's decision boundary can be analyzed to understand which data points are closest to the boundary, indicating cases that are more ambiguous or difficult to classify.\n\nIn summary, while the deep generative models themselves are black-box, the combination with softmax and 1SVM introduces some level of interpretability. The softmax layer provides probabilistic outputs, and the 1SVM's decision boundary offers a visual and analytical tool for understanding the model's classification decisions.",
  "model/output": "The model is primarily designed for classification tasks, specifically for detecting COVID-19 infection based on blood test data. It employs various deep generative models, including Variational Autoencoders (VAE), Generative Adversarial Networks (GAN), Restricted Boltzmann Machines (RBM), and Deep Belief Networks (DBN), combined with a softmax layer for classification. Additionally, a One-Class Support Vector Machine (1SVM) is used for unsupervised classification, focusing on distinguishing between infected and non-infected cases.\n\nThe output of the model is a probability assigned to each class, indicating whether a given case is infected with COVID-19 or not. The models are fine-tuned using supervised learning to optimize the parameters for accurate classification. The performance of these models is evaluated using standard classification metrics such as true-positive rate (TPR), false-positive rate (FPR), accuracy, precision, F1-score, and the area under the receiver operating characteristic curve (AUC).\n\nIn the experiments conducted, the VAE combined with a softmax classifier showed superior performance compared to other models like GAN, RBM, and DBN. This superiority is attributed to the VAE's ability to extract more relevant features using variational inferences to approximate the COVID-19 data probability distribution. Furthermore, the combination of VAE with 1SVM demonstrated high capability for COVID-19 detection, enhancing the detection performance significantly. The VAE-1SVM approach maps the extracted features into a higher-dimensional space, making the features linearly separable and simplifying the detection problem.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method involved two main experiments conducted on two distinct datasets of routine blood tests. The first experiment focused on deep learning generative models, specifically GAN, DBN, RBM, and VAE, coupled with a softmax classifier. This experiment aimed to classify confirmed and clean COVID-19 cases through a classification approach. The performance metrics used for evaluation included true-positive rate (TPR), false-positive rate (FPR), accuracy, precision, F1-score, and the area under the curve (AUC).\n\nThe second experiment utilized hybrid models that combined the aforementioned deep generative learning models with an unsupervised 1SVM detector. This approach was designed to detect COVID-19 infections without relying on labeled data, making it a fully unsupervised method. For training the unsupervised VAE-, GAN-, RBM-, and DBN-based 1SVM detectors, 80% of the noninfected observations were randomly selected. The remaining data, which included both infected and uninfected cases, were used for testing. This setup ensured that the models were trained solely on data from uninfected cases, enhancing their ability to identify anomalies indicative of COVID-19 infection.\n\nThe datasets used for evaluation were collected from two different geographic locations: the Albert Einstein Hospital (AEH) in S\u00e3o Paulo, Brazil, and the San Raffaele Hospital (SRH) in Milan, Italy. Dataset 1 consisted of 5644 patients, including 559 infected with COVID-19, and contained 18 important features selected based on their relevance in indicating COVID-19. Dataset 2 was a concatenation of three different subsets of data, totaling about 1700 samples, and included fewer blood test samples compared to Dataset 1. This data heterogeneity made the classification problem more challenging.\n\nThe results demonstrated that the VAE combined with a softmax classifier outperformed the GAN-, RBM-, and DBN-based softmax classifiers. This superiority was attributed to the VAE's high capability to extract more relevant features using variational inferences to approximate the COVID-19 data probability distribution. Additionally, the VAE combined with 1SVM showed a high capability for COVID-19 detection based on blood test data. The flexibility and modeling capacity of the VAE, along with the effectiveness of the 1SVM machine learning model, contributed to the superior performance of the VAE-1SVM approach. By mapping the extracted features obtained from the VAE model into a higher space, the projected features became linearly separable, simplifying the detection problem.",
  "evaluation/measure": "In our evaluation, we employed a comprehensive set of standard classification metrics to assess the performance of our proposed models. These metrics include the true-positive rate (TPR), false-positive rate (FPR), accuracy, precision, F1-score, and the area under the receiver operating characteristic curve (AUC). These metrics provide a thorough evaluation of the models' ability to correctly identify COVID-19 infections from blood test data.\n\nThe TPR, also known as sensitivity or recall, measures the proportion of actual positives that are correctly identified by the model. Conversely, the FPR indicates the proportion of actual negatives that are incorrectly classified as positives. Accuracy represents the overall correctness of the model's predictions, while precision measures the proportion of positive identifications that are actually correct. The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. The AUC provides an aggregate measure of performance across all classification thresholds.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in medical diagnostics. They offer a robust and representative assessment of model performance, ensuring that our results are comparable to other studies in the field. By reporting these metrics, we aim to provide a clear and comprehensive understanding of our models' effectiveness in detecting COVID-19 infections.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we compared the performance of our proposed detectors with several state-of-the-art methods applied to two datasets. These datasets consisted of routine blood tests from different geographic locations and were used to evaluate the effectiveness of our approach in detecting COVID-19 infections.\n\nWe evaluated our V AE-Softmax and V AE-1SVM detectors against various machine learning methods, including Random Forest (RF), Artificial Neural Network (ANN), Logistic Regression (LR), Lasso-elastic-net regularized Generalized Linear Models (GLMNET), Gradient Boosting Trees (GBTs), Support Vector Machine (SVM), Multilayer Perceptron (MLP), Random Tree (RT), Bayesian Network (BN), and Naive Bayes (NB). These methods were chosen because they represent a range of supervised learning techniques commonly used in medical diagnostics.\n\nThe comparison revealed that our V AE-based methods outperformed these state-of-the-art techniques. For instance, ANN achieved an AUC of 0.95, and SVM showed an AUC of 0.85 in previous studies. In contrast, our V AE-1SVM detector reached an AUC of 0.993, demonstrating superior performance. This highlights the effectiveness of our unsupervised approach in handling the heterogeneity and imbalance in the datasets.\n\nAdditionally, we compared our detectors with simpler baselines, such as standalone 1SVM. The results showed that combining V AE with 1SVM significantly improved detection quality, achieving an AUC of 0.993 compared to 0.96 for standalone 1SVM. This indicates that the integration of deep generative models with 1SVM enhances the detection capabilities, making it a robust solution for COVID-19 infection detection based on blood test data.\n\nOverall, the comparisons with both state-of-the-art methods and simpler baselines underscore the superiority of our proposed V AE-1SVM detector in accurately identifying COVID-19 infections.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of the proposed approach involved a comprehensive assessment using standard classification metrics such as true-positive rate (TPR), false-positive rate (FPR), accuracy, precision, F1-score, and area under the curve (AUC). These metrics were calculated for various models, including V AE, GAN, RBM, and DBN, combined with softmax classifiers and 1SVM detectors.\n\nThe performance of the models was evaluated on two datasets. For Dataset 1, which included over 5000 patients, all generative models achieved an AUC greater than 0.93. Notably, the V AE-based approach demonstrated superior performance across all metrics, achieving an AUC of 99.85%. This was slightly better than GAN (AUC = 99.53%) and significantly higher than RBM (AUC = 93.53%) and DBN (AUC = 94.19%). The V AE-based method also recorded the highest classification performance in terms of accuracy, precision, and F1-score.\n\nFor Dataset 2, which was more heterogeneous and included fewer samples (about 1700), the overall AUC was around 88% to 90%. Again, the V AE-based approach outperformed the others, with an AUC of 90%. The V AE method also showed the lowest FPR (0.176) and the highest TPR (0.849).\n\nIn the final experiment, the detection performance was considerably enhanced when using Dataset 2. The AUC obtained by V AE improved from 90% to 99.3%, and all considered deep generative models achieved an AUC greater than 96%. The V AE-1SVM detector recorded the best score with an AUC of 0.993, demonstrating its high capability for COVID-19 detection based on blood test data.\n\nThe results indicate that the V AE-based methods, both with softmax classifiers and 1SVM detectors, consistently outperformed other models. The superiority of the V AE approach can be attributed to its high capability to extract relevant features using variational inferences to approximate the COVID-19 data probability distribution. The combination of V AE with 1SVM further enhanced detection quality, making the features linearly separable and simplifying the detection problem.\n\nHowever, specific details about confidence intervals or statistical significance tests for the performance metrics are not provided. While the results show clear superiority in terms of AUC and other metrics, the absence of confidence intervals or statistical significance tests means that the exact level of confidence in these results cannot be quantified. Further statistical analysis would be necessary to fully validate the claims of superiority over other methods and baselines.",
  "evaluation/availability": "Not enough information is available."
}