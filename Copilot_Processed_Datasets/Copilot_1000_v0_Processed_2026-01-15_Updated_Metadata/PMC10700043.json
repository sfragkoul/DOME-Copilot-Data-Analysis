{
  "publication/title": "Nomogram Based on Super-Resolution Ultrasound Images Outperforms in Predicting Benign and Malignant Breast Lesions.",
  "publication/authors": "Yang L, Ma Z",
  "publication/journal": "Breast cancer (Dove Medical Press)",
  "publication/year": "2023",
  "publication/pmid": "38074418",
  "publication/pmcid": "PMC10700043",
  "publication/doi": "10.2147/bctt.s435510",
  "publication/tags": "- Breast Cancer\n- Ultrasound Imaging\n- Super-Resolution\n- Machine Learning\n- Deep Learning\n- Radiomics\n- Diagnostic Models\n- Medical Image Processing\n- Generative Adversarial Networks\n- Clinical Nomograms",
  "dataset/provenance": "The dataset used in this study was sourced from breast ultrasound examinations conducted at a hospital. A total of 550 patients with breast lesions underwent these examinations between January 2020 and July 2022. After applying specific screening and selection criteria, 333 patients were included in the analysis. The inclusion criteria required that the breast ultrasound examinations were performed within two weeks before surgery or biopsy, that all breast lesions had a definite pathological diagnosis, and that there was no preoperative treatment. Additionally, only female patients diagnosed with breast lesions were included. The exclusion criteria eliminated patients who had undergone biopsy, neoadjuvant chemotherapy, ablation, or radiotherapy before the ultrasound examination, those with incomplete clinical or pathological information, those with insufficient image quality for feature extraction, and male patients diagnosed with breast lesions.\n\nThe dataset consisted of 333 patients, resulting in 333 ultrasound images. These images were used to train and test various machine learning and deep learning models aimed at distinguishing between benign and malignant breast lesions. The study utilized both original ultrasound images and super-resolution images generated using a generative adversarial network (GAN) to enhance spatial resolution. The super-resolution images were created by introducing Gaussian noise to downsample the out-plane resolution by a factor of two, followed by pairing these low-resolution images with synthetic high-resolution counterparts. This process aimed to improve the detail and clarity of the ultrasound images, thereby enhancing the models' ability to accurately diagnose breast lesions.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a testing set. The training set consisted of 266 patients, resulting in a total of 266 images. The testing set consisted of 67 images. These images were selected from the slice that showed the maximum diameter of the tumor. The training set was further divided into malignant and benign categories, with 142 malignant cases and 124 benign cases. Similarly, the testing set was divided into 34 malignant cases and 33 benign cases. The distribution of data points in each split reflects the clinical characteristics of the patients, with significant differences noted in age and menopause status between benign and malignant breast lesions in both the training and testing sets.",
  "dataset/redundancy": "The dataset used in this study was divided into a training set and a testing set. The training set consisted of 266 patients, resulting in a total of 266 images. The testing set consisted of 67 images. These images were selected from the slice that showed the maximum diameter of the tumor. The regions of interest (ROIs) for tumor segmentation were manually delineated on all ultrasound (US) images by a radiologist with 5 years of experience and subsequently reviewed by another radiologist with 10 years of experience to ensure accuracy. Any discrepancies identified by the two raters were resolved through discussion and consensus-building.\n\nThe training and testing sets were independent, and this was enforced by ensuring that the images used in the training set were not used in the testing set. The distribution of the dataset compares favorably to previously published machine learning datasets in the field of breast lesion diagnosis. The clinical characteristics, such as age and menopause status, showed significant differences between benign and malignant breast lesions in both the training and testing sets, which is crucial for developing robust machine learning models.\n\nThe dataset was split in a way that maintained the integrity of the independent variables, ensuring that the models could be trained and tested on distinct data points. This approach helps in evaluating the generalizability of the models to new, unseen data. The use of manual delineation and consensus-building among radiologists ensured the accuracy and reliability of the ROIs, which is essential for feature extraction and model training.",
  "dataset/availability": "The datasets utilized and analyzed in this study are not publicly available. This decision was made to ensure patient privacy and comply with ethical restrictions. The data includes sensitive patient information, and thus, it is crucial to maintain confidentiality. Measures such as anonymization, encrypted storage, and strict access control were implemented to protect patient data. Additionally, unnecessary information was destroyed in a timely manner to further safeguard privacy. The study was conducted in accordance with ethical standards and received approval from the Institutional Review Boards of the First Affiliated Hospital of Shandong First Medical University & Shandong Provincial Qianfoshan Hospital. Patient consent was waived due to the retrospective nature of the study and the use of anonymous clinical data. The research adhered to the guidelines of the Declaration of Helsinki (2013 revision).",
  "optimization/algorithm": "The optimization algorithm employed in our study primarily involves traditional machine learning models and deep learning models. For the machine learning models, we utilized Logistic Regression (LR) and Support Vector Machine (SVM) algorithms. These are well-established algorithms in the field of machine learning and are not new. They were chosen for their robustness and widespread use in classification tasks.\n\nIn addition to these traditional models, we also developed deep learning models using transfer learning. The deep learning models utilized in this study comprised ResNet 101 and MobileNet V2. MobileNet V2, in particular, is a lightweight convolutional neural network (CNN) known for its efficiency and effectiveness in image classification tasks. The initial weight values for these models were obtained by pretraining on the ImageNet dataset, a common practice in transfer learning to leverage pre-existing knowledge.\n\nThe choice of these algorithms was driven by their proven performance in similar tasks and their ability to handle the complexity of the data. The deep learning models, especially SRMobileNet_v2, demonstrated superior performance in distinguishing between benign and malignant breast lesions. This model achieved high accuracy, sensitivity, and specificity, indicating its effectiveness in the context of our study.\n\nThe optimization process involved stochastic gradient descent (SGD) with an initial learning rate of 0.005, which decayed according to the cosine annealing algorithm over 200 epochs. This approach ensured efficient training and convergence of the models. The use of real-time data augmentation techniques, such as random horizontal flipping and cropping, further enhanced the models' ability to generalize to new data.\n\nThe decision to use these specific algorithms and optimization techniques was based on their suitability for the task at hand and their proven track record in similar applications. The focus of our study was on the application of these models to breast lesion classification rather than the development of new machine learning algorithms. Therefore, the algorithms were not published in a machine-learning journal but rather in a journal focused on breast cancer research.",
  "optimization/meta": "The meta-predictor developed in this study is a nomogram that integrates both clinical variables and a deep-learning score. This deep-learning score is derived from a deep learning model, specifically SRMobileNet_v2, which was identified as the most effective model for distinguishing between benign and malignant breast lesions.\n\nThe SRMobileNet_v2 model is based on super-resolution images and utilizes the MobileNet V2 architecture, a lightweight convolutional neural network (CNN). The model was trained using transfer learning, with initial weight values obtained from pretraining on the ImageNet dataset. The training process involved real-time data augmentation techniques such as random horizontal flipping and cropping, and the model parameters were updated using the stochastic gradient descent (SGD) optimizer.\n\nIn addition to the deep-learning score, the nomogram incorporates statistically significant clinical variables identified through univariate and multivariate logistic regression analyses. These variables include the age of patients and the maximum diameter of tumors.\n\nThe performance of the deep-learning nomogram was evaluated using ROC curves, calibration curves, and the Hosmer\u2013Lemeshow (HL) test. The nomogram demonstrated excellent discrimination and calibration capabilities, outperforming a clinical model that did not incorporate the deep-learning score.\n\nThe training data for the deep learning models and the clinical variables were independently collected and stratified into training and testing sets using an 8:2 ratio. This ensures that the training data for the meta-predictor is independent, reducing the risk of overfitting and enhancing the generalizability of the model.",
  "optimization/encoding": "For the machine-learning algorithms, the data underwent several preprocessing steps to ensure optimal performance. Initially, a Mann\u2013Whitney U-test and feature screening were conducted on all features, retaining only those with a p-value less than 0.05. This step helped in selecting statistically significant features for further analysis.\n\nSubsequently, all feature lines were standardized using the z-score method. This standardization process is crucial as it ensures that each feature contributes equally to the model by transforming the data to have a mean of zero and a standard deviation of one.\n\nTo address multicollinearity, features with a Pearson correlation coefficient greater than 0.9 were identified. In such cases, one of the highly correlated features was retained, while the other was discarded. This step is essential to prevent the model from being overly influenced by redundant information.\n\nThe preprocessed features were then used to develop four models using Logistic Regression (LR) and Support Vector Machine (SVM) algorithms. Two of these models were based on original image features, while the other two utilized super-resolution image features. This approach allowed for a comparison between the performance of models trained on different types of image data.\n\nThe dataset was divided into a training set and a testing set using an 8:2 ratio. This splitting strategy ensures that the model is trained on a sufficient amount of data while also providing an independent set for evaluating its performance.\n\nThe performance of the models was evaluated using several metrics, including sensitivity, specificity, accuracy, negative predictive value (NPV), positive predictive value (PPV), and the area under the receiver operating characteristic curve (AUC). These metrics provide a comprehensive assessment of the model's ability to correctly classify benign and malignant breast lesions.",
  "optimization/parameters": "In our study, we utilized both traditional machine learning and deep learning models to differentiate between benign and malignant breast lesions. For the machine learning models, we initially extracted 107 handcrafted radiomics features from each tumor image, including first-order statistics, gray-level co-occurrence matrix (GLCM), gray-level dependence matrix (GLDM), gray-level run-length matrix (GLRLM), gray-level size-zone matrix (GLSZM), neighboring gray-tone difference matrix (NGTDM), and shape features. We conducted a Mann\u2013Whitney U-test and feature screening to select only those features with a p-value < 0.05, ensuring that we retained the most relevant features for model training. Additionally, we standardized all feature lines using the z-score method and removed features with a Pearson correlation coefficient > 0.9 to avoid redundancy.\n\nFor the deep learning models, we employed transfer learning using pre-trained models such as ResNet 101 and MobileNet V2, which have a large number of parameters due to their deep architectures. The initial weight values were obtained by pretraining these models on the ImageNet dataset. During training, we used stochastic gradient descent (SGD) with an initial learning rate of 0.005, which decayed according to the cosine annealing algorithm over 200 epochs. The batch size was set to 16, and real-time data augmentation techniques such as random horizontal flipping and cropping were implemented to enhance the robustness of the models.\n\nThe selection of parameters for both machine learning and deep learning models was guided by a combination of statistical significance, feature relevance, and model performance. For the machine learning models, the number of parameters (p) was determined by the feature selection process, ensuring that only the most informative features were included. For the deep learning models, the architecture and number of parameters were predefined by the chosen models (ResNet 101 and MobileNet V2), and fine-tuning was performed to optimize performance on our specific dataset.",
  "optimization/features": "In our study, we initially extracted 107 handcrafted radiomics features from each tumor image. These features encompassed various categories, including first-order statistics, gray-level co-occurrence matrix (GLCM), gray-level dependence matrix (GLDM), gray-level run-length matrix (GLRLM), gray-level size-zone matrix (GLSZM), neighboring gray-tone difference matrix (NGTDM), and shape features.\n\nTo refine our model, feature selection was performed using the Mann\u2013Whitney U-test, retaining only those features with a p-value less than 0.05. This process ensured that we focused on the most statistically significant features. Additionally, we standardized all selected features using the z-score method to ensure consistency in the data.\n\nTo address multicollinearity, we further filtered the features by removing any pairs that had a Pearson correlation coefficient greater than 0.9. This step helped in retaining only the most relevant and independent features for model training.\n\nThe feature selection process was conducted exclusively on the training set to prevent data leakage and maintain the integrity of the testing set. This approach ensured that our models were evaluated on unseen data, providing a more accurate assessment of their performance.",
  "optimization/fitting": "The fitting method employed in this study involved both traditional machine learning models and deep learning models, each with its own set of parameters and training strategies.\n\nFor the traditional machine learning models, such as Logistic Regression (LR) and Support Vector Machine (SVM), the number of parameters was relatively small compared to the number of training points. This ensured that overfitting was not a significant concern. To further mitigate any potential overfitting, feature selection was performed using statistical tests and correlation analysis, retaining only the most relevant features. Additionally, the models were evaluated using a separate testing set, which helped in assessing their generalization performance.\n\nIn the case of deep learning models, such as ResNet 101 and MobileNet V2, the number of parameters was indeed much larger than the number of training points. To address the risk of overfitting, several techniques were employed. First, data augmentation was used to artificially increase the size of the training dataset by applying random transformations like horizontal flipping and cropping. Second, transfer learning was utilized, where the models were pre-trained on a large dataset (ImageNet) and then fine-tuned on the specific breast lesion dataset. This approach leveraged the pre-existing knowledge in the model weights, reducing the need for a large amount of training data. Third, regularization techniques like dropout and weight decay were incorporated to prevent the model from becoming too complex and overfitting the training data. Finally, the models were evaluated on a separate testing set to ensure that they generalized well to unseen data.\n\nTo rule out underfitting, the models were trained for an adequate number of epochs with a learning rate schedule that allowed for sufficient optimization. The performance metrics, such as accuracy, sensitivity, specificity, and AUC, were monitored on both the training and testing sets. The models demonstrated good performance on the testing set, indicating that they were not underfitting the data. Additionally, the use of super-resolution images improved the models' performance, suggesting that the models were able to capture relevant features from the data.\n\nIn summary, the fitting method involved careful consideration of the number of parameters relative to the training data, the use of regularization techniques, data augmentation, transfer learning, and thorough evaluation on a separate testing set to ensure that the models neither overfitted nor underfitted the data.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our models. For the machine learning models, we conducted feature screening by selecting only those features with a p-value less than 0.05, which helped in reducing the dimensionality and focusing on the most relevant features. Additionally, we standardized all feature lines using the z-score method to ensure that each feature contributed equally to the model.\n\nTo address multicollinearity, we removed features that had a Pearson correlation coefficient greater than 0.9, retaining only one of the highly correlated features. This step helped in simplifying the model and preventing it from becoming too complex.\n\nFor the deep learning models, we implemented real-time data augmentation techniques such as random horizontal flipping and cropping. This approach increased the diversity of the training data, making the models more generalizable and less likely to overfit to the training set.\n\nFurthermore, we used stochastic gradient descent (SGD) with an initial learning rate of 0.005, which decayed according to the cosine annealing algorithm over 200 epochs. This learning rate schedule helped in fine-tuning the model parameters effectively and prevented overfitting by gradually reducing the learning rate as training progressed.\n\nThe models were trained with a batch size of 16, which balanced the trade-off between computational efficiency and model stability. Additionally, the use of transfer learning with pretrained models on the ImageNet dataset provided a strong foundation, allowing the models to converge faster and with better generalization.\n\nOverall, these regularization techniques ensured that our models were robust, generalizable, and less prone to overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the initial learning rate for the stochastic gradient descent (SGD) optimizer was set at 0.005, with a decay schedule following the cosine annealing algorithm over 200 epochs. Each epoch consisted of 3400 iteration steps, and the batch size was 16. Real-time data augmentation techniques, such as random horizontal flipping and cropping, were implemented to enhance the robustness of the models.\n\nThe model files and optimization parameters are not directly available in the publication. However, the methods and configurations described provide a comprehensive guide for replicating the experiments. The models utilized in this study included ResNet 101 and MobileNet V2, both pretrained on the ImageNet dataset. The specific architectures and pretrained weights can be accessed through standard deep learning frameworks, ensuring reproducibility.\n\nRegarding the availability and licensing of the models and configurations, the pretrained models on ImageNet are typically available under permissive licenses that allow for academic and research use. The detailed configurations and optimization schedules provided in the publication can be freely used by researchers for their own studies, adhering to standard academic practices and citations.",
  "model/interpretability": "To enhance the interpretability of our deep learning model, we made the final convolutional layer transparent. This allowed us to gain insights into the diagnosis of benign and malignant breast lesions. By examining the attention regions generated by the SRMobileNet_v2 model, we found that they were clear and focused mainly on the boundary and internal regions of the tumor. These attention regions did not show activation in areas adjacent to blood vessels, normal breast tissue, or other soft tissue. This suggests that the SRMobileNet_v2 model effectively narrows its focus to areas directly associated with tumors while excluding surrounding structures that may not be significant indicators of malignancy. By doing so, the model increases its specificity and accuracy in identifying malignant breast lesions. This transparency helps in understanding how the model makes its predictions, making it more reliable for clinical use.",
  "model/output": "The model developed in this study is primarily a classification model. It is designed to distinguish between benign and malignant breast lesions. The performance of the model is evaluated using metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV), which are typical for classification tasks. Additionally, the area under the receiver operating characteristic curve (AUC) is used to assess the model's ability to differentiate between the two classes.\n\nThe study employs both traditional machine learning models and deep learning models. The deep learning models, such as SRMobileNet_v2 and SRResNet101, are trained to predict the malignant probability of breast lesion images. These models use convolutional neural networks (CNNs) to analyze the images and make classifications. The final convolutional layer of these models is made transparent to gain insights into the diagnosis process, further confirming their classification nature.\n\nThe models are evaluated on training and testing sets, with the SRMobileNet_v2 model showing superior performance in terms of AUC, accuracy, sensitivity, and specificity. This model focuses on the boundary and internal regions of the tumor, excluding surrounding structures, which enhances its specificity and accuracy in identifying malignant breast lesions.\n\nIn summary, the models developed in this study are classification models aimed at differentiating between benign and malignant breast lesions, with a focus on improving diagnostic accuracy and interpretability.",
  "model/duration": "The execution time for the models varied depending on the specific architecture and the dataset used. The deep learning models, particularly those based on super-resolution images, required more computational resources and time compared to traditional machine learning models. The training process for the deep learning models involved 200 epochs with 3400 iteration steps and a batch size of 16, utilizing stochastic gradient descent (SGD) with an initial learning rate of 0.005. This process was optimized using cosine annealing for learning rate decay. The SRMobileNet_v2 model, which demonstrated superior performance, achieved faster convergence compared to other models. However, the exact execution time was not explicitly measured or reported in the study. The models were evaluated using metrics such as AUC, accuracy, sensitivity, specificity, PPV, and NPV, but detailed timing information for each model's execution was not provided.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the models involved several key metrics and methods to ensure robust performance assessment. Traditional machine learning models and deep learning models were evaluated using the area under the receiver operating characteristic curve (AUC) scores, along with other critical metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics provided a comprehensive view of the models' performance in distinguishing between benign and malignant breast lesions.\n\nThe deep-learning nomogram was evaluated using the receiver operating characteristic (ROC) curve for discrimination, calibration curves with 1000 resamples for calibration, and the Hosmer\u2013Lemeshow (HL) test for goodness-of-fit. The ROC curve helped in assessing the model's ability to differentiate between the two classes, while the calibration curves ensured that the predicted probabilities aligned well with the observed outcomes. The HL test further validated the model's calibration by checking the agreement between predicted and observed events in subgroups of the data.\n\nThe clinical usefulness of the model was assessed through decision curve analysis (DCA) by calculating net benefits. This analysis helped in determining the range of threshold probabilities where the model provided a net benefit over treating all patients or treating none, thus highlighting its practical utility in clinical settings.\n\nThe dataset was divided into training and testing sets using an 8:2 ratio, ensuring that the models were trained on a substantial portion of the data while being evaluated on a separate, unseen dataset. This splitting strategy helped in assessing the generalizability of the models. Additionally, real-time data augmentation techniques, such as random horizontal flipping and cropping, were employed during the training of deep learning models to enhance their robustness and prevent overfitting.\n\nThe performance of the models was compared across different image types, including original and super-resolution images. The super-resolution images generally led to better model performance, with SRMobileNet_v2 exhibiting superior performance among all evaluated models. This model achieved high AUC scores, accuracy, sensitivity, and specificity in both the training and testing sets, indicating its effectiveness in diagnosing breast lesions.\n\nGradient-weighted class activation mapping (Grad-CAM) was used to visualize the decision-making process of the deep learning models, making the models more interpretable. This technique highlighted important regions of the classification target image, providing insights into the features that the model focused on for making predictions. The attention regions generated by the SRMobileNet_v2 model were clear and focused mainly on the boundary and internal regions of the tumor, excluding surrounding structures that may not be significant indicators of malignancy. This enhanced the model's specificity and accuracy in identifying malignant breast lesions.",
  "evaluation/measure": "In the evaluation of our models, we employed a comprehensive set of performance metrics to ensure a thorough assessment. These metrics include the area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics are widely recognized and used in the literature for evaluating the performance of machine learning and deep learning models, particularly in medical imaging and diagnostic tasks.\n\nThe AUC provides a single scalar value that summarizes the performance of the model across all classification thresholds, offering a comprehensive view of the model's ability to distinguish between benign and malignant breast lesions. Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall or true positive rate, indicates the model's ability to correctly identify malignant cases. Specificity, or the true negative rate, reflects the model's capability to correctly identify benign cases. PPV and NPV provide insights into the probability that a positive or negative test result is correct, respectively.\n\nThese metrics collectively offer a robust evaluation framework, ensuring that our models are assessed from multiple angles. The inclusion of these metrics aligns with standard practices in the field, making our evaluation representative and comparable to other studies in the literature. By reporting these metrics, we aim to provide a clear and comprehensive understanding of our models' performance, facilitating their potential application in clinical settings.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of various machine learning and deep learning models to evaluate their performance in distinguishing between benign and malignant breast lesions. We assessed four traditional machine learning models and four deep learning models. The traditional models included Logistic Regression (LR) and Support Vector Machine (SVM), each applied to both original and super-resolution images. Similarly, the deep learning models comprised ResNet 101 and MobileNet V2, also applied to both original and super-resolution images.\n\nThe performance of these models was evaluated using several metrics, including the area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). Our results indicated that models based on super-resolution images generally outperformed those based on original images. Among all the models, SRMobileNet_v2, which utilizes MobileNet V2 on super-resolution images, exhibited the superior performance.\n\nTo ensure a thorough evaluation, we compared the models using ROC curves in both the training and testing sets. The SRMobileNet_v2 model achieved the highest AUC and demonstrated superior accuracy, sensitivity, and specificity compared to the other models. This comparison highlights the effectiveness of using super-resolution images and advanced deep learning architectures in improving the diagnostic accuracy of breast lesions.\n\nAdditionally, we constructed a clinical nomogram that integrated the deep-learning score with statistically significant clinical variables. This nomogram was evaluated using ROC curves, calibration curves, and the Hosmer\u2013Lemeshow test, showing excellent discrimination and calibration capabilities. The deep-learning nomogram outperformed the clinical model in both the training and testing sets, indicating its superior predictive efficacy.\n\nIn summary, our study involved a detailed comparison of various machine learning and deep learning models, with a focus on the superior performance of SRMobileNet_v2. This comparison was conducted using robust evaluation metrics and benchmark datasets, ensuring the reliability and validity of our findings.",
  "evaluation/confidence": "The evaluation of our models included several performance metrics, each accompanied by confidence intervals to provide a measure of reliability. For instance, the area under the receiver operating characteristic curve (AUC) for the SRMobileNet_v2 model in the training set was reported with a 95% confidence interval (CI) of 0.9673\u20130.9939, and in the testing set, the AUC had a 95% CI of 0.7556\u20130.9468. This approach ensures that the performance metrics are not just point estimates but are accompanied by a range within which the true value is likely to fall, enhancing the confidence in our results.\n\nStatistical significance was a key consideration in our analysis. We conducted univariate and multivariate logistic regression analyses, and only variables with a P-value less than 0.05 were deemed statistically significant. This threshold was consistently applied across all statistical tests, including t-tests, Chi-square tests, and Mann\u2013Whitney U-tests, to ensure that our findings were robust and not due to random chance. For example, the differences in age and maximum tumor diameter between benign and malignant lesions were statistically significant (all P<0.05), reinforcing the reliability of these variables in our models.\n\nIn comparing the performance of different models, we used metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV), all of which were evaluated with statistical rigor. The SRMobileNet_v2 model, for instance, demonstrated superior performance with statistically significant improvements in these metrics compared to other models. The use of super-resolution images further enhanced the model's performance, as evidenced by the higher AUC and other metrics in the super-resolution-based models compared to their original image-based counterparts.\n\nAdditionally, the deep-learning nomogram was evaluated using the receiver operating characteristic (ROC) curve for discrimination, calibration curve with 1000 resamples for calibration, and the Hosmer\u2013Lemeshow (HL) test for goodness-of-fit. These evaluations provided a comprehensive assessment of the model's performance, ensuring that it was not only accurate but also well-calibrated and statistically sound. The clinical usefulness of the model was further assessed through decision curve analysis (DCA) by calculating net benefits, providing a practical measure of the model's value in clinical settings.\n\nIn summary, the performance metrics in our study are robust and statistically significant, with confidence intervals provided for key metrics. The use of rigorous statistical methods and the consistent application of significance thresholds ensure that our claims of superiority over other models and baselines are well-founded.",
  "evaluation/availability": "Not enough information is available."
}