{
  "publication/title": "A toolkit for quantifying individual response to herbal extracts in metabolic and inflammatory stress.",
  "publication/authors": "Park SY, Kwon O, van den Broek T, Bouwman J, Kim JY",
  "publication/journal": "NPJ science of food",
  "publication/year": "2025",
  "publication/pmid": "39900584",
  "publication/pmcid": "PMC11791183",
  "publication/doi": "10.1038/s41538-024-00354-y",
  "publication/tags": "- Health Space Modeling\n- Machine Learning\n- Nutrition\n- Metabolism\n- Inflammation\n- PhenFlex Challenge Test\n- Herbal Extracts\n- Biomarkers\n- Generalized Linear Models\n- Health Estimation Scores",
  "dataset/provenance": "The dataset used in this study was sourced from two human intervention studies that employed the PhenFlex challenge test model. These studies shared an identical design, ensuring consistency in the data collection process. The participants in these studies were subjected to a nutritional challenge involving PhenFlex challenge drinks, which served as a health assessment tool and helped expand the sample size.\n\nThe data collected included various inflammatory and metabolic markers measured at multiple time points. Specifically, inflammatory parameters such as interferon (IFN)-\u03b12, IFN-\u03b3, interleukin (IL)-1\u03b1, IL-1\u03b2, IL-1ra, IL-2, IL-3, IL-4, IL-5, IL-6, IL-7, IL-8, IL-9, IL-10, IL-12 (p40), IL-12 (p70), IL-13, IL-15, IL-17A, IFN-\u03b3-induced protein (IP)-10, monocyte chemoattractant protein-1 (MCP)-1, MCP-3, macrophage-derived chemokine (MDC), macrophage inflammatory protein (MIP)-1\u03b1, MIP-1\u03b2, transforming growth factor (TGF)-\u03b1, tumor necrosis factor (TNF)-\u03b1, TNF-\u03b2, and vascular endothelial growth factor (VEGF) were measured. Additionally, metabolic markers such as glucose, insulin, triglycerides (TGs), free fatty acids (FFAs), ApoB, high-density lipoprotein (HDL) cholesterol, low-density lipoprotein (LDL) cholesterol, oxidized low-density lipoprotein (ox-LDL), malondialdehyde (MDA), reactive oxygen species (ROS), C-reactive protein (CRP), basophils, eosinophils, lymphocytes, monocytes, and neutrophils were assessed.\n\nBaseline markers included sex, age, recommended food score (RFS), weight, and body mass index (BMI). The dataset was combined from these two studies, and statistical preprocessing steps were performed to ensure data quality and consistency. The combined dataset was used to develop health estimation scores for metabolism and inflammation, with the goal of predicting individual health status.\n\nThe specific number of data points is not explicitly stated, but the dataset was sufficiently large to allow for the division into training and test sets, with 70% of the data used for training and 30% for testing. This division was applied to the placebo and high-dose treatment groups for training, and the low-dose treatment group for testing. The dataset has not been previously used by the community, as this study represents a novel application of the quantitative health model to intervention study data.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The distribution was 70% for the training set and 30% for the test set. The training set was used to train the model for fitting, while the test set was used to evaluate the generalization error. Additionally, within the training set, a 10-fold cross-validation procedure was employed. This involved dividing the training data into 10 subsets, where each subset sequentially served as a validation set while the remaining 90% of the data were used for model construction. The overall performance was then computed by averaging the results across these ten iterations. This approach ensured a robust evaluation of the model's performance and generalization capabilities.",
  "dataset/redundancy": "The datasets used in this study were divided into training and test sets with a 70:30 split. This division was applied to the placebo and high-dose treatment groups for the training set, while the low-dose treatment group was used as the test set. This approach ensures that the training and test sets are independent, as they come from different treatment groups.\n\nThe independence of the training and test sets was enforced by the study design, which included randomized, double-blind, placebo-controlled, and crossover trials. This design helps to minimize bias and ensures that the results are not influenced by the knowledge of the treatment assignments.\n\nThe distribution of the datasets in this study is comparable to previously published machine learning datasets in that a significant portion of the data is used for training the model, while a smaller portion is reserved for testing the model's performance. This approach is standard in machine learning to evaluate the model's generalization error and its ability to perform well on unseen data. The use of 10-fold cross-validation further ensures that the model's performance is robust and not dependent on a particular split of the data.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study falls under the class of generalized linear models (GLMs). Specifically, we utilized a GLM with a 10-fold cross-validation approach to develop and validate our health space model. This method is well-established in the field of machine learning and statistics, known for its robustness and effectiveness in handling various types of data.\n\nThe algorithm used is not new; it has been extensively used in numerous studies and applications. The choice of GLMs with 10-fold cross-validation was driven by their proven ability to handle complex datasets and provide reliable predictions. This approach ensures that the model generalizes well to unseen data, which is crucial for the accuracy and reliability of our health estimation scores.\n\nGiven that the focus of our study is on nutritional research and the application of machine learning techniques to health data, the publication venue aligns with the objectives of the research. The algorithm itself is a standard tool in the machine learning toolkit, and its application in our context is innovative in terms of how it is used to quantify and visualize health status. Therefore, publishing in a specialized journal focused on food science and nutrition was appropriate, as it highlights the practical implications and novel applications of these established methods in a new domain.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. Instead, it relies on a single machine learning approach, specifically generalized linear models (GLMs) with 10-fold cross-validation, to predict health estimation scores for metabolism and inflammation. The GLMs were used for variable selection and to build the health space model.\n\nThe data used for training and testing the model were carefully divided to ensure independence. The datasets were split into training and test sets in a 70:30 ratio. The training set, which included data from the placebo and high-dose treatment groups, was used to train the model. The test set, consisting of data from the low-dose treatment group, was used to evaluate the model's generalization error. This division ensured that the training data was independent of the test data, preventing any overlap that could bias the model's performance evaluation.\n\nThe study did not combine predictions from multiple machine learning algorithms to form a meta-predictor. Instead, it focused on refining a single model using cross-validation techniques to enhance its predictive accuracy and robustness. The use of 10-fold cross-validation further ensured that the model's performance was consistently evaluated across different subsets of the data, providing a reliable measure of its effectiveness.",
  "optimization/encoding": "The data underwent several preprocessing steps before being encoded for the machine-learning algorithm. Initially, values below the detection limit were replaced with the limit of detection values. The \"80% rule\" was applied, retaining only variables with nonzero measurements in at least 80% of the datasets. Missing values were imputed using the MICE (Multiple Imputation by Chained Equations) method, creating five imputed datasets. The Shapiro-Wilk test assessed data normality, and skewed data were log-transformed to achieve a normal distribution. Variables with largely different means and standard deviations were standardized using the scale function in R. This preprocessing ensured that the data was suitable for the machine-learning models, facilitating accurate and reliable health estimation scores.",
  "optimization/parameters": "In the development of our health estimation scores for metabolism and inflammation, we utilized a total of 26 features for Experiment 1 and 46 features for Experiment 2. These features were selected through a rigorous process aimed at distinguishing metabolic and inflammatory scores. For Experiment 1, 13 features were chosen for metabolic scores and another 13 for inflammatory scores. In Experiment 2, 35 features were selected for the inflammatory index and 11 for the metabolic score. The selection of these features was crucial in constructing our generalized linear models (GLMs) with 10-fold cross-validation, which were employed to build and validate our health space models. The chosen features were derived from a comprehensive dataset that included various inflammatory and metabolic markers, as well as baseline characteristics such as sex, age, and body mass index (BMI). This feature selection process ensured that our models were robust and capable of accurately predicting health estimation scores.",
  "optimization/features": "In the optimization process, feature selection was indeed performed to distinguish metabolic and inflammation scores. For Experiment 1, a total of 13 features were selected for both metabolic and inflammation scores. In Experiment 2, 35 features were chosen for the inflammation score, and 11 features were selected for the metabolic score. The feature selection process was conducted using the training set only, ensuring that the model's performance on the test set remained unbiased. This approach helped in identifying the most relevant features that contribute to the health estimation scores for metabolism and inflammation.",
  "optimization/fitting": "The fitting method employed in this study utilized generalized linear models (GLMs) with a 10-fold cross-validation procedure to develop health estimation scores for metabolism and inflammation. This approach was chosen to ensure robust model performance and to mitigate issues related to overfitting and underfitting.\n\nThe number of parameters in the model was not excessively large compared to the number of training points. The datasets were divided into training and test sets in a 70:30 ratio, ensuring a sufficient number of training points to estimate the model parameters reliably. The training set was used to fit the model, while the test set was reserved for evaluating the model's generalization error.\n\nTo rule out overfitting, 10-fold cross-validation was implemented. This technique involves dividing the training data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. The overall performance of the model is then averaged across these 10 iterations. This method helps to ensure that the model generalizes well to unseen data and does not merely memorize the training data.\n\nUnderfitting was addressed by carefully selecting relevant features for the model. Feature selection was performed using the GLMs with 10-fold cross-validation, which helped in identifying the most informative variables for distinguishing metabolic and inflammatory scores. This process ensured that the model was complex enough to capture the underlying patterns in the data without being overly simplistic.\n\nAdditionally, the model's performance was validated using receiver operating characteristic (ROC) curves and the area under the curve (AUC). These metrics provided a comprehensive evaluation of the model's ability to distinguish between different treatment groups based on their metabolic and inflammatory profiles. The ROC curves illustrated the effectiveness of the models in both the training and test sets, confirming that the models were neither overfitted nor underfitted.\n\nIn summary, the fitting method involved a balanced approach to model complexity, feature selection, and validation techniques to ensure that the models were neither overfitted nor underfitted. The use of 10-fold cross-validation and ROC curves provided robust evidence of the models' generalization capabilities and accuracy.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was 10-fold cross-validation. This technique involves dividing the dataset into 10 subsets, training the model on 9 of these subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. By averaging the results across these iterations, we obtained a more reliable estimate of the model's performance, reducing the risk of overfitting to any single subset of the data.\n\nAdditionally, we utilized generalized linear models (GLMs) with regularization techniques. Specifically, we employed elastic net regularization, which combines the penalties of both L1 (lasso) and L2 (ridge) regularization. This approach helps in selecting relevant features and shrinking the coefficients of less important features, thereby preventing the model from becoming too complex and overfitting the training data.\n\nFurthermore, we ensured that our models were evaluated on a separate test set that was not used during the training process. This test set, comprising 30% of the total data, allowed us to assess the generalization error and confirm that our models performed well on unseen data. The use of receiver operating characteristic (ROC) curves and the area under the curve (AUC) provided additional metrics to evaluate the models' performance and ensure they were not overfitted to the training data.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters are not explicitly detailed in the provided information. The focus of the study is on the development and validation of a health space model using machine learning techniques, specifically generalized linear models (GLMs) with 10-fold cross-validation. The study describes the procedures for model development, including the division of datasets into training and test sets, the use of ROC curves for model validation, and the visualization of health estimation scores in a 2-dimensional health space.\n\nThe study mentions the use of specific datasets and the application of statistical preprocessing steps, but it does not provide detailed information on the availability of hyper-parameter configurations, optimization schedules, or model files. The results and methods are described in a manner that allows for reproducibility, but the specific parameters and configurations used in the optimization process are not explicitly reported.\n\nThe study does not mention any specific licenses or repositories where the model files or optimization parameters can be accessed. The emphasis is on the methodological approach and the validation of the health space model rather than the technical details of the optimization process. Therefore, while the study provides a comprehensive overview of the methods and results, it does not offer detailed information on the availability of the hyper-parameter configurations, optimization schedule, model files, and optimization parameters.",
  "model/interpretability": "The model developed in this study is not a black box; it is designed to be interpretable and transparent. The health space modeling approach uses machine learning techniques, specifically generalized linear models (GLMs) with 10-fold cross-validation, to quantify and visualize health status. This method allows for the selection of biologically significant features that represent metabolic and inflammatory processes.\n\nThe model's transparency is evident in several ways. First, the features selected for the models are clearly defined and biologically relevant. For instance, specific features were chosen to distinguish metabolic and inflammatory scores, and these features are listed in supplementary tables. This ensures that the model's predictions are based on understandable and measurable biological processes.\n\nSecond, the health estimation scores are derived from these selected features, providing a clear and interpretable metric for health status. The scores are visualized in a 2-dimensional health space, where the axes represent metabolic and inflammatory responses. This visualization helps to distinguish between different treatment groups and provides insights into the health effects of interventions.\n\nAdditionally, the model's performance is evaluated using ROC curves, which illustrate the effectiveness of the models in distinguishing between treatment groups based on their metabolic and inflammatory profiles. This evaluation process adds another layer of transparency, as it allows for the assessment of the model's accuracy and reliability.\n\nOverall, the health space modeling approach combines machine learning with biological relevance, resulting in a transparent and interpretable model that can effectively quantify and visualize health status.",
  "model/output": "The model developed in this study is primarily a regression model, specifically a generalized linear model (GLM) with logistic regression components. The primary output of the model is health estimation scores for metabolism and inflammation. These scores are used to quantify and visualize the health status of individuals, distinguishing between different treatment groups based on their metabolic and inflammatory profiles.\n\nThe model employs a 10-fold cross-validation procedure to ensure robustness and generalization. The health estimation scores are derived from selected features that represent metabolic and inflammatory responses. These scores are then visualized in a 2-dimensional health space, where the axes represent metabolic and inflammatory responses. This visualization helps in categorizing individuals according to their health status, highlighting the utility of the health space methodology in evaluating phenotypic flexibility and health outcomes.\n\nThe model's performance is evaluated using receiver operating characteristic (ROC) curves, which compare the model's performance on training and test sets. The area under the ROC curve (AUC) is used to measure the model's effectiveness in distinguishing between different treatment groups. The final formula established based on the AUC value is used to predict health estimation scores, providing insights into the potential benefits or risks associated with specific interventions.\n\nThe health estimation scores are calculated using a logistic regression model, where the fitted probability and linear predictor scores are derived from the selected features. This approach allows for a comprehensive evaluation of the health status of individuals, facilitating personalized health quantification and advice. The model's outputs are visualized in a 2-dimensional health space, where the placement of individuals within the healthy range relies on the regression values derived from the health space model. This visualization effectively segregates subjects into distinct groups based on their responses to treatment, providing a clear distinction between the two extreme groups: placebo (baseline) and high-dose treatment.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive approach to ensure the robustness and generalizability of the health estimation scores. The dataset was divided into training and test sets, with 70% of the data used for training and the remaining 30% reserved for testing. This split was applied to both the placebo and high-dose treatment groups for model training, while the low-dose treatment group served as the test set.\n\nTo enhance the reliability of the model, a 10-fold cross-validation procedure was implemented. This involved dividing the training data into 10 subsets, where each subset was sequentially used as a validation set while the model was trained on the remaining 90% of the data. The performance of the model was then averaged across these 10 iterations to provide a stable estimate of its generalization error.\n\nGeneralized Linear Models (GLMs) were constructed using this cross-validation approach to select relevant variables for health space modeling. The effectiveness of the models was assessed using Receiver Operating Characteristic (ROC) curves, which plot the true positive rate against the false positive rate. The area under the ROC curve (AUC) was calculated to quantify the model's diagnostic ability, with higher AUC values indicating better performance.\n\nThe ROC curves were generated for both the training and test sets, allowing for a comparison of the model's performance across different datasets. This evaluation method ensured that the health estimation scores were not only accurate but also generalizable to new, unseen data. The visual separation of the reference groups in the health space, along with the distinct scores for metabolic and inflammatory responses, further validated the model's effectiveness in distinguishing between different health states.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our health space model. Primarily, we used the area under the Receiver Operating Characteristic (ROC) curve, commonly referred to as the AUC. The ROC curve plots the true positive rate against the false positive rate at various threshold settings, providing a comprehensive view of the model's ability to distinguish between different treatment groups based on their metabolic and inflammatory profiles. The AUC value offers a single scalar value that summarizes the performance of the classification model, with higher values indicating better performance.\n\nAdditionally, we utilized accuracy as a performance metric. Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. This metric is straightforward and provides a clear indication of how often the model's predictions are correct.\n\nTo ensure the robustness of our model, we implemented 10-fold cross-validation. This technique involves dividing the dataset into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. The overall performance is then computed by averaging the results across these 10 iterations. This method helps to mitigate overfitting and provides a more reliable estimate of the model's generalization performance.\n\nThese metrics are widely recognized and used in the literature for evaluating machine learning models, particularly in the context of health and biomedical research. The combination of AUC, accuracy, and cross-validation ensures that our model's performance is thoroughly assessed and validated, making our findings robust and reliable.",
  "evaluation/comparison": "Not applicable. The publication focuses on the development and validation of a health space model using machine learning techniques, specifically generalized linear models with 10-fold cross-validation. The evaluation of the model was conducted using ROC curves to compare the performance on training and test sets. However, there is no mention of a comparison to publicly available methods or simpler baselines on benchmark datasets. The study primarily aims to quantify health status and visualize individual health responses to interventions using the developed health space model.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of the health space model involved several key metrics to assess its performance and reliability. Receiver Operating Characteristic (ROC) curves were generated to validate the scores and compare the fitness of various statistical models. The area under the ROC curve (AUC) was calculated to measure the effective accuracy with meaningful interpretation. This metric is crucial as it provides a comprehensive assessment of the model's diagnostic ability to distinguish between different treatment groups based on their metabolic and inflammatory profiles.\n\nThe ROC curves were used to compare the performance of the models on both training and test sets, ensuring that the model generalizes well to unseen data. The distinction between the training (black curve) and test (blue curve) sets in both Experiment 1 and Experiment 2 was clearly illustrated, demonstrating the model's effectiveness in differentiating between treatment groups.\n\nStatistical significance was ensured through the use of 10-fold cross-validation, a robust technique for estimating the generalized performance of the model. This method involved dividing the data into ten parts, where each part was sequentially used as a validation set while the remaining nine parts were used for training. The overall performance was computed by averaging the results across these ten iterations, providing a reliable estimate of the model's accuracy and robustness.\n\nThe health estimation scores were derived based on the AUC value of the ROC curve, verified in the test set, and the slope was used to indicate the distinction between the two reference groups. This approach ensured that the final formula for health estimation was both accurate and statistically significant.\n\nIn summary, the performance metrics included confidence intervals through the use of cross-validation, and the results were statistically significant. This rigorous evaluation process confirms the superiority of the health space model in quantifying and visualizing health status based on metabolic and inflammatory responses.",
  "evaluation/availability": "Not enough information is available."
}