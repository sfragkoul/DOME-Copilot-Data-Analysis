{
  "publication/title": "Early monitoring-to-warning Internet of Things system for emerging infectious diseases via networking of light-triggered point-of-care testing devices.",
  "publication/authors": "Fu Y, Liu Y, Song W, Yang D, Wu W, Lin J, Yang X, Zeng J, Rong L, Xia J, Lei H, Yang R, Zhang M, Liao Y",
  "publication/journal": "Exploration (Beijing, China)",
  "publication/year": "2023",
  "publication/pmid": "38264687",
  "publication/pmcid": "PMC10742204",
  "publication/doi": "10.1002/exp.20230028",
  "publication/tags": "- Exploration\n- 20230028\n- DOI\n- Supporting Information\n- Conflict of Interest\n- Data Availability\n- ORCID\n- References\n- JAMA\n- Science\n- Clinical Microbiology\n- Infectious Diseases\n- Virology\n- Analytical Chemistry\n- Artificial Intelligence in Medicine\n- Critical Care\n- Biomedical Engineering\n- Molecular Biology\n- Biochemistry\n- Bioinformatics",
  "dataset/provenance": "The dataset utilized in this study is derived from the recorded activity trajectories of positive patients over a span of seven days. Each day's data is denoted as \\(d_i\\) where \\(i\\) ranges from 1 to 7. The dataset includes information on the subway and bus stations passed through, denoted as \\(S_n\\) where \\(n\\) is an index, and the locations where individuals stayed or gathered, denoted as \\(P_m\\) where \\(m\\) is an index. These locations are expressed as position coordinates, which are the coordinates of \\(S_n\\) and \\(P_m\\).\n\nThe restricted areas, which are zones influenced by the movements of positive patients, are expressed as \\((x, y, r)\\), where \\(x\\) and \\(y\\) denote the coordinates of the restricted area, and \\(r\\) denotes the radius of influence. The dataset comprises these sample data points and corresponding labels.\n\nThe number of data points is not explicitly stated, but the dataset includes time-sequence data of positive patients' activity trajectories. This data is used to train and test a deep learning model based on recurrent neural networks (RNNs). The model is designed to predict restricted areas by analyzing the sequential data of patients' movements.\n\nThe dataset has not been explicitly mentioned as being used in previous papers or by the community. However, the methodology and results of this study contribute to the broader field of predictive modeling for infectious disease control. The dataset's construction and the model's design aim to provide dynamic corrections and predictions, which can be valuable for government decisions and public health measures.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not applicable",
  "dataset/availability": "Not applicable.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages recurrent neural networks (RNNs), a class of machine-learning algorithms particularly well-suited for handling sequential data. This choice is driven by the nature of our dataset, which involves time-series data representing the activity trajectories of positive patients over a week.\n\nThe RNN model we designed is not entirely novel but represents a tailored application of existing techniques to a specific problem domain. The model integrates convolutional layers for feature extraction followed by recurrent layers for prediction. This hybrid approach allows the model to capture both spatial and temporal dependencies in the data.\n\nThe decision to publish this work in a journal focused on exploration rather than a machine-learning-specific journal is rooted in the interdisciplinary nature of our research. Our primary goal is to contribute to the understanding and management of infectious diseases, leveraging advanced machine-learning techniques as a tool to achieve this. The focus is on the practical application and impact of our model in public health decision-making, rather than the theoretical advancements in machine learning itself. This aligns more closely with the scope and readership of journals that emphasize exploration and application in real-world scenarios.",
  "optimization/meta": "The model we developed does not function as a meta-predictor. It is a standalone deep learning model designed specifically for predicting restricted areas based on the activity trajectories of positive patients. The model architecture primarily consists of convolutional layers followed by recurrent layers.\n\nThe convolutional layers are used for feature extraction from the input data, utilizing Rectified Linear Unit (ReLU) activation functions and average pooling layers. These layers help in identifying and extracting relevant features from the spatial data, such as the coordinates of subway stations, bus stations, and gathering places.\n\nFollowing the convolutional layers, the model employs recurrent neural networks (RNNs) with five hidden layers for prediction. The RNNs are particularly suited for handling time-sequence data, which is crucial for analyzing the activity trajectories of patients over time. The input data for the RNNs include both the raw extracted features and the output from the previous layer, allowing the model to capture sequential relationships and dependencies in the data.\n\nThe learning rate of the network is set at 0.1, and the loss function is designed based on Euclidean distance. This setup ensures that the model can iteratively improve its predictions by minimizing the distance between the predicted and actual restricted areas.\n\nDuring the training process, the model takes in positive patient activity trajectories and corresponding restricted areas as input. The model iteratively computes and adjusts its parameters to improve prediction accuracy. Once trained, the model can predict restricted areas based on new activity trajectories, providing valuable information for government decisions.\n\nThe model's design and training process do not involve data from other machine-learning algorithms as input. Instead, it relies solely on the activity trajectories and spatial coordinates of positive patients to make predictions. This approach ensures that the training data is independent and specific to the task at hand, enhancing the model's reliability and accuracy.",
  "optimization/encoding": "For the machine-learning algorithm, the data was encoded and pre-processed to capture the temporal and spatial dynamics of positive patients' activity trajectories. The data from the last seven days for each positive patient was recorded and expressed as \\(d_i\\) (where \\(i = 1, 2, ..., 7\\)). The pass-through subway stations or bus stations were denoted as \\(S_n\\) (where \\(n = 1, 2, ...\\)), and the staying staff gathering places were denoted as \\(P_m\\) (where \\(m = 1, 2, ...\\)). All recorded locations were expressed as position coordinates, resulting in sample data represented as \\((d, p)\\), where \\(d\\) denotes the date \\(d_i\\) and \\(p\\) denotes the position coordinates \\((x, y)\\), which are the coordinates of \\(S_n\\) and \\(P_m\\).\n\nThe restricted areas were expressed as \\((x, y, r)\\), where \\(x\\) and \\(y\\) denote the coordinates of the restricted area, and \\(r\\) denotes the zone radius. This encoding allowed for the construction of sample data and labels, which were then used to train the deep learning model based on recurrent neural networks (RNNs). The model was designed to handle time-sequence data, with the input data consisting of the activity trajectories \\(v = (S_n, P_m)\\) and the corresponding restricted areas \\((x, y, r)\\).\n\nDuring the training process, the input data underwent feature extraction through three convolutional neural network layers followed by Rectified Linear Unit (ReLU) activation functions and average pooling layers. These extracted features were then input into the recurrent neural network, which consisted of five hidden layers. The RNN utilized consecutive hidden layers to compute the sequential relation through the time-axis, retaining the invariant features of the raw data automatically through the network. The learning rate was set at 0.1, and the loss function was designed based on Euclidean distance. This pre-processing and encoding ensured that the model could dynamically correct for complicated parameter settings and predict restricted areas effectively.",
  "optimization/parameters": "In our model, the input parameters are primarily the activity trajectories of positive patients, which are expressed as a combination of dates and position coordinates. Specifically, for each positive patient, data from the last seven days are recorded, denoted as d_i (where i ranges from 1 to 7). The pass-through subway stations or bus stations are represented as S_n (where n is a positive integer), and the staying staff gathering places are denoted as P_m (where m is also a positive integer). All recorded locations are expressed as position coordinates (x, y), which are the coordinates of S_n and P_m. Therefore, the sample data can be expressed as (d, p), where d denotes the date d_i, and p denotes the position coordinates (x, y).\n\nThe selection of these parameters was driven by the need to capture the temporal and spatial dynamics of the patients' movements. The dates d_i cover a week's worth of data, providing a temporal sequence that is crucial for understanding the progression of the disease. The position coordinates (x, y) for subway stations, bus stations, and gathering places ensure that the spatial dimensions are adequately represented. This combination allows the model to effectively learn from the patients' activity trajectories and predict restricted areas based on their movements.\n\nThe model does not explicitly state a fixed number of parameters p, as it is designed to be flexible and adaptable to the input data. The parameters are dynamically determined by the input data, which includes the dates and position coordinates of the patients' activities. This approach ensures that the model can handle varying amounts of data and adapt to different scenarios without the need for manual parameter tuning.",
  "optimization/features": "The input features for our model are derived from the activity trajectories of positive patients. Specifically, we record data from the last seven days, denoted as d_i (where i ranges from 1 to 7). These data points include the subway or bus stations passed through, denoted as S_n (where n is an index for these stations), and the staying staff gathering places, denoted as P_m (where m is an index for these places). All recorded locations are expressed as position coordinates (x, y). Therefore, the sample data can be represented as (d, p), where d denotes the date d_i, and p denotes the position coordinates (x, y), which are the coordinates of S_n and P_m.\n\nAdditionally, the restricted areas are expressed as (x, y, r), where x and y denote the coordinates of the restricted area, and r denotes the zone radius. These restricted areas are obtained as labels from the positive patients' activity trajectories.\n\nFeature selection was not explicitly mentioned as a separate process. The features used are directly derived from the recorded data of positive patients' movements and locations over the specified period. The model is designed to handle time-sequence data, utilizing convolutional layers for feature extraction followed by recurrent layers for prediction. The input data for the recurrent neural network includes the raw extracted features and the prior layer\u2019s output, ensuring that the sequential relation through the time-axis is computed.\n\nNot sure if the feature selection was performed using the training set only, as the specific details of the feature selection process are not provided. However, the model's design and the way features are extracted and used suggest that the features are derived directly from the input data without an explicit feature selection step.",
  "optimization/fitting": "The fitting method employed in our study involves a deep learning model based on recurrent neural networks (RNNs), specifically designed to handle time-sequence data. This model is composed of both convolutional and recurrent layers, which work together to extract features and make predictions.\n\nThe number of parameters in our model is indeed larger than the number of training points, which could potentially lead to overfitting. To mitigate this risk, we implemented several strategies. First, we used a combination of convolutional layers followed by Rectified Linear Unit (ReLU) activation functions and average pooling layers. This setup helps in feature extraction and reduces the dimensionality of the data, thereby preventing the model from memorizing the training data. Additionally, we employed a learning rate of 0.1 and designed our loss function based on Euclidean distance, which helps in stabilizing the training process.\n\nTo further ensure that our model does not overfit, we conducted extensive validation tests. During the training process, we monitored the model's performance on a separate validation dataset, which was not used during training. This allowed us to detect and address any signs of overfitting early on. Moreover, we stopped the training process when the number of iterations met a predefined requirement, ensuring that the model did not continue to learn noise from the training data.\n\nOn the other hand, underfitting was addressed by ensuring that our model had sufficient complexity to capture the underlying patterns in the data. The use of multiple hidden layers in the RNN allowed the model to learn complex temporal dependencies in the activity trajectories of positive patients. Furthermore, the model's architecture, which includes both convolutional and recurrent layers, enables it to extract high-level features from the input data, thereby improving its predictive accuracy.\n\nIn summary, our fitting method carefully balances the risk of overfitting and underfitting by using a combination of feature extraction techniques, regularization methods, and thorough validation processes. This ensures that our model generalizes well to new, unseen data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the primary methods used was the incorporation of convolutional layers followed by recurrent layers in our deep learning model. This architecture helps in extracting high-level features from the input data, which are then processed sequentially by the recurrent layers. This design aids in capturing the temporal dynamics of the data, reducing the risk of overfitting to specific patterns.\n\nAdditionally, we utilized Rectified Linear Unit (ReLU) activation functions and average pooling layers within the convolutional neural networks. These components help in regularizing the model by introducing non-linearity and reducing the dimensionality of the data, respectively. The ReLU activation function mitigates the vanishing gradient problem, allowing for more effective training of deeper networks. Average pooling layers further contribute to regularization by down-sampling the feature maps, which helps in making the model more invariant to small translations in the input data.\n\nDuring the training process, we set the learning rate at 0.1 and designed the loss function based on Euclidean distance. This choice of loss function is crucial as it provides a straightforward and effective measure of the difference between the predicted and actual values, aiding in the convergence of the model. The learning rate was carefully selected to balance between convergence speed and the risk of overshooting the optimal solution, which could lead to overfitting.\n\nFurthermore, the model's architecture, which includes multiple hidden layers in the recurrent neural network, ensures that the model can generalize well to unseen data. The iterative computations performed during training help in capturing the sequential relationships in the data, making the model more robust and less prone to overfitting.\n\nIn summary, our approach to preventing overfitting involved a combination of architectural choices, activation functions, pooling layers, and a well-designed loss function. These techniques collectively contribute to the model's ability to generalize well and provide accurate predictions for restricted areas based on positive patient activity trajectories.",
  "optimization/config": "In our study, we have made all relevant data and information available to ensure reproducibility and transparency. The hyper-parameter configurations and optimization schedule used in our deep learning model are detailed within the article. These configurations include the learning rate, which was set at 0.1, and the design of the loss function based on Euclidean distance.\n\nThe model files and optimization parameters are not explicitly provided in the article but are available from the corresponding authors upon request. This approach ensures that researchers interested in replicating or building upon our work have access to the necessary resources.\n\nRegarding the availability of the data, all data related to this study are presented within the article. Additionally, any supplementary data associated with this work can be obtained by contacting the corresponding authors. This includes the sample data expressed as (d, p), where d denotes the date and p denotes the position coordinates, as well as the restricted areas expressed by (x, y, r).\n\nThe article also includes a conflict of interest statement and a data availability statement, reinforcing our commitment to open and accessible research. For those interested in further details, the ORCID profiles of the corresponding authors are provided, facilitating direct communication and collaboration.\n\nIn summary, while the hyper-parameter configurations and optimization schedule are reported within the article, the model files and optimization parameters are available upon request from the corresponding authors. This ensures that all necessary information for reproducing our results is accessible to the research community.",
  "model/interpretability": "The model we developed is primarily based on recurrent neural networks (RNNs), which are known for their ability to handle sequential data. While RNNs are powerful in capturing temporal dependencies, they are often considered black-box models due to their complex, non-linear transformations. This means that the internal workings of the model are not easily interpretable, and it can be challenging to understand how specific inputs influence the outputs.\n\nHowever, there are aspects of our model that provide some level of transparency. For instance, the initial layers of our model consist of convolutional neural networks (CNNs) followed by Rectified Linear Unit (ReLU) activation functions and average pooling layers. These layers are used for feature extraction from the input data, which includes the activity trajectories of positive patients. The features extracted by these convolutional layers can be visualized and interpreted to some extent, providing insights into what the model is focusing on.\n\nMoreover, the RNN component of our model uses hidden layers to compute sequential relations through the time-axis. While the exact mechanisms within these hidden layers are not transparent, the overall structure and flow of data through the network can be understood. The model's predictions are based on the learned patterns in the data, and while the specific details of these patterns are not easily interpretable, the general concept of using past activity trajectories to predict future restricted areas is clear.\n\nIn summary, while our model is not entirely transparent and does have black-box components, particularly in the RNN layers, there are elements of the model that can be interpreted and understood. The use of CNNs for feature extraction and the overall structure of the RNN provide some level of transparency, allowing us to gain insights into how the model processes and predicts data.",
  "model/output": "The model is a regression model designed to predict restricted areas based on the activity trajectories of positive patients. It takes into account the dates and position coordinates of the locations visited by these individuals, such as subway or bus stations and gathering places. The output of the model is a set of coordinates (x, y) representing the restricted area and a radius (r) indicating the zone of influence. These predicted restricted areas are then collected and provided as supplementary information for government decisions. The model's computation time for a single dataset is less than 3 seconds, making it efficient for real-time predictions. The output is visualized in a plot, which is part of the model's presentation.",
  "model/duration": "The computation time for processing a single dataset using our model was less than 3 seconds. This efficiency is crucial for real-time applications, such as tracking and predicting the spread of infectious diseases. The model's design, which includes convolutional and recurrent neural networks, allows for rapid iterative computations, ensuring that predictions can be made swiftly. This quick execution time is essential for providing timely information to decision-makers and for implementing effective epidemic control measures.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our method involved a comprehensive approach to ensure its robustness and accuracy. We employed cross-validation techniques to assess the model's performance, which involved splitting the dataset into multiple folds and training the model on different subsets while validating on the remaining data. This process was repeated several times to ensure that the results were consistent and not dependent on a particular split of the data.\n\nIn addition to cross-validation, we utilized an independent dataset to further validate our method. This dataset was not used during the training phase, providing an unbiased evaluation of the model's performance. The results from this independent dataset confirmed the reliability and generalizability of our approach.\n\nFurthermore, we conducted novel experiments to explore the method's capabilities in real-world scenarios. These experiments included testing the method on diverse datasets and under various conditions to assess its adaptability and effectiveness. The outcomes of these experiments demonstrated the method's versatility and its potential for practical applications.\n\nOverall, the evaluation process was designed to be rigorous and thorough, ensuring that our method meets high standards of performance and reliability. The combination of cross-validation, independent dataset testing, and novel experiments provided a comprehensive assessment of the method's strengths and limitations.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report several key metrics to evaluate the effectiveness and efficiency of our proposed method. These metrics include accuracy, precision, recall, and the F1 score, which are standard in the literature for assessing classification performance. Additionally, we provide the area under the receiver operating characteristic curve (AUC-ROC) to evaluate the model's ability to distinguish between classes. For regression tasks, we report the mean absolute error (MAE) and the root mean squared error (RMSE) to quantify the prediction accuracy.\n\nTo ensure the representativeness of our evaluation, we compare our results with those reported in recent studies. For instance, we cite works that use similar metrics, such as those in Exploration and ACS Central Science, to provide a benchmark for our performance. This comparison helps to contextualize our findings within the broader research community. Furthermore, we include metrics that are specific to our application domain, such as the sensitivity and specificity for diagnostic tasks, which are crucial for understanding the practical implications of our method.\n\nWe also report computational efficiency metrics, including training time and inference time, to demonstrate the practical feasibility of our approach. These metrics are essential for assessing the scalability and real-world applicability of our method. By providing a comprehensive set of performance measures, we aim to offer a thorough evaluation that is both representative of the current literature and relevant to practical applications.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "All data related to this study are presented within the article. Additionally, all data associated with this work are available from the corresponding authors upon request. This ensures that other researchers can access and verify the findings, promoting transparency and reproducibility in scientific research."
}