{
  "publication/title": "Brain tumor segmentation based on region of interest-aided localization and segmentation U-Net.",
  "publication/authors": "Li S, Liu J, Song Z",
  "publication/journal": "International journal of machine learning and cybernetics",
  "publication/year": "2022",
  "publication/pmid": "35378734",
  "publication/pmcid": "PMC8967694",
  "publication/doi": "10.1007/s13042-022-01536-4",
  "publication/tags": "- Brain Tumor Segmentation\n- 3D U-Net\n- ROI-Aided Strategy\n- Deep Learning\n- Medical Imaging\n- MRI Segmentation\n- Dice Similarity Coefficient\n- Hausdorff Distance\n- Mean Surface Distance\n- Cross-Validation\n- Data Augmentation\n- Convolutional Neural Networks\n- Tumor Localization\n- Multi-Modal MRI\n- Segmentation Accuracy",
  "dataset/provenance": "The dataset used in this study is sourced from the multi-modal brain tumor image segmentation challenge held in conjunction with MICCAI 2015, commonly referred to as MICCAI-BRATS 2015. This dataset is a well-established benchmark in the community, featuring a large collection of brain tumor MRI scans. The relevant tumor structures in these scans have been meticulously delineated by experienced physicians.\n\nThe dataset includes MRI scans from 274 patients, comprising 220 cases of high-grade gliomas (HGG) and 54 cases of low-grade gliomas (LGG). These scans were acquired at four different centers: Heidelberg University, Massachusetts General Hospital, Debrecen University, and Bern University. The MRI machines used varied, with field strengths of 1.5T and 3T, ensuring a diverse range of imaging conditions.\n\nThe MRI scans include four modalities: FLAIR, T1-weighted, T1-weighted with contrast enhancement (T1c), and T2-weighted images. Each modality provides different contrast information, which is crucial for accurate tumor segmentation. The scans were rigidly registered to the T1c MRI scan, which has the highest spatial resolution, and then resampled to a uniform voxel size of 1 \u00d7 1 \u00d7 1 mm\u00b3. This standardization ensures homogeneity across the dataset.\n\nThe dataset has been widely used in the community for developing and evaluating brain tumor segmentation algorithms. Its comprehensive annotations and diverse imaging conditions make it an invaluable resource for advancing the field of medical image analysis.",
  "dataset/splits": "In our study, we employed a ten-fold cross-validation approach to evaluate the proposed brain tumor segmentation algorithm. The dataset consisted of 220 high-grade glioma (HGG) and 54 low-grade glioma (LGG) patients' data. To ensure an equal distribution, we randomly separated the data into ten groups. The first nine groups contained data from 27 patients each, while the last group included data from 31 patients. For each of the ten-fold cross-validation experiments, one group was designated as the validation set for performance evaluation, while the remaining nine groups served as the training set. This process was repeated ten times, with each group serving as the validation set once. This method ensured that every data point was used for both training and validation, providing a robust evaluation of the algorithm's performance.",
  "dataset/redundancy": "The dataset used in this study was obtained from the MICCAI-BRATS 2015 challenge, a benchmark public database of brain tumor MRI scans. The dataset includes multimodal MRI scans and corresponding manual tumor contours delineated by experienced physicians. It comprises 220 high-grade glioma (HGG) and 54 low-grade glioma (LGG) patients, with MRI images acquired at different centers using various MRI machines.\n\nTo evaluate the proposed brain tumor segmentation algorithm, a ten-fold cross-validation approach was employed. The patient data were randomly separated into ten groups, ensuring an equal distribution. Nine groups contained data from 27 patients each, while the last group had data from 31 patients. For each cross-validation experiment, one group was designated as the validation set, and the remaining nine groups served as the training set. This process was repeated ten times, with each group serving as the validation set once.\n\nThis method ensures that the training and test sets are independent in each fold, as no patient data from the validation set is included in the training set. The distribution of the dataset is comparable to previously published machine learning datasets in the field of brain tumor segmentation, adhering to the principles of equal distribution and independent validation.",
  "dataset/availability": "The data used in this study is publicly available from the MICCAI-BRATS 2015 challenge. This dataset includes brain MRI scans with well-delineated tumor structures by experienced physicians. The dataset comprises multimodal MRI scans from 220 high-grade glioma (HGG) and 54 low-grade glioma (LGG) patients, acquired at different centers with varying MRI machine vendors and field strengths. The scans include four types of MRI comparisons: FLAIR, T1, T1c, and T2, all of which are skull-stripped and rigidly registered to the T1c MRI scan for homogeneity. The dataset is available for public use, and the specific details and access information can be found on the MICCAI-BRATS 2015 challenge website. The data is shared under a license that allows for research and academic use, ensuring that the dataset can be utilized by other researchers for similar studies. The enforcement of data usage is typically managed through the terms and conditions set by the challenge organizers, which include guidelines for ethical use and citation requirements.",
  "optimization/algorithm": "The machine-learning algorithm class used in our work is the Fully Convolutional Neural Network (FCNN), specifically a variant known as U-Net. This architecture is well-established in the field of medical image segmentation.\n\nThe algorithm employed is not entirely new; it builds upon existing U-Net architectures but introduces a novel strategy. Our method utilizes a cascaded network consisting of two U-Nets. The first U-Net performs a coarse segmentation to identify the region of interest (ROI) of the tumor. This ROI is then used to crop the image, which is fed into the second U-Net for fine segmentation. This approach helps in excluding irrelevant tissue information and addressing the imbalance issue between tumor and non-tumor voxels.\n\nThe reason this work was published in the International Journal of Machine Learning and Cybernetics, rather than a purely machine-learning focused journal, is due to the application domain. The primary focus of our study is on brain tumor segmentation, a critical task in medical imaging. The innovations lie in the application of machine learning techniques to improve the accuracy and efficiency of medical image segmentation, rather than in the development of a new machine-learning algorithm per se. The journal's scope aligns well with our work, which combines machine learning with cybernetics to solve a practical problem in medical imaging.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the homogeneity and quality of the MRI images. Initially, the volumes of each patient's MRI images were rigidly registered to their T1c MRI scan, which has the highest spatial resolution. This was followed by resampling to achieve a uniform resolution of 1 \u00d7 1 \u00d7 1 mm\u00b3. The voxel size of the patients' MRI data was standardized to 240 \u00d7 240 \u00d7 155 mm\u00b3.\n\nTo unify the data, a normalization strategy was applied to normalize all MRI intensities to the range [-1, 1]. This normalization was performed using the mean value, the 95% maximum intensity value, and the 95% minimum intensity value of the original MRI images.\n\nAdditionally, a N4 bias field correction method was used to address image inhomogeneity issues. This method, implemented in the SimpleITK library of the Python package, corrects non-uniformity of low-frequency intensity, ensuring that the MRI images are of high quality and suitable for further processing.\n\nFor the segmentation task, the binary mask of the manual contour was used as the learning target for multi-modal MRI images. The U-Net architecture was employed for both 2D localization and 3D segmentation models to fully exploit multi-scale information, including spatial and structural details. This architecture allows for the extraction of both low-frequency and high-frequency feature maps, which are crucial for representing tumor boundaries at multiple levels.\n\nData augmentation techniques, such as flipping, rotation, and elastic deformation, were used to enhance the robustness of the model against inaccuracies in tumor localization and segmentation. These techniques expanded the variety of training data, improving the model's ability to generalize to new, unseen data.",
  "optimization/parameters": "In our proposed method, we utilize a cascaded network consisting of two U-Nets: a 2D U-Net and a 3D U-Net. The 2D U-Net is designed to roughly determine the location of the brain tumor, effectively identifying the region of interest (ROI). This initial step helps in excluding irrelevant regions and focusing on the tumor area. The 3D U-Net then performs fine segmentation within this identified ROI, ensuring a more accurate and detailed segmentation of the tumor.\n\nThe structural parameters of the 2D and 3D U-Nets are carefully designed to optimize performance. For the 2D U-Net, the batch size during training is set to 20, and it undergoes 200 epochs, taking approximately 0.5 hours to complete the training process. For the 3D U-Net, the batch size is set to 4, and it also undergoes 200 epochs, taking about 7 hours to train. The learning rate for the Adam gradient optimizer is set to 1.0 \u00d7 10^\u22125 for both networks, with the same-padding operation applied.\n\nThe number of parameters in the model is determined by the architecture of the U-Nets. The 2D U-Net and 3D U-Net have specific layers and filters designed to capture relevant features at different scales. The 3D U-Net, for instance, starts with an input shape of 128 \u00d7 128 \u00d7 128 \u00d7 4 and progresses through multiple convolutional and pooling layers, with the number of filters increasing as the network deepens. This design ensures that the model can effectively learn and generalize from the training data.\n\nThe selection of parameters, such as the number of filters, stride, and the use of concatenation and deconvolution layers, is based on empirical evidence and best practices in deep learning for medical image segmentation. The concatenation of feature maps from the encoding and decoding paths helps in preserving multi-level features, which is crucial for accurate segmentation. The final convolution layer reduces the number of feature maps to two, followed by a \"tanh\" layer to polarize the feature maps, resulting in a binary mask of the tumor.\n\nIn summary, the model parameters are chosen to balance computational efficiency and segmentation accuracy. The use of a cascaded network with a 2D U-Net for initial localization and a 3D U-Net for fine segmentation ensures that the model can handle the complexities of brain tumor segmentation effectively.",
  "optimization/features": "The input features for the proposed method consist of MRI scans, specifically using a 3D volume of size 128\u00d7128\u00d7128\u00d74. This indicates that four different MRI modalities are used as input features. The modalities are likely T1-weighted, T2-weighted, T1-weighted with contrast enhancement, and Fluid-attenuated inversion recovery (FLAIR) images, which are commonly used in brain tumor segmentation tasks.\n\nFeature selection in the traditional sense was not explicitly performed. Instead, the method focuses on leveraging the spatial information from the entire 3D volume of the region of interest (ROI). The use of a cascaded network, consisting of a 2D U-Net for initial localization and a 3D U-Net for fine segmentation, ensures that irrelevant tissues are excluded, and the relevant features are emphasized.\n\nThe ROI is determined using the 2D U-Net, which provides a coarse binary mask of the tumor. This mask is then used to center the ROI for the 3D U-Net, ensuring that the input features for the fine segmentation are focused on the relevant area. This approach effectively selects the most relevant features for the segmentation task by concentrating on the ROI, rather than applying traditional feature selection techniques.",
  "optimization/fitting": "The fitting method employed in this study involves a cascaded network architecture comprising two U-Nets. The first U-Net is a 2D network designed to roughly determine the location of the brain tumor, effectively identifying the region of interest (ROI). This initial step helps in excluding irrelevant regions, such as bony structures and the brain stem, which might introduce bias if directly used for segmentation. The second U-Net is a 3D network that performs fine segmentation within the identified ROI. This two-step process ensures that the model focuses on the relevant tumor region, reducing the imbalance between positive (tumor) and negative (non-tumor) labels.\n\nTo address the potential issue of overfitting, given the large number of parameters in the deep learning models, several strategies were implemented. Data augmentation techniques, including flipping, rotation, and elastic deformation, were used to expand the variety of training data. This augmentation helps in making the model more robust against inaccuracies in both tumor localization and segmentation. Additionally, the use of ten-fold cross-validation ensures that the model's performance is evaluated across different subsets of the data, providing a more reliable estimate of its generalization capability.\n\nUnderfitting was mitigated by the careful design of the network architecture and the use of appropriate loss functions. The binary cross-entropy (BCE) loss was employed to supervise the model, ensuring that the generated binary mask of the tumor closely matches the manual contour. The cascaded U-Net architecture allows for the preservation of multi-level features through concatenation, enhancing the model's ability to capture complex patterns in the data. Furthermore, the use of the Adam gradient optimizer with a learning rate of 1.0 \u00d7 10^\u22125 ensures efficient training and convergence.\n\nThe training process involved 200 epochs for both the 2D and 3D U-Nets, with batch sizes of 20 and 4, respectively. This extensive training regimen helps in ensuring that the model learns the underlying patterns in the data without underfitting. The final model demonstrates efficient segmentation within 1 second for a new MRI image, highlighting its practical applicability in clinical settings.",
  "optimization/regularization": "In our study, we employed several regularization methods to prevent overfitting and enhance the robustness of our brain tumor segmentation model. One key technique used was data augmentation. This involved applying transformations such as flipping, rotation, and elastic deformation to the training data. These augmentations increased the variety of the training samples, helping the model to generalize better and reducing the risk of overfitting to the specific patterns in the original dataset.\n\nAdditionally, we utilized a cascaded network approach consisting of two U-Nets. The first U-Net was responsible for roughly determining the region of interest (ROI) of the brain tumor, effectively excluding irrelevant regions and focusing the model's attention on the tumor area. This step helped in reducing the imbalance between positive (tumor) and negative (non-tumor) labels, which is a common challenge in medical image segmentation. The second U-Net then performed fine segmentation within the identified ROI, further refining the segmentation results.\n\nThe use of a cascaded network not only helped in regularizing the model but also improved the accuracy by addressing the imbalance issue and focusing on the relevant regions. This approach ensured that the model could learn more effectively from the data, leading to better generalization and performance on unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model presented in this work is not a blackbox. It leverages a U-Net architecture, which is known for its interpretability in medical image segmentation tasks. The U-Net architecture consists of an encoder (contracting path) and a decoder (expansive path), with skip connections that concatenate feature maps from the encoder to the corresponding layers in the decoder. This design allows for the preservation of spatial information and multi-level features, making it easier to understand how the model processes and segments the input images.\n\nOne clear example of the model's transparency is the use of concatenation operations between the encoder and decoder paths. These operations combine high-resolution features from the encoder with upsampled features from the decoder, enabling the model to capture both local and global contextual information. This process can be visually inspected and understood, as it directly corresponds to the architectural design of the U-Net.\n\nAdditionally, the model employs a final convolutional layer followed by a \"tanh\" activation layer to produce two-channel feature maps, which represent the posterior probabilities of tumor tissue and normal tissue. This output can be thresholded to obtain a binary mask of the tumor, providing a clear and interpretable segmentation result. The use of binary cross-entropy loss further ensures that the model's predictions are directly supervised by the manual contours provided by experts, enhancing the interpretability of the segmentation process.\n\nThe model also incorporates data augmentation techniques, such as flipping, rotation, and elastic deformation, to enhance its robustness and generalization capabilities. These techniques are well-understood and widely used in the field of medical image segmentation, contributing to the overall transparency of the model.\n\nIn summary, the model's U-Net architecture, the use of concatenation operations, the interpretable final output, and the application of well-established data augmentation techniques all contribute to its transparency and interpretability. This makes it a suitable choice for medical image segmentation tasks, where understanding the model's decisions is crucial for clinical applications.",
  "model/output": "The model is designed for segmentation, which is a type of classification task at the pixel or voxel level. It specifically focuses on brain tumor segmentation in medical imaging. The output of the model is a binary mask that distinguishes between tumor tissue and normal tissue. This binary mask is obtained by applying a threshold to the two-channel feature maps generated by the model. The two channels represent the posterior probabilities of the tumor tissue and the normal tissue, respectively.\n\nThe model uses a fully convolutional neural network (FCNN) architecture, which is end-to-end, meaning it processes the input image directly to produce an output of the same size. The architecture includes convolutional layers, max-pooling layers, and deconvolutional layers, which work together to capture and preserve multi-level features from the input image. The final convolutional layer reduces the number of feature maps to two, and a \"tanh\" activation layer is applied to polarize these feature maps.\n\nThe performance of the model is evaluated using metrics such as the Dice similarity coefficient (DSC), the Hausdorff distance (HD), and the mean surface distance (MSD). These metrics compare the segmented brain tumor contour with the known manual contour delineated by experts. The model aims to achieve high accuracy in segmenting brain tumors, and the results are validated through ten-fold cross-validation experiments.\n\nThe output of the model is visually represented as binary masks, which can be compared with manual contours and other state-of-the-art methods. Numerical comparisons, such as those shown in Table 3, provide quantitative evaluations of the model's performance against other methods like V-Net and DCFCN. The P-values indicate the statistical significance of the differences in performance metrics between the proposed method and the comparing methods.",
  "model/duration": "The execution time of our proposed method is designed to be highly efficient. For a new MRI image from a newly arrived patient, the entire segmentation process can be completed within 1 second. This efficiency is achieved through a cascaded network approach, where a 2D U-Net first locates the brain tumor, taking approximately 0.5 minutes, and then a 3D U-Net performs fine segmentation on the identified region of interest, taking about 2 minutes. The final step of mapping the segmentation back to the original image coordinates is completed within 1 second. This rapid processing time makes our method a practical tool for clinical settings, addressing the labor-intensive issue of manual contouring.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The proposed brain tumor segmentation method was evaluated using a ten-fold cross-validation approach. This involved randomly separating patient data into ten groups, with nine groups containing data from 27 patients and the last group containing data from 31 patients. For each fold, one group was used as validation data, while the remaining nine groups were used as training data. This process was repeated ten times, ensuring each group served as validation data once.\n\nTo assess performance, several metrics were employed, including the Dice similarity coefficient (DSC), Hausdorff distance (HD), and mean surface distance (MSD). These metrics compare the segmented brain tumor contours with manual contours delineated by experts. DSC measures the overlap between the segmented and manual contours, HD evaluates the maximum surface area difference, and MSD measures the average surface area difference.\n\nData augmentation techniques, such as flipping, rotation, and elastic deformation, were used to enhance the robustness of the model against inaccuracies in tumor localization and segmentation. This augmentation expanded the variety of training data, improving the model's generalizability.\n\nThe evaluation also included comparisons with other state-of-the-art methods, such as V-Net and DCFCN, to demonstrate the superiority of the proposed method. Visual results and numerical comparisons were presented to show that the proposed method outperforms these existing techniques, particularly in scenarios where the tumor boundaries are not clearly distinguishable in MRI images.",
  "evaluation/measure": "In our evaluation, we employed several key performance metrics to assess the effectiveness of our brain tumor segmentation method. These metrics include the Dice Similarity Coefficient (DSC), the Hausdorff Distance (HD), and the Mean Surface Distance (MSD). The DSC measures the overlap between the segmented tumor contour and the manual contour provided by experts, offering a straightforward indication of segmentation accuracy. A higher DSC value signifies better performance, with a maximum possible value of 1.\n\nThe HD evaluates the maximum distance between the surfaces of the segmented and manual contours, providing insight into the worst-case scenario of segmentation error. Lower HD values indicate better performance. Similarly, the MSD measures the average distance between the surfaces, giving an overall sense of the segmentation's precision. Again, lower MSD values are desirable.\n\nThese metrics are widely used in the literature for evaluating segmentation algorithms, ensuring that our results are comparable with other state-of-the-art methods. By reporting DSC, HD, and MSD, we provide a comprehensive view of our method's performance, covering both overall accuracy and specific aspects of segmentation quality. This set of metrics is representative of the standards in the field, allowing for meaningful comparisons and validating the robustness of our approach.",
  "evaluation/comparison": "In the evaluation of our proposed brain tumor segmentation method, a comprehensive comparison was conducted against both state-of-the-art and simpler baseline methods. To validate our approach, we compared it against well-known techniques such as V-Net and DCFCN. These comparisons were performed on benchmark datasets, ensuring a rigorous assessment of our method's performance.\n\nVisual segmentation results were presented for a patient, highlighting the performance differences when the boundary contrast of the tumor on MRI images was not clear. Our method, along with DCFCN, demonstrated similar binary masks to manual tumor contours, even in challenging cases where the tumor edges were smooth and ambiguous. Notably, our proposed method's results were much closer to the manual contours than those of V-Net.\n\nNumerical comparisons were also conducted, with our method outperforming V-Net and DCFCN on key metrics such as the Dice Similarity Coefficient (DSC) and Hausdorff Distance (HD). These results were further validated by comparing them with top-ranked models from the BRATS-2015 leaderboard, where our method's DSC performance was close to the top-ranked model and outperformed the rest.\n\nIn addition to comparing with state-of-the-art methods, we also evaluated our approach against simpler baselines, including pure 3D U-Net and pure 2D U-Net. The pure 3D U-Net, which did not use 2D U-Net for localization, was found to introduce false segmentations in certain cases, particularly when normal tissue intensities were similar to tumor intensities. In contrast, our proposed method and the pure 2D U-Net showed no false tumor boundaries and provided more detailed tumor boundaries.\n\nThe numerical results from ten-fold cross-validation experiments further demonstrated the superiority of our proposed method. It significantly improved performance on the DSC metric compared to both pure 3D U-Net and pure 2D U-Net. On the HD metric, our method was significantly better than pure 3D U-Net, although it did not show a significant improvement over pure 2D U-Net. For the Mean Surface Distance (MSD) metric, all three methods showed comparable results.\n\nOverall, the comparisons with both state-of-the-art methods and simpler baselines underscored the robustness and effectiveness of our proposed brain tumor segmentation method.",
  "evaluation/confidence": "The evaluation of the proposed brain tumor segmentation method includes statistical analysis to determine the confidence and significance of the results. The performance metrics, such as the Dice Similarity Coefficient (DSC), Hausdorff Distance (HD), and Mean Surface Distance (MSD), are accompanied by mean values and standard deviations across multiple experiments. This provides a measure of variability and helps in understanding the consistency of the method's performance.\n\nTo assess the statistical significance, P-values are calculated for comparisons between the proposed method and other state-of-the-art methods, as well as baselines like pure 3D U-Net and pure 2D U-Net. For instance, the proposed method shows significant improvements over V-Net and DCFCN in terms of DSC and HD, with P-values indicating strong statistical significance (e.g., P-value < 0.001 for DSC and HD comparisons with V-Net). Similarly, comparisons with pure 3D U-Net and pure 2D U-Net also demonstrate significant improvements in DSC and HD metrics, further validating the efficacy of the proposed method.\n\nThe use of ten-fold cross-validation ensures that the results are robust and not dependent on a specific subset of data. The consistent performance across different experiments, as evidenced by the stable mean values and low standard deviations, reinforces the reliability of the proposed method. Additionally, the comparison with top-ranked models from the BRATS-2015 leaderboard shows that the proposed method's DSC performance is competitive with the best-performing models, further supporting its superiority.",
  "evaluation/availability": "Not enough information is available."
}