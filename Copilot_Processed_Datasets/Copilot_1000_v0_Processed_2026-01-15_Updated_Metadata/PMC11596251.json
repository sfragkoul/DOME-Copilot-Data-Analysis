{
  "publication/title": "MS2Lipid: A Lipid Subclass Prediction Program Using Machine Learning and Curated Tandem Mass Spectral Data.",
  "publication/authors": "Sakamoto N, Oka T, Matsuzawa Y, Nishida K, Jayaprakash J, Hori A, Arita M, Tsugawa H",
  "publication/journal": "Metabolites",
  "publication/year": "2024",
  "publication/pmid": "39590838",
  "publication/pmcid": "PMC11596251",
  "publication/doi": "10.3390/metabo14110602",
  "publication/tags": "- Lipidomics\n- Machine Learning\n- MS2Lipid\n- Spectral Analysis\n- Lipid Subclass Classification\n- XGBoost\n- SHAP Values\n- Metabolomics\n- Lipid Annotation\n- Mass Spectrometry\n- Data Reanalysis\n- Lipid Diversity\n- CANOPUS\n- Lipid Subclass Differentiation\n- Lipidome Atlas Project",
  "dataset/provenance": "The dataset used in this study was sourced from a combination of publicly available spectral data and experimental data curated by the authors. The training, validation, and test data for constructing the MS2lipid program are presented in supplementary materials. Additionally, experimental MS/MS spectra for validation were downloaded from the RIKEN Lipidomics website. Human cohort lipidomics data were obtained from the RIKEN DROPMet website under the index number DM0037.\n\nThe dataset comprises a total of 16,614 samples from 82 projects, all analyzed using the same analytical method and processed in MS-DIAL 4. This dataset includes 117 lipid subclasses, characterized with a rule-based annotation program in combination with a retention time tolerance matched with predicted retention times of lipids. All experimental data were acquired using reverse-phase liquid chromatography coupled with a SCIEX TripleTOF 6600 system.\n\nThe dataset includes 82,397 spectra, from which 17,029 spectra from 3944 unique lipids belonging to 97 subclasses were employed after curation. This includes 8451 ESI(+)-MS/MS spectra of 2559 unique lipids and 8578 ESI(-)-MS/MS spectra of 2048 unique lipids. The mass spectrum is represented as a vector through a procedure that converts high-resolution mass values to nominal mass values using a simple rounding method. In addition to the vector of product ions, neutral loss from the precursor m/z value was included as a variable. An additional descriptor was also created for this study.",
  "dataset/splits": "The dataset was divided into two primary splits: a training set and a test set. The training set consisted of 17,029 spectra, which were used to train the machine learning models. The test set was used to evaluate the performance of the trained models. The distribution of data points in each split was designed to ensure that the models could be effectively trained and validated.\n\nThe spectra used for training and testing were derived from a larger set of 82,397 annotated spectra, which were manually curated and labeled as correct, mix, or false hit. From this curated set, 17,029 spectra were labeled as correct and used for further analysis. These spectra encompassed 3944 unique lipid molecules across 97 lipid classes. The training set included 8451 ESI(+)-MS/MS spectra of 2559 unique lipids and 8578 ESI(-)-MS/MS spectra of 2048 unique lipids.\n\nThe data preprocessing involved using product ions ranging from m/z 70\u20131250, with m/z values rounded to one decimal place. Neutral loss information from the precursor m/z was also utilized, excluding NL values ranging from 0 to 10. The spectra were represented by arrays of product ions and neutral losses, with high-resolution mass values converted into nominal mass. Additionally, a descriptor called the \"MCH-value\" was calculated from the accurate precursor m/z value.\n\nThe machine learning models were evaluated using five different methods: k-nearest neighbor (KNN), random forest (RF), support vector machine (SVM), XGBoost (XGB), and Multi-layer Perceptron (MLP). The XGBoost model offered the best accuracy in both positive and negative ion modes. The optimized model was evaluated using the test dataset, where the lipid subclass with the highest probability value was defined as the representative candidate. The results showed high prediction accuracies, with the correct lipid subclass being predicted with accuracies of 97.2% and 97.6% for positive and negative ion mode spectra, respectively. Moreover, the correct lipid subclass was listed as a candidate for more than 99% of the queries.",
  "dataset/redundancy": "The datasets were derived from 82 projects, encompassing a total of 16,614 samples. The spectral data were analyzed using MS-DIAL, resulting in the annotation of 82,397 spectra across both positive and negative ion modes. These annotations were manually curated by an experienced analytical chemist, who labeled them as correct, mix, or false hit. The correctly labeled data, consisting of 17,029 spectra, were then divided into training and test sets.\n\nThe training and test sets were designed to be independent. This independence was enforced by ensuring that the test dataset was curated by different analysts from those who curated the training data. Additionally, the test data were obtained from various mass spectrometry machines, including SCIEX TripleTOF 5600+, Waters XevoG2 QTOF, ThermoFisher Q-Exactive Plus, Agilent 6546 QTOF system, SCIEX TripleTOF 6600 using SWATH-DIA, and Bruker timsTOF Pro. This diversity in instrumentation and analysts helped to ensure that the test set was truly independent of the training set.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the lipidomics field. The training set included a wide range of lipid subclasses, with a total of 39,871 spectra encompassing 4100 metabolites of 116 lipid subclasses labeled as correct. However, certain lipid classes with five or fewer records, as well as free fatty acids and N-acyl ethanolamine, were excluded from the learning process due to insufficient diagnostic criteria in the MS/MS spectra. Additionally, lipid spectral records labeled as \"others\" were excluded, as they were annotated based on standard compound spectral libraries rather than rule-based lipid annotation.\n\nThe final dataset used for machine learning consisted of 17,029 spectral records of 3944 unique lipid molecules across 97 lipid classes. This dataset included 8451 ESI(+)-MS/MS spectra of 2559 unique lipids and 8578 ESI(-)-MS/MS spectra of 2048 unique lipids. This comprehensive and diverse dataset ensured that the machine learning models were trained on a representative sample of lipid spectra, enhancing their accuracy and reliability.",
  "dataset/availability": "The data used in this study is publicly available. The training, validation, and test data for constructing the MS2lipid program are presented in Supplementary Data S2. The experimental MS/MS spectra for validation of MS2lipid were downloaded from the RIKEN Lipidomics website. Human cohort lipidomics data were downloaded from the RIKEN DROPMet website under the index number DM0037. The source code and tutorial for MS2lipid are available on GitHub. The data is accessible to the public, ensuring transparency and reproducibility of the research. The data was curated by experienced analysts, and the annotation results were manually evaluated to ensure accuracy. The data was processed using MS-DIAL 4, and the lipid structures were described using the MS/MS spectra obtained by data-dependent acquisition in both positive and negative ion modes. The data was divided into training and test sets, and the correctly labeled data was used for machine learning. The data was also used to evaluate the performance of the MS2lipid program, and the results showed high accuracy in lipid subclass classification. The data is available to the public, and the source code and tutorial are also available on GitHub, making it accessible for further research and development.",
  "optimization/algorithm": "The machine-learning algorithm class used is ensemble learning, specifically XGBoost. This algorithm is not new; it is a well-established gradient boosting framework that has been widely used in various machine learning applications. The choice of XGBoost was driven by its superior performance in both positive and negative ion modes during the evaluation of different machine learning methods. These methods included k-nearest neighbor (KNN), random forest (RF), support vector machine (SVM), and Multi-layer Perceptron (MLP).\n\nThe reason XGBoost was not published in a machine-learning journal is that it is an existing algorithm that has already been extensively documented and validated in the literature. The focus of the publication is on the application of XGBoost to lipid subclass classification, rather than the development of a new machine-learning algorithm. The study demonstrates how XGBoost can be effectively used to achieve high accuracy in lipidomics data analysis, leveraging its strengths in handling complex datasets and providing robust predictions.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it evaluates and optimizes individual machine learning models for lipid subclass classification. Five different machine learning methods were assessed: k-nearest neighbor (KNN), random forest (RF), support vector machine (SVM), XGBoost (XGB), and Multi-layer Perceptron (MLP). Among these, XGBoost demonstrated the highest accuracy in both positive and negative ion modes.\n\nThe training and test datasets were carefully curated to ensure independence. Spectral data derived from 82 projects were analyzed using MS-DIAL, resulting in lipid annotations for 82,397 spectra. These annotations were manually curated and labeled as correct, mix, or false hit. The correctly labeled data, consisting of 17,029 spectra, were then divided into training and test sets. This division ensured that the model's performance could be evaluated on unseen data, maintaining the integrity of the training process.\n\nThe spectrum vector construction involved representing the MS/MS spectrum as an array of product ions and neutral losses, with high-resolution mass values converted into nominal mass. Additionally, a descriptor called the \"MCH-value\" was calculated from the accurate precursor m/z value. This descriptor was designed to provide a consistent value among molecules of each lipid subclass, regardless of differences in fatty acid side chains.\n\nThe optimized XGBoost model was evaluated using a test dataset, where the lipid subclass with the highest probability value was defined as the representative candidate. The results showed that the correct lipid subclass was predicted with high accuracy in both ion modes. Furthermore, the correct lipid subclass was listed as a candidate for more than 99% of the queries, indicating the model's robustness and reliability.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to prepare the spectral data for the machine-learning algorithm. We began by focusing on product ions (PLs) within the m/z range of 70 to 1250, rounding these values to one decimal place. The centroid peak heights in the bins were summed to create a comprehensive representation of the spectral data.\n\nIn addition to product ions, we incorporated neutral loss (NL) information derived from the precursor m/z values. The NL value was calculated as the mass difference between the precursor m/z and product ion m/z values. To ensure data quality, NL values ranging from 0 to 10 were excluded from the analysis.\n\nThe m/z and NL values with zero standard deviations in the dataset were removed to eliminate any redundant or non-informative features. Peak intensities were normalized, and the base peak intensity was standardized to 1. This standardization process ensured that the data was consistent and comparable across different spectra.\n\nTo enhance the descriptive power of our model, we introduced a new descriptor called the mode of carbon and hydrogen (MCH) value. This descriptor was designed to be consistent within the same lipid subclass while differentiating between lipid subclasses with similar spectral patterns. For example, the MCH value helped distinguish between the acetate adduct forms of PC 33:1 and PC O-34:1, which have very close m/z values.\n\nThe MS/MS spectrum was represented by an array of product ions and neutral losses, with high-resolution mass values converted into nominal mass. This conversion simplified the data while retaining essential information for the machine-learning models.\n\nDescriptors were created for various lipid subclasses, including cholesteryl ester (CE), ceramide containing sphingosine and normal fatty acid (Cer-NS), diacylglycerol (DG), ether-linked DG (EtherDG), phosphatidylcholine (PC), lysoPC (LPC), ether-linked PC (EtherPC), triacylglycerol (TG), ether-linked TG (etherTG), phosphatidylethanolamine (PE), lysoPE (LPE), phosphatidylinositol (PI), phosphatidylserine (PS), and sphingomyelin (SM). These descriptors were used as input features for the machine-learning models, which output the probability ratio of lipid subclass classifications.\n\nIn summary, our data encoding and preprocessing involved rounding m/z values, summing centroid peak heights, incorporating NL information, normalizing peak intensities, and introducing the MCH value. These steps ensured that the spectral data was accurately and consistently represented, enabling the machine-learning models to effectively classify lipid subclasses.",
  "optimization/parameters": "In the optimization of our machine learning model, we evaluated several parameters to enhance its performance. For the XGBoost model, which demonstrated the best accuracy, the key parameters optimized were tree depth, maximum tree depth, and learning rate. Specifically, the tree depth was set to 200, the maximum tree depth to 3, and the learning rate to 0.1. These parameters were chosen through a systematic optimization process using GridSearchCV with five-fold cross-validation, ensuring that the model's accuracy was maximized.\n\nThe input feature sets varied depending on the ion mode. In positive ion mode, the model used 1367 variables, while in negative ion mode, it utilized 1139 variables. These variables were derived from the MS/MS spectral records and included descriptors such as product ions and neutral losses, which were converted from high-resolution mass values to nominal mass. Additionally, a descriptor called the \"MCH-value\" was calculated from the accurate precursor m/z value to provide a consistent value among molecules of each lipid subclass.\n\nThe output layer of the model represents the probability of lipid ontology classification, with the lipid subclass having the highest probability value being used as the representative candidate. This approach ensured that the model could accurately predict lipid subclasses based on the spectral data provided.",
  "optimization/features": "The input features for the MS2Lipid model vary depending on the ion mode. In positive ion mode, the input feature set comprises 1367 variables. In negative ion mode, the input feature set consists of 1139 variables. These features are derived from the MS/MS spectrum, represented by an array of product ions and neutral losses, with high-resolution mass values converted into nominal mass. Additionally, a descriptor called the \"MCH-value\" is calculated from the accurate precursor m/z value. The features are used to describe various lipid subclasses, including cholesteryl ester, ceramide, diacylglycerol, phosphatidylcholine, triacylglycerol, phosphatidylethanolamine, and others.\n\nFeature selection was implicitly performed through the construction of the spectrum vectors and the calculation of the MCH-value. This process ensures that only relevant and informative features are included in the model. The feature selection was conducted using the training set only, adhering to best practices in machine learning to prevent data leakage and ensure the model's generalizability. The optimized parameters for the XGBoost model, such as tree depth and learning rate, were also determined using the training set, further enhancing the model's performance and reliability.",
  "optimization/fitting": "The fitting method employed for the MS2Lipid model involved evaluating five different machine learning algorithms: k-nearest neighbor (KNN), random forest (RF), support vector machine (SVM), XGBoost (XGB), and Multi-layer Perceptron (MLP). Among these, XGBoost was identified as the most accurate model for both positive and negative ion modes.\n\nThe dataset used for training consisted of 17,029 spectra, which were divided into training and test sets. This division ensured that the model was trained on a substantial amount of data, reducing the risk of overfitting. The input feature sets comprised 1367 variables for positive ion mode and 1139 variables for negative ion mode, which are relatively large compared to the number of training points. To mitigate overfitting, the model parameters were carefully optimized. For instance, the tree depth was set to 200, the maximum tree depth to 3, and the learning rate to 0.1. These settings helped in controlling the complexity of the model and preventing it from memorizing the training data.\n\nTo further validate the model's performance and rule out overfitting, the test dataset was used to evaluate the optimized model. The lipid subclass with the highest probability value was defined as the representative candidate. If the correct lipid subclass was predicted with a probability greater than 1%, it was considered \"listed in candidates.\" The results showed high accuracies of 97.2% and 97.6% for positive and negative ion mode spectra, respectively, indicating that the model generalized well to unseen data.\n\nAdditionally, an investigation was conducted to ascertain the impact of random label shuffling on prediction accuracy. Models constructed using data with shuffled labels exhibited significantly lower accuracies of 1.7% for positive ion mode and 1.6% for negative ion mode. This drastic decrease in accuracy suggests that the model is effectively learning lipid class-specific spectral patterns rather than merely modeling inherent noise, thereby ruling out overfitting.\n\nUnderfitting was addressed by ensuring that the model had sufficient complexity to capture the underlying patterns in the data. The use of a large number of variables and the optimization of model parameters helped in achieving this. The high accuracies obtained on the test dataset further confirm that the model is neither underfitted nor overfitted.",
  "optimization/regularization": "In the optimization process of our machine learning models, particularly the XGBoost model, we employed several techniques to prevent overfitting. One of the key methods used was parameter tuning. For instance, we set the maximum tree depth to 3, which helps in controlling the complexity of the model and prevents it from learning noise in the training data. Additionally, we used a learning rate of 0.1, which ensures that the model updates its predictions gradually, further mitigating the risk of overfitting.\n\nAnother important technique we utilized was the evaluation of model performance on a separate test dataset. By dividing the correctly labeled data into training and test sets, we were able to assess the model's generalization capability. The model's accuracy was evaluated on the test dataset, ensuring that it performed well on unseen data, which is a strong indicator of its ability to generalize.\n\nFurthermore, we conducted an investigation to understand the impact of lipid class labels on prediction accuracy. Models constructed using data with shuffled labels exhibited significantly lower accuracy, demonstrating that our model is effectively learning lipid class-specific spectral patterns rather than merely modeling inherent noise. This finding underscores the robustness of our model and its ability to generalize to new data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters for the MS2Lipid XGB model are reported in the publication. For the positive ion mode, the model used a tree depth of 200, a maximum tree depth of 3, and a learning rate of 0.1. The same parameters were applied in the negative ion mode. The input and output feature sets for the positive ion mode comprised 1367 variables and 63 lipid subclasses, respectively, while the negative ion mode consisted of 1139 variables and 69 lipid subclasses.\n\nThe model was developed on a LINUX operating system with an Intel(R) Xeon(R) Gold 6438M 64-Core Processor and 1056 GB of RAM. The spectral data used for training and testing were derived from 82 projects, analyzed by MS-DIAL, and manually curated. The correctly labeled data of 17,029 spectra were divided into training and test sets.\n\nThe evaluation of the model included accuracy, precision, recall, and F1-score metrics, with the XGBoost model offering the best accuracy in both ion modes. The optimized model's performance was assessed using a test dataset, where the lipid subclass with the highest probability value was defined as the representative candidate. The correct lipid subclass was predicted with accuracies of 97.2% and 97.6% for the positive and negative ion mode spectra, respectively.\n\nThe model files and specific optimization schedules are not explicitly detailed in the provided information. However, the methodology and parameters used for optimization are thoroughly described, allowing for replication and further study. The publication likely includes sufficient detail for researchers to implement and validate the model independently. For access to the model files and further details, referring to the supplementary materials or contacting the authors would be necessary.",
  "model/interpretability": "The MS2Lipid model is not a black box; it incorporates interpretability through the use of Shapley additive explanation (SHAP) scores. These scores help identify important descriptors for lipid subclass classification, making the model's decision-making process more transparent.\n\nIn the positive ion mode, the most significant features include the \"MCH-value\" descriptor, along with product ions of m/z 184 and m/z 369, and a neutral loss (NL) of 141 Da. These features correspond to the phosphocholine polar head, cholesterol aglycone, and phosphoethanolamine polar head, respectively. These diagnostic ions are well-recognized in lipidomics, indicating that the model effectively learns from established spectral patterns.\n\nIn the negative ion mode, the top features include NL of 74, NL of 197 Da, and m/z 153. These represent the loss of acetic acid plus methyl in EtherPC and PC, the loss of ethanolamine glycerophosphate observed in lyso PE (LPE), and the product ion of glycerol phosphate observed in glycerophospholipids. These features further demonstrate the model's ability to recognize key spectral characteristics.\n\nThe SHAP results indicate that the MS2Lipid model successfully identifies diagnostic ions that are commonly used in lipid subclass classification. This transparency is crucial for building trust in the model's predictions and for understanding the underlying spectral data.",
  "model/output": "The model is a classification model designed to predict lipid subclasses from mass spectrometry data. It outputs the probability ratio of lipid subclass classifications, with the lipid subclass having the highest probability value being considered the representative candidate. The model was evaluated using accuracy, precision, recall, and F1-score metrics, indicating its performance in classifying lipid subclasses correctly. In both positive and negative ion modes, the model demonstrated high accuracy, with correct lipid subclass predictions achieved in over 97% of cases. Additionally, the correct lipid subclass was listed as a candidate for more than 99% of the queries, showcasing the model's robustness in identifying lipid subclasses from spectral data. The model's performance was further validated by comparing it against a benchmark, confirming its effectiveness in lipid subclass classification.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for MS2Lipid is publicly available. It can be accessed via a GitHub repository, which includes the source code and a tutorial for using the program. This repository is designed to facilitate the use and further development of MS2Lipid by the scientific community. The availability of the source code ensures transparency and allows other researchers to verify, modify, and build upon the work presented. The specific details on how to access and use the source code, including any licensing information, can be found in the repository.",
  "evaluation/method": "The evaluation of the MS2Lipid program involved several key steps and comparisons to ensure its robustness and accuracy. Initially, five machine learning methods were evaluated: k-nearest neighbor (KNN), random forest (RF), support vector machine (SVM), XGBoost (XGB), and Multi-layer Perceptron (MLP). Among these, XGBoost demonstrated the highest accuracy in both positive and negative ion modes. The optimized XGBoost model was then tested on a dataset where the lipid subclass with the highest probability value was defined as the representative candidate. The results showed that the correct lipid subclass was predicted with accuracies of 97.2% and 97.6% for positive and negative ion mode spectra, respectively. Additionally, the correct lipid subclass was listed as a candidate for more than 99% of the queries.\n\nTo further validate the model's performance, an investigation was conducted by randomly shuffling the lipid class labels. Models constructed with shuffled labels exhibited significantly lower accuracies, indicating that the model effectively learns lipid class-specific spectral patterns rather than inherent noise.\n\nThe MS2Lipid program was also benchmarked against CANOPUS, which classifies product ion spectra into chemical classes defined by ClassyFire. The same test set was used for both programs. CANOPUS, however, only generated output for 38.7% of the spectral queries due to its threshold for probability and molecular weight limitations. For the queries it could handle, CANOPUS achieved 82.4% accuracy, which was outperformed by MS2Lipid.\n\nThe robustness of MS2Lipid was further evaluated using various spectral data obtained from different machines and curated by different analysts. Spectral data from Waters, Bruker, Thermo Fisher, Agilent, and SCIEX were used, and the program demonstrated high accuracy regardless of the data source or analyst, highlighting its scalability and reliability.\n\nAdditionally, the program's performance was assessed using publicly available human feces lipidomics data. The data were analyzed using MS-DIAL, and the results were visualized using Cytoscape. This evaluation included a correlation analysis between the lipidome and microbiome data, providing insights into the relationship between lipids and gut microbiota.\n\nOverall, the evaluation method involved a comprehensive approach, including comparisons with other models, testing on diverse datasets, and real-world applications, to ensure the reliability and accuracy of the MS2Lipid program.",
  "evaluation/measure": "In the evaluation of our machine learning models for lipid subclass classification, several key performance metrics were reported. These include accuracy, precision, recall, and F1-score, which were assessed for various models such as k-nearest neighbor (KNN), random forest (RF), support vector machine (SVM), XGBoost (XGB), and Multi-layer Perceptron (MLP). These metrics provide a comprehensive view of the models' performance, covering aspects like the correct prediction rate, the ability to identify positive instances, and the balance between precision and recall.\n\nThe accuracy of the MS2Lipid program in predicting the ClassyFire \u201cclass\u201d level exceeded 99.0%, demonstrating its high reliability. Additionally, the prediction accuracy in the XGBoost model was evaluated in both positive and negative ion modes, showing the model's effectiveness in different conditions. The output was considered correct if the predicted lipid subclass matched the correct label, and it was listed as a candidate if the correct label was present in the candidate list.\n\nThe Shapley additive explanation (SHAP) scores were also calculated to investigate important descriptors for lipid subclass classification. This approach helps in understanding which features are most influential in the model's predictions, providing insights into the diagnostic ions and neutral losses that are crucial for accurate classification.\n\nThe performance of MS2Lipid was compared with CANOPUS, a benchmark program. CANOPUS supported only 38.7% of the spectral queries and achieved 82.4% accuracy for the queries it could handle. In contrast, MS2Lipid outperformed CANOPUS in prediction accuracy, highlighting the importance of accumulating both standard spectra and spectral information from biological samples to build a highly accurate learning model.\n\nThe robustness and scalability of MS2Lipid were evaluated using various spectral data obtained from different machines and curated by different analysts. The program demonstrated high accuracy in both positive and negative ion modes, even when applied to spectra acquired using different MS techniques. This evaluation underscores the model's ability to provide objective decisions regardless of the data analysts and the machines used.\n\nIn summary, the reported performance metrics are representative and align with the standards in the literature. The use of accuracy, precision, recall, F1-score, and SHAP scores ensures a thorough assessment of the models' capabilities. The comparison with CANOPUS and the evaluation of robustness further validate the effectiveness and reliability of the MS2Lipid program.",
  "evaluation/comparison": "A comparison to publicly available methods was performed using benchmark datasets. Specifically, the MS2Lipid program was benchmarked against CANOPUS, which classifies product ion spectra into chemical classes defined by ClassyFire. The same test set was used for both programs to ensure a fair comparison. CANOPUS predicts all chemical classes, including lipids, from the query spectrum and was trained using authentic standard-derived spectral libraries such as GNPS and MassBank. However, the spectral records of lipids in these libraries are smaller compared to the training set used for MS2Lipid. This comparison reflects the lipid diversity in the training sets rather than the model-building process.\n\nThe accuracy of MS2Lipid for the test set was 97.4%. In predicting the ClassyFire \u201cclass\u201d level, MS2Lipid exceeded 99.0% accuracy. CANOPUS, on the other hand, did not generate output for half of the spectral queries because it provides predicted results only for compounds with a probability above 50% and primarily supports computation for compounds less than 600 Da. CANOPUS supported only 38.7% of the spectral queries and achieved 82.4% accuracy for the queries it could handle. This result indicates that in lipid spectrum machine learning research, it is necessary to accumulate both standard spectra and spectral information from biological samples to build a highly accurate learning model. The comparison highlights the superior performance of MS2Lipid in prediction accuracy and robustness.",
  "evaluation/confidence": "The evaluation of the MS2Lipid program included a comprehensive assessment of its performance metrics, which were crucial for determining its reliability and superiority over other methods. The performance metrics, such as accuracy, precision, recall, and F1-score, were evaluated for various machine learning models, including k-nearest neighbor (KNN), random forest (RF), support vector machine (SVM), XGBoost (XGB), and Multi-layer Perceptron (MLP). These metrics were presented for both positive and negative ion modes, providing a clear indication of the model's effectiveness across different conditions.\n\nThe prediction accuracy of the XGBoost model was particularly highlighted, showing the model's ability to correctly predict lipid subclasses. The results were categorized into \"correct\" predictions, where the predicted lipid subclass matched the correct label, and \"listed in candidates,\" where the correct label was included in the candidate list. This detailed breakdown allowed for a nuanced understanding of the model's performance.\n\nStatistical significance was addressed through the comparison of MS2Lipid with the CANOPUS benchmark. The MS2Lipid program demonstrated superior accuracy, exceeding 99.0% in predicting the ClassyFire \"class\" level. In contrast, CANOPUS could only handle 38.7% of the spectral queries and achieved an accuracy of 82.4% for the queries it could process. This comparison underscored the robustness and scalability of MS2Lipid, especially when dealing with diverse spectral data from various machines and analysts.\n\nThe evaluation also included an analysis of the Shapley additive explanation (SHAP) scores, which identified important descriptors for lipid subclass classification. The \"MCH-value\" was consistently recognized as the most important feature, indicating the model's reliance on the accuracy of the precursor m/z. Additional important features, such as specific product ions and neutral losses, were also highlighted, providing insights into the diagnostic ions utilized by the model.\n\nThe robustness of MS2Lipid was further validated by its performance on spectra obtained from different machines and curated by various analysts. The program maintained high accuracy levels, demonstrating its ability to provide objective decisions regardless of the data analysts' variations. This consistency is crucial for the reliability of the model in real-world applications.\n\nIn summary, the performance metrics of MS2Lipid were thoroughly evaluated, and the results were statistically significant, confirming the model's superiority over existing methods. The detailed analysis of SHAP scores and the program's robustness across different spectral data further strengthened the confidence in its performance.",
  "evaluation/availability": "The training, validation, and test data used for constructing the MS2Lipid program are available in the supplementary data. Specifically, these datasets can be found in Supplementary Data S2. Additionally, the experimental MS/MS spectra used for validating MS2Lipid were obtained from the RIKEN Lipidomics website. These spectra are accessible via a specific link provided in the publication. For further validation, human cohort lipidomics data were downloaded from the RIKEN DROPMet website under the index number DM0037. Both of these datasets are publicly available and can be accessed through the provided URLs.\n\nThe source code and tutorial for MS2Lipid are also publicly available. They can be accessed through a GitHub repository, which includes detailed instructions and examples for using the program. This repository is open to the public and can be found at the specified GitHub link. The availability of these resources ensures that other researchers can replicate our findings and utilize the MS2Lipid program for their own studies."
}