{
  "publication/title": "Unified framework for early stage status prediction of autism based on infant structural magnetic resonance imaging.",
  "publication/authors": "Gao K, Sun Y, Niu S, Wang L",
  "publication/journal": "Autism research : official journal of the International Society for Autism Research",
  "publication/year": "2021",
  "publication/pmid": "34643325",
  "publication/pmcid": "PMC8665129",
  "publication/doi": "10.1002/aur.2626",
  "publication/tags": "- Autism Spectrum Disorder\n- Magnetic Resonance Imaging\n- Deep Learning\n- Predictive Modeling\n- Sex Information\n- Siamese Networks\n- Attention Mapping\n- Infant Brain Imaging\n- Data Harmonization\n- Cross-Validation",
  "dataset/provenance": "The datasets used in this study were obtained from the National Database for Autism Research (NDAR), a collaborative informatics network created by the National Institutes of Health (NIH) to support and accelerate research in autism. Two datasets were utilized, each acquired by different scanners and imaging protocols.\n\nThe first dataset, referred to as dataset A, consists of 247 subjects from the Infant Brain Imaging Study (IBIS) network. The second dataset, dataset B, includes 35 subjects from the Autism Centers of Excellence (ACE). All images were scanned from infants at approximately 24 months of age, with no significant age difference between the autism spectrum disorder (ASD) and neurotypical control (NC) groups. The infants were naturally sleeping with ear and head protection during the image acquisition process.\n\nThese datasets have been previously used in the community for research purposes, highlighting their relevance and the potential for comparative studies. The use of different scanners and imaging parameters in these datasets underscores the importance of developing robust models that can generalize across varied imaging conditions.",
  "dataset/splits": "In our study, we utilized two distinct datasets, referred to as dataset A and dataset B, to evaluate the performance of our model. Dataset A consists of 247 subjects, while dataset B consists of 35 subjects. For dataset A, we employed a 10-fold cross-validation strategy. This means the data was split into 10 different folds, where each fold was used once as the testing set, and the remaining nine folds were used as the training set. This approach ensures that each subject is used for both training and testing, providing a robust evaluation of the model's performance.\n\nFor each fold in the 10-fold cross-validation, nine-tenths of the ASD subjects and nine-tenths of the NC subjects from dataset A were used as the training set, while the remaining cases were used as the testing set. This method helps in assessing the model's ability to generalize to unseen data.\n\nDataset B, being smaller, was not subjected to the same cross-validation strategy. Instead, it was used to evaluate the model's performance on a different dataset with varying imaging parameters, providing insights into the model's robustness and generalizability across different datasets.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets used in this study are publicly available through the National Database for Autism Research (NDAR). Specifically, dataset A consists of 247 subjects from the Infant Brain Imaging Study (IBIS) network, and dataset B consists of 35 subjects from the Autism Centers of Excellence (ACE). These datasets can be accessed via the NDAR website, which provides a platform for sharing and collaborating on autism research data.\n\nThe data splits used in our study were not explicitly released, as the focus was on evaluating the model's performance across different datasets with varying imaging parameters. The datasets were used to train and test our model, with a 10-fold cross-validation strategy applied to dataset A. This strategy involved dividing the data into training and testing sets multiple times to ensure robust evaluation.\n\nThe NDAR enforces data sharing and collaboration by requiring researchers to adhere to specific data use agreements and protocols. These agreements ensure that the data is used ethically and responsibly, with appropriate measures in place to protect participant privacy and confidentiality. Researchers must comply with these agreements to access and use the data, promoting a collaborative and transparent research environment.\n\nThe datasets are made available under licenses that allow for research use, subject to the terms and conditions outlined in the data use agreements. These licenses ensure that the data is used for legitimate research purposes and that the rights of the data contributors are respected. By adhering to these licenses, researchers can access and utilize the data to advance autism research while maintaining ethical standards and data integrity.",
  "optimization/algorithm": "The machine-learning algorithm class used is a Siamese network, which is a type of deep neural network designed to find similarities or dissimilarities between pairwise subjects by comparing their feature vectors. This approach differs from traditional convolutional neural networks (CNNs) that directly classify a single subject into a specific category.\n\nThe Siamese network employed in our study is not entirely new, as it has been previously used in various applications. However, its application in the context of autism spectrum disorder (ASD) prediction, particularly with the integration of segmentation and parcellation maps, is novel. The Siamese network in our framework is tailored to handle the specific challenges of ASD prediction, such as dealing with high inter-site data heterogeneity caused by different imaging protocols and scanners.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of our work is on its application in the medical field, specifically for ASD prediction. The innovation lies in how the Siamese network is adapted and integrated into a comprehensive framework that includes preprocessing steps, feature extraction, attention mechanisms, and contrastive loss calculation. This framework is designed to improve the robustness and generalization ability of the model across different datasets and imaging parameters, making it a valuable tool for clinical applications.\n\nThe Siamese network is optimized using contrastive loss and stochastic gradient descent with momentum. The learning rate is initialized at 1e-3 with cosine annealing decay. This optimization process ensures that the model can effectively learn the relationships between pairwise inputs, enhancing its predictive performance for ASD.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model is a deep learning-based predictive model that includes informative feature- and attention-guided Siamese networks. The Siamese network is used as the main architecture to achieve early-status prediction of ASD. It is composed of two parallel paths corresponding to pairwise inputs. Each path includes five fully connected layers, followed by batch normalization and rectified linear unit activation. The model uses segmentation and parcellation maps as input, which are generated by the iBEAT V2.0 Cloud software. The training data consists of pairwise inputs randomly selected from the training set, and the testing data consists of the mean distance between a given testing subject and all training subjects. The model is trained using contrastive loss and stochastic gradient descent with momentum. The learning rate is initialized at 1e-3 with cosine annealing decay. The minibatch size is set at 2, and 0.4 dropout is applied to each fully connected layer in the Siamese network. The model is implemented in a single NVIDIA GTX TITAN (12GB) GPU using the PyTorch framework.",
  "optimization/encoding": "The data encoding and preprocessing for our machine-learning algorithm involved several key steps. Initially, raw intensity images underwent intensity inhomogeneity correction and skull stripping. Following this, segmentation and parcellation were performed using the iBEAT V2.0 Cloud software, which segmented each infant brain image into three tissues\u2014white matter, gray matter, and cerebrospinal fluid\u2014and parcellated it into 151 regions of interest (ROIs), with 133 in the cerebrum and 18 in the cerebellum. These segmentation and parcellation maps served as the input for our deep learning-based predictive model.\n\nThe model itself consisted of three main components: the feature extraction and fusion module, the subject-specific autism attention module, and the Siamese distinguishing module. In the feature extraction and fusion module, two convolutional neural networks (CNNs) were employed to separately extract features from the segmentation and parcellation maps. These CNNs had identical structures but different weights, encouraging the network to learn distinct features from the two maps. The extracted features were then combined and further fused through three convolutional layers, each using 3x3x3 kernels with zero padding, followed by batch normalization and rectified linear unit activation. The stride of the extraction layer was set to 1, while the down-sampling layers used a stride of 2 to enlarge the receptive field and mitigate information loss. The channel numbers of the last layer in the feature extraction and fusion module were set to 32 and 128, respectively, to minimize the number of channels.\n\nThe subject-specific autism attention module was designed to identify regions associated with autism spectrum disorder (ASD) in an end-to-end manner. This module consisted of two parallel attention paths, each containing a squeeze and excitation (SE) block and a channel-wise mean. The SE block weighted all features, while the channel-wise mean generated an attention map for each subject. After processing through the attention module, sex information was concatenated with the features. The two parallel paths in this module had the same structure but different weights.\n\nFinally, the Siamese distinguishing module was used to construct a relationship matrix and calculate the distance between ASD and normal control (NC) subjects using contrastive loss. This module consisted of five fully connected layers, followed by batch normalization and rectified linear unit activation. The contrastive loss was formulated to ensure that distances among the same class were small, while distances between different classes were large. This approach allowed the model to consider the similarity or dissimilarity of pairwise subjects by comparing their feature vectors, rather than directly classifying a single subject into a specific category.",
  "optimization/parameters": "The model utilized a Siamese network architecture, which inherently involves a significant number of parameters due to its dual-path structure. Each path in the Siamese network consists of five fully connected layers, followed by batch normalization and rectified linear unit activation. This design allows for a comprehensive feature extraction process from the input data.\n\nThe specific number of parameters (p) in the model is not explicitly stated, but it can be inferred that the complexity is substantial given the architecture. The choice of this architecture was driven by the need to handle pairwise inputs effectively, which is crucial for the contrastive loss calculation. This approach enlarges the training samples and improves the accuracy of predictions by treating the testing phase as an ensemble system.\n\nThe minibatch size was set to 2, which is consistent with the pairwise input requirement of the Siamese network. A dropout rate of 0.4 was applied to each fully connected layer to prevent overfitting. The learning rate was initialized at 1e-3 with cosine annealing decay, which helps in fine-tuning the model parameters over the training epochs.\n\nThe optimization process used contrastive loss and stochastic gradient descent with momentum. These choices were made to ensure that the model could effectively learn the similarities and differences between the pairwise inputs, which is essential for distinguishing between different classes.\n\nIn summary, the model's parameters were selected based on the requirements of the Siamese network architecture and the need for robust feature extraction and classification. The specific values for dropout rate, learning rate, and minibatch size were chosen to balance between model complexity and generalization performance.",
  "optimization/features": "The input features for our model are derived from segmentation and parcellation maps of infant brain images. Specifically, each infant brain image is segmented into three tissues: white matter, gray matter, and cerebrospinal fluid. Additionally, the brain is parcellated into 151 regions of interest (ROIs), with 133 ROIs in the cerebrum and 18 ROIs in the cerebellum. These segmentation and parcellation maps are used to extract features using convolutional neural networks (CNNs).\n\nFeature selection is implicitly performed through the use of an attention mechanism. The subject-specific autism attention module identifies regions associated with autism spectrum disorder (ASD) by weighting the features extracted from the segmentation and parcellation maps. This process ensures that only the most relevant features are emphasized for the prediction task.\n\nThe attention mechanism is trained end-to-end, meaning that the feature selection is performed using the training set only. This approach helps to avoid overfitting and ensures that the model generalizes well to unseen data. The attention maps generated by this module highlight specific brain regions, such as the amygdala, hippocampus, and cerebellum, which are known to be related to ASD. This not only improves the model's predictive performance but also provides insights into the biological mechanisms underlying the disorder.",
  "optimization/fitting": "The fitting method employed in our study utilized a Siamese network architecture, which inherently addresses some of the challenges associated with overfitting and underfitting.\n\nThe Siamese network consists of two parallel paths that process pairwise inputs, significantly increasing the effective number of training samples. This approach leverages any unique pairwise combinations in the training set, thereby enriching the training data and mitigating the risk of overfitting. Additionally, the use of contrastive loss helps in learning a robust feature representation that can generalize well to unseen data.\n\nTo further prevent overfitting, dropout regularization was applied to each fully connected layer within the Siamese network. A dropout rate of 0.4 was used, which randomly sets a fraction of the input units to zero during training, forcing the network to learn more robust features.\n\nThe model was trained using stochastic gradient descent with momentum and a learning rate initialized at 1e-3 with cosine annealing decay. This learning rate schedule helps in fine-tuning the model parameters effectively, ensuring that the model does not converge too quickly to a suboptimal solution, thus avoiding underfitting.\n\nThe minibatch size was set to 2, which is appropriate for pairwise input processing in the Siamese network. This batch size, combined with the contrastive loss and the learning rate schedule, ensures that the model learns to distinguish between similar and dissimilar pairs effectively.\n\nIn summary, the combination of a rich training set through pairwise inputs, dropout regularization, and an effective learning rate schedule helps in balancing the model complexity, preventing both overfitting and underfitting. The results demonstrate the model's ability to generalize well across different datasets, confirming the robustness of the fitting method.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One key method was the use of dropout, specifically a 0.4 dropout rate, applied to each fully connected layer in the Siamese network. Dropout is a regularization technique that helps prevent overfitting by randomly setting a fraction of input units to zero at each update during training time, which helps to prevent units from co-adapting too much.\n\nAdditionally, we utilized a contrastive loss function, which is designed to learn a metric space where similar pairs of inputs (from the same class) are mapped to nearby points, while dissimilar pairs (from different classes) are mapped far apart. This approach helps in learning more discriminative features and reduces the risk of overfitting to the training data.\n\nWe also implemented stochastic gradient descent with momentum and cosine annealing decay for the learning rate. This optimization strategy helps in stabilizing the training process and prevents the model from getting stuck in local minima, thereby improving generalization.\n\nFurthermore, the Siamese network architecture itself provides a form of regularization. By training on pairwise inputs, the network learns to compare and contrast features between subjects, which can help in capturing more generalizable patterns rather than memorizing specific examples.\n\nThese regularization techniques collectively contribute to the model's ability to generalize well to unseen data, as evidenced by our results on multiple datasets with different imaging parameters.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the minibatch size was set to 2 for pairwise input, and a dropout rate of 0.4 was applied to each fully connected layer in the Siamese network. The learning rate was initialized at 1e-3 with cosine annealing decay. These details are provided to ensure reproducibility.\n\nThe model was implemented using the PyTorch framework on a single NVIDIA GTX TITAN GPU with 12GB of memory. The contrastive loss and stochastic gradient descent with momentum were employed to optimize the model weights.\n\nRegarding the availability of model files and optimization parameters, these are not explicitly provided in the publication. However, the methods and configurations described are sufficient for researchers to replicate the experiments. The software used, such as iBEAT V2.0 Cloud for preprocessing, is publicly available, and the implementation details of the Siamese network and other components are thoroughly explained.\n\nFor those interested in further details or access to specific code or models, additional information can be requested from the corresponding authors. The data used in this study were obtained from the National Database for Autism Research (NDAR), and the methods for accessing this data are outlined in the acknowledgments section. The publication reflects the views of the authors and does not necessarily represent the opinions of the NIH or the original data submitters to NDAR.",
  "model/interpretability": "The model employed in our study is not a blackbox, as it incorporates mechanisms to enhance interpretability. One key aspect of our approach is the use of attention maps, which are generated by a subject-specific autism attention module. These attention maps highlight regions of the brain that are associated with autism spectrum disorder (ASD). Specifically, our method identified the amygdala, hippocampus, and cerebellum as regions related to ASD, which aligns with findings from previous studies. This data-driven approach to region of interest (ROI) identification provides a clearer understanding of the predictive results, as opposed to relying on predefined biomarkers.\n\nAdditionally, the use of segmentation and parcellation maps, processed through the iBEAT V2.0 Cloud, allows for a more transparent and robust analysis. These maps segment the brain into different tissues and parcellate it into specific regions, providing a structured way to analyze the data. This method ensures that the model's predictions are based on well-defined anatomical features, rather than arbitrary image intensities.\n\nThe Siamese network, which is a core component of our model, also contributes to interpretability. By comparing pairwise inputs and calculating the distance between them, the network can distinguish between subjects from the same class or different classes. This pairwise training strategy helps in establishing a clear relationship between ASD and normal control (NC) subjects, even with a relatively small number of subjects.\n\nFurthermore, the integration of sex information into the model improves its predictive performance and stability. The attention maps generated with this information provide a more nuanced understanding of how sex factors into the diagnosis of ASD. This integration not only enhances the model's accuracy but also makes its decision-making process more transparent.\n\nIn summary, our model's use of attention maps, segmentation and parcellation maps, and the Siamese network's pairwise training strategy all contribute to its interpretability. These features allow for a clearer understanding of the model's predictions and the underlying biological mechanisms associated with ASD.",
  "model/output": "The model is a classification model. It is designed to predict whether a subject has autism spectrum disorder (ASD) or is a normal control (NC). The model uses a Siamese network to calculate the contrastive loss based on distances between pairwise inputs, determining whether they are from the same class (ASD or NC) or different classes. The final output is a binary label indicating the classification of the subject.\n\nThe model's output is derived from the mean distance between a testing subject and all training subjects, which is used to distinguish whether the testing subject is from the ASD or NC group. This approach leverages the Siamese network's ability to compare feature vectors and determine similarities or dissimilarities between subjects.\n\nThe model's performance is evaluated using metrics such as sensitivity (SEN), specificity (SPE), and accuracy (ACC). These metrics provide a quantitative measure of the model's ability to correctly classify subjects as ASD or NC. Additionally, the model's performance is assessed using receiver operating characteristic (ROC) curves and area under the ROC curve (AUC) analyses, which further validate its discriminative capacity.\n\nThe model's output is also supported by attention maps generated by the subject-specific autism attention module. These maps highlight regions of interest (ROIs) related to ASD, such as the amygdala, hippocampus, and cerebellum, which are consistent with findings from previous studies. This visual representation enhances the interpretability of the model's predictions and provides insights into the neural mechanisms underlying ASD.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for our model is not publicly released. The model was implemented using the PyTorch framework on a single NVIDIA GTX TITAN (12GB) GPU. The software used for preprocessing, iBEAT V2.0 Cloud, is publicly available and can be accessed at http://www.ibeat.cloud. However, the specific implementation details and the trained model are not provided for public use.",
  "evaluation/method": "The method was evaluated using a comprehensive approach that included cross-validation, comparison with state-of-the-art methods, and the integration of additional factors such as sex information.\n\nWe employed 10-fold cross-validation to assess the performance of our method on dataset A. This involved dividing the dataset into 10 subsets, training the model on 9 subsets, and testing it on the remaining subset. This process was repeated 10 times, with each subset serving as the test set once.\n\nTo further evaluate the robustness of our method, we applied the model trained on dataset A to dataset B. This allowed us to assess the generalization ability of our approach across different datasets acquired by different scanners and imaging protocols.\n\nWe also compared our method with two state-of-the-art methods: the EA-CSF method and the EA-CSF-BAS method. The EA-CSF method uses the ratio of extra-axial fluid to total cerebral volume to predict ASD, while the EA-CSF-BAS method employs a RUSBoost classifier with specific parameters. Our method outperformed both of these methods in terms of sensitivity, specificity, and accuracy.\n\nAdditionally, we explored the impact of integrating sex information into our predictive model. We found that including sex information improved the predictive performance, with increases in sensitivity, specificity, and accuracy. This was further validated through receiver operating characteristic (ROC) curve and area under the ROC curve (AUC) analyses, which showed improved discrimination capacity when sex information was included.\n\nThe evaluation also involved generating attention maps to identify regions of interest (ROIs) related to ASD. The amygdala, hippocampus, and cerebellum were highlighted, consistent with findings from previous studies. This further supports the reliability and reasonability of our predictive method.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to assess the effectiveness of our method. These metrics include sensitivity (SEN), specificity (SPE), and accuracy (ACC). Sensitivity measures the proportion of true positive predictions among all actual positives, specificity measures the proportion of true negative predictions among all actual negatives, and accuracy measures the overall proportion of correct predictions.\n\nWe compared our method with two state-of-the-art methods: the EA-CSF method and the EA-CSF-BAS method. For the EA-CSF method, we calculated the ratio of extra-axial fluid to total cerebral volume to predict ASD, achieving a sensitivity of 73.1% and a specificity of 75.9% for dataset A. The EA-CSF-BAS method, which uses a RUSBoost classifier, showed slightly higher performance with a sensitivity of 78.8% and a specificity of 81.5% for the same dataset.\n\nOur proposed method outperformed both of these methods, achieving a sensitivity of 86.5%, a specificity of 92.8%, and an accuracy of 91.5% for dataset A. This represents more than a 10% improvement in specificity and accuracy compared to the EA-CSF method. Similar improvements were observed for dataset B, although the overall performance was poorer across all methods for this dataset.\n\nAdditionally, we evaluated the impact of incorporating sex information into our model. For dataset A, integrating sex information improved the sensitivity by 1.9%, the specificity by 2.5%, and the accuracy by 2.4%. For dataset B, the improvements were more pronounced, with increases of 9.1% in sensitivity, 12.3% in specificity, and 2.9% in accuracy.\n\nWe also performed receiver operating characteristic (ROC) curve and area under the ROC curve (AUC) analyses. For dataset A, the model trained with sex information achieved an AUC of 91%, compared to 87% for the model trained without sex information. For dataset B, the AUC improved from 85% to 86% with the inclusion of sex information.\n\nThese metrics are representative of those commonly reported in the literature for similar studies, ensuring that our evaluation is comprehensive and comparable to other works in the field.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our proposed method with two state-of-the-art methods: the EA-CSF method and the EA-CSF-BAS method. These methods were chosen for their relevance and previous success in the field. The EA-CSF method relies on predefined biomarkers, specifically the ratio of extra-axial cerebrospinal fluid volume to whole brain volume, to distinguish between ASD and NC groups. On the other hand, the EA-CSF-BAS method employs a RUSBoost classifier with specific parameters to enhance performance.\n\nWe implemented these methods on two benchmark datasets, A and B, which were acquired using different scanners and imaging protocols. This approach allowed us to assess the robustness and generalization ability of our method across diverse datasets. For dataset A, our proposed method achieved significant improvements in sensitivity, specificity, and accuracy compared to both the EA-CSF and EA-CSF-BAS methods. Specifically, our method showed more than a 10% improvement in specificity and accuracy for dataset A. Similar trends were observed for dataset B, although the overall performance was poorer across all methods due to the differences in imaging parameters.\n\nAdditionally, we performed a comparison with simpler baselines to ensure that our method's superior performance was not merely due to the complexity of the model. We evaluated the impact of integrating sex information into our predictive model, as autism is known to be more prevalent in boys than girls. The results indicated that including sex information improved the predictive performance, with increases in sensitivity, specificity, and accuracy. This finding underscores the importance of considering sex as a factor in autism prediction models.\n\nIn summary, our comparison with publicly available methods and simpler baselines demonstrated the superior robustness and accuracy of our proposed method. The integration of sex information further enhanced its performance, highlighting the method's potential for practical application in clinical settings.",
  "evaluation/confidence": "The evaluation of our method includes statistical significance testing, which is crucial for claiming superiority over other methods and baselines. The performance metrics presented in the tables include p-values, which indicate the statistical significance of the improvements observed. For instance, when comparing our proposed method with the EA-CSF and EA-CSF-BAS methods, the p-values in parentheses show the significance levels of the differences in sensitivity, specificity, and accuracy. Lower p-values indicate stronger evidence against the null hypothesis, suggesting that the observed differences are statistically significant.\n\nFor dataset A, the p-values for sensitivity, specificity, and accuracy when comparing our method to the EA-CSF method are 0.0017, 0.0012, and 0.0023, respectively. Similarly, when comparing to the EA-CSF-BAS method, the p-values are 0.013, 0.0059, and 0.03, respectively. These values are well below the conventional threshold of 0.05, indicating that the improvements are statistically significant.\n\nFor dataset B, the p-values for sensitivity, specificity, and accuracy when comparing our method to the EA-CSF method are 0.0042, 0.0001, and 0.0014, respectively. When comparing to the EA-CSF-BAS method, the p-values are 0.37, 0.0001, and 0.0027, respectively. Again, most of these values are below 0.05, confirming the statistical significance of the observed improvements.\n\nAdditionally, the integration of sex information into our model showed significant improvements in performance metrics. For dataset A, the increases in sensitivity, specificity, and accuracy were statistically significant with p-values indicating strong evidence of improvement. Similarly, for dataset B, the improvements were also statistically significant, further supporting the robustness of our method.\n\nIn summary, the performance metrics are accompanied by p-values that demonstrate the statistical significance of the results, providing confidence in the claim that our method outperforms other state-of-the-art methods and baselines.",
  "evaluation/availability": "The raw evaluation files used in this study are available through the National Database for Autism Research (NDAR). Specifically, the datasets utilized include dataset A, consisting of 247 subjects from the Infant Brain Imaging Study (IBIS) network, and dataset B, consisting of 35 subjects from the Autism Centers of Excellence (ACE). These datasets are accessible via the NDAR platform, which provides a collaborative informatics network created by the National Institutes of Health (NIH) to support and accelerate research in autism.\n\nThe datasets are publicly available and can be accessed by researchers for further study and validation. The NDAR platform ensures that the data is shared in a manner that complies with ethical and legal standards, allowing for broad access while protecting participant privacy. The specific imaging parameters and protocols used for these datasets are detailed in the study, enabling other researchers to replicate and build upon the findings presented."
}