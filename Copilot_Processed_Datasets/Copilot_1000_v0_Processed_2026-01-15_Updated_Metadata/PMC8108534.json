{
  "publication/title": "Performance of deep learning restoration methods for the extraction of particle dynamics in noisy microscopy image sequences.",
  "publication/authors": "Kefer P, Iqbal F, Locatelli M, Lawrimore J, Zhang M, Bloom K, Bonin K, Vidi PA, Liu J",
  "publication/journal": "Molecular biology of the cell",
  "publication/year": "2021",
  "publication/pmid": "33502895",
  "publication/pmcid": "PMC8108534",
  "publication/doi": "10.1091/mbc.e20-11-0689",
  "publication/tags": "- Deep Learning\n- Image Restoration\n- Microscopy\n- Particle Dynamics\n- Noise Reduction\n- Computational Biology\n- Image Processing\n- Data Analysis\n- Biological Imaging\n- Algorithms\n\nNot sure if the above tags were provided in the published article.",
  "dataset/provenance": "The dataset used in this study consists of experimental data and simulations. The experimental data were acquired using specific cameras: the Hamamatsu Flash 4 sCMOS camera was used for figures 2 and 3, while the Andor Clara CCD camera was used in a wide-field microscope for figure 6. These details are provided in the Material and Methods section.\n\nThe number of data points is not explicitly stated, but the dataset includes movies and code used for particle tracking. The data and quantification scripts have been made publicly available on OSF for public access. This allows others to reproduce the results and use the dataset as a benchmark for developing and testing new denoising packages.\n\nThe dataset has not been used in previous papers by the community, as it is newly deposited on OSF. However, the authors have shared the movies and code used in this manuscript, encouraging others to use the dataset and approach as benchmarks for future work. The experimental data and simulations used in this manuscript are now accessible to the public, facilitating further research and comparisons with improved methods.",
  "dataset/splits": "For the CARE and N2V networks, a single 90%\u201310% train-validation split was used. This means that 90% of the data was used for training the networks, while the remaining 10% was used for validation purposes. The training data for CARE consisted of 100 pairs of fixed-cell images, captured at different exposure times. For N2V, stacks of fixed images with a 10 ms exposure were used for training. The patch size for training was optimized separately for each network, with CARE using 128 \u00d7 128 pixels and N2V using 64 \u00d7 64 pixels. This split allowed for the evaluation of the networks' performance using high-quality fixed-cell images as the ground truth.",
  "dataset/redundancy": "The datasets used in this study were split using a 90%\u201310% train-validation split for both CARE and N2V. This split ensures that the training and test sets are independent, which is crucial for evaluating the performance of the models.\n\nTo enforce independence, different subsets of the data were used for training and validation. For instance, the CARE network was trained using 100 pairs of fixed-cell images captured at different exposure times. Similarly, N2V was trained using stacks of fixed images with a specific exposure time. This approach helps in avoiding data leakage and ensures that the models generalize well to unseen data.\n\nThe distribution of the datasets used in this study is comparable to previously published machine learning datasets in the field of image denoising. High-quality fixed-cell images with known ground truth were available, which allowed for the optimization of network parameters and the selection of the most accurate models. This is a common practice in the field and ensures that the results are reliable and reproducible.\n\nAdditionally, the datasets included a variety of biological samples, such as yeast genomic loci and spindle pole bodies, which were processed using 3D N2V to generate denoised time lapses. This diversity in the datasets helps in assessing the robustness of the models and their applicability to different biological contexts.\n\nIn summary, the datasets were carefully split and curated to ensure independence between training and test sets, and their distribution is in line with established practices in the field. This approach enhances the reliability and generalizability of the results presented in this study.",
  "dataset/availability": "The data used in this work has been made publicly available to ensure reproducibility and to facilitate comparisons with future methods. All the movies and the code used for particle tracking in this manuscript have been shared. The experimental data and simulations used in this manuscript have been deposited on the Open Science Framework (OSF) for public access. Additionally, code for synthetic data generation, single particle tracking algorithms, localization analysis, and CNN parameter optimization has been deposited on GitHub. This information is indicated in a new section at the end of the Materials and Methods (M&M) to ensure transparency and accessibility. The data is shared under a permissive license to encourage its use as a benchmark for developing and testing new denoising packages.",
  "optimization/algorithm": "The machine-learning algorithm class used is Bayesian optimization. This approach is not new and has been previously described in the literature. It is a well-established method for hyperparameter optimization in machine learning. The reason it was not published in a machine-learning journal is that the focus of our work is on the application of this optimization technique to improve image restoration for particle tracking in biological imaging. The primary contribution of our study is in the biological and imaging sciences, demonstrating how Bayesian optimization can be effectively applied to enhance the performance of convolutional neural networks (CNNs) for denoising microscopy images. The technical details of the Bayesian optimization process were included in the methods section to provide transparency and reproducibility, but the main emphasis of the paper is on the biological implications and improvements in tracking accuracy achieved through this optimization.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The methods used in the study include CARE and N2V, which are content-aware deep learning approaches for denoising microscopy image sequences. These methods do not rely on other machine-learning algorithms for their input data. Instead, they use pairs of noisy and ground truth images for training. The training data for these models is independent and consists of image pairs obtained through specific experimental conditions. For instance, synthetic bead data and images from fixed cells were used to train the CARE algorithm, while N2V networks were trained on images with high noise levels. The independence of the training data is ensured by the experimental design, which involves acquiring images under controlled conditions to generate the necessary pairs for training.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps tailored to the specific tasks and datasets. For synthetic bead data, pairs of noisy and ground truth (GT) images were used, with a patch size of 128 \u00d7 128 pixels for training the CARE algorithm. For chromatin microdomain images, dedicated CARE networks were trained for each exposure time condition using pairs of cropped images from fixed cells. These training pairs were obtained by alternately imaging at the target exposure time and a higher exposure time to achieve a high signal-to-noise ratio (SNR). The parameters for patch size and samples per image were optimized using Bayesian optimization.\n\nFor N2V networks, images with high noise levels were used, with a patch size of 64 \u00d7 64 pixels, 100 epochs, and 100 steps per epoch. The spatial autocorrelation of the noise was assessed using the MATLAB autocorr2d function and single images away from any cells. For single-nucleosome images, a CARE network was trained using 100 pairs of fixed-cell images captured at different exposure times. The patch size was optimized before training the networks. For yeast genomic loci and spindle pole bodies, images were processed using 3D N2V with specific patch sizes for X, Y, and Z dimensions.\n\nA 90%\u201310% train-validation split was used for both CARE and N2V. The data was preprocessed to ensure high-quality fixed-cell images as the ground truth, allowing for the selection of the most accurate network. The heterogeneous background was subtracted using the rolling-ball method in FIJI for the images shown as illustrations. Tracking results were obtained from both original and denoised images, and the motion of the foci was analyzed relative to each other. The radius of confinement was calculated using a custom MATLAB program. Statistical analyses were performed using GraphPad Prism 8, with normality tests and appropriate statistical tests indicated in the figure legends.",
  "optimization/parameters": "In our study, we focused on optimizing two key parameters for our image restoration models: the patch size and the number of training samples per image. These parameters were chosen because they significantly impact the performance of the convolutional neural networks (CNNs) used for denoising microscopy images.\n\nThe patch size refers to the dimensions of the image segments used during training. We initially explored a range of patch sizes to understand their effect on tracking accuracy. The number of training samples per image indicates how many patches are extracted from each image for training the network. Both parameters were selected using a systematic approach called Bayesian optimization. This method is particularly useful when evaluating the target function is computationally expensive, as is the case with training image restoration networks.\n\nBayesian optimization works by modeling the parameter space using Gaussian processes and then using an acquisition function to determine the next set of parameters to evaluate. This approach allows for efficient exploration of the parameter space, finding near-optimal values without exhaustive searching. In our application, the parameter space was two-dimensional, with one dimension representing the patch size and the other representing the number of samples per image.\n\nWe used three different objective functions to assess the performance of the networks: cumulative tracked motion in fixed cells, cumulative tracking error in live cells, and the relative number of spots tracked. The optimizer aimed to minimize the cumulative tracking error, which was calculated as the sum of the differences between the motion vectors tracked in the ground truth and denoised images, divided by the number of frame deltas and spots.\n\nThrough this optimization process, we identified sets of optimal parameter values that resulted in models with significantly lower cumulative tracking errors compared to the default parameter set. This approach not only improved the restoration outcomes but also made the process more accessible and implementable for biological users.",
  "optimization/features": "The input features for the optimization process primarily consist of image patches from microscopy data. For the CARE algorithm, patches of size 128 \u00d7 128 pixels were used for synthetic bead data, while patches of size 28 \u00d7 28 pixels were used for chromatin microdomain images. For the N2V algorithm, patches of size 64 \u00d7 64 pixels were used for high noise levels, and patches of size 32 \u00d7 32 \u00d7 4 pixels were used for 3D processing of yeast genomic loci and spindle pole bodies.\n\nFeature selection in the traditional sense was not performed, as the features are directly derived from the image data itself. However, the optimization process involved selecting the optimal patch size and number of training samples. This selection was done using a Bayesian optimization approach, which initially samples the hypothesis space randomly and then fits Gaussian processes to the observations. The acquisition function determines the next point in the parameter space that would improve the model the most. This active learning approach ensures that near-optimal parameter values are found without exhaustively searching the entire parameter space.\n\nThe training set was used exclusively for this optimization process. A 90%\u201310% train-validation split was employed for both CARE and N2V, ensuring that the validation set was kept separate to assess the performance of the models objectively. This split helps in preventing overfitting and ensures that the selected parameters generalize well to unseen data.",
  "optimization/fitting": "The fitting method employed in our study utilized Bayesian optimization to systematically explore and identify optimal parameters for our convolutional neural networks (CNNs). This approach is particularly useful when the evaluation of the target function is computationally expensive, as is the case when training image restoration networks and tracking their predictions.\n\nTo address the potential issue of overfitting, we implemented a 90%\u201310% train-validation split for both CARE and N2V networks. This split ensures that the model's performance is evaluated on a separate validation set, which helps in detecting overfitting. Additionally, we used a relatively small number of training image pairs (10\u2013100) and found that models trained with more data had a lower cumulative tracking error, indicating that the model generalizes well to unseen data.\n\nUnderfitting was addressed by carefully selecting the hyperparameters and ensuring that the model had sufficient capacity to learn the underlying patterns in the data. The Bayesian optimization process helped in finding near-optimal parameter values without exhaustively searching the parameter space, thus avoiding underfitting. The use of Gaussian processes to model the parameter space and an acquisition function to determine the next point in the parameter space that would improve the model further ensured that the model was not too simplistic.\n\nIn summary, the Bayesian optimization approach, combined with a proper train-validation split and careful selection of hyperparameters, helped in mitigating both overfitting and underfitting issues. The results showed that significant improvement in image quality and tracking precision could be achieved with a small dataset, suggesting that the model was neither overfitted nor underfitted.",
  "optimization/regularization": "In our study, we employed Bayesian optimization to fine-tune the parameters of our convolutional neural network (CNN) for image restoration. This method inherently helps in preventing overfitting by efficiently exploring the parameter space. Bayesian optimization initially samples the hypothesis space randomly and then fits Gaussian processes to the observations. An acquisition function determines the next point in the parameter space that would most improve the model. This active learning approach allows us to find near-optimal parameter values without exhaustively searching the entire parameter space, thus reducing the risk of overfitting.\n\nAdditionally, we investigated the effect of training set size on the restoration outcome. We trained our networks with identical hyperparameters on differently sized training sets and quantified the change in tracking error. Our findings indicated that models trained with more data had a lower cumulative tracking error, but a performance plateau was achieved with a surprisingly small number of training image pairs (10\u2013100). This suggests that significant improvements in image quality and tracking precision can be achieved with a relatively small dataset, further mitigating the risk of overfitting.\n\nWe also ensured that our models generalized well by evaluating their performance on objective assessments, such as particle tracking outcomes. This approach helped us validate that our denoising methods maintained higher signal-to-noise ratio (SNR) over the time course, which is crucial for long-term observations. By focusing on accessible parameters like training dataset size and patch size, we aimed to make our methods implementable by biological users, ensuring robustness and generalizability.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available and have been detailed in the manuscript. Specifically, the Bayesian optimization process employed to identify optimal parameters for our convolutional neural networks (CNNs) is described in the methods section. This process involved modeling the network's parameter space using Gaussian processes and using an acquisition function to determine the next point in the parameter space that would improve the model the most. The reward function of the optimizer was designed to find the set of parameters that minimize cumulative tracking error.\n\nThe optimization schedule and model files are not explicitly mentioned as being available for download. However, the parameters for patch size and samples per image, which were chosen using Bayesian optimization, are provided. For instance, for chromatin microdomain images, the patch size was set to 28 \u00d7 28 pixels, and the number of samples per image was 64. These details are included to ensure reproducibility and to allow other researchers to implement similar optimization strategies.\n\nRegarding the availability and licensing of these configurations and parameters, the manuscript does not specify a particular license. However, the detailed descriptions provided in the methods section should enable other researchers to replicate the optimization process and use the reported parameters in their own work. For access to any specific model files or additional data, interested parties may need to contact the authors directly, as this information is not explicitly stated as publicly available.",
  "model/interpretability": "The model employed in our study is not entirely a black box, although it does leverage deep learning techniques that can sometimes be perceived as such. To enhance interpretability, we have taken several steps to ensure transparency.\n\nFirstly, we have provided detailed information about the cameras and sensors used to acquire the image data. For instance, figures 2 and 3 utilized the Hamamatsu Flash 4 sCMOS camera, while figure 6 employed an Andor Clara CCD camera in a wide-field microscope. This information is crucial for understanding the nature of the data and the potential sources of noise.\n\nSecondly, we have addressed the issue of repetitive elements in the images. Initially, the term \"repetitive elements\" was used, but to clarify this for readers, we replaced it with \"periodic patterns.\" This change was made to ensure that the presence of these patterns in the images is clearly understood.\n\nAdditionally, we have discussed the independence assumption required for the N2V model. For our specific dataset, we used a rolling-ball background subtraction step to remove spatially-dependent background noise. This approach was deemed acceptable because it preserved the random noise components. We have also presented results obtained without background subtraction to demonstrate that our conclusions remain valid.\n\nFurthermore, we have made our data and code publicly available. This includes the movies and the code used for particle tracking, as well as synthetic data generation, single particle tracking algorithms, localization analysis, and CNN parameter optimization. By making these resources available, we aim to facilitate reproducibility and further research.\n\nIn summary, while our model involves complex deep learning techniques, we have taken steps to enhance its interpretability. We have provided detailed information about the data acquisition process, clarified technical terms, and made our data and code publicly available. These efforts should help readers better understand the model and its applications.",
  "model/output": "The model discussed in this publication is primarily focused on image denoising and restoration, rather than traditional classification or regression tasks. It employs unsupervised learning approaches, specifically the Noise2Void (N2V) and Content-Aware Image Restoration (CARE) methods, to enhance the quality of images, particularly in the context of biological imaging.\n\nThe N2V method is an unsupervised learning approach that does not require paired ground truth data for training. This makes it particularly useful in scenarios where obtaining such data is challenging or impossible. The model learns to denoise images by predicting the noise in the image and subtracting it, thereby improving the signal-to-noise ratio.\n\nOn the other hand, CARE is a supervised learning method that uses paired ground truth data to learn the mapping from noisy to clean images. While CARE can produce high-quality results when paired data is available, its applicability is limited in situations where such data is not obtainable.\n\nIn the context of this study, the model's output is denoised images that can be used for further analysis, such as tracking particle dynamics or measuring mean squared displacement (MSD). The effectiveness of the denoising process is evaluated qualitatively through visual inspection of the images and quantitatively through metrics that assess the improvement in image quality.\n\nThe model's performance is also discussed in terms of training time and computational resources. It is noted that longer training times could potentially improve the results, but this was not feasible given the current computational constraints. Future work may involve exploring this possibility with access to supercomputing resources.\n\nIn summary, the model's output is denoised images that are suitable for various downstream analyses in biological imaging. The choice between N2V and CARE depends on the availability of paired ground truth data, with N2V being the preferred method when such data is not obtainable.",
  "model/duration": "The execution time for our models varied depending on the specific task and the computational resources available. For instance, training the CARE network using pairs of fixed-cell images captured at different exposure times took a considerable amount of time, but it was optimized using Bayesian methods to find near-optimal parameters efficiently. Similarly, N2V networks were trained on high-noise images with specific patch sizes and epochs, which also required significant computational resources.\n\nWe initially faced limitations with our current computational resources, which made it challenging to achieve longer training times. However, we plan to test the impact of extended training times as we gain access to supercomputing facilities. This is particularly relevant for N2V, where the loss function may not fully indicate convergence, and longer training could yield better results.\n\nFor synthetic bead data, the CARE algorithm was trained using 100 pairs of noisy and ground truth images with a patch size of 128 \u00d7 128 pixels. N2V networks were trained on images with high noise levels using a patch size of 64 \u00d7 64 pixels, 100 epochs, and 100 steps per epoch. These settings were chosen to balance between computational feasibility and model performance.\n\nIn summary, while the execution time for our models was significant, we employed optimization techniques and plan to leverage more powerful computational resources to further improve our results.",
  "model/availability": "The source code used for this study has been made publicly available. We have deposited the code on GitHub, which includes scripts for synthetic data generation, single particle tracking algorithms, localization analysis, and CNN parameter optimization. Additionally, the experimental data and simulations used in this manuscript have been deposited on the Open Science Framework (OSF) for public access. This allows others to reproduce our results and use our dataset and approach as benchmarks for developing and testing new denoising packages. The data sharing information is indicated in a new section at the end of the Materials and Methods. The code and data are released under a permissive license to encourage their use and further development by the scientific community.",
  "evaluation/method": "The evaluation of our method involved several rigorous steps to ensure its effectiveness and reliability. We employed a 90%\u201310% train-validation split for both CARE and N2V, which allowed us to assess the performance of our models on unseen data. For single-nucleosome images, we trained a CARE network using 100 pairs of fixed-cell images captured at different exposure times (1 second and 10 milliseconds). This approach enabled us to optimize the patch size (128 \u00d7 128 pixels for CARE and 64 \u00d7 64 for N2V) before training the networks. The availability of high-quality fixed-cell images (1-second exposure) as ground truth (GT) helped us determine the most accurate network configuration.\n\nFor yeast genomic loci and spindle pole bodies, we utilized 3D N2V to generate denoised time-lapse sequences. We trained one N2V network for each observation, with specific patch sizes (32, 32, and 4 pixels for X, Y, and Z, respectively). This method ensured that our models could handle the complexities of three-dimensional data.\n\nStatistical analyses were conducted using GraphPad Prism 8. We employed the D\u2019Agostino & Pearson omnibus normality test to assess data normality. Nonparametric tests were used when the data did not pass the normality test (at alpha = 0.05). All statistical tests were two-sided, and P values \u22640.05 were considered significant. This thorough statistical approach ensured the robustness of our findings.\n\nIn addition to these quantitative evaluations, we also performed qualitative assessments. For instance, we compared the results of N2V and CARE side by side with the ground truth plots to ensure clarity and rigor in our representations. We also addressed concerns about the independence assumption required for N2V by reanalyzing data without rolling-ball background subtraction, confirming that our conclusions remained consistent.\n\nFurthermore, we discussed the possibility of improving N2V performances with longer training times, acknowledging the limitations of our current computational resources. We plan to explore this further as we gain access to supercomputing facilities.\n\nOverall, our evaluation method combined both quantitative and qualitative assessments to provide a comprehensive understanding of our method's performance and reliability.",
  "evaluation/measure": "In our study, we employed several performance metrics to rigorously evaluate the efficacy of our denoising methods. One of the key metrics we reported is the radius of confinement (Rc), which quantifies the area explored by a given genetic locus and is crucial for assessing chromosome dynamics. We highlighted the importance of accurate Rc measurements, noting that variations in Rc can be subtle yet significant, often differing by approximately 3-fold across an entire chromosome. This metric provides a gauge of the requirement for precision in our methods.\n\nAdditionally, we utilized mean squared displacement (MSD) graphs to compare the performance of different denoising techniques. These graphs offer a visual representation of particle dynamics over time, allowing us to assess how well our methods preserve the underlying biological signals amidst noise. We ensured that our MSD analyses were comprehensive by including multiple time-points and traces, providing a robust evaluation of our denoising algorithms.\n\nWe also discussed the use of Bayesian optimization for hyperparameter tuning, which is a novel approach in the field. This method allows for the systematic exploration of parameter space to achieve optimal denoising performance. While the importance of Bayesian optimization in our manuscript was a subject of review, we believe it adds a layer of rigor to our evaluations.\n\nFurthermore, we addressed the tracking error scale in our figures, ensuring that values on the color scale were clearly defined. This transparency is essential for readers to interpret our results accurately. We also provided detailed information on the cameras and sensors used in our experiments, which is crucial for reproducibility and understanding the context of our performance metrics.\n\nIn summary, our set of performance metrics is representative of the current literature and includes both established measures like Rc and MSD, as well as innovative approaches like Bayesian optimization. These metrics collectively provide a comprehensive evaluation of our denoising methods, ensuring that our findings are both reliable and comparable to other studies in the field.",
  "evaluation/comparison": "A comparison to publicly available methods was indeed performed. Specifically, the performance of content-aware deep learning methods for denoising microscopy image sequences was evaluated using particle tracking outcomes as an objective assessment. These methods were compared to conventional denoising approaches, highlighting that CNN-based image restoration makes few or no assumptions about noise. This comparison showed that no pre-acquisition of camera-based noise features or calibrations is needed, which simplifies the implementation of these methods.\n\nThe evaluation included the use of different objective functions for assessment, such as cumulative tracked motion in fixed cells, cumulative tracking error in live cells, and the relative number of spots tracked. The results indicated that the parameters found through optimization resulted in a model producing restorations with a 12.8% lower cumulative tracking error compared to the default parameter set of the CARE implementation used.\n\nAdditionally, the effect of training set size on the restoration outcome was investigated. Models trained with more training data had a lower cumulative tracking error, and a performance plateau was achieved with a surprisingly small number of training image pairs (10\u2013100). This suggests that significant improvements in image quality and tracking precision can be achieved with a small dataset.\n\nRegarding simpler baselines, the comparison focused on the effectiveness of deep learning methods in denoising microscopy images. The use of Bayesian optimization for hyperparameter finding was also discussed, noting that it is either given too much importance or too little in the manuscript's current flow. Technical details were added to the methods section, and discussions were included in the text to address this aspect.\n\nIn summary, the evaluation involved a thorough comparison with publicly available methods and demonstrated the advantages of deep learning approaches in denoising microscopy images. The results highlight the potential for significant improvements in image quality and tracking precision with relatively small training datasets.",
  "evaluation/confidence": "The evaluation of our methods includes statistical analyses to ensure the robustness and significance of our results. We used the D\u2019Agostino & Pearson omnibus normality test to assess the distribution of our data. For data that did not pass this normality test, we employed nonparametric tests. All statistical tests were two-sided, and we considered p-values \u22640.05 as significant. This approach ensures that our claims of superiority over other methods and baselines are statistically sound.\n\nFor specific metrics, such as the mean radius of confinement (Rc), we calculated p-values using the Kruskal-Wallis test with Dunn\u2019s multiple comparison test. These p-values are provided in supplementary tables, indicating the statistical significance of the differences observed between noised, denoised, and ground truth images. For instance, in Table S1, the p-values for comparisons between noised and denoised images, as well as between denoised and ground truth images, are clearly indicated, demonstrating the statistical significance of our denoising methods.\n\nAdditionally, we performed rigorous comparisons between different denoising techniques, such as CARE and N2V. We ensured that the results were not only visually compelling but also statistically significant. For example, we discussed the fold change in Rc between untreated and treated cells, showing that our conclusions remained consistent even when different preprocessing steps were applied.\n\nIn summary, our evaluation includes confidence intervals and statistical significance tests to support our claims. We have provided detailed statistical analyses and p-values to demonstrate the robustness and superiority of our methods over baselines and other techniques.",
  "evaluation/availability": "The raw evaluation files, including all the movies and the code used for particle tracking in this manuscript, are publicly available. We have deposited the experimental data and simulations used in this manuscript on the Open Science Framework (OSF) for public access. Additionally, we have made the code for synthetic data generation, single particle tracking algorithms, localization analysis, and CNN parameter optimization available on GitHub. This data sharing information is indicated in a new section at the end of the Materials and Methods (M&M). The data is released under a permissive license to encourage its use as a benchmark for developing and testing new denoising packages."
}