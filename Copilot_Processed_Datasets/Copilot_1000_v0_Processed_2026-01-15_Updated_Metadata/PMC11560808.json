{
  "publication/title": "Development and validation of a machine learning-based model to predict postoperative overall survival in patients with soft tissue sarcoma: a retrospective cohort study.",
  "publication/authors": "Liu X, Yuan J, Wang X, Yu S",
  "publication/journal": "American journal of cancer research",
  "publication/year": "2024",
  "publication/pmid": "39553229",
  "publication/pmcid": "PMC11560808",
  "publication/doi": "10.62347/zqvy3877",
  "publication/tags": "- Soft tissue sarcoma\n- Machine learning\n- Prognostic model\n- Surgery\n- Web calculator\n- Predictive accuracy\n- Clinical characteristics\n- Overall survival\n- Postoperative outcomes\n- Predictive model validation",
  "dataset/provenance": "The dataset used in this study was sourced from two primary locations: the Surveillance, Epidemiology, and End Results (SEER) database and the National Cancer Center (NCC). The SEER database provided the training cohort, while the NCC, a specialized secondary care center, supplied the validation cohort.\n\nThe training cohort consisted of 3,298 data points, while the validation cohort included 422 data points. These data points represent patients with limb and trunk soft tissue sarcomas (STS) who underwent radical surgery between 2010 and 2020.\n\nThe data used in this study has not been previously utilized in other published papers or by the community. This dataset is unique to this research, focusing on fundamental clinical characteristics to predict postoperative overall survival (OS) in STS patients. The study strictly adhered to ethical standards, including informed consent from patients and compliance with the Declaration of Helsinki. Ethical approval was secured from the Hospital Ethics Committee of the National Cancer Center.",
  "dataset/splits": "The dataset was split into two main cohorts: a training cohort and a validation cohort. The training cohort consisted of 3,298 patients, while the validation cohort included 422 patients. The training cohort had a median age of 62 years, with 55.3% being male and a median follow-up time of 4 years. The validation cohort had a median age of 51 years, with 56.6% being male and a median follow-up time of 4.71 years. The distribution of data points in each cohort reflects the characteristics of patients with limb and trunk soft tissue sarcomas who underwent radical resection. The training cohort was used to develop the models, while the validation cohort was used to assess the models' performance and generalizability.",
  "dataset/redundancy": "The dataset used in this study consisted of 5,901 patients with limb and trunk soft tissue sarcomas who underwent radical resection. To ensure a robust analysis, 2,181 patients who did not meet the inclusion criteria were excluded, resulting in a final cohort of 3,720 patients.\n\nThe dataset was split into a training cohort and a validation cohort. The training cohort comprised 3,298 patients, while the validation cohort included 422 patients. This split was designed to ensure that the training and validation sets were independent, allowing for an unbiased evaluation of the models' performance.\n\nTo enforce the independence of the training and validation sets, the data was divided based on predefined inclusion and exclusion criteria. Patients who died during the perioperative period, were lost to follow-up, or had insufficient clinical data were excluded from the analysis. This rigorous selection process helped to maintain the integrity of the datasets and ensure that the models were trained and validated on distinct patient populations.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the field of oncology. The median age of patients in the training cohort was 62 years, with a median follow-up time of 4 years. In the validation cohort, the median age was 51 years, and the median follow-up time was 4.71 years. Both cohorts had a similar proportion of male patients, with 55.3% in the training cohort and 56.6% in the validation cohort. This demographic distribution is representative of the broader population of soft tissue sarcoma patients, enhancing the generalizability of the findings.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are all well-established ensemble learning methods. These include Gradient Boosting (GB), Survival Tree (ST), Conditional Inference Tree (CIT), Random Survival Forest (RSF), Conditional Random Forest (CRF), and Accelerated Oblique Random Survival Forest (AORSF). These algorithms are not new but are widely recognized and have been extensively used in various fields, including survival analysis.\n\nThe choice of these algorithms was driven by their ability to handle different types of variables, including continuous, nominal categorical, and ordinal categorical variables. This versatility was crucial for our study, which involved a diverse set of clinical features.\n\nThe algorithms were sourced from the \"mlr3proba\" R package, which is a comprehensive tool for probabilistic machine learning in R. This package provides implementations of these algorithms, making them accessible for use in our study.\n\nThe focus of this research was on developing a prognostic model for soft tissue sarcoma, rather than on creating new machine-learning algorithms. Therefore, the algorithms were chosen for their proven effectiveness and relevance to the problem at hand. The study's contributions lie in the application of these algorithms to a specific medical problem and the development of a predictive model that outperforms existing ones.",
  "optimization/meta": "The model developed in this study does not operate as a meta-predictor. Instead, it employs a comprehensive approach using multiple machine learning algorithms to select predictors and develop individual models. Six distinct machine learning learners were utilized: Gradient Boosting (GB), Survival Tree (ST), Conditional Inference Tree (CIT), Random Survival Forest (RSF), Conditional Random Forest (CRF), and Accelerated Oblique Random Survival Forest (AORSF). Each of these learners was applied to a training cohort to select the most relevant clinical features, resulting in six different feature subsets.\n\nThese feature subsets were then used to train 36 separate prediction models, each combining one of the six machine learning learners with one of the six feature subsets. The models were validated using both internal 10-fold cross-validation within the training cohort and external validation within a separate validation cohort. This process ensured that the training data for each model was independent, as the validation cohort was distinct from the training cohort.\n\nThe performance of these models was evaluated using the C-index, which measures the concordance between predicted and actual outcomes. The model with the highest average C-index was selected for further investigation. Additionally, calibration curves, time-dependent ROC curves, and decision curve analysis were employed to assess the model's predictive accuracy, discriminative power, and clinical utility.\n\nIn summary, while the study leverages multiple machine learning methods, it does not use a meta-predictor approach. Each model is developed and validated independently, ensuring the integrity and reliability of the predictions.",
  "optimization/encoding": "In our study, we carefully selected machine learning algorithms capable of handling various types of data, including continuous, unordered categorical, and ordered categorical variables. This selection allowed us to compute models that could effectively manage the diverse nature of our dataset.\n\nWe included over 35% of missing parameters in the analysis by excluding them from the training cohort. The dataset comprised ten variables, which included demographic details such as age and sex, pathological information like tumor site, size, pathological diagnosis, lung metastasis, and other metastasis, stage parameters including AJCC T, AJCC N, AJCC M, and Grade, and adjuvant treatment status encompassing adjuvant radiotherapy and chemotherapy.\n\nThe machine learning learners used in our study were sourced from the \u201cmlr3proba\u201d R package. These learners included Gradient Boosting (GB), Survival Tree (ST), Conditional Inference Tree (CIT), Random Survival Forest (RSF), Conditional Random Forest (CRF), and Accelerated Oblique Random Survival Forest (AORSF). Each of these algorithms was chosen for its ability to handle different types of data and to provide robust predictive performance.\n\nFor predictor selection, we employed Wrapper methods (WM). This approach involved fitting models on selected feature subsets and evaluating their performance using a 10-fold cross-validation resampling strategy. The concordance index (C-index) was calculated for each feature subset to determine the best-performing model. This process was repeated until the C-index for all feature subsets was calculated, and the feature subset with the highest C-index was selected for each learner.\n\nThe data encoding and preprocessing steps ensured that our models could effectively handle the complexity and variability of the dataset, leading to accurate and reliable predictions.",
  "optimization/parameters": "In the optimization process of our model, we initially considered a set of 10 variables for predictor selection. These variables encompassed a range of clinical and demographic details, including age, sex, tumor site, size, pathological diagnosis, lung metastasis, other metastasis, stage parameters (AJCC T, AJCC N, AJCC M, and Grade), and adjuvant treatment status (adjuvant radiotherapy and chemotherapy).\n\nTo determine the optimal subset of predictors, we employed six different machine learning learners, each capable of handling various types of data, including continuous, nominal categorical, and ordinal categorical variables. These learners included Gradient Boosting, Survival Tree, Conditional Inference Tree, Random Survival Forest, Conditional Random Forest, and Accelerated Oblique Random Survival Forest.\n\nThe predictor selection was performed using Wrapper methods, which involve fitting models on selected feature subsets and evaluating their performance. Specifically, we used a sequential forward selection approach, where features were iteratively added to the model. A 10-fold cross-validation resampling strategy was applied to develop pre-models and calculate the concordance index (C-index) for each feature subset. The feature subset with the highest C-index was selected as the optimal set of predictors for each learner.\n\nThis process resulted in six different feature subsets, each tailored to the specific strengths of the machine learning learners used. These subsets were then used to develop and validate 36 prediction models, ensuring a comprehensive evaluation of model performance. The final model, CAM, which combines Conditional Inference Tree and Accelerated Oblique Random Survival Forest, demonstrated the highest average C-index, indicating its superior predictive accuracy.",
  "optimization/features": "In the optimization process of our prognostic model for soft tissue sarcoma, we began with a set of ten variables. These variables encompassed demographic details, pathological information, stage parameters, and adjuvant treatment status. To ensure the robustness and relevance of the features used in our models, we employed feature selection techniques.\n\nFeature selection was performed using six different machine learning learners, each utilizing a wrapper method. This approach involved iteratively adding features to the model and evaluating their performance through a 10-fold cross-validation resampling strategy. The goal was to identify the feature subset that yielded the highest concordance index (C-index) for each learner. This process was conducted solely on the training cohort to prevent data leakage and ensure that the selected features were generalizable to unseen data.\n\nAs a result, six distinct feature subsets were obtained, each tailored to a specific machine learning learner. These subsets included a combination of clinical features that were deemed most predictive of overall survival. The number of features (f) used as input varied depending on the learner, ranging from a single feature to multiple features. This variability allowed us to explore different combinations of features and their impact on model performance.",
  "optimization/fitting": "The fitting method employed in our study involved the use of six machine learning learners, each capable of handling various types of variables, including continuous, nominal categorical, and ordinal categorical data. These learners were Gradient Boosting (GB), Survival Tree (ST), Conditional Inference Tree (CIT), Random Survival Forest (RSF), Conditional Random Forest (CRF), and Accelerated Oblique Random Survival Forest (AORSF).\n\nTo address the potential issue of overfitting, especially given the complexity of the models and the number of parameters involved, we implemented a rigorous cross-validation strategy. Specifically, we used a 10-fold cross-validation resampling strategy. This approach ensured that each model was trained and validated on different subsets of the data, reducing the risk of overfitting. Additionally, we employed Wrapper methods (WM) for predictor selection, which iteratively added features to the model and evaluated their performance using the concordance index (C-index). This method helped in selecting the most relevant features, further mitigating overfitting.\n\nUnderfitting was addressed by carefully selecting a diverse set of machine learning algorithms, each with its own strengths in handling different types of data and relationships. The use of ensemble methods, such as Gradient Boosting and Random Survival Forest, allowed for the combination of multiple weak learners to create a robust model. Furthermore, the Conditional Inference Tree and Accelerated Oblique Random Survival Forest models provided additional layers of complexity and flexibility, ensuring that the models could capture intricate patterns in the data without being too simplistic.\n\nThe final models were developed using the training cohort and validated internally using the 10-fold cross-validation strategy and externally using a separate validation cohort. This dual validation approach ensured that the models were generalizable and not merely memorizing the training data. The performance of the models was assessed using the C-index, time-dependent calibration curves, and the area under the time-dependent receiver operating characteristic (ROC) curves (AUC), providing a comprehensive evaluation of their predictive accuracy and discriminative power.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our models. One of the key methods used was the Conditional Inference Tree (CIT), which constructs decision trees using statistical tests to select splitting variables and points. This approach reduces bias and overfitting by avoiding the selection of variables that may not be truly informative. Additionally, the Conditional Random Forest (CRF) was utilized, which builds multiple decision trees and uses conditional inference tests to select variables and splitting points. This method enhances the robustness and accuracy of the model while mitigating the risk of overfitting.\n\nAnother important technique employed was the Accelerated Oblique Random Survival Forest (AORSF), which combines the ensemble learning techniques of random forests with the approach of oblique decision trees. This integration improves the model's ability to handle complex survival data more accurately and efficiently, thereby reducing the likelihood of overfitting.\n\nFurthermore, we used Wrapper methods (WM) for predictor selection, which involve fitting models on selected feature subsets and evaluating their performance. This iterative process helps in identifying the feature subset that performs best, thereby enhancing the model's predictive accuracy and stability. The use of 10-fold cross-validation resampling strategy during this process ensures that the model generalizes well to unseen data, further preventing overfitting.\n\nOverall, these regularization techniques were crucial in developing a predictive model with enhanced performance and reliability, marking a significant innovation in our research.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The Conditional Inference Tree + Accelerated Oblique Random Survival Forest Model (CAM) is a parametric model, which inherently makes it less interpretable compared to non-parametric models like the Cox proportional hazard model. This lack of interpretability means that CAM is somewhat of a black box, making it challenging to create clear and easily understandable nomograms.\n\nHowever, efforts have been made to enhance the usability and interpretability of the model. Feature importance scores have been utilized to explain the model's predictions. These scores indicate that age, tumor size, and tumor grade are the most important factors over the follow-up period. This information provides some transparency into which variables are driving the model's predictions.\n\nAdditionally, a web-based risk calculator has been developed. This tool allows clinicians to input a patient's clinical characteristics, such as age, tumor size, N stage, lung metastasis, other metastasis, grade, adjuvant chemotherapy, and adjuvant radiotherapy. The calculator then outputs the risk score, CAM stage, and predicted survival probability. This tool aims to make the model more practical for clinical use, even if the underlying mechanics of the model remain somewhat opaque.\n\nIn summary, while CAM is not fully transparent and can be considered a black box to some extent, steps have been taken to make it more interpretable and usable in a clinical setting. The use of feature importance scores and the development of a web-based risk calculator are examples of these efforts.",
  "model/output": "The model developed in our study is a regression model. It is designed to predict the overall survival (OS) of patients with soft tissue sarcoma (STS) after undergoing radical resection. The primary output of the model is a continuous risk score that quantifies the likelihood of survival over time. This risk score is then used to classify patients into different risk categories\u2014high-risk, medium-risk, and low-risk\u2014using a staging system. Additionally, the model provides predicted survival probabilities at various time points, which are crucial for clinical decision-making. The output is also integrated into a web-based application, allowing clinicians to input patient characteristics and obtain immediate risk assessments and survival predictions. This approach ensures that the model's predictions are not only accurate but also practical and accessible for clinical use.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the model is not publicly released. However, a web-based application has been developed to make the predictive models accessible online. This web tool allows users to input a patient's clinical characteristics to obtain a risk score, CAM stage, and predicted survival probability. The web application was created using the R package \"shiny\". This tool is designed to facilitate the practical use of the model in clinical settings, providing an easy-to-use interface for healthcare professionals. The web tool is publicly accessible, enabling clinicians to assess the severity of the disease, facilitate patient follow-up, and aid in the formulation of adjuvant treatment strategies.",
  "evaluation/method": "The evaluation of our prognostic model for soft tissue sarcoma involved a comprehensive approach to ensure its accuracy and reliability. We employed several statistical methods and validation techniques to assess the model's performance.\n\nWe utilized the C-index to evaluate the predictive capability of our survival analysis models. The C-index measures the concordance between predicted and observed outcomes, with higher values indicating better predictive accuracy. This metric is widely used in medical research for its robustness in assessing model performance.\n\nTo further validate our model, we generated calibration curves that evaluated the correspondence between predicted and actual non-incidence rates of all-cause death at 1, 3, and 5 years. Time-dependent calibration curves were used to reflect the degree of calibration over the entire time range, providing a dynamic assessment of the model's predictive accuracy.\n\nThe area under the time-dependent receiver operating characteristic (ROC) curves (AUC) was also calculated to compare the predictive accuracy and discriminative power of the model and its components. The AUC provides a single metric that summarizes the model's ability to distinguish between different outcomes, with higher values indicating better performance.\n\nDecision curve analysis (DCA) was conducted to determine the clinical utility of the model. DCA assesses the clinical benefits for patients at 1, 3, and 5 years, providing insights into the model's practical value in a clinical setting.\n\nRisk scores were calculated in both the training and validation cohorts using the machine learning model. This allowed us to evaluate the model's performance across different datasets, ensuring its generalizability and robustness.\n\nAdditionally, a time-dependent feature importance analysis method was employed to examine how different features influence model performance over time. This involved computing the model\u2019s Brier score loss after permuting feature values, repeated through a 10-fold cross-validation resampling strategy. This approach enabled the identification of which features\u2019 importance for model predictions varies over time, providing crucial insights for time-sensitive clinical decision-making.\n\nOverall, our evaluation methods ensured a thorough and rigorous assessment of the model's predictive accuracy, calibration, and clinical utility, making it a reliable tool for predicting overall survival in soft tissue sarcoma patients.",
  "evaluation/measure": "In our study, we employed several performance metrics to rigorously evaluate the effectiveness of our models. The primary metric used was the C-index, a statistical measure widely utilized in medical research to assess the predictive capability of survival analysis models. The C-index gauges the concordance between predicted and observed outcomes, with higher values indicating superior predictive accuracy. We reported the C-index for both the training and validation cohorts, ensuring a comprehensive assessment of model performance.\n\nIn addition to the C-index, we utilized time-dependent calibration curves to evaluate the correspondence between predicted and actual non-incidence rates of all-cause death at 1, 3, and 5 years. These curves provided insights into the model's calibration over an entire time range, ensuring that our predictions were reliable and consistent over different time intervals.\n\nThe area under the time-dependent receiver operating characteristic (ROC) curves (AUC) was another crucial metric we reported. The AUC served to compare the predictive accuracy and discriminative power of the model and its components. We presented the AUC at 1, 3, 5, and 10 years for both the training and validation cohorts, highlighting the model's predictive accuracy over various time frames.\n\nDecision curve analysis (DCA) was conducted to determine the clinical utility of the model. DCA assessed the clinical benefits for patients at 1, 3, and 5 years, providing a practical measure of the model's net benefit in real-world clinical settings. This analysis demonstrated that our model outperformed traditional strategies, such as 'treat none' and 'treat all,' indicating its practical utility in decision-making.\n\nThe set of metrics we reported is representative of current standards in the literature. The C-index, AUC, calibration curves, and DCA are commonly used in medical research to evaluate the performance of predictive models. By including these metrics, we ensured that our evaluation was thorough and aligned with established practices in the field. This comprehensive approach allowed us to demonstrate the accuracy, stability, and clinical utility of our models, providing valuable insights for clinicians and researchers alike.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of our model, the Conditional Inference Tree + Accelerated Oblique Random Survival Forest Model (CAM), with 42 existing nomograms and prognostic models for soft tissue sarcoma (STS). This comparison was crucial to validate the predictive performance of CAM and to establish its superiority in the field.\n\nWe evaluated CAM against these established models using widely recognized metrics such as the C-index and the Area Under the Curve (AUC) at various time points (1, 3, 5, and 10 years). The results demonstrated that CAM achieved the highest C-index and AUC values, indicating its superior predictive accuracy and stability. Specifically, CAM's C-index was 0.849 in the training cohort and 0.837 in the validation cohort, which were the highest values compared to other models.\n\nAdditionally, we compared CAM with simpler baselines, such as traditional Cox regression and least absolute shrinkage and selection operator (LASSO) models. Unlike these methods, which are often limited to continuous variables and lack the ability to handle categorical variables effectively, CAM incorporates a broader range of techniques. This diversification allowed for the creation of a predictive model with enhanced performance, marking a significant innovation in the field.\n\nFurthermore, we ensured that the clinical characteristics required for CAM, such as age, tumor size, and grade, are easily obtainable. This makes CAM practical for clinical use and conducive to its promotion in various settings. The comparison with simpler baselines and publicly available methods underscores the robustness and reliability of CAM as a next-generation prognostic model for STS.",
  "evaluation/confidence": "The evaluation of our model, specifically the Conditional Inference Tree + Accelerated Oblique Random Survival Forest Model (CAM), includes several performance metrics with associated confidence intervals. The C-index, a measure of predictive accuracy, was reported with 95% confidence intervals for both the training and validation cohorts. For instance, in the training cohort, the C-index was 0.849 with a 95% CI of 0.837-0.859, and in the validation cohort, it was 0.837 with a 95% CI of 0.809-0.871. These intervals provide a range within which the true C-index is likely to fall, indicating the reliability of our model's performance estimates.\n\nThe area under the time-dependent receiver operating characteristic (ROC) curves (AUC) was also evaluated with confidence intervals. In the training cohort, the AUC at 1 year was 0.898 (95% CI 0.876-0.917), at 3 years was 0.884 (95% CI 0.869-0.898), and at 5 years was 0.891 (95% CI 0.877-0.904). Similarly, in the validation cohort, the AUC at 1 year was 0.876 (95% CI 0.805-0.940), at 3 years was 0.863 (95% CI 0.822-0.902), and at 5 years was 0.883 (95% CI 0.842-0.922). These intervals help to assess the precision of our model's predictive accuracy over different time frames.\n\nStatistical significance was determined using various tests. For example, the Kolmogorov-Smirnov test was used to assess the normality of data distribution, and the t-test or Mann-Whitney U test was applied for comparing continuous variables depending on their distribution. Categorical data were compared using the Chi-square test or Fisher\u2019s exact test. Kaplan-Meier survival analysis and the log-rank test were utilized to assess differences in overall survival (OS) across different risk groups. All statistical tests were two-sided, with P-values less than 0.05 indicating statistical significance.\n\nThe decision curve analysis (DCA) demonstrated the clinical utility of our model by showing a consistent net benefit over a range of threshold probabilities. This analysis indicated that our model outperformed the 'treat none' and 'treat all' strategies, suggesting its practical value in clinical decision-making.\n\nOverall, the inclusion of confidence intervals for key performance metrics and the use of rigorous statistical tests provide a robust evaluation of our model's performance. The results are statistically significant, supporting the claim that our method is superior to others and baselines in predicting overall survival in soft tissue sarcoma patients.",
  "evaluation/availability": "Not enough information is available."
}