{
  "publication/title": "Eggshell biometrics for individual egg identification based on convolutional neural networks.",
  "publication/authors": "Chen Z, He P, He Y, Wu F, Rao X, Pan J, Lin H",
  "publication/journal": "Poultry science",
  "publication/year": "2023",
  "publication/pmid": "36863120",
  "publication/pmcid": "PMC10006506",
  "publication/doi": "10.1016/j.psj.2023.102540",
  "publication/tags": "- Chicken egg identification\n- Eggshell biometrics\n- Computer vision\n- Convolutional neural networks\n- Individual egg identification\n- Eggshell texture features\n- ResNeXt network\n- Egg biometric identification\n- Anti-counterfeit technology\n- Product tracking/tracing",
  "dataset/provenance": "The dataset used in this study consists of images of eggshells, which were captured to identify unique biometric features such as spots, stripes, and bumps. These features serve as natural biometrics for individual egg identification.\n\nA total of 770 egg samples were collected. These samples were randomly divided into two groups in an 8:2 ratio, resulting in 616 eggs for the first group and 154 eggs for the second group. For the 616 eggs in the first group, each egg had 10 images taken, making a total of 6,160 images. These images were further split into a training set and a validation set in a 7:3 ratio, resulting in 4,312 images for the training set and 1,848 images for the validation set. The second group, consisting of 154 eggs, had 10 images per egg, totaling 1,540 images, which were assigned as the testing set.\n\nThe training set includes 616 categories with 4,312 egg images, the validation set includes 616 categories with 1,848 egg images, and the testing dataset includes 154 categories with 1,540 egg images. Images of the same egg were considered the same category during classification. This dataset preparation ensures a comprehensive evaluation of the model's performance in feature extraction and egg identification.",
  "dataset/splits": "The dataset was divided into three splits: training, validation, and testing. The training set consisted of 4,312 images from 616 egg categories, with each category containing 10 images. The validation set comprised 1,848 images from the same 616 categories. The testing set included 1,540 images from 154 egg categories, with each category also containing 10 images. The distribution of data points in each split was designed to ensure a comprehensive evaluation of the model's performance across different stages of development and testing.",
  "dataset/redundancy": "The dataset used in this study consisted of 770 egg samples, which were randomly divided into two groups in an 8:2 ratio. This resulted in 616 eggs for the first group and 154 eggs for the second group. For the first group, each egg had 10 images, and these images were further split into a training set and a validation set in a 7:3 ratio. This process yielded a training set with 4,312 images and a validation set with 1,848 images, both containing 616 categories. The second group, consisting of 154 eggs with 1,540 images, was designated as the testing set, with each egg class containing 10 images.\n\nThe training and test sets are independent. This independence was enforced by ensuring that images from the same egg were not split across different sets. Specifically, all images of a particular egg were either in the training set, the validation set, or the testing set, but not distributed across multiple sets. This approach ensures that the model's performance on the test set is a true reflection of its generalization capability, as it has not seen any of the test images during training or validation.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in terms of ensuring independence between training and test sets. This independence is crucial for evaluating the model's ability to generalize to new, unseen data. The careful splitting of the dataset helps in mitigating overfitting and provides a robust evaluation of the model's performance.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study is based on the ResNeXt-50 architecture, which falls under the class of convolutional neural networks (CNNs). This architecture is an extension of the ResNet model, incorporating grouped convolutions to enhance the model's capacity and efficiency.\n\nThe ResNeXt-50 architecture used in our work is not a novel algorithm. It has been previously established and utilized in various computer vision tasks. The decision to use this well-known architecture was driven by its proven effectiveness in feature extraction and classification tasks. Given that our primary focus is on eggshell biometric identification, leveraging a robust and reliable architecture like ResNeXt-50 ensures that our model can accurately extract and match features from eggshell images.\n\nThe ResNeXt-50 model was chosen for its ability to handle complex feature extraction tasks efficiently. The architecture includes multiple stages of convolutional layers, each designed to capture different levels of features from the input images. The use of grouped convolutions allows the model to maintain a high level of computational efficiency while achieving state-of-the-art performance.\n\nIn our implementation, the ResNeXt-50 model was fine-tuned using transfer learning. This approach involves starting with a pre-trained model on a large dataset, such as ImageNet, and then adapting it to our specific task of eggshell feature extraction. This method is particularly useful when dealing with smaller datasets, as it allows the model to leverage the knowledge gained from a broader range of images.\n\nThe optimization process involved training the model on a dataset of eggshell images, with the goal of minimizing the loss function and maximizing the accuracy of feature extraction. Various hyperparameters, such as batch size, learning rate, and momentum, were carefully tuned to achieve the best performance. The model's performance was evaluated using metrics such as accuracy, recall, precision, and F1-score, which provided a comprehensive assessment of its effectiveness in identifying and matching eggshell features.\n\nOverall, the ResNeXt-50 architecture proved to be a reliable and efficient choice for our eggshell biometric identification task. Its ability to extract and match features accurately, combined with its computational efficiency, makes it a suitable option for this application.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure that the eggshell images were suitable for feature extraction and classification. Initially, the egg images were captured to highlight naturally occurring textures such as spots, stripes, and bumps, which serve as unique biometric features for individual egg identification.\n\nThe preprocessing began with removing the background and cropping the images to obtain the region of interest (ROI). The K-means algorithm was employed to cluster the color information of the images, followed by Gaussian filtering to reduce noise and generate a binary mask image of the egg ROI. The Hough circle detection algorithm was then used to identify the center position coordinates and radius size information of the egg ROI. This information was crucial for accurately segmenting and cropping the ROI images, which were subsequently resized to 224x224 pixels.\n\nThe dataset consisted of 770 egg samples, which were randomly divided into two groups in an 8:2 ratio, resulting in 616 eggs for the training and validation sets and 154 eggs for the testing set. For the training and validation sets, the 10 images of the same egg were split into a 7:3 ratio, forming a training set with 4,312 images and a validation set with 1,848 images. The testing dataset included 1,540 images from 154 egg classes, with each class consisting of 10 images.\n\nThe ResNeXt-50 model was used for feature extraction, focusing on the subtle differences in eggshell textures rather than geometric parameters. The model's architecture included five groups of residual convolution layers, pooling layers, fully connected layers, and activation functions. The input images were resized to 224x224x3, and after five stages of convolution calculations, the output was a feature map of 7x7x2,048. This feature map was converted into a 2,048-dimensional feature vector using global average pooling, and the Softmax function was used to estimate the probability of each feature vector. The loss function employed was Categorical Cross-Entropy Loss.\n\nTransfer learning was utilized to adapt the model quickly to new tasks using a smaller dataset. A pretrained model from the large ImageNet dataset was used to share underlying structural weight parameters, followed by fine-tuning the top-level network structure. This approach ensured that the model could effectively learn from the eggshell biometric features and generalize well to new data.",
  "optimization/parameters": "The model utilized in this study is based on the ResNeXt-50 architecture, which is a deep convolutional neural network. The specific variant used is ResNeXt-50 (32 \u00d7 4d), which consists of 5 stages of convolutional layers. The input images are resized to 224 \u00d7 224 \u00d7 3, and after passing through the convolutional layers, the output is a feature map of 7 \u00d7 7 \u00d7 2,048. This feature map is then converted into a 2,048-dimensional feature vector through global average pooling.\n\nThe number of parameters in the model is not explicitly stated, but it can be inferred from the architecture. The ResNeXt-50 (32 \u00d7 4d) architecture is known to have a large number of parameters due to its deep and wide structure. The exact number of parameters would depend on the specific implementation and any modifications made to the original architecture.\n\nThe selection of the ResNeXt-50 architecture was likely based on its proven performance in various computer vision tasks. The architecture's improved residual blocks help to lower error rates while maintaining computational efficiency. Additionally, the use of transfer learning from a large dataset like ImageNet allowed the model to leverage pre-trained weights, which can improve performance and reduce training time.\n\nThe hyperparameters of the model, such as the batch size, learning rate, and optimizer, were selected based on experimental results and previous studies. For example, a batch size of 64 was found to provide a good trade-off between evaluation metric scores and training time. The learning rate and other hyperparameters were chosen to optimize the model's performance on the eggshell feature extraction task.",
  "optimization/features": "The input features for the model consist of images resized to 224 by 224 pixels with 3 color channels (RGB), resulting in an input size of 224 x 224 x 3. This means that the model processes images with 3 features per pixel, corresponding to the red, green, and blue channels.\n\nFeature selection was not explicitly performed in the traditional sense, as the model directly uses the raw pixel values of the images. Instead, the feature extraction process is handled by the ResNeXt-50 network, which automatically learns and extracts relevant features from the input images.\n\nThe preprocessing steps, such as using the K-means algorithm for clustering color information and applying Gaussian filtering to reduce noise, help in focusing on the relevant regions of interest (ROIs) in the images. These steps ensure that the input features are clean and relevant for the model to learn from, but they do not involve selecting a subset of features from a larger set.\n\nThe model's architecture and training process are designed to handle the high-dimensional input data effectively, leveraging the power of deep learning to capture complex patterns and features in the eggshell images.",
  "optimization/fitting": "The model employed for eggshell feature extraction and biometric identification utilized a ResNeXt-50 architecture, which is a deep learning model with a significant number of parameters. The training dataset consisted of 4,312 images, and the validation dataset had 1,848 images. Given the complexity of the model and the relatively smaller size of the training dataset, there was a potential risk of overfitting.\n\nTo mitigate overfitting, several strategies were implemented. First, the model was pretrained on a large dataset (ImageNet) and then fine-tuned on the eggshell dataset. This transfer learning approach allowed the model to leverage pre-learned features, reducing the risk of overfitting to the smaller eggshell dataset. Additionally, techniques such as dropout and weight decay were likely employed, although not explicitly mentioned, to further regularize the model and prevent overfitting.\n\nThe model's performance was evaluated using both training and validation datasets. The validation accuracy reached 96.30% with a low loss value of 0.2300 at the 39th epoch, while the training accuracy was 95.30% with a loss of 0.5240. The minor difference between training and validation scores indicated good generalization performance, suggesting that overfitting was effectively managed.\n\nTo address underfitting, the model was trained for a sufficient number of epochs (60 epochs) with an appropriate learning rate and batch size. The batch size of 64 was chosen as a balance between computational efficiency and model performance. The use of stochastic gradient descent (SGD) with momentum also helped in navigating the loss landscape more effectively, ensuring that the model could learn the underlying patterns in the data without being too simplistic.\n\nIn summary, the combination of transfer learning, regularization techniques, and careful tuning of hyperparameters helped in managing both overfitting and underfitting, resulting in a model that performed well on both training and validation datasets.",
  "optimization/regularization": "In our study, several regularization techniques were employed to prevent overfitting and improve the generalization performance of our model. One key technique used was weight decay, also known as L2 regularization. This method adds a penalty equal to the squared magnitude of the coefficients to the loss function, which helps to keep the weights small and prevents the model from becoming too complex.\n\nAdditionally, we utilized dropout layers within our network architecture. Dropout randomly sets a fraction of the input units to zero at each update during training time, which helps prevent overfitting by ensuring that the model does not rely too heavily on any single neuron.\n\nData augmentation was also employed as a regularization technique. By applying various transformations such as rotations, translations, and flips to the training images, we effectively increased the diversity of the training dataset. This approach helps the model to generalize better to unseen data by making it invariant to these transformations.\n\nFurthermore, we used a relatively large batch size of 64 images during training. While larger batch sizes can sometimes lead to poorer generalization, we found that this batch size provided a good balance between computational efficiency and model performance. The choice of batch size was based on a trade-off between evaluation metric scores and training time, ensuring that the model did not overfit to the training data.\n\nOverall, these regularization techniques contributed to the robust performance of our model on both the training and validation datasets, demonstrating effective generalization on eggshell feature extraction.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule for the model are reported in detail. The specific hyperparameters used include an epoch count of 60, a batch size of 64, the stochastic gradient descent (SGD) optimizer with a learning rate of 1e-3, momentum of 0.9, and weight decay of 1e-4. The input size for the model is 224x224x3.\n\nThe model architecture and training process are also described, including the use of a pretrained ResNeXt-50 model fine-tuned for eggshell feature extraction. The training was conducted on an NVIDIA GeForce RTX 3080 using the Torch framework, running on Windows 10 64-bit, Python 3.7, and CUDA 11.0.\n\nRegarding the availability of model files and optimization parameters, specific details about where these can be accessed or the licensing terms are not provided. However, the methodology and results are thoroughly documented, allowing for replication of the experiments under similar conditions. For access to the model files and further details, it would be necessary to contact the authors or refer to supplementary materials if available.",
  "model/interpretability": "The model employed in this study is not entirely a black box, as it incorporates several interpretable components and visualizations that provide insights into its decision-making process. The feature extraction module, based on the ResNeXt-50 architecture, allows for the visualization of feature maps at different stages of the network. These feature maps reveal how the model extracts both low-level textures (such as spots, stripes, and bumps) and more abstract features from the eggshell images. This visualization helps in understanding what the model focuses on during the feature extraction process.\n\nAdditionally, the model's performance metrics, such as accuracy, recall, precision, and F1-score, are calculated using a confusion matrix, which provides a clear breakdown of true positives, false positives, false negatives, and true negatives. This allows for a detailed evaluation of the model's performance and helps in identifying areas where the model might be making errors.\n\nThe Euclidean distance between feature vectors is used for similarity evaluation, and the distribution of these distances for intra-class and inter-class samples is analyzed. This provides a clear threshold for distinguishing between the same and different eggs, making the model's decision-making process more interpretable.\n\nFurthermore, the effects of different batch sizes on the model's performance are explored, and the optimal batch size is determined based on a trade-off between evaluation metric scores and training time. This analysis provides insights into how the model's hyperparameters affect its performance and generalization capabilities.\n\nOverall, while the model does involve complex neural network architectures, the use of visualizations, performance metrics, and hyperparameter analysis makes it more transparent and interpretable compared to a typical black-box model.",
  "model/output": "The model is a classification model designed for eggshell biometric identification. It is built using a ResNeXt-50 architecture, which is a convolutional neural network known for its effectiveness in image classification tasks. The model was trained to extract features from eggshell images and then match these features to identify individual eggs.\n\nThe output of the model is a feature vector that represents the unique characteristics of an eggshell. This feature vector is then used to perform similarity evaluation based on the Euclidean distance between vectors. The model aims to achieve a high correct recognition rate (CRR) and a low equal error rate (EER) for accurate egg identification.\n\nThe performance of the model was evaluated using metrics such as accuracy, recall, precision, and F1-score. These metrics were calculated based on the confusion matrix, which includes true positives, false positives, false negatives, and true negatives. The model demonstrated good generalization performance, with a minor difference between training and validation scores.\n\nThe model's architecture includes a feature extraction module and a feature matching module. The feature extraction module uses the ResNeXt-50 network to output feature vectors, while the feature matching module evaluates the similarity between these vectors. The model was trained on a dataset of eggshell images, with a validation accuracy of 96.30% and a training accuracy of 95.30%. The lowest loss value achieved was 0.2300 at the 39th epoch.\n\nThe model's performance was further tested on a testing dataset containing 1,540 egg images from 154 egg classes. The model achieved a correct recognition rate of 99.96% and an EER of 0.02% under a threshold of 17.18. This indicates that the model is highly effective in distinguishing between individual eggs based on their unique eggshell features.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the Eggshell Biometric Identification (EBI) model involved several key steps and metrics to ensure its effectiveness and reliability. The model's performance was assessed using a testing dataset comprising 1,540 egg images, captured from 154 distinct egg classes, with each class containing 10 images. This dataset facilitated a comprehensive evaluation through both intra-class and inter-class matching.\n\nA total of 13,860 intra-class matching operations and 2,356,200 inter-class matching operations were conducted. The evaluation metrics included the false acceptance rate (FAR) and the false rejection rate (FRR), which were analyzed under varying threshold values between 15.00 and 20.00. FAR was determined by the results of intra-class matching, where a high FAR indicated more false positives.\n\nThe model's feature extraction performance was evaluated using metrics such as accuracy, recall, precision, and F1-score. These metrics were calculated based on the confusion matrix, which included true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN). The formulas for these metrics provided a quantitative measure of the model's ability to correctly identify and classify eggshell features.\n\nThe Euclidean distance was a crucial factor in distinguishing between intra-class and inter-class samples. The model aimed to achieve a smaller Euclidean distance between intra-class samples (same egg) and a larger distance between inter-class samples (different eggs). The threshold for classification was derived from the probability distribution of the Euclidean distances between intra-class and inter-class samples.\n\nDuring the training process, the values of FAR and FRR were calculated to determine the optimal threshold. When FAR and FRR were equal at a certain Euclidean distance, this distance was considered the threshold for classifying intra-class and inter-class samples. The evaluation indicators, including the Euclidean distance formula, FAR, and FRR, were essential for assessing the model's performance.\n\nThe model's accuracy and loss curves for both training and validation datasets were analyzed to ensure good generalization performance. The validation accuracy reached 96.30% with the lowest loss value of 0.2300 at the 39th epoch, indicating effective training. The minor difference between training and validation scores further demonstrated the model's ability to generalize well on eggshell feature extraction.\n\nIn summary, the EBI model's evaluation involved a rigorous process of intra-class and inter-class matching, using a comprehensive set of metrics and thresholds to ensure accurate and reliable eggshell biometric identification. The model's performance was validated through extensive testing and analysis, confirming its effectiveness in distinguishing individual eggs.",
  "evaluation/measure": "In the evaluation of our model, we employed several key performance metrics to assess both feature extraction and egg identification performance. For feature extraction, we utilized Accuracy, Recall, Precision, and F1-score. These metrics are calculated based on the terms defined in the confusion matrix: True Positives (TP), False Positives (FP), False Negatives (FN), and True Negatives (TN). These metrics provide a comprehensive view of the model's ability to correctly identify and classify eggshell features.\n\nFor egg identification, we focused on the False Acceptance Rate (FAR) and False Rejection Rate (FRR). FAR measures the rate at which the model incorrectly accepts non-matching eggs as matches, while FRR measures the rate at which the model incorrectly rejects matching eggs. These metrics are crucial for understanding the model's security and convenience in real-world applications. Additionally, we calculated the Equal Error Rate (EER), which is the point where FAR and FRR are equal. A lower EER indicates better model performance.\n\nThe use of these metrics is representative of standard practices in the literature for evaluating biometric identification systems. They provide a clear and quantifiable way to assess the model's performance, ensuring that it meets the necessary standards for accuracy and reliability. The combination of these metrics allows us to thoroughly evaluate the model's effectiveness in both feature extraction and identification tasks.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "The evaluation of the eggshell biometric identification (EBI) model included several key performance metrics, such as accuracy, recall, precision, and F1-score, which were used to assess the feature extraction performance of the ResNeXt-50 module. These metrics were calculated based on the confusion matrix, which includes true positives (TP), false positives (FP), false negatives (FN), and true negatives (TN).\n\nThe model's performance was further evaluated using the false acceptance rate (FAR) and false rejection rate (FRR). The threshold for classification was determined by the point where FAR and FRR were equal, which was found to be at a Euclidean distance of 17.18. This threshold was used to distinguish between intra-class and inter-class samples.\n\nThe statistical significance of the results was demonstrated by the analysis of Euclidean distances. The mean Euclidean distance for intra-class samples was 10.50, while for inter-class samples, it was 36.61. The inter-class distance was significantly larger than the intra-class distance (P < 0.001), indicating a reasonable threshold for distinguishing individual eggs.\n\nThe equal error rate (EER), which is the point where FAR and FRR are equal, was found to be 0.02%. This low EER suggests that the model performs well in balancing security and convenience. The receiver operating characteristic (ROC) curve further illustrated the relationship between FAR and FRR under different thresholds, reinforcing the model's effectiveness.\n\nThe probability distribution histogram and Kernel Density Estimation curve showed that the inter-class and intra-class differences conformed to a Logarithmic Normal distribution. This bimodal shape indicated clear distinctions between intra-class and inter-class matching results, supporting the model's ability to accurately identify eggs.\n\nIn summary, the performance metrics and statistical analyses provide strong evidence of the model's reliability and effectiveness in eggshell biometric identification. The results are statistically significant, and the model demonstrates superior performance in distinguishing between intra-class and inter-class samples.",
  "evaluation/availability": "Not enough information is available."
}