{
  "publication/title": "A comprehensive analysis of stroke risk factors and development of a predictive model using machine learning approaches.",
  "publication/authors": "Xie S, Peng S, Zhao L, Yang B, Qu Y, Tang X",
  "publication/journal": "Molecular genetics and genomics : MGG",
  "publication/year": "2025",
  "publication/pmid": "39853452",
  "publication/pmcid": "PMC11762205",
  "publication/doi": "10.1007/s00438-024-02217-3",
  "publication/tags": "- Stroke\n- Machine Learning\n- Predictive Modeling\n- Risk Factors\n- Nomogram\n- Chronic Diseases\n- Feature Selection\n- Cox Proportional Hazards\n- Data Imputation\n- Class Imbalance",
  "dataset/provenance": "The dataset utilized in this study was sourced from the China Health and Retirement Longitudinal Study (CHARLS). This comprehensive study covers statistical data from 2011 to 2020 and was approved by the Institutional Review Board of Peking University. The CHARLS dataset is publicly available and has been used extensively in various research studies, making it a reliable and well-established resource in the scientific community.\n\nThe final dataset comprised 12,978 patients, which was prepared after rigorous preprocessing steps to ensure data quality and minimize bias. These steps included excluding samples with missing stroke information, those with over 5% missing data, and patients diagnosed with cancer. Missing data were handled through multiple imputation techniques, ensuring that the dataset was complete and ready for analysis.\n\nThe CHARLS dataset has been utilized in numerous previous studies, highlighting its significance and reliability in the field of health and retirement research. The dataset includes a wide range of demographic and clinical factors, making it a valuable resource for comprehensive analysis and predictive modeling in stroke research.",
  "dataset/splits": "Not applicable",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "The data utilized in this study is publicly available. The sources and handling of these data are thoroughly described in the Materials and Methods section. The data was obtained from the China Health and Retirement Longitudinal Study (CHARLS), covering statistical data from 2011 to 2020. The study was approved by the Institutional Review Board of Peking University (IRB00001052-11015).\n\nAdditional information can be obtained from the corresponding author upon request. The article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. This license permits any non-commercial use, sharing, distribution, and reproduction in any medium or format, as long as appropriate credit is given to the original authors and the source, a link to the Creative Commons license is provided, and any modifications to the licensed material are indicated. However, permission under this license does not extend to sharing adapted material derived from this article or parts of it. The images or other third-party material in this article are included in the article\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field of predictive modeling, particularly in medical research. The algorithms employed include Elastic Net, Lasso, Gradient Boosting Machine (GBM), Random Forest, XGBoost, Neural Network, Support Vector Machine (SVM), and Logistic Regression. These algorithms were selected for their proven performance in handling diverse data characteristics and their ability to capture both linear and non-linear relationships.\n\nNone of the algorithms used are new; they have been extensively studied and applied in various domains, including medical prediction tasks. The choice of these algorithms was driven by their effectiveness in feature selection, handling multicollinearity, capturing complex patterns in high-dimensional data, and robustness in binary classification tasks. For instance, Elastic Net and Lasso are known for their effectiveness in feature selection and mitigating multicollinearity, while Random Forest, GBM, and XGBoost excel at capturing non-linear relationships and interactions. Neural Network methods were included for their capacity to model complex patterns, and SVM was selected for its robustness in binary classification. Logistic Regression served as a baseline model, offering interpretable results to ensure clinical relevance.\n\nThe decision to use these established algorithms in a genomics journal rather than a machine-learning journal is justified by the specific application and the focus of the study. The primary goal was to identify critical predictors of stroke risk using a comprehensive and robust approach. By integrating diverse machine-learning methods, the study aimed to ensure a thorough exploration of the dataset, minimizing algorithm-specific bias and identifying the most critical predictors with high confidence. This approach is particularly valuable in medical research, where the reliability and interpretability of results are paramount. The algorithms were implemented with fivefold cross-validation to ensure unbiased performance estimation, and their predictive power was evaluated using metrics such as ROC-AUC, sensitivity, and specificity. Feature importance scores were calculated, normalized, and visualized to highlight the top features identified by each method. This comprehensive analysis provided a robust foundation for developing a nomogram prediction model to estimate stroke risk, demonstrating the practical application of these machine-learning techniques in clinical settings.",
  "optimization/meta": "The model employed in this study leverages a meta-predictor approach, integrating multiple machine learning algorithms to enhance predictive accuracy and robustness. This meta-predictor utilizes data derived from various machine learning methods, including Elastic Net, Lasso, Random Forest, Gradient Boosting Machine (GBM), XGBoost, Neural Networks, Support Vector Machine (SVM), and Logistic Regression. Each of these algorithms contributes unique strengths: Elastic Net and Lasso are effective in feature selection and mitigating multicollinearity, while Random Forest, GBM, and XGBoost excel at capturing non-linear relationships and interactions. Neural Networks are included for their capacity to model complex patterns in high-dimensional data, and SVM is selected for its robustness in binary classification tasks. Logistic Regression serves as a baseline model, offering interpretable results to ensure clinical relevance.\n\nTo ensure unbiased performance estimation, fivefold cross-validation was implemented for all algorithms. This approach helps in evaluating the predictive power using metrics such as ROC-AUC, sensitivity, and specificity. Feature importance scores were calculated for each algorithm, normalized, and visualized using bar plots to highlight the top features identified by each method. A scatter plot was also generated to display the average importance score against the number of occurrences for each feature across all methods. This integration of diverse machine learning approaches ensures a thorough exploration of the dataset, capturing both linear and non-linear relationships, minimizing algorithm-specific bias, and identifying the most critical predictors of stroke risk with high confidence.\n\nRegarding the independence of training data, the study emphasizes the use of fivefold cross-validation, which helps in ensuring that the data used for training and validation is independent. This method involves dividing the dataset into five subsets, where the model is trained on four subsets and validated on the remaining one, repeating this process five times with different subsets. This approach helps in mitigating overfitting and ensures that the model's performance is generalizable to unseen data.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the quality and reliability of the machine learning models. Initially, we obtained data from the China Health and Retirement Longitudinal Study (CHARLS) covering the period from 2011 to 2020. To maintain data integrity, we excluded samples with missing stroke information and those with over 5% missing data, as well as patients diagnosed with cancer.\n\nWe visualized the missing data patterns for the top 20 variables using the VIM package in R to identify and address potential issues. Remaining missing values were handled through multiple imputation using the MICE package. Variables were categorized into binary, unordered categorical, ordered categorical, or continuous types, and appropriate imputation methods were applied, such as logistic regression, polytomous regression, proportional odds model, and predictive mean matching. The imputation process involved 5 iterations with 50 imputations each, efficiently executed using 4 CPU cores.\n\nFollowing imputation, the datasets were combined into a final complete dataset, which was validated to ensure no remaining missing values. Continuous variables were screened for outliers using the 3-sigma rule, and any identified outliers were removed. To assess the robustness of the imputation process, sensitivity analyses were conducted by comparing model performance on the original dataset with missing values and the imputed dataset, confirming no significant bias was introduced.\n\nTo address class imbalance, where stroke cases accounted for only 1011 out of 12,978 participants, several strategies were implemented. Resampling techniques, including oversampling the minority class using the Synthetic Minority Over-sampling Technique (SMOTE) and undersampling the majority class, were applied. For algorithms supporting class weights, weights inversely proportional to class frequencies were incorporated to penalize misclassification of the minority class. Robust ensemble methods such as Random Forest and Gradient Boosting were employed, and classification thresholds were optimized to balance sensitivity and specificity.\n\nEvaluation metrics less sensitive to class imbalance, including the area under the receiver operating characteristic curve (AUROC) and the F1-score, were used alongside accuracy. Stratified k-fold cross-validation ensured consistent class proportions across folds. These steps resulted in a clean dataset comprising 12,978 participants, prepared for subsequent analysis and predictive modeling.",
  "optimization/parameters": "In our study, we identified nine critical feature parameters that were used as input parameters for our predictive models. These parameters were selected through a comprehensive machine learning-based feature selection process, which involved employing eight different algorithms. The algorithms used included Elastic Net, Lasso, Gradient Boosting Machine (GBM), Random Forest, XGBoost, Neural Network, Support Vector Machine (SVM), and Logistic Regression. Each of these algorithms was chosen for its unique strengths in handling diverse data characteristics and capturing different types of relationships within the data.\n\nThe selection of these nine parameters was based on their consistent ranking as important across multiple algorithms. We prioritized features that were frequently identified as significant by different methods, ensuring robustness and reliability in our feature selection process. The top parameters included TyG-WC, WHtR, TyG-BMI, TyG, TMO, CysC, CREA, SBP, and HDL-C. These parameters were further validated through dose-response relationship analysis using restricted cubic splines in Cox proportional hazards models, confirming their significance in predicting stroke risk.\n\nThe number of parameters (p) used in the model is nine. This selection was driven by the need to balance model complexity and predictive performance, ensuring that the most critical predictors of stroke risk were included. The use of multiple machine learning algorithms and cross-validation techniques helped in mitigating algorithm-specific bias and ensuring the generalizability of our findings.",
  "optimization/features": "In the \"Input Features\" subsection, it is important to note that a comprehensive feature selection process was undertaken to identify the most critical predictors of stroke risk. Eight advanced machine learning algorithms were employed to analyze the features associated with stroke. These algorithms included Elastic Net, Lasso, Gradient Boosting Machine (GBM), Random Forest, XGBoost, Neural Network, Support Vector Machine (SVM), and Logistic Regression. Each algorithm prioritized different parameters, but through a consensus approach, nine key feature parameters were identified. These parameters were TyG-waist-circumference (WC), waist-to-height ratio (WHtR), TyG-BMI, TyG, total metabolic output (TMO), CysC, creatinine (CREA), systolic blood pressure (SBP), and HDL-C.\n\nThe feature selection process ensured that the most relevant features were used as input for the predictive models. This process was conducted using the training set only, adhering to best practices in machine learning to prevent data leakage and ensure the robustness of the models. The final set of features used as input for the predictive models consisted of these nine critical parameters, which were identified through a thorough and rigorous feature selection process.",
  "optimization/fitting": "The study utilized a comprehensive approach to ensure that the model was neither overfitting nor underfitting the data. The dataset comprised 12,978 patients, which provided a substantial number of training points relative to the number of parameters. This helped mitigate the risk of overfitting, as the model had enough data to learn the underlying patterns without memorizing the training examples.\n\nTo further address overfitting, several strategies were employed. First, fivefold cross-validation was implemented for all machine learning algorithms. This technique ensures that the model's performance is evaluated on multiple subsets of the data, providing a more robust estimate of its generalization ability. Additionally, regularization techniques such as Elastic Net and Lasso were used, which are effective in feature selection and mitigating multicollinearity. These methods penalize complex models, thereby reducing the risk of overfitting.\n\nTo rule out underfitting, a diverse set of machine learning algorithms was employed, including Random Forest, Gradient Boosting, XGBoost, Neural Networks, Support Vector Machine (SVM), and Logistic Regression. Each of these algorithms has strengths in capturing different types of relationships in the data. For instance, Random Forest, Gradient Boosting, and XGBoost excel at capturing non-linear relationships and interactions, while Neural Networks can model complex patterns in high-dimensional data. SVM was selected for its robustness in binary classification tasks, and Logistic Regression served as a baseline model offering interpretable results.\n\nThe use of multiple algorithms and their combination in ensemble methods ensured that the model could capture a wide range of patterns in the data, reducing the likelihood of underfitting. Furthermore, the evaluation metrics used, such as ROC-AUC, sensitivity, and specificity, provided a comprehensive assessment of the model's performance, ensuring that it was neither too simple nor too complex. The calibration curves and Harrell's C index further confirmed the model's reliability and accuracy, demonstrating strong alignment with observed outcomes and consistent performance over different time points.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our models. Regularization methods were crucial in this regard. Elastic Net and Lasso were utilized for their effectiveness in feature selection and mitigating multicollinearity. These methods apply penalties to the regression coefficients, which helps in reducing the complexity of the models and preventing overfitting by discouraging large coefficients.\n\nAdditionally, ensemble methods such as Random Forest, Gradient Boosting Machine (GBM), and XGBoost were used. These algorithms inherently reduce overfitting by averaging the predictions of multiple models, thereby capturing non-linear relationships and interactions more effectively.\n\nCross-validation was implemented to further mitigate overfitting. Specifically, fivefold cross-validation was used for all algorithms, ensuring that the models were evaluated on different subsets of the data. This technique helps in assessing the model's performance more reliably and in reducing the risk of overfitting to the training data.\n\nMoreover, feature importance scores were calculated, normalized, and visualized for each algorithm. This process helped in identifying the most critical predictors of stroke risk, ensuring that the models focused on the most relevant features and avoided overfitting to noise in the data.\n\nIn summary, a combination of regularization techniques, ensemble methods, and cross-validation was employed to prevent overfitting and enhance the generalizability of our models.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The model developed in this study incorporates several algorithms that offer varying degrees of interpretability. Logistic Regression, one of the models used, serves as a baseline and provides interpretable results, ensuring clinical relevance. This algorithm is transparent, as it allows for the examination of coefficients associated with each feature, indicating the direction and magnitude of their influence on stroke risk.\n\nAdditionally, feature importance scores were calculated and normalized for each algorithm, including Elastic Net and Lasso, which are effective in feature selection and mitigating multicollinearity. These scores were visualized using bar plots to highlight the top 10 features identified by each method. This approach enhances the interpretability of the model by clearly indicating which features are most critical in predicting stroke risk.\n\nFurthermore, a scatter plot was generated to display the average importance score against the number of occurrences for each feature across all methods. This visualization helps in assessing the robustness and consensus among the different algorithms, prioritizing features that are consistently ranked as important. The top five features by occurrence count and average importance score were particularly emphasized, providing a clear and interpretable set of key predictors.\n\nThe nomogram model developed in this study also contributes to interpretability. It integrates age, gender, and nine key predictors identified using machine learning algorithms, providing a user-friendly and individualized risk assessment tool. The nomogram's calibration and discrimination capabilities, as evidenced by the C-index and AUC metrics, ensure that the model's predictions are reliable and clinically useful. This tool supports effective decision-making in stroke prevention and management by offering clear, interpretable risk estimates.",
  "model/output": "The model developed in this study is a regression model, specifically a Cox proportional hazards model. This type of model is used for survival analysis and time-to-event data, making it suitable for predicting the risk of stroke over time. The model incorporates various predictors identified through machine learning algorithms, along with age and gender, to estimate the probability of stroke occurrence within specific time frames, such as 1-, 3-, and 5-year periods.\n\nThe output of the model is visualized using a nomogram, which facilitates individualized risk estimation. This nomogram allows clinicians to assess the stroke risk for each patient by considering the values of the selected predictors. Additionally, calibration curves and time-dependent area under the curve (AUC) analysis were generated to evaluate the model's accuracy and discriminative ability over an 8-year follow-up period. The model's performance was quantified using metrics such as the C-index and AUC, which indicate its predictive power and reliability in distinguishing between high-risk and low-risk individuals.\n\nThe nomogram provides a user-friendly tool for early stroke detection, risk stratification, and targeted preventive interventions. It helps in identifying high-risk populations and guiding clinical decision-making for stroke prevention and management. The model's outputs are designed to support effective decision-making in clinical settings, where accurate risk stratification is crucial for implementing preventive and therapeutic strategies.",
  "model/duration": "The model was executed using 4 CPU cores. The specific execution time for the model is not provided, but the process involved several steps, including data imputation, outlier removal, and sensitivity analyses to ensure the robustness of the imputation process. These steps were completed before the final dataset, comprising 12,978 patients, was prepared for subsequent analysis and predictive modeling. The use of multiple CPU cores suggests an effort to optimize the computational efficiency of the process.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "To evaluate the robustness and performance of our predictive models, we employed several rigorous techniques. We utilized fivefold cross-validation for all algorithms to ensure unbiased performance estimation. This method involved dividing the dataset into five subsets, training the models on four subsets, and validating on the remaining one, repeating this process five times with different subsets. This approach helped to assess the models' generalizability and consistency across different data partitions.\n\nWe evaluated the predictive power of the models using multiple metrics, including the area under the receiver operating characteristic curve (ROC-AUC), sensitivity, and specificity. These metrics provided a comprehensive view of the models' ability to distinguish between stroke cases and non-cases, as well as their performance in correctly identifying true positives and negatives.\n\nAdditionally, we used evaluation metrics less sensitive to class imbalance, such as the F1-score, to ensure that the models were not biased towards the majority class. Stratified k-fold cross-validation was implemented to maintain consistent class proportions across folds, further enhancing the reliability of our evaluations.\n\nTo assess the robustness and consensus among different algorithms, we generated a scatter plot displaying the average importance score against the number of occurrences for each feature across all methods. This visualization helped to identify features consistently ranked as important, prioritizing those with the highest occurrence count and average importance score.\n\nFurthermore, we developed a nomogram model integrating age, gender, and nine key predictors identified using machine learning algorithms. The model's performance was evaluated using the C-index, which measures the model's discriminative ability by evaluating its capacity to rank patients according to stroke risk. Our model consistently achieved a C-index above 0.70 over an 8-year follow-up period, demonstrating substantial discriminative power.\n\nThe area under the receiver operating characteristic curve (AUC) was also used to assess the model's ability to distinguish disease risk between individuals. Our results showed AUC values exceeding 0.7, indicating good predictive performance. Calibration curves were used to ensure that the predicted probabilities closely matched the actual observed outcomes, further validating the model's reliability and accuracy.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the predictive power of our models. These metrics include the area under the receiver operating characteristic curve (ROC-AUC), sensitivity, and specificity. The ROC-AUC is a widely used metric that assesses the model's ability to distinguish between positive and negative cases, providing a single value that summarizes the trade-off between sensitivity and specificity across all possible classification thresholds. Sensitivity, also known as recall or true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. Together, these metrics offer a robust evaluation of our models' performance.\n\nAdditionally, we used the F1-score, which is the harmonic mean of precision and recall, to provide a balanced measure of a model's accuracy, especially in the presence of class imbalance. The F1-score is particularly useful when the classes are imbalanced, as it considers both the precision and the recall of the model.\n\nTo ensure the reliability and generalizability of our results, we implemented fivefold cross-validation. This technique involves dividing the dataset into five subsets, training the model on four subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. The performance metrics are then averaged across the five folds to provide a more stable and unbiased estimate of the model's performance.\n\nFurthermore, we calculated the C-index, also known as Harrell's C-index, which is a critical metric for survival analysis and time-to-event data. The C-index measures the model's discriminative ability by evaluating its capacity to rank patients according to their risk of stroke. Values range from 0.5 (random discrimination) to 1 (perfect discrimination), with our model consistently achieving a C-index above 0.70 over an 8-year follow-up period. This demonstrates substantial discriminative power, which is particularly valuable in clinical settings where accurate risk stratification is essential.\n\nWe also evaluated the calibration of our models using calibration curves. A well-calibrated model should have predicted probabilities that closely match the actual observed outcomes. Our calibration curves fit the 45-degree line, indicating that the predicted probability of stroke is similar to the actual observed probability. This demonstrates the reliable risk estimates of our model at different levels of risk.\n\nIn summary, our evaluation metrics are representative of the current literature and provide a thorough assessment of our models' performance. The use of ROC-AUC, sensitivity, specificity, F1-score, C-index, and calibration curves ensures that our models are robust, reliable, and clinically relevant. These metrics collectively affirm the model's clinical utility and its potential to support effective decision-making in stroke prevention and management.",
  "evaluation/comparison": "In our study, we employed a comprehensive approach to evaluate the performance of various machine learning algorithms for stroke risk prediction. We utilized eight different algorithms, each chosen for its unique strengths in handling diverse data characteristics and capturing different types of relationships within the data.\n\nTo ensure unbiased performance estimation, we implemented fivefold cross-validation for all algorithms. This method helps in assessing the generalizability of the models by evaluating their performance across multiple subsets of the data. We evaluated the predictive power of each algorithm using several metrics, including ROC-AUC, sensitivity, and specificity. These metrics provide a robust assessment of the models' ability to discriminate between stroke cases and non-cases, as well as their sensitivity and specificity in identifying true positive and true negative instances.\n\nIn addition to evaluating individual algorithms, we also conducted a feature importance analysis. Feature importance scores were calculated for each algorithm, normalized, and visualized using bar plots to highlight the top 10 features identified by each method. This analysis allowed us to identify the most critical predictors of stroke risk and prioritize them based on their consistency across different algorithms.\n\nTo assess the robustness and consensus among the different algorithms, we generated a scatter plot displaying the average importance score against the number of occurrences for each feature across all methods. This visualization helped us identify features that were consistently ranked as important by multiple algorithms, providing a more reliable set of predictors.\n\nWhile we did not perform a direct comparison to publicly available methods on benchmark datasets, our approach involved comparing the performance of multiple advanced machine learning algorithms. This comparison allowed us to evaluate the effectiveness of different techniques in capturing both linear and non-linear relationships within the data. By integrating diverse machine learning approaches, our methodology ensured a thorough exploration of the dataset, minimizing algorithm-specific bias and identifying the most critical predictors of stroke risk with high confidence.\n\nWe also did not perform a comparison to simpler baselines. However, the use of logistic regression as a baseline model provided interpretable results, ensuring clinical relevance and serving as a reference point for evaluating the performance of more complex algorithms. This approach allowed us to balance the need for advanced predictive power with the importance of clinical interpretability.",
  "evaluation/confidence": "The evaluation of our predictive model for stroke risk incorporated several robust metrics to ensure confidence in its performance. The area under the receiver operating characteristic curve (AUC) was used to assess the model's ability to distinguish between individuals at risk of stroke and those who are not. The AUC values exceeded 0.7, indicating good predictive performance. Confidence intervals for the AUC values were provided, further enhancing the reliability of these metrics. For instance, the AUC values ranged from 0.73 (95% CI 0.70\u20130.77) to 0.71 (95% CI 0.69\u20130.73) over different time points, demonstrating consistent and statistically significant performance.\n\nAdditionally, the Harrell's C index was calculated to evaluate the model's discriminative ability over an 8-year follow-up period. This metric remained above 0.70, confirming the model's robustness in predicting stroke risk. The calibration curves, which showed strong alignment with the 45-degree line, indicated that the predicted probabilities closely matched the actual observed outcomes. This alignment was particularly evident for the 1-year and 3-year predictions, underscoring the model's reliability and accuracy.\n\nStatistical significance was assessed using p-values, which confirmed that the differences observed between groups were not due to random chance. For example, the p-values for various baseline characteristics, such as glucose levels and creatinine (CREA), were less than 0.001, indicating strong statistical significance. These p-values, along with the confidence intervals for the performance metrics, provide a solid foundation for claiming that our method is superior to others and baselines.\n\nThe use of stratified k-fold cross-validation ensured that the class proportions were consistent across folds, further validating the model's performance. The evaluation metrics, including the area under the receiver operating characteristic curve (AUROC) and the F1-score, were chosen for their insensitivity to class imbalance, providing a more accurate assessment of the model's effectiveness. The consistent performance across different evaluation metrics and the statistical significance of the results bolster our confidence in the model's superiority.",
  "evaluation/availability": "The raw evaluation files used in this study are not publicly available. The study exclusively utilized publicly available data, but the specific evaluation files generated during the analysis are not released. Additional information regarding the data handling and sources can be obtained from the corresponding author upon request. The study is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits non-commercial use, sharing, distribution, and reproduction of the article, provided appropriate credit is given to the original authors and the source. However, this license does not permit the sharing of adapted material derived from the article or parts of it."
}