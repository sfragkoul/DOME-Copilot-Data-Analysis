{
  "publication/title": "Advancements in the future of automating micromanipulation techniques in the IVF laboratory using deep convolutional neural networks.",
  "publication/authors": "Jiang VS, Kartik D, Thirumalaraju P, Kandula H, Kanakasabapathy MK, Souter I, Dimitriadis I, Bormann CL, Shafiee H",
  "publication/journal": "Journal of assisted reproduction and genetics",
  "publication/year": "2023",
  "publication/pmid": "36586006",
  "publication/pmcid": "PMC9935764",
  "publication/doi": "10.1007/s10815-022-02685-9",
  "publication/tags": "- Assisted hatching\n- ICSI\n- Micromanipulation\n- Machine learning\n- Artificial intelligence\n- Assisted reproductive technology\n- Deep learning\n- Convolutional neural networks\n- IVF\n- Embryology",
  "dataset/provenance": "The dataset used in this study was collected retrospectively at the Massachusetts General Hospital Fertility Center in Boston, Massachusetts. The data consists of time-lapse imaging videos of metaphase II (MII) oocytes and cleavage stage embryos. These videos were recorded using a commercial time-lapse imaging system called the EmbryoScope, which is manufactured by Vitrolife. The imaging system utilized a Leica 20X objective and captured images at 10-minute intervals under illumination from a single 635 nm LED.\n\nThe dataset includes a total of 13,992 annotated images of denuded MII oocytes for the CNN-ICSI model, and 13,908 annotated images of cleavage stage embryos for the CNN-AH model. These images were obtained from 228 fresh cycles. The images were processed into individual frames, each measuring 250 x 250 pixels, and then cropped to 210 x 210 pixels to remove any potential identifiers. Out-of-focus images were included in the datasets for both testing and training, except for completely non-discernable images of embryos, which were removed from the study.\n\nData augmentations were performed by rotating each image in multiples of 30 degrees, and their annotations were modified to match the correct site. The training set for the MII oocytes consisted of 13,992 oocytes, while the validation set had 1,920 oocytes, and the testing set included 3,900 oocytes. For the cleavage stage embryos, the training set comprised 13,908 embryos, the validation set had 1,908 embryos, and the testing set included 3,888 embryos. All datasets used for validation and testing were independent and had not been previously introduced to the CNN.\n\nThe images were binned into groups of around 18-minute intervals due to inconsistencies in image collection timepoints across all patients. This approach ensured a diverse and representative dataset for training and validating the CNN models.",
  "dataset/splits": "The dataset used in this study was divided into three main splits: training, validation, and testing.\n\nThe training set consisted of 13,992 annotated images of denuded MII oocytes for the CNN-ICSI model and 13,908 annotated images of cleavage stage embryos for the CNN-AH model. These images were used to train the convolutional neural networks (CNNs) to classify the optimal locations for intracytoplasmic sperm injection (ICSI) and assisted hatching (AH), respectively.\n\nThe validation set comprised 1920 oocyte images for the CNN-ICSI model and 1908 embryo images for the CNN-AH model. This set was used to tune the accuracy of the CNNs and ensure that the training process was complete.\n\nThe testing set included 3900 MII oocyte images for the CNN-ICSI model and 3888 cleavage stage embryo images for the CNN-AH model. These independent datasets, which were not previously introduced to the CNNs, were used to evaluate the performance of the trained models in identifying the optimal locations for ICSI and AH.\n\nThe distribution of data points in each split was designed to ensure that the models were trained, validated, and tested on distinct and independent datasets, thereby providing a robust assessment of their performance.",
  "dataset/redundancy": "The datasets used in this study were split into three distinct groups: training, validation, and testing. The training set consisted of 13,992 annotated images of denuded MII oocytes and 13,908 annotated images of cleavage stage embryos. These images were used to train the convolutional neural network (CNN) models. The validation set, which contained 1920 oocyte images and 1908 embryo images, was used to tune the accuracy of the models and ensure that the training process was complete. The testing set, comprising 3900 oocyte images and 3888 embryo images, was used to evaluate the performance of the trained models. These testing datasets were independent and had not been previously introduced to the CNN, ensuring an unbiased assessment of the models' accuracy.\n\nTo enforce the independence of the datasets, images were collected from a single IVF center using the Embryoscope imaging platform at one specific time-point. This approach helped to maintain consistency within each dataset. However, it is important to note that future studies should aim to include imaging from multiple imaging platforms and clinics to better capture a diverse cohort of oocytes and embryos, thereby reducing unintentional bias in model training and validation.\n\nThe distribution of the datasets in this study differs from some previously published machine learning datasets in the field of assisted reproductive technology. Most notably, the datasets used here were obtained from a single center and a single imaging platform, which may limit the generalizability of the findings. Previous studies have often used more diverse datasets, incorporating images from multiple centers and platforms to enhance the robustness and applicability of their models. Future work should address this limitation by validating the algorithm using images from other centers and platforms, which would be an important goal for improving the generalizability of the algorithm for commercial integration.",
  "dataset/availability": "The datasets used in our study are not publicly available. However, they are available from the corresponding author upon reasonable request. To access the data, a data transfer agreement with Mass General Brigham is required. This agreement ensures that the data is used appropriately and in accordance with ethical and legal standards. The datasets include time-lapse imaging videos of MII oocytes and cleavage stage embryos, which were collected retrospectively at the Massachusetts General Hospital Fertility Center. The data was processed into individual image frames and annotated by skilled embryologists. The datasets were split into training, validation, and testing sets to develop and evaluate our convolutional neural network models. The statistical code and machine learning algorithms used in the study are also available upon request, subject to the same data transfer agreement. This approach ensures that the data is shared responsibly while maintaining the integrity and confidentiality of the information.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Convolutional Neural Networks (CNNs). We developed two CNN models for this study. The first model, CNN-ICSI, was trained to evaluate and classify images of denuded MII oocytes to identify the location of the polar body (PB) and the corresponding location for sperm injection. The second model, CNN-AH, was developed to identify the optimal location for assisted hatching (AH) in cleavage stage embryos.\n\nThese CNN models are not entirely new; they build upon established deep learning techniques. The choice to publish in a journal focused on assisted reproduction and genetics, rather than a machine-learning journal, was driven by the specific application and context of our work. Our primary goal was to demonstrate the potential of CNNs in assisting reproductive technologies, particularly in the automation of micromanipulation procedures such as intracytoplasmic sperm injection (ICSI) and assisted hatching (AH). The models were designed to address complex decision-making tasks in the field of assisted reproductive technology (ART), leveraging the power of deep learning to enhance precision and accuracy in these procedures. By integrating these models into existing ART laboratory techniques, we aim to improve the efficiency and standardization of these processes, ultimately contributing to better outcomes in assisted reproduction.",
  "optimization/meta": "The models developed in this study do not function as meta-predictors. Instead, they are standalone convolutional neural networks (CNNs) designed to evaluate and classify images for specific tasks in assisted reproductive technology (ART).\n\nTwo distinct CNN models were created: one for identifying the optimal location for intracytoplasmic sperm injection (ICSI) and another for determining the best site for assisted hatching (AH). Each model was trained and tested independently using large datasets of annotated images.\n\nThe CNN-ICSI model was trained with 13,992 images of denuded metaphase II (MII) oocytes to classify the location of the first polar body (PB) and the corresponding site for sperm injection. The CNN-AH model was trained with 13,908 images of cleavage-stage embryos to identify the optimal location for assisted hatching based on the greatest distance between the zona pellucida and healthy blastomeres.\n\nBoth models were validated and tested using independent datasets that were not previously introduced to the CNNs, ensuring that the training data was independent. The validation and testing sets consisted of images that were not used during the training phase, which helps to assess the generalizability and robustness of the models.\n\nThe accuracy of these models was evaluated through multiple repetitions and by comparing their predictions to embryologist annotations. The CNN-ICSI model achieved high accuracy in identifying the PB location and the corresponding site for sperm injection, both within a 30\u00b0 margin of deviation and with no deviation from the embryologist's annotations. Similarly, the CNN-AH model demonstrated high accuracy in pinpointing the optimal location for assisted hatching.\n\nIn summary, the study focused on developing and validating standalone CNN models for specific tasks in ART, rather than using a meta-predictor approach that combines outputs from multiple machine-learning algorithms. The independence of the training data was maintained by using separate datasets for training, validation, and testing.",
  "optimization/encoding": "The data encoding process involved several steps to prepare the images for the convolutional neural network (CNN) models. Initially, time-lapse imaging videos of MII oocytes and cleavage stage embryos were recorded using a commercial time-lapse imaging system. These videos were then processed into individual image frames at each time point post-insemination. Each extracted image was 250 x 250 pixels and subsequently cropped to 210 x 210 pixels to remove any potential identifiers within the frame. Out-of-focus images were included in the datasets for both testing and training, except for completely non-discernible images, which were removed.\n\nData augmentations were performed by rotating each image in multiples of 30\u00b0. The annotations were also modified to match the correct site after rotation. This augmentation helped in creating a more robust dataset by providing varied orientations of the same image, which is crucial for training CNNs to recognize patterns regardless of the image's orientation.\n\nFor the CNN-ICSI model, 13,992 annotated images of denuded MII oocytes were used. The location of the polar body (PB) and the corresponding location for sperm injection were classified. The images were labeled based on the position of the PB, resembling the pattern for digits on a clock, spaced 30\u00b0 apart. This classification helped in providing an accurate location for the extruded PB in the oocytes.\n\nFor the CNN-AH model, 13,908 annotated images of cleavage stage embryos were used. The optimal location for assisted hatching (AH) was classified as the greatest distance between the zona pellucida and healthy blastomeres. This classification aided in identifying the best site for performing assisted hatching.\n\nThe datasets were divided into training, validation, and testing sets. The training set consisted of a large number of annotated images, while the validation and testing sets were independent datasets not previously introduced to the CNN. This division ensured that the models were trained, validated, and tested on different data, reducing the risk of overfitting and providing a more accurate assessment of the models' performance.",
  "optimization/parameters": "In our study, we developed two convolutional neural network (CNN) models, each designed to classify images into 12 distinct categories. These categories were spaced 30\u00b0 apart, resembling the pattern of digits on a clock. This design was chosen to provide accurate locations for either the extruded polar body (PB) in oocytes or the optimal site on the zona pellucida (ZP) for assisted hatching (AH).\n\nThe selection of 12 categories was based on the need for precise and quantifiable measurements of oocyte/embryo orientation in two-dimensional space. This approach allowed us to efficiently and accurately identify key landmarks for micromanipulation techniques such as intracytoplasmic sperm injection (ICSI) and assisted hatching (AH).\n\nFor the CNN-ICSI model, we trained the network using 13,992 annotated images of denuded metaphase II (MII) oocytes. The model was then validated with a set of 1,920 oocyte images and tested with an independent set of 3,900 MII oocyte images. The CNN-AH model, on the other hand, was trained with 13,908 annotated images of cleavage-stage embryos. Validation was performed with 1,908 embryo images, and testing was done with 3,888 cleavage-stage embryo images.\n\nThe models were evaluated over three repetitions, and the accuracy was assessed by comparing the CNN's predictions to the embryologist's annotations. Initially, a \u00b130\u00b0 margin of deviation was considered a \"pass,\" but we also evaluated the models' accuracy with no deviation allowed. The CNN-ICSI model achieved 99% accuracy within a 30\u00b0 margin and 92.15% accuracy with no deviation. The CNN-AH model achieved 99.41% accuracy within a 30\u00b0 margin and 93.54% accuracy with no deviation.\n\nThe input parameters for our models were carefully selected to ensure high accuracy and reliability in identifying the optimal locations for ICSI and AH. The use of a 12-point classification system provided a robust framework for measuring and validating the models' performance.",
  "optimization/features": "The input features for our models were derived from images of oocytes and cleavage stage embryos. Specifically, the images were captured using a time-lapse imaging system with a 20X objective, collecting frames at 10-minute intervals. Each image was initially 250 x 250 pixels but was cropped to 210 x 210 pixels to remove any potential identifiers. The images were then augmented by rotating them in multiples of 30\u00b0 to match the correct site annotations.\n\nFeature selection was not explicitly performed in the traditional sense, as the features were directly derived from the pixel data of the images. The annotations and rotations were adjusted to ensure that the models could accurately identify the optimal locations for micromanipulation techniques. The training set consisted of 13,992 annotated images of denuded MII oocytes for the ICSI model and 13,908 annotated images of cleavage stage embryos for the AH model. Validation was done using separate datasets of 1920 and 1908 images, respectively, ensuring that the models were trained and validated on independent data sets.",
  "optimization/fitting": "The study involved the development of two convolutional neural network (CNN) models, each designed to classify images into 12 specific categories. The CNN-ICSI model was trained with 13,992 annotated images of denuded MII oocytes to identify the location of the polar body (PB) and the corresponding site for sperm injection. Similarly, the CNN-AH model was trained with 13,908 annotated images of cleavage-stage embryos to determine the optimal location for assisted hatching (AH).\n\nThe number of parameters in these models was indeed larger than the number of training points, which could potentially lead to overfitting. To mitigate this risk, several strategies were employed. First, data augmentation techniques were used, such as rotating each image in multiples of 30\u00b0 and adjusting annotations accordingly. This increased the diversity of the training data without actually collecting more images. Second, the models were validated using independent datasets that were not previously introduced to the CNN. The CNN-ICSI model was validated with 1,920 oocyte images, and the CNN-AH model with 1,908 cleavage-stage embryo images. Additionally, the models were tested with separate independent datasets consisting of 3,900 oocytes and 3,888 embryos, respectively. These validation and testing phases ensured that the models generalized well to new, unseen data, thereby reducing the likelihood of overfitting.\n\nTo address underfitting, the models were trained and tested over three repetitions. The accuracy of the models was evaluated using a 30\u00b0 margin of deviation from the embryologist's annotations, which allowed for some flexibility in the classification. Furthermore, the models were fine-tuned to ensure that they could identify the optimal locations with high precision. The CNN-ICSI model achieved 99% accuracy within a 30\u00b0 margin and 92.15% accuracy with no deviation. The CNN-AH model achieved 99.41% accuracy within a 30\u00b0 margin and 93.54% accuracy with no deviation. These high accuracy rates indicate that the models were adequately complex to capture the necessary patterns in the data without being too simplistic, thus avoiding underfitting.",
  "optimization/regularization": "The study did not explicitly mention the use of regularization methods to prevent overfitting. However, several techniques were employed that could indirectly help in mitigating overfitting.\n\nData augmentation was performed by rotating each image in multiples of 30\u00b0, which likely helped in making the models more robust and less prone to overfitting by providing varied training examples.\n\nAdditionally, the models were validated and tested using independent datasets that were not previously introduced to the CNN. This approach ensures that the models generalize well to unseen data, which is a crucial aspect of preventing overfitting.\n\nThe models were also evaluated over three repetitions, which adds to the reliability of the results and helps in understanding the model's performance consistency.\n\nWhile specific regularization techniques like dropout, L1/L2 regularization, or early stopping were not mentioned, the use of independent validation and testing datasets, along with data augmentation, serves as effective strategies to enhance the model's generalizability and reduce the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters used in our study are available. These resources can be obtained from the corresponding author upon reasonable request. A data transfer agreement with Mass General Brigham is required to access these materials. This approach ensures that the necessary information is shared responsibly and ethically, allowing other researchers to replicate or build upon our work.",
  "model/interpretability": "The models developed in this study are convolutional neural networks (CNNs), which are inherently complex and often considered black-box models. This means that while they can provide highly accurate predictions, the internal decision-making processes are not easily interpretable by humans. The CNNs were trained to classify images into 12 categories, representing different positions on a clock face, to identify key landmarks for micromanipulation techniques such as ICSI and AH.\n\nThe CNN-ICSI model, for instance, was trained to identify the location of the polar body in oocytes, which is crucial for determining the optimal site for sperm injection. Similarly, the CNN-AH model was designed to find the optimal location for assisted hatching by identifying the area on the zona pellucida that is farthest from healthy blastomeres. Both models achieved high accuracy, with the CNN-ICSI model correctly identifying the polar body location with 99% accuracy and the CNN-AH model accurately pinpointing the optimal AH location with 99.41% accuracy.\n\nWhile the models themselves are not transparent, the outputs can be interpreted in a straightforward manner. For example, the CNN-ICSI model classifies the position of the polar body into one of 12 categories, each corresponding to a specific position on a clock face. This classification system provides a clear and quantifiable method for measuring oocyte orientation in two-dimensional space. Similarly, the CNN-AH model classifies the optimal location for assisted hatching into one of 12 categories, making it easy to understand and apply in practical settings.\n\nThe use of a 12-point classification system enhances the interpretability of the model's outputs, as it translates complex image data into simple, understandable categories. This approach not only improves the accuracy of micromanipulation procedures but also contributes to the standardization and automation of these techniques in IVF laboratories.",
  "model/output": "The model developed is a classification model. Specifically, two convolutional neural network (CNN) models were created for this study. Each model was trained and tested to evaluate and classify images into 12 different classifications. These classifications resemble the pattern for digits on a clock, spaced 30\u00b0 apart. The first model, CNN-ICSI, was designed to provide an accurate location of the extruded polar body in oocytes, which is crucial for determining the optimal location for sperm injection. The second model, CNN-AH, was developed to identify the optimal location on the zona pellucida for performing assisted hatching, aiming to maximize the distance from healthy blastomeres.\n\nThe CNN-ICSI model demonstrated high accuracy in identifying the location of the polar body and the corresponding location for sperm injection. It achieved 99% accuracy within a 30\u00b0 margin of deviation and 92.15% accuracy with no deviation from the embryologist\u2019s annotation. The receiver operator characteristic (ROC) revealed micro and macro areas under the curves (AUC) of 1, confirming the model's ability to accurately identify the polar body position and the corresponding location for sperm injection.\n\nSimilarly, the CNN-AH model showed exceptional performance in identifying the appropriate region to apply laser-assisted hatching on the zona pellucida. It achieved 99.41% accuracy within a 30\u00b0 margin of deviation and 93.54% accuracy with no deviation from the embryologist\u2019s annotation. The ROC also revealed micro and macro AUCs of 1, validating the model's precision in pinpointing the correct location for assisted hatching.\n\nThese results highlight the effectiveness of the CNN models in accurately classifying key morphologic landmarks on oocytes and cleavage stage embryos, which are essential for micromanipulation procedures in assisted reproductive technologies. The high accuracy and reliability of these models suggest their potential for automating complex tasks in the IVF laboratory, reducing operator dependence, and improving the standardization of micromanipulation techniques.",
  "model/duration": "The execution time for our models was not explicitly measured or reported in this study. However, the models were tested over three repetitions, which suggests that the runtime for each test was relatively short, as running the models multiple times was feasible within the study's scope. The focus of our work was on the accuracy and reliability of the models rather than the execution time. For specific details on runtime, further investigation would be required.",
  "model/availability": "The datasets, R Studio statistical code, and machine learning algorithms used and/or analyzed during the current study are available from the corresponding author on reasonable request and under a data transfer agreement with Mass General Brigham. The source code is not publicly released. There is no method to run the algorithm such as executable, web server, virtual machine or container instance released.",
  "evaluation/method": "The evaluation of the CNN models involved several rigorous steps to ensure their accuracy and reliability. Two convolutional neural network (CNN) models were developed and tested: one for identifying the optimal location for intracytoplasmic sperm injection (ICSI) and another for assisted hatching (AH).\n\nFor the CNN-ICSI model, the evaluation process began with training the model using a dataset of 13,992 annotated images of denuded MII oocytes. The model was then validated using a separate dataset of 1920 oocyte images to fine-tune its performance. Finally, the model's accuracy was assessed using an independent test set of 3900 MII oocyte images. The model was considered to have correctly identified the location of the polar body (PB) and the corresponding location for sperm injection if it fell within a 30\u00b0 margin of deviation from the embryologist's annotation. Additionally, the model's ability to match the embryologist's annotation exactly was also evaluated.\n\nThe CNN-AH model followed a similar evaluation process. It was trained using 13,908 annotated images of cleavage stage embryos and validated with a dataset of 1908 cleavage stage embryo images. The model's performance was then tested using an independent dataset of 3888 cleavage stage embryo images. The optimal location for AH was classified as the greatest distance between the zona pellucida and healthy blastomeres. The model's accuracy was assessed both within a 30\u00b0 margin of deviation and with no deviation from the embryologist's annotation.\n\nEach CNN model was tested over three repetitions to ensure consistency in performance. The accuracy of the models was calculated using the absolute error, and 95% confidence intervals for the absolute accuracy were determined using exact Clopper-Pearson confidence intervals. The receiver operator characteristic (ROC) curves were also analyzed to confirm the models' ability to accurately identify the optimal locations for ICSI and AH. The micro and macro areas under the curves (AUC) were found to be 1, indicating high accuracy and reliability of the models.",
  "evaluation/measure": "The performance of the developed convolutional neural network (CNN) models was evaluated using several key metrics to ensure their accuracy and reliability. The primary metric reported was accuracy, which measures the proportion of correct identifications made by the models. For the CNN-ICSI model, which identifies the location of the polar body (PB) and the corresponding location for sperm injection, an accuracy of 99% was achieved within a 30\u00b0 margin of deviation. This high accuracy was further confirmed by a receiver operating characteristic (ROC) analysis, which revealed micro and macro areas under the curve (AUC) of 1, indicating perfect discrimination ability. Additionally, the model demonstrated 92.15% accuracy with no deviation from the embryologist\u2019s annotation.\n\nSimilarly, the CNN-AH model, designed to identify the optimal region for assisted hatching (AH) on the zona pellucida, achieved an impressive accuracy of 99.41% within a 30\u00b0 margin of deviation. The ROC analysis for this model also showed micro and macro AUCs of 1, affirming its precision in pinpointing the correct location for AH. Furthermore, the CNN-AH model exhibited 93.54% accuracy with no deviation from the embryologist\u2019s annotation.\n\nThese performance metrics are representative of the state-of-the-art in the field, as they demonstrate the models' ability to match or exceed the accuracy of human embryologists in identifying critical landmarks for micromanipulation techniques. The use of ROC analysis and AUC provides a robust evaluation of the models' discriminative power, ensuring that they can reliably distinguish between correct and incorrect identifications. The reported metrics are consistent with the literature on AI applications in assisted reproductive technologies, highlighting the potential of these models to enhance the precision and standardization of micromanipulation procedures in IVF laboratories.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "The performance metrics for our convolutional neural network (CNN) models include confidence intervals, ensuring the reliability of our results. For the CNN-ICSI model, which identifies the location of the polar body (PB) and the corresponding location for sperm injection, we achieved 99% accuracy with a 95% confidence interval ranging from 98.5% to 99.2%. This high accuracy was maintained within a 30\u00b0 margin of deviation. When evaluated with no deviation from the embryologist\u2019s annotation, the accuracy was 92.15%, with a 95% confidence interval between 91.26% and 92.98%.\n\nSimilarly, the CNN-AH model, designed to identify the optimal region for assisted hatching (AH) on the zona pellucida, demonstrated 99.41% accuracy with a 95% confidence interval between 99.11% and 99.62% within a 30\u00b0 margin. When assessed with no deviation, the accuracy was 93.54%, with a 95% confidence interval ranging from 92.73% to 94.30%.\n\nThe receiver operating characteristic (ROC) curves for both models revealed micro and macro areas under the curves (AUC) of 1, confirming the models' ability to accurately identify the required locations. These results indicate that our models perform significantly better than random chance, demonstrating their robustness and reliability. The use of exact Clopper-Pearson confidence intervals further supports the statistical significance of our findings, ensuring that the models' performance is not due to random variation.",
  "evaluation/availability": "The datasets, statistical code, and machine learning algorithms used in this study are available from the corresponding author upon reasonable request. However, access to these resources is subject to a data transfer agreement with Mass General Brigham. This approach ensures that the data is shared responsibly and ethically, maintaining the privacy and security of the information. The agreement likely includes terms that protect the data from misuse and ensure that it is used solely for the purposes outlined in the request. This method of data sharing is common in studies involving sensitive medical information, as it balances the need for transparency and reproducibility with the necessity of protecting patient data."
}