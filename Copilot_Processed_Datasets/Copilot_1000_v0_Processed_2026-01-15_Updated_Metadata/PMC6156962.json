{
  "publication/title": "Development and validation of an endoscopic images-based deep learning model for detection with nasopharyngeal malignancies.",
  "publication/authors": "Li C, Jing B, Ke L, Li B, Xia W, He C, Qian C, Zhao C, Mai H, Chen M, Cao K, Mo H, Guo L, Chen Q, Tang L, Qiu W, Yu Y, Liang H, Huang X, Liu G, Li W, Wang L, Sun R, Zou X, Guo S, Huang P, Luo D, Qiu F, Wu Y, Hua Y, Liu K, Lv S, Miao J, Xiang Y, Sun Y, Guo X, Lv X",
  "publication/journal": "Cancer communications (London, England)",
  "publication/year": "2018",
  "publication/pmid": "30253801",
  "publication/pmcid": "PMC6156962",
  "publication/doi": "10.1186/s40880-018-0325-9",
  "publication/tags": "- Nasopharyngeal malignancy\n- Deep learning\n- Differential diagnosis\n- Automatic segmentation\n- Endoscopic images\n- Cancer detection\n- Medical imaging\n- Artificial intelligence\n- Diagnostic performance\n- Nasopharyngeal carcinoma",
  "dataset/provenance": "The dataset used in this study consists of endoscopic images acquired from subjects under local anesthesia. All images were de-identified and randomized to ensure anonymity and prevent bias. A total of 33,507 images were initially assessed for eligibility, with 27,536 images from 7951 subjects included for analysis. These images were categorized into different subsets: 5713 images from histologically normal subjects, 19,107 from patients with pathologically proven nasopharyngeal carcinoma (NPC), 335 from patients with other malignancies, and 3811 from patients with benign diseases.\n\nThe dataset was divided into several subsets for training, validation, and testing. The training set included 19,576 images from 5557 patients, with a significant portion from patients with biopsy-proven nasopharyngeal malignancies. The validation set comprised 2690 images, including 1771 images from patients with nasopharyngeal malignancies. The test set and prospective test set included 5270 images and 1430 images, respectively, with a substantial number of images from malignant cancer patients.\n\nThe images were captured using a specific endoscope model and were eligible for analysis if they met certain criteria, such as resolution and size requirements. The dataset was used to train and evaluate the performance of eNPM-DM, a deep learning model designed to detect and segment nasopharyngeal malignancies. The model's performance was compared with that of oncologists of different seniorities, providing a comprehensive evaluation of its diagnostic accuracy and efficiency.",
  "dataset/splits": "There are four data splits in the study: the training set, the validation set, the test set, and the prospective test set. The training set includes 19,576 images from 5,557 patients, with 13,313 images from patients with biopsy-proven nasopharyngeal malignancies. The validation set comprises 2,690 images, including 1,771 images from patients with nasopharyngeal malignancies. The test set includes 5,270 images, with 3,618 images from malignant cancer patients. The prospective test set consists of 1,430 images, with 738 images from patients with malignancy. The images were randomized to these sets at a ratio of 7:1:2 for the training, validation, and test sets, respectively. Additionally, 1,430 images were used as the prospective test set to validate the established model against oncologist evaluation.",
  "dataset/redundancy": "The datasets were split into four subsets: training, validation, test, and prospective test sets. The images were randomized into these sets at a ratio of 7:1:2, respectively. Additionally, 1430 images were set aside as an independent prospective test set to validate the model against oncologist evaluations.\n\nTo ensure independence between the training and test sets, all images were de-identified and reorganized with a randomized sequence. This process helped to prevent any overlap or redundancy between the datasets. The prospective test set was entirely independent from the training, validation, and test sets, further ensuring that the model's performance could be objectively evaluated.\n\nThe distribution of the datasets included a total of 33,507 images assessed for eligibility, with 27,536 images from 7951 subjects included for analysis. The training set comprised 19,576 images, the validation set included 2690 images, the test set contained 5270 images, and the prospective test set had 1430 images. This distribution allowed for a comprehensive evaluation of the model's performance across different stages of development and testing.\n\nThe datasets included a diverse range of nasopharyngeal conditions, such as histologically normal subjects, patients with pathologically proven nasopharyngeal carcinoma (NPC), other malignancies, and benign diseases. This diversity ensured that the model could be trained and tested on a wide variety of cases, enhancing its generalizability and robustness.\n\nThe training and validation sets were used to optimize the model, with data augmentation techniques applied to enhance the training process. The test set and prospective test set were used to evaluate the model's performance, comparing it against the diagnoses of oncologists with varying levels of experience. This approach provided a thorough assessment of the model's diagnostic accuracy and reliability.\n\nNot sure how the distribution compares to previously published ML datasets.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is a fully convolutional network. This type of network is designed to receive inputs of arbitrary size and produce correspondingly sized outputs, making it well-suited for image analysis tasks.\n\nThe algorithm is not entirely new; it builds upon existing deep learning techniques. Specifically, it leverages the architecture described in a previous study, which focuses on semantic segmentation. The decision to use this particular architecture was driven by its proven effectiveness in similar image analysis tasks.\n\nThe reason this algorithm was not published in a machine-learning journal is that the primary focus of the study is on its application in medical imaging, specifically the detection and segmentation of nasopharyngeal malignancies. The development and parameter tuning of the algorithm are presented as part of a broader study on the diagnostic performance of the model in a clinical setting. The emphasis is on the practical application and validation of the model rather than the novelty of the algorithm itself. This approach aligns with the goals of the study, which aim to demonstrate the potential benefits of using deep learning in medical diagnostics.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the endoscopic images were suitable for training and evaluation. All images were de-identified and randomized in sequence within each dataset to maintain patient privacy and prevent any bias. The images were captured using a specific endoscope model and recorder, with standard white light during examination.\n\nTo be eligible for analysis, images had to meet certain criteria: a minimum resolution of 500 pixels and 70 dpi, a maximum size of 300 kb, and acquisition during the initial diagnosis. These eligible images were then randomized into training, validation, and test sets at a ratio of 7:1:2. Additionally, 1430 independent images were used as a prospective test set to validate the model against oncologist evaluations.\n\nDuring the training phase, data augmentation techniques were applied to enhance the robustness of the model. These techniques included rotation (\u00b130 degrees), shifting (\u00b120%), shearing (5%), zooming (10%), and channel shifting (10%). The model was optimized over 100 epochs on the augmented training set, with an initial learning rate of 0.001, which decreased by a factor of 0.1 every 40 epochs. The best model was selected based on its performance on the validation set.",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "The input features for the model consist of endoscopic images. These images were acquired using a specific endoscope model and capture recorder, with standard white light during examination. The images were preprocessed to ensure they met certain criteria, including a minimum resolution of 500 pixels and 70 dpi, a maximum size of 300 kb, and acquisition during the initial diagnosis.\n\nFeature selection was not explicitly performed in the traditional sense, as the features are the pixel values of the endoscopic images themselves. The images were randomized and split into training, validation, and test sets at a ratio of 7:1:2. Additionally, data augmentation techniques were applied during training, including rotation, shift, shear, zooming, and channel shift. This augmentation process helped to increase the diversity of the training data without explicitly selecting features.\n\nThe model used is a fully convolutional network, which can receive an input of arbitrary size and produce correspondingly sized output. This type of network is designed to handle image data directly, extracting relevant features through its layers. The training and testing were implemented on a server with specific hardware capabilities, ensuring efficient processing of the image data.\n\nNot applicable",
  "optimization/fitting": "The fitting method employed in this study utilized a fully convolutional network, which is capable of handling inputs of arbitrary size and producing correspondingly sized outputs. This approach is advantageous as it allows for flexibility in input dimensions, which is crucial when dealing with endoscopic images of varying sizes.\n\nThe number of parameters in the model is indeed much larger than the number of training points, a common scenario in deep learning. To mitigate the risk of over-fitting, several strategies were implemented. Firstly, data augmentation techniques were applied during training, including rotation, shifting, shearing, zooming, and channel shifting. These techniques help to artificially increase the diversity of the training dataset, making the model more robust and less likely to over-fit to the training data.\n\nAdditionally, the training process involved monitoring the loss on both the training and validation sets. The training curve revealed that the loss for the training set was similar to that of the validation set, indicating a well-fit model without significant over-fitting. This similarity in loss values suggests that the model generalizes well to unseen data.\n\nTo address the potential issue of under-fitting, the model was optimized over 100 epochs with an initial learning rate of 0.001, which was decreased by a factor of 0.1 every 40 epochs. This learning rate schedule allows the model to converge gradually, ensuring that it captures the underlying patterns in the data without getting stuck in local minima. The best model was selected based on its performance on the validation set, further ensuring that the model generalizes well to new data.\n\nIn summary, the fitting method involved using a flexible convolutional network, applying data augmentation to prevent over-fitting, and carefully monitoring the training and validation loss to ensure a well-fit model. The learning rate schedule and model selection based on validation performance helped to balance the trade-off between over-fitting and under-fitting, resulting in a robust and accurate model for detecting nasopharyngeal malignancies.",
  "optimization/regularization": "In our study, we implemented several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was data augmentation. This involved applying various transformations to the training images, such as rotations, shifts, shears, zooming, and channel shifts. These augmentations helped to increase the diversity of the training data, making the model more generalizable and less likely to overfit to the specific patterns in the training set.\n\nAdditionally, we employed a validation set to monitor the model's performance during training. The model was optimized over 100 epochs, with the learning rate decreasing by a factor of 0.1 every 40 epochs. This learning rate schedule helped in fine-tuning the model parameters more effectively. The best model was selected based on its performance on the validation set, which further aided in preventing overfitting by ensuring that the model generalized well to unseen data.\n\nThe training curve revealed that the loss on the training set was similar to that on the validation set, indicating a well-fit model without significant overfitting. This alignment in loss values between the training and validation sets is a strong indicator that the model is learning relevant features from the data rather than memorizing the training examples.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed a fully convolutional network that was retrained using deep learning techniques. The training process involved data augmentation techniques such as rotation, shifting, shearing, zooming, and channel shifting. The model was optimized over 100 epochs with an initial learning rate of 0.001, which was reduced by a factor of 0.1 every 40 epochs. The best model was selected based on its performance on the validation set.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the publication. However, the methods and configurations described are sufficient for replication by other researchers interested in similar studies. The study was conducted using a server equipped with an Intel Xeon CPU E5-2683, 128 GiB of memory, and a GeForce GTX 1080 Ti GPU, which are standard components for deep learning tasks.\n\nFor those looking to replicate or build upon our work, the publication provides a comprehensive overview of the data preprocessing, model architecture, and training procedures. This information, combined with the standard hardware specifications mentioned, should enable other researchers to implement and test similar models. The study protocol was approved by the Ethics Committee of the affiliated institution, ensuring that all data handling and experimental procedures were conducted in accordance with ethical guidelines.",
  "model/interpretability": "The model eNPM-DM, which stands for endoscopic images-based nasopharyngeal malignancy detection model, is primarily a black-box model. This means that while it can provide highly accurate predictions, the internal workings and the specific features it uses to make these predictions are not easily interpretable by humans. The model is based on a fully convolutional network, a type of deep learning architecture that can receive inputs of arbitrary size and produce correspondingly sized outputs. This type of network is known for its ability to automatically learn and extract features from raw data, but this also contributes to its black-box nature.\n\nThe model was trained using a variety of data augmentation techniques, such as rotation, shifting, shearing, zooming, and channel shifting. These techniques help to improve the model's robustness and generalization ability, but they do not contribute to its interpretability. The model's performance was evaluated using standard metrics such as accuracy, sensitivity, specificity, positive predictive value, and negative predictive value. Additionally, the area under the curve (AUC) was calculated to assess the diagnostic efficacy of eNPM-DM in the detection of nasopharyngeal malignancy using the receiver operating characteristic curve (ROC).\n\nWhile the model's predictions are highly accurate, it is not transparent in terms of how it arrives at these predictions. The model does not provide clear, human-understandable explanations for its decisions. This is a common characteristic of deep learning models, which often prioritize predictive accuracy over interpretability. However, the model's ability to segment malignant areas in endoscopic images and provide biopsy guidance is a significant step forward in the field of medical imaging and artificial intelligence. The model's performance was compared with that of oncologists of different seniorities, and it was found to be superior in detecting nasopharyngeal malignancies. This suggests that the model has the potential to assist physicians in the detection of nasopharyngeal malignancies and provide biopsy guidance, even if its internal workings are not fully transparent.",
  "model/output": "The model, termed the endoscopic images-based nasopharyngeal malignancies detection model (eNPM-DM), is a classification model. It is designed to distinguish between malignant and benign nasopharyngeal conditions using endoscopic images. The model outputs a probability map for each image, where areas with a probability greater than 0.5 are considered malignant. This probability map is then used to classify the image as indicative of malignancy or not. The model's performance is evaluated based on its accuracy, sensitivity, and specificity in detecting nasopharyngeal malignancies. Additionally, the model can segment the malignant areas within the images, providing a visual representation of the detected malignancies. The output of the model includes the classification of the image as malignant or benign and the segmented malignant areas, which are highlighted in the probability map.",
  "model/duration": "The execution time for the eNPM-DM model to render an opinion was approximately 40 seconds. This is significantly faster compared to the time taken by experts, which averaged around 110 minutes. The efficiency of the model in terms of time is a notable advantage, as it allows for quicker diagnosis and potentially earlier intervention in cases of nasopharyngeal malignancies.",
  "model/availability": "The source code for the eNPM-DM model is not publicly released. However, an online platform has been established to make use of the advanced tool in clinical practice. Both patients and physicians can use this platform to assess the probability of malignancy in a certain image by uploading eligible nasopharyngeal endoscopic images to the artificial intelligence platform. If the lesion is recognized as malignant, the suggestive region for biopsy is provided. The platform is accessible at http://nasoa i.sysuc c.org.cn/. The prospective test datasets used during this study are available at http://www.nasoa i.com.",
  "evaluation/method": "The evaluation of the eNPM-DM model involved several key steps and metrics to assess its performance in detecting and segmenting nasopharyngeal malignancies. The model's performance was evaluated using a test set and a prospective test set, which included images from patients with both malignant and benign conditions.\n\nThe evaluation metrics used included accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the area under the curve (AUC). Accuracy was defined as the proportion of correctly identified images out of all images. Sensitivity, or true positive rate, measured the proportion of truly positive images correctly identified. Specificity, or true negative rate, measured the proportion of truly negative images correctly identified. PPV was the proportion of truly positive images among those labeled as positive, while NPV was the proportion of truly negative images among those labeled as negative.\n\nThe model's output was a probability map, where an area with a probability greater than 0.5 was considered malignant. The performance of eNPM-DM was compared with that of oncologists of varying experience levels, including experts, resident oncologists, and interns. The evaluation also included a combined performance assessment of eNPM-DM and experts, where an image was considered benign if recognized as such by either the model or more than two experts.\n\nAdditionally, the dice similarity coefficient (DSC) was used to evaluate the model's segmentation performance. DSC measured the overlap between the expert-delineated malignant area and the area identified by eNPM-DM. The formula for DSC is given by:\n\ns = 2|S\u2229 F| / (|S| + |F|)\n\nwhere S represents the ground-truth segmentation and F stands for the segmentation output.\n\nThe evaluation results showed that eNPM-DM achieved high accuracy, sensitivity, and specificity in detecting nasopharyngeal malignancies. The model's performance was superior to that of oncologists, particularly in terms of specificity and time efficiency. The AUC values for the test set and the prospective test set were 0.938 and 0.930, respectively, indicating strong diagnostic efficacy. The DSC values for segmentation were also encouraging, demonstrating the model's capability in automatic segmentation of malignant areas.",
  "evaluation/measure": "In our study, we evaluated the performance of the eNPM-DM model using several standard metrics to ensure a comprehensive assessment of its diagnostic efficacy. The primary metrics reported include accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics were chosen because they provide a well-rounded view of the model's performance in detecting nasopharyngeal malignancies.\n\nAccuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It gives an overall sense of how often the model is correct. Sensitivity, also known as the true positive rate, indicates the proportion of actual positives that are correctly identified by the model. This is crucial for ensuring that the model can effectively detect malignant cases. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. This is important for minimizing false positives, which can lead to unnecessary interventions.\n\nPPV and NPV provide additional insights into the model's performance. PPV indicates the probability that subjects with a positive screening test truly have the disease, while NPV indicates the probability that subjects with a negative screening test truly do not have the disease. These metrics are particularly useful in clinical settings where the consequences of false positives and false negatives can be significant.\n\nIn addition to these metrics, we also calculated the area under the curve (AUC) using the receiver operating characteristic (ROC) curve. The AUC provides a single scalar value that summarizes the model's ability to discriminate between positive and negative classes. A higher AUC indicates better performance.\n\nThe use of these metrics is representative of standard practices in the literature for evaluating diagnostic models. They allow for a clear comparison of our model's performance with other similar models and provide a robust framework for assessing its clinical utility. The inclusion of time-taken for test based on images is also important, as it highlights the efficiency of the model compared to human experts. This set of metrics ensures that our evaluation is thorough and aligned with established standards in the field.",
  "evaluation/comparison": "In our study, we did not compare our model, eNPM-DM, to publicly available methods on benchmark datasets. Instead, we focused on evaluating eNPM-DM's performance against human experts in the field of nasopharyngeal malignancy detection.\n\nWe compared eNPM-DM's diagnostic performance with that of oncologists of different seniorities in the prospective test set. This included three experts, eight resident oncologists, and three interns, each with varying levels of experience. The comparison was based on several standard evaluation metrics, including accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and time taken for the test.\n\nThe results showed that eNPM-DM outperformed the oncologists in terms of accuracy, specificity, PPV, and NPV. Additionally, eNPM-DM required significantly less time to render an opinion compared to the experts.\n\nRegarding simpler baselines, our approach was to develop a deep learning model using a fully convolutional network, which is a complex method designed to handle the intricacies of medical image analysis. Therefore, a comparison to simpler baselines was not performed. The focus was on demonstrating the superior performance of eNPM-DM in detecting nasopharyngeal malignancies and its potential benefits in clinical settings.",
  "evaluation/confidence": "The evaluation of our model, eNPM-DM, includes several performance metrics, each accompanied by a 95% confidence interval (CI). This provides a range within which the true value of the metric is expected to lie, giving a sense of the precision of our estimates. The metrics evaluated include accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). For instance, in the test set, the accuracy of eNPM-DM is reported as 88.7% with a 95% CI of 87.8% to 89.5%, indicating a high level of confidence in this estimate.\n\nThe statistical significance of our results is evident in the comparison with oncologists of varying seniorities. eNPM-DM demonstrated superior performance in terms of accuracy, specificity, PPV, and NPV compared to experts, residents, and interns. The differences in these metrics are substantial and supported by non-overlapping confidence intervals, suggesting that the observed differences are statistically significant. For example, the accuracy of eNPM-DM in the prospective test set is 88.0% (95% CI 86.1%\u201389.6%), whereas the accuracy for experts is 80.5% (95% CI 77.0%\u201384.0%). The non-overlapping confidence intervals indicate that the performance of eNPM-DM is significantly better than that of the experts.\n\nMoreover, the area under the curve (AUC) for eNPM-DM in detecting nasopharyngeal malignancy is 0.938 in the test set and 0.930 in the prospective test set, further supporting the high diagnostic efficacy of our model. The training curve of eNPM-DM also reveals similar data loss in both the training and validation sets, indicating no appreciable overfitting.\n\nIn summary, the performance metrics of eNPM-DM are robust and statistically significant, providing strong evidence that our model is superior to the baseline performance of oncologists. The inclusion of confidence intervals for all metrics ensures that the results are reliable and generalizable.",
  "evaluation/availability": "Not enough information is available."
}