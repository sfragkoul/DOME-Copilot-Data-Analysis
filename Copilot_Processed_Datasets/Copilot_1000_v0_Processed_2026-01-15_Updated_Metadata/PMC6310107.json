{
  "publication/title": "Classifying and characterizing nicotine use disorder with high accuracy using machine learning and resting-state fMRI.",
  "publication/authors": "Wetherill RR, Rao H, Hager N, Wang J, Franklin TR, Fan Y",
  "publication/journal": "Addiction biology",
  "publication/year": "2019",
  "publication/pmid": "29949234",
  "publication/pmcid": "PMC6310107",
  "publication/doi": "10.1111/adb.12644",
  "publication/tags": "- Nicotine Use Disorder\n- Resting-State Functional Connectivity\n- Machine Learning\n- Support-Vector Machine\n- Functional MRI\n- Classification\n- Neural Networks\n- Addiction\n- Brain Imaging\n- Multidimensional Scaling",
  "dataset/provenance": "Not enough information is available.",
  "dataset/splits": "In our study, we employed a nested 10-fold cross-validation strategy to evaluate the performance of our classifiers. This involved splitting the dataset into 10 subsets, ensuring that each subset maintained the same proportions of individuals with nicotine use disorder and controls. In each fold of the cross-validation, 9 of these subsets were used as training data to build the classification model, while the remaining subset served as the test data for evaluating the model's performance. This process was repeated 10 times, with each subset being used exactly once as the test data. Additionally, to obtain a robust estimation of the classification performance, the entire nested 10-fold cross-validation experiment was repeated 10 times with random splits of training and testing subjects.",
  "dataset/redundancy": "The dataset used in this study consisted of resting-state functional connectivity (rsFC) data from individuals diagnosed with nicotine use disorder (NUD) and demographically-matched nonsmoking, healthy controls. The dataset was split using a nested 10-fold cross-validation approach. This method involves randomly partitioning the dataset into 10 subsets, ensuring that each subset maintains the same proportions of individuals with NUD and controls. In each fold of the cross-validation, 9 of these subsets are used as training data to build a classification model, while the remaining subset is retained as the test data for evaluating the model's performance. This process is repeated 10 times, with each of the 10 subsets used exactly once as the test data. This ensures that the training and test sets are independent in each fold, as the test set is not used in the training process.\n\nTo build the classification model for each fold, an additional 10-fold cross-validation is performed on the training data. This nested cross-validation is used to select the best set of resting state networks (RSNs) and optimize the support-vector machine (SVM) parameters. This nested approach helps to prevent overfitting and ensures that the model's performance is robust and generalizable.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the field of neuroimaging. The use of a large sample size (108 individuals with NUD and 108 controls) and the rigorous cross-validation strategy help to mitigate issues related to dataset redundancy and overfitting. The nested cross-validation ensures that the model's performance is evaluated on independent test sets, providing a more reliable estimate of its generalization capability. Additionally, the use of permutation tests further validates the statistical significance of the classification results.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Support Vector Machine (SVM). SVM is a well-established and widely used supervised learning method for classification and regression tasks. It is not a new algorithm; it has been extensively studied and applied in various fields, including neuroimaging and biomedical research.\n\nThe choice of SVM for our study was driven by its effectiveness in handling high-dimensional data and its ability to identify complex patterns, which are crucial for analyzing neuroimaging data. SVM has been successfully applied in previous studies to classify various neurobiological diseases based on neuroimaging data, achieving moderate to high classification accuracy.\n\nGiven that SVM is a mature and well-understood algorithm, publishing our work in a machine-learning journal was not necessary. Instead, we focused on applying SVM to a specific domain\u2014classifying and characterizing nicotine use disorder (NUD) using resting-state functional connectivity (rsFC) data. Our contribution lies in the application of SVM to this particular problem and the insights gained from our analysis, rather than the development of a new machine-learning algorithm.",
  "optimization/meta": "The model employed in our study does not function as a meta-predictor. Instead, it relies on a nested 10-fold cross-validation strategy to build and evaluate classifiers. This approach involves using support-vector machine (SVM) classifiers, which are trained and optimized based on the resting state networks (RSNs) of the training subjects.\n\nThe nested cross-validation procedure ensures that the training data used to select the best set of RSNs and optimize the SVM parameters is independent of the testing data. This is achieved by performing an inner 10-fold cross-validation within each fold of the outer 10-fold cross-validation. The inner cross-validation is used to tune the SVM parameters and select the most discriminative RSNs, while the outer cross-validation assesses the performance of the final classifier on unseen data.\n\nThis method ensures that the model's performance is robust and that the selected RSNs are truly indicative of the differences between the groups being studied. The use of nested cross-validation helps to prevent overfitting and provides a more reliable estimate of the classifier's generalizability.",
  "optimization/encoding": "Each participant's resting-state functional magnetic resonance imaging (rsfMRI) data underwent preprocessing using Statistical Parametric Mapping (SPM8) and Analysis of Functional NeuroImages (AFNI) software. The initial six volumes were discarded to allow for magnetization equilibration. Despiking was applied to the remaining volumes, followed by slice-time correction. Head motion correction was performed by realigning the rsfMRI volumes to the mean volume obtained through two-pass averaging. Head motion was measured using the root mean square of framewise displacement (RMSFD). The rsfMRI data were intensity scaled to achieve a whole-brain mean value of 1,000. Signals from the white matter and cerebrospinal fluid, along with six rigid head motion parameters, were regressed out using a general linear model. Temporal band-pass filtering (0.01<f<0.08 Hz) was then applied to reduce low-frequency drift and high-frequency noise effects. Finally, SPM8\u2019s DARTEL toolbox was used to spatially normalize individual subject images to a group template and then to the Montreal Neurological Institute (MNI) space with an affine transformation. The data were resampled to 3 mm \u00d7 3 mm \u00d7 3 mm voxels and smoothed with a Gaussian kernel with a full-width at half-maximum (FWHM) of 6 mm.\n\nFor the machine-learning algorithm, group information guided independent components analysis (GIG-ICA) was employed to compute subject-specific resting state networks (RSNs). The number of components was set to 10, and these group-level independent components (ICs) were used as guidance to compute subject-specific ICs and their associated time courses. The ICs were referred to as RSNs. To identify RSNs altered by nicotine use disorder (NUD), a Grassmann manifold learning method was used to build classification models based on RSNs selected to optimize classification performance. The 10 RSNs from each individual were used as bases for a linear subspace, and similarity measures between subjects' RSNs were computed on the Grassmann manifold using a principal angle-based Riemannian distance. These similarity measures were then used in the support vector machine (SVM) classification. A forward component selection technique was adopted to select RSNs for constructing the most discriminative set of RSNs. The forward component selection algorithm initially built a classifier for each individual RSN, and the component with the best classification performance was selected. This procedure was repeated to include more components in the classification until a single classifier was built upon all available components. The combination of components with the overall best classification performance was identified for the final classification. The component selection and classifier construction were based solely on training data.",
  "optimization/parameters": "In our study, the number of parameters used in the model was not fixed but rather determined through a systematic selection process. We employed a nested 10-fold cross-validation strategy to identify the optimal set of resting state networks (RSNs) and to tune the support-vector machine (SVM) parameters. This approach allowed us to evaluate the classification performance of different combinations of RSNs and SVM parameters.\n\nThe process began with the dataset being randomly partitioned into 10 subsets, each maintaining the same proportions of individuals with nicotine use disorder and controls. For each fold of the outer cross-validation, 9 subsets were used as training data to build the classification model, while the remaining subset served as the test data. Within each training fold, a nested 10-fold cross-validation was performed to select the best set of RSNs and optimize the SVM parameters. This nested approach ensured that the model selection and parameter tuning were conducted solely on the training data, preventing overfitting and providing a robust estimate of the classification performance.\n\nThe selection of RSNs and SVM parameters was based on their discriminative performance within the training data. The component with the best classification performance was initially selected, and this procedure was repeated to include more components one by one until a single classifier was built upon all available components. The combination of components with the overall best classification performance was then identified for the final classification.\n\nThis methodical approach ensured that the number of parameters (p) used in the model was dynamically determined based on their contribution to the classification performance, rather than being predefined. The final model incorporated the components that collectively provided the highest accuracy and area under the ROC curve, indicating a robust and effective classification strategy.",
  "optimization/features": "In our study, we utilized resting-state functional connectivity (rsFC) data from individuals diagnosed with nicotine use disorder (NUD) and matched nonsmoking controls. Specifically, we focused on resting state networks (RSNs) derived from the participants' data. The number of RSNs, which serve as input features for our classification model, was determined to be 10. These RSNs were computed using Group Information Guided Independent Components Analysis (GIG-ICA), ensuring inter-individual comparability.\n\nFeature selection was indeed performed to identify the most discriminative RSNs for distinguishing between NUD subjects and controls. This process involved a forward component selection technique, where classifiers were initially built upon individual RSNs. The component with the best classification performance was selected, and this procedure was iteratively repeated to include more components until a single classifier was built upon all available RSNs. The selection of components was carried out based solely on the training data, ensuring that the evaluation and selection process was unbiased and robust. This nested 10-fold cross-validation strategy helped in building classifiers and estimating the statistical significance of our classification results.",
  "optimization/fitting": "The fitting method employed in this study utilized a nested 10-fold cross-validation strategy to build and evaluate classifiers, ensuring robust performance estimation and mitigating both overfitting and underfitting.\n\nThe number of parameters in the model was indeed larger than the number of training points, as the study involved selecting the best set of resting state networks (RSNs) and optimizing support-vector machine (SVM) parameters. To rule out overfitting, a nested cross-validation approach was used. In each of the outer 10 folds, a separate inner 10-fold cross-validation was performed to select the optimal set of RSNs and tune the SVM parameters. This nested structure ensured that the model selection and parameter tuning were done on a separate validation set within each fold, preventing the model from becoming too tailored to the training data.\n\nTo address underfitting, the forward component selection technique was employed. This method iteratively added components (RSNs) to the classifier, evaluating the performance at each step. By progressively including more components, the model's complexity increased, allowing it to capture more of the underlying patterns in the data. The process continued until the combination of components with the overall best classification performance was identified. This approach helped in ensuring that the model was neither too simple (underfitting) nor too complex (overfitting).\n\nAdditionally, the classification performance was evaluated using multiple metrics, including classification accuracy, receiver operating characteristic (ROC) curves, and the area under the ROC curve (AUROC). The use of these metrics provided a comprehensive assessment of the model's discriminative power. Furthermore, the statistical significance of the classification results was estimated using 10e5 permutation tests, which involved building classifiers on data with randomly assigned class labels. This rigorous evaluation ensured that the observed classification performance was not due to chance.\n\nIn summary, the nested 10-fold cross-validation strategy, combined with the forward component selection technique and comprehensive performance evaluation, effectively addressed the challenges of overfitting and underfitting in the fitting method.",
  "optimization/regularization": "In our study, we employed a nested 10-fold cross-validation strategy to prevent overfitting and to ensure robust estimation of classification performance. This method involves partitioning the dataset into 10 subsets, using 9 for training and 1 for testing in each fold. This process is repeated 10 times, with each subset serving as the test set exactly once. Within each fold, another 10-fold cross-validation is performed to select the best set of resting state networks (RSNs) and optimize the support-vector machine (SVM) parameters based on the training data. This nested approach helps to mitigate overfitting by ensuring that the model selection and parameter tuning are performed on a separate validation set within each fold. Additionally, we repeated the entire nested 10-fold cross-validation experiment 10 times with random splits of training and testing subjects to obtain a more reliable estimate of the classification performance. This comprehensive cross-validation strategy ensures that our results are generalizable and not merely a product of overfitting to the specific training data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we employed a nested 10-fold cross-validation strategy to select the best set of resting state networks (RSNs) and optimize the support-vector machine (SVM) parameters. This process involved multiple training and testing runs, where each run used a different subset of the data for testing while the remaining data was used for training. The cross-validation procedure ensured that each subset was used exactly once as the test data, providing a robust estimate of the classification performance.\n\nThe optimization schedule and model files are not explicitly provided in the publication. However, the methods and techniques used, such as the Grassmann manifold learning method and the forward component selection technique, are described in detail. These methods were crucial for building classification models based on RSNs and for selecting the most discriminative set of RSNs.\n\nRegarding the availability and licensing of the configurations and parameters, the publication does not specify where these can be accessed or under what license. The focus of the publication is on the methodological approach and the results obtained, rather than the distribution of specific model files or configurations. Researchers interested in replicating or building upon our work would need to refer to the detailed descriptions provided in the methods section and the referenced literature for guidance on implementing similar techniques.",
  "model/interpretability": "The model employed in this study is not entirely a black box, as it leverages interpretable components and methodologies to enhance transparency. The use of resting-state networks (RSNs) as features for classification provides a clear link to neurobiological processes, making the model more interpretable than many other machine learning approaches.\n\nThe support-vector machine (SVM) classifier, while inherently a black-box model, is used in conjunction with a nested cross-validation strategy that helps in selecting the most discriminative RSNs. This process ensures that the final model is built upon the most relevant neural features, which can be visually inspected and analyzed. For instance, the five RSNs most frequently contributing to the classification\u2014posterior and anterior default mode networks, sensorimotor network, salience network, and right executive control network\u2014can be examined to understand their roles in distinguishing individuals with nicotine use disorder from healthy controls.\n\nAdditionally, the use of multidimensional scaling (MDS) to visualize the heterogeneity of nicotine use disorder based on resting-state functional connectivity (rsFC) measures adds another layer of interpretability. MDS allows for the visualization of how individuals with nicotine use disorder differ from controls and from each other, providing insights into the underlying neural patterns.\n\nThe frequency of different RSNs selected in the cross-validation experiments is also computed, which helps in identifying the most frequently selected RSNs. These RSNs are considered the most different between individuals with nicotine use disorder and non-smoking controls, further aiding in the interpretability of the model.\n\nIn summary, while the SVM classifier itself is a black-box model, the overall approach incorporates interpretable components and visualizations that enhance the transparency of the model. This allows for a better understanding of the neural features that contribute to the classification of nicotine use disorder.",
  "model/output": "The model employed in this study is a classification model. Specifically, a support-vector machine (SVM)-based classification approach was utilized. This model was applied to resting-state functional connectivity (rsFC) data to differentiate individuals diagnosed with nicotine use disorder (NUD) from demographically-matched nonsmoking, healthy controls. The classification process involved a nested 10-fold cross-validation strategy, which helped in selecting the best set of resting state networks (RSNs) and optimizing the SVM parameters to achieve the highest classification accuracy.\n\nThe performance of the classifiers was evaluated using metrics such as classification accuracy and the area under the receiver operating characteristic curve (AUROC). The model demonstrated an average correct classification rate of 88.1% and an average AUROC of 0.93, indicating strong discriminative performance. Additionally, the model identified five key RSNs that played a significant role in distinguishing smokers from controls: the posterior and anterior default mode networks, the sensorimotor network, the salience network, and the right executive control network.\n\nThe classification results were further validated through permutation tests, which involved building classifiers on data with randomly assigned class labels. This rigorous validation process ensured the robustness and reliability of the classification outcomes. The model's ability to accurately classify individuals with NUD and controls, along with its identification of critical RSNs, provides valuable insights into the neural features associated with nicotine use disorder.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed a robust strategy to ensure the reliability and generalizability of the classification performance. A nested 10-fold cross-validation procedure was utilized, where the dataset was randomly partitioned into 10 subsets. In each fold, 9 subsets were used for training, and the remaining subset was used for testing. This process was repeated 10 times, ensuring that each subset was used exactly once as the test data. Within each training fold, another 10-fold cross-validation was performed to select the best set of resting state networks (RSNs) and optimize the support-vector machine (SVM) parameters.\n\nThe overall classification performance was evaluated based on the 10 training and testing runs. Additionally, the classification experiment was repeated 10 times with random splits of training and testing subjects to obtain a robust estimation of the classification performance. This nested cross-validation strategy helped in building classifiers and estimating the statistical significance of the classification results using permutation tests.\n\nTo assess the performance, classification accuracy, receiver operating characteristic (ROC) curves, and the area under the ROC curve (AUROC) were computed. The AUROC provides a summary measure of the classifier's performance, with a larger AUROC indicating better classification performance. The ROC curves visualize the sensitivity and specificity of the classifier at different classification thresholds.\n\nThe permutation tests involved building classifiers on data with randomly assigned class labels to evaluate the statistical significance of the classification results. This approach ensured that the observed classification performance was not due to chance. The frequency of RSNs selected into the best set of discriminative RSNs across all runs was also computed, highlighting the most frequently selected RSNs as the most different between the groups being studied.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our classification approach. The primary metric reported is the classification accuracy, which represents the proportion of correctly classified instances (both individuals with nicotine use disorder (NUD) and controls) out of the total number of instances. This metric provides a straightforward measure of how well our model performs in distinguishing between the two groups.\n\nIn addition to accuracy, we computed the area under the receiver operating characteristic curve (AUROC). The AUROC provides a comprehensive evaluation of the classifier's performance across all possible classification thresholds. A higher AUROC indicates better discriminative ability, with a value of 1 representing perfect classification and 0.5 indicating performance no better than random guessing. Our results showed an average AUROC of 0.93, suggesting robust classification performance.\n\nTo ensure the statistical significance of our classification results, we conducted permutation tests. These tests involved building classifiers on data with randomly assigned class labels and repeating this process 10e5 times. The permutation test results indicated that our classification outcome was statistically significant (p<10\u22126), reinforcing the reliability of our findings.\n\nWe also visualized the performance using receiver operating characteristic (ROC) curves. These curves plot the true positive rate (sensitivity) against the false positive rate (1-specificity) at various threshold settings, providing a visual representation of the trade-off between sensitivity and specificity. The ROC curves from ten repetitions of 10-fold cross-validation demonstrated consistent and high classification performance.\n\nFurthermore, we reported the frequency of different resting state networks (RSNs) selected in the cross-validation experiments. This information helps identify which RSNs are most frequently associated with the classification of NUD, providing insights into the neural correlates of nicotine use disorder.\n\nOverall, the set of performance metrics used in our study is representative of standard practices in the literature. Accuracy, AUROC, and permutation tests are commonly reported metrics in classification studies, particularly in the field of neuroimaging and machine learning. These metrics collectively provide a thorough evaluation of our classifier's performance, ensuring that our results are both reliable and comparable to other studies in the domain.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "The evaluation of our method's performance was conducted using a robust cross-validation strategy to ensure confidence in the results. We employed a nested 10-fold cross-validation procedure, which involved partitioning the dataset into 10 subsets. In each fold, 9 subsets were used for training, and the remaining subset was used for testing. This process was repeated 10 times, with each subset serving as the test set exactly once. Within each training fold, another 10-fold cross-validation was performed to select the best set of resting state networks (RSNs) and optimize the support vector machine (SVM) parameters.\n\nTo assess the statistical significance of our classification results, we conducted 10^5 permutation tests. These tests involved building classifiers on data with randomly assigned class labels, allowing us to estimate the significance of our observed classification performance. The results indicated that our classification method achieved statistically significant performance (p < 10^-6).\n\nIn addition to classification accuracy, we computed receiver operating characteristic (ROC) curves and the area under the ROC curve (AUROC) to evaluate the performance of our classifiers. The AUROC provides a summary measure of the classifier's ability to discriminate between classes, with higher values indicating better performance. Our method achieved an average AUROC of 0.93 across 10 repetitions of the 10-fold cross-validation, demonstrating strong discriminative power.\n\nThe confidence intervals for the performance metrics were not explicitly stated, but the use of cross-validation and permutation tests provides a robust framework for evaluating the reliability and generalizability of our results. The consistent performance across multiple runs and the statistical significance of the results suggest that our method is effective in distinguishing individuals with nicotine use disorder (NUD) from controls.",
  "evaluation/availability": "Not enough information is available."
}