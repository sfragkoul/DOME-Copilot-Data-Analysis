{
  "publication/title": "Improved diagnosis of thyroid cancer aided with deep learning applied to sonographic text reports: a retrospective, multi-cohort, diagnostic study.",
  "publication/authors": "Zhang Q, Zhang S, Li J, Pan Y, Zhao J, Feng Y, Zhao Y, Wang X, Zheng Z, Yang X, Liu L, Qin C, Zhao K, Liu X, Li C, Zhang L, Yang C, Zhuo N, Zhang H, Liu J, Gao J, Di X, Meng F, Ji W, Yang M, Xin X, Wei X, Jin R, Zhang L, Wang X, Song F, Zheng X, Gao M, Chen K, Li X",
  "publication/journal": "Cancer biology & medicine",
  "publication/year": "2021",
  "publication/pmid": "34491007",
  "publication/pmcid": "PMC9196053",
  "publication/doi": "10.20892/j.issn.2095-3941.2020.0509",
  "publication/tags": "- Deep Learning\n- Natural Language Processing\n- Thyroid Cancer Diagnosis\n- Sonographic Radiology\n- Artificial Intelligence\n- Clinical Natural Language Processing\n- BERT\n- Self-Attention Modules\n- Differential Diagnosis\n- Machine Learning\n- Radiological Text Reports\n- Human Intelligence Transfer\n- Clinical Expertise\n- Unstructured EHR Data\n- Prospective Clinical Trials",
  "dataset/provenance": "The dataset utilized in this study comprises radiologic text reports of thyroid examinations collected from multiple medical centers. Specifically, the primary source is Tianjin Medical University Cancer Institute and Hospital (TMUCIH), where data was gathered between January 2012 and December 2018. This dataset includes a total of 720,171 radiologic text reports. Additionally, data from Weihai Municipal Hospital, collected between January 2012 and December 2017, contributed 67,958 radiologic text reports. The combined dataset from these sources totals 788,129 radiologic text reports.\n\nThe training set for developing THCaDxNLP consisted of 132,277 thyroid sonographic text reports. These reports were categorized into non-cancerous diseases (5,704 reports), doctor-directed controls (108,173 reports), and thyroid cancer cases (18,400 reports), resulting in a total of 113,875 control reports.\n\nThe study also included five test sets from different hospitals:\n\n* TMUCIH (n = 439)\n* Tianjin Medical University General Hospital (TGH, n = 186)\n* Tianjin Fourth Central Hospital (TFCH, n = 82)\n* Weihai Municipal Hospital (Weihai, n = 343)\n* Chengde Hospital (Chengde, n = 171)\n\nThese test sets were used to evaluate the performance of THCaDxNLP across diverse clinical settings. The clinical characteristics of the training set and the test sets are detailed in supplementary materials. The dataset was tokenized and used to develop a language representation model specific to thyroid radiologic text reports, termed EhrBERT. This model was then fine-tuned to create THCaDxNLP, a deep learning model designed to identify thyroid cancer via radiologic text reports. The evaluation involved comparing the interpretation results of radiologists aided with and without THCaDxNLP, focusing on metrics such as sensitivity, specificity, positive predictive value, negative predictive value, and F1 score.",
  "dataset/splits": "The dataset used in this study consists of five test sets, each comprising individuals from different hospitals. The first test set, from Tianjin Medical University Cancer Institute and Hospital (TMUCIH), includes 439 individuals. The second test set, from Tianjin Medical University General Hospital (TGH), contains 186 individuals. The third test set, from Tianjin Fourth Central Hospital (TFCH), has 82 individuals. The fourth test set, from Weihai Municipal Hospital, includes 343 individuals. The fifth test set, from Chengde Hospital, consists of 171 individuals.\n\nThe training set, used to develop the THCaDxNLP model, comprises 132,277 thyroid sonographic text reports. These reports were collected from various sources, including TMUCIH and Weihai Municipal Hospital, spanning from January 2012 to December 2017. The training set includes a mix of non-cancerous diseases, doctor-directed controls, and thyroid cancer cases, totaling 132,277 radiologic text reports. The distribution of these reports in the training set is designed to capture a wide range of clinical scenarios, ensuring the model's robustness and generalizability.",
  "dataset/redundancy": "The datasets used in this study were split into training and test sets to ensure independence and to evaluate the performance of the developed models. The training set consisted of 132,277 thyroid sonographic text reports, which were used to develop the THCaDxNLP model. The test sets were composed of 1,221 individuals from five different hospitals: TMUCIH (n = 439), Tianjin Medical University General Hospital (TGH, n = 186), Tianjin Fourth Central Hospital (TFCH, n = 82), Weihai Municipal Hospital (Weihai, n = 343), and Chengde Hospital (Chengde, n = 171).\n\nTo enforce the independence of the training and test sets, data from different time periods and hospitals were used. Specifically, radiologic text reports of thyroid examinations collected from TMUCIH between January 2012 and December 2017 were included in the training set, while reports from January 2012 to December 2018 were used for the test set from the same hospital. Additionally, data from other hospitals were included in the test sets to further ensure diversity and independence.\n\nThe distribution of the datasets in this study compares favorably to previously published machine learning datasets in the field of radiology. By including data from multiple hospitals and ensuring temporal separation, the study aimed to capture a broader range of variability in radiological text reports. This approach helps to mitigate the limitations associated with single-hospital data and enhances the generalizability of the THCaDxNLP model. The use of data from different hospitals also addresses the variability in writing styles among radiologists, which is a known challenge in developing robust natural language processing models for medical text.",
  "dataset/availability": "The data used in this study is not publicly available. The dataset consists of radiologic text reports of thyroid examinations collected from multiple medical centers, including Tianjin Medical University Cancer Institute and Hospital (TMUCIH), Tianjin Medical University General Hospital (TGH), Tianjin Fourth Central Hospital (TFCH), Weihai Municipal Hospital, and Chengde Hospital. The data was used to develop and evaluate the EhrBERT language representation model and the THCaDxNLP deep learning model for identifying thyroid cancer via radiologic text reports.\n\nThe dataset includes a training set of 132,277 radiologic text reports and five test sets consisting of 1,221 individuals in total. The test sets are from different hospitals: TMUCIH (n = 439), TGH (n = 186), TFCH (n = 82), Weihai Municipal Hospital (n = 343), and Chengde Hospital (n = 171). The clinical characteristics of the training set and the test sets are listed in supplementary materials.\n\nThe data was collected and used under the guidelines and regulations of the respective medical centers and ethical approvals obtained for the study. However, due to privacy and confidentiality concerns, the raw data is not released in a public forum. Access to the data is restricted and controlled to ensure the protection of patient information. The specific details about the data splits and the enforcement of data access are not disclosed to maintain the integrity and confidentiality of the dataset.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is deep natural language processing, specifically leveraging models like BERT. These models are not entirely new but have been adapted and optimized for our specific application in analyzing sonographic text reports for thyroid cancer diagnosis.\n\nThe choice to publish in a medical journal rather than a machine-learning journal is driven by the primary focus of our research. Our work is centered on improving the diagnosis of thyroid cancer, and the deep learning algorithms are a means to achieve this medical goal. The application of these algorithms to clinical data and the resulting improvements in diagnostic accuracy are the core contributions of our study.\n\nThe self-attention modules in BERT, for instance, are particularly useful for understanding the relationships among different entities in text notes, which is crucial for linking text notes to disease phenotypes. This capability enhances the recognition of entities and clinical concepts, providing a better understanding of clinical natural language processing tasks.\n\nIn summary, while the deep learning algorithms themselves are not novel, their application to sonographic text reports for thyroid cancer diagnosis is a significant contribution to the medical field. This approach represents a transfer of human intelligence to artificial intelligence, aiming to improve diagnostic accuracy and assist radiologists in their work.",
  "optimization/meta": "The meta-predictor employed in this study leverages the concept of model ensembling, specifically utilizing the last five iterations of the THCaDxNLP models. This approach involves combining the prediction probabilities from multiple models to enhance overall performance.\n\nThe meta-predictor uses the area under the receiver operating characteristic curve (AUROC) of these five models on an internal validation set as weights. For a given individual, the AUROC value of the ith model is denoted as w_i, and the probability predicted to be THCA by the ith model is denoted as P_i. The ensemble probabilities from these five models are calculated as the weighted sum of the individual model probabilities, where the weights are the AUROC values.\n\nThis method ensures that the meta-predictor benefits from the strengths of multiple models, potentially improving the robustness and accuracy of the predictions. The use of AUROC as weights indicates a focus on the models' discriminative ability, which is crucial for distinguishing between different classes in the dataset.\n\nThe training data for the individual models is independent, as they are evaluated on an internal validation set. This independence is essential for ensuring that the meta-predictor's performance is not biased by overlapping data, thereby maintaining the integrity of the model ensembling process.",
  "optimization/encoding": "In our study, the data encoding process was meticulously designed to ensure that the machine-learning algorithm could effectively learn from the unstructured electronic health record (EHR) data. The primary focus was on radiological text reports, which were used to develop semantic representations.\n\nThe first step involved collecting a vast amount of ultrasonographic text reports, totaling 788,129 entries. These reports were then pre-processed to clean and standardize the text data. This included removing any irrelevant information, correcting spelling errors, and normalizing the text to a consistent format. Tokenization was performed to break down the text into individual words or subwords, which are the basic units for our model.\n\nTo obtain semantic representations, we developed EhrBERT, a model pre-trained on the extensive EHR data. This pre-training allowed the model to learn robust and transferable representations from the text data. The advantages of pre-training included providing a good initial point for easier optimization, enhancing robustness to overfitting, and ensuring that the learned representations were highly transferable for downstream tasks.\n\nThe encoded data was then used to train THCaDxNLP, a deep natural language processing algorithm designed to identify thyroid cancer patients. The performance of THCaDxNLP was evaluated across five test sets, demonstrating its effectiveness in classifying thyroid cancer cases.\n\nOverall, the data encoding process involved thorough pre-processing, tokenization, and pre-training on a large dataset to ensure that the machine-learning algorithm could accurately and efficiently identify thyroid cancer patients from radiological text reports.",
  "optimization/parameters": "In our study, the model ensembling process involved combining the prediction probabilities of the last 5 THCaDxNLP models. The number of parameters, p, used in the model ensembling process is equal to the number of models being ensembled, which is 5.\n\nThe selection of these 5 models was based on their performance on the internal validation set, specifically using the area under the receiver operating characteristic curve (AUROC) as the metric. The AUROC values of these models were used as weights to combine the prediction probabilities, ensuring that models with better performance contributed more to the final ensemble prediction.\n\nThe ensemble probabilities were calculated using a weighted sum of the individual model probabilities, where the weights were the AUROC values of the respective models. This approach leverages the strengths of multiple models to improve the overall performance and robustness of the predictions.",
  "optimization/features": "The input features for our model primarily consist of radiologic text reports of thyroid examinations. Specifically, we utilized 788,129 tokenized radiologic text reports of thyroid examinations to develop our language representation model, EhrBERT. This model was then fine-tuned using a task-specific dataset to create THCaDxNLP, a deep learning model designed to identify thyroid cancer via radiologic text reports.\n\nFeature selection was not explicitly mentioned as a separate step in our process. Instead, we focused on developing a robust language representation model using a large dataset of radiologic text reports. This approach allowed us to capture semantic representations directly from the text data, which were then used to train our thyroid cancer identification model.\n\nThe training set consisted of 132,277 thyroid sonographic text reports, which included a mix of non-cancerous diseases, doctor-directed controls, and thyroid cancer cases. This comprehensive dataset ensured that our model was trained on a diverse range of text reports, enhancing its ability to generalize and perform well across different test sets.\n\nIn summary, the input features for our model are derived from a large corpus of radiologic text reports, and the development process did not involve a distinct feature selection step. The training set was used exclusively for model development, ensuring that the evaluation on test sets was unbiased.",
  "optimization/fitting": "In our study, we employed model ensembling techniques to combine the predictions of the last five THCaDxNLP models. This approach allowed us to leverage the strengths of multiple models, potentially reducing the risk of overfitting that can occur when a single model is overly complex relative to the number of training points.\n\nTo address the potential issue of overfitting, we utilized the area under the receiver operating characteristic curve (AUROC) of these models on an internal validation set as weights to combine their prediction probabilities. This method ensures that models with better performance on the validation set contribute more to the final ensemble prediction, thereby mitigating the impact of any individual model that might have overfitted to the training data.\n\nThe ensemble probabilities were calculated by summing the weighted probabilities from the five models. This process helps in smoothing out the predictions and reducing the variance, which is a common strategy to prevent overfitting.\n\nRegarding underfitting, our approach of using multiple models and weighting them based on their validation performance helps in capturing a broader range of patterns in the data. Each model in the ensemble might capture different aspects of the data, and by combining them, we ensure that the ensemble model is robust and generalizes well to unseen data.\n\nAdditionally, the use of a large and diverse dataset for training, which included 132,277 thyroid sonographic text reports, helps in reducing the risk of underfitting. The dataset comprised a significant number of both THCA patients and controls, providing a comprehensive training ground for our models.\n\nIn summary, our ensembling method, combined with the use of a large and diverse dataset, helps in balancing the trade-off between overfitting and underfitting, ensuring that our models are both robust and generalizable.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key approach was the use of pre-trained models, specifically EhrBERT, which was developed using a large dataset of 788,129 ultrasonographic text reports. Pre-training provided a good initial point for optimization, making the model more robust to overfitting and allowing for more transferable representations learned from the electronic health record (EHR) data.\n\nAdditionally, we utilized model ensembling for the final five THCaDxNLP models. This involved combining the prediction probabilities of these models using their area under the receiver operating characteristic curve (AUROC) values on the internal validation set as weights. This ensembling technique helped to improve the overall performance and generalization of the model by leveraging the strengths of multiple models.\n\nThese methods collectively contributed to the development of a reliable and effective model for identifying thyroid cancer patients from unstructured EHR data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules used in our study are detailed within the publication. Specifically, the EhrBERT model was developed for 1 million steps using the Bertadam optimizer, with a batch size of 128 and cosine learning rate decay scheduling starting at an initial learning rate of 0.0001. For the THCaDxNLP model, fine-tuning was conducted for 8 epochs with the Bertadam optimizer, a cosine learning rate decay schedule starting at 5e-5, and a batch size of 16.\n\nThe exact model files and optimization parameters are not explicitly provided in the publication. However, the methods and configurations described are sufficient for replication by other researchers. The study was conducted in accordance with ethical guidelines, and the data used were approved by the institutional review board. While specific model files may not be directly available, the detailed descriptions of the training processes and hyper-parameters should enable other researchers to reproduce the models.\n\nRegarding the availability and licensing of the data and models, the publication does not specify the exact terms under which the data or models might be shared. However, it is standard practice in academic research to make data and models available upon reasonable request, often with appropriate ethical and legal considerations in place. Researchers interested in accessing the specific datasets or models used in this study should contact the corresponding authors for further details and potential collaboration.",
  "model/interpretability": "The model developed in our study, THCaDxNLP, leverages deep learning approaches, specifically BERT, which are known for their interpretability through self-attention mechanisms. Unlike traditional black-box models, THCaDxNLP offers insights into how it processes and understands text data.\n\nThe self-attention modules in BERT allow for the representation of a sentence by attending to different positions within that sentence. This mechanism generates an attention score matrix that quantifies the associations among words. By parsing this matrix, it is possible to recognize entities and clinical concepts, thereby providing a clearer understanding of the model's decision-making process.\n\nFor instance, when analyzing radiological text reports, the attention scores can highlight which words or phrases are most influential in determining the likelihood of thyroid cancer. This transparency is crucial for clinical applications, as it allows radiologists to trust and validate the model's predictions. Moreover, it enables researchers to explore and understand the relationships among different entities within the text, enhancing the overall interpretability of the model.\n\nIn summary, THCaDxNLP is not a black-box model. Its use of self-attention mechanisms in BERT provides a transparent and interpretable framework, making it a valuable tool for differential diagnoses of thyroid cancer.",
  "model/output": "The model employed in this study is a classification model. It is designed to distinguish between two categories: malignant and benign. The output of the model is a probability score indicating the likelihood of a sample being malignant or benign. This probability score ranges from 0 to 1, with values closer to 1 suggesting a higher likelihood of malignancy and values closer to 0 indicating a higher likelihood of benignity. The model's predictions are then categorized as either malignant or benign based on a threshold, which is typically set at 0.5. This classification approach allows for the effective differentiation between the two types of samples, providing valuable insights for further analysis and decision-making.",
  "model/duration": "The execution time for the models developed in this study can be inferred from the training details provided. The EhrBERT model was trained for 1 million steps with a batch size of 128. The THCaDxNLP model, built upon the pretrained EhrBERT, was fine-tuned for 8 epochs with a batch size of 16. The specific hardware used for training is not detailed, but these parameters give an idea of the computational effort involved.\n\nThe training of EhrBERT for 1 million steps indicates a significant amount of computational time, depending on the hardware specifications. Similarly, fine-tuning THCaDxNLP for 8 epochs with the given batch size would also require considerable time, especially when dealing with a large dataset of 172,792 sonographic radiological reports.\n\nThe exact execution time in hours or days is not specified, but the training process for both models was extensive, reflecting the complexity and scale of the data processed. The use of advanced optimizers like Bertadam and cosine learning rate decay scheduling further suggests a focus on optimizing the training time and model performance.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the THCaDxNLP model involved a comprehensive assessment using multiple datasets and metrics. The primary metric used to measure the performance of the model was the Area Under the Receiver Operating Characteristic Curve (AUROC). The ROC curve was generated by plotting sensitivity against specificity at various predicted probability thresholds.\n\nIn addition to AUROC, several other metrics were calculated to evaluate the model's performance. These included accuracy, sensitivity, specificity, positive predictive value, negative predictive value, kappa coefficient, and the F1 metric. The F1 metric was computed as the harmonic average of precision and sensitivity, providing a single score that balances both concerns.\n\nConfidence intervals for sensitivity, specificity, positive predictive value, and negative predictive value were determined using the Clopper-Pearson method. The inter-radiologist agreement and Fleiss\u2019 kappa were also calculated to assess the consistency among radiologists.\n\nThe evaluation process involved comparing the classification performance of radiologists with and without the aid of THCaDxNLP. A one-sided t-test was employed to determine if radiologists using THCaDxNLP achieved significantly higher classification performances.\n\nThe datasets used for evaluation consisted of ultrasonographic radiological texts from various hospitals, including TMUCIH, Tianjin Medical University General Hospital, Tianjin Fourth Central Hospital, Weihai Municipal Hospital, and Chengde Hospital. These datasets were used to create test sets that were read by radiologists, both with and without the assistance of THCaDxNLP. The radiologists' working experience ranged from 6 to 28 years, ensuring a diverse and experienced pool of evaluators.\n\nStatistical analysis was conducted using R software, version 3.4.3, with specific packages such as pROC for ROC curve analysis and irr for kappa calculations. The training and evaluation of the EhrBERT model and THCaDxNLP were performed using MXNet, version 1.5.1, and GluonNLP, version 0.8.1. This rigorous evaluation methodology ensured a thorough assessment of the model's effectiveness in improving the diagnosis of thyroid cancer.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report a comprehensive set of metrics to evaluate the classification performance of radiologists, with and without the aid of THCaDxNLP. The metrics include accuracy, sensitivity, specificity, positive predictive value, negative predictive value, Kappa, and F1 score. These metrics are presented with their respective 95% confidence intervals to provide a clear understanding of the variability and reliability of the results.\n\nAccuracy measures the overall correctness of the classifications made by the radiologists. Sensitivity, also known as recall or true positive rate, indicates the proportion of actual positives that are correctly identified. Specificity, or the true negative rate, represents the proportion of actual negatives that are correctly identified. The positive predictive value (PPV) and negative predictive value (NPV) provide insights into the probability that a positive or negative test result is a true positive or true negative, respectively.\n\nKappa is a statistical measure that assesses the agreement between the predicted classifications and the pathological reports, adjusting for the agreement that could be expected by chance. The F1 score is the harmonic average of precision and recall, providing a single metric that balances both concerns.\n\nThis set of metrics is representative of standard practices in the literature for evaluating classification performance in medical diagnostics. By including a wide range of metrics, we aim to provide a thorough evaluation that considers various aspects of performance, ensuring that the results are robust and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we focused on developing and evaluating the THCaDxNLP model for differential diagnoses of thyroid cancer (THCA) based on the clinical expertise of sonographic radiologists. The primary aim was to leverage deep learning to enhance the diagnostic capabilities of radiologists by analyzing unstructured sonographic electronic health record (EHR) data.\n\nWe did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, our approach was to internalize the expertise of radiologists through the analysis of a large volume of radiological text reports. This method allowed us to transfer human intelligence to artificial intelligence, creating a model that could assist in the diagnosis of THCA.\n\nRegarding simpler baselines, our study did not explicitly compare THCaDxNLP to simpler baselines. The focus was on the development and evaluation of a deep natural language processing algorithm that could efficiently extract clinically relevant information from radiological text reports. The performance of THCaDxNLP was assessed through detailed classification metrics, including accuracy, sensitivity, specificity, positive predictive value, negative predictive value, Kappa, and F1 score. These metrics were evaluated across different test sets, providing a comprehensive understanding of the model's diagnostic capabilities.\n\nFuture work may include integrating THCaDxNLP with deep learning models learned from thyroid sonographic imaging data, combining human and machine intelligence to further improve the differential diagnosis of THCA. Additionally, the study paradigm could be applied to other languages, and language-specific models could be developed with advancements in language translation.",
  "evaluation/confidence": "The evaluation of our method includes a comprehensive analysis of performance metrics with associated confidence intervals. These intervals provide a range within which the true value of the metric is expected to lie, offering a measure of the uncertainty around the point estimates.\n\nFor instance, accuracy, sensitivity, specificity, positive predictive value, and negative predictive value are all reported with 95% confidence intervals. This allows for a more nuanced understanding of the results, indicating the reliability and precision of the estimates.\n\nStatistical significance is also a crucial aspect of our evaluation. We have conducted comparisons between radiologists aided with our tool and those without, using appropriate statistical tests. The p-values associated with these tests help determine whether the observed differences in performance metrics are likely due to chance or represent a true effect.\n\nFor example, the p-values for accuracy, sensitivity, specificity, positive predictive value, negative predictive value, Kappa, and F1 metrics are provided. These values indicate the level of statistical significance, with lower p-values suggesting stronger evidence against the null hypothesis, which typically states that there is no difference between the groups being compared.\n\nIn summary, our evaluation includes confidence intervals for key performance metrics and statistical significance testing to support the claim that our method is superior to others and baselines. This rigorous approach ensures that our findings are robust and reliable.",
  "evaluation/availability": "Not enough information is available."
}