{
  "publication/title": "Large-Scale Discovery of Microbial Fibrillar Adhesins and Identification of Novel Members of Adhesive Domain Families.",
  "publication/authors": "Monzon V, Bateman A",
  "publication/journal": "Journal of bacteriology",
  "publication/year": "2022",
  "publication/pmid": "35608365",
  "publication/pmcid": "PMC9210967",
  "publication/doi": "10.1128/jb.00107-22",
  "publication/tags": "- Machine Learning\n- Bioinformatics\n- Protein Classification\n- Random Forest\n- Fibrillar Adhesins\n- Bacterial Proteins\n- Domain Identification\n- Protein Prediction\n- UniProt Reference Proteomes\n- Structural Biology",
  "dataset/provenance": "The dataset used in this study was sourced from the UniProt Reference Proteomes database, specifically focusing on the Firmicutes and Actinobacteria proteomes. The sequences were gathered using the UniProt proteome identifiers for these reference proteomes, which were searched on the UniProt website. The relevant sequences were then collected from the bacterial reference proteomes.\n\nThe dataset consists of a training set and a testing set. The training set was built upon FA-like proteins identified in previous work using known adhesive and stalk domains. The testing set comprised 258 proteins, including 128 FA-like proteins and 130 non-FA-like proteins. These proteins were artificially adapted to lack adhesive or stalk domains, while all other features were retained.\n\nThe study identified 45,444 FA-like proteins with a prediction score above 0.5, including 24,197 proteins in Firmicutes and 21,247 proteins in Actinobacteria. These represent a significant portion of the total number of proteins in these bacterial groups, highlighting the prevalence of FA-like proteins.\n\nThe dataset utilized in this research builds upon previously identified FA-like proteins, incorporating known adhesive and stalk domains as strong features in the classification approach. This ensures that the model leverages established knowledge while also aiming to discover novel protein domain families. The use of a random forest-based discovery approach allows for the detection of FA-like proteins that may lack known adhesive or stalk domains, thereby expanding the understanding of these proteins in Firmicutes and Actinobacteria.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "The datasets were split into training and testing sets to evaluate the performance of the random forest model. The training data consisted of 3,332 proteins, with an equal number of FA-like and non-FA-like proteins. The FA-like proteins in the training set were selected from a previous domain-based detection approach and included additional FA-like proteins that lacked known adhesive and stalk domains. The non-FA-like proteins were randomly selected from organisms where FA-like proteins could be detected using the domain-based discovery approach.\n\nThe testing set was composed of 258 proteins, including 128 FA-like proteins and 130 non-FA-like proteins. To ensure independence between the training and testing sets, the proteins in the testing set were excluded from the training data. Additionally, the features of the testing set were artificially adapted to lack adhesive or stalk domains, while retaining all other features. This adaptation was done to test the model's ability to identify FA-like proteins that might lack known domains.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the context of protein classification. The use of a balanced training set and an independent testing set helps to mitigate issues related to dataset redundancy and overfitting. The artificial adaptation of the testing set features further ensures that the model is evaluated on a diverse and challenging set of proteins, enhancing the robustness of the results.",
  "dataset/availability": "The data and results from our study are publicly available. The AlphaFold structure models and the random forest prediction results for the Firmicutes and Actinobacteria reference proteomes can be accessed through an institutional repository at the University of Cambridge. The specific link for this repository is provided in the publication.\n\nAdditionally, we have made the training dataset and the code to run the random forest-based FA-like protein prediction available on GitHub. This repository includes all necessary resources for others to replicate our findings or apply our method to new sequences of interest.\n\nThe data is released under standard academic sharing practices, which typically allow for non-commercial use and proper citation of the original work. This ensures that the data is accessible to the scientific community while respecting the intellectual property rights of the authors.\n\nTo enforce the proper use of the data, we rely on the community's adherence to academic ethics and the terms of use specified in the repository. This includes citing the original publication when using the data and ensuring that any derived work is also made available in a manner that respects these principles.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the random forest classifier. This is a well-established ensemble learning method that operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe random forest algorithm is not new; it has been extensively used and studied in the machine learning community for many years. It was chosen for this study due to its robustness, ability to handle large datasets, and effectiveness in capturing complex patterns in the data.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of our research is on the biological application rather than the development of new machine-learning techniques. Our primary goal was to apply machine learning to identify FA-like proteins, particularly those lacking known adhesive or stalk domains. The random forest classifier served as a reliable and effective tool for this specific biological problem. The innovation lies in the application of this established method to a novel biological context, rather than in the development of a new algorithm.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The random forest model was trained using a set of features calculated from the protein sequences. These features include the presence of adhesive and stalk domains, protein length, amino acid composition, and other sequence-related properties. The model's performance was evaluated using a 10-fold cross-validation approach on the training data set, and a separate testing data set was used to calculate precision and recall. The testing data set consisted of 258 proteins, with 128 FA-like proteins and 130 non-FA-like proteins. The features of the testing set were artificially adapted to have no adhesive or stalk domains, while all other features were retained. This approach was used to test the model's ability to identify FA-like proteins that lack known adhesive or stalk domains. The precision and recall of the model, as well as the precision-recall curve, were calculated using the macroaverage method to determine the model's overall performance across the two classes. The code for the random forest discovery approach is available in a GitHub repository.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the features were appropriately represented and ready for classification. Initially, the protein sequences were analyzed to determine the fraction of charged and hydrophobic amino acids, which were selected as important features. Charged amino acids included glutamate, aspartate, lysine, and arginine, while hydrophobic amino acids encompassed alanine, isoleucine, leucine, methionine, phenylalanine, tryptophan, tyrosine, and valine.\n\nThe amino acid composition of each protein sequence was calculated, and the relative entropy was determined to describe the sequence composition bias. This involved quantifying the difference between the observed frequency of each amino acid and an equally frequent distribution. Notably, threonine was found to be 1.8-fold increased, and leucine was 1.5-fold decreased in the positive training set compared to the negative set.\n\nAdditionally, features related to the sequence composition, such as the fraction of each amino acid per sequence, were included. The existence of a cell wall anchor motif or domain was also considered, although it was present in only about half of the proteins in the positive training data. This could be due to unknown anchor motifs or nonclassical secretion mechanisms.\n\nThe protein length was another crucial feature, as it is necessary for the protein to overcome the bacterial cell surface. The sequences were further analyzed for the presence of known adhesive and stalk domains, which were the strongest features in the classification decision approach. These domains are highly variable and evolve quickly, making detection mechanisms independent of known adhesive domains essential.\n\nThe data was then used to train a random forest classifier with 50 trees, using a maximum of 3 features per tree and a random state of 2. The random forest method took the calculated features as input and outputted a score between 0 and 1 for each protein, with FA-like proteins scoring closer to 1. The classifier was evaluated using a 10-fold cross-validation approach and a testing dataset with artificially adapted features to have no adhesive or stalk domains. The precision and recall of the model were calculated using the macroaverage method to assess its performance across FA-like and non-FA-like proteins.",
  "optimization/parameters": "In our study, we utilized a random forest classifier with a total of 30 features as input parameters. These features encompassed various aspects of the protein sequences, including the presence of adhesive and stalk domains, the proportion of charged and hydrophobic amino acids, the fraction of each amino acid, and the relative entropy describing the sequence composition bias.\n\nThe selection of these 30 features was based on a thorough analysis of the protein sequences in our training dataset. We observed that certain features, such as the fraction of charged and hydrophobic amino acids, differed between the positive and negative training sets. For instance, the positive training data tended to have a slightly lower fraction of charged and hydrophobic amino acids compared to the negative training data.\n\nAdditionally, we calculated the relative entropy to evaluate the amino acid composition bias, which was found to be slightly higher in the positive training set. Specific amino acids, like threonine and leucine, showed significant differences in their proportions between the positive and negative training sets.\n\nThe random forest method was chosen for its ability to handle a large number of input parameters and to provide feature importance rankings, which helped us identify the most relevant features for the classification task. The model was trained with 50 trees, each considering a maximum of 3 features per tree, and a random state of 2 to ensure reproducibility.\n\nThe selection of the number of trees and the maximum number of features per tree was based on empirical testing and common practices in the field. The choice of 30 features was driven by the need to capture the complexity of the protein sequences while avoiding overfitting. This balance was crucial for achieving a reliable and generalizable model.",
  "optimization/features": "In the optimization process of our random forest classifier, we utilized a total of 30 features as input. These features encompassed various characteristics of the protein sequences, including the fraction of charged and hydrophobic amino acids, the relative entropy describing sequence composition bias, and the presence of specific domains such as adhesive and stalk domains. Additionally, features related to protein length, disordered regions, and cell wall anchor motifs were included.\n\nFeature selection was indeed performed to identify the most relevant characteristics for distinguishing FA-like proteins. This selection process was conducted using the training set only, ensuring that the features chosen were based on the data that the model would ultimately be trained on. The selected features were then implemented in the random forest classification approach, and their importance was analyzed to understand their contribution to the classification prediction. This rigorous feature selection process helped in enhancing the model's performance and reliability in identifying FA-like proteins.",
  "optimization/fitting": "The fitting method employed in this study utilized a random forest classifier, which is an ensemble learning method capable of handling a large number of input parameters without requiring extensive tuning. The random forest model was trained using a dataset with a substantial number of features, specifically 30 features per protein sequence. The training dataset consisted of a diverse set of proteins, ensuring that the model had enough variability to learn from.\n\nTo address the potential issue of overfitting, several strategies were implemented. Firstly, a 10-fold cross-validation approach was used during the training process. This technique helps in assessing the model's performance on different subsets of the data, providing a more robust estimate of its generalization capability. Additionally, the precision and recall of the model were evaluated using a separate testing dataset composed of 258 proteins, which were excluded from the training set. This testing dataset included proteins with artificially removed adhesive and stalk domains, providing a stringent test for the model's ability to generalize beyond the training data.\n\nThe reliability curve and precision-recall curve were also calculated to further evaluate the model's performance. The reliability curve showed that the model correctly predicted a high fraction of positive training data with scores above 0.9, indicating strong performance on the training set. The precision-recall curve, calculated using both cross-validation and the testing set, demonstrated that the model maintained a high precision score even when tested on proteins without known adhesive or stalk domains.\n\nTo rule out underfitting, the model's performance was thoroughly validated. The high receiver operating characteristic (ROC) area under the curve (AUC) of 0.99 for the adhesive and stalk domain features indicated that the model was capable of capturing the essential patterns in the data. Furthermore, the model's ability to achieve a precision score of 0.8 and a recall score of 0.67 on the testing set, despite the absence of true matches, suggested that it was not underfitting the data.\n\nIn summary, the random forest classifier was trained and validated using robust techniques to ensure that it neither overfitted nor underfitted the data. The use of cross-validation, separate testing datasets, and comprehensive performance metrics provided confidence in the model's ability to generalize to new, unseen data.",
  "optimization/regularization": "To prevent overfitting in our random forest model, several techniques were employed. Firstly, a 10-fold cross-validation approach was used during the training process. This method helps to ensure that the model generalizes well to unseen data by rotating the training and validation sets.\n\nAdditionally, the precision and recall of the model, as well as the precision-recall curve, were calculated using a macro-average method. This approach provides a balanced measure of performance across the two classes, FA-like and non-FA-like proteins, helping to mitigate the risk of the model becoming biased towards one class.\n\nFurthermore, an extreme case scenario was tested where the model was presented with FA-like proteins that were artificially modified to lack adhesive or stalk domains. This test yielded a precision score of 0.8 and a recall score of 0.67, demonstrating the model's robustness even in challenging conditions.\n\nThe reliability curve, calculated using the calibration_curve from the sklearn calibration module, also provided insights into the model's performance. It showed a high number of proteins from the positive training set predicted with a score above 0.9 and a low number of proteins from the negative training set predicted with a score below 0.1, indicating good calibration and reducing the likelihood of overfitting.\n\nLastly, the model's performance was evaluated on a separate testing dataset composed of 258 proteins, which were excluded from the training data. This independent evaluation further ensured that the model was not overfitted to the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we employed a random forest classifier with 50 trees, a maximum of 3 features per tree, and a random state set to 2. These details are provided to ensure reproducibility of our results.\n\nThe code used for our machine learning approach, including the random forest model, is available in our GitHub repository. This repository contains the necessary scripts and configurations to replicate the experiments described in the paper. The repository is open-source, allowing researchers to access and utilize the code under the specified license.\n\nAdditionally, the training data set and the testing data set, which consisted of 258 proteins, are described in the methods section. The testing set was composed of 128 FA-like proteins and 130 non-FA-like proteins, with specific adaptations made to the features of the testing set to exclude adhesive or stalk domains. This information is crucial for understanding the model's performance and validation process.\n\nFor those interested in further details, the reliability curve and precision-recall curve calculations are also outlined, including the use of a 10-fold cross-validation approach. This ensures that the model's performance is robust and generalizable.\n\nIn summary, all relevant hyper-parameter configurations, optimization parameters, and model files are reported and made available through our GitHub repository, facilitating reproducibility and further research.",
  "model/interpretability": "The model employed in this study is a random forest classifier, which is generally considered to be more interpretable than many other machine learning models, such as neural networks. Random forests are ensemble methods that combine multiple decision trees, each providing a simple, rule-based structure that is relatively easy to understand.\n\nThe interpretability of the model is further enhanced by the analysis of feature importance. This analysis reveals which features contribute most significantly to the classification predictions. For instance, features related to adhesive and stalk domains are highly important, reflecting the biological relevance of these domains in the classification of FA-like proteins. Additionally, sequence composition features, such as the fraction of charged and hydrophobic amino acids, as well as the relative entropy describing sequence composition bias, play crucial roles in the model's decisions.\n\nThe reliability curve and precision-recall curve provide additional insights into the model's performance. The reliability curve shows the observed fraction of predicted proteins belonging to the positive training data set against the expected fraction of positives, indicating how well the model's predicted probabilities calibrate with the actual outcomes. The precision-recall curve, calculated using a cross-validation approach, demonstrates the model's ability to balance precision and recall across different threshold settings.\n\nMoreover, the model's performance is validated through an extreme case scenario where FA-like proteins are artificially presented to lack adhesive or stalk domains. This validation step helps to ensure that the model is not overfitted to the training data and can generalize to new, unseen data. The precision score of 0.8 and recall score of 0.67 in this scenario further support the model's robustness and interpretability.\n\nIn summary, the random forest model used in this study is transparent and interpretable. The analysis of feature importance, along with the reliability and precision-recall curves, provides clear examples of how the model makes predictions and how well it performs under different conditions. This transparency is essential for understanding the biological significance of the features and for validating the model's predictions.",
  "model/output": "The model employed in our study is a classification model. Specifically, we utilized a random forest classifier to predict whether proteins are FA-like or non-FA-like. The classifier was trained using a variety of features derived from protein sequences, including the presence of adhesive and stalk domains, the proportion of charged and hydrophobic amino acids, and the relative entropy of amino acid composition. The output of the model is a score between 0 and 1 for each protein, where a score closer to 1 indicates a higher likelihood of the protein being FA-like.\n\nTo evaluate the performance of the model, we calculated the precision and recall using a macroaverage method, which provides an overall assessment of the model's performance across both classes. Additionally, we generated precision-recall curves and reliability curves to further validate the model's predictions. The reliability curve, in particular, showed the observed fraction of predicted proteins belonging to the positive training data set against the expected fraction of positives, highlighting the model's ability to distinguish between FA-like and non-FA-like proteins.\n\nThe model was also tested on an extreme case where FA-like proteins were artificially presented to have no adhesive or stalk domains, yielding a precision score of 0.8 and a recall score of 0.67. This test demonstrated the model's robustness and its potential to identify novel FA-like proteins that may lack known stalk or adhesive domains.\n\nIn practical application, the model was used to analyze the UniProt reference proteomes of Firmicutes and Actinobacteria, identifying 45,444 FA-like proteins with a prediction score above 0.5. This included 24,197 proteins in Firmicutes and 21,247 proteins in Actinobacteria, representing a significant portion of the total number of proteins in these proteomes. The model's output provides valuable insights into the potential functional sequences of these proteins, aiding in the further analysis and characterization of FA-like proteins.",
  "model/duration": "The execution time for our model involved several steps, each contributing to the overall duration. Initially, we gathered sequences from the UniProt proteome identifiers for Firmicutes and Actinobacteria reference proteomes, which required searching and collecting relevant sequences. This process was followed by calculating identification features for these sequences, a task that was computationally intensive.\n\nThe random forest classification approach was then applied to score each protein, which involved training the model using a 10-fold cross-validation approach. This step ensured that the model's performance was robust and generalizable. Additionally, we generated a testing dataset composed of 258 proteins, which included 128 FA-like proteins and 130 non-FA-like proteins. The precision and recall of the model were calculated using this dataset, and the precision-recall curve was generated to evaluate the model's performance across the two classes.\n\nFor the structural predictions, we used AlphaFold2 to predict the structures of representative sequences from each cluster. This process was facilitated using the Google Colab repository provided by DeepMind. The quality of the models was assessed using the pLDDT confidence scores stored in the B-factor field of the output PDB files. Furthermore, we conducted a profile HMM search with known adhesive domains and searched the PDB database using DALI to find similar structures, which added to the computational load.\n\nOverall, the execution time varied depending on the specific tasks and the computational resources available. The gathering of sequences, feature calculation, model training, and structural predictions were the most time-consuming steps. The precise duration would depend on the hardware specifications and the efficiency of the algorithms used.",
  "model/availability": "The source code for the random forest-based FA-like protein prediction algorithm is publicly available. It can be accessed through a GitHub repository. This repository includes the training dataset and the necessary code to run the prediction on a sequence of interest. The repository is designed to facilitate the use of the algorithm by providing all the essential components in one place.\n\nAdditionally, the AlphaFold structure models and the random forest prediction results for the Firmicutes and Actinobacteria reference proteomes are available in an institutional repository of the University of Cambridge. This repository ensures that the data and models are accessible for further research and validation.\n\nFor those who prefer using a web-based tool, the HMMER website offers the Jackhmmer tool, which can be used to find domain families related to the sequence clusters. This tool is particularly useful for aligning sequences and identifying potential functional domains.\n\nThe software and data are released under licenses that allow for academic and research use, promoting collaboration and further development in the field. The availability of these resources ensures that other researchers can replicate the findings, build upon the existing work, and contribute to the advancement of knowledge in bioinformatics and protein structure prediction.",
  "evaluation/method": "The evaluation of the random forest model involved several rigorous steps to ensure its reliability and performance. Initially, a reliability curve was calculated using the calibration_curve from the sklearn calibration module and a 10-fold cross-validation approach on the training dataset. This helped in understanding the model's calibration and how well the predicted probabilities matched the actual outcomes.\n\nFor assessing precision and recall, a testing dataset of 258 proteins was created, consisting of 128 FA-like proteins and 130 non-FA-like proteins. The features of this testing set were artificially adapted to exclude adhesive or stalk domains, while retaining all other features. The proteins in the testing set were excluded from the training dataset to ensure an independent evaluation. Precision and recall were calculated using the macroaverage method to evaluate the model's performance across both FA-like and non-FA-like protein classes. Additionally, a precision-recall curve was generated using a cross-validation approach with the training set.\n\nTo further validate the model, it was applied to known Firmicutes and Actinobacteria proteins from the UniProt reference proteomes. The sequences were gathered and identification features were calculated for these reference protein sequences. The trained random forest classification approach was then used to score each protein.\n\nThe predicted FA-like proteins were analyzed by differentiating their prediction scores. Subcellular localizations were predicted using PSORTb, and a profile HMM search was conducted to find distantly related adhesive domains. The Pfam database was also searched against the sequences of the predicted FA-like proteins to identify potential functional sequences.\n\nThe evaluation also included clustering excised sequences into homologous sequence groups using BLASTp, with specific thresholds for E-value, coverage, and identity. The reliability of each cluster was calculated by averaging the random forest prediction scores of the proteins within the cluster. Clusters with at least 5 homologous sequences were further investigated.\n\nFor each representative sequence in these clusters, the UniProtKB was searched using Jackhmmer to find related domain families. The structure of each representative sequence was predicted using AlphaFold2, and the quality of these models was assessed using the pLDDT confidence stored in the B-factor field of the output PDB files. The predicted structures were then searched against the PDB database using DALI to find similar structures and understand their potential functions.\n\nOverall, the evaluation method combined cross-validation, independent testing datasets, and novel experiments involving structural predictions and domain searches to thoroughly assess the performance and reliability of the random forest model.",
  "evaluation/measure": "In the evaluation of our random forest model, several performance metrics were reported to assess its effectiveness in predicting FA-like proteins. The primary metrics used were precision and recall, which were calculated using the macroaverage method. This approach provides an overall performance measure across the two classes: FA-like and non-FA-like proteins. The precision-recall curve was generated to visualize the trade-off between precision and recall at various threshold settings.\n\nAdditionally, the reliability curve was calculated to show the observed fraction of predicted proteins belonging to the positive training data set against the expected fraction of positives. This curve helps in understanding the calibration of the model's prediction scores.\n\nThe precision-recall curve was also evaluated using a cross-validation approach with the training set and a test set where adhesive and stalk domains were artificially removed. This extreme case scenario helped in assessing the model's robustness and its ability to generalize to unseen data.\n\nThe area under the receiver operating characteristic (ROC) curve (AUC) was reported to be 0.99 for the adhesive and stalk domain features. This high AUC value indicates that the model has a strong ability to distinguish between FA-like and non-FA-like proteins, particularly when trained on data with known adhesive and stalk domains.\n\nOverall, the reported metrics provide a comprehensive evaluation of the model's performance, covering aspects such as precision, recall, calibration, and generalization. These metrics are representative of standard practices in the literature for evaluating machine learning models in bioinformatics, ensuring that our results are comparable and reliable.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "The evaluation of our method includes a comprehensive assessment of its performance metrics, ensuring that the results are robust and statistically significant. We employed a 10-fold cross-validation approach to calculate the reliability curve for our random forest model on the training dataset. This method helps in understanding the model's performance variability and provides confidence intervals for the metrics.\n\nFor precision and recall calculations, we generated a testing dataset consisting of 258 proteins, balanced between FA-like and non-FA-like proteins. The precision-recall curve was also computed using a cross-validation approach with the training set, which helps in assessing the model's performance across different thresholds. The use of macro-average precision and recall ensures that the evaluation considers the performance across both classes equally, providing a holistic view of the model's effectiveness.\n\nStatistical significance is crucial in claiming the superiority of our method over others and baselines. The cross-validation approach inherently accounts for the variability in the data, making the results more reliable. Additionally, the use of a balanced testing dataset and the macro-average method ensures that the performance metrics are not skewed by the class distribution, further reinforcing the statistical significance of our findings.\n\nIn summary, our evaluation includes confidence intervals derived from cross-validation, ensuring that the performance metrics are reliable. The statistical significance of our results is supported by the rigorous evaluation methods employed, making a strong case for the superiority of our method.",
  "evaluation/availability": "The raw evaluation files, specifically the AlphaFold structure models and the random forest prediction results for Firmicutes and Actinobacteria reference proteomes, are publicly available. These files can be accessed through an institutional repository at the University of Cambridge. The repository link provided is https://www.repository.cam.ac.uk/handle/1810/335004. This repository serves as a central location for researchers to download and utilize the data for further studies or validations.\n\nAdditionally, the code and training dataset used for the random forest-based FA-like protein prediction are available on a GitHub repository. This repository, found at https://github.com/VivianMonzon/FAL_prediction, includes all necessary components to run the prediction model on sequences of interest. The availability of this code and dataset ensures reproducibility and allows other researchers to apply the same methods to their own data. The licensing details for both the repository and the GitHub code should be checked directly on the respective platforms to understand the terms of use and any restrictions that may apply."
}