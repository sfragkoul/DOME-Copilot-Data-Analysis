{
  "publication/title": "Identification of sleep phenotypes in COPD using machine learning-based cluster analysis.",
  "publication/authors": "Razjouyan J, Hanania NA, Nowakowski S, Agrawal R, Sharafkhaneh A",
  "publication/journal": "Respiratory medicine",
  "publication/year": "2024",
  "publication/pmid": "38710399",
  "publication/pmcid": "PMC11218872",
  "publication/doi": "10.1016/j.rmed.2024.107641",
  "publication/tags": "- Chronic Obstructive Pulmonary Disease (COPD)\n- Sleep Parameters\n- Polysomnography\n- Machine Learning\n- Natural Language Processing\n- Mortality\n- Veterans Health Administration\n- Phenotypic Clusters\n- Sleep Efficiency\n- Total Sleep Time\n- Comorbidity Burden\n- Unsupervised Clustering\n- Longitudinal Study\n- Sleep Health\n- Data Science\n- COPD Phenotypes\n- Sleep Metrics\n- Sleep Quality\n- Sleep Disorders\n- Risk Stratification",
  "dataset/provenance": "The dataset utilized in our study is sourced from the national Veterans Health Administration (VHA) data, spanning from October 1999 to September 2020. This comprehensive dataset includes records of veterans who used the VA healthcare system and had documented sleep problems based on ICD-9 or ICD-10 codes. Specifically, we focused on patients who had undergone in-lab polysomnography (PSG) tests and had a confirmed diagnosis of Chronic Obstructive Pulmonary Disease (COPD) within three years of their PSG test date. The study exclusively used baseline polysomnogram test reports, excluding split-night or titration PSG tests and home sleep testing.\n\nThe dataset encompasses a large and diverse population of patients with sleep problems and confirmed COPD diagnoses, followed longitudinally for over two decades. This extensive dataset allowed for a robust analysis of sleep parameters and their impact on mortality in COPD patients. The use of validated natural language processing (NLP) algorithms ensured accurate extraction of sleep parameters from PSG physician interpretation notes, enhancing the reliability of our findings.\n\nThe dataset has not been used in previous publications by our group, but it has been utilized in other studies within the community for similar purposes. The comprehensive nature of the dataset, combined with the rigorous methodology and advanced data science modalities employed, provides valuable insights into the sleep health of patients in a real-world setting. This dataset's richness and the longitudinal follow-up period strengthen the validity and generalizability of our study's findings.",
  "dataset/splits": "Not applicable.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study falls under the class of unsupervised machine learning techniques. Specifically, we utilized the K-means clustering algorithm, which is a well-established method for partitioning data into distinct clusters based on feature similarity. This algorithm is not new; it has been widely used and validated in various fields for its effectiveness in identifying patterns and structures within data.\n\nThe choice of K-means clustering was driven by its robustness and simplicity, making it suitable for our objective of grouping patients into clusters based on sleep parameters, age, and comorbidity burden. The algorithm's ability to handle large datasets and its efficiency in computational terms were also crucial factors in its selection.\n\nGiven that K-means is a mature and extensively studied algorithm, publishing it in a machine-learning journal was not necessary. Instead, our focus was on applying this established method to a novel context\u2014identifying distinct phenotypic clusters of COPD patients based on sleep parameters and their association with mortality. This application provided valuable insights into the prognostic implications of these clusters in a real-world clinical setting, contributing to the broader understanding of COPD management and risk stratification.",
  "optimization/meta": "In our study, we employed a meta-predictor approach to enhance the reliability and validity of our findings. Specifically, we utilized a decision tree as a non-parametric supervised learning algorithm. This decision tree was built using the clusters identified through an unsupervised machine learning algorithm, namely K-means clustering. The K-means algorithm grouped patients into clusters based on key variables such as total sleep time (TST), sleep efficiency (SE), age, and Charlson Comorbidity Index (CCI).\n\nThe decision tree used the labels of these clusters as the dependent variable, while TST, SE, CCI, and age were considered as independent variables. This approach allowed the decision tree to perform both classification and regression simultaneously, providing a comprehensive understanding of the relationships between these variables and the identified clusters.\n\nTo ensure the robustness of our meta-predictor, we pruned the decision tree to reduce complexity and remove non-critical and redundant sections. This step was crucial for enhancing the tree's ability to classify instances accurately. The pruning process helped in focusing on the most relevant factors that contribute to the longevity and mortality rates within the clusters.\n\nRegarding the independence of the training data, it is important to note that the clusters were derived from an unsupervised learning process, which means that the data was grouped based on inherent patterns without any predefined labels or assumptions. This unsupervised approach ensured that the training data for the decision tree was independent and unbiased, as it was not influenced by any pre-existing knowledge or external labels.\n\nIn summary, our meta-predictor leverages the strengths of both unsupervised and supervised learning methods. The K-means clustering provided a foundational understanding of the data structure, while the decision tree refined this understanding by identifying key predictors and their interactions. This integrated approach strengthened the validity of our findings and provided a clear and reliable framework for analyzing the impact of sleep parameters and comorbidities on mortality in COPD patients.",
  "optimization/encoding": "For the machine-learning algorithm, several key variables were encoded and pre-processed to facilitate clustering and analysis. Total sleep time (TST) was scaled by dividing it by 10 minutes, which simplified the visualization and interpretation of the data. Sleep efficiency (SE) was divided by 2 to achieve a similar effect. Age was transformed by subtracting it from 100, allowing younger ages to be represented by higher numbers in the visualizations. The Charlson Comorbidity Index (CCI) was adjusted using the equation (7-CCI) * 10, where a higher number indicated a lower comorbidity burden. These transformations were applied to enhance the clarity and simplicity of the graphical representations, such as spider plots and three-dimensional graphs, which helped in understanding the relationships among the variables.\n\nAdditionally, sleep parameters were dichotomized using clinically relevant cutoffs. For instance, TST was categorized as \u2265300 minutes, SE as \u226580%, and the apnea-hypopnea index (AHI) was divided into ranges: <5, 5 to 15, 15 to 30, and \u226530. The Epworth Sleepiness Scale (ESS) was dichotomized at a score of \u226510. These cutoffs were used to provide a more clinically meaningful interpretation of the data.\n\nDemographic variables such as age were categorized into groups: <40, 40\u201365, and \u226565 years. Body mass index (BMI) was categorized as <18.5, 18.5\u201330, and \u226530. Race was categorized as White, Black, and Others. The CCI was dichotomized based on a cutoff of \u22652, which is associated with mortality in patients with COPD. These categorical variables were used in statistical analyses to compare demographic and clinical characteristics across different clusters.\n\nThe data was curated from a longitudinal observational study spanning over 20 years, utilizing the national Veterans Health Administration data. Sleep parameters were extracted using a validated natural language processing (NLP) algorithm from polysomnography physician interpretation notes, ensuring high precision, recall, and F-1 scores for the extracted metrics. This comprehensive dataset allowed for an unbiased identification of phenotypic clusters using unsupervised machine learning techniques, specifically K-means clustering with Euclidean distance. The elbow method was employed to determine the optimal number of clusters, ensuring that the clustering process was objective and data-driven.",
  "optimization/parameters": "In our study, we utilized four key parameters to group patients into distinct clusters. These parameters were total sleep time (TST), sleep efficiency (SE), age, and the Charlson Comorbidity Index (CCI). The selection of these parameters was driven by their established associations with mortality in patients with COPD and their relevance to sleep health.\n\nThe optimal number of clusters was determined using the elbow method, which is a common technique in unsupervised learning to identify the point of diminishing returns in the variance explained by the addition of more clusters. This method helped us to select the most appropriate number of clusters that best represented the underlying structure of the data.\n\nThe choice of these four parameters was informed by their clinical significance and the need to capture a comprehensive set of variables that could influence both sleep health and mortality outcomes in COPD patients. By focusing on these parameters, we aimed to create a robust model that could provide valuable insights into the phenotypic characteristics of COPD patients and their associated mortality risks.",
  "optimization/features": "In our study, we utilized a set of specific input features to perform clustering and subsequent analyses. The primary features used as input were total sleep time (TST), sleep efficiency (SE), age, and the Charlson Comorbidity Index (CCI). These features were selected based on their clinical relevance and potential impact on mortality in patients with COPD.\n\nFeature selection was not explicitly performed in the traditional sense, as we relied on domain knowledge to choose the most relevant variables. The selection of these features was guided by their known associations with mortality and their availability in the dataset. The features were chosen a priori based on literature review and clinical expertise, ensuring that they were relevant to the research questions.\n\nThe features were derived from a comprehensive set of polysomnographic variables and patient demographics. The data was curated from the national Veterans Health Administration (VHA) dataset, which included records from October 1999 to September 2020. The selection of these features was done independently of the training set, as they were chosen based on clinical and statistical considerations rather than through a data-driven feature selection process.\n\nIn summary, four key features\u2014TST, SE, age, and CCI\u2014were used as input for our analyses. These features were selected based on their clinical significance and were chosen independently of the training set, ensuring a robust and unbiased approach to our study.",
  "optimization/fitting": "The study utilized unsupervised machine learning techniques, specifically K-means clustering, to identify distinct phenotypic clusters of COPD patients based on sleep parameters. The number of parameters considered in the clustering process was relatively small, including total sleep time (TST), sleep efficiency (SE), age, and Charlson Comorbidity Index (CCI). These parameters were chosen for their clinical relevance and association with mortality in COPD patients.\n\nTo determine the optimal number of clusters, the elbow method was employed. This method involves plotting the sum of squared distances from each point to its assigned cluster center (within-cluster sum of squares) against the number of clusters and identifying the \"elbow\" point where the rate of decrease sharply slows. This approach helped in selecting the number of clusters that best represented the data structure without overfitting.\n\nOverfitting was mitigated by ensuring that the clusters were clinically meaningful and aligned with known associations between sleep parameters and mortality. The clusters were sorted based on mortality rates, and demographic and clinical characteristics were compared using appropriate statistical tests. Additionally, the decision tree analysis provided a clear and interpretable model that further validated the clustering results.\n\nUnderfitting was addressed by using a comprehensive set of variables derived from polysomnographic data, which were extracted with high precision using a validated natural language processing algorithm. The inclusion of relevant demographic and clinical variables, such as age, sex, race, and body mass index, ensured that the model captured the complexity of the data.\n\nThe study also employed Cox regression analysis to adjust for potential confounders and Kaplan-Meier estimates to visualize survival distributions, further strengthening the validity of the findings. The decision tree analysis, which performed both classification and regression, was pruned to reduce complexity and remove non-critical sections, ensuring that the model was neither too simple nor too complex.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method used was pruning in the decision tree analysis. Pruning helps to reduce the complexity of the final classifier by removing non-critical and redundant sections that do not contribute significantly to the classification power. This process ensures that the model generalizes well to new data rather than fitting noise in the training data.\n\nAdditionally, we utilized the elbow method to determine the optimal number of clusters in our K-means clustering analysis. This method helps in identifying the point of diminishing returns, where adding more clusters does not significantly improve the model's performance. By selecting the optimal number of clusters, we avoided overfitting by preventing the model from becoming too complex.\n\nFurthermore, we adjusted our Cox regression analysis for potential confounders such as age, BMI, sex, and race. This adjustment helps to control for variables that could otherwise lead to spurious associations, thereby enhancing the reliability of our findings.\n\nThese regularization techniques collectively ensured that our models were robust and generalizable, minimizing the risk of overfitting.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The model employed in this study is not a black box. To ensure transparency and interpretability, several techniques were utilized. One key approach was the use of unsupervised clustering techniques, specifically K-means clustering, which grouped patients into distinct clusters based on variables such as total sleep time (TST), sleep efficiency (SE), age, and Charlson Comorbidity Index (CCI). The optimal number of clusters was determined using the elbow method, providing a clear rationale for the chosen clustering structure.\n\nTo further enhance interpretability, a decision tree was applied as a non-parametric supervised learning algorithm. The decision tree used TST, SE, CCI, and age as independent variables to classify patients into different clusters. This method allowed for both classification and regression, providing a visual representation of how different variables contribute to the clustering. The decision tree was pruned to reduce complexity and remove non-critical sections, ensuring that the final classifier was both powerful and interpretable.\n\nAdditionally, three-dimensional graphs and spider plots were created to visualize the relationships among the determinants of longevity. These visualizations scaled variables such as TST and SE to enhance clarity, making it easier to understand how each factor contributes to the overall longevity and mortality rates within the clusters. For instance, the decision tree identified a TST threshold of \u2265278 minutes as a key factor in distinguishing between clusters with different longevity profiles.\n\nOverall, the use of clustering, decision trees, and visualizations ensured that the model's decisions were transparent and interpretable, allowing for a clear understanding of how different variables influence patient outcomes.",
  "model/output": "The model employed in this study is both classification and regression. A decision tree algorithm was utilized, which inherently supports both types of tasks. The decision tree was used to classify patients into distinct phenotypic clusters based on their sleep parameters and other variables. Simultaneously, it provided insights into the relationships and thresholds of these variables, effectively performing regression analysis. The tree was pruned to enhance its simplicity and effectiveness, ensuring that it accurately classified patients while removing non-critical sections. This dual capability allowed for a comprehensive understanding of how different factors contribute to the clustering and the associated mortality risks.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in our study was robust and multifaceted, ensuring the reliability and validity of our findings. We utilized a combination of statistical techniques and machine learning algorithms to assess the performance and generalizability of our models.\n\nFirstly, we validated our natural language processing (NLP) algorithm for extracting sleep parameters from polysomnography reports. This algorithm achieved high precision, recall, and F-1 scores exceeding 0.9 for key sleep metrics such as total sleep time, sleep onset latency, sleep efficiency, wake after sleep onset, and apnea-hypopnea index. This validation step was crucial for ensuring the accuracy of the data used in subsequent analyses.\n\nFor the clustering analysis, we employed the K-means algorithm with Euclidean distance to identify distinct phenotypic clusters of COPD patients based on sleep parameters. The optimal number of clusters was determined using the elbow method, which helped minimize subjectivity in cluster selection. This unsupervised approach allowed us to group patients in an unbiased manner, without relying on pre-existing knowledge or assumptions.\n\nTo evaluate the associations between the identified clusters and all-cause mortality, we performed Cox regression analysis. This statistical method adjusted for potential confounders such as age, body mass index, sex, and race, providing a more accurate assessment of the prognostic implications of these clusters. Additionally, Kaplan-Meier estimates were used to visualize the survival distributions of the clusters, further strengthening the validity of our findings.\n\nWe also conducted a non-parametric supervised learning algorithm using decision trees. This method classified patients into clusters based on total sleep time, sleep efficiency, Charlson Comorbidity Index, and age. The decision tree was pruned to reduce complexity and remove non-critical sections, ensuring a robust and interpretable model.\n\nThe study's longitudinal design, spanning over two decades, provided a comprehensive dataset for evaluating the long-term impact of sleep parameters on COPD outcomes. The use of a large and diverse population of veterans with confirmed COPD diagnoses enhanced the generalizability of our findings. However, it is important to note that the male-predominant veteran dataset may limit the applicability of our results to the broader population.\n\nIn summary, our evaluation method combined advanced data science modalities, rigorous statistical analysis, and longitudinal observational data to provide a thorough assessment of the relationship between sleep parameters and COPD outcomes. This multifaceted approach ensured the reliability and validity of our findings, contributing valuable insights to the field of COPD research.",
  "evaluation/measure": "In our study, we focused on evaluating the performance of our natural language processing (NLP) algorithms using a set of well-established metrics. The primary metrics reported are precision, recall, and the F-1 score. These metrics were chosen because they provide a comprehensive evaluation of the algorithm's performance in extracting sleep parameters from polysomnography (PSG) physician interpretation notes.\n\nPrecision measures the accuracy of the positive predictions made by the algorithm, indicating how many of the identified instances are relevant. Recall, on the other hand, assesses the algorithm's ability to find all relevant instances within the data, reflecting its sensitivity. The F-1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. This is particularly useful in scenarios where there is an uneven class distribution, as it ensures that the algorithm performs well across both dimensions.\n\nThe performance of our NLP algorithms exceeded a threshold of 0.90 for precision, recall, and F-1 score for several key sleep parameters. These parameters include total sleep time (TST), sleep onset latency (SOL), sleep efficiency (SE), wake after sleep onset (WASO), and the apnea-hypopnea index (AHI). Additionally, we developed a separate NLP algorithm specifically for the Epworth Sleepiness Scale (ESS), which also achieved a performance of greater than 0.90.\n\nThese metrics are widely recognized and used in the literature for evaluating the performance of NLP and machine learning models, particularly in the context of medical data extraction and analysis. By achieving high scores in these metrics, we demonstrate that our algorithms are robust and reliable for extracting relevant sleep parameters from clinical notes. This set of metrics is representative of the standards in the field, ensuring that our findings are comparable and valid within the broader scientific community.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "The evaluation of our study's performance metrics was conducted with a strong emphasis on statistical significance and confidence intervals. We utilized robust statistical methods to ensure the reliability of our findings.\n\nFor instance, we employed the elbow method to determine the optimal number of clusters in our K-means clustering analysis, which minimized subjectivity in cluster selection. This method provided a clear visual indication of the point at which adding more clusters did not significantly improve the model, thereby enhancing the confidence in our cluster selection process.\n\nIn our Cox regression analysis, we reported hazard ratios (HR) along with 95% confidence intervals (CI). This approach allowed us to quantify the uncertainty associated with our estimates and to assess the statistical significance of the associations between the identified clusters and mortality outcomes. The confidence intervals provided a range within which the true hazard ratio is likely to fall, giving a clear indication of the precision of our estimates.\n\nAdditionally, we used Kaplan-Meier estimates to visualize the survival distributions of the clusters. The log-rank test was employed to compare the survival curves, and the results were statistically significant, further reinforcing the validity of our findings.\n\nThe p-values reported in our tables, such as those in Table 2, indicate the statistical significance of the differences observed between the clusters for various sleep parameters and mortality outcomes. For example, the p-values for total sleep time, sleep efficiency, and other parameters were all less than 0.001, demonstrating that the differences between the clusters were highly statistically significant.\n\nOverall, the performance metrics in our study were evaluated with a high degree of confidence, supported by statistical significance and the inclusion of confidence intervals. This rigorous approach ensures that our findings are robust and reliable, providing a strong basis for the conclusions drawn from our analysis.",
  "evaluation/availability": "Not enough information is available."
}