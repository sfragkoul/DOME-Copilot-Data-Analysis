{
  "publication/title": "Multiplexed molecular imaging with surface enhanced resonance Raman scattering nanoprobes reveals immunotherapy response in mice <i>via</i> multichannel image segmentation.",
  "publication/authors": "Andreou C, Plakas K, Berisha N, Gigoux M, Rosch LE, Mirsafavi R, Oseledchyk A, Pal S, Zamarin D, Merghoub T, Detty MR, Kircher MF",
  "publication/journal": "Nanoscale horizons",
  "publication/year": "2022",
  "publication/pmid": "36285605",
  "publication/pmcid": "PMC10360075",
  "publication/doi": "10.1039/d2nh00331g",
  "publication/tags": "- Multiplexed molecular imaging\n- Surface enhanced resonance Raman scattering\n- Immunotherapy response\n- Multichannel image segmentation\n- Machine learning in imaging\n- Tumor classification\n- Superpixel analysis\n- Cancer immunotherapy\n- Molecular imaging techniques\n- Preclinical imaging models",
  "dataset/provenance": "The dataset used in this study was derived from Raman imaging of tumors in mice. The tumors were established by subcutaneous implantation of CT26 and 4T1 murine cancer cell lines in BALB/c mice. The mice were divided into treatment and control groups, with the treatment group receiving intraperitoneal injections of anti-CTLA-4 and anti-PD-1 antibodies, while the control group received PBS. The dataset consists of Raman scans of these tumors, which were performed using a Renishaw InVia Raman imaging microscope. The scans were conducted both through intact skin and after surgical exposure of the tumor area.\n\nThe Raman imaging process involved selecting the focal plane to intersect the tumors and scanning the tumor areas with a Raman laser. The resulting data were used to create pseudocolor images, where each point of the Raman scan was converted into a pixel. The dataset includes images from 20 tumors, with each tumor contributing multiple data points. The exact number of data points is not specified, but it is implied that each tumor scan contains a large number of pixels, which were grouped into superpixels for analysis.\n\nThe data used in this study have not been previously published or used by the community in the same context. The dataset is unique to this study, focusing on the classification of tumor regions based on multiplexed SERS signals. The superpixels were classified into three categories: 'ICB', 'No treatment', and 'No tumor', based on whether the superpixel was from a treated animal, a control animal, or an area without a tumor. The classification results were validated using cross-validation, with a set of 4 tumors left out of calibration for each iteration. This process was repeated five times to include all 20 tumors for validation. The dataset and the results of the classification are presented in the supplementary material and figures within the publication.",
  "dataset/splits": "In our study, we employed a cross-validation approach to ensure robust model training and validation. Specifically, we used a 5-fold cross-validation strategy. This means that the dataset was split into five different subsets, or folds. In each iteration of the cross-validation process, one fold was used as the validation set, while the remaining four folds were used for training the models. This process was repeated five times, ensuring that each fold served as the validation set exactly once. Consequently, every tumor in the dataset was included in the validation set in one of the iterations.\n\nEach fold contained data from four tumors, resulting in a total of 20 tumors being used across all five iterations. This approach helped to mitigate overfitting by ensuring that the models were evaluated on different subsets of the data in each iteration. The distribution of data points in each split was balanced, with each fold containing an equal number of tumors, thereby providing a comprehensive assessment of the models' performance across the entire dataset.",
  "dataset/redundancy": "To address dataset redundancy, we employed a rigorous cross-validation strategy. The datasets were split using a leave-four-out cross-validation approach. This means that for each iteration of training, four tumors were excluded from the calibration set and used exclusively for validation. This process was repeated five times, ensuring that each of the 20 tumors in the dataset was used for validation exactly once. This method helps to ensure that the training and test sets are independent, reducing the risk of overfitting and providing a more robust evaluation of the models' performance.\n\nThe distribution of the datasets in our study is designed to reflect the variability and complexity of tumor microenvironments. Unlike some previously published machine learning datasets that might focus on homogeneous samples, our approach accounts for the heterogeneous nature of tumors. By segmenting the images into superpixels and using these as the unit of analysis, we capture both spatial and spectral information, which is crucial for understanding the intricate details of tumor biology.\n\nThe superpixels were generated using a SLIC algorithm, which groups pixels based on both their spatial proximity and their spectral characteristics. This ensures that the superpixels represent meaningful biological regions within the tumors. Each superpixel was then assigned to one of three classes: 'ICB' (immunotherapy-treated), 'No treatment' (control), or 'No tumor' (areas without tumor tissue). This classification was based on the physical location of the superpixels within the tumor boundaries, ensuring that the training data accurately reflects the biological context.\n\nBy using this approach, we aim to create a dataset that is both representative of the underlying biological processes and robust enough to train and validate machine learning models effectively. The cross-validation strategy, combined with the superpixel segmentation, helps to mitigate dataset redundancy and ensures that the models generalize well to new, unseen data.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in our study fall under the category of supervised machine learning (SML) methods. Specifically, we employed several established techniques, including artificial neural networks (ANN), support vector machines (SVM), partial least squares discriminant analysis (PLS-DA), and boosted gradient trees (XBG). These algorithms are well-known in the field of machine learning and have been extensively used in various applications.\n\nThe algorithms utilized are not new; they are widely recognized and have been thoroughly documented in the literature. The choice to use these established methods was driven by their proven effectiveness in handling complex datasets and their ability to provide robust classification results. Given that our primary focus was on applying these algorithms to multiplexed molecular imaging data, rather than developing new machine-learning techniques, it was appropriate to publish our findings in a journal that specializes in nanoscale imaging and molecular biology. This allowed us to highlight the innovative application of these algorithms in a novel context, rather than their development.",
  "optimization/meta": "The models used in this study do not function as a meta-predictor. Instead, several supervised machine learning (SML) methods were individually assessed and compared. These methods included artificial neural networks (ANN), support vector machines (SVM), partial least squares discriminant analysis (PLS-DA), and boosted gradient trees (XBG). Each of these models was trained and validated independently using the same dataset of superpixels, which were grouped based on their spectral profiles and physical locations within tumor boundaries.\n\nCross-validation was performed for all models to prevent overfitting. This involved excluding a set of 4 tumors from the training data and using them for validation. This process was repeated five times to ensure that all tumors in the dataset were used for validation. The performance of each model was evaluated based on metrics such as class error and root mean square error of cross-validation (RMSECV).\n\nThe results indicated that while the ANN model performed adequately, SVM and XBG models showed better performance with lower class errors. PLS-DA identified key variables contributing to the classification, such as PD-L1 and GITR, highlighting their importance in the model's predictive power. XBG also emphasized PD-L1 expression as a crucial predictor.\n\nOverall, the approach demonstrated that the methodology is model-independent, as different SML models corroborated the results, indicating the robustness of the classification strategy. The independence of the training data was maintained through the cross-validation process, ensuring that each model was evaluated on unseen data.",
  "optimization/encoding": "For the machine-learning algorithm, the data underwent several preprocessing steps to ensure optimal encoding and standardization. Initially, each of the eight data channels derived from the nn-LS scores was mean-centered and standardized to have a mean of zero and a standard deviation of one. This step is crucial for ensuring that all features contribute equally to the model, preventing any single feature from dominating due to its scale.\n\nFollowing standardization, a SLIC (Simple Linear Iterative Clustering) algorithm was employed to group individual pixels from the Raman scans into superpixels. This algorithm minimizes the distance between each pixel and the superpixel it belongs to, considering both physical distance in 2D space and score distance in the 8D space of the multiplexed image channels. The compactness parameter, which weighs the physical distance against the score distance, was determined empirically and set to a specific value to balance these two factors effectively.\n\nThe SLIC algorithm was iterated 20 times, recalculating new coordinates and mean scores for the superpixels in each iteration. This process ensures that each superpixel represents the average of similar pixels within its vicinity, providing a more coherent and representative dataset for the machine-learning models.\n\nEach superpixel was then assigned to a class based on its physical location within the tumor boundaries. This classification step is essential for training the supervised machine-learning models, as it provides the ground truth labels needed for calibration.\n\nFor the classification models, the physical location of the superpixels was ignored, and only the aggregate nn-LS scores and the assigned class of the superpixel were considered. This approach ensures that the models focus on the spectral information rather than spatial information, which is crucial for accurate classification.\n\nCross-validation was performed to avoid overfitting, with a set of four tumors excluded from training and used as validation. This process was repeated five times to include all 20 tumors for validation, ensuring robust and generalizable model performance.",
  "optimization/parameters": "In our study, the input parameters for the machine learning models were derived from the superpixels generated using the SLIC algorithm. Each superpixel was characterized by the aggregate non-negative least squares (nn-LS) scores across eight data channels. These scores were mean-centered and standardized to have a mean of 0 and a standard deviation of 1. Therefore, the number of input parameters (p) for each superpixel is 8, corresponding to the eight multiplexed image channels.\n\nThe selection of these eight channels was based on the panel of targets chosen for imaging the tumor immune microenvironment. This panel included SERS nanoprobes functionalized with antibodies against various markers such as CD8a, CD4, GITR, 4\u20131BB, CD11b, NKp46, and PD-L1, along with a non-targeted IgG isotype control. The Raman reporters were selected to yield high intensities when interrogated with the 785-nm laser and to have sufficiently distinct spectral features to facilitate unmixing. This ensured that the eight channels provided a comprehensive and distinct set of data for the machine learning models.\n\nThe SLIC algorithm was used to group individual pixels from the Raman scans into superpixels, with the same constraints and superpixel density applied to all images. The compactness parameter, which weighs physical distance against score distance, was determined empirically. This process was repeated for 20 iterations to ensure robust segmentation. The resulting superpixels represented the average of similar pixels within their vicinity, providing a reliable input for the machine learning models.",
  "optimization/features": "The input features for our models were derived from multiplexed molecular Raman imaging data using SERS nanoprobes. We utilized a library of 8 distinct and bright nanoprobes, resulting in 8 data channels. Each of these channels represents the signal from a specific nanoprobe, providing information about the presence and relative abundance of different biomarkers within the tumor microenvironment.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, we employed a superpixel algorithm to segment the images, grouping pixels together based on their similarity in nanoprobe uptake profiles. This approach helped to reduce noise and improve statistical significance while preserving physiological features. The superpixels were then used as input for the supervised machine learning models, with each superpixel represented by the aggregate scores from the 8 data channels.\n\nThe classification models considered only the aggregate scores and the assigned class of the superpixel, ignoring the physical location. This ensured that the models were trained on the relevant spectral information without being biased by spatial data. Cross-validation was performed by excluding a set of 4 tumors from training and using them for validation, repeating this process 5 times to include all 20 tumors in the dataset.",
  "optimization/fitting": "In our study, we employed a fitting method that involved non-negative least squares (nn-LS) to assign scores to each point spectrum from the image using reference spectra derived from pure nanoparticle populations. This method ensured that the scores were physically meaningful by avoiding negative values.\n\nThe number of parameters in our model was indeed larger than the number of training points, as we were dealing with high-dimensional data from multiplexed Raman imaging. To address the risk of over-fitting, we implemented a rigorous cross-validation strategy. Specifically, we performed cross-validation by leaving out a set of 4 tumors from the calibration process and using them for validation. This procedure was repeated five times to ensure that all tumors in the dataset were used for validation. This approach helped to generalize the model and avoid over-fitting to the training data.\n\nTo mitigate the risk of under-fitting, we ensured that our model was complex enough to capture the underlying patterns in the data. We used several supervised machine learning (SML) methods, including artificial neural networks (ANN), support vector machines (SVM), partial least squares discriminant analysis (PLS-DA), and boosted gradient trees (XBG). Each of these methods has its own strengths and can capture different aspects of the data. By comparing the performance of these models, we could select the one that best balanced complexity and generalization.\n\nAdditionally, we used a superpixel algorithm to segment the image, grouping pixels together based on their spectral similarities. This approach helped to reduce noise and improve the statistical significance of our results. The superpixel algorithm minimized the distance between pixels and superpixels in both physical and spectral spaces, ensuring that the segmentation reflected the underlying biological structures.\n\nIn summary, our fitting method involved a balance between model complexity and generalization. We used cross-validation to prevent over-fitting and ensured that our model was complex enough to capture the underlying patterns in the data. The use of multiple SML methods and a superpixel algorithm further enhanced the robustness and reliability of our results.",
  "optimization/regularization": "In our study, we employed several techniques to prevent over-fitting during the model training process. One of the primary methods used was cross-validation. Specifically, we implemented a leave-four-out cross-validation strategy. This involved excluding a set of four tumors from the calibration process and using them for validation. This procedure was repeated five times to ensure that all tumors in the dataset were used for validation at some point. This approach helped to assess the model's performance on unseen data and to mitigate the risk of over-fitting.\n\nAdditionally, we standardized the data channels by mean-centering and scaling them to have a mean of zero and a standard deviation of one. This preprocessing step helped to ensure that all features contributed equally to the model, reducing the likelihood of any single feature dominating the learning process and thus helping to prevent over-fitting.\n\nFurthermore, the use of superpixels, which group together adjacent pixels with similar characteristics, provided a more robust representation of the data. This aggregation reduced the dimensionality of the data and helped to smooth out noise, making the model more generalizable to new, unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models employed in our study, including artificial neural networks (ANN), support vector machines (SVM), partial least squares discriminant analysis (PLS-DA), and boosted gradient trees (XBG), can be considered somewhat interpretable, though the degree of transparency varies among them.\n\nANN and XBG are generally considered black-box models due to their complex, non-linear structures, making it challenging to interpret the decision-making process directly. However, techniques like feature importance scores and SHAP (SHapley Additive exPlanations) values can be used to gain insights into which features contribute most to the model's predictions. For instance, XBG identified PD-L1 expression as the single most important predictor for classification, highlighting its significance in the model's decision-making process.\n\nOn the other hand, PLS-DA offers more transparency. It identifies variables with the most descriptive power, such as PD-L1 and GITR with significant weights, compared to less important variables like CD4 and CD11b. This makes it easier to understand which features are driving the model's classifications.\n\nSVM, while also a black-box model, can provide some interpretability through the support vectors, which are the data points closest to the decision boundary. Analyzing these support vectors can offer insights into the critical data points influencing the model's decisions.\n\nIn summary, while some of our models are inherently black-box, techniques and model-specific features can be employed to enhance interpretability. This allows us to understand the key factors contributing to the model's predictions, such as the importance of PD-L1 and GITR in PLS-DA, and the significance of PD-L1 in XBG.",
  "model/output": "The model employed in our study is a classification model. We utilized supervised machine learning (SML) techniques to classify superpixels into distinct categories based on their characteristics. The classes assigned were 'ICB', 'No treatment', and 'No tumor', which correspond to whether the superpixel was from a treated animal, a control animal, or an area without a tumor, respectively. Various SML methods were assessed, including artificial neural networks (ANN), support vector machines (SVM), partial least squares discriminant analysis (PLS-DA), and boosted gradient trees (XBG). The classification results were visualized using pseudocolor images, where superpixels classified as 'ICB', 'No treatment', or 'No tumor' were shown in green, pink, and black, respectively. The model's performance was evaluated using cross-validation, which involved leaving out a set of 4 tumors for validation in each iteration. This approach ensured that the model could generalize well to new data and avoid overfitting. Overall, the model successfully classified the tumors based on the multiplexed SERS signal, indicating areas that aligned with the expected outcomes and those that did not.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several supervised machine learning (SML) techniques to classify superpixels into three categories: 'ICB' (treated animal), 'No treatment' (control animal), and 'No tumor' (areas without a tumor). The models considered intra-tumoral variation but did not differentiate between viable and necrotic areas within a tumor, which simplified the classification process but reduced the goodness of fit statistics.\n\nTo ensure the robustness of the models and prevent overfitting, cross-validation was employed. This involved leaving out a set of 4 tumors for validation while using the remaining data for training. This process was repeated five times, ensuring that all 20 tumors in the dataset were used for validation at some point.\n\nSeveral SML methods were assessed, including artificial neural networks (ANN), support vector machines (SVM), partial least squares discriminant analysis (PLS-DA), and boosted gradient trees (XBG). The classification results were visualized in figures, with superpixels classified as 'ICB', 'No treatment', or 'No tumor' shown in green, pink, and black, respectively.\n\nThe performance of the models was evaluated based on their ability to correctly classify areas from na\u00efve and treated CT26 and 4T1 tumors. The ANN model showed a class error of cross-validation around 0.10 and a root mean square error of cross-validation (RMSECV) around 0.26. SVM and XBG performed better, with class errors of 0.13 and 0.07, respectively. The errors were primarily due to intra-tumoral variability, as necrotic areas provided negligible signal and were often misclassified as 'No tumor'.\n\nThe results indicated that 4T1 tumors were more resistant to ICB therapy compared to CT26 tumors, consistent with existing literature. The methodology successfully classified tumors based on the multiplexed SERS signal and identified areas not aligned with the expected outcome. Future improvements could involve fine-tuning the calibration data or using morphological image processing approaches to better identify necrotic areas and regions of effective treatment or emerging resistance.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to assess the effectiveness of our models. For all supervised machine learning methods employed, we performed cross-validation to prevent overfitting. This involved leaving out a set of four tumors for validation while using the remaining data for training, and this process was repeated five times to ensure all tumors were used for validation.\n\nThe primary metrics we reported include the class error of cross-validation and the root mean square error of cross-validation (RMSECV). The class error provides a direct measure of the misclassification rate, indicating how often the models incorrectly predicted the class of a superpixel. The RMSECV gives an indication of the average magnitude of the errors between predicted and actual values, providing a sense of the model's accuracy.\n\nSpecifically, the artificial neural network (ANN) model showed a class error of cross-validation around 0.10 and an RMSECV around 0.26. In comparison, support vector machines (SVM) and boosted gradient trees (XBG) performed better, with class errors of 0.13 and 0.07, respectively. These metrics are representative of the model's ability to correctly classify superpixels into the categories of 'ICB', 'No treatment', and 'No tumor'.\n\nAdditionally, we noted that most of the classification errors stemmed from intra-tumoral variability, particularly in necrotic areas which provided negligible signal and were often classified as 'No tumor'. This highlights the challenge of intra-tumoral heterogeneity in achieving high classification accuracy.\n\nOur approach to performance evaluation is consistent with standard practices in the literature, ensuring that our results are comparable and meaningful within the field of molecular imaging and machine learning. By reporting these metrics, we aim to provide a clear and comprehensive assessment of our models' performance, demonstrating their effectiveness in classifying tumor regions based on multiplexed SERS signals.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, we focused on evaluating several supervised machine learning (SML) methods using our own dataset, which consisted of multiplexed molecular Raman imaging data. The SML methods assessed included artificial neural networks (ANN), support vector machines (SVM), partial least squares discriminant analysis (PLS-DA), and boosted gradient trees (XBG).\n\nTo ensure robust evaluation, we employed cross-validation, where a set of 4 tumors was left out of the calibration process and used for validation. This procedure was repeated five times to include all 20 tumors in the dataset for validation. This approach helped us to avoid overfitting and provided a comprehensive assessment of each model's performance.\n\nIn terms of simpler baselines, our methodology inherently included a form of baseline comparison by evaluating different SML algorithms. Each of these algorithms represents a different approach to classification, with varying levels of complexity. For instance, PLS-DA is a linear method, while ANN and XBG are more complex, non-linear methods. By comparing these, we could gauge the effectiveness of simpler versus more complex models.\n\nThe performance metrics, such as class error and root mean square error of cross-validation (RMSECV), allowed us to quantify the effectiveness of each model. For example, the ANN model had a class error around 0.10 and an RMSECV around 0.26, while SVM and XBG performed better with class errors of 0.13 and 0.07, respectively. This comparison highlighted the strengths and weaknesses of each method within the context of our specific dataset and problem.\n\nOverall, our evaluation focused on internal comparisons among different SML methods rather than external benchmarks. This approach provided insights into which models were most effective for our particular application of multiplexed molecular imaging and tumor classification.",
  "evaluation/confidence": "The evaluation of our models involved several supervised machine learning (SML) methods, including artificial neural networks (ANN), support vector machines (SVM), partial least squares discriminant analysis (PLS-DA), and boosted gradient trees (XBG). To ensure robustness and avoid overfitting, cross-validation was performed by leaving out a set of 4 tumors for validation in each iteration, and this process was repeated five times to include all 20 tumors in the dataset.\n\nPerformance metrics such as class error and root mean square error of cross-validation (RMSECV) were reported for each model. For instance, the ANN model had a class error of cross-validation around 0.10 and an RMSECV around 0.26. SVM and XBG performed better, with class errors of 0.13 and 0.07, respectively. These metrics provide a quantitative measure of the models' performance and their ability to generalize to unseen data.\n\nStatistical significance was assessed through cross-validation, which helps in understanding the variability and reliability of the model's performance. The consistent performance across different models and the clear distinction in classification results, such as the correct classification of areas from na\u00efve and treated CT26 tumors, indicate the robustness of our approach.\n\nHowever, it is important to note that most of the error stems from intra-tumoral variability, particularly in necrotic areas that provided negligible signal and were often classified as \u2018No tumor\u2019. This highlights the challenge of intra-tumoral heterogeneity but also the potential for improvement by fine-tuning the calibration data or using additional morphological image processing approaches.\n\nOverall, the results demonstrate that our methodology can classify tumors appropriately based on the multiplexed SERS signal and indicate areas not aligned with the expected outcome. The consistency across different SML models suggests that the approach is model-independent, further bolstering confidence in the results.",
  "evaluation/availability": "Not enough information is available."
}