{
  "publication/title": "Combining comparative genomic analysis with machine learning reveals some promising diagnostic markers to identify five common pathogenic non-tuberculous mycobacteria.",
  "publication/authors": "Jia X, Yang L, Li C, Xu Y, Yang Q, Chen F",
  "publication/journal": "Microbial biotechnology",
  "publication/year": "2021",
  "publication/pmid": "34019733",
  "publication/pmcid": "PMC8313281",
  "publication/doi": "10.1111/1751-7915.13815",
  "publication/tags": "- Machine Learning\n- Random Forest\n- Ensemble Classification\n- Diagnostic Markers\n- NTM Species Identification\n- Bioinformatics\n- Genomic Analysis\n- SNP Detection\n- Core Genes\n- Mycobacterium\n- Genomic Sequencing\n- Classification Algorithms\n- Predictive Modeling\n- Genomic Variants\n- Microbial Biotechnology",
  "dataset/provenance": "The dataset utilized in this study was sourced from the National Center for Biotechnology Information (NCBI). The genomes included in the study were those with more than five completed genomes or assembled genome sequences at the chromosome level. The data collection was conducted up to March 12, 2021.\n\nThe dataset comprises a variety of non-tuberculous mycobacteria (NTM) species. Specifically, it includes one complete genome and six assembled genomes at the chromosome level of seven Mycobacterium kansasii (Mka) strains, 33 complete genomes and one assembled genome at the chromosome level of 34 M. avium (Mav) strains, 30 complete genomes of 30 M. intracellular (Min) strains, 5 complete genomes and three assembled genomes at the chromosome level of 8 M. chelonae (Mch) strains, and 40 complete genomes and four assembled genomes at the chromosome level of 44 M. abscessus (Mab) strains.\n\nAdditionally, raw Illumina sequencing reads of genomic DNAs of NTM species were downloaded from the Sequence Read Archive (SRA) database as a validation set. This validation set includes 20 Mka strains, 159 Mav strains, 37 Min strains, 47 Mch strains, and 285 Mab strains, totaling over 400 Mb of data.\n\nThe dataset has been used to identify diagnostic markers for discriminating among the five common pathogenic NTM species. The study leverages machine learning algorithms, specifically random forest and ensemble classification, to screen out species-specific biomarkers from a large validation set. This approach aims to improve the accuracy of identifying and classifying these genetically close species of pathogens.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The training set comprised 70% of the samples, while the test set included the remaining 30%. This split was used to build and evaluate the strain identification models for each type of NTM.\n\nFor the training set, the data was further divided into multiple subsets to perform cross-validation. Specifically, a 10-fold cross-validation was conducted using the `rfcv` function with parameters `cv.fold=10` and `step=0.8`. This means the training data was split into 10 approximately equal parts, with the model trained on 9 parts and validated on the remaining 1 part, repeated 10 times to ensure robust performance evaluation.\n\nThe test set was used to evaluate the final performance of the models after training. The distribution of data points in each split was designed to ensure that the models were trained and tested on representative samples, allowing for a comprehensive assessment of their classification performance.",
  "dataset/redundancy": "The datasets used in this study were split into training and testing groups to evaluate the performance of the machine learning models. Specifically, 70% of the samples were randomly selected for the training group, while the remaining 30% were allocated to the testing group. This split ensures that the training and test sets are independent, which is crucial for obtaining unbiased performance metrics.\n\nTo enforce the independence of the training and test sets, cross-validation was conducted using a 10-fold cross-validation approach. This method involves dividing the training data into 10 subsets, or folds, and then training the model on 9 of these folds while validating it on the remaining fold. This process is repeated 10 times, with each fold serving as the validation set once. This technique helps to ensure that the model generalizes well to unseen data.\n\nThe distribution of the datasets used in this study compares favorably to previously published machine learning datasets in the context of identifying pathogenic NTM species. The datasets include a diverse range of genomic sequences from five common NTM species, ensuring a comprehensive representation of the genetic variability within these species. This diversity is essential for training robust machine learning models that can accurately discriminate between different NTM species.\n\nThe datasets were obtained from publicly available sources, including the NCBI and SRA databases, which provide high-quality genomic sequences. The inclusion of both complete genomes and assembled genomes at the chromosome level ensures that the datasets are representative of the genetic diversity within each species. Additionally, the datasets include a large number of samples, with over 400 Mb of sequencing data, which provides a robust foundation for training and validating the machine learning models.",
  "dataset/availability": "The data utilized in this study were obtained from publicly available sources, specifically the NCBI database. The complete genome sequences and assembled genome sequences at the chromosome level were downloaded from NCBI up to March 12, 2021. Additionally, raw Illumina sequencing reads of genomic DNAs of NTM species were downloaded from the SRA database as a validation set.\n\nThe specific strains and their respective genome sequences used in the study are detailed in supplementary tables, which include information on the number of complete and assembled genomes for each NTM species. These tables provide transparency regarding the data splits used for training and testing the models.\n\nThe data are not explicitly released in a public forum by the authors of this study. However, the sources from which the data were obtained are publicly accessible, and the methods for data acquisition are clearly described. This ensures that the data can be replicated and verified by other researchers.\n\nThe enforcement of data usage is governed by the terms and conditions of the NCBI and SRA databases. These platforms typically require proper citation and adherence to their data usage policies, which include acknowledging the source and ensuring that the data are used for legitimate research purposes.\n\nNot applicable",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is ensemble classification, specifically the bagging method. This approach is not new; it has been established as a powerful tool in machine learning for improving classification performance by combining multiple classifiers. The bagging algorithm, in particular, is known for its ability to correct errors made by individual classifiers, leading to better overall accuracy.\n\nThe reason this algorithm was not published in a machine-learning journal is that our primary focus was on applying it to a specific biological problem\u2014namely, the identification and classification of non-tuberculous mycobacteria (NTM) species. Our work demonstrates the practical application of ensemble classification in the context of comparative genomics and precision medicine. The algorithm itself is well-documented in the machine-learning literature, but its application to this particular biological challenge is novel and contributes to the field of microbiology and genomics.\n\nWe utilized the random forest algorithm as an initial step to identify important features and then employed the ensemble classification algorithm to achieve simultaneous good classification performance across five NTM species. This two-step process leverages the strengths of both algorithms, providing a robust framework for identifying species-specific biomarkers. The random forest algorithm was chosen for its flexibility and ease of use, while the ensemble classification algorithm was selected for its ability to handle multiple classifiers effectively.",
  "optimization/meta": "In our study, we employed an ensemble classification algorithm as a meta-predictor to achieve robust classification performance across five different NTM species. This meta-predictor leverages the outputs of multiple binary classifiers, each trained using a random forest algorithm. The random forest classifiers were initially used to discriminate one NTM species from the others in a binary classification setup. Specifically, we trained separate classifiers for each species: Mka vs. 'non-Mka', Mav vs. 'non-Mav', Min vs. 'non-Min', Mch vs. 'non-Mch', and Mab vs. 'non-Mab'.\n\nThe ensemble classification algorithm, implemented using the 'bagging' function from the 'adabag' package in R, combines the predictions from these binary classifiers. This approach allows for the correction of errors made by any individual classifier, leading to improved overall accuracy. The ensemble method was trained using a subset of the data (4/5 for training and 1/5 for testing) and validated on an independent test set to ensure that the training data was indeed independent.\n\nBy integrating the results from multiple random forest classifiers, our ensemble model effectively enhances the classification performance for the five NTM species simultaneously. This meta-predictor approach not only improves the accuracy of species identification but also provides a more reliable framework for discriminating between genetically similar pathogens.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for the effective application of machine learning algorithms. We began by collecting genomic data from various non-tuberculous mycobacteria (NTM) species, ensuring that we had a comprehensive dataset for analysis. The genomic sequences were obtained from the NCBI database, with a focus on complete and assembled genomes at the chromosome level.\n\nTo prepare the data for machine learning, we first identified single-copy genes (SCGs) and single-copy single nucleotide polymorphisms (SCSNPs) through comparative genomic analysis. These genetic markers were then used to create feature sets for our models. The data was split into training and testing sets, with 70% of the samples used for training and 30% reserved for testing. This split ensured that our models could be evaluated on unseen data, providing a robust assessment of their performance.\n\nFor the random forest algorithm, we utilized the randomForest package in R, growing 10,000 trees to build the classification models. Cross-validation was performed using a 10-fold approach to optimize the model parameters and prevent overfitting. Important features were extracted based on metrics such as Mean Decrease Accuracy (MDA) and Mean Decrease Gini (MDG), which helped in identifying the most discriminative genetic markers.\n\nIn addition to the random forest, we employed an ensemble classification algorithm using the 'bagging' function from the 'adabag' package in R. This approach combined the predictions from multiple binary classifiers to achieve better overall classification performance. The ensemble method was particularly effective in handling the complexity of distinguishing between the five NTM species simultaneously.\n\nThroughout the preprocessing and encoding steps, we ensured that the data was normalized and standardized to facilitate accurate and efficient model training. This involved scaling the genetic features to a common range and handling any missing or inconsistent data points. The resulting encoded data was then fed into the machine learning algorithms, enabling us to develop robust models for the identification and classification of NTM species.",
  "optimization/parameters": "In our study, we utilized a random forest algorithm to identify optimized gene and SNP combinations for distinguishing among five different NTM species. The number of parameters, p, in our model was determined through a systematic screening process.\n\nInitially, we obtained a large set of potential markers by downloading genome sequences from the NCBI SRA database. This included 349 single-copy genes (SCGs) and 146 single-copy SNPs (SCSNPs) for Mka, 91 SCGs and 305 SCSNPs for Mav, 263 SCGs and 21 SCSNPs for Min, 95 SCGs and 8 SCSNPs for Mch, and 139 SCGs and 28 SCSNPs for Mab.\n\nTo refine this set, we employed the random forest algorithm, which is known for its ability to handle high-dimensional data and identify important features. The algorithm was implemented using the randomForest package in R, with 10,000 trees grown to ensure robustness. We randomly selected 70% of the samples for training and 30% for testing, and conducted cross-validation using a 10-fold approach.\n\nThe importance of each feature was assessed using Mean Decrease Accuracy (MDA) and Mean Decrease Gini (MDG) coefficients. These metrics helped us to identify the most relevant genes and SNPs for each species. For instance, the optimized marker gene combinations included two genes for Mka (pfkA2 and MKAN_11495), three genes for Mav (nikA, ddpC, and yejF), three genes for Min (mnhF1, codA, and dmlR), two genes for Mch (yjcH and mpr), and five genes for Mab (benM, aqpZ, aldHT, osmX, and fsr).\n\nThe final set of parameters, p, used in our model consisted of these optimized gene and SNP combinations, which were found to have excellent predictive power as evaluated by the area under the receiver operating characteristic curve (AUC), sensitivity, and specificity. This approach ensured that our model was both efficient and accurate in identifying the five NTM species.",
  "optimization/features": "In our study, we utilized a combination of single nucleotide polymorphisms (SNPs) and single-copy genes (SCGs) as input features for our machine learning models. The specific number of features used as input varied depending on the model and the stage of the analysis. Initially, a large set of potential features was considered, but feature selection was performed to identify the most important ones.\n\nFeature selection was conducted using the random forest algorithm, which helped in identifying important features based on metrics such as Mean Decrease Accuracy (MDA) and Mean Decrease Gini (MDG). This process was crucial for optimizing the performance of our classifiers. The feature selection was performed using the training set only, ensuring that the testing set remained independent and unbiased.\n\nThe ensemble classification algorithm, which was built upon the pre-selected features from the random forest binary classifiers, further refined the feature set. This approach allowed us to achieve good classification performance for the five non-tuberculous mycobacterium (NTM) species simultaneously. The final models used a subset of the initially considered features, which were selected based on their importance and contribution to the classification accuracy.",
  "optimization/fitting": "The fitting method employed in this study utilized machine learning algorithms, specifically random forest and ensemble classification, to identify diagnostic markers for five pathogenic NTM species. The random forest algorithm was chosen for its flexibility and ability to produce good results even without extensive hyper-parameter tuning. This algorithm was used to create binary classifiers that discriminated one NTM species from the others.\n\nTo ensure that over-fitting was not an issue, cross-validation was conducted using the `rfcv` function with parameters `cv.fold=10` and `step=0.8`. This approach helped in validating the model's performance and generalizability by splitting the data into multiple folds and training the model on different subsets, thereby reducing the risk of over-fitting.\n\nAdditionally, the ensemble classification algorithm, specifically bagging, was used to further improve classification performance. This method combines multiple classifiers to correct for errors made by any individual classifier, leading to better overall accuracy. The use of bagging helped in mitigating the risk of over-fitting by averaging the results of multiple models.\n\nThe number of parameters in the random forest model was managed by growing 10,000 trees, which provided a robust framework for feature selection and classification. Important features were extracted using the `imp` function based on Mean Decrease Accuracy (MDA) and Mean Decrease Gini (MDG), ensuring that the most relevant markers were selected for classification.\n\nTo address under-fitting, the model was trained on a large validation set consisting of genomic data from multiple NTM strains. The training set included 70% of the samples, while the testing set included 30%, ensuring that the model had enough data to learn the underlying patterns without being too simplistic.\n\nIn summary, the fitting method involved the use of random forest and ensemble classification algorithms, cross-validation, and feature selection techniques to ensure that the model was neither over-fitted nor under-fitted. The robust training and validation process helped in achieving accurate and reliable classification of the five NTM species.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was cross-validation. Specifically, we utilized 10-fold cross-validation to assess the performance of our random forest models. This technique helps to provide a more accurate estimate of model performance by dividing the data into training and validation sets multiple times.\n\nAdditionally, we implemented an ensemble classification algorithm known as bagging. This method involves creating multiple versions of a predictor and using these to get an aggregated prediction. By combining the predictions from multiple models, bagging helps to reduce the variance and improve the stability of the final model, thereby mitigating the risk of overfitting.\n\nFurthermore, we carefully selected important features using the Mean Decrease Accuracy (MDA) and Mean Decrease Gini (MDG) metrics. This feature selection process helps to identify the most relevant variables, reducing the complexity of the model and preventing it from fitting noise in the data.\n\nThe use of these techniques collectively ensures that our models are robust and generalizable, minimizing the likelihood of overfitting.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters used in our study are not explicitly detailed in the provided information. Therefore, it is not possible to confirm their availability or the specific means of access.\n\nHowever, it is standard practice in scientific publications to make such information available to ensure reproducibility. Typically, this would be done through supplementary materials, data repositories, or direct links provided within the publication. Given the context, it is likely that these details are included in supplementary files or associated data repositories, which are often referenced in the main text or acknowledgments section of the paper.\n\nFor specific access, readers would usually refer to the supplementary materials or contact the corresponding author for any additional data or code. The license under which these materials are provided would also be specified, often adhering to open-access principles to facilitate wider use and verification by the scientific community.",
  "model/interpretability": "The model employed in this study is not a blackbox. It leverages interpretable machine learning techniques to ensure transparency. Specifically, the random forest algorithm was used, which inherently provides insights into feature importance. This was achieved through the calculation of Mean Decrease Accuracy (MDA) and Mean Decrease Gini (MDG) using the `imp()` function. These metrics help identify the most significant genes and SNPs contributing to the classification of different NTM species.\n\nFor example, in the identification of the five common pathogenic NTM species, specific genes and SNPs were highlighted as crucial. For the species Mka, genes such as `pfkA2` and `MKAN_11495`, along with SNPs like `rrl G377A` and `rrl C426T`, were found to be important. Similarly, for Mav, genes like `nikA`, `ddpC`, and `yejF`, along with SNPs such as `ino1 G832A` and `clpB G2124C`, played significant roles. This level of detail allows for a clear understanding of which biological markers are most influential in the classification process.\n\nThe ensemble classification algorithm further refined these findings by combining the pre-selected features from each binary classifier. This approach not only improved the overall accuracy but also maintained interpretability by focusing on a subset of the most relevant genes and SNPs. For instance, the gene&SNP panel included markers like `nikA`, `benM`, `codA`, `pfkA2`, `mpr`, `yjcH`, `rrl C2638T`, and `rrl A1173G`, which collectively achieved high classification accuracy.\n\nIn summary, the model's transparency is ensured through the use of interpretable machine learning techniques, providing clear examples of how specific genes and SNPs contribute to the classification of NTM species.",
  "model/output": "The model employed in our study is a classification model. Specifically, we utilized a random forest classification algorithm to build strain identification models for each kind of NTM. This algorithm was further enhanced using an ensemble classification approach, known as bagging, to simultaneously achieve good classification performance across five NTM groups. The model's performance was evaluated using various metrics such as sensitivity, specificity, balanced accuracy, and overall accuracy, which are typical for classification tasks. The confusion matrices provided for both the training and test sets further illustrate the model's classification capabilities.\n\nThe classification model was designed to distinguish between different NTM species using gene and SNP panels. The gene&SNP panel, gene panel, and SNP panel were screened to identify the five common pathogenic NTM species with high accuracy. The gene&SNP panel and gene panel demonstrated higher classification accuracy compared to the SNP panel alone. This indicates that the combination of genes and SNPs, as well as genes alone, provides more robust diagnostic markers for identifying these NTM species.\n\nThe model's performance was assessed using cross-validation, and important features were extracted based on Mean Decrease Accuracy (MDA) and Mean Decrease Gini (MDG). The Area Under the Curve (AUC) was also calculated using receiver operating characteristic (ROC) analysis to evaluate the model's discriminative ability. The overall accuracy of the model was found to be above 94% for the gene&SNP panel and above 92% for the gene panel, indicating strong classification performance.",
  "model/duration": "The execution time for the model varied depending on the specific tasks and datasets used. For the random forest classification, the process involved growing 10,000 trees, which is computationally intensive. The cross-validation process, conducted with 10 folds and a step size of 0.8, also contributed to the overall runtime. Additionally, the ensemble classification algorithm, which utilized the bagging method, further added to the execution time. While specific runtime values are not provided, it is evident that the model required significant computational resources and time to complete the analysis. The use of high-performance computing resources would have been beneficial to handle the large-scale data and complex algorithms efficiently.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its robustness and accuracy. Initially, a random-forest classification algorithm was employed using the randomForest package in R, with 10,000 trees grown. The dataset was split into training and testing groups, with 70% of the samples used for training and 30% for testing. Cross-validation was performed using the rfcv function with parameters cv.fold=10 and step=0.8. This process helped in identifying important features based on Mean Decrease Accuracy (MDA) and Mean Decrease Gini (MDG).\n\nTo further enhance the classification performance, an ensemble classification algorithm, specifically the bagging method from the adabag package in R, was proposed. This ensemble approach utilized pre-selected features from each binary classifier obtained from the random forest analysis. The bagging method involved a 4/5 split for training and 1/5 for testing, ensuring a comprehensive evaluation of the model's performance.\n\nThe evaluation metrics included sensitivity, specificity, balanced accuracy, and overall accuracy. These metrics were calculated for both the training and test sets, providing a clear picture of the model's performance. The confusion matrices for the training and test sets were also presented, showing the number of true positives, true negatives, false positives, and false negatives for each class.\n\nAdditionally, the area under the receiver operating characteristic curve (AUC) was calculated using the roc function of the pROC package in R. This metric provided further insight into the model's ability to distinguish between different classes. The results demonstrated excellent predictive powers, with high AUC values, sensitivity, and specificity for identifying the five NTM species.\n\nOverall, the evaluation method was rigorous and comprehensive, involving multiple steps and metrics to ensure the reliability and accuracy of the classification model.",
  "evaluation/measure": "In our evaluation, we reported several key performance metrics to comprehensively assess the effectiveness of our classification models. These metrics include sensitivity, specificity, balanced accuracy, and overall accuracy. Sensitivity, also known as recall, measures the proportion of true positive predictions among the actual positives. Specificity, on the other hand, measures the proportion of true negative predictions among the actual negatives. Balanced accuracy is the average of sensitivity and specificity, providing a single metric that takes into account both types of errors. Overall accuracy gives the proportion of correct predictions (both true positives and true negatives) among the total number of cases.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in the context of biological and medical data. They provide a clear and representative view of the model's performance across different aspects, ensuring that both the ability to correctly identify positive cases and the ability to correctly identify negative cases are considered. Additionally, we presented confusion matrices to provide a detailed breakdown of the classification results, showing the number of true positives, true negatives, false positives, and false negatives for each class. This detailed view allows for a more nuanced understanding of where the model performs well and where it may need improvement.",
  "evaluation/comparison": "In our study, we employed a combination of comparative genomics and machine learning techniques to identify and validate biomarkers for five non-tuberculous mycobacteria (NTM) species. We utilized the random forest algorithm to screen for optimized marker genes and single nucleotide polymorphisms (SNPs) that could accurately discriminate between the NTM species. This approach involved using a large validation set of genome sequences downloaded from the NCBI SRA database.\n\nThe random forest algorithm was chosen for its flexibility and robustness, even without extensive hyper-parameter tuning. It was used to build binary classifiers for each NTM species, distinguishing one species from the others. This method proved effective in identifying key marker genes and SNPs that showed excellent predictive power, as evidenced by high area under the receiver operating characteristic curve (AUC) values and sensitivity/specificity metrics.\n\nTo further enhance classification performance, we implemented an ensemble classification algorithm. This approach combined the results from multiple binary classifiers, correcting for individual errors and improving overall accuracy. The ensemble method demonstrated superior performance in simultaneously classifying the five NTM species, as shown in the confusion matrices for both training and test sets.\n\nOur research not only revealed new panels and marker genes/SNPs for accurate species discrimination but also provided insights into the potential of machine learning in precision medicine. The use of comparative genomics and machine learning allowed us to precisely identify genetically close species of pathogens, offering a promising avenue for future diagnostic and therapeutic strategies.\n\nNot applicable",
  "evaluation/confidence": "The evaluation of the classification models was conducted using a robust methodology that included cross-validation and statistical analysis. The models were built using a random forest algorithm with 10,000 trees, and the samples were split into training and testing groups with a 70-30 ratio. Cross-validation was performed using a 10-fold cross-validation approach, which helps in assessing the model's performance and generalizability.\n\nThe performance metrics, such as sensitivity, specificity, balanced accuracy, and overall accuracy, were calculated for both the training and test sets. These metrics provide a comprehensive view of the model's performance across different classes. The sensitivity and specificity values indicate how well the model can correctly identify positive and negative cases, respectively. The balanced accuracy takes into account the performance on both positive and negative classes, providing a more balanced view, especially when dealing with imbalanced datasets.\n\nThe results were analyzed using statistical methods to ensure their significance. The use of cross-validation and the calculation of mean decrease accuracy (MDA) and mean decrease Gini (MDG) values helped in identifying the most important features contributing to the model's performance. The area under the curve (AUC) values were also calculated using receiver operating characteristic (ROC) analysis, which provides a measure of the model's ability to distinguish between different classes.\n\nThe ensemble classification algorithm, 'bagging', was used to further improve the classification performance. This method combines multiple models to enhance the overall accuracy and robustness of the predictions. The bagging approach was applied using pre-selected features from each binary classifier, ensuring that the final model could simultaneously achieve good classification performance across all five NTM groups.\n\nThe statistical significance of the results was assessed to claim that the method is superior to others and baselines. The high sensitivity, specificity, and AUC values, along with the consistent performance across different datasets, indicate that the proposed method is effective and reliable for identifying the five NTM species. The use of cross-validation and statistical analysis ensures that the results are not due to chance and that the method can be generalized to new, unseen data.",
  "evaluation/availability": "Not enough information is available."
}