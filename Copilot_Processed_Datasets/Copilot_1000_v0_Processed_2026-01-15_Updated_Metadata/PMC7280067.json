{
  "publication/title": "Applying Machine Learning Models to Predict Medication Nonadherence in Crohn's Disease Maintenance Therapy.",
  "publication/authors": "Wang L, Fan R, Zhang C, Hong L, Zhang T, Chen Y, Liu K, Wang Z, Zhong J",
  "publication/journal": "Patient preference and adherence",
  "publication/year": "2020",
  "publication/pmid": "32581518",
  "publication/pmcid": "PMC7280067",
  "publication/doi": "10.2147/ppa.s253732",
  "publication/tags": "- Machine Learning\n- Predictive Modeling\n- Azathioprine Nonadherence\n- Crohn's Disease\n- Support Vector Machine\n- Logistic Regression\n- Neural Networks\n- Feature Selection\n- Patient Adherence\n- Clinical Data Analysis\n- Random Forest\n- Cross-Validation\n- Medical Outcomes\n- Stratified Sampling\n- Performance Evaluation",
  "dataset/provenance": "The dataset used in this study was sourced from patients attending the GI Department. A total of 553 patients were initially solicited, but after applying exclusion criteria and accounting for refusals and incomplete data, 446 patients were included in the final analysis. These patients were on azathioprine (AZA) maintenance therapy for Crohn's disease, with an average duration of AZA use being 34.3 months. The dataset included various characteristics such as age, marital status, education level, alcoholism, psychological distress, and medication beliefs and knowledge. Notably, 41.9% of the patients were identified as non-adherent to AZA, defined by a Morisky Medication Adherence Scale (MARS) score of less than 17, indicating an adherence rate of less than 80%. The dataset also included information on the incidence rates of moderate-to-severe anxiety and depression, which were found to be 18.2% and 12.1%, respectively. This dataset was unique to this study and had not been previously used in other publications by the community.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a testing set. The ratio used for this split was 9:1, meaning 90% of the data was allocated to the training set, and the remaining 10% was used for testing. This division was done randomly to ensure that the models could be trained effectively and then evaluated on unseen data.\n\nAdditionally, a stratified 10-fold cross-validation procedure was employed. This involved dividing the dataset into 10 subsets, or folds, where each fold was used once as a validation set while the remaining 9 folds were used for training. This process was repeated 10 times, with each fold serving as the validation set exactly once. This method helps to limit overfitting and selection bias, ensuring that the models generalize well to new data.",
  "dataset/redundancy": "The dataset used in this study consisted of 446 patients on AZA maintenance therapy. This dataset was first constructed using identified features and classification labels of AZA adherence for all patients. It was then randomly divided into training and testing sets in a 9:1 ratio. This split ensures that the training set is large enough to capture the underlying patterns in the data, while the testing set provides an independent evaluation of the model's performance.\n\nTo limit overfitting and selection bias, a stratified 10-fold cross-validation procedure was employed. This technique involves dividing the training set into 10 subsets, or folds, and then training the model on 9 of these folds while validating it on the remaining fold. This process is repeated 10 times, with each fold serving as the validation set once. This approach helps to ensure that the model generalizes well to unseen data and is not overly tailored to the training set.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of medical adherence prediction. The use of a stratified approach in both the initial split and the cross-validation ensures that the distribution of adherence and nonadherence cases is consistent across the training and testing sets. This consistency is crucial for developing reliable and generalizable prediction models.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is Support Vector Machine (SVM). SVM is a well-established supervised machine learning algorithm commonly used for data classification modeling. It is not a new algorithm, having been developed in the 1990s. The SVM algorithm was implemented using the open-source software library LIBSVM.\n\nThe choice of SVM for this study was driven by its effectiveness in handling complex clinical data and its ability to manage nonlinear relationships between features and outcomes. The SVM model constructed used a radial basis function (RBF) kernel, which is particularly suited for such tasks. The parameters C and \u03b3 were optimized through grid-search using cross-validation to ensure the model's robustness and generalization.\n\nThe decision to use SVM in this context was based on its proven track record in similar classification tasks and its ability to deliver high accuracy and reliability. The focus of this study was on applying machine learning to predict AZA nonadherence in Crohn's disease patients, rather than on developing a new machine-learning algorithm. Therefore, the use of a well-known and widely accepted algorithm like SVM was appropriate for achieving the study's objectives.",
  "optimization/meta": "The study does not employ a meta-predictor. Instead, it develops and compares three distinct machine learning models: logistic regression, back-propagation neural network, and support vector machine (SVM). Each model is trained and validated independently using the same dataset, which is divided into training and testing sets in a 9:1 ratio. The models are evaluated based on their performance metrics, including accuracy, recall, precision, F1 score, and the area under the receiver operating characteristic curve (AUC).\n\nThe dataset used for training and testing these models is constructed from features selected through a combination of univariate analysis and random forest methods. This feature selection process helps in identifying the most predictive variables for AZA nonadherence, ensuring that the models are built on a robust set of features.\n\nThe models are developed using different software tools: logistic regression is developed using SPSS 22.0, the back-propagation neural network is developed using MATLAB R2017a, and the SVM model is developed using the open-source LIBSVM library. Each model undergoes a strati\ufb01ed 10-fold cross-validation procedure to limit over\ufb01tting and selection bias, ensuring that the models generalize well to independent datasets.\n\nThe performance of the models is compared using five evaluation metrics, and the SVM model is found to outperform the other two models in nearly every aspect, suggesting its suitability for predicting AZA nonadherence in the maintenance therapy among Chinese CD patients.",
  "optimization/encoding": "For the machine learning algorithms, the input features were normalized into the range of 0 to 1. This normalization process was crucial for ensuring that all features contributed equally to the model's learning process, regardless of their original scales.\n\nThe classification labels for adherence and non-adherence to AZA were designated as 1 and -1, respectively. This binary encoding was necessary to meet the format requirements of the support vector machine (SVM) model, which was one of the algorithms used in this study.\n\nThe SVM model utilized a radial basis function (RBF) kernel, which is particularly effective for handling non-linear relationships between features and the adherence outcome. The RBF kernel includes two key parameters: C and \u03b3. The parameter C acts as a weight between empirical error and generalization error, while \u03b3 controls the shape of the separating hyperplane. These parameters were optimized using a grid-search method with cross-validation to find the pair of (C, \u03b3) that yielded the highest accuracy.\n\nIn addition to SVM, other models such as logistic regression and back-propagation neural networks were also developed. For logistic regression, variables with a P-value less than 0.05 were included in the model. The linearity of continuous variables was tested using the Box-Tidwell Transformation, and if any resulting statistic terms were significant, the associated continuous variables were translated into categorical variables. The variation inflation factor (VIF) was used to check for multicollinearity, and variables with a VIF greater than 10 were eliminated.\n\nFor the back-propagation neural network, a model with two hidden layers was chosen to handle the potential non-linear separability of the data. The number of nodes in each hidden layer was determined through trial and error. The transfer function between the input/hidden and hidden/output layers was generated using the sigmoid function, and the training process was achieved using the Levenberg-Marquardt optimization algorithm.",
  "optimization/parameters": "The model utilized eight input parameters. These parameters were selected through a combination of random forest and univariate analysis. Random forest was employed to build 100 classification trees based on the original dataset, identifying features with the highest predictive accuracy. The top-10 features from this analysis were then cross-examined with those from univariate analysis. This process yielded eight common features that were selected for modeling. These features included age, education, alcoholism, anxiety, depression, medication necessity belief, medication knowledge, and medication concerns belief. This approach ensured that the selected features were both important and statistically significant, enhancing the model's predictive performance.",
  "optimization/features": "Feature selection was performed using a combination of univariate analysis and random forest methods. The importance of each predictor was evaluated using permutation of out-of-bag prediction. The interaction test was applied instead of classification and regression trees to grow unbiased trees. The variables in common between the random forest and univariate analysis were chosen as the feature set for model construction. This resulted in a feature set of eight-dimensional vectors. These eight features were used as input for the models. The feature selection process was conducted using the entire dataset before it was split into training and testing sets.",
  "optimization/fitting": "The fitting method employed in this study involved the use of three different machine learning models: logistic regression, back-propagation neural network, and support vector machine (SVM). Each model was developed and validated using a dataset of patients undergoing AZA maintenance therapy.\n\nThe dataset was divided into training and testing sets in a 9:1 ratio to ensure that the models were trained on a sufficient number of samples. This division helped in evaluating the models' performance on unseen data, thereby reducing the risk of overfitting.\n\nTo address the potential issue of overfitting, especially in models with a large number of parameters relative to the training points, several strategies were implemented. Firstly, a stratified 10-fold cross-validation procedure was employed. This technique helps in assessing the model's performance across different subsets of the data, ensuring that the model generalizes well to new, unseen data. Secondly, feature selection was performed using random forest and univariate analysis. This step reduced the dimensionality of the feature set, focusing on the most important predictors and thereby simplifying the models. Additionally, for the SVM model, parameters C and \u03b3 were optimized using grid-search with cross-validation, ensuring that the model balanced between empirical error and generalization error.\n\nUnderfitting was mitigated by carefully selecting the model architectures. For the back-propagation neural network, two hidden layers were used, which have been found sufficient for creating classification regions of any desired shape. The logistic regression model was constructed using a stepwise approach, ensuring that only significant variables were included. The SVM model utilized a radial basis function (RBF) kernel, which is effective in handling nonlinear relationships between features and the adherence outcome.\n\nOverall, these methods ensured that the models were neither too complex (leading to overfitting) nor too simple (leading to underfitting), thereby achieving a balanced and reliable prediction of AZA nonadherence.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our models. Firstly, we utilized a stratified 10-fold cross-validation procedure. This method helps to limit overfitting and selection bias by ensuring that each fold of the data is used for both training and validation, providing a more reliable estimate of model performance.\n\nAdditionally, feature selection was performed using a combination of random forest and univariate analysis. This step helped to reduce the dimensionality of the feature set, which not only sped up the model development process but also helped to avoid overfitting by focusing on the most relevant features.\n\nFor the support vector machine (SVM) model, we optimized the parameters C and \u03b3 using grid-search with cross-validation. This process involved systematically working through multiple combinations of parameter values to find the pair that yielded the highest accuracy, further enhancing the model's generalization ability.\n\nIn the logistic regression model, we checked for multicollinearity using the variation inflation factor (VIF). Variables with a VIF greater than 10 were eliminated to ensure that the model was not overly influenced by correlated features, which can lead to overfitting.\n\nThese techniques collectively contributed to the development of reliable and generalizable models for predicting AZA nonadherence in CD patients.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, for the Support Vector Machine (SVM) model, we utilized the radial basis function (RBF) kernel with parameters C and \u03b3, which were optimized through grid-search using cross-validation. The pair of (C & \u03b3) with the highest accuracy was selected for continuous training steps until the final classifier was produced.\n\nFor the back-propagation neural network, the transfer function between the input/hidden and hidden/output layers was generated using the sigmoid function (logsig), and the training function was achieved using trainlm according to Levenberg-Marquardt optimization. The network consisted of two hidden layers, which have been found sufficient for creating classification regions of any desired shape.\n\nThe logistic regression model was developed using SPSS 22.0, and variables with a P-value <0.05 were included. The linearity in the logit for continuous variables was tested using the Box-Tidwell Transformation, and variables with a variation inflation factor (VIF) > 10 were eliminated to ensure the absence of multicollinearity.\n\nRegarding the availability of model files and optimization parameters, the specific details and configurations are described within the text of the publication. However, the actual model files and optimization parameters are not directly provided in the publication. For access to the datasets or specific model files, interested parties would need to contact the authors directly, as the publication does not specify an open-access repository or license for these resources.",
  "model/interpretability": "The models developed in this study, including logistic regression, back-propagation neural network, and support vector machine (SVM), vary in their levels of interpretability.\n\nThe logistic regression model is relatively transparent. It provides clear coefficients for each feature, indicating the direction and strength of their influence on the outcome. This transparency allows for straightforward interpretation of how each variable contributes to the prediction of AZA nonadherence. For instance, higher educational degrees, enhanced levels of anxiety and depression, and less medication beliefs and knowledge were identified as risk factors for nonadherence. These variables can serve as targets for tailored engagement programs.\n\nIn contrast, the back-propagation neural network and SVM models are more black-box in nature. These models, particularly the neural network, involve complex interactions between layers and nodes, making it difficult to trace the exact influence of individual features on the predictions. While these models demonstrated superior performance in terms of accuracy, recall, precision, and AUC, their internal workings are less interpretable. This lack of transparency can be a challenge in clinical settings where understanding the rationale behind predictions is crucial.\n\nThe SVM model, although powerful, also suffers from a lack of interpretability. The use of a radial basis function kernel and the optimization of parameters like C and \u03b3 add layers of complexity that obscure the direct relationship between input features and the output. However, the SVM model's high performance in predicting AZA nonadherence makes it a valuable tool despite its black-box nature.\n\nIn summary, while the logistic regression model offers clear interpretability, the back-propagation neural network and SVM models, though highly effective, are more opaque. This trade-off between performance and interpretability is a common consideration in the development and application of machine learning models in healthcare.",
  "model/output": "The model is a classification model. It was developed to predict whether patients would be adherent or nonadherent to azathioprine (AZA) maintenance therapy. The output of the model is a classification label indicating adherence or nonadherence. Specifically, the labels used were 1 for adherence and -1 for nonadherence. The performance of the model was evaluated using metrics such as accuracy, recall, precision, F1 score, and the area under the receiver operating characteristic curve (AUC), which are commonly used for assessing classification models. The model's primary goal is to classify patients into these two categories based on various features, aiming to identify those at risk of nonadherence.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive approach to ensure the reliability and generalizability of the models. The dataset, consisting of identified features and classification labels for 446 patients, was randomly divided into training and testing sets in a 9:1 ratio. This division allowed for robust training of the models while reserving a portion of the data for unbiased evaluation.\n\nThe modeling process consisted of two main steps: the learning process and the evaluation process. During the learning process, three different models\u2014logistic regression, back-propagation neural network, and support vector machine (SVM)\u2014were applied and validated on both the training and testing sets. To mitigate overfitting and selection bias, a stratified 10-fold cross-validation procedure was employed. This technique involved dividing the dataset into 10 subsets, training the models on 9 subsets, and validating on the remaining subset, repeating this process 10 times with different subsets.\n\nIn the evaluation process, five key metrics were used to assess the performance of each model: accuracy, recall, precision, F1 score, and the area under the receiver operating characteristic curve (AUC). Accuracy measured the proportion of true results (both true positives and true negatives) among the total number of cases. Recall, also known as sensitivity, indicated the proportion of actual positives that were correctly identified by the model. Precision, or positive predictive value, measured the proportion of true positives among the predicted positives. The F1 score provided a harmonic mean of precision and recall, offering a single metric that balances both concerns. AUC provided a comprehensive assessment of the model's ability to distinguish between classes, with higher values indicating better performance.\n\nThe logistic regression model was developed using SPSS, with variables having P-values less than 0.05 included in the model. The linearity of continuous variables was tested using the Box-Tidwell Transformation, and variables were converted to categorical if necessary. The variation inflation factor (VIF) was used to check for multicollinearity, with variables having VIF greater than 10 being eliminated. A stepwise approach was then applied to construct the logistic regression model.\n\nThe back-propagation neural network model was developed using MATLAB. Given the potential non-linearity in predicting patient nonadherence, a network with two hidden layers was chosen. The number of nodes in each hidden layer was determined through trial and error. The transfer function between layers used the sigmoid function, and the training function employed the Levenberg-Marquardt optimization algorithm.\n\nThe SVM model was developed using the open-source LIBSVM library. Input features were normalized to the range of 0 to 1, and class labels were designated as 1 and -1. The radial basis function (RBF) kernel was used, with parameters C and \u03b3 optimized through grid-search and cross-validation to achieve the highest accuracy. The final classifier was then validated on the testing dataset.\n\nOverall, the evaluation method ensured that the models were thoroughly tested and validated, providing reliable performance metrics and insights into their generalizability.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our machine learning models. The primary metrics we reported include accuracy, recall, precision, F1 score, and the area under the receiver operating characteristic curve (AUC).\n\nAccuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It provides a general sense of how well the model performs overall.\n\nRecall, also known as sensitivity, focuses on the model's ability to identify positive cases correctly. It is particularly important in scenarios where the cost of false negatives is high.\n\nPrecision, on the other hand, assesses the proportion of true positive predictions among all positive predictions made by the model. It is crucial when the cost of false positives is significant.\n\nThe F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. It is especially useful when there is an uneven class distribution.\n\nThe AUC is a more comprehensive measure that evaluates the model's ability to distinguish between classes across all possible classification thresholds. It provides a single scalar value that summarizes the model's performance, making it a widely accepted metric in the literature.\n\nThese metrics collectively offer a robust evaluation framework, ensuring that our models are assessed from multiple angles. This approach is consistent with established practices in the field, where a combination of these metrics is commonly used to provide a thorough assessment of model performance.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, we focused on developing and evaluating three specific machine learning models\u2014logistic regression, back-propagation neural network, and support vector machine (SVM)\u2014for predicting azathioprine (AZA) nonadherence in Chinese Crohn's disease (CD) patients.\n\nTo ensure the robustness and reliability of our models, we employed a stratified 10-fold cross-validation procedure. This method helps to identify selection bias or overfitting, providing insights into how the models would generalize on an independent dataset. By using this approach, we aimed to enhance model generalization and improve classification performance.\n\nAdditionally, we compared the performance of our models using several metrics, including accuracy, recall, precision, F1 score, and the area under the receiver operating characteristic curve (AUC). These metrics allowed us to assess the predictive ability of each model comprehensively.\n\nWhile we did not compare our methods to simpler baselines explicitly, the feature selection process involved combining univariate analysis and random forest. This combination helped to produce a feature set with reduced dimensionality, which is crucial for avoiding overfitting and enhancing model generalization. The use of random forest for feature selection is well-established in classification tasks, particularly in identifying genetic biomarkers to predict disease outcomes.\n\nIn summary, our evaluation focused on internal validation and performance metrics rather than direct comparisons to publicly available methods or simpler baselines. The stratified 10-fold cross-validation and the combination of feature selection methods ensured that our models were reliable and generalizable.",
  "evaluation/confidence": "The evaluation of the models' performance was conducted using several metrics, including accuracy, recall, precision, F1 score, and the area under the receiver operating characteristic curve (AUC). These metrics provide a comprehensive assessment of the models' predictive abilities.\n\nThe minimum accuracy reported across the models was 81.6%, with an AUC of 0.896, indicating generally good performance. The support vector machine (SVM) model, in particular, demonstrated superior performance with an accuracy of 87.7%, recall of 86.2%, precision of 85.6%, F1 score of 0.855, and an AUC of 0.930. These results suggest that the SVM model is highly effective in predicting AZA nonadherence.\n\nStatistical significance was regarded as P-values less than 0.05. This threshold was applied to ensure that the findings were not due to random chance. The use of a strati\ufb01ed 10-fold cross-validation procedure further enhanced the reliability of the results by identifying selection bias or over\ufb01tting. This step is crucial for understanding how the models would generalize to independent datasets.\n\nThe combination of random forest and univariate analysis for feature selection also contributed to the models' robustness. This approach helped in reducing the dimensionality of the feature set, which in turn minimized the risk of over\ufb01tting and improved model generalization. The feature set consisted of eight-dimensional vectors, which were selected based on their importance measures and commonality between the two methods.\n\nIn summary, the performance metrics were rigorously evaluated, and the results were statistically significant. The use of cross-validation and a well-defined feature selection process further bolstered the confidence in the models' predictive capabilities. The SVM model, in particular, showed outstanding performance, making it a reliable tool for predicting AZA nonadherence in clinical settings.",
  "evaluation/availability": "Not enough information is available."
}