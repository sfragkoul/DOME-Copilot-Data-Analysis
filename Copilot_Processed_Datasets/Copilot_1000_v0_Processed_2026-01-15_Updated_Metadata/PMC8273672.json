{
  "publication/title": "Application of convolutional neural networks for distal radio-ulnar fracture detection on plain radiographs in the emergency room.",
  "publication/authors": "Kim MW, Jung J, Park SJ, Park YS, Yi JH, Yang WS, Kim JH, Cho BJ, Ha SO",
  "publication/journal": "Clinical and experimental emergency medicine",
  "publication/year": "2021",
  "publication/pmid": "34237817",
  "publication/pmcid": "PMC8273672",
  "publication/doi": "10.15441/ceem.20.091",
  "publication/tags": "- Wrist\n- Fractures, bone\n- Deep learning\n- Neural networks, computer\n- Emergency room\n- Radiographs\n- Distal radio-ulnar fracture\n- Convolutional neural networks\n- DenseNet-161\n- ResNet-152",
  "dataset/provenance": "The dataset used in this study was sourced from the emergency room (ER) of Hallym University Sacred Heart Hospital. It consists of radiographs of patients who underwent plain radiography due to wrist trauma between January 2018 and May 2020. The dataset includes 2,609 patients, with a total of 9,984 radiographs. These radiographs were retrieved from the hospital\u2019s picture archiving and communication system (PACS) using INFINITT PACS M6 software.\n\nThe dataset was split into two subsets: training and testing. Radiographs taken between January 2018 and December 2019 were included in the training dataset, while those taken between January 2020 and May 2020 were included in the testing dataset. The training dataset consists of 8,994 radiographs from 2,279 patients, and the test dataset consists of 990 radiographs from 330 patients.\n\nThe radiographs were classified into two groups: non-fracture and fracture. The fracture group includes images of radial, ulnar, and radio-ulnar fractures. The dataset was annotated based on dual radiological reporting, and poor-quality images or those lacking radiologist classifications were excluded. The images were preprocessed using a contrast-limited adaptive histogram equalization (CLAHE) algorithm to enhance local contrast and were reduced to 550 \u00d7 660 pixels for analysis.\n\nPrevious studies have used various deep-learning models for fracture diagnosis, but they often collected and analyzed heterogeneous image data, which limited their clinical use in emergency room settings. This study aimed to develop a model representative of emergency room settings with satisfactory performance to recognize fractures of the wrist. The dataset used in this study is specific to ER patients with wrist trauma and was collected to address the limitations of previous studies.",
  "dataset/splits": "The dataset was divided into three distinct splits: training, tuning, and testing. The training dataset comprised radiographs taken between January 2018 and December 2019, while the testing dataset included radiographs from January 2020 to May 2020. Additionally, 10% of the training dataset was allocated to a tuning dataset for hyperparameter tuning.\n\nThe training dataset consisted of 8,994 radiographs from 2,279 patients. Within this dataset, there were 4,443 radiographs from 1,481 patients without fractures and 4,551 radiographs from 798 patients with fractures. The test dataset contained 990 radiographs from 330 patients, with 690 radiographs from 230 patients without fractures and 300 radiographs from 100 patients with fractures. The tuning dataset, which was 10% of the training dataset, was used for hyperparameter tuning and was separated from the training and testing datasets.\n\nThe distribution of data points in each split reflected the overall dataset, which had approximately half as many radiographs in the fracture group as in the non-fracture group. To address this imbalance, oversampling was employed by doubling the number of radiographs in the fracture group in the training dataset through a 10% zoom-in technique. No image flipping or rotation was applied during this process.",
  "dataset/redundancy": "The dataset used in this study was split into two subsets: training and testing. Radiographs taken between January 2018 and December 2019 were included in the training dataset, while those taken between January 2020 and May 2020 were included in the test dataset. This temporal split ensures that the training and test sets are independent, as they do not overlap in time.\n\nTo enforce this independence, we allocated 10% of the training dataset using patient identification numbers. This means that the test set contains data from patients who were not included in the training set, ensuring that the model's performance is evaluated on unseen data.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of wrist fracture detection. The dataset includes a significant number of radiographs from patients with wrist trauma, providing a robust basis for training and testing the models. Specifically, the training dataset consisted of 4,551 radiographs from 798 patients with fractures and 4,443 radiographs from 1,481 patients without fractures. The test dataset included 300 radiographs from 100 patients with fractures and 690 radiographs from 230 patients without fractures. This distribution ensures a balanced representation of both fracture and non-fracture cases, which is crucial for the model's generalizability and performance.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is convolutional neural networks (CNNs). Specifically, we employed two well-established CNN architectures: DenseNet-161 and ResNet-152. These models are not new; they have been widely used and validated in the field of computer vision and image classification.\n\nDenseNet-161 is characterized by its dense blocks, where each layer receives inputs from all preceding layers and passes on its feature maps to all subsequent layers. This design ensures that each layer has access to the gradients from the loss function and the original input, facilitating efficient training and feature reuse.\n\nResNet-152, on the other hand, utilizes residual blocks with skip connections. These connections allow the model to learn residual functions, making it easier to train very deep networks by mitigating the vanishing gradient problem. ResNet-152 has been particularly successful in image classification tasks and won the ImageNet Large Scale Visual Recognition Challenge in 2015.\n\nBoth models were pretrained on the ImageNet dataset and fine-tuned for our specific task of wrist fracture detection. The choice of these architectures was driven by their proven effectiveness in similar image classification tasks, rather than the need to develop a new algorithm. Publishing in a machine-learning journal was not a priority for this study, as our focus was on applying established techniques to a specific medical problem. The models were trained using the Adam optimizer with a binary cross-entropy loss function, and various techniques such as learning rate decay and early stopping were employed to optimize performance and prevent overfitting.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, data preprocessing was a crucial step to enhance the performance of our convolutional neural network (CNN) models. We began by applying a contrast-limited adaptive histogram equalization (CLAHE) algorithm to the radiographs. This technique was used to improve local contrast, which is essential for better visualization of fractures. The CLAHE algorithm helps to mitigate noise amplification issues that can occur with adaptive histogram equalization, ensuring that the processed images clearly reveal fractures.\n\nBefore applying the CLAHE algorithm, histogram values were clipped to a predefined value to limit noise amplification. This step is vital for maintaining the integrity of the image data while enhancing the relevant features. The CLAHE algorithm was implemented using OpenCV version 4.1.2.30 in Python, a robust tool for image processing tasks.\n\nFollowing contrast enhancement, all images were resized to 550 \u00d7 660 pixels. This resizing was done to balance memory capacity, batch sizes, training times, and model performance. By standardizing the image size, we ensured consistency in the input data for our CNN models, which is essential for efficient training and accurate predictions.\n\nThe datasets used in this study were separated into three groups: training, validation, and testing. The number of radiographs in the fracture group was approximately half that of the non-fracture group. To address this imbalance, we employed oversampling techniques. Specifically, the number of radiographs in the fracture group in the training dataset was doubled by zooming in on the images by 10%. This approach helped to mitigate the limitations posed by the class imbalance, ensuring that the models were adequately trained to detect fractures.\n\nNo additional image transformations, such as flipping or rotation, were applied beyond the zooming-in technique. This decision was made to preserve the natural characteristics of the radiographs, which are crucial for accurate fracture detection.\n\nIn summary, our data preprocessing steps involved enhancing image contrast using the CLAHE algorithm, resizing images to a standard dimension, and employing oversampling to balance the dataset. These preprocessing techniques were essential for preparing the data for effective training of our CNN models, DenseNet-161 and ResNet-152.",
  "optimization/parameters": "In our study, we utilized two convolutional neural network (CNN) architectures: DenseNet-161 and ResNet-152. These models were pretrained on the ImageNet dataset and fine-tuned for our specific task of wrist fracture detection.\n\nDenseNet-161 consists of dense blocks where all output feature maps are propagated to all deeper layers as input. This architecture encourages feature reuse and reduces the number of parameters, which helps in achieving state-of-the-art performance without overfitting. The number of parameters in DenseNet-161 is substantial, but it is designed to handle complex image classification tasks efficiently.\n\nResNet-152, on the other hand, is designed with residual blocks that include skip connections. These connections allow the model to learn residual features, enabling deeper layers and improving performance. ResNet-152 also has a large number of parameters, but its residual connections help in mitigating the vanishing gradient problem, making it suitable for deep networks.\n\nThe selection of these models was based on their proven performance in image classification tasks. Both DenseNet-161 and ResNet-152 have been successful in various computer vision challenges, including the ImageNet Large Scale Visual Recognition Challenge. Their architectures are well-suited for handling the complexity of medical imaging data, making them ideal choices for our study on wrist fracture detection.\n\nDuring the training process, we used the Adam optimizer with specific beta values and a binary cross-entropy loss function. The initial learning rate was set to 1e-4, with a decay policy that reduced the learning rate by 90% every 10 epochs until it reached 1e-7. The batch size was set to 4, and weight decay was applied at 1e-4. Early stopping was used to prevent overfitting, with a starting point of 30 epochs and a patience of 20 epochs. These parameters were chosen to ensure efficient training and to avoid overfitting, given the size and nature of our dataset.",
  "optimization/features": "The input features for our convolutional neural network (CNN) models consisted of preprocessed wrist radiographs. The images were preprocessed using a contrast-limited adaptive histogram equalization (CLAHE) algorithm to enhance local contrast, which helped in revealing fractures more clearly. All images were then resized to 550 \u00d7 660 pixels to balance memory capacity, batch sizes, training times, and model performance.\n\nFeature selection in the traditional sense was not applicable, as we used raw image data as input features. Instead, the models were designed to automatically learn relevant features from the images during training. The two CNN architectures used were DenseNet-161 and ResNet-152, both of which are known for their ability to extract hierarchical features from images.\n\nThe dataset was split into training (90%) and test (10%) sets. The training set was used to fine-tune the pretrained models on our specific task of wrist fracture detection. This process involved adjusting the models' parameters to better capture the relevant features for distinguishing between fractured and non-fractured wrists. The test set was used to evaluate the performance of the trained models, ensuring that the models generalized well to unseen data.",
  "optimization/fitting": "In our study, we employed two convolutional neural network (CNN) architectures, DenseNet-161 and ResNet-152, both of which are known for their deep structures and large number of parameters. The number of parameters in these models is indeed much larger than the number of training points, which could potentially lead to overfitting.\n\nTo mitigate overfitting, several strategies were implemented. First, we used a learning rate decay policy, reducing the learning rate by 90% every 10 epochs until it reached 1e-7. This gradual reduction helps in fine-tuning the model and prevents it from overfitting to the training data. Second, early stopping was employed with a starting point of 30 epochs and a patience of 20, meaning the training process would halt if the model's performance on a validation set did not improve for 20 consecutive epochs. This technique ensures that the model does not continue to train beyond the point where it starts to overfit.\n\nAdditionally, we utilized data augmentation techniques such as oversampling the fracture group by zooming in 10% on the images. This approach helped in balancing the dataset and providing the model with more varied training examples, thereby reducing the risk of overfitting.\n\nTo address the potential issue of underfitting, we fine-tuned the models using a pretrained ImageNet dataset. This transfer learning approach leverages the knowledge gained from a large and diverse dataset, enabling the models to generalize better to our specific task of wrist fracture detection. Furthermore, the use of advanced architectures like DenseNet-161, which encourages feature reuse and reduces the number of parameters, and ResNet-152, which employs residual connections to learn residual features, ensures that the models are capable of capturing complex patterns in the data without being too simplistic.\n\nThe combination of these techniques\u2014learning rate decay, early stopping, data augmentation, and transfer learning\u2014helped us to effectively manage both overfitting and underfitting, ensuring robust and generalizable performance of our models.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting during the training of our convolutional neural network (CNN) models. One of the primary methods used was early stopping. This technique involves monitoring the model's performance on a validation dataset and halting the training process when the performance stops improving. Specifically, we set the starting point for early stopping at 30 epochs and used a patience of 20 epochs, meaning the training would stop if the validation performance did not improve for 20 consecutive epochs.\n\nAdditionally, we utilized a learning rate decay policy. The initial learning rate was set to 1e-4, and it was decreased by 90% every 10 epochs until it reached 1e-7. This gradual reduction in the learning rate helps the model to converge more smoothly and prevents it from getting stuck in local minima, thereby reducing the risk of overfitting.\n\nWe also implemented weight decay, also known as L2 regularization, with a value of 1e-4. Weight decay adds a penalty to the loss function based on the magnitude of the weights, encouraging the model to keep the weights small and thus reducing the complexity of the model.\n\nAnother technique we employed was data augmentation. Given the imbalance in the number of radiographs between the fracture and non-fracture groups, we used oversampling by zooming in on the fracture group images by 10%. This helped to balance the dataset and improve the model's generalization ability.\n\nThese regularization methods collectively ensured that our models were robust and generalizable, reducing the likelihood of overfitting to the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed two convolutional neural network architectures: DenseNet-161 and ResNet-152. Both models were pretrained on the ImageNet dataset and fine-tuned during our training process. The Adam optimizer was utilized with specific beta values and a binary cross-entropy loss function. The initial learning rate was set at 1e-4, with a decay policy that reduced the learning rate by 90% every 10 epochs until it reached 1e-7. The batch size was 4, and weight decay was set at 1e-4. Early stopping was implemented with a starting point of 30 epochs and a patience of 20 to prevent overfitting. Dropout was not applied in either model. The models were implemented using the PyTorch deep-learning framework and trained on an NVIDIA GeForce Titan RTX graphics-processing unit.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the detailed configurations and schedules are thoroughly described, allowing for reproducibility. The publication is available under the terms specified by the journal, which typically include standard academic sharing and citation practices. For specific details on accessing the full text or additional materials, readers can refer to the journal's policies or contact the corresponding authors.",
  "model/interpretability": "The models used in this study, DenseNet-161 and ResNet-152, are not entirely black-box models. To enhance interpretability, we employed Gradient-weighted Class Activation Mapping (Grad-CAM). This technique highlights the regions of the radiograph scans that are most influential in the model's decision-making process. By using Grad-CAM, we can visualize which areas of the wrist radiographs the models focus on to detect fractures. For instance, in the case of a pediatric patient, both models highlighted the fracture area with a probability of 100%. Similarly, for an adult patient, the probabilities were 100% and 99.4%, respectively. This visualization helps in understanding the model's decision-making process and ensures that the models are focusing on the relevant areas of the radiographs.",
  "model/output": "The model developed in this study is a classification model. It is designed to detect the presence of wrist fractures in plain radiographs. Specifically, it categorizes radiographs into two classes: those with fractures and those without. The model uses convolutional neural networks (CNNs), namely DenseNet-161 and ResNet-152, to analyze the images and make these classifications. The performance of the model was evaluated using metrics such as sensitivity, specificity, positive predictive value, negative predictive value, and accuracy, which are typical for classification tasks. Additionally, the area under the receiver operating characteristic curve (AUROC) was computed to assess the model's ability to distinguish between the two classes.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the convolutional neural network models used in this study, specifically DenseNet-161 and ResNet-152, is not explicitly released as part of this publication. These models were implemented using the PyTorch deep-learning framework. The specific implementations and training details, including the use of the Adam optimizer, binary cross-entropy loss function, and learning rate decay policy, are described in the methods section. However, the exact code and trained models are not made publicly available.\n\nThe preprocessing steps, including the use of the contrast-limited adaptive histogram equalization (CLAHE) algorithm implemented with OpenCV, are also detailed. This algorithm was used to enhance the local contrast of the radiographs, which is crucial for accurate fracture detection. The images were resized to 550 \u00d7 660 pixels to optimize memory usage and training times.\n\nFor those interested in replicating the study or using similar models, the descriptions provided in the methods section offer a comprehensive guide to the techniques and parameters used. However, the specific code and trained models are not provided, so interested parties would need to implement the described methods independently.\n\nNot applicable",
  "evaluation/method": "The evaluation method for the study involved using a separate test dataset to assess the performance of the convolutional neural network (CNN) models, specifically DenseNet-161 and ResNet-152. The models were trained on a dataset of wrist radiographs collected from emergency room patients with wrist trauma. The test dataset consisted of radiographs taken between January 2020 and May 2020, while the training dataset included radiographs from January 2018 to December 2019.\n\nTo evaluate the models, several key metrics were computed. These included the area under the receiver operating characteristic curve (AUROC), accuracy, sensitivity, specificity, positive predictive value, and negative predictive value. The Youden index was used to determine the optimal threshold on the ROC curves, which is a criterion for finding the optimal threshold regardless of prevalence.\n\nStatistical analyses were performed using IBM SPSS Statistics version 21.0. Categorical variables were analyzed using the chi-square test, while continuous variables were expressed as mean \u00b1 standard deviation and analyzed using the Student\u2019s t-test. Two-tailed tests were used for all comparisons, and group differences with a P-value of less than 0.05 were considered statistically significant.\n\nAdditionally, DeLong\u2019s test was used to compare the performances of the two models. This method is specifically designed to compare the AUROCs of two correlated ROC curves, providing a robust statistical comparison of the models' performance.\n\nThe evaluation process also included the use of gradient-weighted class activation mapping (Grad-CAM) to visualize the regions of the radiographs that contributed most to the classification decisions made by the AI models. This visualization technique helps in understanding which parts of the radiographs the models are focusing on to make their predictions.",
  "evaluation/measure": "In our study, we evaluated the performance of our convolutional neural network (CNN) models, DenseNet-161 and ResNet-152, using a comprehensive set of metrics to ensure a thorough assessment. The primary metrics reported include sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and accuracy. These metrics were calculated using receiver operating characteristic (ROC) curves at the maximum point, with the Youden index serving as the criterion for determining the optimal threshold.\n\nThe sensitivity and specificity of DenseNet-161 were both 90.3%, indicating its high true positive and true negative rates. The PPV was 80.3%, and the NPV was 95.6%, reflecting the model's ability to correctly predict positive and negative cases. The overall accuracy of DenseNet-161 was 90.3%. For ResNet-152, the sensitivity was 88.6%, and the specificity was 88.4%. The PPV and NPV were 76.9% and 94.7%, respectively, with an overall accuracy of 88.5%.\n\nAdditionally, we computed the area under the receiver operating characteristic curves (AUROCs) for both models. DenseNet-161 achieved an AUROC of 0.962, while ResNet-152 had an AUROC of 0.947. These values indicate strong discriminative power for both models in detecting wrist fractures.\n\nTo compare the performances of the two models, we used DeLong\u2019s test, which confirmed that DenseNet-161 had a statistically significant better performance than ResNet-152.\n\nThese metrics are representative of those commonly reported in the literature for similar studies, ensuring that our evaluation is both rigorous and comparable to other research in the field. The use of AUROC, sensitivity, specificity, PPV, NPV, and accuracy provides a well-rounded view of model performance, addressing various aspects of diagnostic accuracy and reliability.",
  "evaluation/comparison": "Not applicable. The study focused on evaluating the performance of two specific convolutional neural network (CNN) architectures, DenseNet-161 and ResNet-152, for wrist fracture detection. The evaluation was conducted using a separate test dataset derived from emergency room patients with wrist trauma. The performance metrics included accuracy, sensitivity, specificity, positive predictive value, negative predictive value, and the area under the receiver operating characteristic curve (AUROC). The study did not explicitly compare these models to publicly available methods or simpler baselines on benchmark datasets. Instead, the performance of the models was assessed independently, and the results were discussed in the context of previous studies that used different deep-learning models for similar tasks. The comparison with other studies was qualitative rather than quantitative, focusing on the AUROC values and other performance metrics reported in the literature.",
  "evaluation/confidence": "The performance metrics for the convolutional neural network (CNN) models, DenseNet-161 and ResNet-152, were evaluated using a separate test dataset. The area under the receiver operating characteristic curves (AUROCs) were computed for both models, with DenseNet-161 achieving an AUROC of 0.962 and ResNet-152 achieving an AUROC of 0.947. These metrics indicate the models' ability to distinguish between fracture and non-fracture cases effectively.\n\nTo assess the statistical significance of the results, DeLong's test was used to compare the performances of the two models. This test is specifically designed for comparing AUROCs and provides a robust statistical measure. Additionally, two-tailed tests were employed for all comparisons, ensuring that any observed differences were not due to chance. Group differences with a P-value of less than 0.05 were considered statistically significant.\n\nThe accuracy, sensitivity, specificity, positive predictive value, and negative predictive value were also calculated using the Youden index, which is derived from the receiver operating characteristic (ROC) curves at the maximum point. The Youden index, J, is calculated using the formula J = sensitivity + specificity - 1, providing a criterion for finding the optimal threshold of ROC curves regardless of prevalence.\n\nAll statistical analyses were performed using IBM SPSS Statistics version 21.0, ensuring the reliability and validity of the results. The use of established statistical methods and software further supports the confidence in the performance metrics and the statistical significance of the findings.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data consists of patient radiographs and associated annotations, which are sensitive medical information. Therefore, to protect patient privacy and comply with ethical guidelines, these files are not released publicly. However, the performance metrics and results derived from these evaluations are thoroughly detailed in the publication. Researchers interested in replicating or building upon our work can refer to the methods and datasets described in the paper. For specific inquiries or collaborations, interested parties can contact the corresponding authors for further information."
}