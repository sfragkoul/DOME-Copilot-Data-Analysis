{
  "publication/title": "Classification of Sputum Sounds Using Artificial Neural Network and Wavelet Transform.",
  "publication/authors": "Shi Y, Wang G, Niu J, Zhang Q, Cai M, Sun B, Wang D, Xue M, Zhang XD",
  "publication/journal": "International journal of biological sciences",
  "publication/year": "2018",
  "publication/pmid": "29989104",
  "publication/pmcid": "PMC6036751",
  "publication/doi": "10.7150/ijbs.23855",
  "publication/tags": "- Respiratory system diagnosis\n- Auscultation\n- Sputum sound analysis\n- Discrete wavelet transform\n- Artificial neural network\n- Mechanical ventilation\n- Intensive care unit\n- Secretion clearance\n- Ventilator-associated pneumonia\n- Biomedical signal processing",
  "dataset/provenance": "The dataset used in this study consists of sound samples collected from patients with mechanical ventilation in the ICU. The recordings were made at the Department of Pulmonology ICU, Beijing Chaoyang Hospital, Beijing, China. A dedicated system was designed for specific experimental subjects and environments to acquire respiratory sound signals. The sound samples were collected using a connector that links an artificial airway to an acquisition device, followed by signal amplification and digitization through a sound card. The recordings were stored in digital WAVE files, which are time-based and contain uncompressed audio in the pulse-code modulation (PCM) format.\n\nA total of 595 sound samples were obtained, comprising 337 sputum deposition sound signals and 258 non-sputum deposition sound signals. These samples underwent a series of preprocessing steps, including noise reduction and discrete wavelet transform (DWT) for frequency subband decomposition. Statistical features were then extracted from these subbands to represent the distribution of wavelet coefficients. These features were used as inputs for an artificial neural network (ANN) based classification system to distinguish between sputum and non-sputum deposition.\n\nThe dataset leverages the similarities between sputum and lung sounds, utilizing established methods for feature extraction and classification of lung sounds. This approach was validated through experimental studies conducted by the authors. The classification of sputum sounds was performed by a pulmonology group headed by a senior physician specialized in pulmonology and respiratory care, ensuring the accuracy and reliability of the dataset.",
  "dataset/splits": "The dataset used in this study consisted of 595 sound samples, which were divided into 6 disjoint subsets for cross-validation. Each subset contained approximately n/6 samples, where n is the total number of data points. Specifically, 496 samples were used for training, and the remaining 99 samples were used for validation in each iteration. This process was repeated 6 times, ensuring that each subset was used once for validation while the others were used for training. The distribution of data points in each split was designed to maintain a balanced representation of both sputum and non-sputum deposition sound signals across all subsets.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is Artificial Neural Networks (ANNs), specifically Backpropagation (BP) neural networks. These are widely used for modeling, data analysis, and diagnostic classification in the biomedical field.\n\nThe BP algorithm employed is not entirely new; it is one of the most frequently used training algorithms for classification problems. However, to address the slow convergence issues of the traditional BP algorithm, several modified versions were explored. These include adaptive learning rate BP, resilient BP, Levenberg\u2013Marquardt, and scaled conjugate gradient BP algorithms. These modifications aim to improve the training efficiency and performance of the ANN.\n\nThe reason these algorithms were not published in a machine-learning journal is that the focus of this study is on their application in the biomedical field, specifically for classifying sputum sounds. The primary contribution lies in the application and validation of these algorithms in a novel context\u2014sputum sound classification\u2014rather than the development of new machine-learning algorithms. The study demonstrates the effectiveness of these modified BP algorithms in a practical healthcare setting, which is the main novelty presented.",
  "optimization/meta": "The study does not employ a meta-predictor. The primary model used is an artificial neural network (ANN) with a backpropagation (BP) algorithm. This ANN is specifically designed for classification tasks, particularly for distinguishing between sputum and non-sputum sound signals.\n\nThe ANN architecture explored in this study includes various configurations of three-layer and four-layer feedforward networks. The best-performing architecture was identified as the 14-18-2 configuration, which achieved the highest classification accuracy of 84.53%.\n\nWhile the study compares the performance of the ANN with other classifiers such as Bayesnet, Reptree, SVM, and logistic classifiers, these comparisons are used to evaluate the effectiveness of the ANN rather than to integrate them into a meta-predictor. The training data for the ANN is derived from sound samples, which undergo preprocessing, wavelet decomposition, and feature extraction to generate statistical features used as inputs for the ANN.\n\nThe independence of the training data is ensured through the use of cross-validation. The dataset is divided into six subsets, with five subsets used for training and one subset used for testing in each iteration. This process is repeated six times, ensuring that each subset is used for testing once, thereby validating the reliability of the classifier's outcomes.",
  "optimization/encoding": "In our study, the data encoding and preprocessing were crucial steps to ensure the accuracy and reliability of the machine-learning algorithm used for classifying sputum sounds. The process began with the acquisition of sputum sound signals from mechanically ventilated patients in the ICU. These signals were recorded using a dedicated system designed for the specific experimental subjects and environments. The recordings were made under the supervision of a senior physician specialized in pulmonology and respiratory care, ensuring the quality and relevance of the data.\n\nThe recorded signals were stored in the digital WAVE format, which is time-based and contains uncompressed audio in the pulse-code modulation (PCM) format. This format is standard for CDs and includes two channels of 44,100 samples per second, with 16 bits per sample. This high-fidelity format was essential for capturing the nuances of the sputum sounds accurately.\n\nBefore processing, the signals underwent preprocessing to remove noise and ensure they were relatively pure. This step was vital because noise can significantly affect the analysis and classification of signals, especially in high-precision studies. The preprocessing involved filtering out unwanted frequencies and amplifying the relevant sound signals to enhance their clarity.\n\nFollowing preprocessing, the signals were decomposed into frequency subbands using the discrete wavelet transform (DWT). This method allowed us to analyze the signals in both the time and frequency domains, which is crucial for classifying non-stationary signals like sputum sounds. The DWT provided a detailed representation of the signal's characteristics, enabling us to extract meaningful features.\n\nA set of statistical features was then extracted from the subbands to represent the distribution of wavelet coefficients. These features included the energy of detail coefficients, which were calculated for each level of wavelet decomposition. The signals were divided into inspiration and expiration parts, and the features were normalized to ensure consistency across different samples.\n\nThe normalized features were used as inputs to the artificial neural network (ANN) classifier. The ANN was designed with a three-layer architecture, which included an input layer, a hidden layer, and an output layer. The input layer had 14 nodes, corresponding to the number of input feature vectors. The hidden layer had varying numbers of nodes, and the output layer had 2 nodes, representing the two classes of output: sputum or non-sputum deposition.\n\nThe ANN was trained using different architectures to determine the optimal configuration for classification accuracy. Cross-validation was employed to verify the reliability of the classifier's outcomes. The dataset was divided into six subsets, with five subsets used for training and one subset used for testing. This process was repeated six times, and the average classification accuracy was reported for each ANN architecture.\n\nIn summary, the data encoding and preprocessing involved recording high-fidelity sputum sound signals, removing noise through preprocessing, decomposing the signals using DWT, extracting statistical features, and normalizing these features. The processed data were then used to train and validate an ANN classifier, ensuring accurate and reliable classification of sputum sounds.",
  "optimization/parameters": "In our study, the number of input parameters, p, used in the model was 14. This number was selected to match the number of input feature vectors obtained from each sound sample. The features were derived through a series of methods, including preprocessing, wavelet decomposition, and feature extraction. The wavelet decomposition was performed using the db5 wavelet basis, with seven levels of decomposition, ensuring that the relevant frequency components for classification were retained. The extracted features provided a compact representation of the energy distribution of the signal in both time and frequency domains, which were then used as inputs for the artificial neural network (ANN) model. The ANN architecture consisted of three layers, with 14 input nodes corresponding to the 14 feature vectors. This configuration was chosen because a three-layer backpropagation (BP) neural network with a Sigmoid function in its layers can approximate any nonlinear functions with arbitrary precision.",
  "optimization/features": "In our study, we utilized 14 features as input for our artificial neural network (ANN) model. These features were derived from the energy of detail coefficients obtained through wavelet decomposition of sputum sound signals. The signals were divided into inspiration and expiration parts, and after 7 levels of wavelet decomposition, 14 detail coefficients were extracted. These coefficients were then normalized to form the feature space.\n\nFeature selection was performed to ensure that the most relevant features were used for classification. This process was conducted using the training set only, ensuring that the selection was unbiased and did not leak information from the test set. The selected features provided a compact representation of the energy distribution of the signals in both time and frequency domains, which was crucial for the accurate classification of sputum and non-sputum sounds.",
  "optimization/fitting": "In our study, we employed artificial neural networks (ANNs) for classification tasks, specifically using a backpropagation (BP) algorithm. The ANN architecture consisted of three layers: an input layer, a hidden layer, and an output layer. The number of input nodes was set to 14, corresponding to the number of input feature vectors derived from the statistical features of the sound signals. The output layer had 2 nodes, representing the two classes: sputum and non-sputum deposition.\n\nThe hidden layer's size was varied to explore different architectures, ranging from 10 to 20 nodes. This range was chosen to balance the complexity of the model and its ability to capture the underlying patterns in the data. We tested multiple architectures, including 14-10-2, 14-12-2, 14-14-2, 14-16-2, 14-18-2, and 14-20-2, among others. The architecture with 18 hidden nodes (14-18-2) yielded the highest classification accuracy of 84.53%.\n\nTo address the potential issue of overfitting, we utilized cross-validation. The dataset was divided into 6 subsets, with 5 subsets used for training and 1 subset for testing. This process was repeated 6 times, ensuring that each subset was used for testing once. The average classification accuracy was reported for each ANN architecture, providing a robust estimate of the model's performance.\n\nAdditionally, we compared the performance of our ANN models with other classifiers, such as Bayesnet, Reptree, SVM, and logistic classifiers. The ANN with the BP algorithm consistently outperformed these alternatives, indicating that our model was not underfitting the data.\n\nIn summary, the number of parameters in our ANN models was carefully managed by varying the hidden layer size and using cross-validation to mitigate overfitting. The consistent performance across different architectures and comparisons with other classifiers suggests that our models were appropriately fitted to the data without underfitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our classification system. One of the primary methods used was cross-validation. We divided our dataset into six subsets, using five for training and one for testing in each iteration. This process was repeated six times, with each subset serving as the test set once. This approach helped to ensure that our model's performance was consistent and not merely a result of overfitting to a specific subset of data.\n\nAdditionally, we explored various architectures of artificial neural networks (ANNs), including both three-layer and four-layer feedforward networks. Through this exploration, we found that three-layer networks generally performed better than four-layer networks. This simplification helped to reduce the risk of overfitting by limiting the model's complexity.\n\nWe also utilized normalized features as inputs to our ANN classifiers. Normalization helps to standardize the input data, making it easier for the network to learn and reducing the likelihood of overfitting to the scale of the input features.\n\nFurthermore, we compared the performance of our ANN system with other classifiers, such as BayesNet, Reptree, SVM, and logistic classifiers. The consistent superior performance of our ANN system with the backpropagation (BP) algorithm indicated that our model was well-suited to the task and not merely overfitting the training data.\n\nIn summary, our use of cross-validation, simplified network architectures, normalized features, and comparative analysis with other classifiers all contributed to preventing overfitting and ensuring the reliability of our classification system.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in this study are reported within the publication. Specifically, the configurations of the artificial neural networks (ANNs) explored in this study include various three-layer and four-layer feedforward architectures. These configurations are detailed in the results section, where six different architectures are listed, such as 14-10-2, 14-10-10-2, 14-12-2, and so on. The optimization parameters, including the use of cross-validation and the division of datasets into training and testing sets, are also described.\n\nThe model files and specific optimization schedules are not explicitly provided in the publication. However, the methods and techniques used for preprocessing, wavelet decomposition, and feature extraction are thoroughly described, allowing for replication of the study's procedures. The statistical features used as inputs for the ANN are also detailed, providing a clear path for others to implement similar models.\n\nRegarding availability and licensing, the publication itself is accessible through the International Journal of Biological Sciences. The methods and results are presented in a manner that adheres to academic publishing standards, ensuring that the information is available for further research and replication. However, specific model files or code implementations are not directly available through the publication. For detailed implementation, readers would need to refer to the described methods and potentially contact the authors for further details or access to any supplementary materials.",
  "model/interpretability": "The model employed in this study is primarily based on Artificial Neural Networks (ANNs), specifically using the Backpropagation (BP) algorithm. ANNs are generally considered black-box models due to their complex, non-linear nature, which makes it challenging to interpret the internal workings and decision-making processes directly. The BP algorithm, while effective for classification tasks, does not inherently provide transparency in how it arrives at its predictions.\n\nHowever, the structure of the ANN used in this study can be described in terms of its architecture. The network consists of three layers: an input layer, a hidden layer, and an output layer. The input layer has 14 nodes, corresponding to the 14 statistical features extracted from the sputum sound signals. The hidden layer varies in the number of nodes, with architectures such as 14-10-2, 14-12-2, and so on, being explored. The output layer has 2 nodes, representing the two classes of output: sputum or non-sputum deposition.\n\nThe use of a three-layer ANN with a Sigmoid function in the hidden layers allows the network to approximate any nonlinear function with arbitrary precision, given enough data and appropriate training. This capability is crucial for the classification task at hand, as the relationship between the input features and the output classes is complex and non-linear.\n\nWhile the internal weights and biases of the ANN are adjusted during training to minimize error, these adjustments are not easily interpretable. The model learns patterns from the data that are not explicitly defined by the researchers, making it a black-box in terms of interpretability. However, the performance of the model can be evaluated through metrics such as classification accuracy, which provides a quantitative measure of its effectiveness.\n\nIn summary, the ANN model used in this study is a black-box model due to its complex, non-linear nature and the lack of transparency in its decision-making process. The model's architecture and training process can be described, but the internal workings remain opaque. The focus is on the model's performance in classifying sputum sounds accurately, rather than on interpreting the specific features it uses to make predictions.",
  "model/output": "The model is a classification system. It is designed to categorize sound samples into two distinct classes: sputum or non-sputum siltation. This binary classification is achieved using a three-layer feedforward artificial neural network (ANN) trained with the backpropagation (BP) algorithm. The output layer of the network consists of two nodes, corresponding to the two classes. The model's performance is evaluated based on its accuracy in correctly classifying these sound samples. The highest classification accuracy achieved is 84.53%, demonstrating the model's effectiveness in distinguishing between sputum and non-sputum sounds.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method involved a comprehensive approach using a dataset of 595 sound samples, which included 337 sputum and 258 non-sputum deposition sound signals. These samples underwent a series of preprocessing steps, wavelet decomposition, and feature extraction to obtain statistical features. These features were then used as inputs for a classification system based on a three-layer feedforward artificial neural network (ANN).\n\nTo ensure the reliability of the classifier's outcomes, cross-validation was employed. The dataset was randomly divided into 6 sets of equal size. For each validation scheme, five sets were used for training the ANN classifier, while the remaining set was used for testing. This process was repeated six times, with each subset serving as the test set once. The average classification accuracy was reported for each ANN architecture.\n\nSeveral ANN architectures were explored, including both three-layer and four-layer configurations. The architectures tested were 14-10-2, 14-10-10-2, 14-12-2, 14-12-12-2, 14-14-2, 14-14-14-2, 14-16-2, 14-16-16-2, 14-18-2, 14-18-18-2, 14-20-2, and 14-20-20-2. The results indicated that three-layer architectures generally performed better than their four-layer counterparts. The highest classification accuracy achieved was 84.53% with the 14-18-2 architecture, which had 18 middle processing layer nodes.\n\nAdditionally, the performance of the ANN with the backpropagation (BP) algorithm was compared against other classifiers, including Bayesnet, Reptree, SVM, and logistic classifiers. The ANN with the BP algorithm consistently outperformed these other methods. Traditional features were also evaluated, with the highest accuracy achieved being 80.84%, which was lower than the accuracy obtained using the proposed method.",
  "evaluation/measure": "In our study, we primarily focused on classification accuracy as the key performance metric. This metric was chosen because it directly reflects the ability of our models to correctly identify sputum and non-sputum deposition sounds. We reported the classification accuracy for various artificial neural network (ANN) architectures, both with three and four layers. The highest accuracy achieved was 84.36% with a three-layer ANN architecture.\n\nWe also compared the performance of our ANN system with other classifiers, including Bayesnet, Reptree, SVM, and logistic classifiers. The ANN system with the backpropagation (BP) algorithm consistently outperformed these other classifiers, demonstrating its superiority in this specific task.\n\nAdditionally, we evaluated the performance of traditional features, which had a highest accuracy of only 80.84%. This comparison highlighted the effectiveness of our approach using statistical features extracted from sputum sound signals.\n\nTo ensure the reliability of our results, we employed cross-validation. The dataset was divided into six subsets, with five subsets used for training and one subset used for testing. This process was repeated six times, and the average classification accuracy was reported for each ANN architecture. This method provided a robust measure of our models' performance and generalizability.\n\nWhile classification accuracy is a widely used metric in the literature, it is important to note that other metrics such as precision, recall, and F1-score could also provide valuable insights. However, given the binary nature of our classification problem and the focus on overall correctness, classification accuracy was deemed the most representative metric for our study.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of various classification methods to evaluate the performance of our proposed system. We compared our artificial neural network (ANN) system using the backpropagation (BP) algorithm with several other classifiers, including Bayesnet, Reptree, Support Vector Machine (SVM), and logistic classifiers. The results, presented in a table, clearly showed that our ANN system with the BP algorithm outperformed the other classifiers, achieving the highest classification accuracy.\n\nAdditionally, we compared the performance of our ANN system using traditional features. The highest accuracy obtained with traditional features was 80.84%, which is significantly lower than the accuracy achieved by our ANN system with the BP algorithm. This comparison highlights the superiority of our method in classifying sputum sounds.\n\nWe also explored different architectures of three-layer and four-layer feedforward ANNs. The results indicated that three-layer architectures generally performed better than four-layer architectures. Specifically, the ANN architecture with 14 middle processing layer nodes (14-18-2) yielded the maximum classification accuracy of 84.36%.\n\nFurthermore, we employed cross-validation to ensure the reliability of our classification outcomes. The dataset was divided into six subsets, with five subsets used for training and one subset used for testing. This process was repeated six times, and the average classification accuracy was reported for each ANN architecture. This rigorous validation method confirms the robustness and accuracy of our classification system.\n\nIn summary, our study involved a comprehensive comparison with other classifiers and traditional feature-based methods, demonstrating the effectiveness and superiority of our ANN system with the BP algorithm in classifying sputum sounds.",
  "evaluation/confidence": "The evaluation of our classification system involved cross-validation to ensure the reliability of the results. Specifically, the dataset was divided into six subsets, with five used for training and one for testing in each iteration. This process was repeated six times, and the average classification accuracy was reported for each artificial neural network (ANN) architecture.\n\nThe performance metrics, such as classification accuracy, were derived from this cross-validation scheme. However, confidence intervals for these metrics were not explicitly provided in the results. The highest accuracy achieved was 84.36% with a specific ANN architecture, indicating strong performance.\n\nStatistical significance was not explicitly discussed in the context of comparing our method to others and baselines. However, the consistent superior performance of the ANN system with the backpropagation (BP) algorithm across different architectures suggests that it is indeed superior to other classifiers like Bayesnet, Reptree, SVM, and logistic classifiers. The traditional features used in other methods showed a maximum accuracy of only 80.84%, further supporting the effectiveness of our approach.\n\nIn summary, while confidence intervals are not provided, the cross-validation process and the consistent superior performance of our method indicate a high level of confidence in the results. The statistical significance of these results is implied by the clear performance differences observed.",
  "evaluation/availability": "Not enough information is available."
}