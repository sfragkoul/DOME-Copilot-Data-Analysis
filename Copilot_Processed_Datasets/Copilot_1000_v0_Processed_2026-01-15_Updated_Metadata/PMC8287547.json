{
  "publication/title": "Prediction of COVID-19 deterioration in high-risk patients at diagnosis: an early warning score for advanced COVID-19 developed by machine learning.",
  "publication/authors": "Jakob CEM, Mahajan UM, Oswald M, Stecher M, Schons M, Mayerle J, Rieg S, Pletz M, Merle U, Wille K, Borgmann S, Spinner CD, Dolff S, Scherer C, Pilgram L, R\u00fcthrich M, Hanses F, Hower M, Strau\u00df R, Massberg S, Er AG, Jung N, Vehreschild JJ, Stubbe H, Tometten L, K\u00f6nig R,",
  "publication/journal": "Infection",
  "publication/year": "2022",
  "publication/pmid": "34279815",
  "publication/pmcid": "PMC8287547",
  "publication/doi": "10.1007/s15010-021-01656-z",
  "publication/tags": "- COVID-19\n- Machine learning\n- Predictive model\n- Advanced stage\n- Complicated stage\n- LEOSS\n- SARS-CoV-2\n- Patient variables\n- Risk factors\n- Clinical decision making",
  "dataset/provenance": "The dataset used in our study is derived from the LEOSS (Lean European Open Survey on SARS-CoV-2 Infected Patients) study, which is a large, multicenter, European cohort study. The LEOSS study includes comprehensive clinical data on high-risk patients infected with SARS-CoV-2. For our analysis, we included 3,487 out of 6,360 patients enrolled in LEOSS. These patients were recruited from 117 study sites located primarily in Germany, with additional sites in Turkey, Belgium, Switzerland, the United Kingdom, Latvia, Spain, Austria, and Italy. The majority of patients were recruited from university hospitals and community hospitals, with a smaller proportion from medical practices.\n\nThe dataset comprises a wide range of baseline patient variables, totaling 472, which were used to develop our predictors. These variables are commonly assessed in primary care settings and are easily available, making our predictor practical for clinical use. The data includes information on patient demographics, comorbidities, symptoms, laboratory values, and clinical outcomes. The dataset has been used previously within the LEOSS study and by the research community to understand the progression and outcomes of COVID-19 in high-risk patients. The large and diverse cohort enhances the generalizability of our findings, although further validation in different demographic and resource settings is necessary.",
  "dataset/splits": "The dataset was split into three main parts: the discovery cohort, the training set, and the test set.\n\nThe discovery cohort consisted of 2819 patients, from which 1223 were used for model discovery. This cohort was further divided into an endpoint-balanced training set, comprising 80% of the data (approximately 978 patients), and a test set with the remaining 20% (approximately 245 patients). Endpoint balancing was achieved by stratifying the classes to ensure an appropriate representation of patients progressing to advanced COVID-19 and those who did not.\n\nThe validation cohort included 3541 patients, of which 2264 were used for validation purposes. This cohort was kept untouched during the machine learning process and the development of the SACOV-19 score.\n\nThe data was collected from various study sites, predominantly in Germany, with smaller contributions from other countries. Patients were recruited from university hospitals, community hospitals, and medical practices. The majority of patients were hospitalized, and a significant portion had their first positive SARS-CoV-2 test performed in an inpatient setting. The clinical stage of a substantial number of patients worsened to the advanced COVID-19 stage within a median of five days from baseline.",
  "dataset/redundancy": "The dataset was split into a discovery cohort and a validation cohort. The discovery cohort, used for model development, included patients enrolled between March 16, 2020, and July 14, 2020. The validation cohort, used for evaluating the model's performance, included patients enrolled between July 15, 2020, and February 16, 2021.\n\nWithin the discovery cohort, patients were randomly separated into an endpoint-balanced training set (80%) and a test set (20%). Endpoint balancing was achieved by stratifying the classes, which involved adjusting the sampling rate of patients who progressed to advanced COVID-19 and those who did not. This ensured that the training and test sets were independent and that the distribution of outcomes was similar in both sets.\n\nThe training set was used to develop the base predictor, which was then evaluated on the test set to assess its performance. This process helped to ensure that the model's performance was not overestimated due to overfitting to the training data. The validation cohort was used to further evaluate the performance of the final model, providing an additional layer of independent assessment.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of COVID-19 prediction. The use of endpoint balancing and the separation of the dataset into independent training, test, and validation sets helps to mitigate issues related to dataset redundancy and ensures that the model's performance is robust and generalizable.",
  "dataset/availability": "The data used in this study is not publicly available in its entirety. However, a portion of the data is accessible through the LEOSS Public Use File (PUF), which adheres to principles designed to reduce the risk of re-identification. This file is available on the LEOSS website. The data collection and analysis were approved by the applicable local ethics committees of all participating centers and registered at the German Clinical Trials Registry (DRKS, No. S00021145). The study included patients with laboratory-confirmed SARS-CoV-2 infection, and clinical information was documented retrospectively and anonymously. Written informed consent was waived by the respective ethics committees due to the anonymous nature of the data collection, except for patients recruited in Turkey, where informed consent was obtained upon request of the national ethics committee. The data was additionally anonymized using the principles used for the LEOSS Public Use File to further ensure privacy and confidentiality.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is ensemble learning, specifically focusing on methods like random forests, gradient boosting machines, extreme gradient boosting (XGBoost), and StackedEnsemble. These methods are well-established in the field of machine learning and are known for their robustness and ability to handle complex datasets.\n\nThe algorithm employed is not new; it leverages existing machine-learning techniques that have been widely used and validated in various applications. The choice of these methods was driven by their proven effectiveness in predictive modeling and their ability to handle a large number of variables and interactions within the data.\n\nThe decision to use these established methods rather than developing a new algorithm was strategic. The primary goal of our study was to develop a reliable predictive model for identifying high-risk COVID-19 patients at the time of diagnosis. Given the urgency and the need for immediate clinical application, it was crucial to utilize well-understood and validated techniques. This approach ensured that the model could be developed and implemented quickly, providing actionable insights for healthcare providers.\n\nMoreover, the focus of our publication is on the clinical application and validation of the predictive model rather than the innovation of a new machine-learning algorithm. The ensemble methods chosen are robust and have been extensively studied, making them suitable for the complex and high-stakes task of predicting COVID-19 deterioration. The implementation and validation of these methods in the context of COVID-19 provide valuable insights into their practical application in a real-world healthcare setting.",
  "optimization/meta": "The optimization process involved creating multiple predictors, including a base predictor, a slim predictor, and a minimalistic predictor. The base predictor was developed using an automated machine learning platform that selected the best performing algorithm from a set of methods, including random forests, gradient boosting machines, extreme gradient boosting, and StackedEnsemble. This approach can be considered a form of meta-predictor, as it leverages the outputs of multiple machine learning algorithms to identify the most effective model.\n\nThe StackedEnsemble method itself is a type of meta-predictor, which combines the predictions of several base models to improve overall performance. In this case, the base models included random forests, gradient boosting machines, and extreme gradient boosting. The training data for these models was derived from an endpoint-balanced training set, which was created by stratifying the classes and adjusting the sampling rates of patients progressing to advanced COVID-19 and those who did not. This ensured that the training data was independent and representative of the underlying population.\n\nThe final minimalistic predictor, which was based on a reduced set of variables, was also evaluated for robustness by constructing supplementary predictors that omitted one variable at a time. This process helped to confirm that the minimalistic predictor performed well under varying input conditions, further validating its reliability and generalizability.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, all baseline patient characteristics were converted into binary variables. This binarization process did not result in any loss of information, as even rational variables provided in categories were included. Missing values or data documented as \"unknown,\" \"not measured,\" or \"not detected\" were incorporated into the design of these binary variables.\n\nThe patient cohort from the discovery set was randomly separated into an endpoint-balanced training set (80%) and a test set (20%). Endpoint balancing was achieved by stratifying the classes, which involved adjusting the sampling rate of patients who progressed to advanced COVID-19 and reducing the sampling rate of those who did not. This ensured that the training and test sets were representative of the overall patient population.\n\nThe base predictor was constructed using the H2O.ai platform, which automatically selected the best-suited machine learning method from a predefined set, including random forests, gradient boosting machines, extreme gradient boosting, and StackedEnsemble. The parameters of each method were optimized using an internal tenfold cross-validation on the training set. The optimal method was then applied to the test set to assess its final performance. The selection of predictors was based on performance measures such as the area under the curve (AUC > 0.75) and logloss (< 0.50).\n\nVariables associated with the base predictor were selected based on their scaled importance above 0.05 to obtain the slim predictor, which consisted of a reduced set of 61 variables. To further refine the model, variables of the slim predictor were ranked according to their scaled importance. An iterative process was employed, where the lowest-ranking variable was removed, a new predictor was trained on the training set, and its performance was evaluated on the test set. This procedure continued until no variables remained, resulting in the minimalistic predictor, which showed the best tradeoff between performance and the minimal set of variables.",
  "optimization/parameters": "In the optimization process, the number of parameters used in the model was iteratively reduced to enhance interpretability and robustness. Initially, a base predictor was developed using all available baseline variables, totaling 472 parameters. To simplify the model, variables with low impact were iteratively removed, resulting in a slim predictor with 61 parameters. Further refinement led to a minimalistic predictor comprising 20 parameters. This selection was based on performance metrics such as the area under the curve (AUC) and logloss, ensuring that the model maintained high predictive accuracy while becoming more interpretable and generalizable. The final set of 20 parameters included variables like body mass index, smoking habit, presence of acute kidney injury, dyspnea, oxygen saturation level, body temperature, respiratory rate, C-reactive protein, creatinine, LDH, AST, gamma-GT, lymphocyte counts, neutrophil counts, and age thresholds. This minimalistic predictor demonstrated robust performance and was further validated using an unseen validation cohort.",
  "optimization/features": "The initial model, referred to as the \"base predictor,\" was developed using a comprehensive set of 472 baseline patient variables. These variables encompassed a wide range of patient characteristics, symptoms, comorbidities, microbiological data, preexisting medications, and laboratory and vital parameters.\n\nTo enhance the robustness and interpretability of the model, feature selection was performed. Variables with low impact were iteratively removed based on their performance on the test set. This process resulted in the creation of a \"slim predictor\" with 61 variables and a minimalistic predictor with 20 variables. The selection of these variables was conducted using the training set only, ensuring that the test set remained untouched and could be used for unbiased performance evaluation.\n\nThe minimalistic predictor, which includes 20 variables, was chosen because it provided a good tradeoff between performance and the number of variables. This predictor was further validated using data from the validation cohort, demonstrating its generalizability and robustness. The variables included in the minimalistic predictor cover various aspects such as age, body mass index, smoking habits, acute kidney injury, dyspnea, oxygen saturation levels, body temperature, respiratory rate, C-reactive protein levels, creatinine, LDH, AST, gamma-GT, lymphocyte counts, and neutrophil counts. These variables were selected to simplify the interpretation and improve the model's generalizability.",
  "optimization/fitting": "The fitting method employed in this study involved a systematic approach to ensure both robustness and interpretability of the predictors. Initially, a base predictor was constructed using all baseline variables, leveraging machine learning methods such as random forests, gradient boosting machines, extreme gradient boosting, and stacked ensembles. The parameters of each method were optimized through internal tenfold cross-validation on the training set, which helped in mitigating overfitting by ensuring that the model generalizes well to unseen data.\n\nTo address the potential issue of overfitting, especially given the large number of baseline variables (472), an iterative variable reduction process was implemented. Variables with low impact were iteratively removed, leading to the development of a \"slim predictor\" with 61 variables and a minimalistic predictor with 20 variables. This reduction was based on the performance on the test set, ensuring that the model's performance was evaluated on data not used during training.\n\nThe minimalistic predictor was further refined using a dynamic programming approach, which involved iteratively removing the least important variables and evaluating the performance of the resulting predictors. This process continued until the best tradeoff between performance and the minimal set of variables was achieved. The robustness of the minimalistic predictor was evaluated by constructing supplementary predictors that omitted one variable at a time, ensuring that the performance remained stable under varying input conditions.\n\nAdditionally, the impact of missing values on the predictive power was assessed by applying the minimalistic predictor to data of patients without missing values, which showed a slightly better prediction performance. This step ensured that the model was not underfitting by accounting for the presence of missing data in the training set.\n\nOverall, the fitting method involved a rigorous process of model selection, parameter optimization, and variable reduction, all aimed at balancing the complexity of the model with its generalizability and robustness.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and enhance the robustness of our predictors. Initially, we constructed a base predictor using all available baseline variables. To improve robustness and interpretability, we iteratively removed variables with low impact, resulting in a slim predictor with 61 variables and a minimalistic predictor with 20 variables. This iterative process helped in identifying the most relevant features, reducing the risk of overfitting to noise in the data.\n\nAdditionally, we used cross-validation techniques to optimize the parameters of each machine learning method. Specifically, we employed an internal tenfold cross-validation on the training set to tune the parameters of random forests, gradient boosting machines, extreme gradient boosting, and StackedEnsemble. This approach ensured that the selected parameters were generalizable and not overly fitted to the training data.\n\nFurthermore, we evaluated the robustness of the minimalistic predictor by constructing supplementary predictors that excluded one variable at a time. By comparing the performance of these mutated predictors to the original minimalistic predictor, we confirmed that the model maintained its performance even when individual variables were removed, indicating robustness against overfitting.\n\nThe selection of the minimalistic predictor was based on a tradeoff between performance and the number of variables. We iteratively removed variables and assessed the performance on the test set, ensuring that the final model was both efficient and effective. This methodical approach helped in mitigating overfitting and enhancing the generalizability of our predictors.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available through the packages employed for the analysis. Specifically, the H2O.ai platform was used for machine learning, with the selection of methods limited to random forests, gradient boosting machines (GBM), extreme gradient boosting (XGBoost), and StackedEnsemble. The parameters of each method were optimized using an internal tenfold cross-validation on the training set.\n\nThe computational core of our minimalistic predictor was implemented using the packages h2o and lime in R. The graphical user interface for the minimalistic predictor was developed using the Shiny and ggplot2 packages. These packages, along with their respective functionalities, are open-source and freely available, allowing for reproducibility and further development by the research community.\n\nThe specific configurations and optimization schedules are detailed within the supplementary materials and the methods section of the publication. The data processing and variable selection procedures are also described, providing a comprehensive overview of the steps taken to develop the predictors.\n\nThe web application implementing the minimalistic predictor and SACOV-19 is designed for research use, making the predictor accessible to the research community. This application, along with the associated code and models, is available through the provided web interface, ensuring that the tools developed in this study can be utilized and validated by other researchers.",
  "model/interpretability": "The model developed in our study is not a blackbox. We have taken significant steps to ensure interpretability and transparency. Initially, we created a base predictor using all baseline variables, but to enhance interpretability, we iteratively removed variables with low impact. This process led to the creation of a \"slim predictor\" with 61 variables and a minimalistic predictor with just 20 variables. The minimalistic predictor includes variables such as body mass index, smoking habits, presence of acute kidney injury, dyspnea, oxygen saturation levels, body temperature, respiratory rate, C-reactive protein levels, creatinine, LDH, AST, gamma-GT, lymphocyte counts, and neutrophil counts. Age was also included with different thresholds to reflect the increasing risk with age.\n\nThe minimalistic predictor was designed to be easily understandable and applicable in clinical settings. Each variable in the predictor is binary, making it straightforward to interpret. For example, a body mass index greater than 24.9 kg/m\u00b2, being a smoker or former smoker, having an oxygen saturation level below 96%, or a body temperature above 37.3\u00b0C are all clear and actionable criteria. This transparency allows healthcare providers to quickly assess a patient's risk of progressing to an advanced COVID-19 stage based on readily available clinical data.\n\nAdditionally, we developed a clinical score called SACOV-19, which uses a subset of the minimalistic predictor's variables. This score is designed to be simple and effective, providing a clear and interpretable way to predict the risk of advanced COVID-19. The score assigns a value of +1 to each relevant variable, and a threshold is used to determine the risk level. This approach ensures that the model is not only accurate but also easily understandable and applicable in real-world clinical settings.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict whether a patient with COVID-19 will progress to an advanced stage of the disease. The model uses various baseline patient variables to make this binary classification.\n\nThe development process involved creating a base predictor using all available variables, followed by iterative removal of low-impact variables to improve robustness and interpretability. This resulted in a slim predictor with 61 variables and a minimalistic predictor with 20 variables. The minimalistic predictor was further refined to create a clinical score called SACOV-19, which comprises 11 patient variables.\n\nThe performance of the model was evaluated using metrics such as the area under the curve (AUC) and odds ratio (OR). The minimalistic predictor showed good performance in predicting the development of advanced COVID-19, with an AUC of 0.71 and an OR of 4.41 on the validation cohort. The model's robustness was also assessed by constructing supplementary predictors with single variables removed, and it was found to perform similarly under varying input conditions.\n\nA web interface was implemented to allow users to input patient variables and receive a prediction of the likelihood of developing advanced COVID-19. The interface provides the model-based estimated probability, odds ratio, SACOV-19 score, and model prediction, along with graphical presentations to illustrate the impact of specific variables.",
  "model/duration": "To save computational time, the selection of machine learning methods was limited to random forests, gradient boosting machines, extreme gradient boosting, and StackedEnsemble. The parameters of each method were optimized using an internal tenfold cross-validation on the training set. This process was repeated iteratively to refine the model, with the best performing predictor being identified in each loop based on the performance measure logloss. The final model was then applied to the test set to assess its performance. The iterative process of variable selection and model training was continued until a minimalistic predictor with the best tradeoff between performance and the number of variables was achieved. The computational core of the minimalistic predictor was implemented using the packages h2o and lime in R. The entire data processing, modeling, and assessment of performances were performed using R (version 3.6.3). The specific execution time for the model to run was not explicitly mentioned, but the use of efficient computational packages and techniques suggests that efforts were made to optimize the runtime.",
  "model/availability": "The predictor developed in this study is accessible to the research community through a web interface. This interface allows for quick entry of patient variables and provides predictions regarding the likelihood of a patient developing advanced COVID-19 stages. The web interface can be accessed at a specified URL, where users can log in with provided credentials to utilize the model. This implementation ensures that the predictor is user-friendly and readily available for clinical decision-making. The web interface includes graphical presentations to illustrate the impact of specific variables, enhancing the interpretability of the predictions.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its robustness and generalizability. Initially, the data from the discovery cohort was split into an endpoint-balanced training set (80%) and a test set (20%). This split was achieved through stratification to balance the classes, ensuring an adequate representation of patients progressing to advanced COVID-19 and those who did not.\n\nThe base predictor was constructed using the H2O.ai platform, which automatically selected the best machine learning method from a predefined set, including random forests, gradient boosting machines, extreme gradient boosting, and StackedEnsemble. The parameters of each method were optimized using an internal tenfold cross-validation on the training set. The optimal method was then applied to the test set to assess its final performance.\n\nTo improve robustness and interpretability, variables with low impact were iteratively removed. This process yielded a \"slim predictor\" with 61 variables and a minimalistic predictor with 20 variables. The selection of these variables was based on their performance on the test set.\n\nThe minimalistic predictor and SACOV-19 were further evaluated using data from an independent validation cohort, which included patients from the first to the third wave of the COVID-19 pandemic. This cohort was collected after the development of the score, ensuring that the evaluation was conducted on data not used in the training process.\n\nThe performance of the predictors was measured using the area under the curve (AUC) and logloss. The minimalistic predictor was selected based on the best tradeoff between good performance and a minimal set of variables. Additionally, the robustness of the minimalistic predictor was evaluated by constructing supplementary predictors that left out one variable at a time and comparing their performance to the original predictor.\n\nA browser-based web application was implemented to make the minimalistic predictor and SACOV-19 accessible for further evaluation and use. This application allows for the assessment of the predictors in different clinical settings and regions, promoting their potential applicability in various healthcare environments.",
  "evaluation/measure": "In the evaluation of our predictors, several performance metrics were reported to provide a comprehensive assessment of their effectiveness. The primary metric used was the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, which measures the ability of the model to distinguish between patients who progress to an advanced COVID-19 stage and those who do not. The AUC values were reported with their standard deviations to indicate the variability of the performance across different runs or subsets of data.\n\nAdditionally, the Odds Ratio (OR) with 95% Confidence Intervals (CI) was provided to quantify the strength of the association between the predictor variables and the outcome. This metric helps to understand the likelihood of developing an advanced COVID-19 stage given the presence of certain risk factors.\n\nSensitivity and specificity were also reported for different thresholds of the predictors. Sensitivity measures the proportion of true positives correctly identified by the model, while specificity measures the proportion of true negatives correctly identified. These metrics are crucial for understanding the trade-off between correctly identifying patients at risk and avoiding false alarms.\n\nAbsolute Risk Reduction (ARR) was another metric reported, which indicates the reduction in the risk of progressing to an advanced COVID-19 stage when using the predictor compared to not using it. This metric is particularly useful for clinical decision-making, as it provides a direct measure of the benefit of using the predictor in a real-world setting.\n\nThe balanced accuracy was also considered, especially when dealing with imbalanced datasets. This metric takes into account both sensitivity and specificity, providing a more balanced view of the model's performance.\n\nThe performance metrics reported are representative of those commonly used in the literature for evaluating predictive models in medical research. The use of AUC, OR, sensitivity, specificity, and ARR ensures that the evaluation is thorough and comparable to other studies in the field. This set of metrics provides a comprehensive view of the model's performance, covering aspects such as discriminative power, association strength, and clinical utility.",
  "evaluation/comparison": "A comparison to simpler baselines was performed during the development of the predictors. Initially, a base predictor was constructed using all baseline variables and data from the training set. This base predictor served as a comprehensive model incorporating a wide range of variables. To enhance robustness and interpretability, variables with low impact were iteratively removed, leading to the creation of a \"slim predictor\" with 61 variables and a minimalistic predictor with 20 variables. The selection of variables for these predictors was based on their performance on the test set, ensuring that only the most relevant variables were retained.\n\nThe minimalistic predictor was further evaluated for its robustness by constructing supplementary predictors that excluded one variable at a time. The performance of these mutated predictors was compared to the original minimalistic predictor to assess the impact of each variable. This process highlighted the stability and reliability of the minimalistic predictor, as the exclusion of individual variables did not significantly affect its performance.\n\nAdditionally, the discriminative power of each individual patient variable was estimated using the discovery set. This analysis helped identify the most predictive variables, which were then combined to form the SACOV-19 score. The SACOV-19 score was developed using a dynamic programming approach, ensuring that the selected variables provided the best trade-off between performance and simplicity.\n\nWhile the focus was on developing and refining internal predictors, the performance of the minimalistic predictor and SACOV-19 was also evaluated on an independent validation cohort. This step provided an external validation of the models' generalizability and robustness. The results demonstrated that the minimalistic predictor and SACOV-19 maintained good performance even when applied to unseen data, indicating their potential for clinical use.\n\nNot applicable.",
  "evaluation/confidence": "The evaluation of the predictors involved calculating performance metrics with associated confidence intervals. For instance, the base predictor showed an AUC of 0.79 with a confidence interval of \u00b1 0.11, and an odds ratio (OR) of 7.65 with a 95% confidence interval ranging from 4.13 to 14.19. Similarly, the slim predictor had an AUC of 0.80 \u00b1 0.01 and an OR of 9.14 with a 95% confidence interval from 4.90 to 17.05. The minimalistic predictor also demonstrated an AUC of 0.80 \u00b1 0.01 and an OR of 8.20 with a 95% confidence interval from 4.51 to 14.88. These confidence intervals provide a measure of the reliability and precision of the performance metrics.\n\nStatistical significance was assessed to ensure that the observed performance differences were not due to random chance. The odds ratios and their confidence intervals indicate that the predictors are statistically significant, as the intervals do not include 1, suggesting a meaningful difference from a null effect. Additionally, the performance of the minimalistic predictor was evaluated on an unseen validation cohort, where it showed an AUC of 0.71 and an OR of 4.41 with a 95% confidence interval from 3.57 to 5.46. This further supports the robustness and generalizability of the predictor.\n\nTo assess the impact of missing values, the minimalistic predictor was applied to data from patients without any missing values, resulting in a slightly better performance with an AUC of 0.77 \u00b1 0.02 and an OR of 6.78 with a 95% confidence interval from 2.74 to 16.65. This indicates that the predictor maintains its effectiveness even when missing data is present, although performance improves with complete data.\n\nThe robustness of the minimalistic predictor was evaluated by constructing supplementary predictors with one variable removed at a time. The performance of these mutated predictors was compared to the original minimalistic predictor, and it was observed that the performance did not significantly degrade, reflecting the robustness of the minimalistic predictor. This evaluation process ensures that the predictor is reliable and can be trusted for clinical decision-making.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study focuses on the development and validation of a machine learning-based predictor, SACOV-19, for identifying patients at risk of developing advanced COVID-19 stages. The data used in this study were collected from the LEOSS registry, which includes comprehensive clinical data on high-risk patients. However, the specific datasets used for training and validating the SACOV-19 predictor are not released to the public. The predictor itself is made accessible to the research community through a web interface, allowing researchers to utilize the model for their own studies. This approach ensures that the predictor can be widely used while maintaining the privacy and security of the patient data. For those interested in further details or potential collaborations, additional information can be found in the supplementary material available online."
}