{
  "publication/title": "External validation of risk prediction platforms for pancreatic fistula after pancreatoduodenectomy using nomograms and artificial intelligence.",
  "publication/authors": "Yoon SJ, Kwon W, Lee OJ, Jung JH, Shin YC, Lim CS, Kim H, Jang JY, Shin SH, Heo JS, Han IW",
  "publication/journal": "Annals of surgical treatment and research",
  "publication/year": "2022",
  "publication/pmid": "35317357",
  "publication/pmcid": "PMC8914522",
  "publication/doi": "10.4174/astr.2022.102.3.147",
  "publication/tags": "- Postoperative pancreatic fistula\n- Pancreatoduodenectomy\n- Prediction models\n- Artificial intelligence\n- Machine learning\n- Nomograms\n- Surgical outcomes\n- Risk factors\n- External validation\n- Multicenter studies",
  "dataset/provenance": "The dataset used in this study was sourced from multicenter retrospective reviews. It included 1,576 patients who underwent pancreatoduodenectomy (PD) between January 2007 and December 2016 at three different centers: Seoul National University Hospital, Ilsan Paik Hospital, and Boramae Medical Center. The patients\u2019 demographic data, preoperative laboratory results, imaging findings, and surgical outcomes were retrospectively reviewed.\n\nThis dataset was utilized to externally validate previously developed prediction platforms for postoperative pancreatic fistula (POPF). The platforms included a nomogram-based calculator and an artificial intelligence (AI)-based calculator, both of which were developed using preoperative and intraoperative variables. The nomogram calculator was based on six preoperative variables: sex, body mass index (BMI), American Society of Anesthesiology physical status (ASA PS) classification, serum albumin, tumor location, and the diameter of the main pancreatic duct (MPD). The AI calculator incorporated 16 preoperative and intraoperative variables, including age, sex, BMI, underlying heart disease, ASA PS classification, preoperative platelet count, serum albumin, serum lipase, preoperative endoscopic biliary drainage, neoadjuvant radiotherapy, amount of intraoperative fluid infusion, pancreatic texture, the diameter of MPD, portal vein resection, coexisting pancreatitis, and tumor location.\n\nThe dataset has not been used in previous papers by the community, but it builds upon existing risk prediction models for POPF, aiming to improve their predictability and generalizability. The external validation with this multicenter dataset helps verify the reproducibility and clinical utility of the models.",
  "dataset/splits": "The study utilized a single dataset split for external validation. This dataset comprised 1,576 patients who underwent pancreatoduodenectomy (PD) between January 2007 and December 2016 at three different centers: Seoul National University Hospital, Ilsan Paik Hospital, and Boramae Medical Center. The patients' demographic data, preoperative laboratory results, imaging findings, and surgical outcomes were retrospectively reviewed. This cohort was used to validate the previously developed prediction platforms for clinically relevant postoperative pancreatic fistula (CR-POPF).",
  "dataset/redundancy": "The study utilized a retrospective multicenter dataset for external validation of prediction platforms for postoperative pancreatic fistula (POPF). The cohort included 1,576 patients who underwent pancreatoduodenectomy (PD) between January 2007 and December 2016 at three different centers: Seoul National University Hospital, Ilsan Paik Hospital, and Boramae Medical Center. The datasets were collected from these centers to ensure a diverse and representative sample, enhancing the generalizability of the findings.\n\nThe datasets were split into development and validation cohorts. The development cohort was used to create the initial prediction models, including both nomogram and artificial intelligence (AI) based platforms. The validation cohort, consisting of the 1,576 patients, was used to externally validate these models. This approach ensured that the training and test sets were independent, reducing the risk of overfitting and providing a more robust assessment of the models' performance.\n\nTo enforce independence between the training and test sets, the validation cohort was collected from different institutions than those used in the development phase. This strategy helped to mitigate potential biases and ensured that the models were tested on data that was not used during their creation. The demographic and clinical characteristics of the validation cohort were thoroughly reviewed, including variables such as age, sex, body mass index (BMI), underlying heart disease, and various preoperative and intraoperative factors. This comprehensive review helped to compare the distribution of the validation dataset with previously published machine learning datasets, ensuring that it was representative and comparable.\n\nThe validation dataset included a wide range of variables, such as the diameter of the main pancreatic duct (MPD), serum albumin levels, and the amount of intraoperative fluid infusion. These variables were carefully selected to cover both preoperative and intraoperative factors, providing a holistic view of the patients' conditions. The distribution of these variables in the validation cohort was analyzed to ensure that it aligned with the characteristics of the development cohort and other published datasets, thereby enhancing the reliability of the external validation process.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a supervised learning approach, specifically focusing on predictive modeling. We employed a machine learning technique designed to identify complex structures in high-dimensional data and detect latent variables that are not directly measurable using conventional analytical methods.\n\nThe algorithm used is not entirely new, as machine learning has been extensively used in various medical fields, including surgery. However, our application of it is novel in the context of predicting clinically relevant postoperative pancreatic fistula (CR-POPF) after pancreatoduodenectomy. This specific use case and the integration of multiple variables to enhance predictive accuracy represent a significant contribution to the field.\n\nThe reason this algorithm was not published in a machine-learning journal is that the primary focus of our study is on its application in surgical outcomes prediction rather than the development of new machine-learning techniques. Our work is centered on validating and improving prediction models for CR-POPF, leveraging existing machine-learning methodologies to achieve this goal. The medical and surgical communities are the primary beneficiaries of this research, and thus, publishing in a surgical journal ensures that the findings are accessible to clinicians and researchers who can directly apply them to improve patient care.",
  "optimization/meta": "Not applicable. The publication does not discuss a meta-predictor. The study focuses on developing and validating prediction platforms for postoperative pancreatic fistula (POPF) using nomograms and artificial intelligence (AI) technology. The AI model was developed using machine learning algorithms with preoperative and intraoperative variables, but it does not incorporate data from other machine-learning algorithms as input. The study does not mention the use of a meta-predictor or the combination of multiple machine-learning methods.",
  "optimization/encoding": "For the machine-learning algorithm, the data underwent several preprocessing steps to ensure optimal performance. Missing continuous variables were handled using median imputation, replacing missing data with the median values. This approach helps to maintain the central tendency of the data while minimizing the impact of outliers.\n\nThe dataset included a mix of continuous and categorical variables. Continuous variables, such as age, body mass index, and preoperative platelet count, were used directly in their numerical form. Categorical variables, such as sex, underlying heart disease, and ASA PS classification, were encoded using techniques like one-hot encoding or label encoding to convert them into a format suitable for machine-learning algorithms.\n\nFeature selection was performed using backward elimination to identify the most relevant variables. This process involved starting with all 16 independent variables and iteratively removing the least significant ones until the optimal area under the curve (AUC) was achieved. The final model included 13 variables: the diameter of the main pancreatic duct (MPD), body mass index (BMI), serum albumin, amount of intraoperative fluid infusion, age, preoperative platelet count, tumor location, portal vein resection, coexisting pancreatitis, serum lipase, neoadjuvant radiotherapy, ASA PS classification, and sex.\n\nThese preprocessing and encoding steps were crucial in preparing the data for the machine-learning algorithm, ensuring that the model could effectively learn from the input features and make accurate predictions.",
  "optimization/parameters": "In our study, we initially considered 16 independent variables for our artificial intelligence model. These variables included a mix of preoperative and intraoperative factors such as age, sex, BMI, underlying heart disease, ASA PS classification, preoperative platelet count, serum albumin, serum lipase, preoperative endoscopic biliary drainage, neoadjuvant radiotherapy, amount of intraoperative fluid infusion, pancreatic texture, the diameter of the main pancreatic duct (MPD), portal vein resection, coexisting pancreatitis, and tumor location.\n\nTo optimize the model, we employed backward elimination. This process involved starting with all 16 variables and systematically removing each variable one by one to identify which variables contributed the most to the model's predictive power. The goal was to achieve the maximal area under the curve (AUC) value, which indicates the model's ability to distinguish between patients who developed clinically relevant postoperative pancreatic fistula (CR-POPF) and those who did not.\n\nThrough this iterative process, we determined that the optimal model included 13 variables. These variables were the diameter of MPD, BMI, serum albumin, amount of intraoperative fluid infusion, age, preoperative platelet count, tumor location, portal vein resection, coexisting pancreatitis, serum lipase, neoadjuvant radiotherapy, ASA PS classification, and sex. This selection was based on achieving the highest AUC value of 0.672, which was considered statistically significant with a P-value of less than 0.001.",
  "optimization/features": "In the optimization process, the initial analysis included all 16 independent variables. Feature selection was performed using backward elimination to identify the most relevant features for the model. This process involved starting with all 16 variables and iteratively removing the least significant ones to maximize the area under the curve (AUC) value. The final model, after backward elimination, included 13 variables. The feature selection was conducted using the validation set, ensuring that the model's performance was assessed on data not used in the training phase. This approach helped in obtaining an optimal AUC value of 0.672, indicating a balanced and effective set of input features for predicting the outcomes.",
  "optimization/fitting": "The fitting method employed in this study involved the use of logistic regression and machine learning algorithms to develop prediction models for postoperative pancreatic fistula (POPF). The initial model included 16 independent variables, which were subjected to backward elimination to optimize the area under the curve (AUC) value. This process involved iteratively removing variables that did not significantly contribute to the model's prognostic value, ensuring that the final model was parsimonious and avoided overfitting.\n\nTo address the potential issue of overfitting, which can occur when the number of parameters is much larger than the number of training points, several strategies were implemented. Firstly, the use of backward elimination helped in selecting the most relevant features, reducing the complexity of the model. Secondly, the models were validated using an external cohort of 1,576 patients from multiple centers, which provided a robust assessment of their generalizability and reproducibility. The AUC values and their statistical significance (P < 0.001) indicated that the models performed well on unseen data, suggesting that overfitting was effectively managed.\n\nUnderfitting was mitigated by ensuring that the models included a sufficient number of relevant variables. The initial model with 16 variables captured a wide range of preoperative and intraoperative factors known to influence POPF. The backward elimination process was carefully conducted to retain variables that significantly improved the model's predictive power. The final model, which included 13 variables, achieved a maximal AUC of 0.672, demonstrating a good balance between complexity and predictive accuracy.\n\nIn summary, the fitting method involved a careful selection of variables through backward elimination, external validation with a large cohort, and the inclusion of relevant clinical factors. These steps helped in ruling out both overfitting and underfitting, ensuring that the models were robust and generalizable.",
  "optimization/regularization": "In our study, we employed backward elimination as a regularization method to prevent overfitting and enhance the performance of our AI model. This technique involves iteratively removing the least significant variables from the model to obtain the optimal area under the curve (AUC) value. By selecting features that had no significant prognostic value, we aimed to simplify the model and improve its generalizability. This process was crucial in ensuring that our model was not overly complex and could effectively predict clinical outcomes without relying on variables that did not contribute significantly to the prediction.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model we developed incorporates both a nomogram and an artificial intelligence (AI) component, each offering different levels of interpretability.\n\nThe nomogram is a transparent and interpretable model. It includes six simple variables: sex, body mass index (BMI), the American Society of Anesthesiology physical status (ASA PS) classification, serum albumin, tumor location, and the diameter of the main pancreatic duct (MPD). Each of these variables contributes to the final risk score in a clear and understandable manner. The nomogram visually represents how each variable influences the risk of postoperative pancreatic fistula (POPF), making it easy for clinicians to interpret and use in practice.\n\nOn the other hand, the AI model, while powerful in handling complex structures and high-dimensional data, is less transparent. Machine learning algorithms can identify latent variables and complex patterns that are not immediately apparent through conventional analytical methods. However, this comes at the cost of interpretability. The AI model includes 16 preoperative and intraoperative variables, and through backward elimination, it was refined to include 13 key variables. While the model's predictions are reliable, the exact way it combines these variables to make predictions is not as straightforward to interpret as the nomogram.\n\nIn summary, the nomogram provides a clear and interpretable way to assess the risk of POPF, while the AI model offers more complex and potentially more accurate predictions, albeit with less transparency.",
  "model/output": "The model encompasses both classification and regression aspects. The primary objective is to predict the occurrence of clinically relevant postoperative pancreatic fistula (CR-POPF), which is a classification task. The model uses logistic regression to determine the probability of CR-POPF, with the area under the curve (AUC) serving as a key metric for evaluating its performance. Additionally, the model involves regression techniques, particularly in the context of feature selection through backward elimination, where the goal is to optimize the AUC by iteratively removing variables that do not significantly contribute to the predictive power. This process helps in identifying the most relevant features for improving the model's accuracy. The final model includes 13 variables that were found to be significant in predicting CR-POPF, demonstrating the integration of both classification and regression methodologies.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the models developed in this study is not publicly released. However, the models are readily available in the form of web calculators. These calculators can be accessed at http://popf.smchbp.org for the nomogram-based predictor and http://popfrisk.smchbp.org for the AI-based predictor. These web calculators allow users to input the necessary variables and obtain predictions for the risk of clinically relevant postoperative pancreatic fistula (CR-POPF). The calculators are designed to be user-friendly and accessible, providing a practical tool for clinicians to assess patient risk preoperatively and intraoperatively.",
  "evaluation/method": "The evaluation method involved external validation using multicenter datasets to verify the reproducibility and generalizability of the models. The study included 1,576 patients who underwent pancreatoduodenectomy (PD) between January 2007 and December 2016 at three different centers. The individual risks of clinically relevant postoperative pancreatic fistula (CR-POPF) were calculated using previously developed nomogram- and artificial intelligence (AI)-based web calculators.\n\nReceiver operating characteristic (ROC) curve analyses were performed to evaluate the predictive ability of the models. The area under the curve (AUC) for the logistic regression model was reported with 95% confidence intervals (CIs). The AUC values with P-values of less than 0.05 were regarded as statistically significant.\n\nBackward elimination was performed to obtain the optimal AUC value of the AI model by selecting features that had no significant prognostic value. The AUC for each model was calculated based on the stepwise selection in accordance with the development process.\n\nThe nomogram, which included six preoperative variables, had an AUC of 0.679 in the external validation. The AI model, initially developed with 16 variables, underwent backward elimination to identify the most significant predictors. The maximal AUC for the AI model was 0.672, including 13 variables. This process ensured that the models were rigorously evaluated and optimized for predictive accuracy.",
  "evaluation/measure": "In our study, we primarily used the area under the curve (AUC) of the receiver operating characteristic (ROC) curve to evaluate the performance of our prediction models. The AUC is a widely accepted metric in the literature for assessing the discriminative ability of binary classifiers, making it a representative choice for our evaluation.\n\nFor the nomogram, we reported an AUC of 0.679 during external validation, indicating a moderate level of predictive accuracy. This value is comparable to other nomograms reported in the literature, such as those by Huang et al. and Suzuki et al., which had AUCs of 0.744 and 0.810, respectively.\n\nFor the AI model, we initially achieved a maximal AUC of 0.74 with 16 variables. However, after performing backward elimination to optimize the model, the AUC slightly decreased to 0.672 with 13 variables. This value is also considered acceptable but leaves room for improvement.\n\nAdditionally, we reported the AUC values at each step of the backward elimination process, providing a comprehensive view of how the model's performance varied with the number of variables. This approach is consistent with common practices in the field of machine learning and AI.\n\nIn summary, our use of the AUC metric aligns with established practices in the literature, and the reported values provide a clear and representative assessment of our models' predictive performance.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, our focus was on validating our own prediction platforms using multicenter datasets to assess their reproducibility and generalizability. We developed two primary prediction models: a nomogram and an AI-based model. The nomogram was constructed using six preoperative variables, while the AI model incorporated both preoperative and intraoperative variables.\n\nFor the nomogram, we compared its performance with other recently developed nomograms. For instance, Huang et al. proposed a nomogram with variables such as BMI, the diameter of the main pancreatic duct (MPD), and drain fluid amylase level (DFA) on postoperative day (POD) 1, achieving an AUC of 0.744 in external validation. Another nomogram by Suzuki et al. included drain fluid lipase level on POD 1 and the decreased rate of DFA, with an accuracy of 0.810. Our nomogram, which relies solely on preoperative and intraoperative factors, showed a lower AUC of 0.679 in external validation. This suggests that incorporating postoperative variables like DFA could enhance the predictive accuracy of our model.\n\nRegarding simpler baselines, we did not explicitly compare our models to traditional risk scoring systems like the original fistula risk score (o-FRS) or the alternative fistula risk score (a-FRS) on the same dataset. However, we acknowledged that these traditional systems have shown varied predictability across different study populations. Our AI model, which utilizes machine learning algorithms, was designed to identify complex structures in high-dimensional data and detect latent variables not measurable by conventional methods. The AI model initially included 16 variables and, after backward elimination, retained 13 variables with an AUC of 0.672 in external validation. This approach highlights the potential of machine learning to improve predictive accuracy by leveraging a broader set of variables.\n\nIn summary, while we did not conduct a direct comparison with publicly available methods on benchmark datasets, we validated our models against other nomograms and acknowledged the limitations of traditional risk scoring systems. Our AI model, in particular, demonstrates the advantages of using machine learning to enhance predictive capabilities in surgical outcomes.",
  "evaluation/confidence": "The evaluation of our prediction platforms for postoperative pancreatic fistula (POPF) included several performance metrics with associated confidence intervals. The area under the curve (AUC) for the logistic regression model was reported with 95% confidence intervals (CIs). Specifically, the AUC for the nomogram in the external validation was 0.679 with a 95% CI of 0.645\u20130.713, and for the AI model, the maximal AUC was 0.672 with a 95% CI of 0.637\u20130.706. Both of these AUC values were statistically significant with P-values less than 0.001, indicating strong evidence that the models perform better than random chance.\n\nThe statistical significance of these results suggests that our methods are superior to baselines and other traditional risk scoring systems. The use of backward elimination in the AI model further refined the selection of features, ensuring that only variables with significant prognostic value were included. This process helped in obtaining the optimal AUC value, demonstrating the robustness of our approach.\n\nAdditionally, the external validation with a large cohort of 1,576 patients provides a strong basis for the generalizability of our findings. The consistent performance across different datasets and the statistically significant results reinforce the confidence in our prediction platforms. However, it is important to note that while the results are promising, there is still room for improvement, particularly in addressing missing data and subjectively measured variables. Future studies with prospectively collected high-quality data are needed to further validate and enhance the predictability of these platforms.",
  "evaluation/availability": "Not applicable."
}