{
  "publication/title": "Use of Artificial Intelligence for the Development of Predictive Model to Help in Decision-Making for Patients with Degenerative Lumbar Spine Disease.",
  "publication/authors": "Purohit G, Choudhary M, Sinha VD",
  "publication/journal": "Asian journal of neurosurgery",
  "publication/year": "2022",
  "publication/pmid": "36120630",
  "publication/pmcid": "PMC9473813",
  "publication/doi": "10.1055/s-0042-1750785",
  "publication/tags": "- neurosurgery\n- artificial intelligence\n- degenerative lumbar spine disease\n- machine learning\n- Random Forest Classifier\n- lumbar canal stenosis\n- low back pain\n- spinal surgery\n- predictive modeling\n- patient outcomes",
  "dataset/provenance": "The dataset used in this study was collected from a prospective cohort of 180 patients with lumbar degenerative spine disease. These patients were over 18 years of age and were managed through three different strategies: conservative treatment, decompressive surgery, and decompression with fixation. The data points included preoperative variables such as sociodemographic factors, symptomatology scoring, psychosocial factors, and radiological factors. Outcome measures like the Visual Analog Scale (VAS), Modified Oswestry Disability Index (MODI), and Neurogenic Claudication Outcome Score (NCOS) were assessed preoperatively and at 6 months postoperatively. The dataset was divided into training and testing subsets, with 80% used for training the machine learning models and 20% reserved for testing. This division ensured that the class ratios remained proportional in both subsets, allowing for a robust evaluation of the models' performance on new data. The dataset was specifically curated for this study and has not been previously used in other publications or by the community.",
  "dataset/splits": "The dataset was divided into two splits: a training dataset and a testing dataset. The training dataset comprised 80% of the complete dataset, while the testing dataset consisted of the remaining 20%. The dataset was divided in such a way that the class ratio of all classes remained proportional in the training and test datasets. This approach ensured that the model's performance could be estimated on new data that was not used during training and that all classes were present for validation.",
  "dataset/redundancy": "The dataset was divided into training and testing subsets to evaluate the performance of the machine learning models. The training dataset comprised 80% of the complete dataset, while the test dataset consisted of the remaining 20%. This split was carefully designed to ensure that the class ratio of all classes remained proportional in both the training and test datasets. This approach aimed to maintain the independence of the training and test sets, ensuring that the model's performance could be accurately assessed on new, unseen data.\n\nThe proportional class distribution in both subsets was enforced to prevent any bias that could arise from an imbalanced dataset. This method helps in estimating the model's performance on new data that includes all the classes present for validation. By maintaining the class ratio, the model is trained and tested on data that reflects the true distribution of the classes, leading to more reliable and generalizable results.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in terms of ensuring class balance and independence between training and test sets. This careful splitting and balancing process is crucial for developing robust predictive models that can be applied in real-world scenarios.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is the Random Forest Classifier. This algorithm is not new; it is a well-established ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe Random Forest Classifier was chosen because it demonstrated the best performance among the evaluated algorithms, achieving the highest ROC-AUC scores for predicting improvements in VAS, MODI, and NCOS. The ROC-AUC scores for VAS, MODI, and NCOS were 0.863, 0.831, and 0.869, respectively, indicating its strong discriminatory power.\n\nThe focus of this study was on developing a prognostic model for patients with degenerative lumbar spine disease, rather than introducing a new machine-learning algorithm. The Random Forest Classifier was selected for its effectiveness in handling complex datasets and providing robust predictions, which aligns with the study's objective of aiding decision-making in neurosurgery.",
  "optimization/meta": "The model developed in this study can be considered a meta-predictor, as it integrates outputs from multiple machine learning algorithms to make predictions. Specifically, the model uses data from several machine learning methods, including Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine, and K-Nearest Neighbor.\n\nThe Random Forest Classifier was identified as the most effective algorithm, achieving the highest ROC-AUC scores across all three outcome measures: VAS (0.863), MODI (0.831), and NCOS (0.869). This indicates that the Random Forest Classifier was the primary contributor to the final predictive model.\n\nRegarding the independence of the training data, the dataset was divided into training and testing subsets. The training dataset, which constituted 80% of the complete dataset, was used to fit the models. The remaining 20% of the dataset served as the test dataset, ensuring that the models were evaluated on data not used during training. This division was done in a way that maintained the proportional class ratio in both subsets, which helps to validate the model's performance on new, unseen data.\n\nThe use of multiple algorithms and the careful division of the dataset into training and testing subsets ensure that the model's predictions are robust and generalizable. This approach leverages the strengths of different machine learning techniques to provide a comprehensive and accurate predictive tool for decision-making in the management of degenerative lumbar spine disease.",
  "optimization/encoding": "For the machine-learning algorithm, data encoding and preprocessing were crucial steps to ensure the models could effectively learn from the input features. The primary outcome measures, including the Visual Analog Scale (VAS), Modified Oswestry Disability Index (MODI), and Neurogenic Claudication Outcome Score (NCOS), were collected preoperatively and at 6 months postoperatively. These measures were used to assess improvement in pain, functional status, and patient satisfaction.\n\nTo prepare the data for the machine-learning models, the improvement in each outcome measure was calculated by subtracting the preoperative value from the postoperative value. These improvements were then classified into distinct categories. For VAS improvement, the ranges were divided into four classes: 0 to 2, 3 to 4, 5 to 6, and 7 to 10. Similarly, MODI improvement was categorized into ranges of 0 to 5, 5 to 10, 11 to 15, and more than 15. NCOS improvement was divided into ranges of 0 to 10, 11 to 20, 21 to 30, and more than 30.\n\nLabel encoding was employed for other discrete input classes, which allowed the models to handle categorical variables effectively. This encoding technique converts categorical data into numerical format, making it suitable for training machine-learning algorithms.\n\nThe dataset was divided into training and testing subsets. The training dataset comprised 80% of the complete dataset and was used to fit the models. The remaining 20% constituted the test dataset, which was used to evaluate the models' performance on unseen data. The division ensured that the class ratios remained proportional in both subsets, maintaining the representativeness of all classes.\n\nTwo different models were trained for each type of classifier: Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine, and K-Nearest Neighbor. The first model was trained using sociodemographic factors, symptomatology scoring, psychosocial factors, and radiological factors. The second model was trained with the type of management used, which included conservative management, decompression, and decompression with fixation.\n\nThe final predicted probability for each model was derived by averaging the individual probabilities from the two models. The performance of the models was evaluated using the receiver-operating characteristic (ROC)\u2013area under the curve (AUC) score, which provided a measure of the models' discrimination capability. The Random Forest Classifier yielded the best ROC-AUC scores across all outcome measures, indicating its superior performance in predicting improvement in VAS, MODI, and NCOS.",
  "optimization/parameters": "In our study, the model utilized a variety of input parameters to predict outcomes for patients with degenerative lumbar spine disease. These parameters were categorized into sociodemographic factors, symptomatology scoring, psychosocial factors, and radiological factors. Specifically, the sociodemographic factors included variables such as sex and BMI. Symptomatology scoring involved measures like the Visual Analog Scale (VAS), Modified Oswestry Disability Index (MODI), and Neurogenic Claudication Outcome Score (NCOS). Psychosocial factors and radiological factors, such as the size and shape of the foramen and foraminal nerve root impingement, were also considered.\n\nThe selection of these parameters was based on their relevance to the clinical outcomes and the ability of the machine learning models to effectively utilize them for prediction. Two different models were trained for each type of classifier: one with the sociodemographic, symptomatology, psychosocial, and radiological factors, and another with the type of management used. This approach allowed for a comprehensive analysis of how different variables influence patient outcomes.\n\nThe number of parameters (p) used in the model varied depending on the specific classifier and the input features selected. For instance, the first model included features like sex and BMI, while the second model focused on the management class as input. The final predicted probability was derived from the average of individual probabilities, ensuring a robust prediction mechanism. The Random Forest Classifier, which provided the best ROC-AUC scores, was particularly effective in handling the selected parameters.",
  "optimization/features": "The study utilized a comprehensive set of input features to develop the predictive models. These features were categorized into sociodemographic, symptomatology, psychosocial, and radiological factors. The sociodemographic factors included age, gender, body mass index (BMI), occupation, and smoking status. Symptomatology factors encompassed the severity of back pain compared to leg pain, duration of symptoms, ambulation status, history of previous lumbar spine surgery, and scores from the Hamilton Anxiety scale (HAM-A), visual analog scale (VAS), Neurogenic Claudication Outcome Score (NCOS), and Modified Oswestry Disability Index (MODI). Additionally, neurological examination results, including the presence of neurological deficits such as objective weakness and cauda equina syndrome, were considered. Radiological factors included measurements related to foraminal nerve root impingement and the size and shape of the foramen.\n\nFeature selection was performed to identify the most relevant variables for training the models. This process was conducted using the training dataset only, ensuring that the test dataset remained unbiased and was used solely for evaluating the model's performance. The selected features were then used to train various machine learning algorithms, including Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine, and K-Nearest Neighbor. Two models were trained for each algorithm: one with the sociodemographic, symptomatology, psychosocial, and radiological factors, and another with the type of management used. This approach aimed to enhance the predictive accuracy and robustness of the models.",
  "optimization/fitting": "The study employed a robust approach to ensure that the models were neither overfitting nor underfitting the data. The dataset consisted of 180 patients, which was divided into training and testing subsets. The training dataset comprised 80% of the total data, while the testing dataset included the remaining 20%. This division ensured that the class ratios remained proportional in both subsets, maintaining the representativeness of the data.\n\nTo address the potential issue of overfitting, given the relatively large number of parameters compared to the number of training points, several strategies were implemented. First, the dataset was divided into training and testing sets to evaluate the model's performance on unseen data. Second, multiple machine learning algorithms were used, including Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine, and K-Nearest Neighbor. The Random Forest Classifier was ultimately chosen due to its superior performance, as indicated by the highest ROC-AUC scores across all outcome measures (VAS, MODI, and NCOS). This algorithm's ensemble nature helps to reduce overfitting by averaging the results of multiple decision trees.\n\nAdditionally, the models were trained using two different sets of features: one including sociodemographic factors, symptomatology scoring, psychosocial factors, and radiological factors, and the other including the type of management used. This dual approach helped to ensure that the models were generalizable and not overly reliant on any single set of features.\n\nTo rule out underfitting, the models were evaluated using the ROC-AUC metric, which provides a comprehensive measure of the model's discrimination capability. The Random Forest Classifier achieved high ROC-AUC scores (0.863 for VAS, 0.831 for MODI, and 0.869 for NCOS), indicating strong predictive performance. Furthermore, the models were validated on a separate test dataset, ensuring that they could generalize well to new, unseen data.\n\nIn summary, the study employed a combination of dataset division, multiple algorithm evaluation, and comprehensive performance metrics to ensure that the models were neither overfitting nor underfitting the data. The use of the Random Forest Classifier, with its ensemble learning approach, further enhanced the models' robustness and generalizability.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a blackbox. It leverages the Random Forest Classifier, which is inherently more interpretable compared to other complex machine learning models. Random Forest models provide insights into feature importance, allowing clinicians to understand which variables significantly influence the outcomes.\n\nFor instance, the model can highlight that variables such as the duration of symptoms, body mass index (BMI), and the presence of radiculopathy are critical in predicting patient outcomes. This transparency is crucial for medical professionals, as it enables them to trust the model's predictions and incorporate them into their decision-making processes.\n\nMoreover, the graphical user interface (GUI) tool built using this model allows surgeons to input patient details and observe how changes in management strategies affect predicted outcomes. This interactive feature enhances the interpretability by showing the impact of different variables in real-time, making it easier for clinicians to understand and apply the model's recommendations.",
  "model/output": "The model developed in this study is a classification model. It was designed to predict the improvement in outcome measures, specifically the Visual Analog Scale (VAS), Modified Oswestry Disability Index (MODI), and Neurogenic Claudication Outcome Score (NCOS), based on preoperative variables. These outcome measures were categorized into discrete classes to facilitate classification.\n\nThe model uses various machine learning algorithms, including Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine, and K-Nearest Neighbor. Among these, the Random Forest Classifier performed the best, achieving the highest ROC-AUC scores for all three outcome measures. The ROC-AUC scores for VAS, MODI, and NCOS were 0.863, 0.831, and 0.869, respectively, indicating strong discriminatory power.\n\nThe model's output is a prediction of the class of improvement in the outcome measures based on the input variables. This allows clinicians to estimate the likely improvement in pain, functional status, and patient satisfaction for different management strategies, such as conservative treatment, decompressive surgery, and decompression with fixation. The model's predictions can help guide decision-making to achieve the best possible outcomes for patients with degenerative lumbar spine disease.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The software developed as part of this study is accessible online. A graphical user interface (GUI) tool was created to facilitate the input of patient details and predict changes in outcome measures. This tool leverages the machine learning algorithm defined in the study. The tool can be accessed via a web server, allowing surgeons to input patient data and receive predictions on the expected improvement in various indices based on different management strategies. This interface helps in tailoring the decision-making process to achieve the best possible outcomes for patients.\n\nThe toolkit is available at the URL: http://134.209.148.167:5000. This online accessibility ensures that the predictive model can be easily integrated into clinical practice, aiding in the decision-making process for managing degenerative lumbar spine disease.",
  "evaluation/method": "The evaluation method involved assessing the discrimination capability of various machine learning models using the area under the curve (AUC) from the receiver-operating characteristic (ROC) analysis. The models were trained on a dataset of 180 patients with lumbar spine disease, divided into training and testing datasets. The training dataset comprised 80% of the complete dataset, while the testing dataset consisted of the remaining 20%. This division ensured that the class ratio of all classes remained proportional in both datasets.\n\nSeveral machine learning algorithms were evaluated, including Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine, and K-Nearest Neighbor. Two different models for each type of classifier were trained: the first with sociodemographic factors, symptomatology scoring, psychosocial factors, and radiological factors, and the second with the type of management used.\n\nThe Random Forest Classifier demonstrated the best performance, achieving the highest ROC-AUC scores across all three outcome measures: 0.863 for the Visual Analog Scale (VAS), 0.831 for the Modified Oswestry Disability Index (MODI), and 0.869 for the Neurogenic Claudication Outcome Score (NCOS). The macroaverage AUC score was found to be 0.842, indicating moderate discriminatory power.\n\nA graphical user interface (GUI) tool was developed to facilitate the practical application of the model. This tool allows surgeons to input patient details, select the initial management strategy, and observe predicted improvements in the VAS, MODI, and NCOS scores. Surgeons can also adjust the management strategy to see how different approaches might affect the outcomes, helping them to determine the most suitable management for individual patients.",
  "evaluation/measure": "The performance of the machine learning models was primarily evaluated using the Area Under the Curve (AUC) metric derived from the Receiver Operating Characteristic (ROC) analysis. This metric is widely recognized for assessing the discriminatory power of diagnostic tests. The AUC values for different models and outcome measures were reported, with the Random Forest Classifier achieving the highest scores across all categories. Specifically, the AUC scores for the Random Forest Classifier were 0.863 for the Visual Analog Scale (VAS) improvement, 0.831 for the Modified Oswestry Disability Index (MODI) improvement, and 0.869 for the Neurogenic Claudication Outcome Score (NCOS) improvement. The macroaverage AUC score, which provides an overall measure of performance, was found to be 0.842, indicating moderate discriminatory power. This set of metrics is representative of standard practices in evaluating machine learning models, particularly in medical diagnostics, where the ROC-AUC is a common and reliable measure. The use of these metrics ensures that the models' performance can be compared with other studies in the field, providing a clear indication of their effectiveness in predicting patient outcomes.",
  "evaluation/comparison": "In our study, we evaluated the performance of various machine learning algorithms to predict improvements in VAS, MODI, and NCOS scores for patients with degenerative lumbar spine disease. The algorithms compared included Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Machine, and K-Nearest Neighbor. The performance of these algorithms was assessed using the ROC-AUC score, which measures the discrimination capability of the models.\n\nThe Random Forest Classifier emerged as the best-performing algorithm, achieving the highest ROC-AUC scores across all three outcome measures: 0.863 for VAS improvement, 0.831 for MODI improvement, and 0.869 for NCOS improvement. This resulted in a macroaverage AUC score of 0.842, indicating moderate discriminatory power.\n\nWhile we did not perform a direct comparison to publicly available methods on benchmark datasets, our approach involved training and validating multiple models using a comprehensive dataset of 180 patients. This dataset included a variety of preoperative variables categorized into sociodemographic, clinical, and radiological factors. The models were trained on 80% of the dataset and tested on the remaining 20%, ensuring that the class ratios were proportional in both subsets.\n\nAdditionally, we compared the performance of different machine learning algorithms, which can be considered simpler baselines in some contexts. For instance, Logistic Regression and Decision Tree Classifier served as baseline models against which the more complex Random Forest Classifier was evaluated. The Random Forest Classifier's superior performance in all outcome measures justified its selection for the predictive tool.\n\nIn summary, our study involved a thorough comparison of multiple machine learning algorithms to identify the most effective model for predicting patient outcomes. The Random Forest Classifier's consistent high performance across all outcome measures underscored its suitability for developing a predictive tool to aid in clinical decision-making.",
  "evaluation/confidence": "The evaluation of the machine learning models in this study focused on the area under the receiver-operating characteristic curve (AUC-ROC) to assess their discrimination capability. The Random Forest Classifier demonstrated the highest AUC-ROC scores across all three outcome measures: 0.863 for the Visual Analog Scale (VAS), 0.831 for the Modified Oswestry Disability Index (MODI), and 0.869 for the Neurogenic Claudication Outcome Score (NCOS). The macroaverage AUC score was 0.842, indicating moderate discriminatory power.\n\nThe study did not explicitly mention confidence intervals for the performance metrics. However, the p-values reported in the results suggest statistical significance in the improvements observed across different management strategies. For instance, the p-values for improvements in VAS, MODI, and NCOS scores were all less than 0.001, indicating that the observed differences are statistically significant.\n\nThe use of the Random Forest Classifier was justified by its superior performance compared to other algorithms such as Logistic Regression, Decision Tree Classifier, Support Vector Machine, and K-Nearest Neighbor. The statistical significance of the results supports the claim that the Random Forest Classifier is a robust method for predicting outcomes in patients with degenerative lumbar spine disease.\n\nIn summary, while confidence intervals were not provided, the statistical significance of the results and the superior performance of the Random Forest Classifier lend confidence to the evaluation metrics presented.",
  "evaluation/availability": "Not applicable"
}