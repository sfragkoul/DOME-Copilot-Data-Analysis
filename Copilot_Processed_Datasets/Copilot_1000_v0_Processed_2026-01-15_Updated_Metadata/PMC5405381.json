{
  "publication/title": "Mass Spectrometry Profiling of HLA-Associated Peptidomes in Mono-allelic Cells Enables More Accurate Epitope Prediction.",
  "publication/authors": "Abelin JG, Keskin DB, Sarkizova S, Hartigan CR, Zhang W, Sidney J, Stevens J, Lane W, Zhang GL, Eisenhaure TM, Clauser KR, Hacohen N, Rooney MS, Carr SA, Wu CJ",
  "publication/journal": "Immunity",
  "publication/year": "2017",
  "publication/pmid": "28228285",
  "publication/pmcid": "PMC5405381",
  "publication/doi": "10.1016/j.immuni.2017.02.007",
  "publication/tags": "- HLA class I\n- Peptide presentation\n- LC-MS/MS\n- Epitope prediction\n- Gene expression\n- Proteasomal cleavage\n- Neural networks\n- Antigen processing\n- Immunopeptidomics\n- Bioinformatics predictors\n- HLA peptidome\n- RNA-Seq\n- Protein abundance\n- Binding motifs\n- Immunopurifications\n- Spectral search algorithm\n- T cell receptors\n- HLA alleles\n- Endogenous peptides\n- Machine learning",
  "dataset/provenance": "The dataset used in our study was generated through a scalable mass spectrometry (MS)-based pipeline. This approach allowed us to identify over 24,000 endogenous HLA class I peptides. The key advantage of our dataset is that it comes from cells expressing a single HLA allele, which eliminates the need for bioinformatics predictors or deconvolution methods to assign peptides to specific alleles. This unambiguous allele assignment greatly enhanced the depth and accuracy of our analyses.\n\nOur dataset is larger and more comprehensive than what is reported in the Immune Epitope Database (IEDB). This size and specificity allowed us to reveal allele-specific binding motifs, proteasomal cleavage rules, and the effects of transcript abundance on peptide presentation. These findings were validated biochemically, providing a robust foundation for our conclusions.\n\nThe dataset includes a variety of predictor variables such as affinity, stability, RNA-Seq expression, protein expression (iBAQ), cleavability score, and source protein localization. These variables were used to train neural network models, which outperformed standard predictors by approximately two-fold. The models, MSIntrinsic and MSIntrinsicEC, were evaluated on both internal and external datasets, demonstrating their superior performance in predicting HLA-presented peptides.\n\nThe dataset's quality and the integration of multiple variables have significantly improved our understanding of antigen-processing rules. This advancement is expected to enhance the prediction of which peptides will be presented by specific HLA alleles, which is crucial for vaccine development and other immunological applications.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is neural networks. Specifically, we developed single-layer artificial networks for each of the 16 HLA alleles studied. These networks were designed to predict epitope presentation based on various features.\n\nThe neural-network approach employed is not entirely new, as it is closely modeled after existing algorithms like NetMHC. However, the novelty lies in the integration of high-quality mass spectrometry (MS) data and conceptual advances in data integration. This integration allowed us to improve the predictive power of the algorithms significantly.\n\nThe reason this work was not published in a machine-learning journal is that the primary focus of our study is on immunology and the prediction of HLA-peptide binding. The advancements in the neural-network design are secondary to the biological insights and the improvement in predictive accuracy for HLA-presented peptides. Our results demonstrate that large MS datasets of endogenous HLA-binding peptides can greatly enhance our understanding of antigen-processing rules and the power of algorithms to predict which peptides will be presented by specific HLA alleles. This biological context and application are more aligned with journals in the field of immunology and bioinformatics.",
  "optimization/meta": "The models developed in this study, MSIntrinsic and MSIntrinsicEC, are not traditional meta-predictors that use the outputs of other machine-learning algorithms as direct inputs. Instead, they are neural-network models that integrate various biological features to predict HLA-peptide binding.\n\nMSIntrinsic is trained exclusively on mass spectrometry (MS) data and uses peptide-intrinsic features such as amino acid dummy variables, amino acid properties, and peptide properties. These features are directly derived from the peptide sequences and their biochemical properties, rather than being outputs from other machine-learning models.\n\nMSIntrinsicEC, on the other hand, includes additional inputs beyond the peptide-intrinsic features. It incorporates RNA-Seq expression data and cleavability scores, which are derived from experimental measurements rather than other machine-learning predictions. The RNA-Seq data provides information on gene expression levels, while the cleavability scores indicate the likelihood of the peptide being cleaved by proteasomes or other peptidases.\n\nThe training data for these models is derived from a large dataset of endogenous HLA-binding peptides, which were unambiguously assigned to specific HLA alleles. This dataset was generated using a rapid approach that ensured high quality and depth of analysis. The models were evaluated using both internal and external datasets, demonstrating their superior performance compared to existing predictors like NetMHC 4.0 and NetMHCpan 2.8.\n\nThe independence of the training data is ensured by the experimental design, which involved generating a high-quality MS dataset of endogenous peptides. The peptides were assigned to specific HLA alleles a priori, which allowed for a more accurate and unbiased training of the models. The external evaluation using datasets from other studies further validates the independence and generalizability of the training data.",
  "optimization/encoding": "For the machine-learning algorithms, we employed several encoding schemes to capture various aspects of the peptide data. We used dummy encoding for amino acids, which involves creating binary vectors for each amino acid in the peptide sequence. Additionally, we incorporated amino acid properties and peptide-level features to provide a more comprehensive representation of the peptides. These properties included biochemical characteristics and structural features that are known to influence peptide binding and processing.\n\nWe also utilized the BLOSUM62 substitution matrix to encode amino acid similarities, which helps in capturing evolutionary relationships between amino acids. Furthermore, we integrated the PMBEC matrix, which is designed to reflect the physicochemical properties of amino acids, providing another layer of information for the models.\n\nTo account for expression levels, we used RNA-Seq data, which offers a high-resolution view of transcript abundance. This data was processed to ensure that non-coding transcripts were excluded and that the expression values were rescaled appropriately. For protein expression, we employed the iBAQ method, which provides a quantitative measure of protein abundance based on mass spectrometry data.\n\nCleavability scores were also included as input features, derived from the sequence context of the peptides. These scores help in predicting the likelihood of a peptide being cleaved by proteasomes or other peptidases, which is a crucial step in antigen processing.\n\nIn summary, the data encoding process involved a combination of amino acid dummy variables, amino acid properties, peptide-level features, expression data, and cleavability scores. This multifaceted approach allowed our machine-learning models to leverage a wide range of biological information, leading to improved predictive performance.",
  "optimization/parameters": "In our study, we utilized a neural-network model architecture that incorporated a variety of input parameters to predict HLA-peptide binding. The model, referred to as MSIntrinsic, included 215 input parameters. These parameters were categorized into three main groups: amino acid dummy variables, amino acid properties, and peptide properties. Specifically, the model used 180 nodes for amino acid dummy variables, 27 nodes for amino acid properties, and 8 nodes for peptide properties.\n\nAdditionally, we developed another model, MSIntrinsicEC, which included 182 input parameters. This model expanded on MSIntrinsic by incorporating expression data (1 node) and cleavability scores (1 node) alongside the amino acid dummy variables.\n\nThe selection of these parameters was driven by the goal of integrating multiple variables to improve the accuracy of epitope selection. We assessed the performance of our models by evaluating their ability to discern mass spectrometry (MS) peptides among a 999-fold excess of decoy peptides. This approach allowed us to measure the positive predictive value (PPV), which is a critical metric for understanding the model's performance in real-world scenarios. Through exhaustive testing of all possible predictor combinations, we identified the order of variable addition that provided the most predictive value early in the process. This method ensured that the most influential variables were prioritized, enhancing the model's explanatory power.",
  "optimization/features": "In our study, we utilized a comprehensive set of input features to train our neural-network classifiers. The total number of features (f) used as input varied depending on the model. For the MSIntrinsic model, we employed 215 features, which included amino acid dummy variables, amino acid properties, and peptide properties. The MSIntrinsicEC model, on the other hand, incorporated an additional 182 features, including amino acid dummy variables, expression data, and cleavability scores.\n\nFeature selection was not explicitly performed in the traditional sense of reducing the number of features. Instead, we carefully curated a set of relevant features based on biological knowledge and previous studies. This approach ensured that our models were trained on a rich and informative set of input features without the need for extensive feature selection procedures.\n\nThe selection of features was done independently of the training set, relying on established biological principles and external datasets. This method helped to avoid overfitting and ensured that the features used were generalizable and biologically meaningful. By integrating a diverse range of features, we aimed to capture the complexity of the epitope selection process and improve the predictive performance of our models.",
  "optimization/fitting": "Not enough information is available.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models developed in this study, specifically MSIntrinsic and MSIntrinsicEC, are not entirely black-box models. They incorporate various predictor variables that contribute to their decision-making process, making them more interpretable than purely black-box models.\n\nThe MSIntrinsic model uses peptide-intrinsic features, including amino acid dummy variables, amino acid properties, and peptide properties. These features are directly related to the sequence and characteristics of the peptides, providing a clear basis for the model's predictions.\n\nThe MSIntrinsicEC model builds upon MSIntrinsic by additionally accounting for RNA-Seq expression and the cleavability of the protein sequence context. This inclusion of external factors enhances the model's ability to predict peptide presentation by considering the biological context in which the peptides are generated.\n\nThe explanatory contributions of these predictor variables can be quantified by observing the cumulative improvement in predictive value as each variable is added to the model. This analysis reveals that affinity and expression are the dominant factors, with other variables like cleavability and localization providing incremental improvements.\n\nFor instance, the positive predictive value (PPV) of the model improves significantly when RNA-Seq or iBAQ-based protein expression is included, indicating the strong influence of gene expression on peptide presentation. Similarly, the addition of cleavability prediction boosts the PPV, highlighting the importance of proteasomal processing in determining which peptides are presented.\n\nMoreover, the neural-network architecture of these models is designed to be transparent, with inputs clearly defined and their contributions to the output measurable. This design allows for a better understanding of how different factors interact to influence the model's predictions.\n\nIn summary, while the models leverage complex neural networks, they are not entirely opaque. The use of well-defined predictor variables and the ability to track their contributions to the model's performance make these models more interpretable and provide insights into the biological processes governing peptide presentation.",
  "model/output": "The model developed in our study is primarily a classification model. It is designed to discern mass spectrometry (MS) peptides among a vast excess of decoy peptides, effectively identifying which peptides are likely to be presented by specific HLA alleles. The performance of these models is evaluated using the positive predictive value (PPV), which measures the percentage of predicted positives that are indeed observed in the MS data. This approach contrasts with the standard area under the receiver operator characteristic curve (AUC), which integrates performance over all possible target-to-decoy ratios.\n\nTwo main models were created: MSIntrinsic and MSIntrinsicEC. MSIntrinsic is trained exclusively on MS data and uses peptide-intrinsic features only. MSIntrinsicEC, on the other hand, additionally accounts for RNA-Seq expression and the cleavability of the protein sequence context. Both models are single-layer artificial networks developed for each of the 16 alleles studied.\n\nThe models were evaluated on both internal and external datasets, demonstrating superior performance compared to existing tools like NetMHC 4.0 and NetMHCpan 2.8. Specifically, MSIntrinsic and MSIntrinsicEC outperformed these tools in a 5-fold cross-validation by an average PPV of 20 and 30 percentage points, respectively. This indicates that our models are highly effective in classifying peptides that are likely to be presented by HLA alleles.\n\nIn external evaluations using published datasets, MSIntrinsic and MSIntrinsicEC showed a positive predictive value that was 1.4-fold and 1.9-fold better on average, respectively, compared to NetMHC 4.0 and NetMHCpan 2.8. This suggests that our models can significantly enhance the accuracy of epitope identification, which is crucial for applications such as vaccine development.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our methods involved several rigorous approaches to ensure the robustness and generalizability of our findings. We employed both internal and external datasets to assess the performance of our models. For internal evaluation, we used a 5-fold cross-validation strategy, which involved splitting our dataset into five parts, training our models on four parts, and testing on the remaining part. This process was repeated five times, with each part serving as the test set once. This method allowed us to evaluate the models' performance consistently across different subsets of the data.\n\nIn addition to cross-validation, we also evaluated our models on external datasets. These datasets were derived from published studies and included observations from six different HLA alleles and seven cell lines. This external evaluation helped us to assess how well our models generalize to new, unseen data. We compared the positive predictive value (PPV) of our models, MSIntrinsic and MSIntrinsicEC, against established predictors like NetMHC 4.0 and NetMHCpan 2.8. Our models outperformed these predictors, demonstrating their superior ability to identify presented peptides among a large excess of decoy peptides.\n\nFurthermore, we conducted experiments to validate the peptides that scored poorly in our models. Specifically, we selected MS 9-mer peptides that scored in the bottom 10% by NetMHCpan 2.8 and experimentally validated them. This step was crucial in ensuring that our models were not only accurate but also reliable in identifying true positive peptides.\n\nOverall, our evaluation methods combined internal cross-validation, external dataset testing, and experimental validation to provide a comprehensive assessment of our models' performance. This multi-faceted approach ensured that our findings are robust and applicable to real-world scenarios.",
  "evaluation/measure": "In our evaluation, we primarily focused on the positive predictive value (PPV) as our key performance metric. PPV measures the percentage of predicted positive peptides that were indeed observed in the mass spectrometry (MS) data. This metric is particularly relevant because it reflects the real-world scenario where the number of potential peptides is vastly larger than the number of actual presented peptides. We assessed PPV by discerning MS peptides among a 999-fold excess of decoy peptides, mimicking the reality of the epitope selection problem.\n\nIn addition to PPV, we also considered the area under the receiver operator characteristic curve (AUC). However, we noted that AUC integrates performance over all possible target-to-decoy ratios, which includes unrealistic scenarios. Therefore, while AUC provides a comprehensive view of model performance, PPV is more aligned with the practical challenges of epitope prediction.\n\nOur approach to evaluating performance involved both internal and external datasets. Internally, we used a 5-fold cross-validation to assess the models' ability to generalize to unseen data. Externally, we compared our models against established predictors like NetMHCpan 2.8 and NetMHC 4.0 using published datasets. This dual evaluation strategy ensures that our models are robust and perform well in diverse settings.\n\nThe use of PPV and AUC is consistent with the literature, where these metrics are commonly employed to evaluate the performance of epitope prediction models. PPV is especially crucial in the context of HLA-peptide binding prediction, as it directly addresses the challenge of identifying true positives among a large number of potential candidates. Our focus on PPV, along with the inclusion of AUC for a broader performance assessment, provides a comprehensive and representative evaluation of our models.",
  "evaluation/comparison": "In our evaluation, we performed a comprehensive comparison of our methods with publicly available tools, specifically NetMHCpan 2.8 and NetMHC 4.0, using benchmark datasets. We utilized MS-binding data from two published datasets to assess the positive predictive value of our models, MSIntrinsic and MSIntrinsicEC, against these established predictors. The datasets included peptides from multiple alleles and cell lines, providing a robust benchmark for comparison.\n\nOur models demonstrated superior performance, with MSIntrinsicEC showing a 1.9-fold better positive predictive value on average compared to NetMHCpan 2.8 and NetMHC 4.0. This improvement was consistent across different alleles and cell lines, indicating the robustness of our approach.\n\nAdditionally, we evaluated the performance of our models using simpler baselines, such as affinity-only and stability-only predictors. These baselines served as foundational comparisons to highlight the incremental improvements achieved by integrating multiple variables. For instance, an affinity-only model achieved a positive predictive value of 28%, while the addition of RNA-Seq expression and cleavability significantly enhanced the predictive accuracy.\n\nThe comparison with simpler baselines and publicly available methods underscores the effectiveness of our integrated approach, which leverages peptide-intrinsic features, RNA-Seq expression, and cleavability to improve the prediction of HLA-presented peptides. This evaluation demonstrates that our models outperform existing tools and provide a more accurate and reliable framework for epitope selection.",
  "evaluation/confidence": "The evaluation of our models, MSIntrinsic and MSIntrinsicEC, was conducted using positive predictive value (PPV) and area under the curve (AUC) metrics. These metrics were chosen to assess the performance of our models in discerning true MS peptides among a large excess of decoy peptides. The PPV metric, in particular, was used to measure the fraction of true MS peptides among the top-scoring 0.1% of peptides, which closely mimics the reality of the epitope selection problem.\n\nIn our evaluation, we found that MSIntrinsic and MSIntrinsicEC outperformed both NetMHC 4.0 and NetMHCpan 2.8 in a 5-fold cross-validation by an average PPV of 20 and 30 percentage points, respectively. This performance difference was statistically significant, indicating that our models have a superior ability to predict presented peptides. Additionally, while all models achieved an average AUC greater than 0.98, MSIntrinsic and MSIntrinsicEC consistently reached higher true-positive rates at minimal false-positive rates.\n\nThe statistical significance of our results was further supported by external evaluations using MS-binding data from published datasets. In these evaluations, MSIntrinsic and MSIntrinsicEC demonstrated a positive predictive value that was 1.4-fold and 1.9-fold better on average, respectively, compared to NetMHC 4.0 and NetMHCpan 2.8. These results suggest that our models can roughly double the number of correct epitope identifications in a vaccine, highlighting their potential clinical relevance.\n\nConfidence intervals for the performance metrics were not explicitly provided in the main text, but the consistent and significant performance improvements across multiple evaluations and datasets lend strong support to the reliability and robustness of our models. The use of multiple evaluation metrics and datasets helps to ensure that the reported performance is not due to chance or overfitting, but rather reflects a genuine improvement in predictive accuracy.",
  "evaluation/availability": "Not enough information is available."
}