{
  "publication/title": "MULTI-DEEP: A novel CAD system for coronavirus (COVID-19) diagnosis from CT images using multiple convolution neural networks.",
  "publication/authors": "Attallah O, Ragab DA, Sharkas M",
  "publication/journal": "PeerJ",
  "publication/year": "2020",
  "publication/pmid": "33062453",
  "publication/pmcid": "PMC7532764",
  "publication/doi": "10.7717/peerj.10086",
  "publication/tags": "- Subjects Infectious Diseases\n- Computational Science\n- Data Mining and Machine Learning\n- Computed tomography (CT)\n- Computer-aided diagnosis (CAD)\n- Convolution neural networks (CNN)\n- Coronavirus (COVID-19)\n- Deep learning (DL)\n- Medical imaging\n- Principal component analysis (PCA)\n- Support vector machine (SVM)\n- COVID-19 diagnosis\n- Machine learning in healthcare\n- Image classification\n- Feature extraction\n- Medical image analysis\n- COVID-19 detection\n- Radiology\n- Artificial intelligence in medicine\n- Data augmentation\n- Performance evaluation",
  "dataset/provenance": "The dataset used in this study is sourced from a previous publication by Zhao et al. It comprises a total of 744 CT images, with 347 images labeled as COVID-19 cases and 397 images labeled as non-COVID-19 cases. These non-COVID-19 images encompass various types of pathology.\n\nThe CT images in the dataset exhibit a range of dimensions. The length of the images varies from 153 to 1,853 pixels, with an average length of 491 pixels. Similarly, the width of the images ranges from 124 to 383 pixels, averaging 1,485 pixels.\n\nThis dataset has been utilized in the current study to evaluate the performance of the proposed MULTI-DEEP CAD system in detecting COVID-19 and differentiating it from non-COVID-19 cases. The dataset's diversity in image dimensions and pathology types ensures a robust evaluation of the system's capabilities.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study is publicly available. It can be accessed via GitHub at the COVID-CT-Dataset repository. This dataset includes both COVID-19 and non-COVID-19 CT images, providing a comprehensive resource for research and validation purposes. The availability of this dataset ensures transparency and reproducibility in our research. The dataset includes 347 COVID-19 images and 397 non-COVID-19 images, covering various pathologies. The images vary in size, with lengths ranging from 153 to 1,853 pixels and widths from 124 to 383 pixels. This public availability allows other researchers to verify our findings and build upon our work, fostering collaboration and advancement in the field.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Support Vector Machines (SVM), specifically the cubic SVM classifier. This classifier is not new; it is a well-established method in the field of machine learning. The cubic SVM classifier was chosen for its effectiveness in handling high-dimensional spaces and for its ability to perform well with clear margin of separation.\n\nThe reason the cubic SVM classifier is discussed in a medical journal rather than a machine-learning journal is that the focus of our work is on the application of machine learning techniques to medical imaging, specifically for the detection of COVID-19 from lung CT images. The novelty lies in the application and the integration of the cubic SVM classifier within a multi-deep Convolutional Neural Network (CNN) framework for medical diagnosis. This approach combines deep learning features with traditional machine learning classification methods to enhance the accuracy and efficiency of COVID-19 detection.\n\nThe cubic SVM classifier is used in conjunction with deep features extracted from pre-trained CNNs, such as AlexNet, GoogleNet, ResNet-18, and ShuffleNet. These deep features are either used individually or fused together to train the SVM classifier. The use of PCA to reduce the dimensionality of the deep feature space further enhances the performance of the SVM classifier. This integration of deep learning and traditional machine learning techniques is what makes our approach unique and applicable to the medical field.",
  "optimization/meta": "The model described in this publication does not use data from other machine-learning algorithms as input. Instead, it employs a multi-deep CAD system that utilizes four different pre-trained convolutional neural networks (CNNs): AlexNet, GoogleNet, ResNet-18, and ShuffleNet. These CNNs are used to extract deep features from lung CT images, which are then processed and classified.\n\nThe system operates through four distinct scenarios:\n\n1. **End-to-End Deep Learning Approach**: Four pre-trained CNNs are fine-tuned to classify COVID-19 and non-COVID-19 cases directly.\n2. **Deep Feature Extraction Approach**: Deep features are extracted from the fully connected layers of the CNNs and used to train cubic SVM classifiers individually.\n3. **Principal Component Selection Approach**: Principal Component Analysis (PCA) is applied to the deep features, and the selected principal components are used to train SVM classifiers.\n4. **Feature Fusion Approach**: The deep features from all four CNNs are fused, and PCA is applied to the fused features to reduce dimensionality before training the SVM classifier.\n\nThe meta-predictor aspect comes into play in the third and fourth scenarios, where the outputs of the individual CNNs (either as deep features or principal components) are combined and used to train a cubic SVM classifier. This fusion of features aims to enhance the detection accuracy and computational efficiency of the system.\n\nRegarding the independence of training data, the system uses 5-fold cross-validation to ensure that the performance of the proposed CAD system is validated robustly. This method helps to confirm that the training data is independent and that the model's performance is generalizable to new, unseen data. The use of augmentation techniques, such as flipping, translation, and scaling, further ensures that the model does not overfit to the training data, thereby maintaining the independence of the training samples.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of the machine-learning algorithms employed. The dataset consisted of lung CT images, which were first resized to match the input size requirements of the convolutional neural network (CNN) architectures used. This step was essential because different CNNs have varying input size specifications.\n\nAugmentation techniques were applied to increase the size of the dataset and to prevent overfitting. These techniques included flipping, translation, and scaling. Each CT image was translated in the x and y directions within a pixel range of -30 to 30. Additionally, each original image was flipped, and scaling was applied with a range of 0.9 to 1.1. These augmentations helped in creating a more robust and diverse training set, which is vital for improving the generalization capability of the models.\n\nFor the deep feature extraction approach, valuable features were extracted from each deep CNN separately. Principal component analysis (PCA) was then applied to each deep feature set individually to reduce dimensionality and select the optimal number of principal components. This step was crucial for enhancing the computational efficiency and performance of the support vector machine (SVM) classifiers.\n\nIn the detection approach, four different scenarios were employed to evaluate the performance of the proposed multi-deep CAD system. The first scenario involved fine-tuning four pre-trained CNNs for end-to-end classification of COVID-19 and non-COVID-19 cases. The second scenario extracted deep features from each CNN and used them individually to train cubic SVM classifiers. The third scenario applied PCA to each deep feature set, selecting a chosen number of principal components to train the SVM classifiers individually. The fourth scenario investigated the effect of fusing the deep features from the four CNNs, applying PCA to the fused features to further reduce dimensionality and enhance the performance of the SVM classifier.\n\nThe parameters for the pre-trained CNNs were fine-tuned to optimize performance. The number of epochs was set to 20, with an initial learning rate of 10^-4. The mini-batch size and validation frequency were set to 10 and 4, respectively. L-regularization was set to 0.0005, and stochastic gradient descent with momentum was used for optimization. These configurations were designed to ensure that the parameters were finely tuned for the detection of medical data.\n\nTo validate the performance of the proposed system, 5-fold cross-validation was used. The kernel function for the SVM classifier was set to cubic, as it achieved the best performance in our experiments. These preprocessing and encoding steps were essential for preparing the data and ensuring the reliability and accuracy of the machine-learning models used in our study.",
  "optimization/parameters": "In the optimization process of our model, several parameters were tuned to ensure optimal performance for the detection of medical data. The number of epochs was set to 20, and the initial learning rate for the four convolutional neural networks (CNNs) was 10^-4. The mini-batch size was configured to 10, and the validation frequency was set to 4. Additionally, L-regularization was applied with a value of 0.0005. These configurations were chosen to fine-tune the parameters specifically for the detection of medical data. Stochastic gradient descent with momentum was used for optimization. To validate the performance of the proposed MULTI-DEEP CAD system, 5-fold cross-validation was employed. The kernel function used for the support vector machine (SVM) classifier was cubic, as it achieved the best performance.",
  "optimization/features": "In the optimization process, the input features used for the Support Vector Machine (SVM) classifiers varied depending on the scenario. Feature selection was performed using Principal Component Analysis (PCA) to reduce the dimensionality of the deep features extracted from the pre-trained Convolutional Neural Networks (CNNs). This process was conducted individually for each deep feature set, ensuring that the selection was done using the training set only.\n\nFor Scenario III, the number of principal components selected for each CNN was determined through a forward sequential procedure. Specifically, 50 principal components were chosen for ResNet-18 and ShuffleNet. For GoogleNet, the highest accuracy was achieved using 50 and 100 principal components. For AlexNet, the optimal number of principal components was found to be 100 and 150. These selected principal components were then fused to form different feature sets, which were used to train the SVM classifiers.\n\nFour fused feature sets were generated and compared to determine the best combination that impacted the accuracy. Feature set (1) contained 50 components from each of ResNet-18, GoogleNet, and ShuffleNet, and 100 components from AlexNet. Feature set (2) included 50 components from each of ResNet-18, GoogleNet, and ShuffleNet, and 150 components from AlexNet. Feature set (3) was composed of 50 components from each of ResNet-18 and ShuffleNet, 100 components from GoogleNet, and 150 components from AlexNet. Feature set (4) had 50 components from each of ResNet-18 and ShuffleNet, and 100 components from both GoogleNet and AlexNet.\n\nThe highest SVM performance was achieved using Feature set (2), which yielded an accuracy of 94%, an AUC of 98%, a sensitivity of 94.9%, a specificity of 93.2%, a precision of 93%, and an F1-score of 94%. This indicates that the selection of principal components and their fusion significantly influenced the performance of the SVM classifiers.",
  "optimization/fitting": "In our study, we employed several strategies to address potential overfitting and underfitting issues. The number of parameters in our pre-trained Convolutional Neural Networks (CNNs) is indeed much larger than the number of training points, which is a common scenario in deep learning, especially when dealing with medical imaging data.\n\nTo mitigate overfitting, we utilized transfer learning, where we fine-tuned pre-trained CNNs that were originally trained on large datasets like ImageNet. This approach helps the model to generalize better to the new task of COVID-19 detection. Additionally, we applied data augmentation techniques such as flipping, translation, and scaling to artificially increase the size of our training dataset. This helps in making the model more robust and less likely to overfit to the training data.\n\nWe also employed L2 regularization with a value of 0.0005 to penalize large weights and prevent the model from becoming too complex. Furthermore, we used stochastic gradient descent with momentum for optimization, which helps in navigating the loss surface more effectively and can lead to better generalization.\n\nTo ensure that our model was not underfitting, we carefully tuned several hyperparameters, including the number of epochs (set to 20), the initial learning rate (set to 10^-4), the mini-batch size (set to 10), and the validation frequency (set to 4). We also used 5-fold cross-validation to validate the performance of our model, which helps in assessing the model's ability to generalize to unseen data.\n\nMoreover, we compared the performance of our model using different scenarios, including the fusion of multiple CNNs, which helped in enhancing the accuracy of the Computer-Aided Diagnosis (CAD) system. This multi-deep approach ensures that the model is not underfitting by leveraging the strengths of multiple CNNs.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was data augmentation. This process involved creating new lung CT images from the training data through techniques such as flipping, translation, and scaling. Each CT image was translated in the x and y directions within a pixel range of -30 to 30, flipped, and scaled within a range of 0.9 to 1.1. This augmentation helped to increase the size of the dataset, reducing the risk of overfitting by providing the model with a more diverse set of training examples.\n\nAdditionally, we utilized L-regularization with a value of 0.0005. This technique helps to penalize large weights in the model, encouraging simpler models that generalize better to unseen data. By incorporating L-regularization, we aimed to mitigate overfitting and improve the model's performance on validation and test sets.\n\nFurthermore, we employed stochastic gradient descent with momentum for optimization. This method not only helps in faster convergence but also aids in escaping local minima, which can contribute to better generalization of the model.\n\nTo validate the performance of our proposed MULTI-DEEP CAD system, we used 5-fold cross-validation. This technique ensures that the model is evaluated on different subsets of the data, providing a more reliable estimate of its performance and helping to prevent overfitting to a specific subset of the data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in detail within the publication. Specifically, the number of epochs was set to 20, with an initial learning rate of 10^-4 for the four convolutional neural networks (CNNs) used. The mini-batch size was 10, and the validation frequency was 4. L-regularization was set to 0.0005. Stochastic gradient descent with momentum was employed for optimization. These configurations were fine-tuned to ensure optimal performance for detecting medical data.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the methods and parameters used are described comprehensively, allowing for replication of the experiments. The publication does not specify the availability of model files or optimization parameters under a particular license, but the detailed descriptions provided should enable researchers to implement similar configurations in their own work.\n\nNot applicable",
  "model/interpretability": "The proposed MULTI-DEEP CAD system leverages the fusion of multiple convolutional neural networks (CNNs) to detect and classify COVID-19 cases, which inherently introduces a level of complexity that can make the model appear as a black box. However, the system's design incorporates several transparent and interpretable components that enhance its overall interpretability.\n\nFirstly, the use of pre-trained CNNs like AlexNet, GoogleNet, ResNet-18, and ShuffleNet, which have been extensively studied and documented, provides a foundational layer of transparency. These networks have well-defined architectures and are known for their feature extraction capabilities, making it easier to understand the types of features being extracted from the input images.\n\nSecondly, the deep feature extraction approach involves pulling out significant features from the fully connected (fc) layers of these pre-trained CNNs. This process is transparent because it relies on established layers within the networks, and the features extracted can be visualized and analyzed. For instance, the \"fc7\" layer in AlexNet or the dropout layer in GoogleNet are specific points where meaningful features are extracted, which can be inspected to understand what the model is focusing on.\n\nAdditionally, the application of Principal Component Analysis (PCA) to reduce the dimensionality of the extracted features adds another layer of interpretability. PCA transforms the original features into a set of principal components that capture the most variance in the data. By selecting the optimal number of principal components, the model ensures that the most informative features are retained, making it easier to interpret which features are contributing most to the classification task.\n\nThe use of Support Vector Machines (SVM) as classifiers further enhances the interpretability of the model. SVMs are known for their ability to provide clear decision boundaries and can be analyzed to understand how different features influence the classification outcomes. The performance metrics, such as accuracy, sensitivity, specificity, precision, F1-score, and AUC, are also transparent and provide a clear indication of the model's effectiveness.\n\nMoreover, the system's performance is evaluated across multiple scenarios, each with different configurations of feature extraction and fusion. This comparative analysis allows for a transparent evaluation of how different components of the model contribute to its overall performance. For example, the comparison between individual CNNs and the fusion of multiple CNNs provides insights into the benefits of combining different feature sets.\n\nIn summary, while the MULTI-DEEP CAD system leverages complex deep learning techniques, it incorporates several transparent and interpretable components. The use of well-documented pre-trained CNNs, clear feature extraction processes, dimensionality reduction through PCA, and the application of interpretable SVM classifiers all contribute to a model that, while powerful, is also understandable and interpretable.",
  "model/output": "The model presented in this publication is a classification model. It is designed to detect and classify COVID-19 cases from non-COVID-19 cases using lung CT images. The model employs convolutional neural networks (CNNs) and support vector machines (SVMs) to achieve this classification task. Specifically, the model uses four different pre-trained CNNs\u2014AlexNet, GoogleNet, ResNet-18, and ShuffleNet\u2014to extract deep features from the CT images. These features are then used to train SVM classifiers. The performance of the model is evaluated using metrics such as accuracy, sensitivity, specificity, precision, F1-score, and the area under the receiver operating characteristics curve (AUC). The highest performance was achieved by ResNet-18, with an accuracy of 92.5% and an AUC of 0.97 when the deep features were used to train the SVM classifier. The model's output is a classification of the input CT images into COVID-19 or non-COVID-19 categories.",
  "model/duration": "The execution time of the model varied across different scenarios. In the first scenario, where four pre-trained CNNs were used individually, the execution time ranged from approximately 19 minutes to 25 minutes. ResNet-18, which achieved the highest performance in this scenario, had an execution time of 19 minutes and 31 seconds.\n\nIn the second scenario, where deep features were extracted from each pre-trained CNN and used to train SVM classifiers individually, the execution times were significantly lower. The fastest execution time was 1.947 seconds for ResNet-18, while the slowest was 20.991 seconds for AlexNet.\n\nThe third scenario involved the fusion of a selected number of principal components from each deep feature set. This scenario had an execution time of 2.105 seconds, which was notably efficient compared to the other scenarios.\n\nIn the fourth scenario, which fused all deep features extracted from the four pre-trained CNNs without PCA, the execution time was 33.765 seconds. This was the highest execution time among all scenarios but resulted in a slightly higher accuracy of 94.7%.\n\nOverall, the fusion of the selected principal components in the third scenario led to a more efficient computational cost, making it the most time-effective approach while maintaining high performance.",
  "model/availability": "Not applicable",
  "evaluation/method": "The evaluation of the proposed MULTI-DEEP CAD system involved several metrics to assess its performance comprehensively. The primary metrics used were accuracy, sensitivity, specificity, precision, F1-score, and the area under the receiving operating characteristics curve (AUC). These metrics were calculated using standard equations to ensure consistency and reliability.\n\nTo validate the performance of the system, 5-fold cross-validation was employed. This technique helps in assessing the model's ability to generalize to an independent dataset by dividing the data into five subsets, training the model on four subsets, and testing it on the remaining one. This process is repeated five times, with each subset serving as the test set once.\n\nThe evaluation was conducted across four different scenarios. The first scenario involved using four pre-trained convolutional neural networks (CNNs) for end-to-end detection. The other three scenarios utilized a cubic support vector machine (SVM) classifier. In the second scenario, deep features extracted from each CNN were used to train individual cubic SVM classifiers. The third scenario involved using principal components selected from the deep feature sets via principal component analysis (PCA) to train the SVM classifiers. The fourth scenario investigated the impact of fusing the deep features from all four CNNs on detection accuracy and computational efficiency. PCA was also applied to the fused features to examine its effect on the SVM classifier's performance.\n\nThe performance metrics for each scenario were compared to determine the most effective approach. For instance, the fourth scenario achieved an accuracy of 94.7%, slightly higher than the 94% accuracy in the third scenario. However, the third scenario was more computationally efficient, with an execution time of 2.368 seconds compared to 33.765 seconds in the fourth scenario.\n\nAdditionally, data augmentation techniques such as flipping, translation, and scaling were applied to the training data to prevent overfitting and enhance the model's performance on testing sets. These techniques helped in creating a more robust and generalizable model.",
  "evaluation/measure": "In the evaluation of our proposed CAD system, we have reported several key performance metrics to comprehensively assess the effectiveness of our models. These metrics include accuracy, the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, precision, and the F1-score. Additionally, we have considered the execution time as a crucial metric to evaluate the computational efficiency of our models.\n\nAccuracy measures the overall correctness of the classification, providing a general sense of how well the model performs. The AUC evaluates the model's ability to distinguish between positive and negative classes, offering a single scalar value that summarizes the performance across all classification thresholds. Sensitivity, also known as recall, indicates the proportion of actual positives that are correctly identified by the model. Specificity measures the proportion of actual negatives that are correctly identified. Precision reflects the proportion of predicted positives that are actually positive, while the F1-score provides a harmonic mean of precision and recall, offering a balanced measure of a model's performance, especially when dealing with imbalanced datasets.\n\nThe execution time is an important metric that assesses the computational efficiency of the models, which is crucial for real-world applications where timely results are essential.\n\nThese metrics are widely recognized and used in the literature for evaluating classification models, particularly in medical imaging and diagnostic systems. They provide a comprehensive view of the model's performance, covering aspects such as correctness, discriminative power, and efficiency. By reporting these metrics, we aim to offer a clear and representative evaluation of our models' capabilities, allowing for meaningful comparisons with other studies in the field.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of different methods to evaluate the performance of our proposed CAD system. We examined four distinct scenarios to assess the effectiveness of fusing multiple CNNs for detecting COVID-19 and differentiating it from non-COVID-19 cases.\n\nIn the first scenario, we employed four pre-trained end-to-end networks\u2014AlexNet, GoogleNet, ResNet-18, and ShuffleNet\u2014which were fine-tuned to classify COVID-19 and non-COVID-19 cases. This approach allowed us to benchmark the performance of individual CNNs against our more complex fusion methods.\n\nThe second scenario involved extracting deep features from each CNN and using them individually to construct SVM classifiers. This method provided a baseline for comparing the performance of deep features extracted from individual networks.\n\nIn the third scenario, we applied Principal Component Analysis (PCA) to each deep feature set separately, selecting an optimal number of principal components for each feature set. These principal components were then used to train SVM classifiers individually. This approach helped us understand the impact of dimensionality reduction on the classification performance.\n\nThe fourth scenario focused on fusing the deep features extracted from the four CNNs to study the influence of this fusion on the performance of the SVM classifier. We also compared this fusion method with the fusion of selected principal components from scenario III. This comparison highlighted the benefits and trade-offs of feature fusion and dimensionality reduction.\n\nAdditionally, we compared our results with publicly available methods and simpler baselines. For instance, we referenced studies that used individual CNNs or fused two CNNs for segmentation and classification tasks. Our approach, which involves fusing multiple CNNs and applying PCA, demonstrated superior performance in terms of accuracy, sensitivity, specificity, precision, F1-score, and AUC.\n\nOverall, our comparisons showed that the fusion of multiple CNNs, particularly when combined with PCA, significantly enhances the detection accuracy and computational efficiency of the CAD system. This method outperformed simpler baselines and publicly available methods, underscoring its potential for improving COVID-19 diagnosis.",
  "evaluation/confidence": "The performance metrics presented in the study include standard deviations, which serve as a measure of confidence intervals for the results. These standard deviations are provided for accuracy, AUC, sensitivity, specificity, precision, F1-score, and execution time across different scenarios and models. For instance, in scenario II, the accuracy of the SVM classifier trained with deep features from ResNet-18 is reported as 92.5% with a standard deviation of 0.005, indicating the variability in the accuracy measurements.\n\nStatistical significance is implied through the use of 5-fold cross-validation, a robust method for validating the performance of the proposed MULTI-DEEP CAD system. This technique helps ensure that the results are not due to random chance and provides a more reliable estimate of the model's performance. The comparison of different scenarios and models, along with the reported standard deviations, suggests that the differences in performance are statistically significant. For example, ResNet-18 consistently shows higher performance metrics compared to other models, with lower standard deviations, indicating more stable and reliable results.\n\nThe use of standard deviations and cross-validation techniques enhances the confidence in the reported performance metrics. The results demonstrate that the proposed method is superior to individual models and baselines, as evidenced by the higher accuracy, AUC, sensitivity, specificity, precision, and F1-score achieved in various scenarios. The statistical rigor applied in the evaluation process supports the claim that the MULTI-DEEP CAD system is effective and reliable for detecting and classifying COVID-19 cases.",
  "evaluation/availability": "The raw evaluation files are not directly available. However, the data used for evaluation is accessible through the COVID-CT-Dataset, which can be found on GitHub. This dataset is publicly available and can be used for further research and validation of the MULTI-DEEP system. The specific link to access the dataset is provided in the publication. The dataset includes lung CT images that were used to train and test the models described in the study. Researchers and practitioners can utilize this dataset to replicate the experiments or conduct new analyses. The availability of this dataset ensures transparency and reproducibility of the results presented in the study."
}