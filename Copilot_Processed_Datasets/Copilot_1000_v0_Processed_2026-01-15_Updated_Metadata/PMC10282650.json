{
  "publication/title": "A machine learning-based prediction model pre-operatively for functional recovery after 1-year of hip fracture surgery in older people.",
  "publication/authors": "Lin C, Liang Z, Liu J, Sun W",
  "publication/journal": "Frontiers in surgery",
  "publication/year": "2023",
  "publication/pmid": "37351328",
  "publication/pmcid": "PMC10282650",
  "publication/doi": "10.3389/fsurg.2023.1160085",
  "publication/tags": "- Machine Learning\n- Prediction Model\n- Hip Fracture Surgery\n- Functional Recovery\n- Elderly Patients\n- Random Forest Algorithm\n- Preoperative Indicators\n- Postoperative Indicators\n- Surgical Indicators\n- Clinical Frailty Scale",
  "dataset/provenance": "The dataset used in this study was collected from patients admitted to the Orthopaedics and Oncology Department of a specific hospital between May 2019 and December 2019. Initially, data from 176 hip fracture patients were gathered, but after applying inclusion and exclusion criteria, 77 patients were included in the final analysis.\n\nThe inclusion criteria specified that patients had to be aged 65 years or older, diagnosed with a unilateral hip fracture (either intertrochanteric or femoral neck fracture), and treated surgically. The fractures had to be caused by low-energy injuries, and patients needed to have a complete medical history and provide informed consent. Mental illness that hindered follow-up was an exclusion criterion.\n\nExclusion criteria included patients with pathological fractures, fractures combined with other fractures in the same or opposite lower limb, disabilities, or other conditions leading to incomplete recovery of hip function. End-stage patients with severe postoperative complications and serious comorbidities who were unable to comply with prescribed rehabilitation exercises were also excluded. Additionally, patients who were lost to follow-up, refused to participate in the follow-up, or died during the study were excluded.\n\nThe dataset consists of various demographic and clinical characteristics, including 12 preoperative indicators, 8 surgical indicators, and 7 postoperative indicators. These characteristics were analyzed to develop a prediction model for the functional recovery of older individuals after 1-year hip fracture surgery. The study utilized machine learning models to identify key features that contribute to functional recovery, with the random forest model exhibiting the highest prediction performance.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The ratio used for this split was 7:3, meaning 70% of the data was allocated to the training set, and the remaining 30% was used for the test set. This division was done randomly to ensure that both sets were representative of the overall data.\n\nThe training set was used to develop and train the machine learning models, while the test set was used to evaluate the performance of these models. The specific number of data points in each split is not provided, but the ratio indicates that the training set contains a larger portion of the data, which is typical for model training and validation processes.",
  "dataset/redundancy": "The dataset was divided into a training set and a test set with a 7:3 ratio. This split ensures that the training and test sets are independent, which is crucial for evaluating the performance of the machine learning models. The random division helps to enforce independence by ensuring that the data points in the training set are not used to evaluate the model's performance on the test set.\n\nThe distribution of the dataset in this study is designed to be representative of the population under study, focusing on older individuals who have undergone hip fracture surgery. This approach aligns with previously published machine learning datasets that emphasize the importance of having a balanced and representative dataset for training and testing machine learning models. By ensuring a random and independent split, the study aims to provide a robust evaluation of the models' predictive capabilities.",
  "dataset/availability": "The data used in this study is not publicly available. The study involved a cohort of 77 older patients with hip fractures, and the data was collected from the Orthopaedics and Oncology Department of Shenzhen Second People\u2019s Hospital. The dataset includes various preoperative, surgical, and postoperative indicators that were analyzed to develop a prediction model for functional recovery.\n\nThe research protocol was approved by the Clinical Research Ethics Committee of Shenzhen Second People\u2019s Hospital, ensuring that the data collection and usage adhered to ethical standards. Informed consent was obtained from each patient, which is a crucial step in maintaining the privacy and rights of the participants.\n\nThe study does not mention the release of the dataset in a public forum. Therefore, the data splits used in the study are not publicly accessible. The predictive software developed based on the study's findings is available on Baidu Netdisk, but this does not include the raw data or the specific data splits used in the analysis.\n\nThe enforcement of data privacy and ethical standards was managed through the approval process by the hospital's ethics committee and the informed consent procedure. This ensures that the data was handled responsibly and that the participants' rights were protected throughout the study.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the Random Forest (RF) algorithm. This algorithm is not new; it has been established and widely used in various fields, including medical research. The Random Forest algorithm is an ensemble learning method that operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe decision to use the Random Forest algorithm was based on its proven effectiveness in handling complex datasets and its ability to provide robust predictions. Among the seven machine learning models tested, the Random Forest model demonstrated the highest performance in predicting functional recovery after hip fracture surgery in elderly patients.\n\nThe Random Forest algorithm was chosen for its strengths in managing high-dimensional data, reducing overfitting, and providing feature importance, which is crucial for interpreting the model's predictions. This algorithm has been extensively validated in the literature and is known for its reliability and accuracy in various predictive tasks.\n\nGiven that the Random Forest algorithm is well-established, it was not necessary to publish it in a machine-learning journal. Instead, our focus was on applying this algorithm to develop a predictive model specifically for functional recovery after hip fracture surgery, which is a novel application in the context of orthopedic surgery and geriatric care.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on a set of predefined features derived directly from patient data.\n\nSeveral machine-learning methods were evaluated to determine the best prediction model. These methods included logistic regression, k-nearest neighbors, support vector machine, Gaussian naive Bayes, decision tree, random forest, and Extreme Gradient Boosting. Among these, the random forest model demonstrated the highest performance.\n\nThe training data used for these models was collected from 176 elderly hip fracture patients, with 77 patients included after applying exclusion criteria. This data was randomly allocated into a training set (70%) and a test set (30%) for internal validation. The Lasso method was employed to screen prognostic variables, ensuring that the features used were relevant and non-redundant.\n\nThe independence of the training data is maintained through the random allocation process, which ensures that the training and test sets are distinct and do not overlap. This approach helps in validating the model's performance and generalizability.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithms. We began by collecting data from 176 elderly hip fracture patients, focusing on 26 factors that included preoperative, surgical, and postoperative indicators. To handle missing values, we employed imputation techniques, filling in gaps with appropriate statistical measures to maintain data integrity.\n\nCategorical variables, such as marital status and rehabilitation compliance, were encoded using one-hot encoding. This method converts categorical data into a binary matrix, allowing the machine-learning models to interpret these variables effectively. For continuous variables like the age-adjusted Charlson comorbidity score (aCCI) and the clinical frailty scale (CFS), we performed normalization to standardize the range of values, ensuring that no single feature dominated the model due to its scale.\n\nFeature selection was conducted using the Lasso regression method, which helped in identifying the most significant prognostic variables. This process involved generating a coefficient profile plot based on the logarithmic sequence of lambda and plotting the binomial deviance curve against the logarithm of lambda. The 1 standard error criterion was used to select the optimal lambda value, thereby retaining the most relevant features for model training.\n\nThe selected features were then used to train various machine-learning models, including logistic regression, k-nearest neighbors, support vector machine, Gaussian naive Bayes, decision tree, random forest, and Extreme Gradient Boosting. Each model was evaluated using metrics such as AUC, accuracy, sensitivity, specificity, positive predictive value, negative predictive value, F1-score, and Matthews correlation coefficient. The random forest model ultimately demonstrated the highest performance, achieving the best prediction accuracy for functional recovery after hip fracture surgery.",
  "optimization/parameters": "In our study, we utilized four key features to develop our prediction model. These features were selected through a process involving Lasso regression, which helped identify the most significant variables from a larger set of preoperative, surgical, and postoperative indicators.\n\nThe four crucial features that were ultimately chosen for the model are marital status, age-adjusted Charlson comorbidity score (aCCI), clinical frailty scale (CFS), and postoperative rehabilitation compliance. These variables were determined to have the most substantial impact on predicting functional recovery in older patients who had undergone hip fracture surgery.\n\nThe selection of these features was based on their ability to provide the most relevant and non-redundant information for the prediction task. By focusing on these four parameters, we aimed to create a robust and efficient model that could accurately predict the likelihood of good functional recovery.",
  "optimization/features": "In the optimization process of our study, we initially considered a comprehensive set of features to predict functional recovery after hip fracture surgery. These features encompassed preoperative, surgical, and postoperative indicators, totaling 27 features. To enhance the predictive power and simplicity of our model, we employed Lasso regression for feature selection. This technique helped us identify the most relevant variables by penalizing less important features, effectively reducing the dimensionality of our dataset.\n\nThe feature selection process was conducted using the training set only, ensuring that the test set remained independent and unbiased. This approach is crucial for validating the model's performance and generalizability. Through Lasso regression, we narrowed down the features to four crucial ones: marital status, age-adjusted Charlson comorbidity score (aCCI), clinical frailty scale (CFS), and postoperative rehabilitation compliance. These selected features were then used as inputs for developing our prediction models.\n\nBy focusing on these key features, we aimed to create a more robust and interpretable model, balancing complexity and performance. This feature selection strategy not only improved the model's efficiency but also provided insights into the most significant factors influencing functional recovery in older patients with hip fractures.",
  "optimization/fitting": "The study employed several machine learning models to predict functional recovery after hip fracture surgery, including logistic regression, k-nearest neighbors, support vector machine, Gaussian naive Bayes, decision tree, random forest, and Extreme Gradient Boosting. The dataset consisted of 77 older patients, with 21 experiencing poor functional recovery. This relatively small sample size could potentially lead to overfitting, especially with complex models.\n\nTo mitigate overfitting, the dataset was randomly split into a training set and a test set with a 7:3 ratio. This division ensured that the model's performance could be evaluated on unseen data, providing a more reliable estimate of its generalization capability. Additionally, the recursive feature elimination algorithm based on SHAP values was used to identify the most important features, reducing the risk of overfitting by focusing on the most relevant predictors.\n\nThe random forest model, which exhibited the highest prediction performance, inherently includes mechanisms to prevent overfitting. It does so by averaging multiple decision trees, each trained on a different subset of the data, and by using a random selection of features at each split. This ensemble approach helps to reduce variance and improve the model's robustness.\n\nTo rule out underfitting, various models were compared, and the one with the highest AUC value was selected. The random forest model achieved the highest AUC, indicating strong discriminative ability. Furthermore, calibration plots and decision curve analysis were performed to assess the model's performance comprehensively. These evaluations ensured that the model was neither too simple (underfitting) nor too complex (overfitting), striking a balance that optimized predictive accuracy.",
  "optimization/regularization": "In our study, we employed Lasso regression as a regularization method to prevent overfitting. This technique is particularly useful for variable selection and regularization to enhance the prediction accuracy and interpretability of the model. By applying Lasso regression, we were able to screen and identify the most relevant prognostic variables from a larger set of potential predictors. This process helped in reducing the complexity of the model and mitigating the risk of overfitting, especially when dealing with a relatively small sample size. The use of Lasso regression ensured that our final prediction model was more robust and generalizable to new, unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not entirely a black box. While it leverages complex machine learning algorithms, efforts have been made to enhance its interpretability. The random forest (RF) model, which demonstrated the highest performance, provides insights into the importance of predictor variables. This allows for an understanding of which factors significantly influence the prediction of functional recovery.\n\nTo interpret the model's predictions, SHAP (SHapley Additive exPlanations) values were used. These values help in ranking the variables based on their impact on the model's output. For instance, variables such as marital status, age-adjusted Charlson comorbidity index (aCCI), and clinical frailty scale (CFS) were identified as key predictors. The SHAP value summary graph visually represents how these variables contribute to the prediction, making it easier to understand their individual and combined effects.\n\nAdditionally, the decision tree component within the random forest model offers a clear, rule-based structure. This structure can be translated into if-else-then statements, providing a transparent view of the decision-making process. For example, the model might indicate that patients who are widowed or divorced, have high aCCI and CFS scores, and exhibit negative rehabilitation compliance are at a higher risk of poor functional recovery.\n\nFurthermore, the calibration curve and decision curve analysis (DCA) provide additional layers of interpretability. These tools help in assessing the model's reliability and the net benefit of using the model for clinical decision-making. The calibration curve shows how well the predicted probabilities match the actual outcomes, while the DCA evaluates the model's clinical utility by comparing it against other strategies, such as treating all patients or treating none.\n\nIn summary, while the random forest model is complex, it is not a black box. The use of SHAP values, decision trees, calibration curves, and decision curve analysis enhances the model's transparency, allowing healthcare providers to understand and trust the predictions made by the model.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the probability of good functional recovery, which is a binary outcome. The model uses machine learning algorithms to classify patients into categories based on their likelihood of achieving good functional recovery post-surgery. Various evaluation metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), F1-score, and Matthews correlation coefficient (MCC) were used to assess the performance of the model. The random forest (RF) model, in particular, demonstrated the highest performance among the seven models tested, indicating its effectiveness in classifying patients accurately.\n\nThe output of the model is a probability score that indicates the likelihood of a patient achieving good functional recovery. This probability can be used by healthcare providers to make informed decisions about patient care, including early interventions and tailored rehabilitation programs. The model's predictions are based on four key features: marital status, age-adjusted Charlson comorbidity score (aCCI), clinical frailty scale (CFS), and rehabilitation compliance. These features were identified as significant risk and protective factors for functional recovery.\n\nThe predictive software developed from this model is available for use, enabling healthcare providers to input patient data and receive probability scores for good functional recovery. This tool can facilitate better communication with patients and their families about treatment options and associated risks, ultimately leading to more effective and personalized care.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The software developed based on the prediction model is available online. It is hosted on Baidu Netdisk, which can be accessed via the link https://pan.baidu.com/s/16Iq93rxvu8fh5PTgYsqZNw. The access code to download the software is \"ea6z\". This software allows users to predict the probability of good functional recovery using the four key features identified in the study: marital status, age-adjusted Charlson comorbidity score, clinical frailty scale, and postoperative rehabilitation compliance. The software is designed to be user-friendly, enabling healthcare providers, families, and caregivers to make informed clinical decisions promptly. However, the specific licensing details for the software are not provided.",
  "evaluation/method": "The evaluation of the models involved several key indicators to assess their performance. These indicators included the area under the curve (AUC), accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), F1-score, and Matthews correlation coefficient (MCC). These metrics were used to evaluate the models on internal validation sets using four specific features.\n\nThe random forest (RF) model demonstrated the highest values in AUC, specificity, and PPV. Additionally, calibration curve plotting and decision curve analysis (DCA) were conducted to further evaluate the models. These analyses provided a visual and quantitative comparison of the models' performance, including logistic regression (Logit), k-nearest neighbors (KNN), support vector machine (SVM), Gaussian naive Bayes (GNB), decision tree (DT), and Extreme Gradient Boosting (XGB).\n\nThe final model selected was the one with the highest AUC value, indicating its superior discriminative ability in predicting functional recovery after one year of hip fracture surgery. The importance of the feature variables was assessed using the recursive feature elimination algorithm based on SHAP values, which helped in understanding the contribution of each variable to the model's predictions.",
  "evaluation/measure": "In our study, we evaluated the performance of various machine learning models using a comprehensive set of metrics to ensure a thorough assessment. The metrics reported include the Area Under the Curve (AUC), accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), F1-score, and Matthews correlation coefficient (MCC). These metrics provide a holistic view of the models' performance, covering aspects such as the models' ability to discriminate between classes (AUC), overall correctness (accuracy), true positive rate (sensitivity), true negative rate (specificity), precision (PPV), and the balance between precision and recall (F1-score). The MCC offers a measure of the quality of binary classifications, considering all elements of the confusion matrix.\n\nThe choice of these metrics is representative of standard practices in the literature, ensuring that our evaluation is both rigorous and comparable to other studies in the field. By including a diverse set of performance measures, we aim to provide a clear and comprehensive understanding of each model's strengths and weaknesses. This approach allows for a more informed selection of the most suitable model for predicting good functional recovery in patients with hip fractures.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of various machine learning models to evaluate their performance in predicting functional recovery. We tested seven different models: logistic regression, k-nearest neighbors, support vector machine, Gaussian naive Bayes, decision tree, random forest, and Extreme Gradient Boosting. Each model was assessed using several evaluation metrics, including AUC, accuracy, sensitivity, specificity, positive predictive value, negative predictive value, F1-score, and Matthews correlation coefficient.\n\nThe random forest model demonstrated the highest performance across multiple metrics, particularly in AUC, specificity, and positive predictive value. This model was chosen for its robustness and ability to handle complex feature spaces without requiring extensive manual feature engineering.\n\nTo simplify the comparison, we plotted calibration curves and performed decision curve analysis for all models. These visualizations provided insights into how well each model's predicted probabilities aligned with the actual outcomes and helped in assessing the clinical utility of the models.\n\nAdditionally, we developed a predictive software based on the four key features identified in our study. This software is designed to predict the probability of good functional recovery and is available for public use. The software's development underscores our commitment to making the predictive model accessible for practical applications in clinical settings.\n\nIn summary, our evaluation involved a thorough comparison of multiple machine learning models, with a focus on identifying the most effective approach for predicting functional recovery. The random forest model emerged as the top performer, and its integration into a user-friendly software tool highlights the practical implications of our findings.",
  "evaluation/confidence": "The evaluation of the models in this study includes several key performance metrics such as AUC, accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), F1-score, and Matthews correlation coefficient (MCC). These metrics were calculated for various models, including logistic regression, k-nearest neighbors, support vector machine, Gaussian naive Bayes, decision tree, random forest, and Extreme Gradient Boosting.\n\nThe random forest model demonstrated the highest values in AUC, specificity, and PPV, indicating its superior performance in these areas. The evaluation also involved calibration curve plotting and decision curve analysis to further assess the models' performance.\n\nStatistical significance is indicated for certain values, as seen in the provided tables. For instance, the P-value for some conditions is highlighted in bold, signifying statistical significance. This suggests that the differences observed in the performance metrics are not due to random chance.\n\nHowever, specific confidence intervals for the performance metrics are not explicitly mentioned. This omission might limit the ability to fully assess the precision of the estimates. While the random forest model shows promising results, the lack of confidence intervals means that the variability and reliability of these estimates are not fully quantified.\n\nIn summary, while the study provides a comprehensive evaluation of various models using multiple performance metrics and indicates statistical significance for some results, the absence of confidence intervals for the performance metrics is a notable gap. This makes it challenging to definitively claim the superiority of one method over others without additional statistical context.",
  "evaluation/availability": "The predictive software developed in this study is publicly available on Baidu Netdisk. The link to access the software is provided, along with a password for entry. This software is based on four key features identified through Lasso regression and is designed to predict the probability of good functional recovery in patients who have undergone hip fracture surgery. The software can be accessed using the following details:\n\n* Link: [Baidu Netdisk](https://pan.baidu.com/s/16Iq93rxvu8fh5PTgYsqZNw)\n* Password: ea6z\n\nThis availability allows other researchers and healthcare professionals to utilize the predictive model for their own studies or clinical practices. The software is intended to aid in the assessment of functional recovery outcomes, thereby potentially improving patient care and rehabilitation strategies."
}