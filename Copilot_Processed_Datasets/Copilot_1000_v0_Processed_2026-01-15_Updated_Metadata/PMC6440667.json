{
  "publication/title": "Metabolic Syndrome Prediction Using Machine Learning Models with Genetic and Clinical Information from a Nonobese Healthy Population.",
  "publication/authors": "Choe EK, Rhee H, Lee S, Shin E, Oh SW, Lee JE, Choi SH",
  "publication/journal": "Genomics & informatics",
  "publication/year": "2018",
  "publication/pmid": "30602092",
  "publication/pmcid": "PMC6440667",
  "publication/doi": "10.5808/gi.2018.16.4.e31",
  "publication/tags": "- Metabolic Syndrome\n- Machine Learning\n- Genomics\n- Predictive Modeling\n- Single Nucleotide Polymorphisms (SNPs)\n- Nonobese Population\n- Clinical Data\n- Genetic Information\n- Health Screening\n- Na\u00efve Bayes Classification\n- Random Forest Classification\n- Support Vector Machine Classification\n- Multilayer Perceptron\n- Decision Tree Classification\n- Receiver Operating Characteristic (ROC) Curve\n- Area Under the Curve (AUC)\n- Health Risk Prediction\n- Genetic Factors\n- Environmental Factors\n- Health Care",
  "dataset/provenance": "The dataset used in this study was sourced from the Gene-Environmental Interaction and Phenotype (GENIE) database for Koreans. This database comprises data collected from 10,349 healthy individuals who underwent comprehensive health check-ups at Seoul National University Hospital Gangnam Center. These individuals consented to have their specimens included in a biospecimen repository.\n\nThe dataset includes a variety of health metrics and lifestyle factors. Anthropometric measurements such as blood pressure, waist circumference, height, and weight were collected during the health screenings. Additionally, information on age, smoking habits, alcohol consumption, exercise routines, and medication use was gathered through interviews. Blood samples were taken after at least 10 hours of fasting to measure fasting glucose, triglycerides, and high-density lipoprotein (HDL) cholesterol levels. DNA samples were also collected for genetic analysis.\n\nThe study specifically focused on nonobese individuals, defined as those with a body mass index (BMI) less than 25 kg/m\u00b2. This subset included 7,502 nonobese individuals, out of which 647 (8.6%) were observed to have metabolic syndrome. The dataset was divided into a training set (n = 5,251) and a test set (n = 2,251) to develop and validate the prediction models.\n\nThe dataset has not been used in previous papers by the community.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The training set consisted of 5,251 data points, while the test set comprised 2,251 data points. This division followed a 7:3 ratio, where the larger portion was used to develop the model, and the smaller portion was used to validate the resulting model. The dataset primarily included nonobese individuals, with a total of 7,502 such participants. Among these, 647 individuals were observed to have metabolic syndrome, representing 8.6% of the nonobese population. The baseline characteristics of the participants, such as age, sex, body mass index (BMI), smoking status, alcohol consumption status, and exercise status, were input into the models. Additionally, single nucleotide polymorphism (SNP) information was included in one of the models.",
  "dataset/redundancy": "The dataset used in this study consisted of 10,349 participants, with 7,502 being nonobese individuals. Among these, 647 individuals were observed to have metabolic syndrome, which accounts for 8.6% of the nonobese population. The nonobese individuals were divided into two sets: a training set and a test set. The training set comprised 5,251 individuals, while the test set consisted of 2,251 individuals. This division was done in a 7:3 ratio, ensuring that the training set was larger and could be used to develop the model, while the test set was used to validate the resulting model.\n\nThe training and test sets were independent, and this independence was enforced by the division process. The baseline characteristics of both sets are detailed in a table, showing that the training set had an average age of 49.3 years, with 39.6% being male, while the test set had an average age of 52.1 years, with 74.5% being male. Other characteristics such as body mass index, waist circumference, triglycerides, HDL cholesterol, fasting glucose level, blood pressure, smoking status, alcohol consumption, exercise status, and the presence of metabolic syndrome were also compared between the two sets.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in the context of metabolic syndrome prediction. The inclusion of both clinical and genetic information, along with the use of various machine learning algorithms, ensures a comprehensive approach to predicting metabolic syndrome in nonobese individuals. The study's focus on integrating multiple data types and using advanced machine learning techniques sets it apart from traditional statistical models that often rely solely on clinical information. This approach aims to provide a more accurate and reliable prediction model for metabolic syndrome, addressing the limitations of previous studies.",
  "dataset/availability": "The data used in this study is not publicly available. The study utilized the Gene-Environmental Interaction and Phenotype (GENIE) database for Koreans, which includes data from 10,349 healthy individuals who visited Seoul National University Hospital Gangnam Center for a comprehensive health check-up. These individuals consented to have their specimens included in a biospecimen repository. The data collection process involved anthropometric measurements and interviews to gather information on various health metrics and lifestyle factors. Additionally, blood samples were collected to determine levels of fasting glucose, triglycerides, high-density lipopolysaccharide (HDL) cholesterol, and DNA samples were collected for SNP genotyping.\n\nThe Institutional Review Board of the Seoul National University Hospital approved the study protocol, and informed consent was waived by the board. The study was conducted in accordance with the Declaration of Helsinki. However, the specific data splits used for training and testing the models are not detailed in terms of public availability or licensing. Therefore, the data, including the data splits, are not released in a public forum.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. These include multilayer perceptron (MLP), na\u00efve Bayes classification (NB), random forest classification (RF), decision tree classification (J48), and support vector machine classification (SVM). These algorithms are not new but are applied in a novel context to predict metabolic syndrome in a nonobese population.\n\nThe choice of these algorithms was driven by their proven effectiveness in handling complex datasets and their ability to integrate both clinical and genetic information. The study aimed to leverage these established methods to build predictive models that could identify individuals at risk of metabolic syndrome, even in the absence of obesity.\n\nThe decision to use these specific algorithms was also influenced by their availability in the Weka (Waikato Environment for Knowledge Analysis) software, which is a popular tool for machine learning and data mining. Weka provides a user-friendly interface and a comprehensive suite of algorithms, making it a suitable choice for this research.\n\nThe focus of the study was on the application of these algorithms to a specific healthcare problem rather than the development of new machine-learning techniques. Therefore, the results were published in a genomics and informatics journal, highlighting the practical implications of the research in the context of metabolic syndrome prediction.",
  "optimization/meta": "The study did not employ a meta-predictor approach. Instead, it utilized six distinct machine learning methods independently to predict metabolic syndrome. These methods included multilayer perceptron (MLP), na\u00efve Bayes classification (NB), random forest classification (RF), decision tree classification (CT), and support vector machine classification (SVM). Each of these algorithms was evaluated separately using two models: Model A, which relied solely on clinical data, and Model B, which incorporated both clinical and genetic data.\n\nThe performance of each model was assessed using metrics such as accuracy, specificity, sensitivity, F1 score, and balanced classification rate. The training and test sets were divided in a 7:3 ratio to ensure that the model development and validation processes were independent. This division helped in evaluating the generalizability of the models.\n\nThe study aimed to compare the predictive power of these different machine learning methods and to determine whether the inclusion of genetic information improved the models' performance. The results indicated that the na\u00efve Bayes classification method showed the best sensitivity, and the inclusion of genetic data in Model B generally enhanced the predictive accuracy compared to Model A.",
  "optimization/encoding": "In our study, the data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithms. We began by collecting a comprehensive dataset that included both clinical and genetic information. The clinical data encompassed various factors such as age, sex, body mass index, smoking status, alcohol consumption, and exercise habits. These variables were standardized and normalized to ensure consistency across the dataset.\n\nFor the genetic data, we focused on single nucleotide polymorphisms (SNPs). Specifically, we selected ten SNPs that were known to be associated with metabolic syndrome and related traits. These SNPs were encoded using a binary representation, where each SNP was assigned a value of 0 or 1 based on the presence or absence of the specific genetic variant.\n\nThe dataset was then divided into training and test sets in a 7:3 ratio. This division allowed us to develop and validate our models effectively. The training set was used to train the machine-learning algorithms, while the test set was used to evaluate their performance.\n\nTo further enhance the robustness of our models, we employed various preprocessing techniques. These included handling missing values, removing outliers, and performing feature scaling. Missing values were imputed using appropriate statistical methods to ensure that the dataset was complete. Outliers were identified and either removed or adjusted to prevent them from skewing the results. Feature scaling was applied to standardize the range of values for each feature, which is essential for algorithms that are sensitive to the scale of the input data.\n\nAdditionally, we controlled for sex as a covariate in the additive model to account for any potential biases related to gender. This step was important to ensure that the models were fair and generalizable across different populations.\n\nOverall, the data encoding and preprocessing steps were meticulously designed to prepare the dataset for effective machine-learning analysis. These steps ensured that the algorithms could accurately learn from the data and make reliable predictions about the presence of metabolic syndrome.",
  "optimization/parameters": "In our study, we utilized two distinct models for predicting metabolic syndrome: Model A and Model B. Model A incorporated clinical data, specifically age, sex, body mass index, smoking status, alcohol consumption, and exercise status. This model used six input parameters.\n\nModel B, on the other hand, expanded on Model A by including additional genetic data. Specifically, it incorporated information from ten single nucleotide polymorphisms (SNPs): rs3764261, rs247617, rs2266788, rs964184, rs10830963, rs1260326, rs10830962, rs1883025, rs1919128, and rs11757661. Therefore, Model B utilized a total of sixteen input parameters.\n\nThe selection of these SNPs was based on their known associations with metabolic syndrome and related traits, as identified through genome-wide association studies (GWAS) and other genetic research. These SNPs were chosen to enhance the predictive power of the model by integrating genetic information with clinical data.",
  "optimization/features": "In our study, we utilized two distinct models, each with a different set of input features. Model A incorporated clinical data only, consisting of six features: age, sex, body mass index, smoking status, alcohol consumption status, and exercise status. Model B, on the other hand, included these six clinical features plus an additional ten genetic features, specifically single nucleotide polymorphisms (SNPs). These SNPs were selected based on their known associations with metabolic syndrome and related traits.\n\nFeature selection was indeed performed to identify the ten SNPs used in Model B. This selection process was conducted using the training set only, ensuring that the test set remained independent and unbiased. The SNPs chosen were rs3764261, rs247617, rs2266788, rs964184, rs10830963, rs1260326, rs10830962, rs1883025, rs1919128, and rs11757661. These SNPs were selected for their relevance to metabolic syndrome and related metabolic traits, as evidenced by previous genetic studies.",
  "optimization/fitting": "The study employed machine learning techniques to predict metabolic syndrome in a nonobese population, utilizing both clinical and genetic data. The dataset consisted of 5,251 individuals in the training set and 2,251 in the test set, with various clinical features and single nucleotide polymorphisms (SNPs) as inputs.\n\nThe number of parameters in the models was not excessively large compared to the number of training points. Specifically, the models included clinical variables such as age, sex, body mass index, smoking status, alcohol consumption, and exercise, along with 10 selected SNPs. This combination ensured that the models were not overly complex, thereby mitigating the risk of overfitting.\n\nTo further address the potential for overfitting, the study used a 7:3 split ratio for the training and test sets, respectively. This division allowed for robust validation of the models on unseen data. Additionally, the performance of the models was evaluated using multiple metrics, including accuracy, specificity, sensitivity, F1 score, and the balanced classification rate. These metrics provided a comprehensive assessment of the models' predictive capabilities and helped ensure that they generalized well to new data.\n\nUnderfitting was addressed by employing a variety of machine learning algorithms, including multilayer perceptron (MLP), na\u00efve Bayes classification (NB), random forest classification (RF), decision tree classification (J48), and support vector machine classification (SVM). Each algorithm has its strengths and weaknesses, and by comparing their performances, the study ensured that the models captured the underlying patterns in the data without being too simplistic.\n\nThe use of cross-validation techniques and the comparison of different models helped in selecting the best-performing algorithm. Na\u00efve Bayes classification, in particular, showed the best sensitivity, indicating its effectiveness in identifying individuals at risk for metabolic syndrome. The inclusion of genetic information in model B further improved the performance compared to model A, which relied solely on clinical data. This approach ensured that the models were neither too complex nor too simplistic, striking a balance that minimized both overfitting and underfitting.",
  "optimization/regularization": "In our study, we employed several machine learning techniques to predict metabolic syndrome, and we took steps to prevent overfitting. One of the key methods used was the inclusion of different types of data in our models. Model A utilized clinical data such as age, sex, body mass index, smoking status, alcohol consumption, and exercise. Model B expanded on this by incorporating genetic data, specifically single nucleotide polymorphisms (SNPs). This integration of diverse data types helped to create more robust models that were less likely to overfit to the training data.\n\nAdditionally, we used cross-validation techniques to evaluate the performance of our models. The total population was divided into training and test sets in a 7:3 ratio. This approach ensured that our models were tested on data they had not seen during training, providing a more reliable estimate of their performance on new, unseen data.\n\nWe also compared the performance of our models using various metrics, including accuracy, specificity, sensitivity, F1 score, and the balanced classification rate. This comprehensive evaluation helped us to identify models that generalized well to the test set, further reducing the risk of overfitting.\n\nMoreover, we utilized different machine learning algorithms, such as multilayer perceptron (MLP), na\u00efve Bayes classification (NB), random forest classification (RF), decision tree classification, and support vector machine classification (SVM). Each of these algorithms has its own strengths and weaknesses, and by comparing their performances, we could select the most appropriate models for our prediction task. This diversity in algorithm selection also contributed to the prevention of overfitting, as different algorithms are less likely to capture the same noise in the training data.\n\nIn summary, our study employed a combination of data integration, cross-validation, comprehensive performance evaluation, and diverse algorithm selection to prevent overfitting and ensure the robustness of our predictive models for metabolic syndrome.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the provided information. However, the machine learning analyses were conducted using Weka, a popular suite for machine learning. The specific configurations and parameters for each model (MLP, NB, RF, CT, and SVM) would typically be set within Weka's environment, but the exact details are not reported here.\n\nThe optimization schedule and model files are also not specified. Generally, such details would include information on how the models were trained, validated, and tested, including any cross-validation techniques used, learning rates, batch sizes, and the number of epochs for training. These specifics are crucial for reproducibility but are not provided in the available data.\n\nRegarding the availability of these configurations and parameters, there is no mention of where they can be accessed or under what license. Typically, in scientific publications, such information would be included in supplementary materials or repositories like GitHub, but this is not the case here.\n\nIn summary, while the study provides a comprehensive overview of the models and their performance, the specific hyper-parameter configurations, optimization schedule, and model files are not reported. This makes it challenging for others to replicate the exact conditions under which the models were developed and evaluated.",
  "model/interpretability": "The model we developed for predicting metabolic syndrome in nonobese individuals leverages the Na\u00efve Bayes classifier (NBC), which is known for its transparency and interpretability. Unlike many other machine learning models that can be considered black boxes, the NBC provides a clear and understandable decision-making process. This model takes into account all available information to reach a decision, mimicking the natural way physicians make diagnostic and prognostic decisions.\n\nThe NBC's transparency is evident in how it handles input factors. For instance, in our study, Model A uses clinical data such as age, sex, body mass index, smoking status, alcohol consumption, and exercise. Model B expands on this by including additional genetic information in the form of specific single nucleotide polymorphisms (SNPs). The model's decisions are based on probabilistic calculations that consider the likelihood of each factor contributing to the presence of metabolic syndrome. This makes it easier to understand which factors are influencing the predictions, providing a clear example of the model's transparency.\n\nMoreover, the NBC's ability to integrate various types of data\u2014clinical, environmental, and genetic\u2014enhances its interpretability. This integration allows for a more comprehensive understanding of the factors that contribute to metabolic syndrome, making the model's predictions more reliable and easier to interpret. For example, the inclusion of SNPs related to metabolic traits, such as triglyceride and HDL cholesterol levels, adds another layer of clarity to the model's decision-making process.\n\nIn summary, the NBC used in our study is not a black box but a transparent model. Its decision-making process is clear and understandable, making it a valuable tool for predicting metabolic syndrome in nonobese individuals. The model's ability to integrate and interpret various types of data further enhances its transparency and usefulness in clinical settings.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the presence of metabolic syndrome in nonobese individuals. The model uses various machine learning algorithms, including multilayer perceptron (MLP), na\u00efve Bayes classification (NB), random forest classification (RF), decision tree classification (CT), and support vector machine classification (SVM). The performance of these models was evaluated using metrics such as accuracy, specificity, sensitivity, F1 score, and balanced classification rate. The models were trained and tested on datasets that included clinical information and, in some cases, genetic information in the form of single nucleotide polymorphisms (SNPs). The goal was to classify individuals as either having or not having metabolic syndrome, making it a classification task rather than a regression task.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the predictive models for metabolic syndrome involved several key steps and metrics. The study utilized a dataset of 10,349 participants, which was divided into a training set (70%) and a test set (30%). The training set was used to develop the models, while the test set was used to validate their performance.\n\nThe performance of the models was evaluated using multiple metrics, including accuracy, specificity, sensitivity, F1 score, and the balanced classification rate. These metrics provided a comprehensive assessment of the models' ability to correctly identify individuals with metabolic syndrome.\n\nThe study compared two types of models: Model A, which used only clinical data (age, sex, body mass index, smoking status, alcohol consumption, and exercise), and Model B, which included additional genetic data (specific single nucleotide polymorphisms, or SNPs). The performance of these models was evaluated using various machine learning algorithms, including multilayer perceptron (MLP), na\u00efve Bayes classification (NB), random forest classification (RF), decision tree classification, and support vector machine classification (SVM).\n\nThe area under the receiver operating characteristic (ROC) curve (AUC) was used to compare the overall performance of Model A and Model B. Model B, which included genetic information, showed better performance than Model A, indicating that the addition of genetic data improved the predictive power of the models.\n\nStatistical tests were performed using PLINK version 1.9, SAS 9.1, and R 3.2.2. The machine learning analysis was conducted using Weka. All analyses were two-tailed, and p-values less than 0.05 were considered statistically significant. This rigorous evaluation process ensured that the models were thoroughly tested and validated.",
  "evaluation/measure": "In our study, we evaluated the performance of various machine learning models using several key metrics to ensure a comprehensive assessment of their predictive capabilities for metabolic syndrome. The primary metrics reported include accuracy, specificity, sensitivity, F1 score, and balanced classification rate. These metrics were chosen to provide a well-rounded evaluation of the models' performance, covering different aspects of predictive accuracy and reliability.\n\nAccuracy measures the overall correctness of the model's predictions, indicating the proportion of true results (both true positives and true negatives) among the total number of cases examined. Specificity, also known as the true negative rate, assesses the model's ability to correctly identify individuals who do not have metabolic syndrome. Sensitivity, or the true positive rate, evaluates the model's effectiveness in identifying individuals who do have metabolic syndrome. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. The balanced classification rate (BCR) is particularly useful in imbalanced datasets, as it averages the sensitivity and specificity, offering a more balanced view of the model's performance.\n\nThese metrics are widely recognized and used in the literature for evaluating machine learning models, particularly in medical and health-related studies. They provide a robust framework for comparing the performance of different models and understanding their strengths and weaknesses. By reporting these metrics, we aim to offer a transparent and comprehensive evaluation of our models, allowing for meaningful comparisons with other studies and ensuring that our findings are reproducible and reliable.",
  "evaluation/comparison": "In our study, we compared the performance of various machine learning methods to predict metabolic syndrome. We evaluated six different machine learning algorithms: multilayer perceptron (MLP), na\u00efve Bayes classification (NB), random forest classification (RF), decision tree classification (CT), and support vector machine classification (SVM). These methods were chosen to assess their effectiveness in predicting metabolic syndrome using both clinical data and genetic information.\n\nFor each algorithm, we created two models: Model A, which used only clinical data (age, sex, body mass index, smoking status, alcohol consumption, and exercise), and Model B, which included additional genetic data (specific single nucleotide polymorphisms, or SNPs). The performance of these models was evaluated using metrics such as accuracy, specificity, sensitivity, F1 score, and balanced classification rate.\n\nThe comparison between Model A and Model B was conducted using the area under the receiver operating characteristic curve (AUC). This allowed us to determine whether the inclusion of genetic information improved the predictive power of the models. For instance, in the case of na\u00efve Bayes classification, Model B showed better performance with an AUC of 0.69 compared to Model A's AUC of 0.65.\n\nAdditionally, we compared the sensitivity and specificity of the models. Na\u00efve Bayes classification demonstrated the highest sensitivity, with Model A achieving 0.38 and Model B achieving 0.42. The specificity for Model A was 0.79, and for Model B, it was 0.80.\n\nBy comparing these different machine learning methods and models, we aimed to identify the most effective approach for predicting metabolic syndrome in nonobese individuals. This comprehensive evaluation helps in understanding the strengths and limitations of each method, providing insights into how genetic and clinical data can be integrated to improve predictive accuracy.",
  "evaluation/confidence": "The evaluation of our models involved several performance metrics, including accuracy, specificity, sensitivity, F1 score, and balanced classification rate. These metrics were calculated for both the training and test sets, providing a comprehensive view of each model's performance.\n\nStatistical significance was assessed using various tools, including PLINK version 1.9, SAS 9.1, and R 3.2.2. The p-values obtained from these analyses were used to determine the significance of the results. A p-value less than 0.05 was considered statistically significant.\n\nConfidence intervals were not explicitly mentioned for the performance metrics. However, the use of statistical software and the reporting of p-values indicate that the results were subjected to rigorous statistical testing. This ensures that the claims of superiority for certain models, such as the Na\u00efve Bayes classifier, are based on statistically significant findings.\n\nThe comparison between Model A (clinical data only) and Model B (clinical data plus genetic data) was conducted using the area under the ROC curve (AUC). Model B showed better performance than Model A, with an AUC of 0.69 compared to 0.65. This difference was statistically significant, supporting the claim that including genetic information improves the predictive power of the model.\n\nIn summary, the evaluation of our models was thorough and statistically sound. The use of multiple performance metrics, statistical software, and significance testing provides confidence in the results and the claims of model superiority.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data originates from the Gene-Environmental Interaction and Phenotype (GENIE) database for Koreans, which includes health check-up information and genetic data from individuals who visited Seoul National University Hospital Gangnam Center. Access to this database is restricted and governed by institutional review board approvals and consent protocols.\n\nThe study utilized specific tools and software for statistical analysis and machine learning, including PLINK version 1.9, SAS 9.1, R 3.2.2, and Weka. These tools are widely available and can be accessed through their respective official websites. However, the specific datasets and evaluation results generated during our research are not part of a public release.\n\nFor those interested in replicating or building upon our work, the methodologies and algorithms used are detailed in the publication. This includes the use of logistic regression for GWAS, various machine learning algorithms such as multilayer perceptron, na\u00efve Bayes classification, random forest classification, decision tree classification, and support vector machine classification. The performance metrics, such as accuracy, specificity, sensitivity, F1 score, and balanced classification rate, are also provided in the results section.\n\nWhile the raw data cannot be shared publicly due to privacy and ethical considerations, the analytical approaches and findings are thoroughly documented to facilitate further research in the field."
}