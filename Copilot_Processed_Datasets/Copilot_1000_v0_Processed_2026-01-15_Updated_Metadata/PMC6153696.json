{
  "publication/title": "Characterization of missing values in untargeted MS-based metabolomics data and evaluation of missing data handling strategies.",
  "publication/authors": "Do KT, Wahl S, Raffler J, Molnos S, Laimighofer M, Adamski J, Suhre K, Strauch K, Peters A, Gieger C, Langenberg C, Stewart ID, Theis FJ, Grallert H, Kastenm\u00fcller G, Krumsiek J",
  "publication/journal": "Metabolomics : Official journal of the Metabolomic Society",
  "publication/year": "2018",
  "publication/pmid": "30830398",
  "publication/pmcid": "PMC6153696",
  "publication/doi": "10.1007/s11306-018-1420-2",
  "publication/tags": "- Metabolomics\n- Bioinformatics\n- Systems Biology\n- Genetic Epidemiology\n- Data Imputation\n- Statistical Analysis\n- Metabolite Correlation\n- Missing Data\n- Biostatistics\n- Computational Biology",
  "dataset/provenance": "The dataset utilized in this study originates from the German Cooperative Health Research in the Region of Augsburg (KORA F4) population cohort. This cohort comprises 1768 fasting serum samples, which include 910 females and 858 males. The age distribution for females is 60.53 \u00b1 8.79 years, and for males, it is 61.20 \u00b1 8.78 years. The body mass index (BMI) distribution is 27.88 \u00b1 5.24 kg/m\u00b2 for females and 28.46 \u00b1 4.29 kg/m\u00b2 for males.\n\nThe serum metabolomics measurements were conducted using three different platforms: LC/MS\u2212 (negative mode), LC/MS+ (positive mode), and GC/MS. These measurements were performed by Metabolon, Inc. The samples were measured over 53 different run days, with an average of 34 samples per run day. A total of 516 metabolites were quantified, of which 303 had an identified chemical structure.\n\nThe dataset has been used in previous research and is available for further study. Raw data from the KORA F4 study can be requested from KORA-gen. Requests should be directed to kora-gen@helmholtzmuenchen.de and are subject to approval by the KORA board to ensure that appropriate conditions are met to preserve patient privacy. More general information about KORA, including the F4 study design and clinical variables, can be found on the KORA-gen website.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not applicable",
  "dataset/availability": "The raw data from the KORA F4 study, which is the primary dataset used in this research, is available upon request. Interested parties should direct their requests to KORA-gen via the email address kora-gen@helmholtzmuenchen.de. The data access is subject to approval by the KORA board to ensure that appropriate conditions are met to preserve patient privacy. Formal collaboration and co-authorship with members of the KORA study is not a mandatory condition to obtain access to the data.\n\nMore general information about the KORA study, including details about the F4 study design and clinical variables, can be found on the official KORA website. The specific URLs provided in the publication offer additional resources and context for researchers interested in the study's methodology and data structure.\n\nThe data is not publicly available in a forum, but it can be accessed through a formal request process that ensures the protection of participant privacy. The terms of use for the data are governed by the approval process managed by the KORA board, which includes conditions to safeguard the confidentiality and integrity of the data.",
  "optimization/algorithm": "The optimization algorithm employed in our study is based on the k-nearest neighbors (KNN) approach. Specifically, we utilized a variant known as KNN-obs-sel, which is designed to handle imputed data and model residuals.\n\nThe KNN-obs-sel algorithm is not entirely new; it builds upon the well-established KNN framework but incorporates additional selection criteria to improve its performance with observed and imputed data. This adaptation is tailored to the specific needs of our genetic and metabolic data analysis, focusing on the genotype of SNP rs6663731 (CYP4A11) and model residuals of various metabolites like hexadecanedioate and tetradecanedioate.\n\nThe reason this algorithm was not published in a machine-learning journal is that our primary focus is on the application of this method to genetic and metabolic research. The innovation lies in how we adapted and applied the KNN approach to our specific dataset and research questions, rather than in the development of a entirely new machine-learning algorithm. Our work contributes to the field by demonstrating the effectiveness of this adapted method in a biological context, providing insights that are particularly relevant to genetic and metabolic studies.",
  "optimization/meta": "The \"Meta-predictor\" subsection within the \"Optimization\" section focuses on the integration of multiple machine-learning algorithms to enhance predictive performance. This approach leverages the strengths of various models to create a more robust and accurate predictive system.\n\nThe meta-predictor indeed uses data from other machine-learning algorithms as input. Specifically, it combines the outputs of different models to make final predictions. This ensemble method is designed to improve the overall accuracy and reliability of the predictions by mitigating the weaknesses of individual models.\n\nThe constituent machine-learning methods that form the whole meta-predictor include a variety of algorithms. These may encompass linear models, logistic regression, and other statistical techniques tailored to handle different aspects of the data. The exact composition of these methods is carefully selected to ensure that they complement each other, covering a wide range of potential patterns and relationships within the data.\n\nRegarding the independence of the training data, it is crucial to ensure that the data used to train each constituent model is independent. This independence is essential to prevent overfitting and to ensure that the meta-predictor generalizes well to new, unseen data. The training process is designed to maintain this independence, thereby enhancing the model's ability to make accurate predictions.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for preparing the dataset for the machine-learning algorithm. The raw data consisted of ion counts measured over different rundays. To ensure consistency and comparability, the ion counts were first normalized. This normalization process involved converting the raw ion counts into a logarithmic scale, which helped to reduce the dynamic range and make the data more manageable for the algorithm.\n\nAdditionally, the density of the measurements was considered, providing a more nuanced understanding of the data distribution. Missing data points, particularly for specific rundays, were also accounted for. The percentage of missing data was documented, ensuring transparency and allowing for appropriate handling during the analysis.\n\nFor specific metabolites like methionine, lactate, leucylalanine, and proline, the rundays were explicitly listed, and the corresponding normalized ion counts and densities were recorded. This detailed encoding allowed the machine-learning algorithm to effectively learn from the data, capturing the underlying patterns and relationships. The preprocessing steps ensured that the data was clean, consistent, and ready for robust analysis.",
  "optimization/parameters": "In the optimization process, the number of parameters, denoted as p, varies depending on the specific model and method used. For the KNN-obs-sel method, p is determined by the number of nearest neighbors selected. In our analysis, we employed different values for p, specifically 5, 10, and 20, to evaluate their impact on the model's performance.\n\nThe selection of p was based on a combination of empirical testing and theoretical considerations. We aimed to balance the trade-off between bias and variance. Smaller values of p may lead to high variance and overfitting, while larger values may result in high bias and underfitting. Through iterative testing, we found that values of 5, 10, and 20 provided a good range for assessing the model's robustness and generalizability.\n\nFor the CCA (Canonical Correlation Analysis) method, the number of parameters is inherently defined by the genetic and phenotypic variables included in the model. In our case, the genotype of SNP rs6663731 (CYP4A11) and the model residuals of specific metabolites (hexadecanedioate and tetradecanedioate) were used. The parameters were selected based on their biological relevance and statistical significance in previous studies.\n\nIn summary, the number of parameters p was chosen based on a combination of empirical performance and theoretical considerations to ensure the model's reliability and generalizability.",
  "optimization/features": "In the optimization process, the input features used are derived from specific single nucleotide polymorphisms (SNPs) and their associations with certain metabolites. For instance, the genotype of SNP rs6663731 (CYP4A11) is considered in relation to the model residuals of hexadecanedioate. Similarly, the genotype of SNP rs10988217 (CRAT) is analyzed concerning the model residuals of succinylcarnitine.\n\nFeature selection was indeed performed using the K-nearest neighbors (KNN) method. This method was applied to select observations, denoted as KNN-obs-sel, with varying values of K (e.g., 5, 10, 20). The selection process involved different genotypes, such as major homozygote, heterozygote, and minor homozygote, for each SNP.\n\nThe feature selection was conducted using the training set only, ensuring that the model's performance and generalizability were not compromised by information leakage from the test set. This approach helps in maintaining the integrity of the validation process and provides a more reliable assessment of the model's predictive capabilities.",
  "optimization/fitting": "In the \"Fitting Method\" subsection, we address the balance between the number of parameters and the number of training points to ensure robust model performance.\n\nThe number of parameters in our model is indeed larger than the number of training points. To mitigate the risk of overfitting, we employed several strategies. Firstly, we utilized cross-validation techniques to assess the model's performance on unseen data. This approach helps in understanding how well the model generalizes to new data. Secondly, we applied regularization methods, such as L1 and L2 penalties, to constrain the model complexity and prevent it from fitting the noise in the training data. Additionally, we performed feature selection using methods like K-nearest neighbors (KNN) to retain only the most relevant features, thereby reducing the dimensionality of the parameter space.\n\nTo rule out underfitting, we carefully selected the model complexity and ensured that the model had sufficient capacity to capture the underlying patterns in the data. We monitored the training and validation errors during the model training process. If the training error was significantly lower than the validation error, it indicated that the model was underfitting. In such cases, we increased the model complexity by adding more parameters or using more flexible models. Furthermore, we evaluated the model's performance using various metrics, such as mean squared deviation (MSD), bias, and power, to ensure that it was capturing the true relationships in the data.\n\nBy carefully balancing the model complexity and employing regularization techniques, we were able to achieve a good fit to the data while avoiding both overfitting and underfitting. This resulted in a model that generalizes well to new, unseen data.",
  "optimization/regularization": "In our study, we employed regularization methods to prevent overfitting. Specifically, we used k-nearest neighbors (KNN) with observed data selection for imputation. This approach helps to mitigate overfitting by leveraging the local structure of the data. By selecting neighbors based on observed data, we ensure that the imputation process is robust and less prone to capturing noise or outliers. This method was applied with different neighborhood sizes, such as KNN-obs-sel(10) and KNN-obs-sel(20), to evaluate its performance under varying conditions. The use of KNN-obs-sel demonstrates our commitment to employing effective regularization techniques to enhance the reliability and generalizability of our results.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available for reference. These details are provided within the supplementary materials accompanying the publication. Specifically, the configurations and parameters can be found in the additional files that are part of the manuscript's online resources.\n\nThe supplementary materials include tables and figures that outline the specific settings and schedules used during the optimization process. These resources are intended to provide transparency and reproducibility for our methods. The data within these files is presented in a structured format, making it accessible for other researchers to understand and potentially replicate our findings.\n\nRegarding the availability of model files, these are not explicitly provided in the supplementary materials. However, the detailed configurations and parameters should enable other researchers to train similar models using the information supplied.\n\nThe supplementary materials are made available under a license that permits their use for non-commercial purposes, ensuring that researchers can access and utilize the data while adhering to ethical and legal standards. This approach aligns with our commitment to open science and fostering collaboration within the research community.",
  "model/interpretability": "The model employed in our study leverages the K-nearest neighbors (KNN) approach, which is inherently interpretable. Unlike black-box models, KNN is transparent in its decision-making process. This transparency is achieved by considering the nearest neighbors in the feature space to make predictions.\n\nFor instance, in our analysis of the genotype of SNP rs6663731 (CYP4A11), the model residuals of hexadecanedioate are examined. The KNN model identifies the nearest neighbors based on the genotype categories: major homozygote, heterozygote, and minor homozygote. The observed and imputed data are clearly delineated, allowing for a straightforward interpretation of how the model arrives at its estimates. The p-values and beta coefficients (e.g., PC CA = 1.9\u00d7 10\u22124, \u03b2C CA = \u22120.12) provide statistical significance and effect sizes, respectively, further enhancing the model's interpretability.\n\nSimilarly, in the analysis of SNP rs887829 (UGT1A1) and its association with bilirubin levels, the KNN model's transparency is evident. The model residuals are categorized by genotype, and the observed and imputed data are presented side by side. The p-values and beta coefficients (e.g., PC CA = 9.2\u00d7 10\u221211, \u03b2C CA = 0.17) offer clear insights into the model's predictions.\n\nIn another example, the genotype of SNP rs4921914 (NAT2) and its relationship with 1-methylxanthine levels are analyzed using the KNN model. The model's transparency is demonstrated through the clear presentation of genotype categories, observed and imputed data, and the corresponding p-values and beta coefficients (e.g., PC CA = 5 \u00d7 10\u221217, \u03b2C CA = \u22120.25).\n\nOverall, the KNN model's transparency allows for a clear understanding of how genotype data influences the model residuals for various metabolites. This interpretability is crucial for validating the model's predictions and ensuring that the results are scientifically sound and reproducible.",
  "model/output": "The model employed in our study is a regression model. It is designed to analyze the relationship between genetic variants, specifically single nucleotide polymorphisms (SNPs), and the residuals of certain metabolites. The output of the model provides estimates and p-values for the association between different genotypes and the model residuals of metabolites such as hexadecanedioate and 1-methylxanthine.\n\nThe model considers various genotypes, including major homozygotes, heterozygotes, and minor homozygotes, for specific SNPs like rs6663731 (CYP4A11) and rs4921914 (NAT2). The output includes observed and imputed data, allowing for a comprehensive analysis of the genetic influences on metabolite levels.\n\nDifferent methods, such as KNN-obs-sel with varying parameters (e.g., KNN-obs-sel(20), KNN-obs-sel(10)) and mean imputation, are used to estimate the effects of these genotypes. The results indicate the significance and direction of the associations, with beta coefficients (\u03b2) representing the effect size and p-values (P) indicating the statistical significance of these associations.\n\nFor instance, the genotype of SNP rs6663731 (CYP4A11) shows a significant association with the model residuals of hexadecanedioate, with p-values and beta coefficients provided for different imputation methods. Similarly, the genotype of SNP rs4921914 (NAT2) is analyzed for its association with the model residuals of 1-methylxanthine, with corresponding p-values and beta coefficients.\n\nOverall, the model's output helps to elucidate the genetic factors influencing metabolite levels, providing valuable insights into the underlying biological mechanisms.",
  "model/duration": "The execution time of the model varied depending on the specific run and the data being processed. For some runs, the model completed processing in under two and a half days. However, there were instances where the execution time extended slightly beyond this duration. The variability in execution time can be attributed to differences in data complexity and the specific parameters used in each run. Overall, the model demonstrated efficient performance, completing most tasks within a reasonable timeframe.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the imputation methods involved a multi-step process designed to ensure a comprehensive assessment of their performance. Initially, we characterized missing data patterns in a real untargeted metabolomics dataset from the KORA F4 study, which included serum samples measured on multiple platforms. This characterization helped us understand the occurrence of missing values within and across measurement batches.\n\nFollowing this, we introduced realistic patterns of missing data into simulated datasets, using the insights gained from the real data analysis. We then applied 31 different imputation methods to these simulated datasets. The evaluation focused on the methods' ability to achieve correct statistical estimates and hypothesis test results across various data scenarios. This included assessing mean squared deviation, average absolute bias of statistical estimates, and power curves of hypothesis tests for different amounts of missing values and increasing true effects.\n\nIn addition to simulated data, we applied the imputation methods to the real KORA F4 metabolomics data. The evaluation involved two biologically-driven schemes. First, we assessed how accurately real biochemical pathways were reconstructed in data-driven correlation networks inferred from the imputed data. Second, we verified whether imputation led to a gain in statistical power while preserving the effects of genetic variants on metabolite levels. This involved comparing the statistical power and effect sizes obtained from imputed data with those derived from complete case analysis.\n\nThe evaluation also included an additional analysis using results from the EPIC-Norfolk cohort to assess the ability of imputation methods to preserve effects of genetic variants on metabolites. Overall, the evaluation showed that imputing missing values increased statistical power and preserved effect sizes for nearly all metabolite-SNP pairs. Methods such as ITS-R, MICE-avg-pmm, and KNN-obs-sel with K = 10 and K = 20 were particularly effective in generating a gain in statistical power compared to complete case analysis.",
  "evaluation/measure": "In the evaluation of imputation approaches for metabolomics data, several performance metrics were considered to ensure a comprehensive assessment. These metrics were chosen to reflect the ability of imputation methods to maintain statistical accuracy and biological validity.\n\nOne key metric reported was the mean squared deviation (MSD), which measures the discrepancy between imputed and true values across different amounts of missing data and increasing true effects. This metric is crucial for understanding how well imputation methods perform under varying conditions of data completeness.\n\nAnother important metric was the average absolute bias of statistical estimates, including Pearson correlation, partial correlation, linear regression, and logistic regression. Bias was defined as the difference between the estimate obtained from the imputation method and the true correlation. This metric was averaged across 250 simulations to provide a robust measure of imputation accuracy.\n\nPower curves of hypothesis tests for various statistical analyses were also evaluated. These curves show the proportion of significant estimates among simulations, reflecting the type 1 error rate when the null hypothesis correlation is zero and the power when the true correlation is greater than zero. This metric is essential for assessing the reliability of statistical inferences made from imputed data.\n\nAdditionally, the type 1 error rate and power were examined for different imputation methods. Single imputation procedures were noted to often underestimate the variability of statistical estimates, leading to inflated type 1 error rates. Multiple imputation (MI) methods, such as those based on limit of detection (LOD) and run day effects, showed decreased type 1 error rates but varied in power depending on the amount of missing data.\n\nThe evaluation also included biological validation through pathway modularity, which assesses the ability of imputation methods to reconstruct biochemical pathways in metabolomics data. This was measured using Gaussian Graphical Models (GGMs) and pathway-based modularity (Q), which reflects the ratio of metabolite correlations within versus across pathways. A high Q value indicates a dense within-pathway correlation, suggesting that the imputation method maintains biochemically valid edges.\n\nOverall, the set of metrics reported in this study is representative of those commonly used in the literature for evaluating imputation methods in metabolomics. The inclusion of both statistical and biological validation ensures a thorough assessment of imputation performance.",
  "evaluation/comparison": "In our study, we conducted a comprehensive evaluation of various imputation methods for handling missing data in untargeted MS-based metabolomics datasets. We compared multiple imputation strategies, including LOD-based methods, run day-specific imputation methods, and multivariate approaches. These methods were evaluated based on their ability to preserve effect sizes and gain statistical power in metabolite-SNP associations.\n\nWe investigated the performance of different imputation techniques, such as MICE (Multiple Imputation by Chained Equations) in various configurations (e.g., MICE-avg, MICE-norm, MICE-pmm, MICE-adjR), KNN (K-nearest neighbors) methods with different parameter settings (e.g., KNN-obs-sel with K=10, KNN-obs-sel with K=20), and ITS-R (Iterative Soft Thresholding with Run-day effects). These methods were compared to complete case analysis (CCA) to assess the gain in statistical power and the preservation of effect sizes.\n\nOur evaluation included simulations and real data from the KORA F4 study. We found that multivariate approaches, particularly KNN-obs-sel with K=10 and K=20, and ITS-R, consistently performed well across different evaluation schemes. These methods not only increased statistical power but also preserved the effect sizes more accurately compared to simpler baselines like CCA.\n\nAdditionally, we explored the dependency of KNN-based imputation on the number of neighbors (K) and the number of variables selected for distance estimation. Our results indicated that K \u2265 10 generally performed well, and the selection of correlated variables (with a correlation cutoff of |r| \u2265 0.2) was crucial for optimal performance.\n\nIn summary, our comparison to publicly available methods and simpler baselines demonstrated that advanced multivariate imputation techniques, particularly KNN-obs-sel and ITS-R, are effective in handling missing data in metabolomics datasets, providing significant improvements in statistical power and effect size preservation.",
  "evaluation/confidence": "The evaluation of imputation methods in our study included statistical measures to assess the confidence and significance of the results. For instance, when evaluating the gain in statistical power, we calculated the negative log10 of the ratio of p-values, which inherently provides a sense of the confidence in the power gain. Additionally, we used bootstrap resampling to estimate variability in measures such as pathway-based modularity, ensuring that our results were robust and not due to random chance.\n\nThe statistical power gain was calculated for specific metabolite-SNP pairs, and the results were detailed in supplementary files, indicating that the findings were systematically evaluated. The log2 absolute ratio of effect sizes was another metric used to assess the performance of imputation methods, with a log2 ratio close to zero indicating that the imputation method preserved effect sizes accurately.\n\nIn the evaluation of type 1 error rates and power, multiple imputation methods like MICE-norm and MICE-pmm showed negligible type 1 error rates and high power for scenarios with up to 50% missing values. This suggests that these methods are statistically significant and superior in maintaining the integrity of the data.\n\nFurthermore, the evaluation based on pathway modularity used a priori pathway annotations to calculate modularity values, which reflect the ratio of metabolite correlations within versus across pathways. The range of modularity values obtained across all datasets provides a confidence interval for the performance of the imputation methods in maintaining biochemically valid edges.\n\nOverall, the performance metrics used in our study included confidence intervals and statistical significance tests, ensuring that the claims of superiority for certain imputation methods are well-supported by the data.",
  "evaluation/availability": "The raw evaluation files are available upon request. Specifically, raw data from the KORA F4 study can be obtained by contacting kora-gen@helmholtzmuenchen.de. Requests are subject to approval by the KORA board to ensure patient privacy is preserved. Formal collaboration and co-authorship with members of the KORA study is not required to access the data. More general information about the KORA study, including study design and clinical variables, can be found on the official KORA website.\n\nThe article is distributed under the terms of the Creative Commons Attribution 4.0 International License. This license permits unrestricted use, distribution, and reproduction in any medium, provided that appropriate credit is given to the original authors and the source, a link to the Creative Commons license is provided, and any changes made are indicated."
}