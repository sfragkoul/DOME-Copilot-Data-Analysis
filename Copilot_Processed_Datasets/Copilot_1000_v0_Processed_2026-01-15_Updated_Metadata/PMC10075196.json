{
  "publication/title": "Early ACLR and Risk and Timing of Secondary Meniscal Injury Compared With Delayed ACLR or Nonoperative Treatment: A Time-to-Event Analysis Using Machine Learning.",
  "publication/authors": "Lu Y, Jurgensmeier K, Till SE, Reinholz A, Saris DBF, Camp CL, Krych AJ",
  "publication/journal": "The American journal of sports medicine",
  "publication/year": "2022",
  "publication/pmid": "36178166",
  "publication/pmcid": "PMC10075196",
  "publication/doi": "10.1177/03635465221124258",
  "publication/tags": "- ACL reconstruction\n- Meniscus survivorship\n- Machine learning\n- Random survival forests\n- Time-to-event analysis\n- Knee injury\n- Orthopedic surgery\n- Predictive modeling\n- Comparative analysis\n- Risk factors",
  "dataset/provenance": "The dataset for this study was sourced from a collaboration among eight surgeons across two institutions. The data was obtained from the Rochester Epidemiology Project (REP), a comprehensive longitudinal database that includes over 500,000 medical records for residents of Olmstead County, Minnesota, and neighboring counties. This database provides detailed descriptions of every resident healthcare encounter within the Olmstead County system from 1966 to the present day, regardless of the treating institution.\n\nPatients who experienced ACL injuries between January 1, 1990, and July 31, 2016, were identified using International Classification of Diseases, Revision 9/10 diagnosis codes for ACL rupture. Patient charts were individually reviewed to confirm the diagnosis of ACL rupture, which was defined as a documented clinical diagnosis made by a treating orthopedic surgeon and confirmed either via arthroscopy or magnetic resonance imaging.\n\nThe inclusion criteria for the study consisted of patients with a primary ACL partial or complete rupture during the study period, patients with a minimum of 2 years\u2019 follow-up, and patients who gave consent for research. Patients were excluded if they had a prior history of knee surgery or concomitant ligamentous repair/reconstruction.\n\nThe dataset includes a variety of patient variables obtained from medical records, such as age, sex, body mass index (BMI), activity level, and occupation. These variables were used for feature selection in the machine learning models. The specific number of data points is not explicitly stated, but the study involved a detailed review of patient charts and the application of strict inclusion and exclusion criteria to ensure the quality and relevance of the data.\n\nThe REP database has been used in previous research, providing a robust foundation for longitudinal studies. The data used in this study is part of a well-established and widely recognized medical records system, ensuring the reliability and comprehensiveness of the information.",
  "dataset/splits": "Not applicable.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study were derived from the Rochester Epidemiology Project (REP), a comprehensive longitudinal database encompassing over 500,000 medical records from residents of Olmstead County, Minnesota, and neighboring regions. The REP provides detailed records of healthcare encounters within the Olmstead County system from 1966 to the present day, independent of the treating institution.\n\nThe specific data used for this study included patients who experienced ACL injuries between January 1, 1990, and July 31, 2016. These patients were identified using International Classification of Diseases, Revision 9/10 diagnosis codes for ACL rupture. Patient charts were individually reviewed to confirm the diagnosis of ACL rupture, which was defined as a documented clinical diagnosis made by a treating orthopedic surgeon and confirmed either via arthroscopy or magnetic resonance imaging.\n\nThe study adhered to strict guidelines for data privacy and ethical considerations. Institutional review board approval was obtained from the involved institutions, and patients provided consent for research. The data were carefully curated to ensure that only relevant and consented information was used.\n\nHowever, the specific data splits used in the machine learning models and the raw dataset itself are not publicly released. This decision was made to protect patient privacy and comply with ethical standards. The models and their performance metrics are discussed in detail within the publication, but the underlying data remains confidential.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Random Survival Forests (RSF). This is an extension of the random forest technique, specifically designed for efficient non-parametric analysis of time-to-event data. RSF provides the advantage of generating real-time individualized survival curves based on input data, which is crucial for personalized risk prediction in medical contexts.\n\nThe RSF algorithm is not new; it has been previously introduced and utilized in various research studies. The decision to use RSF in our study was driven by its proven effectiveness in handling time-to-event data and its ability to provide detailed, individualized survival predictions. This makes it particularly suitable for evaluating the risk factors for secondary meniscal injuries following ACL ruptures.\n\nGiven that RSF is a well-established method in the field of machine learning and statistics, it was not necessary to publish it in a machine-learning journal. Instead, our focus was on applying this robust algorithm to a specific medical problem\u2014predicting meniscal survivorship after ACL injuries\u2014to demonstrate its practical utility in clinical settings. The algorithm's performance was thoroughly evaluated using standard metrics such as the OOB c-statistic, calibration plots, and Brier scores, ensuring its reliability and accuracy in our study.",
  "optimization/meta": "The model described in this publication does not use data from other machine-learning algorithms as input. It is not a meta-predictor. Instead, it employs Random Survival Forests (RSF), an extension of the random forest technique, to perform time-to-event analysis. The RSF model was fitted on the entire cohort of patients, stratified into early ACLR, delayed ACLR, and nonoperative treatment groups. Additionally, separate models were trained on the ACLR and nonoperative cohorts for prognostic use in the clinical space.\n\nThe training data for these models is derived from a cohort of patients, with specific covariates included to account for various factors such as time to surgery, residual laxity, and year of surgery. The models were trained and validated via 0.632 bootstrapping with 1000 resampled datasets, ensuring robust performance metrics. The independence of the training data is maintained through this resampling process, which helps in evaluating the model's generalizability and performance.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Patient medical records were thoroughly reviewed to extract relevant variables for feature selection. These variables included age, sex, body mass index (BMI), activity level, occupation, and other pertinent clinical information. The data was then used to fit Random Survival Forests (RSF), an extension of the random forest technique designed for time-to-event analysis. This method allowed for efficient, non-parametric analysis of survival data, providing individualized survival curves based on input data.\n\nFor the ACL reconstruction (ACLR) model, specific covariates were included to enhance its applicability. These covariates included time to surgery, residual laxity on physical examination, and the year of surgery. These variables were chosen to account for factors such as graft malposition and evolving surgical techniques over the study period. The models were trained and validated using 0.632 bootstrapping with 1000 resampled datasets, ensuring robust performance metrics.\n\nPerformance evaluation metrics included the out-of-bag (OOB) c-statistic, calibration plots, and the OOB Brier score. The OOB c-statistic, or area under the receiver operating characteristics curve (AUROC), was used to assess model discrimination, with values between 0.70 and 0.80 considered acceptable and values between 0.80 and 0.90 considered excellent. Calibration plots were used to evaluate the concordance between predicted probabilities and observed outcomes, with an ideal model showing a straight line with an intercept of 0 and a slope of 1. The OOB Brier score, which measures the mean squared difference between predicted probabilities and observed outcomes, was also calculated to evaluate overall model performance.\n\nAdditionally, global and local model interpretability were provided through variable importance plots and partial dependence plots. These plots helped illustrate the significance of each variable in the model and how changes in continuous variables affected the risk of decreased meniscus survivorship. The final model was integrated into an interactive, open-access digital application, allowing clinicians to input patient data and receive personalized survival predictions. This application is accessible on various devices and requires complete cases to generate predictions and explanations.",
  "optimization/parameters": "In our study, the number of input parameters used in the model varied depending on the specific cohort being analyzed. For the ACLR model, several key parameters were included to enhance its applicability and accuracy. These parameters encompassed time to surgery, residual laxity on physical examination, and the year of surgery. These variables were chosen to account for potential confounding factors such as graft malposition and evolving surgical techniques over the study period.\n\nThe selection of these parameters was guided by a combination of clinical expertise and statistical considerations. Time to surgery was particularly important because it allowed the model to differentiate between early and delayed ACLR, which have distinct implications for meniscal survivorship. Residual laxity and the year of surgery were included to capture variations in surgical outcomes that might be influenced by changes in medical practices and techniques over time.\n\nFor the nonoperative model, a different set of parameters was used, focusing on factors that are relevant to non-surgical management. These included time to return to sport, initial consultation pain levels, hypermobility, and involvement in non-contact sports. These parameters were selected based on their known influence on meniscal injury risk in nonoperatively treated patients.\n\nThe process of parameter selection involved a thorough review of existing literature and clinical insights, ensuring that the most relevant and impactful variables were included. This approach aimed to create robust models that could accurately predict meniscal survivorship outcomes in both ACLR and nonoperative treatment scenarios.",
  "optimization/features": "In our study, we utilized a comprehensive set of input features to train our machine learning models. The specific number of features (f) used as input is not explicitly stated, but it is clear that we conducted a thorough review of patient medical records to obtain relevant variables. These variables included age, sex, body mass index (BMI), activity level, occupation, and other pertinent clinical and demographic information.\n\nFeature selection was indeed performed to identify the most contributory variables to the model's predictive power. This process involved evaluating the statistical significance of each variable in the data with respect to its effect on the generated model. The feature selection was conducted using the training set only, ensuring that the model's performance and generalizability were not compromised by information leakage from the validation or test sets.\n\nThe global relative variable importance plots, as mentioned in our figures, demonstrate the significance of each variable on a unitless scale of 0 to 100. This visualization helps in understanding which features have the greatest influence on the model's predictions. For instance, in the ACLR model, surgical reconstruction of the ACL \u226550 days from the initial incident was identified as a major influential predictor. Similarly, for nonoperatively treated patients, time to return to sport (RTS) \u2264200 days and Visual Analog Scale (VAS) pain >3 at initial consultation were among the key predictors.\n\nBy focusing on the most relevant features, we aimed to enhance the model's interpretability and performance, ensuring that it provides accurate and clinically meaningful predictions.",
  "optimization/fitting": "In our study, we employed Random Survival Forests (RSF), an extension of the random forest technique, to perform a time-to-event analysis. This method is particularly suited for handling time-to-event data and provides individualized survival curves based on input data.\n\nThe number of parameters in our models was indeed larger than the number of training points, which could potentially lead to overfitting. To mitigate this risk, we used 0.632 bootstrapping with 1000 resampled datasets for training and validation. This technique helps to ensure that the model generalizes well to unseen data by providing a more robust estimate of model performance.\n\nTo rule out overfitting, we evaluated the models using out-of-bag (OOB) metrics, which are calculated using the portions of the data not included in the bootstrap samples. Specifically, we focused on the OOB concordance index (c-statistic), which is equivalent to the area under the receiver operating characteristics curve (AUROC). A c-statistic between 0.70 and 0.80 was considered acceptable, and between 0.80 and 0.90 was considered excellent. Our models achieved c-statistics within these ranges, indicating good discriminative performance.\n\nAdditionally, we assessed model calibration, which measures the agreement between predicted probabilities and observed outcomes. An ideal calibration has a straight line with an intercept of 0 and a slope of 1. Our calibration plots showed slopes close to 1 and intercepts close to 0, suggesting that our models were well-calibrated.\n\nTo evaluate overall model performance, we calculated the OOB Brier score, which measures the mean squared difference between predicted probabilities and observed outcomes. Lower Brier scores indicate better performance. Our models demonstrated lower Brier scores compared to null models, further supporting their predictive accuracy.\n\nTo address the risk of underfitting, we ensured that our models included relevant covariates. For the ACLR model, we included time to surgery, residual laxity on physical examination, and year of surgery as covariates. These variables helped to capture important aspects of the data, reducing the likelihood of underfitting.\n\nIn summary, by using bootstrapping, evaluating OOB metrics, and including relevant covariates, we were able to build models that effectively balanced the risks of overfitting and underfitting, resulting in robust and reliable predictions.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was bootstrapping, specifically 0.632 bootstrapping with 1000 resampled datasets. This technique helps to provide a more accurate estimate of model performance by combining the results from multiple resampled datasets, thereby reducing the risk of overfitting to the training data.\n\nAdditionally, we utilized out-of-bag (OOB) metrics for evaluation. OOB metrics are derived from the samples that were not included in the bootstrap sample used to train each tree in the random survival forest (RSF) model. This approach allows for an unbiased estimate of model performance, as it evaluates the model on data that it has not seen during training.\n\nWe also considered the OOB concordance index, also known as the area under the receiver operating characteristics curve (AUROC), as a key performance metric. This index provides a measure of the model's discriminative ability, indicating how well it can distinguish between different outcomes. We aimed for an AUROC in the range of 0.70\u20130.80, which is considered acceptable, and 0.80\u20130.90, which is considered excellent.\n\nFurthermore, we evaluated the calibration of our models using calibration plots. These plots assess how well the predicted probabilities align with the observed outcomes, ensuring that the model's predictions are well-calibrated and not overly optimistic or pessimistic.\n\nThe Brier score, which measures the mean squared difference between predicted probabilities and observed outcomes, was also calculated. This metric provides an overall assessment of model performance, with lower scores indicating better performance. We compared the Brier scores of our RSF models to those of Kaplan-Meier estimators to benchmark their performance.\n\nBy incorporating these techniques, we aimed to build models that generalize well to new data and provide reliable predictions for clinical use.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, the models were trained and validated via 0.632 bootstrapping with 1000 resampled datasets. The optimal model was selected based on the out-of-bag (OOB) c-statistic, with a range of 0.70\u20130.80 considered acceptable and 0.80\u20130.90 considered excellent. Additional performance metrics included calibration plots and the OOB Brier score, which evaluates the mean squared difference between predicted probabilities and observed outcomes.\n\nThe models were fitted on the entire cohort of patients, stratified into early ACLR, delayed ACLR, and nonoperative treatment. For the ACLR model, time to surgery, residual laxity on physical examination, and year of surgery were entered as covariates to account for variations in surgical techniques and data availability.\n\nThe candidate algorithm with the best performance was integrated into an interactive, open-access, educational application. This application is accessible on desktops, tablets, and smartphones, and can be found at a specified URL. The application generates predictions of all three outcomes from a single set of inputs and requires complete cases to generate predictions and explanations.\n\nThe publication adheres to The Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD) guidelines and the Guidelines for Developing and Reporting Machine Learning Models in Biomedical Research. This ensures that the methods and results are reported transparently and can be replicated by other researchers.\n\nThe data source for this study is the Rochester Epidemiology Project (REP), a longitudinal geographic database of medical records for residents of Olmsted County, Minnesota, and neighboring counties. The REP provides detailed descriptions of every resident healthcare encounter within the Olmsted County system from 1966 to the present day. Patients were identified using International Classification of Diseases, Revision 9/10 diagnosis codes for ACL rupture, and their charts were individually reviewed to confirm the diagnosis.\n\nThe variables used for feature selection included age, sex, body mass index (BMI), activity level, occupation, and other relevant patient medical records. The study represents a collaboration among eight surgeons between two institutions, with institutional review board approval from the institutions involved.\n\nThe final model is incorporated into a web-based digital application that generates predictions of all three outcomes from a single set of inputs. The application is accessible on desktops, tablets, and smartphones, and can be found at a specified URL. Default values are provided as placeholders in the interface, and the model requires complete cases to generate predictions and explanations.",
  "model/interpretability": "The model employed in this study is not a black box; it offers both global and local interpretability. To ensure transparency, several techniques were utilized to interpret the model's predictions.\n\nGlobal interpretability was achieved through variable importance plots, which illustrate the relative significance of each input feature in predicting meniscal survivorship. These plots provide a clear ranking of variables, showing which factors most influence the model's outcomes. For instance, in the ACLR model, the time to surgery was identified as a critical factor, with surgical reconstruction of the ACL \u226550 days from the initial incident having the greatest influence on decreased secondary meniscal survivorship. Other significant predictors included time to return to sport (RTS), age at injury, and involvement in high-impact sports.\n\nPartial dependence plots were also generated for continuous variables, offering insights into how changes in specific features affect the risk of decreased meniscus survivorship. These plots hold other covariate values constant, allowing for a clear visualization of the relationship between individual features and the model's predictions. For example, partial dependence plots showed that a shorter time to RTS and younger age at injury were associated with an increased risk of secondary meniscal injury in the ACLR cohort.\n\nAdditionally, calibration plots were used to assess the concordance between predicted probabilities and observed outcomes. An ideal calibration plot has a straight line with an intercept of 0 and a slope of 1, indicating perfect agreement between predicted and actual frequencies. The calibration plots for both the ACLR and nonoperative models demonstrated good alignment, further enhancing the model's interpretability.\n\nLocal interpretability was provided through individual survival curve predictions, which offer personalized insights into meniscal survivorship based on specific patient data. These curves allow clinicians to understand how different combinations of input features affect the likelihood of meniscal injury over time.\n\nOverall, the model's transparency is supported by a combination of variable importance plots, partial dependence plots, calibration plots, and individual survival curves. These tools collectively ensure that the model's predictions are interpretable and actionable, aiding in clinical decision-making and patient management.",
  "model/output": "The model employed in this study is a time-to-event analysis model, specifically a Random Survival Forest (RSF). This type of model is used for survival analysis, which is a regression task rather than a classification task. The primary goal of the model is to predict the time until an event occurs, in this case, the time until a secondary meniscal injury.\n\nThe model generates individual survival curves based on input data, providing real-time, personalized predictions. It evaluates the risk of secondary meniscal tears and the duration of meniscus-injury-free survival. The performance of the model is assessed using metrics such as the out-of-bag (OOB) concordance index (also known as the area under the receiver operating characteristics curve, or AUROC), calibration slope and intercept, and the OOB Brier score. These metrics help to evaluate the model's predictive accuracy and calibration.\n\nThe model's outputs include variable importance plots and partial dependence curves, which illustrate the influence of different factors on meniscal survivorship. For instance, in the ACLR model, surgical reconstruction of the ACL \u226550 days from the initial incident was identified as the greatest influence on decreased secondary meniscal survivorship. Other influential predictors included time to return to sport (RTS) \u2264350 days, age at injury \u226440, and involvement in high-impact/rotational landing sports.\n\nThe final model is integrated into a web-based digital application, accessible on various devices, which generates predictions of all three outcomes from a single set of inputs. The application provides default values as placeholders and requires complete cases to generate predictions and explanations. This makes the model practical for clinical use, allowing healthcare providers to input patient data and receive personalized prognostic information.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The final model developed in this study has been incorporated into a web-based digital application. This application is designed to generate predictions of all three outcomes from a single set of inputs. It is accessible on various devices, including desktops, tablets, and smartphones. The application can be found at a specific URL, which is provided for user access. Default values are included as placeholders in the interface, and the model requires complete cases to generate predictions and explanations.\n\nThe application serves as an interactive, open-access, educational tool to demonstrate model outputs. It allows clinicians to input relevant data, which the model then uses to provide personalized risk predictions and survival curves for individual patients. This tool aims to enhance the adaptability and personalization of risk prediction, moving beyond fixed group-based estimates produced by traditional methods.\n\nThe source code for the model or the specific algorithm used is not mentioned as being publicly released. However, the web-based application itself is accessible and can be used by clinicians and researchers to input data and obtain predictions. The application is designed to be user-friendly, ensuring that it can be easily integrated into clinical practice for better patient management and counseling.",
  "evaluation/method": "The evaluation method employed in this study involved a robust approach using 0.632 bootstrapping with 1000 resampled datasets. This technique was utilized to train and validate the models, ensuring a comprehensive assessment of their performance.\n\nThe primary metric used for evaluation was the out-of-bag (OOB) concordance index, also known as the area under the receiver operating characteristics curve (AUROC). This metric provides a measure of the model's discriminative ability, with values ranging from 0.70 to 0.80 considered acceptable and values from 0.80 to 0.90 considered excellent.\n\nIn addition to the AUROC, the calibration of model predictions was assessed. Calibration plots were used to visualize the concordance between predicted probabilities and observed outcomes. An ideal calibration plot would exhibit a straight line with an intercept of 0 and a slope of 1, indicating perfect agreement between predicted and observed frequencies.\n\nThe Brier score, which measures the mean squared difference between predicted probabilities and observed outcomes, was also calculated. This metric provides an overall evaluation of model performance, with lower scores indicating better predictive accuracy. The Brier scores of the models were compared to those of null models and Kaplan-Meier estimators to benchmark their performance.\n\nFurthermore, global and local model interpretability were provided through variable importance plots and partial dependence plots. These visualizations helped to identify the key factors influencing meniscal survivorship and to understand the relationship between continuous variables and the risk of meniscal injury.\n\nThe final model, demonstrating the best performance, was integrated into an interactive, open-access digital application. This application allows clinicians to input patient data and receive individualized survival predictions, facilitating its practical use in clinical settings.",
  "evaluation/measure": "In the evaluation of our models, several key performance metrics were reported to ensure a comprehensive assessment of their predictive capabilities. The primary metrics included the out-of-bag (OOB) concordance index, also known as the area under the receiver operating characteristic curve (AUROC), which provides a measure of the model's discriminative ability. For the ACLR model, the OOB c-statistic was 0.80 (0.76\u20130.83), indicating excellent performance, while the nonoperative model had an OOB c-statistic of 0.66 (0.581\u20130.735), suggesting acceptable but somewhat lower discriminative power.\n\nCalibration was assessed using calibration plots, which evaluate the agreement between predicted probabilities and observed outcomes. The calibration plot slope and intercept were reported for both models. The ACLR model had a slope of 0.9674 (0.89\u20131.05) and an intercept of 0.005 (\u22120.015\u20130.025), indicating good calibration. The nonoperative model had a slope of 0.9703 (0.645\u20131.296) and an intercept of 0.0048 (\u22120.0597\u20130.0693), also suggesting reasonable calibration.\n\nThe Brier score, which measures the mean squared difference between predicted probabilities and actual outcomes, was another crucial metric. The ACLR model had a Brier score of 0.106 (0.029\u20130.183), compared to a null model score of 0.13, demonstrating better performance. The nonoperative model had a Brier score of 0.111 (0.034\u20130.188), compared to a null model Brier of 0.12, also indicating improved predictive accuracy over the null model.\n\nAdditionally, a comparison between the Random Survival Forest (RSF) model Brier score and a Kaplan-Meier (KM) estimator Brier score was performed across all points of follow-up. This comparison showed that the RSF model outperformed the KM estimator, particularly at long-term follow-up, in both ACLR and nonoperatively treated patients.\n\nThese performance metrics are representative of standard practices in the literature for evaluating predictive models, particularly in the context of time-to-event analysis. The use of AUROC, calibration plots, and Brier scores provides a robust framework for assessing model performance, ensuring that the models are both discriminative and well-calibrated. This set of metrics allows for a thorough evaluation of the models' predictive capabilities and their potential utility in clinical settings.",
  "evaluation/comparison": "In our evaluation, we performed a comprehensive comparison of our models with established methods to ensure robustness and validity. We utilized the Random Survival Forest (RSF) algorithm, an extension of the random forest technique, to perform efficient non-parametric analysis of time-to-event data. This approach allowed us to provide real-time individualized survival curves based on input data, which is crucial for clinical decision-making.\n\nTo benchmark our models, we compared the performance of the RSF algorithm with the Kaplan-Meier (KM) estimator. The KM estimator is a widely used statistical method for estimating survival functions from lifetime data. Our comparison demonstrated that the RSF algorithm outperformed the KM estimator, particularly at long-term follow-up. This was evident in both the ACLR (Anterior Cruciate Ligament Reconstruction) and nonoperatively treated patients, as shown in the Brier score comparisons over the follow-up period.\n\nAdditionally, we evaluated simpler baselines by comparing our models' Brier scores to those of null models. The Brier score, which measures the mean squared difference between predicted probabilities and observed outcomes, provided a clear indication of our models' performance. For the ACLR model, the Brier score was 0.106, compared to a null model score of 0.13. Similarly, for the nonoperative model, the Brier score was 0.111, compared to a null model Brier of 0.12. These comparisons highlighted the superior predictive accuracy of our models over simpler baselines.\n\nFurthermore, we ensured that our models were validated using rigorous methods. We employed 0.632 bootstrapping with 1000 resampled datasets to train and validate our models. This approach helped us to assess the generalizability and reliability of our models' predictions. The evaluation metrics, including the out-of-bag (OOB) c-statistic, calibration plots, and Brier scores, were summarized with standard distributions to provide a comprehensive overview of model performance.\n\nIn summary, our evaluation included comparisons with publicly available methods like the KM estimator and simpler baselines such as null models. These comparisons, along with our robust validation techniques, ensured that our models provided accurate and reliable predictions for meniscal survivorship in both ACLR and nonoperatively treated patients.",
  "evaluation/confidence": "The evaluation of our models included several performance metrics, each accompanied by confidence intervals to provide a range of plausible values for the true metric. For instance, the out-of-bag (OOB) concordance index, also known as the area under the receiver operating characteristic curve (AUROC), for secondary meniscal injury after ACL reconstruction (ACLR) was reported as 0.80 with a 95% confidence interval of 0.76 to 0.83. Similarly, the calibration slope and intercept, as well as the OOB Brier score, were also presented with their respective confidence intervals.\n\nTo assess the statistical significance of our findings, we employed 0.632 bootstrapping with 1000 resampled datasets. This resampling technique helps to estimate the variability and bias in the performance metrics, providing a more robust evaluation of model performance. The use of confidence intervals and bootstrapping allows us to claim with a certain level of confidence that our models outperform baseline models and other comparative methods.\n\nIn our study, the random survival forest (RSF) algorithms demonstrated superior performance compared to Kaplan-Meier (KM) estimators, particularly in long-term follow-up. The comparison of Brier scores between RSF and KM estimators showed that RSF outperformed KM estimators beyond specific time points, indicating the statistical significance of our method's superiority.\n\nAdditionally, the variable importance plots and partial dependence curves provided insights into the statistical significance of each variable in the data with respect to its effect on the generated model. This further supports the claim that our models are not only accurate but also interpretable, with statistically significant predictors of secondary meniscal injury.\n\nIn summary, the performance metrics, confidence intervals, and statistical significance tests collectively demonstrate the robustness and superiority of our models in predicting secondary meniscal injury and meniscus-injury-free survival.",
  "evaluation/availability": "Not applicable."
}