{
  "publication/title": "Automated CT image prescription of the gallbladder using deep learning: Development, evaluation, and health promotion.",
  "publication/authors": "Yang CY, Kao HL, Chen YC, Kuo CF, Liu CH, Liu SC",
  "publication/journal": "Acute medicine & surgery",
  "publication/year": "2025",
  "publication/pmid": "40018053",
  "publication/pmcid": "PMC11865635",
  "publication/doi": "10.1002/ams2.70049",
  "publication/tags": "- Gallbladder\n- Acute Cholecystitis\n- CT Scans\n- Machine Learning\n- Convolutional Neural Networks\n- Medical Imaging\n- Diagnostic Tools\n- Image Segmentation\n- Feature Extraction\n- Clinical Decision Support",
  "dataset/provenance": "The dataset for this study was sourced from patients who presented to the emergency room and underwent abdominal CT scans due to a diagnosis of acute cholecystitis (AC), followed by laparoscopic cholecystectomy within 24 hours, with pathology confirming the diagnosis. The study period spanned from January 2015 to January 2020. A total of 250 consecutive patients, aged between 20 and 80 years, were collected as the AC group. Additionally, 250 patients with acute appendicitis, who had a clearly visible and healthy gallbladder on their CT scans, and 20 patients without AC or appendicitis were included as a control group. The CT images consisted of 1-mm contiguous sections, obtained using a Philips Brilliance 256-slice CT scanner. Furthermore, an additional 40 cases (20 with AC and 20 healthy controls) were recruited from another institution using a different type of CT machine (Philips Brilliance 64-slice CT scanner) for external validation. All images were independently reviewed for accuracy by three board-certified experts (two general surgeons and one radiologist). Approximately 28% of these CT images were annotated for CNN training, with each gallbladder manually outlined and labeled by the same board-certified radiologist. The remaining CT images were reserved for validation and testing. The total number of CT images collected was 27,437 from the AC group and 29,614 from the control group. Initially, 4324 high-quality CT images from the AC group and 4387 from the control group were manually selected for training a neural network to accurately identify CT images containing the gallbladder. The rest of the images were set aside for validation.",
  "dataset/splits": "The dataset was divided into three main splits: training, validation, and testing.\n\nFor the training split, a total of 80 cases were used, with 40 cases from the acute cholecystitis (AC) group and 40 cases from the control group. Each case provided around 90\u2013110 CT images, resulting in 4324 high-quality CT images from the AC group and 4387 from the control group.\n\nThe validation split consisted of 440 cases, with 210 cases from the AC group and 230 cases from the control group. These cases were utilized to validate the gallbladder identification model.\n\nThe testing split involved 120 cases, which were used to evaluate the final model's performance after revisions to the dataset. This split was used to assess the model's accuracy, sensitivity, and specificity.\n\nAdditionally, an external validation set was recruited from another institution, consisting of 40 cases (20 with AC and 20 healthy controls) using a different type of CT machine. This set was used to further validate the model's generalizability.",
  "dataset/redundancy": "The dataset used in this study was carefully curated and split to ensure independence between training and test sets. The study involved patients who presented to the emergency room and underwent abdominal CT scans due to a diagnosis of acute cholecystitis (AC), followed by laparoscopic cholecystectomy within 24 hours, with pathology confirming the diagnosis. From January 2015 to January 2020, a total of 250 consecutive patients, aged between 20 and 80 years, were collected as the AC group. Additionally, 250 patients with acute appendicitis, who had a clearly visible and healthy gallbladder on their CT scans, and 20 patients without AC or appendicitis were included as a control group.\n\nThe CT images, consisting of 1-mm contiguous sections, were obtained using a Philips Brilliance 256-slice CT scanner. Furthermore, an additional 40 cases (20 with AC and 20 healthy controls) from another institution, using a different type of CT machine (Philips Brilliance 64-slice CT scanner), were recruited as a source of external validation. All images were independently reviewed for accuracy by three board-certified experts (two general surgeons and one radiologist). Any cases flagged as suspicious by any of these three experts were excluded from the study.\n\nApproximately 28% of these CT images were annotated for CNN training, with each gallbladder manually outlined and labeled by the same board-certified radiologist. The remaining CT images were reserved for validation and testing. This split ensured that the training and test sets were independent, reducing the risk of data leakage and ensuring that the model's performance could be reliably evaluated on unseen data.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the medical imaging field. The use of a diverse set of CT images from different institutions and different types of CT scanners enhances the generalizability of the model. The careful annotation process and the involvement of multiple experts ensure the high quality and reliability of the dataset. This approach aligns with best practices in medical imaging research, where the independence and quality of the dataset are crucial for the development of robust and reliable machine learning models.",
  "dataset/availability": "The data that support the findings of this study are available from the corresponding author upon reasonable request. This means that the dataset is not publicly released in a forum. Instead, interested parties can contact the corresponding author to access the data. The specifics of how the data can be used, such as licensing details, would likely be discussed directly with the corresponding author. This approach ensures that the data is shared responsibly and that any usage adheres to the guidelines set by the researchers.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages convolutional neural networks (CNNs), specifically utilizing the VGG16 architecture for transfer learning. This approach is well-established in the field of medical imaging and deep learning, known for its effectiveness in feature extraction and image classification tasks.\n\nThe VGG16 model is not a new algorithm; it has been widely used and validated in numerous studies across various domains, including medical imaging. The choice to use VGG16 was driven by its proven capability to handle complex image data and its robustness in identifying intricate patterns within medical images.\n\nGiven that VGG16 is a well-documented and extensively used model, publishing our work in a machine-learning journal was not necessary. Instead, our focus was on applying this established algorithm to a specific medical problem\u2014automatic detection, segmentation, and diagnosis of gallbladder conditions in patients requiring cholecystectomy. This application demonstrates the practical utility of CNNs in a clinical setting, contributing to the broader goal of integrating advanced computational techniques into medical practice.",
  "optimization/meta": "The model described in this publication does not explicitly use a meta-predictor approach. However, it does integrate multiple machine learning methods to achieve its goals. The system architecture involves several steps and models working sequentially.\n\nInitially, the VGG-16 model is utilized for transfer learning to recognize gallbladder images. This model is trained on a dataset that includes images of gallbladders with acute cholecystitis (AC) and normal gallbladders. The VGG-16 model helps in identifying potential gallbladder structures in the CT images.\n\nFollowing this, a U-Net architecture is employed for semantic segmentation and feature extraction. The U-Net model is used to segment the gallbladder region and extract features indicative of AC, such as gallbladder wall thickening, gallstones, and pericholecystic fluid. The U-Net model is trained on images that have been preprocessed using a bilateral filter to reduce noise while preserving the edges of different organs.\n\nThe system also incorporates a post-processing workflow that leverages the continuity of CT images to filter out non-gallbladder regions. This workflow calculates the center point of each contour and uses the continuity of centroids across slices to determine which masks represent the gallbladder.\n\nThe training data for these models includes a significant number of CT images from patients with AC and control groups. The images are manually annotated by board-certified experts, ensuring the accuracy of the labels. The dataset is divided into training, validation, and testing sets to evaluate the performance of the models.\n\nWhile the models are trained independently, the final system integrates their outputs sequentially. The images first undergo grayscale conversion, normalization, and resizing before being processed by the gallbladder recognition model. The identified gallbladder images are then processed using a bilateral filter and input into the gallbladder segmentation model. Finally, the segmented images are analyzed by the AC recognition model to output the probability of AC features.\n\nThe independence of the training data is ensured by the rigorous selection and annotation process, as well as the division of the dataset into separate training, validation, and testing sets. This approach helps in evaluating the generalizability and robustness of the models.",
  "optimization/encoding": "The data encoding and preprocessing for our machine-learning algorithm involved several key steps to ensure optimal performance. Initially, the CT images were converted to grayscale to simplify the data and reduce computational complexity. This was followed by normalization to standardize the pixel values, which helps in stabilizing the learning process and improving convergence.\n\nTo enhance the model's ability to recognize features indicative of acute cholecystitis, we applied dilation to the mask regions. This process expands the surrounding area of the gallbladder, making it easier for the model to identify relevant features. Additionally, a bilateral filter was used for denoising the images. This filter is particularly effective as it preserves the edges of different organs while reducing noise, which is crucial for maintaining the integrity of the gallbladder's boundaries.\n\nThe images were then resized to specific dimensions depending on the stage of processing. For the gallbladder recognition model, images were resized to 256 \u00d7 256 pixels. After identifying images containing the gallbladder, these images were further processed using a bilateral filter and resized to 512 \u00d7 512 pixels for the gallbladder segmentation model. This resizing ensures that the model can capture detailed features necessary for accurate segmentation.\n\nFor the acute cholecystitis recognition model, a 256 \u00d7 256 pixel area centered on the mask's centroid was extracted and fed into the model. This focused approach helps the model to concentrate on the most relevant regions of the gallbladder, improving its ability to detect features associated with acute cholecystitis.\n\nOverall, these preprocessing steps were designed to enhance the quality and relevance of the data, enabling the machine-learning models to perform more accurately and efficiently.",
  "optimization/parameters": "In our study, the model's parameters were automatically set, which significantly reduces the workload for physicians. This automation is a key advantage of our proposed method, as it streamlines the process and enhances efficiency. The selection of parameters was integrated into the model's design to ensure optimal performance without requiring manual adjustments. This approach leverages advanced algorithms to determine the most effective parameters, thereby improving the accuracy and reliability of the model's outputs. By automating this process, we aim to provide a more user-friendly and efficient tool for medical professionals.",
  "optimization/features": "In our study, the input features for the models were derived from CT images, specifically focusing on the gallbladder region. The images underwent preprocessing steps, including grayscale conversion, normalization, and resizing to 256 \u00d7 256 pixels for initial recognition and 512 \u00d7 512 pixels for segmentation. A bilateral filter was applied to reduce noise while preserving the edges of the gallbladder.\n\nFeature selection was implicitly performed through the use of the VGG-16 model for transfer learning. This model was trained on a dataset that included 708 images of gallbladders with acute cholecystitis (AC) and 866 images of normal gallbladders. The initial dataset included all images from each AC case, but it was later refined by removing images that lacked clear signs of AC. This refinement process ensured that the model focused on relevant features indicative of AC, such as gallbladder wall thickening, gallstones, and pericholecystic fluid.\n\nThe feature selection process was conducted using the training set only, ensuring that the model's performance on the validation and test sets was not biased. The final dataset used for training consisted of 198 AC cases and 202 control cases, which improved the model's ability to learn AC-specific features. The number of input features (f) is not explicitly stated as a numerical value, but it is inherent in the dimensionality of the preprocessed CT images and the architecture of the VGG-16 model.",
  "optimization/fitting": "The fitting method employed in our study involved the use of convolutional neural networks (CNNs), specifically the VGG-16 and U-Net architectures, which are known for their high capacity and ability to learn complex patterns from data. The number of parameters in these models is indeed much larger than the number of training points, which could potentially lead to overfitting.\n\nTo mitigate overfitting, several strategies were implemented. First, we used a bilateral filter for image preprocessing, which reduces noise while preserving important features, thereby helping the model to generalize better. Second, we employed centroid continuity to determine the gallbladder's location, which helped in filtering out non-gallbladder segments and improved the model's robustness. Additionally, we used an ensemble of two CNN architectures, which has been shown to improve generalization and reduce overfitting.\n\nTo further ensure that the model was not overfitting, we conducted extensive validation and testing. The dataset was split into training, validation, and testing sets, with the validation set used to tune hyperparameters and monitor the model's performance during training. The testing set, which was not used during training, provided an unbiased evaluation of the model's performance. Moreover, we used metrics such as accuracy, recall, specificity, and the area under the curve (AUC) to thoroughly evaluate the model's performance.\n\nUnderfitting was addressed by ensuring that the models were sufficiently complex to capture the underlying patterns in the data. The VGG-16 and U-Net architectures are deep networks with many layers, which allows them to learn hierarchical features. Furthermore, we used transfer learning with VGG-16, which leverages pre-trained weights to improve the model's ability to learn relevant features from the data. The iterative process of refining the dataset and retraining the model also helped in improving the model's performance and ensuring that it was not underfitting.\n\nIn summary, the fitting method involved the use of powerful CNN architectures, careful preprocessing, ensemble learning, and rigorous validation and testing to address both overfitting and underfitting. These strategies ensured that the models were able to generalize well to new, unseen data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was data augmentation, which involved creating variations of the training images through techniques such as rotation, scaling, and flipping. This helped to increase the diversity of the training dataset, making the model more generalizable to new, unseen data.\n\nAdditionally, we utilized dropout layers within our neural network architectures. Dropout is a regularization technique where randomly selected neurons are ignored during training. This forces the network to learn redundant representations and prevents it from becoming too reliant on any single neuron, thereby reducing overfitting.\n\nWe also implemented early stopping during the training process. This involved monitoring the model's performance on a validation set and stopping the training when the performance stopped improving. This technique helps to prevent the model from overfitting to the training data by avoiding excessive training epochs.\n\nFurthermore, we employed cross-validation to ensure that our model's performance was consistent across different subsets of the data. This involved splitting the data into multiple folds and training the model on different combinations of these folds, which helped to assess the model's generalization ability more reliably.\n\nLastly, we used a bilateral filter for image preprocessing, which reduced noise while preserving the edges of the gallbladder. This preprocessing step helped to improve the quality of the input data, making it easier for the model to learn relevant features without overfitting to noise or irrelevant details.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in our study is primarily a convolutional neural network (CNN), which is often considered a black-box model due to its complex, multilayered architecture. This means that the decision-making process within the CNN is not easily interpretable by humans. The model integrates two CNN architectures to achieve precise differentiation of the gallbladder from other abdominal structures, facilitating accurate feature recognition of gallbladder conditions.\n\nHowever, our approach includes several steps that enhance interpretability to some extent. For instance, the use of a bilateral filter for noise reduction while preserving gallbladder edges provides a clear preprocessing step that can be visually inspected. Additionally, the centroid continuity method used to determine the gallbladder's location offers a more interpretable way to filter out non-gallbladder regions. By leveraging the continuity of centroids across CT slices, we can visually verify the segmentation masks, making the process more transparent.\n\nFurthermore, the feature extraction process using VGG16 for transfer learning allows us to identify specific features indicative of acute cholecystitis, such as gallbladder wall thickening, gallstones, and pericholecystic fluid. These features can be visually confirmed in the CT images, providing a level of interpretability.\n\nThe model's performance is evaluated using metrics like accuracy, recall, and specificity, which are derived from the confusion matrix. This matrix provides a detailed breakdown of true positives, true negatives, false positives, and false negatives, offering insights into the model's strengths and weaknesses. The receiver operating characteristic (ROC) curve and the area under the curve (AUC) further aid in understanding the model's diagnostic performance.\n\nIn summary, while the core CNN model remains a black-box, our methodology includes several interpretable steps and evaluations that enhance the transparency of the overall process. This approach helps in building trust and understanding among clinicians who use the model for diagnostic purposes.",
  "model/output": "The model developed in this study is primarily a classification model, designed to identify and diagnose gallbladder conditions, specifically acute cholecystitis (AC), using CT images. The model's output is a probability indicating the likelihood that an image contains features of AC. If any image in a series is found to contain such features, the entire case is classified as positive for AC.\n\nThe model's performance was evaluated using several metrics, including accuracy, recall, specificity, and the area under the receiver operating characteristic (ROC) curve. The initial model achieved an accuracy of 83.9% and a recall of 77.1%. After refining the dataset by removing images lacking AC characteristics, the model's performance improved significantly, achieving an accuracy of 92.5%, a sensitivity of 0.904, and a specificity of 0.941. The area under the ROC curve was found to be 0.97, indicating strong diagnostic performance.\n\nThe model's output is binary, classifying each case as either positive or negative for AC. This binary output is crucial for clinical decision support, providing reliable indications of suspected AC and assisting in further medical image evaluations. The model's ability to distinguish between healthy and diseased gallbladders is essential for accurate diagnosis and treatment planning.\n\nThe automated recognition system, which integrates gallbladder recognition, segmentation, and feature extraction, achieved an overall accuracy of 86.7% in a test set of 120 cases. The system's average processing time was 3.59 seconds per case, with a maximum time of under 6 seconds. This efficiency is vital for real-time clinical applications, where quick and accurate diagnoses are essential.\n\nIn summary, the model's output is a classification result that indicates the presence or absence of AC in CT images. The model's high accuracy, sensitivity, and specificity make it a valuable tool for clinical decision support, assisting physicians in the diagnosis and treatment of gallbladder conditions.",
  "model/duration": "The model demonstrated remarkable efficiency in processing CT images. For a single CT slice, the segmentation process took approximately 0.029 seconds. When considering a complete CT scan, which typically consists of about 90 to 120 slices, the entire process of segmentation and acute cholecystitis detection averaged around 3.59 seconds per case. This efficiency is a significant advantage, as it allows for rapid assessment and diagnosis, which is crucial in emergency settings. The model's speed, combined with its high accuracy, makes it a valuable tool for clinical decision support, enabling quicker interventions and potentially reducing patients' lengths of stay in emergency departments.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our method involved several steps to ensure its robustness and clinical applicability. Initially, we utilized a dataset consisting of 40 cases each from the acute cholecystitis (AC) and control groups for training. The remaining patients, totaling 210 cases from the AC group and 230 from the control group, were used for validation in gallbladder identification. This validation process yielded an average accuracy of 90.9% and a recall of 90.2%. The worst-case scenario showed an accuracy of 87.9% and a recall of 44.4%, while the best case achieved an accuracy of 96.4% and a recall of 100%.\n\nFor feature learning, we employed the VGG16 model for transfer learning, using a training dataset that included 708 images of gallbladders with AC and 866 images of normal gallbladders. During testing, the model initially achieved an accuracy of 83.9% and a recall of 77.1%. However, after revising the dataset to remove images lacking AC characteristics and retraining the model, we improved its performance. The revised model was tested on 120 cases, achieving an accuracy of 92.5% and a sensitivity of 0.904, with a specificity of 0.941. A receiver operating characteristic (ROC) curve analysis was conducted to evaluate model performance, resulting in an area under the curve (AUC) of 0.97.\n\nWe also integrated the gallbladder recognition, segmentation, and feature extraction models to develop a fully automated recognition system. This system was tested on a set of 120 cases, achieving an overall accuracy of 86.7%, with an average processing time of 3.59 seconds per case. The system's sensitivity was 86.5%, and its specificity was 86.8%. For external validation, we used an additional 40 cases from another institution, resulting in an accuracy of 87.5%, with a sensitivity of 85% and a specificity of 90%.\n\nThe evaluation metrics used included accuracy, recall, specificity, and the area under the ROC curve. These metrics provided a comprehensive assessment of the model's performance in detecting and diagnosing gallbladder conditions. The use of both internal and external validation datasets ensured that the model's performance was generalizable and reliable for clinical applications.",
  "evaluation/measure": "In our study, we employed several key performance metrics to evaluate the effectiveness of our models for gallbladder identification, segmentation, and acute cholecystitis (AC) diagnosis. The primary metrics reported include accuracy, recall, specificity, and the area under the receiver operating characteristic curve (AUC).\n\nAccuracy was defined as the ratio of true positives (TP) and true negatives (TN) to the total number of cases, providing an overall measure of the model's correctness. Recall, also known as sensitivity, was calculated as the ratio of true positives to the sum of true positives and false negatives (FN), indicating the model's ability to identify positive cases. Specificity, on the other hand, was defined as the ratio of true negatives to the sum of true negatives and false positives (FP), reflecting the model's ability to correctly identify negative cases.\n\nFor the gallbladder recognition task, our initial results showed an average accuracy of 90.9% and a recall of 90.2%. The worst-case scenario demonstrated an accuracy of 87.9% and a recall of 44.4%, while the best case achieved an accuracy of 96.4% and a recall of 100%. These metrics indicate the model's performance across different scenarios.\n\nIn the segmentation task, we used the Intersection over Union (IoU) metric to compare our results with the ground truth. The U-Net model alone achieved an IoU of 66.95%, while the U-Net with preprocessing filter improved to 72.71%. Additionally, we reported the Dice coefficient and precision, with the U-Net with filtering consistently outperforming the standalone U-Net model across all metrics.\n\nFor the AC diagnosis, we achieved an accuracy of 83.9% and a recall of 77.1% during initial testing. After revising the dataset, the model's performance improved to an accuracy of 92.5%, a sensitivity of 0.904, and a specificity of 0.941. The AUC was found to be 0.97, indicating strong model performance.\n\nThe ensemble model, which integrates two CNN architectures, demonstrated an overall accuracy of 86.7%, with a sensitivity of 86.5% and specificity of 86.8%. In external validation, the model achieved an accuracy of 87.5%, with a sensitivity of 85% and specificity of 90%.\n\nThese metrics are representative of the current literature on medical image analysis, providing a comprehensive evaluation of our models' performance in gallbladder identification, segmentation, and AC diagnosis.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. However, we did compare our approach to simpler baselines to evaluate its effectiveness.\n\nInitially, we used a standalone U-Net model for segmentation, which achieved an Intersection over Union (IoU) of 66.95%. To improve this, we introduced a preprocessing step using a bilateral filter to reduce noise while preserving gallbladder edges. This enhancement led to a significant improvement, with the U-Net model achieving an IoU of 72.71%. This comparison demonstrated the value of preprocessing in enhancing segmentation accuracy.\n\nFor feature learning and classification, we utilized transfer learning with the VGG16 architecture. Our initial model, trained on a dataset that included inconsistent labeling, achieved an accuracy of 83.9% and a recall of 77.1%. After refining the dataset to include only relevant images, the model's performance improved substantially, reaching an accuracy of 92.5% and a sensitivity of 0.904, with a specificity of 0.941. This improvement highlighted the importance of careful dataset curation in achieving reliable model performance.\n\nAdditionally, we compared our model's performance to state-of-the-art methods in detecting acute cholecystitis (AC). Our deep learning model, based on the VGG16 architecture, achieved a sensitivity of 90.4% and a specificity of 94.1%, which are slightly lower than the pooled sensitivities and specificities of surgeon-performed ultrasound. However, our approach offers the advantage of being fully automated, eliminating the need for manual intervention and reducing diagnostic time significantly.\n\nIn summary, while we did not compare our method directly to publicly available benchmarks, we conducted internal comparisons to simpler baselines and state-of-the-art methods, demonstrating the robustness and efficiency of our approach.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The data that support the findings of this study are available from the corresponding author upon reasonable request. This means that while the raw evaluation files are not publicly released, they can be obtained by contacting the corresponding author. The availability is subject to reasonable request, implying that there might be some conditions or processes to follow for accessing the data. The specific license or terms under which the data would be shared are not detailed, so it is advisable to contact the corresponding author for more information."
}