{
  "publication/title": "A radiomics approach based on support vector machine using MR images for preoperative lymph node status evaluation in intrahepatic cholangiocarcinoma.",
  "publication/authors": "Xu L, Yang P, Liang W, Liu W, Wang W, Luo C, Wang J, Peng Z, Xing L, Huang M, Zheng S, Niu T",
  "publication/journal": "Theranostics",
  "publication/year": "2019",
  "publication/pmid": "31410221",
  "publication/pmcid": "PMC6691572",
  "publication/doi": "10.7150/thno.34149",
  "publication/tags": "- Radiomics\n- Lymph Node Metastasis\n- Machine Learning\n- Support Vector Machines\n- Feature Selection\n- Medical Imaging\n- Texture Analysis\n- Statistical Significance\n- Validation Group\n- Training Group\n- Nomogram\n- Prognostic Model\n- Gray Level Co-occurrence Matrix\n- Gray Level Run Length Matrix\n- Gray Level Size Zone Matrix",
  "dataset/provenance": "The dataset used in this study was sourced from a single institution and was collected retrospectively. The patient population consisted of 148 individuals who underwent pretreatment T1-weighted contrast-enhanced MRI scans. These scans were performed using Gadopentetate dimeglumine, a paramagnetic contrast agent that enhances the signal intensity within the tumor, improving tumor detection and characterization compared to unenhanced MRI and contrast-enhanced CT.\n\nThe dataset was divided into two subgroups based on the diagnosis time. The first subgroup, serving as the training group, included 106 patients diagnosed between April 2011 and February 2016. This group comprised 53 males and 53 females, with ages ranging from 35 to 86 years. The second subgroup, used as the validation group, consisted of 42 patients diagnosed between March 2016 and November 2017. This group included 13 males and 29 females, with ages ranging from 40 to 80 years.\n\nThe baseline clinical features for patients in both the training and validation groups were derived from medical records. These features included gender, age, cholelithiasis status, hepatitis B status, cirrhosis status, primary hepatic lobe site, and the number of primary tumors. Additionally, serum carbohydrate antigen 19-9 (CA19-9) levels and serum carcinoembryonic antigen (CEA) levels were recorded, with threshold values of 37 u/ml for CA19-9 and 5 ng/ml for CEA.\n\nAll MR images were evaluated by two experienced abdomen radiologists who were blind to the actual clinicopathologic results. The number of primary tumors was used as a clinical predictive factor, referring to the number of solid primary tumors for each patient. The dataset was used to justify the use of baseline clinical features by performing demographic comparisons between the training and validation groups for patients with and without lymph node metastasis (LNM).\n\nThe MRI acquisition parameters and definitions for various clinical features are provided in supplementary materials. The dataset was specifically used to test the robustness of image features and to construct and validate a predictive model for LNM in patients with intrahepatic cholangiocarcinoma (ICC). The sample sizes for the training and validation groups were determined to be sufficient based on a power analysis, with an estimated power value of 0.85.",
  "dataset/splits": "The dataset was divided into two main splits: a training group and a validation group. The training group consisted of 106 patients diagnosed between April 2011 and February 2016. The validation group included 42 patients diagnosed between March 2016 and November 2017. Both groups underwent pre-treatment T1-weighted contrast-enhanced MRI scans.\n\nThe training group had an equal gender distribution with 53 males and 53 females, and ages ranging from 35 to 86 years. The validation group had 13 males and 29 females, with ages ranging from 40 to 80 years. The distribution of clinical features such as age, gender, primary hepatic lobe site, number of primary tumors, hepatitis status, cirrhosis status, cholelithiasis, CA19-9 level, CEA level, and MR-reported LNM factor was compared between the two groups. No significant differences were found in these baseline clinical features, justifying the use of these groups for training and validation purposes.",
  "dataset/redundancy": "The datasets were split into a training group and a validation group. The split was justified by the absence of statistically significant differences in baseline clinical features between the two groups, both for patients with lymph node metastasis (LNM) and those without. This ensures that the training and validation groups are independent and comparable.\n\nTo enforce independence, a robustness and reproducibility test was conducted using the Spearman rank correlation test. This test retained features with correlation coefficients greater than 0.8 between two different feature sets, ensuring that the selected features were consistent and reliable.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the medical field. The lymph node metastasis (LNM) rate was 44.34% in the training group and 45.24% in the validation group, indicating a balanced distribution of the target variable. Additionally, the baseline clinical features, such as age, gender, primary hepatic lobe site, number of primary tumors, hepatitis, cirrhosis, cholelithiasis, CA 19-9 level, CEA level, and MR-reported LNM factor, showed no significant differences between the two groups. This balance and independence are crucial for the generalizability and robustness of the models developed.",
  "dataset/availability": "The data used in this study is not publicly available. The dataset consists of patients who underwent pre-treatment T1-weighted contrast-enhanced MRI scans. The patients were divided into two groups: a training group and a validation group, based on their diagnosis times. The training group included 106 patients diagnosed between April 2011 and February 2016, while the validation group included 42 patients diagnosed between March 2016 and November 2017. The MRI acquisition parameters and other relevant details are provided in supplementary materials, but the actual data is not released in a public forum. The study does not mention any public release of the data or the specific data splits used. Therefore, the data is not available for public access or reuse under any specific license.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is Support Vector Machine (SVM). This is a well-established and widely used supervised learning method for classification and regression tasks. The SVM model was constructed using features selected through the minimum Redundancy Maximum Relevance (mRMR) method, which was identified as the optimal feature selection algorithm based on its performance metrics, such as the Area Under the Curve (AUC) and sensitivity.\n\nThe SVM algorithm itself is not new; it has been extensively researched and applied in various fields, including medical imaging and bioinformatics. The choice to use SVM in this context is likely due to its effectiveness in handling high-dimensional data and its robustness in classification tasks. The focus of this publication is on the application of SVM in predicting lymph node metastasis (LNM) rather than the development of a new machine-learning algorithm.\n\nGiven that SVM is a mature and well-documented algorithm, it is appropriate that the publication appears in a journal focused on theranostics rather than a machine-learning journal. The emphasis here is on the clinical application and the integration of machine learning with medical data to improve diagnostic accuracy. The study demonstrates the practical utility of SVM in a specific medical context, contributing to the field of theranostics by enhancing the predictive power of LNM.",
  "optimization/meta": "The model indeed uses data from other machine-learning algorithms as input, specifically from a Support Vector Machine (SVM) model. This approach is part of a meta-predictor strategy, where the output from the SVM model is combined with other clinical factors to create a more robust predictive tool.\n\nThe meta-predictor integrates the SVM score with additional features such as the CA 19-9 level and the MR-reported Lymph Node Metastasis (LNM) factor. These features were selected through a multivariable analysis using the Akaike Information Criterion (AIC) and independence analysis. The final combination includes the SVM score, CA 19-9 level, and the MR-reported LNM factor, all of which were found to be statistically significant and independent in the training group.\n\nThe training data for the SVM model and the combination nomogram were carefully managed to ensure independence. The SVM model was initially developed using a training group segmented by one radiologist, and its performance was validated using a separate validation group. Subsequently, the combination nomogram was tested using an overall dataset segmented by a different radiologist, ensuring that the training and validation datasets were independent.\n\nThis meta-predictor approach aims to enhance the predictive accuracy and reliability by leveraging the strengths of both the SVM model and the additional clinical features. The combination nomogram demonstrated better performance metrics, including higher accuracy and area under the curve (AUC) values, compared to the SVM model alone. This indicates that the meta-predictor effectively integrates multiple sources of information to improve predictive capabilities.",
  "optimization/encoding": "In our study, we applied several preprocessing steps to the image data before feature extraction. Initially, we resampled the arterial phase contrast-enhanced MR images to a voxel size of 1\u00d71\u00d71 mm\u00b3. This step ensured consistency in the spatial resolution of the images. Following resampling, we performed grey level normalization, scaling the image intensities to a range of 1 to 32. This normalization step helped to standardize the image data, making it more suitable for subsequent feature extraction.\n\nFor feature extraction, we utilized a total of 491 image features for each patient, based on the volume of interest (VOI). These features were categorized into several types, including histogram features, geometry features, gray level co-occurrence matrix features, grey-level run-length matrix features, grey-level size zone matrix features, neighborhood gray-tone difference matrix features, and wavelet-based texture features. These features were designed to capture intratumor heterogeneity, as well as underlying tumor genotypes and protein structures.\n\nBefore constructing the support vector machine (SVM) model, we performed feature normalization to eliminate differences in the value scales of the radiomics features. For the training group, each feature for a specific patient was subtracted by the mean value and divided by the standard deviation value from this group. The same normalization method was applied to the validation group using the mean values and standard deviation values calculated based on the training group.\n\nGiven the high-dimensional feature size and relatively low-dimensional patient sample size, we employed a feature selection process to identify the most relevant features for lymph node (LN) status prediction. This process involved two main steps. First, we tested the robustness and reproducibility of the image features using the Spearman rank correlation test. Features with correlation coefficients greater than 0.8 were considered robust and retained for further analysis. Second, we applied the maximum relevance minimum redundancy (mRMR) algorithm to assess the relevance and redundancy of each feature. The mRMR method helped us select features that had the maximal correlation to the actual LN status while ensuring minimal redundancy among the selected features. The top features with high relevance and low redundancy were then used to construct the SVM model with a linear kernel.",
  "optimization/parameters": "In the optimization process, the model utilized a specific set of parameters to enhance predictive performance. Initially, a robustness and reproducibility test was conducted on 491 image features, retaining 91 features with correlation coefficients greater than 0.8 between two feature sets using the Spearman rank correlation test. To further refine the feature set and reduce redundancy, the minimum Redundancy Maximum Relevance (mRMR) method was employed. This method selected the five highest-ranked features, which were then used to build the Support Vector Machine (SVM) model. The selected features were HLH_GLCM_maxpr, LLH_GLCM_sosvh, HLL_GLCM_corrm, LLL_GLCM_denth, and HLL_GLSZM_LGZE. Among these, three features\u2014HLH_GLCM_maxpr, LLL_GLCM_denth, and HLL_GLSZM_LGZE\u2014showed significant correlation with the actual lymph node status and significant differences between patients with and without lymph node metastasis (LNM) in the training group, with P-values less than 0.05.\n\nThe mRMR method was chosen as the optimal feature selection algorithm after comparing the performances of several methods, including LASSO, Random Forest, Elastic Net, Wilcoxon, and Gini index. The mRMR method demonstrated the best performance in terms of the Area Under the Curve (AUC) value in both the training and validation groups. This selection process ensured that the model was built with the most relevant and non-redundant features, thereby improving its predictive accuracy.",
  "optimization/features": "In our study, we initially extracted a total of 491 image features for each patient based on the volume of interest (VOI). These features encompassed various types, including histogram features, geometry features, gray level co-occurrence matrix features, gray-level run-length matrix features, gray-level size zone matrix features, neighborhood gray-tone difference matrix features, and wavelet-based texture features.\n\nTo ensure the robustness and reproducibility of these features, we performed a feature selection process. This involved two main steps. First, we tested the robustness of the features by calculating the correlation coefficients between two feature sets extracted by different radiologists using the Spearman rank correlation test. Only features with correlation coefficients greater than 0.8 were retained, resulting in 91 robust features.\n\nNext, we applied the maximum relevance minimum redundancy (mRMR) algorithm to further select the most relevant features for predicting lymph node metastasis (LNM) status. The mRMR method helped us identify features that had the highest correlation with the actual LNM status while minimizing redundancy among the selected features. Through this process, the five highest mRMR-ranked features were chosen to build the support vector machine (SVM) model. These selected features were HLH_GLCM_maxpr, LLH_GLCM_sosvh, HLL_GLCM_corrm, LLL_GLCM_denth, and HLL_GLSZM_LGZE.\n\nIt is important to note that the feature selection process was performed using only the training set to avoid any bias that could arise from using the validation set. This ensures that the selected features are truly representative of the underlying patterns in the data and can generalize well to new, unseen data.",
  "optimization/fitting": "In the development of our predictive model, we employed a Support Vector Machine (SVM) approach, which is known for its effectiveness in high-dimensional spaces. The number of parameters in our model was indeed larger than the number of training points, a common scenario in radiomics studies where a large number of features are extracted from medical images.\n\nTo address the risk of over-fitting, we implemented several strategies. Firstly, we used the minimum Redundancy Maximum Relevance (mRMR) feature selection method to reduce the dimensionality of our feature set while retaining the most relevant features. This step helped to mitigate over-fitting by focusing on the most informative features. Secondly, we employed a robustness and reproducibility test using the Spearman rank correlation to retain only the most stable features across different datasets. Additionally, we utilized the bootstrap method to internally validate our model, ensuring that our results were robust and generalizable.\n\nTo rule out under-fitting, we carefully selected our features and model parameters. The mRMR method not only reduced dimensionality but also ensured that the selected features were complementary and provided the most predictive power. Furthermore, we used the Akaike Information Criterion (AIC) and independence analysis to select the optimal combination of features, ensuring that our model was neither too simple nor too complex. The final model included the SVM score, CA 19-9 level, and the MR-reported LNM factor, which were all statistically significant and independent in the training group.\n\nThe performance of our model was evaluated using the Area Under the Curve (AUC) and prediction accuracy in both training and validation groups. The AUC values were consistent across both groups, indicating that our model generalizes well to unseen data. The prediction accuracy was also satisfactory, further confirming that our model is well-fitted and not under-fitting the data.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our model. One of the key methods used was feature selection, specifically the maximum relevance minimum redundancy (mRMR) algorithm. This algorithm helped in selecting features that had the highest correlation with the actual lymph node status while minimizing redundancy among the selected features. By doing so, we reduced the dimensionality of the feature set, which in turn helped to mitigate overfitting.\n\nAdditionally, we performed feature normalization to standardize the value scales of the radiomics features. This step was crucial in ensuring that no single feature dominated the model due to its scale, thereby promoting a more balanced and generalizable model.\n\nWe also conducted a robustness and reproducibility test using the Spearman rank correlation test. Features with correlation coefficients greater than 0.8 between different radiologists' segmentations were retained. This step ensured that the selected features were robust against manual segmentation variations, further enhancing the model's reliability.\n\nMoreover, we compared the performances of different feature selection methods, including mRMR, least absolute shrinkage and selection operator (LASSO), Random Forest, Elastic Net, Wilcoxon, and Gini index. The mRMR method was ultimately chosen due to its superior performance in both the training and validation groups, as evidenced by the highest area under the curve (AUC) values and the lowest P values.\n\nTo evaluate the model's performance, we used the area under the curve (AUC) and prediction accuracy, which provided a comprehensive assessment of the model's discriminative capability. The calibration of the model was also checked using calibration curves and the Hosmer-Lemeshow test, ensuring that the predicted probabilities aligned well with the actual outcomes.\n\nIn summary, our approach to preventing overfitting involved a combination of feature selection, normalization, robustness testing, and comparative analysis of different feature selection methods. These techniques collectively contributed to the development of a reliable and generalizable model for predicting lymph node status.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not explicitly detailed in the provided information. However, the methods and results of the feature selection and model construction are thoroughly described. The mRMR method was used for feature selection, and the SVM model was constructed using the top five features ranked by mRMR. The calculation formulas for the SVM model and the combination nomogram are provided, which can be used to replicate the models.\n\nThe specific performances of the SVM model and the combination nomogram are summarized in tables and figures, which include accuracy, AUC, sensitivity, and specificity for both the training and validation groups. The decision curves and ROC curves are also provided to evaluate the clinical utilities of the models.\n\nRegarding the availability of optimization parameters, the details of the optimization process are not explicitly stated. However, the methods used for feature selection and model construction are well-documented, allowing for reproducibility. The performance metrics and validation results are presented, which can guide the optimization process.\n\nNot applicable.",
  "model/interpretability": "The models developed in this study include a Support Vector Machine (SVM) model and a combination nomogram. The SVM model is inherently a black-box model, meaning its internal workings and decision-making processes are not easily interpretable. However, the combination nomogram offers a more transparent approach.\n\nThe combination nomogram integrates several key factors, including the SVM score, CA 19-9 level, and the MR-reported Lymph Node Metastasis (LNM) factor. These factors were selected through a multivariable analysis using the Akaike Information Criterion (AIC) and independence analysis. The nomogram provides a visual representation of how each factor contributes to the final prediction, making it easier to understand the relative importance of each variable.\n\nFor instance, the calculation formula for the combination nomogram includes specific coefficients for each factor, such as 0.0988 for HLH_GLCS_mmdms and -0.1524 for LLLH_GLCS_sh. These coefficients indicate the weight of each factor in the prediction model. Additionally, the nomogram score threshold of -0.8270 is used to classify patients as having synchronous LNM or non-LNM, providing a clear and interpretable decision boundary.\n\nThe decision curves for the combination nomogram and the SVM model further illustrate the clinical utility of the models. The combination nomogram consistently shows a higher area under the decision curve compared to the SVM model, indicating better clinical performance. This transparency in the combination nomogram allows clinicians to understand the rationale behind the predictions, enhancing trust and facilitating practical application in clinical settings.",
  "model/output": "The model developed in this study is primarily a classification model. It is designed to predict the presence of synchronous lymph node metastasis (LNM) in patients. The model uses a support vector machine (SVM) score, along with other clinical factors, to classify patients into two categories: those with synchronous LNM and those without. The classification threshold for the SVM score is set at 0.4915, where patients with scores higher than this threshold are predicted to have synchronous LNM, and those with scores lower than this threshold are predicted to be non-LNM. Similarly, the combination nomogram uses a threshold of -0.8270 to classify patients, with scores greater than this threshold indicating synchronous LNM and scores lower than this threshold indicating non-LNM. The prediction accuracy for the SVM model is 73.58% for the training group and 69.05% for the validation group. The combination nomogram shows slightly better performance, with an accuracy of 72.64% for the training group and 78.57% for the validation group. The model's performance is evaluated using metrics such as accuracy, area under the curve (AUC), sensitivity, and specificity, which are standard for classification tasks.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several key steps to ensure its robustness and generalizability. Initially, the model's performance was assessed using the area under the curve (AUC) and prediction accuracy. The AUC values were calculated using the Delong test, which measures differences in ROC curves between the combination nomogram and the SVM model. This test was applied to both the training and validation groups, ensuring that the model's performance was consistent across different datasets.\n\nThe model's discrimination performance was evaluated using ROC curves and AUC values. Additionally, the calibration of the model was assessed using calibration curves and the Hosmer-Lemeshow test (H-L test). The calibration curves measured the consistency between the predicted lymph node metastasis (LNM) probability and the actual LNM probability. A significant statistic from the H-L test would indicate a poor fit of the model, meaning there is a significant difference between the predicted and actual LNM probabilities.\n\nTo further validate the model, a bootstrap method was employed. This involved generating histograms that described the distributions of AUCs from the bootstrap method for both the SVM model and the combination nomogram in both training and validation groups. The bootstrap method helped in understanding the stability and reliability of the model's performance.\n\nThe clinical utility of the models was measured using decision curve analysis. This analysis plotted the clinical net benefit values against the threshold probability, providing a visual representation of the model's practical value in clinical settings. The decision curves corresponding to the \"treat-all plan\" and the \"treat-none plan\" were used as references, with a larger area under the decision curve indicating better clinical utility.\n\nStatistical tests were executed using MedCalc Statistical Software and R software. Univariate analysis for clinical features was implemented using the Chi-square test for categorical variables and the Mann-Whitney U test for continuous variables. The significance level was set at P<0.05 for two-tailed analyses.\n\nIn summary, the evaluation method involved a comprehensive approach that included AUC and prediction accuracy, calibration curves, the Hosmer-Lemeshow test, bootstrap validation, and decision curve analysis. These steps ensured that the model's performance was thoroughly assessed and validated across different datasets and clinical scenarios.",
  "evaluation/measure": "In the evaluation of our models, we employed a comprehensive set of performance metrics to ensure a thorough assessment. The primary metrics reported include sensitivity, specificity, and the area under the curve (AUC) with its corresponding 95% confidence interval (CI). These metrics were calculated for both the training and validation groups, providing a robust evaluation of model performance.\n\nSensitivity, also known as the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, indicates the proportion of actual negatives that are correctly identified. The AUC provides a single scalar value that summarizes the model's ability to discriminate between positive and negative classes across all possible classification thresholds.\n\nIn addition to these standard metrics, we also reported P-values calculated using the Delong test. This test is used to compare the AUCs of different models and determine if the differences in performance are statistically significant. A P-value less than 0.05 indicates a statistically significant difference.\n\nTo evaluate the clinical utility of our models, we used decision curve analysis. This method assesses the net benefit of using a predictive model across a range of threshold probabilities. The decision curve plots the net benefit against the threshold probability, allowing for a visual comparison of different models. A larger area under the decision curve suggests better clinical utility.\n\nThe calibration of our models was evaluated using calibration curves and the Hosmer-Lemeshow test. Calibration curves measure the agreement between predicted probabilities and actual outcomes, while the Hosmer-Lemeshow test assesses the goodness-of-fit of the prediction models. A non-significant P-value from the Hosmer-Lemeshow test indicates good calibration.\n\nThese performance metrics are widely used in the literature and provide a representative evaluation of model performance. By reporting sensitivity, specificity, AUC, P-values from the Delong test, decision curve analysis, and calibration metrics, we ensure that our evaluation is comprehensive and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of various feature selection methods to determine the optimal approach for our predictive model. The methods evaluated included mRMR, LASSO, Random Forest, Elastic Net, Wilcoxon, and Gini Index. These methods were assessed based on their performance in both the training and validation groups.\n\nFor the training group, the P values calculated using the Delong test indicated that mRMR, LASSO, Elastic Net, and Random Forest all performed significantly better, with P values less than 0.0001. When using the AUC value as the evaluation index, both the mRMR method and the LASSO method demonstrated the best performances.\n\nIn the validation group, the mRMR method stood out with the lowest P value and the highest AUC, making it the chosen optimal method for our study. This thorough comparison allowed us to select the most effective feature selection method, ensuring the robustness and reliability of our predictive model.\n\nRegarding simpler baselines, we did not explicitly compare our methods to publicly available benchmarks or simpler baselines on standard datasets. Instead, our focus was on evaluating the performance of different feature selection techniques within the context of our specific problem and dataset. This approach ensured that our model was tailored to the unique characteristics of our data, providing the most accurate and relevant predictions.",
  "evaluation/confidence": "The evaluation of our method's performance includes several key aspects that ensure the reliability and statistical significance of our results.\n\nPerformance metrics such as the area under the curve (AUC) are accompanied by confidence intervals. For instance, the AUC for the mRMR method in the training group is reported as 0.788 with a 95% confidence interval of 0.698 to 0.862. This provides a clear range within which the true AUC is likely to fall, giving a sense of the precision of our estimates.\n\nStatistical significance is a crucial factor in determining the superiority of our method. We used the Delong test to compare the performance of different feature selection methods. The P-values obtained from this test indicate whether the differences in AUCs between methods are statistically significant. For example, the P-value for the mRMR method in both the training and validation groups is less than 0.0001, which is well below the conventional threshold of 0.05. This strongly suggests that the mRMR method's performance is significantly better than random chance and potentially superior to other methods.\n\nAdditionally, we evaluated the calibration of our models using the Hosmer-Lemeshow test. A non-significant P-value from this test indicates that the predicted probabilities are well-calibrated, meaning they closely match the actual outcomes. This further supports the reliability of our method.\n\nIn summary, the inclusion of confidence intervals for performance metrics and the use of statistical tests like the Delong test and Hosmer-Lemeshow test ensure that our claims of superiority are backed by robust statistical evidence. This approach provides a comprehensive evaluation of our method's performance and its potential advantages over other techniques.",
  "evaluation/availability": "Not enough information is available."
}