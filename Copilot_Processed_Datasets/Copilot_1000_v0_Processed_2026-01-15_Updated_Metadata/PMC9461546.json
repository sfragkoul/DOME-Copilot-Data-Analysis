{
  "publication/title": "Prediction of outpatient visits and expenditure under the Universal Coverage Scheme in Bangkok using subscriber's attributes: A random forest analysis.",
  "publication/authors": "Mongkonchoo K, Yamana H, Aso S, Machida M, Takasaki Y, Jo T, Yasunaga H, Chongsuvivatwong V, Liabsuetrakul T",
  "publication/journal": "Public health in practice (Oxford, England)",
  "publication/year": "2021",
  "publication/pmid": "36101615",
  "publication/pmcid": "PMC9461546",
  "publication/doi": "10.1016/j.puhip.2021.100190",
  "publication/tags": "- Health care services\n- Outpatient visits\n- Prediction model\n- Capitation budget\n- Machine learning\n- Random forest algorithm\n- Health expenditure\n- Universal Coverage Scheme\n- Health care facilities\n- Middle-income countries\n- Data quality\n- Service utilization\n- Chronic diseases\n- Health insurance\n- Health promotion\n- Health prevention\n- Health care data\n- Health care finance\n- Health care policy\n- Health care utilization",
  "dataset/provenance": "The dataset utilized in this study originates from the Bangkok Metropolitan Administration's National Health Security Office (BKKNHSO). This comprehensive database encompasses all healthcare services provided to Universal Coverage Scheme (UCS) subscribers in Bangkok. The data includes detailed records of outpatient services, inpatient services, health promotion, and prevention services. Each record contains information on diagnoses, procedures, drugs, examinations, and medical charges. Additionally, the dataset includes subscriber data, such as demographic information and registrations of non-communicable chronic diseases.\n\nThe study specifically used data from the 2016 and 2017 fiscal years, spanning from October 2015 to September 2017. To explore the feasibility of predicting service utilization for the full population, we randomly sampled 1% and 10% of subscribers observed during these fiscal years to create training and testing groups, respectively. Subscribers who withdrew from the UCS in FY2017 were excluded from the analysis.\n\nThe training group consisted of 37,259 subscribers, while the testing group included 371,650 subscribers. These samples were used to construct and validate prediction models for the number of outpatient visits and expenditure in the subsequent fiscal year. The dataset's richness and comprehensiveness allowed for a detailed analysis of service utilization patterns and the development of accurate predictive models.",
  "dataset/splits": "Two data splits were used in this study. The first split, referred to as the training group, consisted of 37,259 subscribers, which represented a 1% sample of the total population. The second split, known as the testing group, included 371,650 subscribers, representing a 10% sample of the population. These splits were created to explore the feasibility of predicting service utilization for the full population using models derived from a smaller group of subscribers. Subscribers who withdrew from the Universal Coverage Scheme (UCS) in the fiscal year 2017 were excluded from both groups. The datasets were constructed from the database as subscriber-based aggregated data, representing each subscriber's conditions, frequency of visits, and annual health expenditure on outpatient services.",
  "dataset/redundancy": "The datasets used in this study were derived from a comprehensive database of all health-care services provided to Universal Coverage Scheme (UCS) subscribers in Bangkok. To explore the feasibility of predicting service utilization for the full population using models derived from a smaller group of subscribers, we randomly sampled 1% of subscribers for the training group and 10% for the testing group. These samples were observed through the fiscal years 2016 and 2017.\n\nThe training and testing groups were constructed to be independent. This independence was enforced by ensuring that subscribers who withdrew from the UCS in the fiscal year 2017 were excluded from both groups. This step helped in maintaining the integrity of the data and ensuring that the models were trained and tested on distinct sets of subscribers.\n\nThe distribution of the datasets in this study is notable for its focus on a middle-income country setting, which is less common in the literature compared to high-income countries. The datasets include detailed information on subscribers' characteristics, such as sex, age, home registration, and underlying non-communicable diseases. Additionally, the datasets capture a wide range of service utilization details, including diagnoses categorized by the International Classification of Diseases, 10th revision (ICD-10), and various types of medical services utilized.\n\nThe random sampling process ensured that the training and testing groups were representative of the overall population of UCS subscribers in Bangkok. This approach is crucial for building robust prediction models that can generalize well to the entire population. The datasets were constructed as subscriber-based aggregated data, representing each subscriber's conditions, frequency of visits, and annual health expenditure on outpatient services. This aggregation allowed for a comprehensive analysis of service utilization patterns and expenditures.\n\nIn summary, the datasets were split into independent training and testing groups through random sampling, with careful consideration to exclude subscribers who withdrew from the UCS. The distribution of the datasets is unique in its focus on a middle-income country setting and provides a detailed and comprehensive view of subscribers' characteristics and service utilization patterns.",
  "dataset/availability": "The data used in this study is not publicly available. The study utilized a database from the Bangkok Metropolitan Administration's National Health Security Office (BKKNHSO), which contains detailed health service data for Universal Coverage Scheme (UCS) subscribers in Bangkok. This database includes information on outpatient services, inpatient services, health promotion and prevention services, as well as subscriber demographics and chronic disease registrations.\n\nThe data was accessed and used under a specific agreement with the BKKNHSO, which allowed for the utilization of de-identified data. This agreement ensured that the data was used in compliance with ethical guidelines and privacy regulations. The study was approved by the Institutional Review Board for Clinical Research at the National Center for Global Health and Medicine, as well as the Ethics Committee of the Faculty of Medicine at Prince of Songkla University.\n\nDue to the sensitive nature of the health data and the need to protect subscriber privacy, the dataset is not released in a public forum. The data access and usage were strictly controlled and monitored to ensure compliance with ethical standards and data protection regulations.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is the random forest algorithm. This algorithm is not new; it is a well-established ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe choice to use the random forest algorithm was driven by its proven effectiveness in handling large datasets with numerous predictors, which is particularly relevant in healthcare cost and utilization prediction. The algorithm's ability to capture complex interactions between variables and its robustness to overfitting make it suitable for this type of analysis.\n\nThe decision to publish this work in a public health journal rather than a machine-learning journal is likely due to the focus of the study. The primary objective was to apply machine learning techniques to predict healthcare utilization and expenditure, which is a significant public health concern. The study's contributions lie in its application of machine learning to a real-world healthcare dataset, demonstrating the practical utility of these methods in improving healthcare resource allocation and budgeting.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. It relies solely on a random forest algorithm to predict the number of outpatient visits and expenditure for the following year based on data from the previous fiscal year. The random forest algorithm was chosen for its superior predictive ability, especially when dealing with a large number of predictors and complex relationships.\n\nThe study utilized a 1% sample of subscribers to build the initial model and then applied it to a 10% sample of the population. The data used for training and testing were carefully selected to ensure independence, with no overlap between the training and testing groups. This approach helps to validate the model's predictive performance and generalizability.\n\nThe random forest algorithm itself is an ensemble learning method that combines multiple decision trees to improve predictive accuracy and control over-fitting. Each tree in the forest is trained on a different bootstrap sample of the data, and the final prediction is made by aggregating the predictions from all the trees. This method does not involve using data from other machine-learning algorithms as input; it operates solely on the features derived from the subscriber data.\n\nIn summary, the model is a standalone random forest algorithm that does not incorporate predictions from other machine-learning methods. The training and testing data were independently selected to ensure robust model validation.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to prepare the dataset for the machine-learning algorithm. We began by categorizing age into 10-year intervals, with individuals over 80 years grouped together. This approach helped in managing the age variable effectively.\n\nWe utilized chronic disease registration data to identify subscribers' underlying non-communicable diseases, such as cancer, diabetes, hypertension, stroke, asthma, chronic obstructive pulmonary diseases (COPD), and cardiovascular diseases (CVD). These diseases were encoded as binary variables, indicating their presence or absence.\n\nDiagnosis records from the service transaction data in the fiscal year 2016 were categorized using the International Classification of Diseases, 10th revision (ICD-10) chapters. We identified 19 diagnoses, which were then encoded into three groups: diagnosed users (those with diagnosis records), non-diagnosed users (those who utilized services but had no diagnosis records), and non-users (those who did not utilize any services).\n\nMedical charges were used to identify the utilization of various services, including medicines, blood transfusion, examinations, radiology, special diagnostics, medical equipment, procedures and anesthesia, hospital fees, and doctor fees. These services were encoded as binary variables, indicating whether resources were consumed or not for each type of service.\n\nHealth promotion and prevention services were summarized into the total number of visits. Inpatient data were used to identify the number of admissions, length of hospitalization, and relative weight based on the Diagnosis-Related Group system.\n\nThe outcome variables for our study were the number of outpatient visits and expenditure in the fiscal year 2017. These variables included referral outpatient services provided at referral hospitals and billed to the main contracting unit of each subscriber.\n\nFor the machine-learning algorithm, we included 43 candidate covariates at the subscriber level. These covariates encompassed patient type, sex, age, home registration, non-communicable diseases, diagnoses from transaction data, use of services, number of outpatient visits, number of health promotion and prevention services, number of inpatient admissions, total length-of-stay in hospital, and total relative weight of inpatient services. Each of these covariates was carefully encoded to ensure compatibility with the random forest algorithm used in our analysis.",
  "optimization/parameters": "In our study, we utilized a total of 43 candidate covariates as input parameters for our random forest model. These parameters were selected based on their potential relevance to predicting the number of outpatient visits and expenditure for the following fiscal year. The parameters included a mix of demographic information, health status indicators, and service utilization data.\n\nDemographic information included variables such as patient type (user or non-user), sex, age, and home registration. Health status indicators comprised non-communicable diseases from the chronic disease register, coded as seven dummy variables, and diagnoses from transaction data, coded as 19 dummy variables. Service utilization data included the use of various services, coded as eight dummy variables, as well as the number of outpatient visits, health promotion and prevention services, inpatient admissions, total length of hospitalization, and total relative weight of inpatient services.\n\nThe selection of these parameters was informed by previous research and the availability of data within our dataset. The random forest algorithm's ability to handle a large number of predictors made it a suitable choice for this study. The number of trees in the random forest was set at 500, and the number of random candidate variables to be entered was selected using the tuneRF function, which optimizes the number of variables to consider at each split. This approach ensured that the model was robust and capable of capturing complex relationships within the data.",
  "optimization/features": "In our study, we utilized a total of 43 candidate covariates as input features for our prediction models. These features were selected based on their potential relevance to the outcome variables, which were the incremental number of outpatient visits and expenditure in the following fiscal year.\n\nFeature selection was performed to ensure that only the most relevant variables were included in the models. This process was conducted using the training group data only, ensuring that the testing group data remained independent and unbiased. The selected features included a mix of demographic information, such as patient type, sex, age, and home registration, as well as clinical data, including non-communicable diseases from the chronic disease register, diagnoses from transaction data, and use of various services. Additionally, we considered the number of outpatient visits, health promotion and prevention services, inpatient admissions, total length of stay in the hospital, and the total relative weight of inpatient services.\n\nThe random forest algorithm was employed to identify the most important predictors among these features. For the incremental number of visits, the top predictors were the number of visits, hypertension, laboratory tests, medicines, and radiology services. For incremental expenditure, the key predictors were medicines, laboratory tests, number of health promotion and prevention services, number of outpatient visits, and being diagnosed with hypertension. This approach helped in refining the model and improving its predictive accuracy.",
  "optimization/fitting": "The fitting method employed in this study utilized a random forest algorithm, which is particularly well-suited for handling a large number of predictors. The dataset included 43 candidate covariates, which is indeed a substantial number compared to the training sample size of 37,259 subscribers. This scenario could potentially lead to overfitting, where the model performs well on the training data but fails to generalize to new, unseen data.\n\nTo mitigate the risk of overfitting, several strategies were implemented. Firstly, the random forest algorithm inherently reduces overfitting by averaging multiple decision trees, each trained on a different bootstrap sample of the data. This ensemble approach helps to smooth out the predictions and reduce the variance. Secondly, the number of trees in the forest was set to 500, which is a sufficiently large number to ensure robust and stable predictions. Additionally, the number of random candidate variables to be entered at each split was optimized using the tuneRF function, which helps in selecting the optimal number of variables to consider for splitting at each node, further reducing the risk of overfitting.\n\nTo address the concern of underfitting, the model's performance was evaluated on a separate testing dataset consisting of 371,650 subscribers. The predicted outcomes were compared with the actual values, and the model demonstrated strong predictive ability with R\u00b2 values of 0.85 and 0.75 for utilization rate and annual expenditure, respectively. This indicates that the model was able to capture the underlying patterns in the data without being too simplistic.\n\nFurthermore, the model's performance varied across different types of healthcare facilities, with better accuracy for hospitals and health centers compared to clinics. This variability suggests that the model is sensitive to the differences in service utilization patterns across facility types, further supporting its robustness and generalizability.",
  "optimization/regularization": "In our study, we employed a random forest algorithm to construct prediction models for the number of outpatient visits and expenditure. Random forests inherently include a form of regularization through the process of building multiple decision trees and averaging their results. This method helps to prevent overfitting by reducing the variance of the predictions. Additionally, the random forest algorithm uses a technique called bagging (bootstrap aggregating), where each tree is trained on a different subset of the data, further enhancing its robustness and generalization capabilities. The number of trees was set at 500, and the number of random candidate variables to be entered was selected using the tuneRF function, which helps in optimizing the model's performance and preventing overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we utilized the random forest algorithm with 500 trees and selected the number of random candidate variables using the tuneRF function. The exact R script for our prediction model is provided in the supplementary material, which includes all necessary details for replication.\n\nThe model files themselves are not explicitly shared in the publication, but the methodology and parameters are thoroughly documented. This allows for the reconstruction of the model using the provided scripts and data processing steps.\n\nRegarding the availability and licensing, the supplementary material, including the R script, is accessible to readers. The data used in this study is de-identified and was accessed under an agreement with the National Health Security Office Region 13 Bangkok. Ethical approval was obtained from the Institutional Review Board for Clinical Research, National Center for Global Health and Medicine, and the Ethics Committee of Faculty of Medicine, Prince of Songkla University. While the specific licensing terms for the data are not detailed, the ethical approval and data usage agreements ensure compliance with regulatory standards.",
  "model/interpretability": "The model employed in this study is a random forest algorithm, which is generally considered a black-box model. Random forests are ensemble learning methods that operate by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees. This complexity makes it challenging to interpret the model's decisions in a straightforward manner.\n\nHowever, random forests do offer some level of interpretability through feature importance. Feature importance measures the contribution of each variable in the model's predictions. In our study, we included various subscriber attributes such as age, sex, underlying non-communicable diseases, and service utilization patterns as predictors. The random forest algorithm can rank these features based on their importance, providing insights into which factors most significantly influence the prediction of outpatient visits and expenditure.\n\nFor example, age and the presence of chronic diseases like hypertension and diabetes are likely to be among the most important features. This is because these factors are known to affect healthcare utilization and costs. By examining the feature importance, we can understand which subscriber attributes are crucial for predicting outpatient visits and expenditure, even though the exact decision-making process within the random forest remains opaque.\n\nAdditionally, partial dependence plots can be used to visualize the relationship between a specific feature and the predicted outcome, marginalizing over the values of all other features. This can help in understanding how changes in a particular feature affect the predictions, providing a more interpretable view of the model's behavior.\n\nIn summary, while the random forest model itself is a black-box, techniques like feature importance and partial dependence plots offer ways to gain insights into the model's decision-making process. These methods help in understanding which subscriber attributes are most influential in predicting outpatient visits and expenditure, thereby enhancing the interpretability of the model.",
  "model/output": "The model constructed in this study is a regression model, specifically designed to predict continuous outcomes. The primary outputs of the model are the incremental number of outpatient visits and expenditure in the subsequent fiscal year (FY2017) compared to the previous year (FY2016). These outcomes are predicted at the subscriber level using data from the training group, which includes various subscriber attributes from FY2016 as predictors.\n\nThe model utilizes a random forest algorithm, which is well-suited for regression tasks when dealing with a large number of predictors. The random forest approach helps in capturing complex relationships between the predictors and the outcomes, providing more accurate predictions compared to simpler regression models.\n\nThe predictions are made for two main outcomes: the number of outpatient visits and the total expenditure on outpatient services. These predictions are then aggregated to the facility level to calculate the predicted and actual number of visits and expenditure for each contracting unit to which subscribers are registered. The facility-level variables include the number of visits per subscriber (utilization rate) and the average expenditure per subscriber.\n\nThe model's performance is evaluated by comparing the predicted values with the actual values using correlation analysis. The results indicate that the model performs well for different types of healthcare facilities, including hospitals, clinics, and health centers. The prediction accuracy varies across facility types, with better performance observed for hospitals and health centers compared to clinics. This variation is attributed to the more uniform and predictable nature of services provided at public hospitals and health centers, as opposed to the heterogeneity observed in clinics.\n\nIn summary, the model is a regression model that predicts continuous outcomes related to outpatient visits and expenditure. It leverages a random forest algorithm to handle a large number of predictors and provides facility-level predictions that are compared with actual values to assess performance.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the prediction model is available. The R script used for the prediction is provided in the supplementary material accompanying the publication. This script utilizes the 'randomForest' package in R to conduct the random forest analyses. The specific version of R used is 3.4.0, and the version of the 'randomForest' package is 4.6\u201314. The script includes details on how the models were constructed using subscriber attributes from the previous fiscal year to predict outpatient visits and expenditure for the next year. The supplementary material can be accessed along with the publication, allowing others to replicate the analysis or adapt the model for their own use.",
  "evaluation/method": "The evaluation method involved constructing a prediction model using a random forest algorithm to forecast the number of outpatient visits and expenditure for the subsequent year based on subscriber data from the preceding year. The model was initially built using a 1% random sample of subscribers, which served as the training group. This model was then applied to a 10% random sample of the population, acting as the testing group. The results were aggregated based on the subscribers' registered facilities to predict the utilization rate and average expenditure for each facility in the following year.\n\nThe performance of the model was assessed by comparing the predicted outcomes with the actual data. The evaluation metrics included the coefficient of determination (R\u00b2), which measures the proportion of the variance in the dependent variable that is predictable from the independent variables. The R\u00b2 values for the models predicting facility-level utilization rate and expenditure per subscriber were 0.85 and 0.75, respectively. These values indicate a strong predictive performance, suggesting that the model can accurately forecast outpatient visits and expenditure.\n\nThe evaluation also considered the variability in model performance across different types of healthcare facilities. The model performed better for hospitals and health centers, with higher R\u00b2 values, while the performance was relatively lower for clinics. This variability is attributed to the more uniform and predictable nature of services provided at public hospitals and health centers compared to the heterogeneity observed in clinics.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our prediction model. The primary metrics reported include the number of outpatient visits and expenditure for outpatient services. These metrics were predicted for the fiscal year 2017 based on data from the previous year.\n\nWe aggregated the subscriber-level data into facility-level data to calculate the predicted and actual number of visits and expenditure for each contracting unit. This aggregation allowed us to assess the model's performance across different types of healthcare facilities, including hospitals, clinics, and health centers.\n\nKey performance metrics included:\n\n* The number of subscribers\n* Total visits\n* Utilization rate (number of outpatient visits per subscriber)\n* Total expenditure (in million baht)\n* Average expenditure per subscriber (in baht)\n\nThese metrics were compared between predicted and actual values to evaluate the model's accuracy. We used correlation analysis to compare the predicted utilization rate and average expenditure per subscriber with the actual values.\n\nThe overall prediction results at the facility level were accurate, with R\u00b2 values of 0.85 for utilization rate and 0.75 for annual expenditure. However, the accuracy varied across different types of facilities. The model performed better for hospitals and health centers, while the R\u00b2 was lower for clinics. This variation is likely due to the more uniform and predictable services provided at public hospitals and health centers compared to the more heterogeneous nature of clinics.\n\nOur set of metrics is representative of those used in similar studies in the literature. Previous research has also focused on predicting service utilization and expenditure using various demographic and health-related variables. By including diagnoses from transaction data and utilizing the chronic disease register, our study aligns with the methodologies employed in other countries, ensuring a comprehensive and comparable evaluation of our model's performance.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. However, we did conduct a preliminary analysis to compare the predictive ability of different modeling approaches. Specifically, we found that the random forest algorithm outperformed a simple regression model in predicting the number of visits and expenditure from the preceding fiscal year's information. This comparison was crucial given that machine learning methods, like random forest, are known to handle large numbers of predictors more effectively than traditional regression models, especially when the specification of the regression model is challenging.\n\nWhile we did not use benchmark datasets from other studies, our approach was informed by previous research that has utilized various predictors such as underlying disease, region, and socioeconomic status to refine prediction models. Our model incorporated different diagnoses recorded in the fiscal year 2016 to describe underlying conditions, leveraging both transaction data and the chronic disease register. This allowed for a detailed evaluation of the types of services provided to each subscriber, which is a strength of our study.\n\nIn summary, although we did not conduct a direct comparison with publicly available methods on benchmark datasets, our internal comparisons and the inclusion of comprehensive data sources provided a robust foundation for our predictive model. This approach ensured that our model was well-suited to the specific context of our study, focusing on the unique characteristics of the subscriber population in Bangkok.",
  "evaluation/confidence": "The evaluation of our prediction model focused on assessing its performance using specific metrics. We utilized the R-squared (R\u00b2) value to measure the goodness of fit for our predictions. The R\u00b2 values for utilization rate and annual expenditure were 0.85 and 0.75, respectively, indicating a strong predictive performance. However, the accuracy varied across different types of healthcare facilities. The model performed better for hospitals and health centers, with lower R\u00b2 values observed for clinics, suggesting more heterogeneity in clinic services.\n\nStatistical significance was not explicitly detailed in the performance metrics presented. While the R\u00b2 values provide a measure of how well the model explains the variance in the data, confidence intervals for these metrics were not reported. This omission means that the precision of these estimates and the statistical significance of the differences between predicted and actual values are not explicitly quantified.\n\nThe comparison with a simple regression model in a preliminary analysis showed that the random forest algorithm had better predictive ability. However, the specific statistical tests or confidence intervals for this comparison were not provided. Therefore, while the random forest model demonstrated superior performance in our preliminary analysis, the statistical significance of this superiority is not explicitly established.\n\nIn summary, while the performance metrics indicate strong predictive capabilities, the lack of reported confidence intervals and detailed statistical significance tests limits the ability to confidently claim the model's superiority over other methods and baselines. Further statistical analysis would be necessary to fully validate the model's performance and its advantages over alternative approaches.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data utilized in this research were obtained from the BKKNHSO database, which contains detailed health-care service information for UCS subscribers in Bangkok. This data includes subscriber demographics, service utilization details, and medical charges. Access to this data is restricted and was provided under an agreement with the BKKNHSO, ensuring the confidentiality and security of the information. The study was conducted in compliance with ethical guidelines and approved by the relevant institutional review boards. While the specific raw evaluation files are not released to the public, the methods and results of the study have been thoroughly documented in the publication. This includes descriptions of the data sources, variables used, and the statistical analyses performed. The R script for the prediction model is available in the supplementary material, allowing other researchers to replicate the analysis using their own datasets."
}