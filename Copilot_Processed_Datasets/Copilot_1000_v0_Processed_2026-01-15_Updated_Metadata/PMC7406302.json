{
  "publication/title": "Deep neural network analyses of spirometry for structural phenotyping of chronic obstructive pulmonary disease.",
  "publication/authors": "Bodduluri S, Nakhmani A, Reinhardt JM, Wilson CG, McDonald ML, Rudraraju R, Jaeger BC, Bhakta NR, Castaldi PJ, Sciurba FC, Zhang C, Bangalore PV, Bhatt SP",
  "publication/journal": "JCI insight",
  "publication/year": "2020",
  "publication/pmid": "32554922",
  "publication/pmcid": "PMC7406302",
  "publication/doi": "10.1172/jci.insight.132781",
  "publication/tags": "- COPD\n- Spirometry\n- Machine Learning\n- Deep Learning\n- Neural Networks\n- Random Forest\n- Structural Phenotypes\n- Chronic Obstructive Pulmonary Disease\n- Computed Tomography\n- Feature Importance\n- Monte-Carlo Cross-Validation\n- COPDGene Study\n- Pulmonary Function Testing\n- Predictive Modeling\n- Disease Classification",
  "dataset/provenance": "The dataset used in this study is derived from the COPDGene study, a large multicenter cohort study. This study includes current and former smokers aged between 45 and 80 years, with a smoking history of at least 10 pack-years. The COPDGene study has been previously published and is well-known in the community. The dataset consists of spirometry data from participants enrolled in the COPDGene study. The study population includes a substantial number of African Americans and women, providing a diverse sample for analysis. The dataset has been used to train and validate machine-learning models, including a deep neural network and a random forest classifier, to identify structural phenotypes of COPD from spirometry data. The performance of these models was evaluated on a hold-out test dataset, ensuring the robustness of the findings. The COPDGene study has been approved by the Institutional Review Boards of all participating clinical centers, ensuring ethical standards and participant consent.",
  "dataset/splits": "The dataset was divided into three main splits: training, validation, and test sets. The expiratory flow data was initially split into an input set (80%) and a hold-out test set (20%). The input set was further divided into 10 random splits of training (80%) and validation (20%) to train the fully convolutional network (FCN) model. Each expiratory flow-volume curve was standardized to have a length of 200 points using data padding with zeros at the end of the sequence. The test set consisted of 1796 participants, with the distribution as follows: 617 participants (34.3%) were classified as normal, 641 participants (35.6%) had predominant airway disease, 278 participants (15.4%) had emphysema predominant disease, and 260 participants (14.4%) had a mixed phenotype. The training and validation splits were used to optimize the model's hyperparameters and prevent overfitting, while the hold-out test set was used for final evaluation to ensure the model's robustness and generalizability.",
  "dataset/redundancy": "The dataset used in this study was derived from the COPDGene study, which includes spirometry data from participants who are current and former smokers aged between 45 and 80 years, with a smoking history of at least 10 pack-years. The dataset was split into training and test sets to evaluate the performance of the models. The training of the neural network and subsequent hyperparameter optimization was performed over 10 replications of Monte-Carlo cross-validation to ensure the robustness of the model. This cross-validation technique helps in reducing overfitting and provides a more reliable estimate of model performance.\n\nThe final evaluation of the classifier was performed on a hold-out test dataset, which was not seen by the model previously. This ensures that the training and test sets are independent, providing an unbiased evaluation of the model's performance. The hold-out test dataset consisted of 20% of the cohort, with 1796 participants. The distribution of participants in the test set was as follows: 617 participants (34.3%) were normal, 641 participants (35.6%) had predominant airway disease, 278 participants (15.4%) had emphysema-predominant disease, and 260 participants (14.4%) had a mixed phenotype.\n\nThe use of a hold-out test set and Monte-Carlo cross-validation ensures that the results are generalizable and not specific to a particular split of the data. This approach is consistent with best practices in machine learning and provides a robust evaluation of the models' performance. The distribution of the dataset compares favorably with previously published machine learning datasets in the medical domain, ensuring that the findings are relevant and applicable to similar studies.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a fully convolutional network (FCN), which is a type of deep neural network. This algorithm is not entirely new, as FCNs have been previously applied in various domains, including medical imaging. However, our application of FCNs to spirometry data for classifying structural phenotypes of COPD is novel and represents a unique contribution to the field.\n\nThe reason this work was not published in a machine-learning journal is that the primary focus of our study is on clinical medicine, specifically the identification and classification of COPD phenotypes using spirometry data. The machine-learning aspects of our work are secondary to the clinical applications and insights gained. Our study aims to demonstrate the potential of deep learning and machine-learning approaches to improve COPD outcomes by identifying individuals for targeted therapies. The clinical relevance and potential impact on patient care are the main drivers for publishing in a clinical medicine journal.\n\nAdditionally, the optimization of the FCN involved techniques such as Monte-Carlo cross-validation and hyperparameter tuning, which are standard practices in machine learning. The learning rate was adjusted during training to ensure optimal performance. These methods are well-established and have been applied to ensure the robustness and generalizability of our model. The comparison with other machine-learning algorithms, such as the random forest classifier, further validates the effectiveness of our approach in the context of COPD phenotype classification.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on spirometry data from participants enrolled in the COPDGene study. The training of the neural network and subsequent hyperparameter optimization was performed over 10 replications of Monte-Carlo cross-validation to ensure robustness. The final evaluation of the classifier was conducted on a hold-out test data set, which was not previously seen by the model. This approach ensures that the training data is independent from the test data, maintaining the integrity of the model's performance evaluation. The study focuses on using deep learning and machine-learning approaches to identify structural phenotypes of COPD from spirometry data, demonstrating their potential to identify individuals for targeted therapies.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved minimal requirements. The spirometry data, which consists of a sequence of raw data points, was used directly as input for the models. This approach eliminated the need for extensive preprocessing and feature crafting before classification. The fully convolutional network (FCN) model, in particular, benefited from this minimal preprocessing, as it could handle the sequential or time series nature of the spirometry data effectively. The FCN model included convolution operations followed by batch normalization and ReLU activation layers, which helped in extracting relevant features from the raw data. A global average pooling layer was then applied to reduce the number of training parameters and to enable the visualization of class activations specific to each structural phenotype of COPD. This encoding and preprocessing strategy allowed the FCN to perform well in classifying the structural phenotypes from spirometry data. Additionally, the random forest classifier, which was also used, relied on decision points and avoided correlated points, further demonstrating the effectiveness of using raw data sequences for classification tasks in this medical domain.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the specific machine learning approach employed. For the fully connected network (FCN), the architecture and thus the number of parameters were determined through a process of hyperparameter optimization. This involved reducing the learning rate by a factor of 0.01 after 15 epochs of no decline in the validation loss, ensuring that the model converged effectively.\n\nFor the random forest model, the parameters were chosen through 5-fold cross-validation, with the model exhibiting the minimum out-of-the-bag error being selected. This method ensured that the model was robust and generalizable to unseen data.\n\nThe neural network underwent training and hyperparameter optimization over 10 replications of Monte-Carlo cross-validation. This rigorous process aimed to enhance the model's robustness and reliability. The final evaluation was conducted on a hold-out test dataset, which the model had not previously seen, further validating its performance.\n\nThe selection of parameters was guided by the need to balance model complexity and performance, ensuring that the models could accurately classify participants into one of the four structural disease categories based on quantitative CT data. The use of cross-validation techniques helped in mitigating overfitting and underfitting biases, thereby improving the models' discriminative accuracy.",
  "optimization/features": "The input features for the model consist of the flow data points in each expiratory flow-volume curve. These data points are used as a 1D input sequence, with each sequence standardized to have a length of 200 points through data padding with zeros at the end of the sequence.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the model leverages the raw spirometry data directly, minimizing the need for extensive preprocessing or feature crafting. This approach allows the fully convolutional network (FCN) to act as a feature extractor, identifying relevant patterns within the sequential data.\n\nThe hyperparameter tuning process, which included evaluating various combinations of filters, learning rates, and batch sizes, was conducted using the training set. This ensured that the model's performance was optimized based on the training data alone, without any information leakage from the hold-out test set. The final model was selected based on its performance on the validation set, which was part of the training process, ensuring that the evaluation remained unbiased.",
  "optimization/fitting": "The fitting method employed in this study utilized a fully convolutional network (FCN) and a random forest classifier, both of which were subjected to rigorous optimization processes to ensure robustness and generalizability.\n\nThe FCN architecture was designed with convolutional blocks that perform convolution operations followed by batch normalization and ReLU activation layers. This design helps in reducing the number of training parameters significantly, which is crucial when dealing with a large number of parameters relative to the number of training points. The global average pooling layer further reduces the number of parameters, making the model more efficient and less prone to overfitting.\n\nTo address the potential issue of overfitting, the training process involved 10 replications of Monte-Carlo cross-validation. This technique ensures that the model's performance is evaluated across multiple splits of the data, providing a more reliable estimate of its generalization capability. Additionally, the learning rate was dynamically adjusted during training, reducing it by a factor of 0.01 after 15 epochs of no decline in validation loss. This adaptive learning rate helps in fine-tuning the model and preventing it from overfitting to the training data.\n\nThe final evaluation of the classifier was performed on a hold-out test dataset, which the model had not seen previously. This hold-out set served as an independent validation of the model's performance, ensuring that the results were not merely a product of overfitting to the training data.\n\nFor the random forest classifier, parameters were chosen through 5-fold cross-validation, and the model with the minimum out-of-the-bag error was selected. This approach helps in identifying the optimal set of parameters that minimize the risk of both overfitting and underfitting. The random forest's reliance on decision points and avoidance of correlated points further contribute to its robustness and generalizability.\n\nIn summary, the fitting method involved careful design and optimization of the FCN and random forest models, along with extensive cross-validation and hold-out testing. These steps collectively ensured that the models were neither overfitted nor underfitted, providing reliable and generalizable results.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method was the reduction of the learning rate by a factor of 0.01 after 15 epochs of no decline in the validation loss. This approach helped to fine-tune the model and prevent it from overfitting to the training data.\n\nAdditionally, we utilized Monte-Carlo cross-validation over 10 replications during the training of the neural network. This technique involved repeatedly splitting the data into training and validation sets, which helped to assess the model's performance across different subsets of the data and reduce the risk of overfitting.\n\nFor the random forest classifier, we chose parameters through 5-fold cross-validation and selected the model with the minimum out-of-the-bag error. This method ensured that the model generalized well to unseen data by evaluating its performance on multiple folds of the data.\n\nFurthermore, we evaluated the final model performance on a hold-out test dataset that was not seen by the model during training. This step provided an unbiased estimate of the model's performance and helped to confirm that the models were not overfitting to the training data.",
  "optimization/config": "The hyperparameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the learning rate was adjusted by a factor of 0.01 after 15 epochs of no decline in validation loss. The training process of the fully convolutional network (FCN) is visualized in Supplemental Figure 4, which provides insights into the chosen hyperparameters for classifying spirometry data into different structural COPD phenotypes.\n\nThe parameters and weights of the model with the minimum validation loss for the neural network and the minimum out-of-the-bag error for the random forest were selected from 10 replications of Monte-Carlo cross-validation. These parameters were then used to evaluate model performance on a held-out test set, ensuring robustness and generalizability.\n\nRegarding the availability of model files and optimization parameters, the specific details are not provided in the main text. However, the methods and results are thoroughly described, allowing for replication of the study's findings. The supplemental materials, including figures and additional methods, are accessible online, providing further transparency into the optimization process.\n\nThe study was conducted using Python \u2265 3.0, R version \u2265 3.6.0, and MedCalc Statistical Software, which are widely available and commonly used in the scientific community. The use of these tools ensures that the methods and results can be reproduced by other researchers.\n\nIn summary, while the exact model files and optimization parameters are not explicitly shared, the detailed description of the hyperparameter configurations, optimization schedule, and the use of standard software tools provide a clear path for replication and further research.",
  "model/interpretability": "The model employed in this study is primarily a deep neural network, specifically a fully convolutional network (FCN), which is known for its black-box nature. This means that the internal workings of the model are not easily interpretable, and it can be challenging to understand how specific inputs influence the outputs. However, efforts were made to enhance interpretability through the use of SHapley Additive exPlanation (SHAP) values. SHAP values help in identifying the importance of different features in the model's predictions, providing some insight into which aspects of the input data are most influential. This approach allows for a better understanding of the model's decision-making process, although it does not fully eliminate the black-box nature of the FCN. Additionally, the study compared the FCN with a random forest classifier, which relies on decision points and is generally more interpretable than neural networks. The random forest model's performance was nearly on par with the FCN, suggesting that other machine-learning algorithms could also be effective and potentially more interpretable for similar tasks.",
  "model/output": "The model discussed in this publication is designed for classification tasks. Specifically, it focuses on classifying participants into one of four structural disease categories based on quantitative CT scans. The primary outcome of the model is to categorize individuals into normal, predominant airway disease, emphysema predominant disease, or a mixed phenotype. The model's performance is evaluated using metrics such as the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and the F1 score. These metrics are crucial for assessing the model's ability to accurately classify different structural phenotypes related to emphysema and airway disease. The neural network model, in particular, demonstrated superior performance compared to traditional spirometry measures and other classifiers like the random forest. The AUC for the neural network was 0.80, indicating strong discriminative accuracy. Additionally, the neural network achieved a higher F1 score of 0.56, which balances precision and recall, further highlighting its effectiveness in classification tasks. The model's architecture, including convolutional operations and global average pooling, is tailored to handle sequential or time-series data, making it well-suited for classifying spirometry curves. Overall, the model's primary function is to classify structural phenotypes accurately, providing valuable insights into respiratory health.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed for the study involved a robust approach to ensure the reliability and generalizability of the results. The training of the neural network and subsequent hyperparameter optimization was conducted over 10 replications of Monte-Carlo cross-validation. This technique helps in assessing the model's performance and stability by repeatedly splitting the data into training and validation sets in a random manner.\n\nFollowing the cross-validation process, the final evaluation of the classifier was performed on a hold-out test dataset. This dataset was not seen by the model during the training phase, providing an unbiased assessment of the model's performance. The hold-out test dataset ensures that the model's ability to generalize to new, unseen data can be accurately evaluated.\n\nIn addition to the hold-out test dataset, the performance of the fully convolutional network (FCN) was compared with an optimized random forest model. The random forest model's parameters were chosen through 5-fold cross-validation, and the model with the minimum out-of-the-bag error was selected. This comparison allowed for a thorough evaluation of the FCN's effectiveness relative to a well-established machine-learning technique.\n\nThe discriminative accuracies of the FCN and the random forest classifier were also compared with traditional spirometry measurements, specifically FEV1/FVC and FEV1% predicted, using logistic regression. Various metrics, including sensitivity, specificity, Youden index, and F1 score, were tested for each model to provide a comprehensive evaluation of their performance in classifying structural disease.\n\nThe nonparametric DeLong test was used to compare the area under the curve (AUC) between the models, with a 2-tailed P value of less than 0.05 considered significant. This statistical test helps in determining whether the differences in AUC values between the models are statistically significant.\n\nThe analyses were performed using a combination of Python (version \u2265 3.0), R (version \u2265 3.6.0), and MedCalc Statistical Software, ensuring the use of robust and widely accepted tools for data analysis.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report several key metrics to evaluate the performance of our models. These include the Area Under the Curve (AUC) with 95% Confidence Intervals (CI), sensitivity, specificity, and the Youden index. The AUC is a crucial metric that provides an aggregate measure of performance across all classification thresholds. Sensitivity, also known as recall or true positive rate, measures the proportion of actual positives correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives correctly identified. The Youden index, calculated as sensitivity plus specificity minus one, offers a single statistic that captures the performance of a diagnostic marker.\n\nAdditionally, we report the \u0394 AUC, which indicates the difference in AUC compared to a reference model. This allows for a direct comparison of the performance improvements or declines relative to a baseline model. The metrics are computed for various models, including traditional spirometry variables like FEV1/FVC and FEV1% predicted, as well as more advanced models like the Fully Convolutional Network (FCN) and random forest classifiers.\n\nThese performance metrics are widely used in the literature for evaluating classification models, particularly in medical diagnostics. They provide a comprehensive view of model performance, covering aspects of both true positive and true negative predictions. The inclusion of the Youden index is particularly useful as it summarizes the performance into a single value, making it easier to compare different models. The reporting of 95% CIs for these metrics ensures that the results are statistically robust and provides insight into the reliability of the estimates. Overall, the set of metrics reported is representative of standard practices in the field and allows for a thorough evaluation of the models' diagnostic capabilities.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of our fully convolutional network (FCN) with both traditional spirometry metrics and a machine-learning baseline, specifically an optimized random forest classifier. This comparison was crucial to assess the performance and generalizability of our model.\n\nFor the traditional spirometry metrics, we used FEV1/FVC and FEV1% predicted, which are standard measurements in pulmonary function testing. These metrics were evaluated using logistic regression to classify participants into structural disease categories based on quantitative CT scans. The performance of these traditional metrics was compared against our FCN and the random forest classifier using several statistical measures, including the area under the curve (AUC), sensitivity, specificity, Youden index, and F1 score.\n\nThe random forest classifier was chosen as a simpler baseline because it is a well-established machine-learning algorithm known for its robustness and ability to handle high-dimensional data. The parameters for the random forest model were optimized using 5-fold cross-validation, and the model with the minimum out-of-the-bag error was selected. This ensured that the random forest classifier was tuned to perform optimally on the same input sequences used by the FCN.\n\nTo ensure a fair comparison, all models were evaluated on the same hold-out test dataset, which had not been seen by the models during training. This approach helped to mitigate overfitting and provided a more accurate assessment of each model's performance.\n\nThe results of these comparisons are presented in the tables and figures within the publication. The AUC analyses, sensitivity, specificity, Youden index, and F1 score for each model were computed to evaluate their discriminative accuracies. Additionally, the nonparametric DeLong test was used to compare the AUCs between the models, with a 2-tailed P value of < 0.05 considered significant.\n\nIn summary, our evaluation included a thorough comparison with both traditional spirometry metrics and a simpler machine-learning baseline. This approach allowed us to demonstrate the effectiveness of our FCN in classifying structural disease categories based on spirometry data.",
  "evaluation/confidence": "The evaluation of our models includes several performance metrics, each accompanied by confidence intervals to provide a range within which the true value is likely to lie. These metrics include the area under the curve (AUC), sensitivity, specificity, and the Youden index. The confidence intervals offer a measure of the precision of these estimates, allowing for a more nuanced understanding of the model's performance.\n\nTo determine the statistical significance of our results, we employed the DeLong test. This nonparametric test is specifically designed to compare the AUCs of different models, providing a robust statistical framework for assessing whether the observed differences in performance are likely to be due to chance or represent a genuine superiority of one model over another. A two-tailed P value of less than 0.05 was considered significant, ensuring that our claims of superior performance are supported by strong statistical evidence.\n\nIn addition to the DeLong test, we also computed sensitivity, specificity, and the Youden index for each model. The Youden index, in particular, is a useful metric for evaluating the overall performance of a diagnostic test, as it takes into account both sensitivity and specificity. By comparing these metrics across different models, we were able to identify which models provided the best balance of true positive and true negative rates.\n\nOverall, the inclusion of confidence intervals and the use of the DeLong test for statistical significance provide a comprehensive evaluation of our models' performance. These methods ensure that our conclusions are not only based on point estimates but are also supported by a rigorous statistical analysis, enhancing the reliability and validity of our findings.",
  "evaluation/availability": "Not enough information is available."
}