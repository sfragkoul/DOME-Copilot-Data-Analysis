{
  "publication/title": "Introducing a machine learning algorithm for delirium prediction-the Supporting SURgery with GEriatric Co-Management and AI project (SURGE-Ahead).",
  "publication/authors": "Benovic S, Ajlani AH, Leinert C, Fotteler M, Wolf D, Steger F, Kestler H, Dallmeier D, Denkinger M, Eschweiler GW, Thomas C, Kocar TD",
  "publication/journal": "Age and ageing",
  "publication/year": "2024",
  "publication/pmid": "38776213",
  "publication/pmcid": "PMC11110913",
  "publication/doi": "10.1093/ageing/afae101",
  "publication/tags": "- Machine Learning\n- Delirium Prediction\n- Postoperative Delirium\n- Linear SVM\n- Clinical Prediction\n- Model Validation\n- Feature Selection\n- Medical Data Analysis\n- Patient Outcomes\n- Healthcare AI\n- Surgical Procedures\n- Elderly Patients\n- Predictive Modeling\n- Medical Ethics\n- Bias in AI",
  "dataset/provenance": "The dataset used in this study was collected from the PAWEL-R study. The study population consisted of 878 patients, with a mean age of 77.8 years. The dataset included various features such as ASA score, multimorbidity, cut-to-suture time, estimated glomerular filtration rate, polypharmacy, use of cardio-pulmonary bypass, MoCA subscores, pre-existing dementia, clinical frailty score, age, recent falls, post-operative isolation, and pre-operative benzodiazepines.\n\nThe PAWEL-R study was the primary source of data for this analysis. The dataset was preprocessed to include only those variables that were also available in the SURGE-Ahead dataset. Missing values were handled by replacing them with the mean for continuous variables and the median for discrete and categorical variables, based on the training data. Continuous and discrete variables were z-transformed using the training data as a reference, while categorical variables were one-hot encoded to binary variables.\n\nThe dataset was randomly split into a training set and a test set with a 4:1 ratio. The training set was used to train the machine learning models, while the test set was used to evaluate their performance. The final model was determined by the better ROC AUC in the test set. The study population characteristics are summarized in Table 1, and further details about the dataset can be found in the PAWEL-R study and the PAWEL trial study protocol.",
  "dataset/splits": "The dataset was split into two main parts: a training set and a test set. The data was randomly divided with a 4:1 ratio, resulting in approximately 709 data points in the training set and 169 data points in the test set. This split was done to ensure that the model could be trained on a substantial amount of data while still having a separate set to evaluate its performance. The random split helps to maintain the generalizability of the model by ensuring that the test set is representative of the overall dataset.",
  "dataset/redundancy": "The dataset used for the machine learning models consisted of data from 878 patients, with a mean age of 77.8 years. The primary endpoint, postoperative delirium (POD), occurred in 209 cases (23.8%), with 171 cases in the training set. The data were randomly split into a training set and a test set with a 4:1 ratio, ensuring that the training and test sets were independent. This split was enforced by randomly assigning patients to either the training or test set, maintaining the integrity of the data distribution.\n\nThe dataset underwent preprocessing to handle missing values, which were replaced by the mean for continuous variables and the median for discrete and categorical variables, as defined by the training data. Continuous and discrete variables were z-transformed using the training data as a reference, and categorical variables were one-hot encoded to binary variables.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the field, ensuring a robust and reliable model training process. The features included in the models were selected based on their availability in both the PAWEL-R study and the SURGE-Ahead dataset, ensuring consistency and reliability in the feature set. The features included ASA score, multimorbidity, cut-to-suture time, estimated glomerular filtration rate, polypharmacy, use of cardio-pulmonary bypass, MoCA subscores, preexisting dementia, clinical frailty score, age, recent falls, post-operative isolation, and pre-operative benzodiazepines. This careful selection and preprocessing of the dataset ensured that the models were trained on high-quality, relevant data, enhancing their performance and generalizability.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used were logistic regression (LR) and a linear support vector machine (SVM). Both models were implemented using the liblinear library. The choice of linear models was driven by the preference for robustness, transparency, and explainability over the slightly better performance that non-linear models might offer.\n\nThe algorithms employed are not new; they are well-established methods in the field of machine learning. The linear SVM was ultimately chosen as the final model due to its performance metrics. The decision to use these specific algorithms was influenced by the need for a model that could be easily interpreted and validated, which is crucial in a clinical setting.\n\nThe focus of this study was on the application of these algorithms to predict postoperative delirium (POD) rather than on the development of new machine-learning techniques. Therefore, the algorithms were not published in a machine-learning journal but rather in a medical research publication, where the clinical relevance and practical application of the models are of primary interest.",
  "optimization/meta": "The model described does not use data from other machine-learning algorithms as input. It is not a meta-predictor. Instead, it directly uses clinical features from patient data. The features included in the model are ASA score, multimorbidity, cut-to-suture time, estimated glomerular filtration rate, polypharmacy, use of cardio-pulmonary bypass, MoCA subscores for memory, orientation, and verbal fluency, preexisting dementia, clinical frailty score, age, recent falls, post-operative isolation, and pre-operative benzodiazepines.\n\nThe model training process involved using the scikit-learn library for Python, version 1.2.2, to train two machine learning models on the training set: a logistic regression (LR) and a linear support vector machine (SVM). Both models used the liblinear implementation. The SVM applied a class weight to account for the geometric properties of the hinge loss function, scaling its loss inversely proportional to the frequency of the respective class. No imbalance correction was performed for the LR to avoid performance loss and miscalibration.\n\nThe L2 regularization hyperparameter C was chosen from a range of 17 values between 2^-8 and 2^8, evenly spaced on a logarithmic scale, through leave-one-out cross-validation optimizing for accuracy. The 'max_iter' hyperparameter was set to 10^9 to ensure convergence. For the remaining hyperparameters, the default values from the scikit-learn library were used. After training, the SVM was calibrated to the training data using Platt Scaling. The final model was determined by the better ROC AUC in the test set.",
  "optimization/encoding": "For the machine-learning algorithm, data preprocessing involved several steps to ensure compatibility and optimal performance. Initially, only variables present in both the PAWEL and SURGE-Ahead datasets were considered. Polypharmacy was assessed by counting the number of long-term medications. A comorbidity score was calculated using the Charlson Comorbidity Index, which assigns values to various pre-existing conditions such as myocardial infarction, congestive heart failure, and dementia.\n\nThe glomerular filtration rate (eGFR) was estimated using the Cockcroft-Gault method. The dataset was then randomly split into training and test sets with a 4:1 ratio. Missing values, which constituted 0.7% of the data, were imputed using the mean for continuous variables and the median for discrete and categorical variables, based on the training data. Continuous and discrete variables were z-transformed using the training data as a reference. Categorical variables were one-hot encoded to convert them into binary variables.\n\nThese preprocessing steps ensured that the data was standardized and ready for input into the machine-learning models, facilitating accurate and reliable predictions.",
  "optimization/parameters": "The model utilizes 15 input parameters. The selection of these parameters was guided by a focus on features that are either routinely assessed during admission or associated with minimal additional cost in terms of time and resources. The feature selection process aimed to balance information gain and data acquisition complexity. Initially, a set of 23 candidate features was considered, but this was reduced to 15 through a recursive feature elimination process. This process involved training both a logistic regression (LR) and a support vector machine (SVM) model and selecting features based on their coefficients and general selection criteria. The final set of 15 features includes variables such as ASA score, multimorbidity, cut-to-suture time, estimated glomerular filtration rate, polypharmacy, use of cardio-pulmonary bypass, MoCA subscores, pre-existing dementia, clinical frailty score, age, recent falls, post-operative isolation, and pre-operative benzodiazepines. This approach ensured that the model remains robust, transparent, and ethically sound, aligning with the principles emphasized during feature selection and model training.",
  "optimization/features": "The optimization process for our delirium prediction model involved a careful selection of input features. Initially, we considered a set of 23 candidate features, which were chosen based on previous machine learning models, literature reviews, and expert domain knowledge. These features included a mix of demographic, clinical, and surgical variables.\n\nTo ensure the robustness and explainability of our model, we limited the number of features to 15. This decision was made to balance information gain and the complexity of data acquisition, thereby avoiding the Hughes effect despite the pronounced class imbalance. The feature selection process was conducted using the training set only, ensuring that the model's performance on the test set remained unbiased.\n\nDuring the feature selection process, we eliminated three features due to data quality issues, two due to low variance, and one due to collinearity. The remaining 17 features underwent recursive feature elimination, training both a logistic regression (LR) and a linear support vector machine (SVM) model. We selected features based on their coefficients in both models, ensuring that the final set of 15 features was both informative and reliable.\n\nThe final model includes features such as the American Society of Anesthesiologists (ASA) score, multimorbidity, cut-to-suture time, estimated glomerular filtration rate, polypharmacy, use of cardio-pulmonary bypass, and various subscores from the Montreal Cognitive Assessment (MoCA). These features were chosen for their relevance to delirium prediction and their routine assessment in clinical settings, making the model practical for implementation.",
  "optimization/fitting": "The study utilized a dataset from 878 patients, with 15 features selected for the model. This results in a high sample-to-feature ratio, which is unlikely to trigger the Hughes effect despite the pronounced class imbalance. The feature selection process was designed to balance information gain and complexity, ensuring that the number of features was limited to 15. This approach helps in mitigating over-fitting, as a high sample-to-feature ratio generally indicates that the model is less likely to over-fit the training data.\n\nTo further address over-fitting, a leave-one-out cross-validation was employed to optimize the L2 regularization hyperparameter C. This method helps in selecting the best hyperparameter that generalizes well to unseen data, reducing the risk of over-fitting. Additionally, the model's performance was evaluated on a separate test set, which provided an independent assessment of its generalization capability.\n\nUnder-fitting was addressed by ensuring that the models were sufficiently complex to capture the underlying patterns in the data. The use of linear models, specifically logistic regression (LR) and linear support vector machine (SVM), was chosen for their robustness, transparency, and explainability. These models are less prone to under-fitting compared to more complex, non-linear models. The decision to use linear models was also supported by the fact that they provided good performance metrics, as evidenced by the ROC AUC scores in both the training and test sets.\n\nThe final model, a linear SVM, was selected based on its superior performance in terms of ROC AUC compared to the LR model. The linear SVM was calibrated using Platt Scaling to improve its probability estimates, further enhancing its predictive accuracy. The model's performance was thoroughly evaluated using metrics such as ROC AUC, F1 score, sensitivity, and specificity, along with their 95% confidence intervals determined by bootstrapping. This comprehensive evaluation ensures that the model is neither over-fitted nor under-fitted, providing reliable predictions for postoperative delirium.",
  "optimization/regularization": "In our study, we employed regularization techniques to prevent overfitting. Specifically, we used L2 regularization for both the logistic regression (LR) and the linear support vector machine (SVM) models. The L2 regularization hyperparameter, denoted as C, was carefully selected from a range of 17 values between 2^-8 and 2^8. These values were evenly spaced on a logarithmic scale and optimized through leave-one-out cross-validation, with the goal of maximizing accuracy. This approach helped to balance the trade-off between fitting the training data well and generalizing to unseen data, thereby mitigating the risk of overfitting. Additionally, we ensured convergence by setting the 'max_iter' hyperparameter to 10^9, which allowed the models to adequately learn from the training data without premature termination.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we utilized the scikit-learn library for Python, version 1.2.2, to train two machine learning models: a Logistic Regression (LR) and a linear Support Vector Machine (SVM), both implemented using the liblinear library. The L2 regularization hyperparameter C was selected from a range of 17 values between 2^-8 and 2^8, evenly spaced on a logarithmic scale, through leave-one-out cross-validation optimized for accuracy. The 'max_iter' hyperparameter was set to 10^9 to ensure convergence. For the SVM, a class weight was applied to scale the loss inversely proportional to the frequency of the respective class. The final model was determined by the better ROC AUC in the test set.\n\nThe Platt Scaling parameters, which were used to calibrate the SVM to the training data, are reported. Additionally, the coefficients of the final model are provided, allowing for the reconstruction of the delirium prediction model. The decision function z, which is the dot-product of the preprocessed features and the coefficients, is also detailed. This information is sufficient to rebuild the model using the provided coefficients and Platt Scaling parameters.\n\nThe model files and optimization parameters are not explicitly hosted online, but all necessary details for replication are included in the publication and supplementary materials. The supplementary data mentioned in the text are available to subscribers online. The publication adheres to standard academic practices, ensuring that the methods and results are reproducible by other researchers.",
  "model/interpretability": "The model employed in this study is not a blackbox but rather transparent and highly explainable. This transparency is achieved through the use of linear models, specifically logistic regression (LR) and a linear support vector machine (SVM). In these models, the contribution of each input feature to the model\u2019s prediction can be determined by the element-wise product of the feature vector and the parameter vector. This product results in a scalar with a specific magnitude and sign. A positive scalar indicates a higher risk of delirium, while a negative scalar indicates a lower risk.\n\nFor instance, in the linear SVM, the individual feature importance is calculated through the element-wise multiplication of the coefficient and feature vectors. This allows for the representation of individual feature importance in numerical terms, where positive numbers signify a higher risk of delirium and negative numbers a lower risk. This approach enables the display of features that are important for a particular prediction, making the model's decisions understandable.\n\nFurthermore, the distribution of these feature importance scalars in the test set is presented in a boxplot, providing insights into how certain features have influenced the outcome of individual predictions. Features such as cut-to-suture time, ASA score, and MoCA orientation score generally contribute most to the individual predictions. This transparency is crucial for sustaining awareness of the importance of experience-based clinical knowledge in navigating complex human interactions.\n\nThe model's transparency also facilitates the targeted use of delirium prevention interventions among those at high risk, aligning with the medico-ethical principle of justice. Additionally, the model has been screened for potential biases related to sex and native language, ensuring that it does not disadvantage patients based on these factors. The demographic of the training data is representative of the target population, further enhancing the model's reliability and fairness.",
  "model/output": "The model is a classification model. It predicts the occurrence of postoperative delirium (POD) using a linear Support Vector Machine (SVM) algorithm. The output of the model is a decision function, denoted as z, which is a linear combination of the input features multiplied by their respective coefficients. This decision function is then mapped to a probability for delirium using Platt Scaling. If the decision function z is positive, the model predicts the presence of delirium. The model's performance is evaluated using metrics such as ROC AUC, F1 score, sensitivity, and specificity, indicating its effectiveness in classifying patients as likely or unlikely to experience POD.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the delirium prediction model involved several rigorous steps to ensure its robustness and generalizability. An internal-external cross-validation was conducted at the center level, where the model was fitted to all but one center and tested on the held-out center. This approach helped to assess the model's performance across different settings. The weighted average ROC AUC was 0.82 in the training set and 0.76 in the test set, indicating good discriminative ability.\n\nAdditionally, an external validation is planned using data from an observational study within the SURGE-Ahead project, which is expected to conclude in early 2024. This will further evaluate the model's performance on external data, addressing the common issue of performance metrics dropping significantly when tested on new datasets.\n\nThe model was calibrated to the entire sample, but it is acknowledged that the prevalence of delirium varies across different settings. Future calibrations for specific settings are considered to enhance the model's applicability. The dataset used, the PAWEL cohort, included only data from Germany, which might introduce racial bias, and only elective surgical procedures, potentially excluding frailer individuals. These limitations are noted, and efforts are being made to address them.\n\nThe features used by the model include some that might be time-intensive for routine clinical practice, such as the MoCA subscores. A modified version of the MoCA, requiring approximately 5 minutes, has been proposed to mitigate this issue. Most features, however, are routine data that can be extracted from electronic medical records using an automated pipeline, which is part of the SURGE-Ahead project.\n\nThe model's ability to handle missing data by using the median or mean of the training data was also evaluated, although this comes at the cost of some accuracy. For pre-operative delirium prediction, the cut-to-suture time is not available and must be estimated. Post-operatively, the prediction can be updated using the actual cut-to-suture time.\n\nThe study also considered the potential for better performance metrics with more samples or non-linear models. While non-linear models like neural networks and XGBoost showed slightly better performance in other studies, the current study favored the robustness, transparency, and explainability of linear models. The final model chosen was a linear SVM, which provided an ROC AUC of 0.81 in the test set, demonstrating its effectiveness in predicting post-operative delirium.",
  "evaluation/measure": "In our study, we reported several key performance metrics to evaluate the effectiveness of our delirium prediction model. The primary metric used was the Receiver Operating Characteristic Area Under the Curve (ROC AUC), which provides a comprehensive measure of the model's ability to distinguish between patients who will develop postoperative delirium (POD) and those who will not. The ROC AUC was reported for both the training and test sets, with values of 0.82 and 0.81, respectively. These values indicate strong discriminative power.\n\nAdditionally, we reported the F1 score, which is the harmonic mean of precision and recall, offering a balance between these two metrics. The F1 scores were 0.58 in the training set and 0.54 in the test set. Sensitivity, also known as recall or true positive rate, was reported as 0.71 in the training set and 0.68 in the test set, indicating the model's ability to correctly identify patients who will develop POD. Specificity, or the true negative rate, was 0.76 in both the training and test sets, showing the model's ability to correctly identify patients who will not develop POD.\n\nThese metrics are representative of those commonly reported in the literature for clinical prediction models. The ROC AUC is widely used due to its robustness in evaluating model performance across different thresholds. The F1 score is particularly useful when dealing with imbalanced datasets, as is often the case in medical research. Sensitivity and specificity provide crucial insights into the model's clinical utility, ensuring that it can accurately identify both positive and negative cases. Together, these metrics offer a comprehensive evaluation of our model's performance, aligning with established standards in the field.",
  "evaluation/comparison": "A comparison to simpler baselines was performed, favoring the robustness, transparency, and explainability of linear models over the slightly better performance of non-linear models. While non-linear models like neural networks and XGBoost achieved higher ROC AUC scores, the chosen linear SVM model was selected for its advantages in these areas. This decision aligns with the conceptual framework of medico-ethical principles and guidelines for algorithmic design, emphasizing transparency, explainability, and flexibility/robustness.\n\nThe linear SVM model was chosen as the final model, demonstrating good performance with an ROC AUC of 0.82 in the training set and 0.81 in the test set. The model's features are commonly assessed during admission, making it practical for routine clinical use. The decision to use a linear model was influenced by the desire to create a tool that is not only accurate but also understandable and reliable in various clinical settings.\n\nThe comparison to simpler baselines highlights the trade-off between performance and interpretability. While non-linear models may offer marginally better predictive power, the linear SVM model provides a balance that is crucial for clinical applications, where transparency and explainability are paramount. This approach ensures that the model can be easily understood and trusted by healthcare professionals, facilitating its integration into clinical practice.",
  "evaluation/confidence": "The evaluation of our model includes performance metrics with confidence intervals, providing a range within which the true performance is likely to fall. For instance, the ROC AUC in the training set is 0.82 with a 95% confidence interval of 0.78 to 0.85, and in the test set, it is 0.81 with a 95% confidence interval of 0.71 to 0.88. This indicates a high level of confidence in the model's discriminative ability.\n\nAdditionally, the F1 score, sensitivity, and specificity are also reported with their respective confidence intervals, further supporting the robustness of our findings. The F1 score, which balances precision and recall, is 0.58 in the training set and 0.54 in the test set. Sensitivity, the ability to correctly identify positive cases, is 0.71 in the training set and 0.68 in the test set. Specificity, the ability to correctly identify negative cases, is consistently high at 0.76 in both the training and test sets.\n\nTo ensure the generalizability of our model, we conducted an internal-external cross-validation at the center level. This involved fitting the model to all but one center and testing it on the held-out center, resulting in a weighted average ROC AUC of 0.82 in the training set and 0.76 in the test set. This approach helps to mitigate overfitting and provides a more realistic estimate of the model's performance in new, unseen data.\n\nFurthermore, we plan to conduct an external validation using data from an observational study within the SURGE-Ahead project, which is expected to conclude in early 2024. This will provide an additional layer of confidence in the model's performance and its applicability to different settings.\n\nIn summary, the performance metrics are accompanied by confidence intervals, and the results are statistically significant. The model's performance is robust and generalizable, as evidenced by the cross-validation and planned external validation.",
  "evaluation/availability": "Not applicable."
}