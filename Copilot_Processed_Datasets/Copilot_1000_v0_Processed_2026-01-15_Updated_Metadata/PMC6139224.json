{
  "publication/title": "Integration of Genome-Wide DNA Methylation and Transcription Uncovered Aberrant Methylation-Regulated Genes and Pathways in the Peripheral Blood Mononuclear Cells of Systemic Sclerosis.",
  "publication/authors": "Zhu H, Zhu C, Mi W, Chen T, Zhao H, Zuo X, Luo H, Li QZ",
  "publication/journal": "International journal of rheumatology",
  "publication/year": "2018",
  "publication/pmid": "30245726",
  "publication/pmcid": "PMC6139224",
  "publication/doi": "10.1155/2018/7342472",
  "publication/tags": "- Systemic sclerosis\n- DNA methylation\n- Gene expression\n- Differentially methylated genes\n- Differentially expressed genes\n- Support vector machines\n- Real-time PCR validation\n- Transcriptome analysis\n- Clinical phenotype\n- Biomarkers\n- Interstitial lung disease\n- Extracellular matrix remodeling\n- Angiogenesis\n- Inflammatory response\n- Transcription factors",
  "dataset/provenance": "The dataset utilized in this study was derived from a comprehensive analysis of gene expression and DNA methylation profiles. The dataset included 590 transcripts and 935 CpG sites, which were identified through differential gene expression and methylation analyses. Specifically, 453 genes were found to be differentially expressed, and 618 genes were identified as differentially methylated. Among these, 25 genes were common in both differentially expressed genes (DEGs) and differentially methylated genes (DMGs), with 20 of these genes showing an inverse correlation between gene expression and DNA methylation.\n\nThe dataset was processed to remove probes corresponding to the X and Y chromosomes to ensure that both male and female samples could be analyzed together. Locus-by-locus analyses were conducted using the nonparametric Wilcoxon rank-sum test, with multiple comparisons correction performed in R. A CpG site was considered statistically differentially methylated if the BH-adjusted p-value was less than 0.05 between the tested groups and the absolute difference of the median \u03b2-value was greater than 0.12. For genes with multiple probes measuring DNA methylation, the probe with the highest fold change value for DNA methylation was selected.\n\nThe dataset was further validated using Taqman assays on a 7900HT Fast Real-Time PCR system. The assay was performed using a TaqMan RNA-to-CT 1-Step kit, with specific conditions for cDNA amplification. The relative quantity of gene expression in each sample was calculated by normalizing to the housekeeping gene GAPDH.\n\nThe dataset was also used for integrative analysis of transcriptome and DNA methylation. Each methylation probe was mapped to the nearest transcription start site, and transcription information was fetched from the UCSC Genome browser database. Probes were mapped to the nearest gene if the distance between the probe and the nearest gene\u2019s transcription start site was less than 10 kilobases. This resulted in the retention of 16,750 genes associated with the CpG probes in methylation and transcription probes in gene expression.\n\nThe dataset was also utilized for support vector machine (SVM) analysis to evaluate whether selected DEGs could correctly classify normal control from SSc patient samples. The SVM was trained using data from all but one of the samples, with the sample not used in training assigned a class by the SVM. This analysis was part of a broader effort to understand the molecular mechanisms underlying systemic sclerosis (SSc) and to identify potential biomarkers for the disease.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is Support Vector Machines (SVMs). SVMs are supervised learning models traditionally employed for classification analysis. They work by constructing a model based on a separating plane that maximizes the margin between different classes.\n\nThe SVM algorithm used is not new. It is a well-established method in the field of machine learning and has been extensively studied and applied in various domains. The choice to use SVMs in this context is likely due to their effectiveness in handling high-dimensional spaces and their ability to perform well with clear margin of separation.\n\nThe reason the SVM algorithm was not published in a machine-learning journal is that this study focuses on its application in a specific biological context rather than the development of the algorithm itself. The primary goal is to evaluate whether selected differentially expressed genes (DEGs) can correctly classify normal control samples from systemic sclerosis (SSc) patient samples using SVMs. The study involves tuning the optimal model parameters, such as cost and gamma, to achieve the best diagonal performance on a hold-on-one-out cross-validation test. This approach leverages the established strengths of SVMs for classification tasks in the context of biological data analysis.",
  "optimization/meta": "The model employs a Support Vector Machine (SVM) algorithm, which is a supervised learning model traditionally used for classification tasks. This algorithm constructs a model based on a separating plane that maximizes the margin between different classes.\n\nThe SVM is trained using data from all but one of the samples, and the sample not used in training is then assigned a class by the SVM. This process is repeated for each sample, ensuring that the training data is independent for each iteration.\n\nThe SVM uses a radial kernel, and the optimal model parameters, such as cost and gamma, are tuned to achieve the best diagonal performance on a hold-on-one-out cross-validation test. This approach helps in evaluating whether the selected differentially expressed genes (DEGs) can correctly classify normal control samples from systemic sclerosis (SSc) patient samples.\n\nThe SVM algorithm is used to identify a set of six DEGs\u2014F2R, CXCR6, FYN, LTBR, CTSG, and ELANE\u2014that completely separate the SSc and normal control (NC) populations. This set of DEGs may potentially be used as diagnostic markers.",
  "optimization/encoding": "For the machine-learning algorithm, specifically the Support Vector Machines (SVMs), the data encoding and preprocessing involved several steps. Initially, probes corresponding to the X and Y chromosomes were removed from the dataset to accommodate both male and female samples. Locus-by-locus analyses were conducted using the nonparametric Wilcoxon rank-sum test, with multiple comparisons correction performed in R. A CpG site was considered statistically differentially methylated if the BH-adjusted p-value was less than 0.05 between the tested groups and the absolute difference of the median \u03b2-value was greater than 0.12. For genes with multiple probes measuring DNA methylation, the probe with the highest fold change value for DNA methylation was selected.\n\nThe differentially expressed genes (DEGs) were validated using Taqman assays on a 7900HT Fast Real-Time PCR system. The assay was performed using a TaqMan RNA-to-CT 1-Step kit, with a total volume of 20 \u00b5l containing specific concentrations of sense and antisense primers, Taqman gene probe, TaqMan RT Enzyme Mix, and TaqMan RT-PCR Mix. The cDNA amplification was monitored under specific temperature conditions, and the assay was carried out in triplicate for each sample, including a no-template control. The relative quantity (RQ) of gene expression in each sample was calculated by normalizing to the housekeeping gene GAPDH.\n\nFor the integrative analysis of transcriptome and DNA methylation, each methylation probe was mapped to the nearest transcription start site. Transcription information from the hg19 genome was fetched from the UCSC Genome browser database and processed using the Bioconductor GenomicFeatures package. A probe was mapped to the nearest gene if the distance between the probe and the nearest gene\u2019s transcription start site was less than 10 kilobases. Only the subset of probes associated with genes represented on the gene expression microarray was retained, resulting in 16,750 genes associated with CpG probes in methylation and transcription probes in gene expression. Pearson correlation coefficients for each annotated gene were calculated among all possible pairs of methylation probe sets and gene expression probe sets between SSc and normal control groups. The methylation-expression probe set pair with the maximum absolute correlation coefficient was chosen for each gene.\n\nThe SVM algorithm used a radial kernel, and optimal model parameters (cost and gamma) were tuned to achieve the best diagonal performance on a hold-on-one-out cross-validation test. The SVM was trained using data from all but one of the samples, and the sample not used in training was then assigned a class by the SVM. This process was repeated for each sample to evaluate the classification performance.",
  "optimization/parameters": "In the optimization process, two key parameters were used in the model: cost and gamma. These parameters are crucial for tuning the support vector machine (SVM) to achieve optimal performance. The selection of these parameters was done through a process of tuning to maximize the diagonal performance on a hold-on-one-out cross-validation test. This method ensures that the model generalizes well to unseen data by evaluating its performance on each sample individually. The radial kernel was chosen for the SVM, which is a common choice for its effectiveness in handling non-linear relationships in the data. The specific values for cost and gamma were determined through this cross-validation process to balance the trade-off between bias and variance, ultimately leading to the best classification performance between normal control and patient samples.",
  "optimization/features": "In our study, we utilized a set of 20 differentially expressed genes (DEGs) as input features for our analysis. These genes were identified through a comprehensive process involving locus-by-locus analyses using the nonparametric Wilcoxon rank-sum test and multiple comparisons correction. To ensure the robustness of our findings, we performed feature selection by choosing the probe with the highest fold change value for DNA methylation when multiple probes were available for a single gene.\n\nThe selection of these 20 DEGs was based on their significant correlation with the disease status, specifically systemic sclerosis (SSc). We further refined this set by applying a support vector machine (SVM) algorithm, which helped us identify a subset of six DEGs\u2014F2R, CXCR6, FYN, LTBR, CTSG, and ELANE\u2014that completely separated the SSc and normal control (NC) populations. This subset was derived from the initial set of 20 DEGs, ensuring that the feature selection process was rigorous and based on the entire dataset.\n\nTo maintain the integrity of our analysis, the feature selection process was conducted using the entire dataset, ensuring that the selected features were representative of the overall data distribution. This approach helped us to avoid overfitting and to ensure that our model generalizes well to new, unseen data. The final set of six DEGs was used to train the SVM model, which demonstrated high accuracy in classifying SSc patients and normal controls.",
  "optimization/fitting": "In our study, we employed Support Vector Machines (SVMs) for classification analysis, which is a supervised learning model traditionally used for constructing a model based on a separating plane that maximizes the margin between different classes. The number of parameters in our SVM model, specifically the cost and gamma parameters for the radial kernel, is indeed much smaller compared to the number of training points. This is because the SVM model's complexity is primarily determined by the number of support vectors, which are a subset of the training data points.\n\nTo rule out over-fitting, we utilized a hold-on-one-out cross-validation approach. This method involves training the SVM on all but one of the samples and then testing it on the remaining sample. This process is repeated for each sample in the dataset, ensuring that every sample is used for both training and testing. By doing so, we could evaluate the model's performance on unseen data and ensure that it generalizes well to new samples, thereby mitigating the risk of over-fitting.\n\nConversely, to address under-fitting, we carefully tuned the model parameters (cost and gamma) to achieve the best diagonal performance. The cost parameter controls the trade-off between achieving a low training error and a low testing error, while the gamma parameter defines how far the influence of a single training example reaches. By optimizing these parameters, we ensured that the model was complex enough to capture the underlying patterns in the data without being too simplistic, thus avoiding under-fitting. Additionally, the use of a radial kernel allowed the model to capture non-linear relationships in the data, further enhancing its ability to fit the data appropriately.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our results. One key method involved the use of support vector machines (SVMs) with a radial kernel. To optimize the model parameters, we utilized a hold-on-one-out cross-validation approach. This technique helps in tuning the optimal model parameters, specifically the cost and gamma values, to achieve the best diagonal performance. By doing so, we aimed to maximize the margin between different classes, which is a fundamental aspect of SVM classification.\n\nAdditionally, we performed multiple comparisons correction in our statistical analyses. Specifically, we used the Benjamini-Hochberg (BH) procedure to adjust p-values, ensuring that our findings were statistically significant and not due to chance. This step is crucial in genome-wide studies to control the false discovery rate and prevent overfitting.\n\nFurthermore, in our integrative analysis of transcriptome and DNA methylation, we mapped each methylation probe to the nearest transcription start site and retained only the subset of probes associated with genes represented on the gene expression microarray. This filtering process helped in reducing the dimensionality of the data and focusing on the most relevant features, thereby minimizing the risk of overfitting.\n\nIn summary, our approach included the use of cross-validation for model parameter tuning, multiple comparisons correction for statistical significance, and feature selection in integrative analyses. These methods collectively contributed to the prevention of overfitting and enhanced the reliability of our findings.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in the methods section. Specifically, for the support vector machines (SVMs), we detailed the use of a radial kernel and the tuning of optimal model parameters, such as cost and gamma, to achieve the best diagonal performance on a hold-on-one-out cross-validation test. These details are crucial for reproducibility and are provided to ensure that others can replicate our findings.\n\nThe optimization schedule, including the conditions for cDNA amplification monitored using the 7900HT Fast Real-Time PCR system, is also thoroughly described. This includes the specific temperatures and durations for each step of the process, ensuring that the experimental conditions are clearly outlined.\n\nRegarding model files and optimization parameters, while the specific files are not directly provided in the text, the methods and parameters used for data processing and analysis are extensively documented. This includes the use of the Wilcoxon rank-sum test for locus-by-locus analyses and the criteria for considering a CpG site as statistically differentially methylated. Additionally, the integration of transcriptome and DNA methylation data, along with the use of Pearson correlation coefficients, is detailed to provide a comprehensive understanding of the analytical approach.\n\nFor access to the data and methods, the study adheres to standard academic practices, and the information is available through the publication. The methods and parameters are described in a manner that allows for replication and further research, ensuring transparency and rigor in the scientific process.",
  "model/interpretability": "The model employed in this study is not a black box. It utilizes a Support Vector Machine (SVM) algorithm, which is a supervised learning model traditionally used for classification analysis. The SVM constructs a model based on a separating plane that maximizes the margin between different classes. This approach provides a level of transparency, as the decision boundary is explicitly defined by the support vectors, which are the data points closest to the decision boundary.\n\nThe SVM was used to evaluate whether selected differentially expressed genes (DEGs) could correctly classify normal control samples from SSc patient samples. The model parameters, such as the cost and gamma, were tuned to achieve the best performance on a hold-on-one-out cross-validation test. This tuning process ensures that the model is optimized for the specific dataset, enhancing its interpretability.\n\nOne of the key outcomes of using the SVM was the identification of a set of six DEGs\u2014F2R, CXCR6, FYN, LTBR, CTSG, and ELANE\u2014that completely separated the SSc and normal control populations. This set of genes can potentially be used as diagnostic markers, providing a clear and interpretable result. The SVM's ability to distinguish between the two groups with high accuracy demonstrates the model's transparency and reliability.\n\nAdditionally, the study performed an exploratory two-dimensional (2D) hierarchical clustering with the 20 MeDEGs across the samples. This clustering resulted in separate sample clusters for SSc and normal controls, further supporting the model's interpretability. The clustering analysis, along with the SVM results, provides a comprehensive view of how the model differentiates between the two groups based on the selected genes.\n\nIn summary, the model used in this study is transparent and provides clear examples of how it differentiates between SSc patients and normal controls. The use of SVM and the identification of specific DEGs as diagnostic markers contribute to the model's interpretability.",
  "model/output": "The model employed in this study is a classification model. Specifically, a Support Vector Machine (SVM) was used. SVMs are supervised learning models traditionally employed for classification analysis. They work by constructing a model based on a separating plane that maximizes the margin between different classes. In this context, the SVM was utilized to evaluate whether selected differentially expressed genes (DEGs) could correctly classify normal control samples from systemic sclerosis (SSc) patient samples. The model was trained using data from all but one of the samples, and the sample not used in training was then assigned a class by the SVM. The goal was to identify a set of DEGs that could completely separate the SSc and normal control populations. Through this process, a set of six DEGs\u2014F2R, CXCR6, FYN, LTBR, CTSG, and ELANE\u2014was identified as potential diagnostic markers, successfully classifying all 19 normal controls as healthy and all 18 SSc patients as having the condition.",
  "model/duration": "The execution time for the model varied depending on the specific analyses performed. For instance, the locus-by-locus analyses using the nonparametric Wilcoxon rank-sum test and multiple comparisons correction in R took a considerable amount of time. Additionally, the support vector machine (SVM) analysis, which involved tuning optimal model parameters and performing hold-on-one-out cross-validation, also required significant computational resources. The real-time PCR validation of differentially expressed genes (DEGs) was conducted on a 7900HT Fast Real-Time PCR system, with each assay carried out in triplicate for each sample, further adding to the overall execution time. The integrative analysis of transcriptome and DNA methylation, including mapping probes to the nearest transcription start sites and calculating Pearson correlation coefficients, was another time-consuming process. Overall, the model's execution time was influenced by the complexity of the analyses and the need for rigorous validation and cross-validation steps.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study involved several rigorous steps to ensure the robustness and validity of the findings. Initially, differentially methylated CpG sites were identified using the nonparametric Wilcoxon rank-sum test, with multiple comparisons correction performed in R. A CpG site was considered statistically differentially methylated if the BH-adjusted p-value was less than 0.05 between the tested groups and the absolute difference of the median \u03b2-value was greater than 0.12. For genes with multiple probes measuring DNA methylation, the probe with the highest fold change value was selected.\n\nTo validate the differentially expressed genes (DEGs), Taqman assays were conducted on a 7900HT Fast Real-Time PCR system. The assay was performed using a TaqMan RNA-to-CT 1-Step kit, with specific conditions for cDNA amplification. This validation was carried out in triplicate for each sample, including a no-template control. The relative quantity of gene expression in each sample was calculated by normalizing to the housekeeping gene GAPDH.\n\nAn integrative analysis of transcriptome and DNA methylation was also performed. Each methylation probe was mapped to the nearest transcription start site, and transcription information was fetched from the UCSC Genome browser database. Probes were mapped to the nearest gene if the distance was less than 10 kilobases. Pearson correlation coefficients were calculated for each annotated gene among all possible pairs of methylation and gene expression probe sets between SSc and normal control groups. The methylation-expression probe set pair with the maximum absolute correlation coefficient was chosen for each gene.\n\nSupport Vector Machines (SVMs) were used to evaluate whether the selected DEGs could correctly classify normal control samples from SSc patient samples. A radial kernel was chosen, and optimal model parameters were tuned to achieve the best diagonal performance on a hold-on-one-out cross-validation test. The SVM was trained using data from all but one of the samples, and the sample not used in training was then assigned a class by the SVM. This process was repeated for each sample to ensure comprehensive evaluation.\n\nAdditionally, the study included a validation step using QPCR in a separate cohort of SSc and normal control samples. This step confirmed the differential expression of 11 MeDEGs, with 7 upregulated and 4 downregulated genes showing statistical significance. The overall consistency between microarray and QPCR assays was observed in 17 of the 20 MeDEGs, with further confirmation ongoing for the remaining genes.",
  "evaluation/measure": "In the evaluation of our study, we primarily focused on the performance of support vector machines (SVMs) in classifying samples based on differentially expressed genes (DEGs). The key performance metric reported is the classification accuracy of the SVM model. Specifically, we used a radial kernel and optimized the model parameters to achieve the best performance on a hold-on-one-out cross-validation test. This approach ensured that each sample was used once as a test case while the model was trained on the remaining samples.\n\nThe SVM analysis demonstrated that a set of six DEGs\u2014F2R, CXCR6, FYN, LTBR, CTSG, and ELANE\u2014completely separated the systemic sclerosis (SSc) and normal control (NC) populations. All 19 NC samples were correctly predicted as healthy controls, and all 18 SSc patients were accurately classified as having SSc. This high level of accuracy suggests that these six DEGs could potentially serve as diagnostic markers for SSc.\n\nWhile the primary focus was on classification accuracy, the study also involved locus-by-locus analyses using the nonparametric Wilcoxon rank-sum test and multiple comparisons correction. For a CpG site to be considered statistically differentially methylated, it had to meet stringent criteria, including a BH-adjusted p-value of less than 0.05 and an absolute difference of the median \u03b2-value greater than 0.12. This rigorous statistical approach ensures the reliability of the identified DEGs.\n\nThe performance metrics reported in this study are representative of standard practices in the field. The use of SVM for classification is well-established, and the hold-on-one-out cross-validation method is a robust technique for evaluating model performance. The criteria for differential methylation are also in line with commonly accepted standards in epigenetic studies. Overall, the metrics and methods used provide a comprehensive and reliable evaluation of the study's findings.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "The evaluation of the methods employed in this study includes several statistical analyses to ensure the robustness and significance of the findings.\n\nFor the locus-by-locus analyses, a nonparametric Wilcoxon rank-sum test was used, followed by multiple comparisons correction in R. A CpG site was considered statistically differentially methylated only if the BH-adjusted p-value was less than 0.05 between the tested groups and the absolute difference of the median \u03b2-value was greater than 0.12. This stringent criterion ensures that the identified differentially methylated sites are statistically significant and biologically relevant.\n\nIn the real-time PCR validation of differentially expressed genes (DEGs), the assay was carried out in triplicate for each sample, including a no-template control. The relative quantity (RQ) of gene expression in each sample was calculated by normalizing to the housekeeping gene GAPDH. This approach provides a reliable measure of gene expression levels, reducing the likelihood of false positives.\n\nThe integrative analysis of transcriptome and DNA methylation involved mapping each methylation probe to the nearest transcription start site and calculating Pearson correlation coefficients for each annotated gene. The methylation-expression probe set pair with the maximum absolute correlation coefficient was chosen for each gene. This method ensures that the correlations identified are the strongest possible, enhancing the confidence in the results.\n\nSupport vector machines (SVMs) were used to evaluate whether selected DEGs could correctly classify normal control samples from SSc patient samples. The SVM model was tuned using a radial kernel and optimal parameters to achieve the best diagonal performance on a hold-on-one-out cross-validation test. This rigorous cross-validation approach ensures that the model's performance is not overfitted to the training data and provides a reliable estimate of its generalization ability.\n\nThe SVM analysis successfully separated the SSc and normal control populations using a set of six DEGs: F2R, CXCR6, FYN, LTBR, CTSG, and ELANE. All 19 normal controls were predicted as healthy, and all 18 SSc patients were classified as SSc, indicating a high level of confidence in the diagnostic potential of these markers.\n\nOverall, the statistical methods and validation steps employed in this study provide a high level of confidence in the results, ensuring that the findings are robust, statistically significant, and biologically relevant.",
  "evaluation/availability": "Not enough information is available."
}