{
  "publication/title": "Laboratory variables-based artificial neural network models for predicting fatty liver disease: A retrospective study.",
  "publication/authors": "Lv P, Cao Z, Zhu Z, Xu X, Zhao Z",
  "publication/journal": "Open medicine (Warsaw, Poland)",
  "publication/year": "2024",
  "publication/pmid": "39291279",
  "publication/pmcid": "PMC11406433",
  "publication/doi": "10.1515/med-2024-1031",
  "publication/tags": "- Fatty Liver Disease\n- Machine Learning\n- Artificial Neural Networks\n- Predictive Modeling\n- Serum Biomarkers\n- Clinical Data\n- Diagnostic Accuracy\n- Receiver Operating Characteristic\n- Sensitivity and Specificity\n- Non-Alcoholic Fatty Liver Disease",
  "dataset/provenance": "The dataset used in this study was sourced from initial fatty liver screenings conducted at Minhang Hospital, Fudan University. The screening took place between January 1, 2021, and December 31, 2022. A total of 12,058 participants underwent these screenings. However, 4,068 patients were excluded due to incomplete examinations, resulting in a final sample size of 7,990 patients who met all the inclusion criteria for model development.\n\nThe dataset was divided into three sets: the training set, the validation set, and the testing set. The training set comprised 4,415 subjects, of which 1,717 had fatty liver disease (FLD) and 2,698 did not. The validation set included 1,894 subjects, with 737 having FLD and 1,157 without. The testing set contained 1,681 subjects, with 1,041 having FLD and 640 without.\n\nThis dataset has not been used in previous papers or by the community, as it is specific to this study. The data collection was limited to one medical center, which may introduce selection bias. Future research aims to use multicenter datasets to improve the reliability and clinical usability of the constructed models.",
  "dataset/splits": "The dataset was divided into three distinct splits: a training set, a validation set, and a testing set. The training set comprised 4,415 subjects, with 1,717 patients diagnosed with fatty liver disease (FLD) and 2,698 patients without FLD. The validation set included 1,894 subjects, consisting of 737 FLD patients and 1,157 non-FLD patients. The testing set contained 1,681 subjects, with 1,041 FLD patients and 640 non-FLD patients. These splits were used to develop, evaluate, and assess the performance of the artificial neural network models for predicting fatty liver disease.",
  "dataset/redundancy": "The dataset used in this study was derived from a cohort of 12,058 participants who underwent initial fatty liver screening at Minghang Hospital, Fudan University, between January 1, 2021, and December 31, 2022. After excluding 4,068 patients due to incomplete examination, a final sample size of 7,990 patients was obtained. This sample was then divided into three sets: a training set, a validation set, and a testing set.\n\nThe training set comprised 4,415 subjects, of which 1,717 had fatty liver disease (FLD) and 2,698 did not. The validation set included 1,894 subjects, with 737 having FLD and 1,157 without. The testing set contained 1,681 subjects, of which 1,041 had FLD and 640 did not. The training set was used to determine the network\u2019s architecture and establish the weights between nodes. The validation set was utilized to evaluate the artificial neural network\u2019s ability to predict the desired output. The neural network\u2019s performance was then assessed using the independent testing set.\n\nTo ensure the independence of the training and test sets, the dataset was randomly divided. This random division helped to minimize the risk of data leakage and ensured that the model's performance could be generalized to new, unseen data. The distribution of variables within the FLD and non-FLD groups was compared across the training, validation, and testing sets, revealing that all variables (except for DBIL in some cases) were statistically significant factors associated with FLD. This careful splitting and validation process aimed to create a robust model that could accurately predict fatty liver disease.",
  "dataset/availability": "The datasets used and analyzed during the current study are available from the corresponding author upon reasonable request. The data is not publicly released in a forum. The data availability is enforced through direct communication with the corresponding author, ensuring that the data is shared responsibly and in accordance with ethical and legal standards.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is Artificial Neural Networks (ANNs). This class of algorithms is well-established and widely used for various predictive modeling tasks, including medical diagnostics.\n\nThe specific ANN models employed in this research are not new; they are standard architectures that have been extensively studied and applied in the field of machine learning. These models were chosen for their proven ability to handle complex, non-linear relationships in data, which is crucial for predicting fatty liver disease (FLD) based on various clinical and serum variables.\n\nThe decision to use ANNs in this context, rather than publishing them in a machine-learning journal, is driven by the specific application and the domain of the study. The focus here is on the medical application of these algorithms, particularly in the diagnosis and prediction of FLD. The primary goal is to demonstrate the effectiveness of ANNs in improving the accuracy and reliability of FLD prediction using readily available clinical data. This aligns with the objectives of medical research, which often involves adapting existing machine-learning techniques to solve specific healthcare problems. By showcasing the practical benefits of ANNs in a clinical setting, the study contributes to the broader goal of enhancing medical diagnostics and patient care.",
  "optimization/meta": "The models developed in this study do not use data from other machine-learning algorithms as input. Instead, they rely on serum variables and, in some cases, demographic factors like age and gender. The models include various configurations, such as 18-variable, 11-variable, 3-variable, and 2-variable models, as well as their counterparts that include age and gender.\n\nThe machine-learning methods employed are primarily artificial neural networks (ANNs). These ANNs were trained and validated using different sets of variables to predict fatty liver disease (FLD). The process involved selecting the optimal combinations of variables based on their area under the receiver operating characteristic curve (AUROC) to ensure the best predictive performance.\n\nThe training data for these models is independent, as the models were evaluated across training, validation, and testing sets. This independence is crucial for assessing the generalizability and robustness of the models. The performance metrics, including sensitivity, specificity, accuracy, false positive rate, and positive predictive value, were calculated for each model to ensure reliable and accurate predictions. The inclusion of age and gender in some models slightly improved the AUROC values, indicating their added predictive value. However, the 2-variable model, which includes ALT and TG, showed comparable performance to more complex models, demonstrating the effectiveness of a simplified approach.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the input data was suitable for training the artificial neural network (ANN). The input layer's number of neurons was determined by the input data, which was represented as an n-dimensional vector. This vector included various serum variables, such as triglycerides (TG) and alanine aminotransferase (ALT), as well as demographic factors like age and gender.\n\nThe data propagated from the input layer through two hidden layers before reaching the output layer. These layers were fully connected, meaning each neuron in a higher layer was connected to all neurons in the lower layer. The activation function used in the hidden layers was the sigmoid function, which helped introduce non-linearity into the model. The output layer used softmax regression to produce the final predictions.\n\nDuring the training process, the dataset was randomly divided into a training set (70% of total patients), a validation set (30% of total patients), and an independent testing set. The training set was used to determine the network's architecture and establish the weights between nodes. The validation set evaluated the ANN's ability to predict the desired output, while the testing set assessed the neural network's performance.\n\nThe connection weights between neurons were adjusted iteratively during training to minimize the overall error. Training ceased when the sum of squared errors reached a minimum. This process ensured that the ANN could accurately classify patients at high risk of fatty liver disease (FLD) during examination. The models incorporated different numbers of variables, ranging from two to twenty, and demonstrated robust performance in predicting FLD.",
  "optimization/parameters": "In our study, we developed several artificial neural network (ANN) models to predict fatty liver disease (FLD), each utilizing a different number of input parameters. Initially, we considered 39 blood variables. However, due to their minimal impact on classification performance, 21 routine blood variables were excluded. This left us with 18 serum variables for the 18-variable model.\n\nTo identify the most promising predictive variables and achieve the highest predictive accuracy, we retained variables with an area under the receiver operating characteristic curve (AUROC) greater than 0.6. This process resulted in an 11-variable model. Further refinement led to the development of a 3-variable model and a 2-variable model, which were selected based on their optimal combinations of variables that yielded the highest AUROC.\n\nAdditionally, we incorporated demographic factors such as age and gender into our models, resulting in expanded versions: a 20-variable model, a 13-variable model, a 5-variable model, and a 4-variable model. These expanded models were created to analyze the potential value of including easily collectible and demographic factors in predicting FLD.\n\nThe final selection of input parameters for each model was based on a meticulous evaluation process that considered the AUROC of all training, validation, and testing sets. This approach ensured that the models were optimized for predictive performance while utilizing readily available and inexpensive variables.",
  "optimization/features": "In our study, we developed multiple models with varying numbers of input features to predict fatty liver disease (FLD). Initially, we considered 39 blood variables. However, due to poor classification performance, we narrowed down to 18 serum variables for the 18-variable model. Further refinement led to an 11-variable model, focusing on variables with an area under the receiver operating characteristic curve (AUROC) greater than 0.6.\n\nTo identify the most predictive and readily available variables, we systematically evaluated combinations of three and two variables from the 18-variable set. This process involved assessing 816 possible 3-variable combinations and 153 possible 2-variable combinations. The combinations with the highest AUROC were selected as the optimal configurations for the 3-variable and 2-variable models, respectively.\n\nAdditionally, we incorporated demographic factors such as age and gender into our models, resulting in a 20-variable model, a 13-variable model, a 5-variable model, and a 4-variable model. These additional factors were included to analyze their potential value in enhancing the predictive performance of the models.\n\nFeature selection was performed using the training set only, ensuring that the validation and testing sets remained independent for unbiased evaluation of the models' performance. This meticulous process enabled us to derive performance metrics for each model based on their respective optimal combinations of variables.",
  "optimization/fitting": "The artificial neural network (ANN) employed in this study consisted of an input layer, two hidden layers, and an output layer. The input layer's dimensions were determined by the input data, while the hidden layers were fully connected to both the input and output layers. This architecture ensured that any neuron in an upper layer was connected to all neurons in the lower layer, facilitating comprehensive data propagation.\n\nTo address the potential issue of overfitting, given the relatively large number of parameters compared to the number of training points, several strategies were implemented. The dataset was randomly divided into a training set (70% of total patients), a validation set (30% of total patients), and an independent testing set. This division allowed for the evaluation of the ANN's performance on unseen data, ensuring that the model generalized well beyond the training set. Additionally, the training process involved iterative adjustment of connection weights between neurons to minimize the overall error, with training ceasing when the sum of squared errors reached a minimum. This approach helped in preventing overfitting by focusing on minimizing error rather than memorizing the training data.\n\nTo rule out underfitting, the model's performance was rigorously evaluated using multiple metrics, including the area under the receiver operating characteristic curve (AUROC), sensitivity, specificity, accuracy, false positive rate, and positive predictive value. The models achieved high AUROC values, indicating strong predictive performance. Furthermore, the inclusion of additional variables such as age and gender in some models helped in capturing more nuanced patterns in the data, thereby enhancing the model's ability to generalize and reducing the risk of underfitting.\n\nThe confusion matrix was used to determine the relationship between actual and predicted values, providing a clear view of the model's performance in terms of true positives, true negatives, false positives, and false negatives. This detailed evaluation ensured that the models were neither overfitting nor underfitting the data, striking a balance that optimized predictive accuracy.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was the division of the dataset into three distinct subsets: a training set, a validation set, and a testing set. The training set, comprising 70% of the total patients, was used to determine the network's architecture and establish the weights between nodes. The validation set, which included 30% of the total patients, was utilized to evaluate the model's ability to predict the desired output. Finally, the model's performance was assessed using an independent testing set.\n\nDuring the training process, the connection weights between neurons were adjusted iteratively to minimize the overall error. Training ceased when the sum of squared errors reached a minimum, which helped in preventing overfitting by ensuring that the model did not become too complex and start memorizing the training data.\n\nAdditionally, we systematically evaluated different combinations of variables to identify the optimal configuration for both the 3-variable and 2-variable models. This meticulous process involved calculating the area under the receiver operating characteristic curve (AUROC) for various combinations and selecting the one with the highest AUROC. This approach helped in assessing the effectiveness of the variables incorporated in the training set and ensured that only the most relevant variables were included in the final models.\n\nFurthermore, we incorporated demographic factors such as age and gender into some of our models to analyze their potential value in improving prediction accuracy. This resulted in the development of models with additional variables, which were evaluated using the same performance metrics as the original models. The inclusion of these factors helped in enhancing the models' predictive power and generalizability.\n\nOverall, these techniques collectively contributed to the prevention of overfitting and ensured that our models were robust and capable of generalizing well to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. We systematically evaluated various combinations of variables to determine the optimal configurations for our models. Specifically, we assessed 816 possible combinations for the 3-variable model and 153 combinations for the 2-variable model, selecting those with the highest area under the receiver operating characteristic curve (AUROC) as the optimal configurations.\n\nThe final weights of the variables for both the 2-variable and 3-variable models were determined based on the AUROC across the training, validation, and testing sets. This meticulous process ensured that the models were optimized for performance.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the publication. However, the methodology and results are thoroughly described, allowing for replication of the study's findings. The publication adheres to ethical standards and regulatory requirements, ensuring transparency and reproducibility in our research practices.",
  "model/interpretability": "The models developed for predicting fatty liver disease (FLD) are based on artificial neural networks (ANNs), which are inherently black-box models. This means that the internal workings of the models are not easily interpretable, and the relationships between input variables and predictions are not straightforward to understand.\n\nHowever, several steps were taken to enhance the interpretability and transparency of the models. Firstly, the models were developed using a subset of relevant variables identified from a larger set of blood variables. This process involved calculating the area under the receiver operating characteristic curve (AUROC) for each variable to assess its predictive performance. Variables with an AUROC greater than 0.6 were retained for model building, ensuring that only the most informative variables were included.\n\nAdditionally, the models were evaluated using a confusion matrix, which provides a clear representation of the relationship between actual values and predicted values. This allows for a detailed assessment of the model's performance in terms of sensitivity, specificity, accuracy, false positive rate, and positive predictive value.\n\nMoreover, the models were developed in a systematic manner, starting with an 18-variable model and progressively reducing the number of variables to create 11-variable, 3-variable, and 2-variable models. This approach allowed for the identification of the most critical variables for FLD prediction, with ALT and TG being the primary predictors. The inclusion of age and gender in the models further enhanced their predictive performance, highlighting the importance of these demographic factors.\n\nWhile the ANNs themselves are not transparent, the process of model development and evaluation provides insights into the key variables and their contributions to FLD prediction. This information can be valuable for clinicians and researchers seeking to understand the underlying factors associated with FLD and to develop more effective diagnostic and treatment strategies.",
  "model/output": "The model developed is a classification model designed to predict fatty liver disease (FLD). It utilizes artificial neural networks (ANNs) to categorize patients into those with and without FLD. The output layer of the ANN employs a softmax function, which is commonly used in classification tasks to provide probability distributions over multiple classes. This setup allows the model to output the likelihood of a patient having FLD based on the input variables.\n\nThe model's performance was evaluated using several metrics, including sensitivity, specificity, accuracy, false positive rate, and positive predictive value. These metrics help assess the model's ability to correctly identify patients with FLD (sensitivity) and those without the disease (specificity). The area under the receiver operating characteristic curve (AUROC) was also calculated to evaluate the diagnostic accuracy, with values close to 1 indicating higher accuracy.\n\nThe model was trained, validated, and tested using different sets of variables. Four primary models were developed: an 18-variable model, an 11-variable model, a 3-variable model, and a 2-variable model. Additionally, models incorporating age and gender were created, resulting in a 20-variable model, a 13-variable model, a 5-variable model, and a 4-variable model. The 2-variable model, which uses triglycerides (TG) and alanine aminotransferase (ALT), and the 4-variable model, which includes age and gender in addition to TG and ALT, demonstrated good performance across the training, validation, and testing sets. This indicates the model's robustness and generalization ability, making it a reliable tool for FLD prediction in clinical settings.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code used in the study was developed by Mindray Medical International Limited, China. Due to stringent information security regulations mandated by the company, access to the code is not provided. The code contains proprietary information owned by Mindray, and as such, strict confidentiality protocols prevent its export. Therefore, no executable, web server, virtual machine, or container instance is publicly available.",
  "evaluation/method": "The evaluation of the models involved a comprehensive assessment using several key metrics and methodologies. The primary metric used was the area under the receiver operating characteristic curve (AUROC), which provided a measure of the diagnostic accuracy of the models. Values close to 1 indicated higher accuracy.\n\nThe models were evaluated using a confusion matrix, which helped determine the relationship between actual and predicted values. This matrix included true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). From this, several performance metrics were calculated:\n\n- Sensitivity (SEN): The proportion of actual positives correctly identified by the model.\n- Specificity (SPE): The proportion of actual negatives correctly identified by the model.\n- Accuracy (ACC): The overall proportion of correct predictions made by the model.\n- False Positive Rate (FPR): The proportion of actual negatives incorrectly identified as positives.\n- Positive Predictive Value (PPV): The proportion of positive predictions that are actually correct.\n\nThe models were developed and evaluated using training, validation, and testing sets. The training set was used to develop the models, the validation set to tune hyperparameters and prevent overfitting, and the testing set to evaluate the final performance of the models. The models included various configurations, such as 18-variable, 11-variable, 3-variable, and 2-variable models, as well as extended versions that incorporated age and gender.\n\nThe performance of the models was assessed across these datasets, with the AUROC values indicating strong predictive ability. For instance, the 18-variable model achieved an AUROC of 0.95 in the training set, while the 2-variable model had an AUROC of 0.92. When age and gender were added, the AUROC values slightly increased, demonstrating the added predictive value of these demographic factors.\n\nThe models were also evaluated using receiver operating characteristic (ROC) curves, which visually represented the trade-off between sensitivity and specificity. The ROC curves for the models in the training, validation, and testing sets showed consistent performance, with high AUROC values indicating robust predictive ability.\n\nIn summary, the evaluation method involved a rigorous assessment using multiple performance metrics and datasets, ensuring that the models were thoroughly validated and demonstrated strong predictive capabilities for fatty liver disease.",
  "evaluation/measure": "In our study, we employed several performance metrics to comprehensively evaluate the effectiveness of our models in predicting fatty liver disease (FLD). The primary metrics reported include the area under the receiver operating characteristic curve (AUROC), sensitivity (SEN), specificity (SPE), accuracy (ACC), false positive rate (FPR), and positive predictive value (PPV).\n\nThe AUROC is a critical metric that assesses the diagnostic accuracy of the models, with values closer to 1 indicating higher accuracy. This metric was calculated for all models across training, validation, and testing sets, providing a robust measure of their predictive performance.\n\nSensitivity, or the true positive rate, measures the proportion of actual positives correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives correctly identified. Both metrics are essential for understanding the model's ability to correctly classify patients with and without FLD.\n\nAccuracy provides an overall measure of the model's correctness, representing the proportion of true results (both true positives and true negatives) among the total number of cases examined. The false positive rate complements specificity by indicating the proportion of negatives incorrectly classified as positives.\n\nThe positive predictive value (PPV) is the probability that subjects with a positive screening test truly have the disease. This metric is particularly important in clinical settings, as it helps in understanding the reliability of positive predictions made by the model.\n\nThese metrics collectively offer a comprehensive evaluation of the models' performance, ensuring that they are reliable and accurate in predicting FLD. The reported metrics are representative of standard practices in the literature, providing a clear and comparable assessment of the models' effectiveness.",
  "evaluation/comparison": "Not enough information is available.",
  "evaluation/confidence": "The evaluation of our models involved a comprehensive assessment using several performance metrics, including the area under the receiver operating characteristic curve (AUROC), sensitivity (SEN), specificity (SPE), accuracy (ACC), false positive rate (FPR), and positive predictive value (PPV). These metrics were calculated for various models, including 2-variable, 3-variable, 11-variable, and 18-variable models, as well as their counterparts that included age and gender.\n\nThe AUROC values for these models were notably high, indicating strong diagnostic accuracy. For instance, the 18-variable model achieved an AUROC of 0.95, while the 2-variable model had an AUROC of 0.92. The inclusion of age and gender slightly improved the AUROC for all models, with the 20-variable model reaching an AUROC of 0.95. These results suggest that the models have a high level of confidence in their predictive performance.\n\nStatistical significance was assessed for all variables except for direct bilirubin (DBIL) in the training set, and for DBIL, albumin/globulin ratio (A/G), and globulin (GLB) in the validation set. In the testing set, all variables were found to be statistically significant factors associated with fatty liver disease (FLD). This indicates that the models are robust and that the variables used are reliable predictors of FLD.\n\nThe sensitivity and specificity of the models were also evaluated. For example, the 18-variable model had a sensitivity of 84.7% and a specificity of 90.1%, while the 2-variable model had a sensitivity of 81.3% and a specificity of 89.3%. These metrics further support the reliability and effectiveness of the models in predicting FLD.\n\nIn summary, the performance metrics for our models are robust and statistically significant. The high AUROC values, along with the sensitivity and specificity, demonstrate the models' strong predictive capabilities. The inclusion of age and gender further enhances the models' performance, indicating that these demographic factors are valuable additions to the predictive models.",
  "evaluation/availability": "The datasets used and analyzed during the current study are available from the corresponding author upon reasonable request. However, the code used in the study was developed by Mindray Medical International Limited, China. Due to stringent information security regulations mandated by the company, access to the code is not provided. The code contains proprietary information owned by Mindray, and strict confidentiality protocols prevent its export."
}