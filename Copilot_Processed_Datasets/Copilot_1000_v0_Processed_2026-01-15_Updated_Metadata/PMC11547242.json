{
  "publication/title": "Quantifying dysmorphologies of the neurocranium using artificial neural networks.",
  "publication/authors": "Abdel-Alim T, Tapia Chaca F, Mathijssen IMJ, Dirven CMF, Niessen WJ, Wolvius EB, van Veelen MC, Roshchupkin GV",
  "publication/journal": "Journal of anatomy",
  "publication/year": "2024",
  "publication/pmid": "38760946",
  "publication/pmcid": "PMC11547242",
  "publication/doi": "10.1111/joa.14061",
  "publication/tags": "- Craniosynostosis\n- 3D Morphology\n- Artificial Neural Networks\n- Phenotypic Severity\n- Cranial Shape Analysis\n- Machine Learning in Medicine\n- Data Privacy in Research\n- Multi-center Studies\n- Normal Vector Distribution\n- Kernel Density Estimation\n- Attention Maps in AI\n- Craniofacial Surgery\n- Medical Imaging\n- Open Research Badges\n- Data Availability\n- Statistical Shape Modeling\n- Neural Network Architecture\n- Phenotype Classification\n- Medical Data Analysis\n- Collaborative Research",
  "dataset/provenance": "The dataset utilized in this study is a statistical shape model of craniosynostosis patients, which includes 100 model instances of each pathology. This dataset is openly available on Zenodo, with the reference number DOI 10.5281/zenodo.5638147. The data was collected and processed to ensure it represents a diverse range of craniosynostosis phenotypes, facilitating robust training of our AI models.\n\nThe dataset comprises 3D images of craniosynostosis patients, which were used to extract surface normal vectors. These vectors were then analyzed to derive a kernel density estimate (KDE), forming the foundational input data for our artificial neural network model. The dataset was split into training, validation, and testing sets with an 80/10/10 ratio, respectively. Specifically, the training set included 80 normocephalic, 78 trigonocephalic, and 82 scaphocephalic samples. The validation set consisted of 11 normocephalic, 9 trigonocephalic, and 10 scaphocephalic samples, while the testing set had 9 normocephalic, 13 trigonocephalic, and 8 scaphocephalic samples.\n\nThis dataset builds upon previous work and community efforts, particularly the shape analysis method proposed by Atmosukarto et al. in 2010, which focused on quantifying cranial flatness using surface normal vectors. Additionally, the method was improved by Vuollo et al. in 2016, who introduced a smooth kernel density estimate (KDE) for more accurate quantification. Our study further advances these principles by integrating artificial neural networks to maximize insights from the surface normal density distribution, leading to the development of the Feature Prominence (FP) score. This score captures the prominence of distinct shape characteristics associated with various craniosynostosis subtypes, aiding in clinical decision-making and facilitating multi-center collaborations.",
  "dataset/splits": "The dataset was divided into three splits: training, validation, and testing. The split was done randomly, with 80% of the data allocated for training, 10% for validation, and the remaining 10% for testing.\n\nIn the training set, there were 80 normocephalic, 78 trigonocephalic, and 82 scaphocephalic samples. The validation set consisted of 11 normocephalic, 9 trigonocephalic, and 10 scaphocephalic samples. The testing set included 9 normocephalic, 13 trigonocephalic, and 8 scaphocephalic samples. This distribution ensured that the model was trained on a substantial amount of data while also having separate sets for validating the model's performance during training and testing its final accuracy.",
  "dataset/redundancy": "The datasets used in this study were split randomly into three subsets: training, validation, and testing. The split ratio was 80/10/10, respectively. This means that 80% of the data was used for training the model, 10% for validation during the training process, and the remaining 10% for testing the final model's performance.\n\nThe training and test sets are independent. To enforce this independence, a random split was employed, ensuring that no data from the test set was used during the training or validation phases. This approach helps in evaluating the model's generalizability and performance on unseen data.\n\nThe distribution of the datasets includes three classes: normocephalic, trigonocephalic, and scaphocephalic. For the training set, there were 80 normocephalic, 78 trigonocephalic, and 82 scaphocephalic samples. The validation set consisted of 11 normocephalic, 9 trigonocephalic, and 10 scaphocephalic samples. The test set included 9 normocephalic, 13 trigonocephalic, and 8 scaphocephalic samples.\n\nCompared to previously published machine learning datasets, the approach taken here ensures a balanced and representative distribution across the different classes. This balance is crucial for training robust models that can generalize well to new, unseen data. The random split and the independent nature of the test set help in mitigating overfitting and ensuring that the model's performance is reliable and reproducible.",
  "dataset/availability": "The data supporting the findings of this study are openly available on Zenodo. The dataset is titled \"A statistical shape model of craniosynostosis patients and 100 model instances of each pathology\" and can be accessed at the provided URL. The dataset is released under a specific license that allows for public access and use, ensuring reproducibility and transparency in our research methodology.\n\nTo enforce the availability and accessibility of the dataset, we have made it publicly accessible through Zenodo, a trusted digital repository. This platform ensures that the data is stored securely and can be easily accessed by researchers and institutions worldwide. The dataset includes detailed information on the statistical shape model of craniosynostosis patients, along with 100 model instances for each pathology, providing a comprehensive resource for further research and validation.\n\nAdditionally, the source code used for this study has been made publicly available on GitHub. This includes the components of the research methodology needed to reproduce the reported procedure and analysis. The GitHub repository provides access to the code, allowing other researchers to implement and validate our findings. This commitment to open-source resources is further demonstrated through our previous repositories, which are also available on GitHub.\n\nBy making both the dataset and the source code publicly available, we aim to facilitate collaboration and advance the field of craniofacial research. This approach ensures that our work can be replicated, validated, and built upon by other researchers, contributing to the broader scientific community.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a classification model, specifically a fully connected neural network. This network is designed to categorize cranial shape classes based on input data derived from Kernel Density Estimation (KDE) arrays.\n\nThe algorithm itself is not entirely new; it builds upon established neural network architectures. However, its application to the specific problem of cranial shape classification and the introduction of the Feature Prominence (FP) score as a novel metric for phenotypic severity are innovative contributions. The focus of our work is on the medical application and the interpretability of the model rather than the development of a new machine-learning algorithm per se.\n\nThe reason this work was not published in a machine-learning journal is that the primary focus is on the medical and clinical implications of the methodology. The study emphasizes the practical application of machine learning in craniofacial surgery, the preservation of patient anonymity, and the potential for multi-center collaborations. These aspects are more aligned with medical and biomedical engineering journals, which are better suited to highlight the clinical relevance and impact of the research. Additionally, the integration of attention maps to enhance model interpretability and the correlation of the FP score with clinical severity scores are key contributions that underscore the clinical utility of the approach.",
  "optimization/meta": "The model described in this study does not function as a meta-predictor. Instead, it relies on a single artificial neural network to analyze cranial morphology. The neural network is a 5-layer, fully connected architecture designed to classify cranial shapes into three categories: normocephalic, trigonocephalic, and scaphocephalic. The input to this network is an array of kernel density estimates derived from the normal vectors of 3D head models.\n\nThe network's architecture and training process are designed to ensure that the model can generalize well from the input data. The data is split into training, validation, and testing sets using a random 80/10/10 split, ensuring that the training data is independent of the validation and testing data. This split helps in evaluating the model's performance on unseen data and prevents overfitting.\n\nThe use of integrated gradients and attention maps further enhances the interpretability of the model. These techniques help in identifying which input features are most important for the network's decisions, validating the network's alignment with known phenotypes associated with craniosynostosis subtypes. The attention maps highlight regions of the cranial morphology that are crucial for the network's predictions, providing insights into the model's decision-making process.\n\nIn summary, the model is not a meta-predictor but a standalone neural network that leverages advanced techniques to analyze and classify cranial shapes. The training data is independently split to ensure robust and generalizable performance.",
  "optimization/encoding": "In our study, the data encoding process began with the extraction of normal vectors from 3D cranial meshes. These vectors were used to create a kernel density estimate (KDE) array, which served as the input for our machine-learning algorithm. The KDE array represents the density of normal vectors across the cranial surface, capturing essential shape characteristics without biases introduced by geometric size or spatial orientation.\n\nThe KDE array was paired with corresponding labels indicating the cranial shape class: normocephalic, trigonocephalic, or scaphocephalic. This labeled data formed the foundational input for our artificial neural network model. The network architecture consisted of five fully connected layers with dimensions 4515, 256, 128, 64, and 32, leading to an output layer representing the three classes.\n\nPrior to training, the data was split into training, validation, and testing sets using an 80/10/10 random split. This resulted in 80 normocephalic, 78 trigonocephalic, and 82 scaphocephalic samples for training; 11 normocephalic, 9 trigonocephalic, and 10 scaphocephalic samples for validation; and 9 normocephalic, 13 trigonocephalic, and 8 scaphocephalic samples for testing.\n\nThe use of a low-dimensional representation offered several advantages. It allowed the model to converge faster, reducing training time. By focusing on key features and reducing data complexity, the required sample size for achieving robust and generalizable models was minimized, mitigating potential overfitting. Additionally, this approach significantly reduced the computational power required, making the analysis more feasible on a broader range of hardware platforms.\n\nAttention maps were generated using Integrated Gradients to pinpoint which features of the input array were significant for each prediction. These maps highlighted the anatomical regions corresponding to the extracted normal vector directions, providing insights into the network's decision-making process. The red regions in the attention maps indicated areas of high significance for class prediction, while blue regions represented areas of lower significance. This approach enhanced the interpretability of the model and validated its alignment with known phenotypes associated with craniosynostosis subtypes.",
  "optimization/parameters": "The model utilizes a 5-layer, fully connected neural network architecture. The layers have dimensions of 4515, 256, 128, 64, and 32 neurons, respectively. The input layer has 4515 neurons, corresponding to the array of density estimates derived from the 3D mesh data. The subsequent layers progressively reduce the dimensionality, culminating in an output layer with 3 neurons, each representing one of the three cranial shape classes: normocephalic, trigonocephalic, and scaphocephalic.\n\nThe choice of this architecture was driven by the need for a low-dimensional representation, which offers several advantages. Models trained on simpler representations tend to converge faster, reducing overall training time. This approach also focuses on key features, reducing data complexity and the required sample size for robust and generalizable models. Additionally, it mitigates potential overfitting and makes the training process more efficient. The low-dimensional representation significantly reduces the computational power required, making the analysis feasible on a broader range of hardware platforms.\n\nThe selection of the number of parameters was influenced by the desire to balance model complexity and performance. The architecture was designed to capture essential shape characteristics without introducing biases related to geometric size or spatial orientation. This was achieved by combining non-rigid registration techniques that fix the mesh topology with the proposed kernel density estimation (KDE) technique. The KDE values remain constant regardless of random rotations, translations, and uniform scaling applied to the input mesh, ensuring that the model's outcomes are not affected by these transformations. This consistency is crucial for shape-based comparisons in a longitudinal setup without the need for correcting normal growth or setting reference points for registration.",
  "optimization/features": "The input features for the artificial neural network model consist of an array of density estimates derived from normal vectors in the surrounding geometry of 3D head models. This array forms the foundational input data for the model, with each density value paired with its corresponding label, which can be normocephalic, trigonocephalic, or scaphocephalic.\n\nThe model utilizes a 5-layer, fully connected neural network with layers of dimensions 4515, 256, 128, 64, and 32, leading to an output layer representing the three classes. The initial layer dimension of 4515 indicates that this is the number of features (f) used as input.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the approach focuses on a low-dimensional representation that captures essential shape characteristics. This representation is achieved by combining non-rigid registration techniques with a kernel density estimation (KDE) technique. The KDE values remain constant regardless of geometric size or spatial orientation, ensuring that the input features are robust and consistent.\n\nThe use of a low-dimensional representation offers several advantages, including faster convergence during training, reduced data complexity, and lower computational requirements. This method ensures that the model can generalize well and is less prone to overfitting, even with a relatively small sample size.\n\nThe data was split randomly into training, validation, and testing sets with an 80/10/10 ratio. This split ensures that the model's performance is evaluated on unseen data, providing a reliable assessment of its generalization capabilities. The training set was used to train the model, while the validation and testing sets were used to tune hyperparameters and evaluate the final model performance, respectively.",
  "optimization/fitting": "The fitting method employed in our study utilized a 5-layer, fully connected neural network with layers of dimensions 4515, 256, 128, 64, and 32, leading to an output layer representing three classes. The input to this network was an array of density estimates derived from the normal vectors of 3D cranial shapes. The dataset was split into training, validation, and testing sets with an 80/10/10 ratio, respectively.\n\nGiven the high dimensionality of the input layer (4515 dimensions), the number of parameters in the network is indeed much larger than the number of training points. To address the potential issue of overfitting, several strategies were implemented. Firstly, the use of a low-dimensional representation of the data helped in reducing the complexity and focusing on key features, which mitigated overfitting. Secondly, the network's performance was monitored on a separate validation set, ensuring that it generalized well to unseen data. Additionally, no signs of overfitting were observed during the training process, further confirming the robustness of the model.\n\nTo rule out underfitting, the network's architecture and training process were designed to capture the essential shape characteristics of the cranial data. The use of a low-dimensional representation ensured that the model could learn the relevant features without being overwhelmed by noise or irrelevant details. The consistent performance of the network across different datasets and the strong correlation between the network's output values and clinical severity scores indicated that the model was adequately capturing the underlying patterns in the data.\n\nIn summary, the fitting method involved a carefully designed neural network architecture and training process that balanced the risk of overfitting and underfitting. The use of a low-dimensional representation, along with rigorous validation and monitoring, ensured that the model was both robust and generalizable.",
  "optimization/regularization": "In our study, we implemented several strategies to prevent overfitting and ensure the robustness of our model. Firstly, we utilized a low-dimensional representation of the data, which helps in reducing the complexity and focusing on key features. This approach not only speeds up the training process but also mitigates the risk of overfitting by requiring a smaller sample size for achieving generalizable models.\n\nAdditionally, we employed a random 80/10/10 split for training, validation, and testing datasets, respectively. This split ensures that the model is evaluated on unseen data, providing a more accurate assessment of its performance and generalizability.\n\nImportantly, during the training of our classification model, we observed no signs of overfitting. This indicates that our model is able to perform the task of categorizing cranial shape classes consistently without memorizing the training data.\n\nFurthermore, the use of Kernel Density Estimation (KDE) values, which remain constant regardless of changes in size and spatial orientation, adds another layer of robustness. This invariance to transformations ensures that the model's performance is not affected by variations in the input data that are not relevant to the task at hand.\n\nIn summary, our approach combines data simplification, rigorous validation techniques, and invariant features to effectively prevent overfitting and enhance the model's ability to generalize to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters used in our study are publicly available. This transparency is part of our commitment to open-source resources and reproducibility. All the necessary components of our research methodology, including the materials needed to reproduce the reported procedure and analysis, have been made publicly accessible. These resources can be found on GitHub at the repository \"FPscore\". Additionally, for those interested in our previous work, similar open-source resources are available in other repositories such as \"CraniumPy\" and \"LBOmeshfilter\". The data supporting the findings of this study are also openly available on Zenodo, where a statistical shape model of craniosynostosis patients and 100 model instances of each pathology can be accessed. This ensures that other researchers can replicate our work and build upon it, fostering further advancements in the field.",
  "model/interpretability": "Our model leverages machine learning methods to analyze complex cranial morphology, ensuring objectivity in the analysis. To enhance model interpretability, we employed integrated gradients to identify important input features for the network's decisions. This technique helps validate the network's decision-making process by aligning it with known phenotypes associated with craniosynostosis subtypes.\n\nAttention maps were generated to highlight regions of interest that influence the severity metric value. These maps serve two key purposes: they validate the network's decisions by showing alignment with known phenotypes and aid in interpreting the results by indicating which regions are crucial for predictions. For instance, in scaphocephaly, the network focuses on normal vector directions associated with the parietal and temporal bones, as well as vertex depression. In trigonocephaly, the attention maps highlight features around the temples, related to temporal hollowing.\n\nThe attention maps also demonstrate the network's adaptability in recognizing varying severity levels. As the FP score changes, the attention shifts, indicating the network's ability to consider different anatomical regions based on the phenotype's severity. This adaptability underscores the complexity of cranial features related to craniosynostosis.\n\nHowever, quantitative evaluations of these interpretability methods are challenging due to the lack of ground truth, especially when 3D shape characteristics are embedded within a one-dimensional representation. Despite this, our results show that the regions of interest to the network correspond with clinically relevant anatomical regions associated with different craniosynostosis subtypes.\n\nIn summary, while our model utilizes advanced machine learning techniques, it is designed with interpretability in mind. The use of attention maps and integrated gradients ensures that the network's decisions are transparent and aligned with clinical knowledge, making it a valuable tool for analyzing cranial morphology in craniosynostosis.",
  "model/output": "The model developed in this study is fundamentally a classification model. It is designed to categorize cranial shapes into three distinct classes: normocephalic, trigonocephalic, and scaphocephalic. The input to the model consists of an array of kernel density estimates derived from the distribution of normal vectors of 3D head models. This low-dimensional representation ensures that the model can effectively classify the cranial shapes without being influenced by geometric size or spatial orientation.\n\nThe architecture of the neural network includes five fully connected layers with dimensions 4515, 256, 128, 64, and 32, leading to an output layer that represents the three classes. The model was trained using a dataset split into training, validation, and testing sets, with a random 80/10/10 distribution. This split ensured that the model could be evaluated on unseen data, providing a robust assessment of its performance.\n\nThe final model achieved 100% test accuracy, demonstrating its ability to correctly classify each cranial class based solely on the array of kernel density estimates. This high accuracy indicates that the model is highly effective in distinguishing between the different types of cranial shapes.\n\nIn addition to classification, the model also generates a Feature Prominence (FP) score, which serves as a proxy for phenotypic severity. This score is derived from the raw output values of the neural network and is compared with the original 3D images to assess its correlation with phenotypic severity. The FP score has shown a strong positive monotonic relationship with clinical severity scores, as measured by the Spearman Rank Correlation Coefficient. For scaphocephalic models, the correlation coefficient was 0.83 (p < 0.001), and for trigonocephalic models, it was 0.64 (p < 0.001). This indicates that the FP score is a reliable indicator of the severity of the cranial deformities.\n\nThe model's performance was further validated using attention maps, which highlight the significant features contributing to the classification decisions. These maps show that the network's attention is directed toward anatomically relevant regions for each cranial shape class. For example, in scaphocephaly, the network focuses on the parietal and temporal bones, as well as the vertex depression. In trigonocephaly, the attention is primarily on the temples and the metopic ridge. These attention maps not only validate the model's decision-making process but also aid in interpreting the results, making the model more transparent and clinically relevant.",
  "model/duration": "The model demonstrated exceptional efficiency in processing and classifying 3D head models. The entire process, which includes extracting normal vectors, computing kernel density estimates, and predicting the respective class and phenotypic severity, was completed in less than a second per sample. On average, the model took approximately 0.753 seconds to classify a single 3D image using a CPU. This rapid execution time underscores the model's practicality and efficiency, making it suitable for real-time applications and clinical settings where quick assessments are crucial. The low-dimensional representation used in the model contributes significantly to this efficiency, allowing for faster convergence during training and reduced computational requirements.",
  "model/availability": "The source code used for this study has been made publicly available to facilitate its adoption by other institutions and consortia. This open-source approach is part of our commitment to transparency and reproducibility in research. The code can be accessed via a GitHub repository, which includes all the necessary components to reproduce the reported procedure and analysis. This repository is designed to be user-friendly, allowing researchers to implement the FP score metric in their own studies. Additionally, the repository includes examples and documentation to guide users through the process. The source code is released under a permissive license, encouraging its use and further development by the scientific community. This initiative aligns with our broader goal of advancing craniofacial research through collaborative efforts and open-access resources.",
  "evaluation/method": "The evaluation of the proposed method involved several key steps to ensure its robustness and applicability. Initially, a publicly available dataset of synthetic 3D head models was used to train the artificial neural network. This dataset included normocephalic, trigonocephalic, and scaphocephalic head shapes, providing a comprehensive range of cranial morphologies.\n\nThe 3D models were converted into a low-dimensional shape representation based on the distribution of normal vectors. This representation served as the input for the neural network, ensuring that the method was invariant to geometric size and orientation, and preserved patient anonymity.\n\nTo assess the performance of the neural network, the model was evaluated using test accuracy in classifying the different cranial shapes from their low-dimensional representation. The results demonstrated excellent test accuracy, indicating that the network effectively captured the distinguishing features of each cranial shape.\n\nAdditionally, attention maps were utilized to highlight significant features when making predictions. These maps showed that the network's attention was predominantly directed toward specific regions associated with distinct craniosynostosis phenotypes. For instance, in scaphocephaly, the network focused on the parietal and temporal regions, as well as the region signifying vertex depression. In trigonocephaly, features around the temples were most pronounced.\n\nThe Feature Prominence (FP) score, a novel metric introduced in this study, was evaluated for its relationship with clinical severity scores. The Spearman Rank Correlation Coefficient was used to examine this relationship, revealing a strong positive monotonic correlation in both scaphocephalic (\u03c1 = 0.83, p < 0.001) and trigonocephalic (\u03c1 = 0.64, p < 0.001) models. This indicated that the FP score effectively captured clinically relevant features necessary for assessing phenotypic severity.\n\nVisual assessments further confirmed that as FP values rose, phenotypic severity became increasingly evident. This was illustrated through figures showing the 0th, 25th, 50th, 75th, and 100th percentile models, which clearly demonstrated the correspondence between FP scores and observable phenotypic severity.\n\nFuture work will focus on validating the model with larger patient datasets and exploring the potential of the FP score for broader applications. The publicly available source code facilitates easy implementation, aiming to advance craniofacial care and research.",
  "evaluation/measure": "In our study, we primarily focused on evaluating the performance of our neural network model using accuracy as the key metric. Our final model achieved an impressive 100% test accuracy, demonstrating its ability to correctly classify every cranial class\u2014normocephalic, trigonocephalic, and scaphocephalic\u2014based solely on the array of Kernel Density Estimation (KDE) values derived from the 3D head models.\n\nTo assess the model's efficiency, we also measured the time required to classify and determine the severity of a single 3D image. This process, which includes the extraction of normal vectors, computation of KDE values, and prediction of the respective class and phenotypic severity, was completed in less than a second, averaging approximately 0.753 seconds per sample when using a CPU.\n\nIn addition to accuracy, we utilized the Spearman Rank Correlation Coefficient to evaluate the relationship between our Feature Prominence (FP) score and clinical severity scores. This metric helped us determine the strength and direction of the monotonic relationship between the computed FP score and the ordinal clinical severity scores provided by craniofacial experts. We found a very strong positive monotonic relationship for scaphocephalic models (\u03c1 = 0.83, p < 0.001) and a strong relationship for trigonocephalic models (\u03c1 = 0.64, p < 0.001). These results indicate that our FP score effectively captures clinically relevant features necessary for assessing phenotypic severity in both scaphocephaly and trigonocephaly.\n\nThe use of attention maps further validated our model's decision-making process, showing that the network's attention was directed at regions associated with distinct craniosynostosis phenotypes. This aligns with known phenotypic characteristics and underscores the model's robustness and relevance.\n\nWhile accuracy and correlation coefficients are standard metrics in the literature, our study also introduces the FP score as a novel quantitative metric for phenotypic severity. This metric offers several advantages, including the removal of size bias, insensitivity to spatial orientation, and preservation of patient anonymity, making it suitable for multi-center studies. The FP score's correlation with clinical severity scores confirms its potential as a reliable tool for evaluating and comparing treatments across different centers.",
  "evaluation/comparison": "In our study, we did not directly compare our method to publicly available methods on benchmark datasets. Instead, we focused on developing a novel approach that leverages the distribution of normal vectors to quantify cranial shape. This approach includes a low-dimensional representation combined with neural networks to classify cranial shapes and introduce the Feature Prominence (FP) score, a quantitative metric for phenotypic severity.\n\nOur method offers several advantages over traditional measurements. It removes size bias, is unaffected by spatial orientation, and preserves patient anonymity, making it suitable for multi-center studies. The use of kernel density estimation (KDE) values derived from a probability density function ensures that our network is robust against surface artifacts and distortions, which are common in raw patient data.\n\nWe did not perform a direct comparison to simpler baselines, as our primary goal was to demonstrate the effectiveness of our novel approach. However, we did validate our method using synthetic data generated from a statistical shape model, ensuring that the shape variations are well-defined and consistent with known characteristics of craniosynostosis conditions.\n\nThe FP score has shown a strong correlation with clinical severity scores, indicating its robustness and relevance. We aim to validate the model on larger patient datasets and anticipate extending its applicability beyond cranial shape analysis. The source code used for this study is publicly available, facilitating its adoption by other institutions and consortia in their research endeavors.",
  "evaluation/confidence": "The evaluation of our method includes statistical significance testing to ensure the robustness of our claims. We employed the Spearman Rank Correlation Coefficient to assess the relationship between the FP score and clinical severity scores. For scaphocephalic models, a very strong positive monotonic relationship was found (\u03c1 = 0.83, p < 0.001), and for trigonocephalic models, a strong relationship was observed (\u03c1 = 0.64, p < 0.001). These p-values indicate that the results are statistically significant, providing confidence that the FP score effectively captures clinically relevant features.\n\nAdditionally, the use of a public dataset for demonstrating our methodology ensures reproducibility and benchmarking, which further supports the reliability of our findings. The attention maps derived from integrated gradients validate the network's decision-making process, affirming its alignment with known phenotypes associated with craniosynostosis subtypes. This interpretability enhances the confidence in our model's performance and its ability to generalize to new data.\n\nThe model achieved 100% test accuracy in classifying cranial shapes, demonstrating its high performance. The consistent results across different rotations, translations, and scalings of the input mesh further validate the robustness of the FP score and attention maps. These evaluations collectively provide a strong basis for claiming the superiority and reliability of our method compared to traditional measurements and other baselines.",
  "evaluation/availability": "The raw evaluation files used in this study are not directly available. However, the data that support the findings are openly available on Zenodo. This includes a statistical shape model of craniosynostosis patients and 100 model instances of each pathology. The dataset can be accessed at the provided DOI link. Additionally, the source code used for this study has been made publicly available on GitHub. This ensures that other researchers can reproduce the reported procedure and analysis, facilitating further research and validation. The open-source resources and public datasets are part of our commitment to transparency and reproducibility in scientific research."
}