{
  "publication/title": "Personalized Risk Prediction for 30-Day Readmissions With Venous Thromboembolism Using Machine Learning.",
  "publication/authors": "Park JI, Kim D, Lee JA, Zheng K, Amin A",
  "publication/journal": "Journal of nursing scholarship : an official publication of Sigma Theta Tau International Honor Society of Nursing",
  "publication/year": "2021",
  "publication/pmid": "33617689",
  "publication/pmcid": "PMC8568050",
  "publication/doi": "10.1111/jnu.12637",
  "publication/tags": "- Venous Thromboembolism\n- Machine Learning\n- Electronic Health Records\n- 30-day Readmission\n- Risk Prediction Model\n- Predictive Analytics\n- Healthcare Data\n- Patient Outcomes\n- Medical Diagnosis\n- Data Preprocessing\n- Feature Selection\n- Logistic Regression\n- Balanced Random Forest\n- Multilayer Perceptron\n- Cross-validation",
  "dataset/provenance": "The dataset used in this study was sourced from a tertiary academic hospital's electronic health records (EHR). The data is stored in a research clinical data warehouse (CDW) and analyzed in a secure computing environment. The CDW is structured using the Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM), which enables standardized representation of patient information for efficient and high-quality computing.\n\nThe patient cohort analyzed includes adult patients (18 years or older) who had been hospitalized and had at least one subsequent visit recorded in the EHR after the initial discharge, between January 1, 2009, and September 20, 2020. This time frame was chosen to exclude patients whose hospitalization was the only contact with this healthcare system. Multiple hospitalizations of the same patient within this hospital were possible as long as they occurred more than 30 days after any previous hospitalization.\n\nThe final sample included a total of 158,804 admissions associated with 92,481 distinct patients. This dataset was derived from an initial pool of 171,136 admissions, with data points that had missing values being excluded. The dataset includes structured patient data such as demographics, diagnoses, procedures, medications, Charlson Comorbidity score, medical history, and length of inpatient stay.\n\nThe data used in this study has not been previously published or used by the community in other studies. The dataset is unique to this research and focuses on predicting 30-day readmission with acute deep vein thrombosis (DVT) or pulmonary embolism (PE). The structured data were extracted from the CDW for analysis, with relevant diagnoses and medications grouped into higher-level diagnosis groups and medication classes to improve computing efficiency.",
  "dataset/splits": "The dataset was divided into two primary splits: a training set and a test set. This division is a common practice in machine learning to ensure that models are not overfitted to the training data and can generalize well to unseen data.\n\nThe training set comprised 70% of the total data, while the test set included the remaining 30%. This split ratio is standard in healthcare machine learning studies to balance the need for sufficient training data with the necessity of having a robust test set for evaluating model performance.\n\nAdditionally, during the model evaluation phase, a 10-fold cross-validation technique was employed. This method involves randomly dividing the data into 10 approximately equal partitions. In each fold of the cross-validation, one partition is used for testing, while the remaining nine partitions are used for training. This process is repeated 10 times, with each partition serving as the test set exactly once. This approach helps in providing a more reliable estimate of the model's performance by ensuring that every data point is used for both training and testing.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not applicable.",
  "optimization/algorithm": "The machine-learning algorithms used in this study include Logistic Regression, Balanced Random Forest (BRF), and Multilayer Perceptron (MLP). These are well-established algorithms in the field of machine learning and are not new.\n\nLogistic Regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there are only two possible classes).\n\nThe Balanced Random Forest (BRF) model is an extension of the traditional Random Forest algorithm. It addresses class imbalance by using balanced down-sampled data, which helps to avoid poor performance for predicting the minority class.\n\nThe Multilayer Perceptron (MLP) is a class of feedforward artificial neural network. It is a robust, supervised learning algorithm used to solve complex classification problems. An MLP model typically has at least three layers of nodes: an input layer, a hidden layer, and an output layer. Each node, except for the input nodes, is a perceptron that uses a nonlinear activation function, enabling the MLP model to fit complex data distributions.\n\nThese algorithms were chosen for their effectiveness in handling classification problems and their ability to manage imbalanced datasets, which is crucial for the specific application in this study. The algorithms were implemented using established libraries in Python, such as Scikit-learn and TensorFlow, which are widely used in the machine learning community. The focus of this study is on the application of these algorithms to a specific healthcare problem, rather than the development of new machine-learning algorithms. Therefore, it is appropriate that the study was published in a nursing scholarship journal rather than a machine-learning journal.",
  "optimization/meta": "The models developed in this study do not use data from other machine-learning algorithms as input. Instead, they directly use the preprocessed data from the Clinical Data Warehouse (CDW) stored in Microsoft SQL Server 2016. The prediction models include Logistic Regression, Balanced Random Forest (BRF), and Multilayer Perceptron (MLP). Each of these models was trained and evaluated independently using the same dataset, which was split into training and test sets.\n\nThe Logistic Regression model uses a set of independent features to model dichotomous classes and predicts the odds of an event\u2019s occurrence using an odds ratio. The BRF model is based on the Random Forest approach, which constructs multiple decision trees to improve predictive accuracy. The MLP model is a type of feedforward artificial neural network used to solve complex classification problems.\n\nThe training data for each model was independent, as the dataset was split into training and test sets following the norm of machine learning studies in healthcare. Specifically, 70% of the data was used for the training set, and 30% was used for the test set. This ensures that the models were not built and tested on the same datasets, which is crucial for evaluating their generalizability to unseen, real-world data.\n\nThe class weighting approach was utilized for the Logistic Regression and MLP models to address the imbalanced classes in the dataset. This method adjusts the misclassification costs to minimize the total cost and prevent false negatives. The BRF model, however, automatically adjusts for imbalanced conditions through a balanced down-sampling approach, making the class weighting approach unnecessary for this model.\n\nIn summary, the models developed in this study do not rely on data from other machine-learning algorithms as input. They are trained independently using the same dataset, with clear separation between training and test data to ensure robust evaluation and generalization.",
  "optimization/encoding": "In our study, data preprocessing and feature selection were crucial steps to ensure the effectiveness of our prediction models. We began by normalizing the ranges of features like age and length of inpatient stay using min-max normalization. This step was essential to prevent certain features from dominating the training process due to their numerical ranges, ensuring that each feature contributed proportionally to the model's learning.\n\nFeatures with zero variance, which remained constant across all data points, were eliminated to reduce computational cost and avoid adding redundant information. Data points with missing features were also dropped to maintain data integrity.\n\nCategorical features, such as race, ethnicity, and diagnosis codes, were transformed into binary features using one-hot encoding. This technique created new binary features corresponding to each category, assigning a value of 1 if a data point belonged to the category and 0 otherwise. This encoding method allowed our models to handle categorical data effectively.\n\nTo avoid overfitting and reduce computational memory requirements, we performed feature selection using the Balanced Random Forest (BRF) model. This process involved assessing the predictive value of each feature and selecting those with relevance scores above the mean feature importance. The selected features were then applied to both the training and test sets for further validation.\n\nThe dataset was split into a training set (70%) and a test set (30%), following standard practices in machine learning studies in healthcare. This division ensured that our models were trained and evaluated on different datasets, enhancing their generalizability to real-world, unseen data.\n\nIn summary, our data encoding and preprocessing steps included normalization, elimination of zero-variance features, handling of missing data, one-hot encoding of categorical features, and feature selection. These steps were essential in preparing the data for effective model training and evaluation.",
  "optimization/parameters": "In our study, we initially considered a total of 641 candidate features for model development. However, through a feature selection process using the Balanced Random Forest (BRF) model, we identified 189 relevant features that significantly contributed to the prediction accuracy. These selected features were then used in the final analysis.\n\nThe feature selection process involved evaluating the predictive value of each feature using the BRF model. The model provided feature importance scores, where higher values indicated greater relevance to the prediction accuracy. We used the mean of these feature importance scores as a cut-off criterion. Features with relevance scores below this mean were excluded to avoid overfitting and to reduce computational memory requirements.\n\nThis approach ensured that only the most relevant features were included in the model, enhancing its performance and generalizability to unseen data. The final set of 189 features was applied to both the training and test sets for further validation and model evaluation.",
  "optimization/features": "In the optimization process of our study, we initially considered a total of 641 candidate features. To enhance the model's performance and reduce computational complexity, feature selection was performed using the training set only. This approach helped to avoid overfitting and ensured that the selected features were relevant to the prediction task. As a result of this feature selection process, 189 features were included in the final analysis. These selected features were then applied to the test set for further validation. The top ten features with the highest importance, as determined by the Balanced Random Forest (BRF) model, included various medical conditions, demographic information, and clinical parameters, such as diseases of veins, pulmonary heart disease, age at the initial inpatient visit, and Charlson Comorbidity score. This rigorous feature selection process ensured that our models were trained on the most relevant and informative features, thereby improving their predictive accuracy and generalizability.",
  "optimization/fitting": "In our study, we developed three prediction models using Logistic Regression (LR), Balanced Random Forest (BRF), and Multilayer Perceptron (MLP). The number of parameters in these models varied significantly, with the MLP having the largest number due to its neural network structure.\n\nFor the LR model, the number of parameters was relatively small, corresponding to the number of features used in the model. We employed L2 regularization (also known as ridge regularization) to prevent overfitting. This technique adds a penalty equal to the square of the magnitude of coefficients to the loss function, which helps to keep the coefficients small and reduces the risk of overfitting.\n\nThe BRF model, being an ensemble of decision trees, inherently has a large number of parameters. To mitigate overfitting, we used a balanced down-sampling approach, which ensures that the model does not become biased towards the majority class. Additionally, we tuned hyperparameters such as the number of trees and maximum depth using 10-fold cross-validation, which helps in selecting a model that generalizes well to unseen data.\n\nThe MLP model had the most parameters due to its multiple layers and neurons. To address overfitting, we incorporated Dropout layers, which randomly set a fraction of input units to zero at each update during training time. This technique helps to prevent the model from becoming too reliant on specific neurons. Furthermore, we used early stopping during training, which monitors the model's performance on a validation set and stops training when performance stops improving. We also tuned hyperparameters such as the number of epochs, learning rate, number of layers, and neurons per layer using 10-fold cross-validation.\n\nTo ensure that our models were not underfitting, we evaluated their performance using the AUROC curve, sensitivity, and specificity. The BRF model showed the highest AUROC curve (0.84) and sensitivity (0.74), indicating that it effectively captured the positive cases without excessively increasing false positives. The LR and MLP models also performed well, with AUROC curves of 0.83 and sensitivities of 0.69 and 0.71, respectively. These results suggest that our models were appropriately complex to capture the underlying patterns in the data without being too simplistic.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was feature selection. We performed feature selection from the training set to avoid overfitting and to decrease computational memory requirements. This process involved using a classifier called the Balanced Random Forest (BRF) model to assess the predictive value of each feature. Features with relevance scores lower than the overall average were dropped, ensuring that only the most relevant features were included in the final model.\n\nAdditionally, for the Multilayer Perceptron (MLP) model, we utilized Dropout layers as a regularization technique. Dropout helps to prevent overfitting by randomly setting a fraction of input units to zero at each update during training time, which forces the network to learn more robust features that are useful in conjunction with many different random subsets of the other neurons.\n\nWe also split our dataset into training and test sets, using 70% of the data for training and 30% for testing. This approach ensures that the model is evaluated on unseen data, which helps in assessing its generalizability and preventing overfitting to the training data.\n\nFurthermore, hyperparameter tuning was performed using 10-fold cross-validation. This method involves dividing the data into 10 approximately equal partitions, using each partition for testing while the remainder is used for training. This process helps in selecting the optimal hyperparameters and ensures that the model performs well across different subsets of the data, reducing the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules for the models developed in this study are reported in the publication. Specifically, for the Logistic Regression (LR) model, the standard implementation from the Scikit-learn library in Python was used with an L2-norm penalty and the L-BFGS optimizer. The model was run with enough iterations to fully converge under a tolerance of 0.0001.\n\nFor the Balanced Random Forest (BRF) model, the number of trees and the maximum depth of a tree were tuned using 10-fold cross-validation. The optimal configuration found was 630 trees with a maximum depth of 33.\n\nThe Multilayer Perceptron (MLP) model utilized Rectified Linear Unit (ReLU) as the activation function for the hidden layers and Dropout layers for regularization. The hyperparameters tuned included the number of epochs, learning rate, number of layers, neurons per layer, and dropout rate. The final configuration used 100 epochs with early stopping, a learning rate of 0.0002, two hidden layers with 50 neurons each, and a dropout rate of 0.5.\n\nThe model files and optimization parameters are not explicitly provided in the publication, but the methods and configurations used are detailed sufficiently for replication. The data preprocessing steps, including normalization, handling of missing values, and one-hot encoding of categorical features, are also described. The study used Python software version 3.8.3 for data preprocessing and model development, with specific libraries such as Scikit-learn for logistic regression and balanced random forest, and TensorFlow for the multilayer perceptron.\n\nRegarding the availability and licensing of the configurations and parameters, the publication does not specify a particular license for the reported methods and configurations. However, the use of open-source libraries like Scikit-learn and TensorFlow suggests that the methods can be freely replicated using these tools, which are available under permissive open-source licenses.",
  "model/interpretability": "The model we developed, specifically the Balanced Random Forest (BRF), is not entirely a black-box model. While random forests are generally considered complex and less interpretable than simpler models like logistic regression, they do offer some level of transparency through feature importance.\n\nFeature importance in the BRF model helps identify which variables contribute most to the predictions. For instance, diseases of veins, lymphatic vessels, and lymph nodes, along with pulmonary heart disease and diseases of pulmonary circulation, were among the top features influencing the model's predictions. This information is crucial for understanding the underlying factors driving the risk of 30-day readmission with venous thromboembolism (VTE).\n\nAdditionally, the use of decision trees within the random forest allows for a hierarchical understanding of how different features interact. Each tree in the forest provides a pathway of decisions leading to a prediction, which can be traced to understand the logic behind the model's outputs. This hierarchical structure, though complex, offers insights into the decision-making process of the model.\n\nIn summary, while the BRF model is more complex than linear models, it provides interpretable outputs through feature importance and the decision pathways within individual trees. This makes it a valuable tool for both prediction and understanding the key factors associated with VTE risk.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the risk of venous thromboembolism (VTE) after hospital discharge, which is a binary outcome\u2014either the patient is at risk or not. Three different types of models were trained and compared: Logistic Regression, Balanced Random Forest, and Multilayer Perceptron. Each of these models was evaluated using metrics suitable for classification tasks, such as the Area Under the Receiver Operating Characteristic curve (AUROC), sensitivity, and specificity.\n\nThe Balanced Random Forest model demonstrated the highest performance, with an AUROC of 0.84 and a sensitivity of 0.74. This indicates that the model is effective in correctly identifying patients who are at risk of developing VTE post-discharge. The Logistic Regression model, while having the highest specificity at 0.84, had the lowest sensitivity at 0.69, suggesting it is better at correctly identifying patients who are not at risk but less effective at identifying those who are.\n\nThe models were trained using a dataset that underwent extensive preprocessing, including normalization, handling of missing values, and one-hot encoding of categorical features. The dataset was split into training and test sets, with 70% of the data used for training and 30% for testing. Feature selection was performed using the Balanced Random Forest model to ensure that only the most relevant features were included, thereby improving the model's predictive accuracy and reducing the risk of overfitting.\n\nIn summary, the output of this study is a classification model that can effectively predict the risk of VTE in patients after hospital discharge, with the Balanced Random Forest model showing the best performance among the models evaluated.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study focused on assessing the predictive performance of the models using several key metrics. The primary metric used was the Area Under the Receiver Operating Characteristic Curve (AUROC), which ranges from 0 to 1, with higher values indicating better performance. This metric was prioritized to measure the overall performance of the models.\n\nAdditionally, sensitivity and specificity were evaluated to assess the models' ability to correctly identify positive cases (sensitivity) and negative cases (specificity). Sensitivity was given particular importance to maximize the capture of patients with a positive outcome.\n\nTo ensure the robustness and generalizability of the models, 10-fold cross-validation was utilized. This technique involves dividing the data into 10 approximately equal partitions, where each partition is used once as the test set while the remaining data is used for training. This process helps to validate the performance of the models by ensuring they are not overfitting to a specific subset of the data.\n\nThe models were also evaluated on a separate test set, which comprised 30% of the total data. This test set was not used during the training phase, providing an unbiased estimate of the models' performance on unseen data.\n\nThe evaluation results are presented in a table, comparing the AUROC, sensitivity, and specificity of three different models: Logistic Regression, Multilayer Perceptron, and Balanced Random Forest. The Balanced Random Forest model demonstrated the highest AUROC and sensitivity, indicating its superior performance in predicting VTE risk.",
  "evaluation/measure": "The performance metrics reported in our study include the area under the receiver operating characteristic curve (AUROC), sensitivity, and specificity. These metrics are commonly used in the literature to assess the quality of classification models, particularly in healthcare settings.\n\nThe AUROC curve is a widely accepted measure for evaluating and comparing the overall performance of a model. It ranges from 0.5 to 1, with higher values indicating better performance. This metric provides a comprehensive view of a model's ability to distinguish between positive and negative classes across all possible classification thresholds.\n\nSensitivity, also known as recall or the true positive rate, measures a model's ability to correctly identify positive cases. This metric is crucial in medical contexts where the cost of missing a positive case (false negative) is high, such as in predicting venous thromboembolism (VTE) risk. High sensitivity ensures that most patients who will experience the event are correctly identified.\n\nSpecificity, on the other hand, measures the proportion of true negatives that are correctly identified. It indicates the model's ability to correctly identify patients who will not experience the event. While specificity is important, in our study, sensitivity and the AUROC curve had higher priority due to the critical need to maximize the recall of VTE positive cases.\n\nThese metrics collectively provide a robust evaluation of our models' performance. The AUROC curve offers an overall assessment, while sensitivity and specificity provide insights into the model's performance in identifying positive and negative cases, respectively. This set of metrics is representative of standard practices in the field and ensures a comprehensive evaluation of our prediction models.",
  "evaluation/comparison": "In our study, we developed and compared three prediction models using logistic regression, balanced random forest, and multilayer perceptron. We did not perform a comparison to publicly available methods on benchmark datasets. However, we did compare our models to simpler baselines, specifically logistic regression and multilayer perceptron, which are commonly used in similar studies.\n\nThe balanced random forest model outperformed the other two models, showing the highest area under the receiver operating characteristic curve and sensitivity. This indicates that the balanced random forest model has the best performance for venous thromboembolism risk prediction based on our predetermined criteria.\n\nWe used class weighting for the logistic regression and multilayer perceptron models to address the imbalanced classes in our dataset. This approach helps to minimize the cost of misclassification, particularly for the rarer class, which is regarded as the positive class. The balanced random forest model, on the other hand, automatically adjusts for imbalanced conditions through a balanced down-sampling approach.\n\nIn summary, while we did not compare our methods to publicly available benchmarks, we did evaluate and compare our models to simpler baselines, providing a comprehensive assessment of their performance.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not enough information is available."
}