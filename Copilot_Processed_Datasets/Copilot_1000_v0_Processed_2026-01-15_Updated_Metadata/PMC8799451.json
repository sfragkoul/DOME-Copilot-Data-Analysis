{
  "publication/title": "A complete framework for accurate recognition and prognosis of COVID-19 patients based on deep transfer learning and feature classification approach.",
  "publication/authors": "Balaha HM, El-Gendy EM, Saafan MM",
  "publication/journal": "Artificial intelligence review",
  "publication/year": "2022",
  "publication/pmid": "35125606",
  "publication/pmcid": "PMC8799451",
  "publication/doi": "10.1007/s10462-021-10127-8",
  "publication/tags": "- COVID-19\n- Machine Learning\n- Prognosis\n- Severity Prediction\n- CT Chest Images\n- Laboratory Test Results\n- Diagnostic Framework\n- Ensemble Bagged Trees\n- Convolutional Neural Networks\n- Data Augmentation",
  "dataset/provenance": "The dataset utilized in our study comprises CT images of Egyptian patients, sourced from various radiology centers across Egypt. This dataset is diverse, containing a total of 15,535 CT images. Of these, 5,159 images are confirmed positive COVID-19 cases, while the remaining 10,376 images are of non-COVID-19 cases, serving as the control group. All images are in the JPG format, ensuring compatibility with our computational framework.\n\nThe decision to use this specific dataset was influenced by recommendations from previous studies, which emphasized the importance of incorporating high-quality, locally sourced data to avoid overfitting and address bias issues. By including a substantial number of images from Egyptian patients, we aimed to build a robust model that can be reliably applied in local healthcare settings.\n\nOur dataset is unique in its focus on Egyptian patients, providing a valuable contribution to the existing body of research. While other studies may have used different datasets or sources, our approach ensures that the model is tailored to the specific characteristics and needs of the Egyptian population. This localization is crucial for enhancing the accuracy and reliability of COVID-19 diagnosis in our target demographic.",
  "dataset/splits": "The dataset was split into three parts: training, validation, and testing. The split ratio was 85% for training and validation combined, and 15% for testing. The training and validation portion was further divided internally into 85% for training and 15% for validation. This means that approximately 85% of the total dataset was used for training, 12.75% for validation, and 15% for testing. The dataset consisted of 15,535 images, with 5,159 COVID-19 cases and 10,376 non-COVID-19 cases. The distribution of data points in each split reflects this overall ratio.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to several well-established classes, including decision trees, discriminant analysis, regression, Na\u00efve Bayes, support vector machines (SVM), k-nearest neighbors (KNN), and ensemble methods.\n\nThe algorithms employed are not new; they are commonly used machine-learning techniques. These algorithms were selected because they are among the most prevalent and effective methods for classification tasks. Decision trees, for instance, are used for their ability to handle both numerical and categorical data and to provide interpretable models. Discriminant analysis, particularly linear and quadratic discriminant analysis, is known for its simplicity and effectiveness in classification problems. Logistic regression is a staple in statistical modeling for binary outcomes. Na\u00efve Bayes classifiers are popular for their simplicity and effectiveness, especially with high-dimensional data. Support vector machines are powerful for high-dimensional spaces and are effective in cases where the number of dimensions exceeds the number of samples. K-nearest neighbors is a non-parametric method used for classification and regression. Ensemble methods, such as bagged trees and boosted trees, combine multiple models to improve overall performance and robustness.\n\nThe choice to use these established algorithms in a study focused on COVID-19 prognosis is driven by their proven track records and wide applicability. The study aims to leverage these algorithms to achieve high accuracy in predicting COVID-19 severity, rather than introducing new algorithms. The focus is on applying and comparing these methods to determine the most effective approach for the specific problem at hand. The results demonstrate that ensemble methods, particularly the Ensemble Bagged Trees, achieved the highest accuracy, underscoring their effectiveness in this context.",
  "optimization/meta": "The meta-predictor approach employed in our study leverages the outputs of multiple machine learning algorithms to enhance the prognosis of COVID-19 severity. This method involves using the predictions from various algorithms as input features for a higher-level model. The constituent machine-learning methods include a diverse range of algorithms such as Discriminant (Linear Discriminant and Quadratic Discriminant), Regression (Logistic Regression), Na\u00efve Bayes (Gaussian Na\u00efve Bayes and Kernel Na\u00efve Bayes), SVM (Linear SVM, Quadratic SVM, Cubic SVM, Fine Gaussian SVM, Medium Gaussian SVM, and Coarse Gaussian SVM), KNN (Fine KNN, Medium KNN, Coarse KNN, Cosine KNN, Cubic KNN, and Weighted KNN), and Ensemble methods (Ensemble Boosted Trees, Ensemble Bagged Trees, Ensemble Subspace Discriminant, Ensemble Subspace KNN, and Ensemble RUSBoosted Trees).\n\nThe Ensemble Bagged Trees method, in particular, demonstrated the highest accuracy, achieving 98.7% in both standardized and non-standardized experiments. This indicates the robustness of the ensemble approach in handling the data, regardless of the standardization process.\n\nRegarding the independence of the training data, it is crucial to ensure that the data used to train the individual algorithms and the meta-predictor are independent. This independence is maintained through rigorous cross-validation techniques, where each machine learning algorithm is applied to 50 cross-validation folds. This process helps to avoid overfitting and ensures that the meta-predictor generalizes well to unseen data. The standardization method, which centers the data around the mean with a unit standard deviation, further aids in maintaining the integrity and independence of the training data.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithms. For numerical datasets, we began by handling missing values, filling any empty or null entries with zeros. This step was essential to maintain the integrity of the data and prevent any disruptions in the learning process.\n\nFollowing this, we applied a standardization method to scale the data. Standardization centers the values around the mean, making the mean zero, and ensures a unit standard deviation. This process is vital for algorithms that are sensitive to the scale of the data, as it helps in improving the convergence speed and performance of the models. The standardization formula used was X' = (X - \u03bc) / \u03c3, where \u03bc is the mean of the features and \u03c3 is the standard deviation of the features.\n\nFor image data, such as CT scans, preprocessing involved several steps to convert the dataset into a suitable format for Convolutional Neural Networks (CNNs). This included handling images from different sources, which often have varying dimensions and may contain unnecessary details or noise. The preprocessing steps ensured that the images were standardized and free from irrelevant information, allowing the CNN to focus on detecting the necessary features for accurate recognition and prognosis.\n\nIn summary, our data encoding and preprocessing steps were designed to prepare both numerical and image data for effective machine-learning model training. These steps included handling missing values, standardization of numerical data, and comprehensive preprocessing of image data to enhance the performance and accuracy of our models.",
  "optimization/parameters": "In our study, the number of parameters used in the model varies depending on the specific machine learning algorithm employed. For instance, in logistic regression, the number of parameters is determined by the number of input variables plus one for the bias term. In discriminant analysis, the number of parameters is influenced by the dimensionality of the feature space and the number of classes.\n\nThe selection of parameters was guided by the nature of the data and the requirements of each algorithm. For logistic regression, the parameters were chosen based on the features that showed significant correlation with the target variable. In discriminant analysis, the parameters were selected to maximize the separation between classes. Additionally, techniques such as regularization were employed to handle high-dimensional data and prevent overfitting.\n\nFor the convolutional neural networks (CNNs) used in our image classification tasks, the number of parameters is much larger and is determined by the architecture of the network. We utilized pre-trained models like EfficientNetB7, InceptionV3, and ResNet-50, which have been optimized for performance on large datasets. The parameters in these models were fine-tuned using transfer learning techniques, where the weights were adjusted based on our specific dataset of CT images.\n\nIn summary, the number of parameters in our models was selected based on a combination of domain knowledge, statistical significance, and empirical performance. The goal was to achieve a balance between model complexity and generalization ability, ensuring that the models could accurately predict the severity of COVID-19 infections and the need for ICU transfer.",
  "optimization/features": "The input features used in our study are derived from laboratory test results extracted from patients\u2019 records. These features serve as prognostic markers to assess the severity of pneumonia in COVID-19 patients. The specific features include various clinical and laboratory parameters such as gender, age, admission time, INR, PT, fibrinogen, lung tissue affected, platelet count, ICU transfer time, CRP levels, and the use of artificial ventilation. A sample of these prognostic markers is presented in a dataset, illustrating the diversity and richness of the input features.\n\nFeature selection was not explicitly mentioned as a separate step in our methodology. However, the preprocessing steps involved filling empty values with zeros and applying standardization to the dataset. Standardization centers the values around the mean with a unit standard deviation, which can be seen as a form of feature scaling rather than feature selection. This process ensures that all features contribute equally to the model, enhancing the performance and stability of the machine learning algorithms used.\n\nThe preprocessing, including standardization, was applied to the entire dataset before splitting it into training and testing sets. This approach ensures that the training set is used to learn the necessary patterns without any information leakage from the testing set, maintaining the integrity of the model evaluation process.",
  "optimization/fitting": "In our study, we employed a variety of machine learning algorithms to ensure robust and generalizable results. To address the potential issue of overfitting, where the number of parameters might be much larger than the number of training points, we implemented several strategies.\n\nFirstly, we applied cross-validation, specifically using 50 cross-validation folds. This technique helps to assess the model's performance on different subsets of the data, reducing the risk of overfitting to any single subset.\n\nAdditionally, we utilized batch normalization, which adaptively normalizes the input values of the next layer. This method reduces overfitting, improves the flow through the network, and allows for the use of higher learning rates, thereby lessening the reliance on the weight initialization process.\n\nWe also experimented with both standardized and non-standardized data. Standardization centers the values around the mean with a unit standard deviation, which can help in stabilizing and speeding up the training process. However, we found that in some cases, non-standardized data yielded higher accuracies, indicating that the choice of preprocessing can significantly impact the model's performance.\n\nTo further mitigate overfitting, we employed ensemble methods, such as Ensemble Bagged Trees, which reported the highest accuracy value of 98.7% in our experiments. Ensemble methods combine the predictions of multiple models, reducing the variance and improving the overall performance.\n\nRegarding underfitting, we ensured that our models were complex enough to capture the underlying patterns in the data. We used a diverse set of 25 machine learning classification algorithms, including decision trees, discriminant analysis, logistic regression, support vector machines, k-nearest neighbors, and various ensemble methods. This diversity allowed us to select the most appropriate model for our dataset, balancing bias and variance.\n\nMoreover, we compared our results with state-of-the-art studies, demonstrating that our approach achieved higher accuracies than 11 related studies. This comparison provides confidence that our models are not underfitting the data.\n\nIn summary, we employed cross-validation, batch normalization, standardization, ensemble methods, and a diverse set of algorithms to address both overfitting and underfitting, ensuring robust and generalizable results.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting, a common challenge in machine learning and deep learning models. One effective method we utilized was batch normalization. This technique adaptively normalizes the input values of the subsequent layer, which helps to reduce overfitting, improve the flow of information through the network, and allows for the use of higher learning rates. Additionally, it lessens the dependence on the weight initialization process, making the training more stable and efficient.\n\nAnother crucial technique we implemented was data augmentation. This method addresses the issue of limited training data, which can lead to overfitting. By applying various distortions to the training samples, such as brightness changes, cropping, rotation, shearing, zooming, and flipping, we were able to generate new training data. This approach significantly increased the diversity of our training dataset, helping the model to generalize better to unseen data.\n\nFurthermore, we employed cross-validation, specifically using 50 cross-validation folds. This technique ensures that the model is evaluated on different subsets of the data, reducing the risk of overfitting to a particular subset. Cross-validation provides a more robust estimate of the model's performance and helps in selecting the best hyperparameters.\n\nIn summary, our study incorporated batch normalization, data augmentation, and cross-validation as key strategies to mitigate overfitting and enhance the model's generalization capabilities.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters are indeed available. These details are summarized in a table that outlines the configurations used for the experiments. The table includes specifics such as the dataset type, size, split ratio, pre-processing steps, data augmentation techniques, pre-trained CNN models, pre-trained weights, optimizer settings, learning rate, number of epochs, and batch size. This information provides a comprehensive overview of the experimental setup.\n\nThe optimization schedule is also detailed, with the number of epochs set to 128 and a batch size of 32. The Adam optimizer was used with a learning rate of 0.0002 and a beta value of 0.5. These parameters were consistently applied across all experiments to ensure comparability of results.\n\nRegarding model files and optimization parameters, the specific details about where these can be accessed or their licensing information is not provided. However, the use of Python and specific libraries such as Keras, NumPy, MatPlotlib, OpenCV, and Pandas is mentioned, which are commonly used in the machine learning community and have their own licensing terms. The training environments included a Toshiba Qosmio X70-A device and Google Colab, both of which are standard tools in the field.\n\nFor those interested in replicating the experiments, the provided configurations and parameters offer a clear roadmap. However, for access to the actual model files or more detailed optimization parameters, additional information or direct contact with the authors may be necessary.",
  "model/interpretability": "The model we propose is not entirely transparent and can be considered somewhat of a black box, particularly in its deep learning components. The use of pre-trained Convolutional Neural Networks (CNNs) such as EfficientNetB7, InceptionV3, ResNet-50, VGG-16, VGG-19, Xception, and MobileNetV1 for image classification involves complex architectures with millions of parameters. These models learn hierarchical features from the data, making it challenging to interpret exactly how they arrive at their predictions.\n\nHowever, efforts have been made to enhance interpretability in certain aspects of our framework. For instance, the use of data augmentation techniques like CycleGAN and CCGAN, along with traditional methods, helps in understanding how the model generalizes to new, unseen data. Additionally, the Early Prognostic Phase (EPP) utilizes laboratory test results, which are more interpretable as they are based on established medical markers.\n\nIn terms of transparency, the machine learning algorithms used for prognosis, such as Ensemble Bagged Trees, provide some level of interpretability. These algorithms can be analyzed to understand the importance of different features in making predictions. For example, the feature importance scores can indicate which laboratory test results are most influential in predicting the severity of COVID-19.\n\nMoreover, the framework's two-phase approach\u2014Early Diagnostic Phase (EDP) and Early Prognostic Phase (EPP)\u2014provides a clear structure for understanding the model's workflow. The EDP focuses on diagnosing COVID-19 using chest CT images, while the EPP aims to predict the severity of the disease using laboratory test results. This separation helps in isolating and interpreting the different components of the model.\n\nOverall, while the deep learning components of our model are complex and somewhat opaque, the use of interpretable machine learning algorithms and a structured framework helps in providing insights into the model's decision-making process.",
  "model/output": "The model discussed in this publication is primarily focused on classification tasks. Various classification algorithms are explored, including discriminant analysis, logistic regression, support vector machines (SVM), and k-nearest neighbors (KNN). These algorithms are used to categorize data into different classes based on the features provided. The goal is to accurately recognize and prognose outcomes by selecting the algorithm that achieves the best accuracy. The output of the model is the classification of new data into predefined categories, which serves as the main lead for prognosing infections or other outcomes of interest. The dataset undergoes preprocessing steps such as filling empty values and standardization before being fed into the machine learning classifiers. The final chosen algorithm's results are used to make predictions and prognoses.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the Early Diagnostic Phase (EDP) is written in Python and is not publicly released. The scripts for the Early Prognostic Phase (EPP) are written in MATLAB and are also not publicly released. No executable, web server, virtual machine, or container instance is provided for running the algorithms.\n\nThe training environments used include a Toshiba Qosmio X70-A device with specific hardware configurations and Google Colab with GPU support. The Python packages used for the EDP include Keras, NumPy, MatPlotlib, OpenCV, and Pandas. However, these details are provided for reproducibility purposes and do not imply that the code itself is available for public use.",
  "evaluation/method": "In our study, we employed a robust evaluation method to ensure the reliability and generalizability of our results. We utilized 50 cross-validation folds for each machine learning algorithm to mitigate the risk of overfitting. This approach allowed us to thoroughly assess the performance of our models by training and validating them on different subsets of the data.\n\nFor the machine learning experiments, we conducted a comprehensive analysis using various configurations, as summarized in the relevant tables. We evaluated the performance of different machine learning algorithms both with and without the application of standardization methods. The results, presented in the respective tables, highlight the effectiveness of the Ensemble Bagged Trees method, which reported the highest accuracy value of 98.7% in both scenarios.\n\nIn addition to the machine learning experiments, we also evaluated the performance of several deep learning architectures. We compared the results of different augmentation techniques, including no augmentation, CC-GAN, and CycleGAN. The performance metrics, such as accuracy, AUC, recall, precision, and F1-score, were carefully analyzed for each model. For instance, the EfficientNetB7 architecture achieved the highest testing accuracy of 99.61% with no augmentation, while the MobileNetV1 architecture reported a testing accuracy of 99.57% with CycleGAN augmentation. These results demonstrate the superior performance of advanced augmentation techniques in preserving important features in the images.\n\nOverall, our evaluation method involved a combination of cross-validation, performance metric analysis, and comparison of different augmentation techniques. This comprehensive approach allowed us to thoroughly assess the effectiveness of our models and ensure the reliability of our findings.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report a comprehensive set of metrics to evaluate the effectiveness of our proposed framework. The metrics include loss, accuracy, area under the curve (AUC), recall, precision, and F1 score. These metrics are calculated for both the testing subset and the entire dataset, providing a thorough assessment of our models' performance.\n\nThe loss value indicates the error rate of the model, with lower values signifying better performance. Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. The AUC represents the ability of the model to distinguish between classes, with a value closer to 1 indicating better performance.\n\nRecall, also known as sensitivity, evaluates the model's ability to identify positive samples. Precision assesses the correctness of the positive predictions made by the model. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n\nThis set of metrics is widely used in the literature and is considered representative of the state-of-the-art in performance evaluation for similar studies. By including these metrics, we ensure that our results are comparable with other works in the field, allowing for a fair assessment of our framework's effectiveness.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison with state-of-the-art methods to evaluate the performance of our proposed approach. We compared our results with several publicly available studies, including those by Apostolopoulos and Mpesiana (2020), Ozturk (2020), Brunese et al. (2020), and others. These comparisons were performed on benchmark datasets to ensure a fair and rigorous evaluation.\n\nOur approach, which utilizes Convolutional Neural Networks (CNN) and Transfer Learning (TL), demonstrated superior accuracy compared to many of these state-of-the-art methods. Specifically, our study achieved an accuracy of 99.61%, which is higher than the accuracies reported by 11 related studies. This comparison is visually represented in Figure 19, which provides a graphical comparison of the results in ascending order.\n\nIn addition to comparing with advanced methods, we also evaluated simpler baselines to understand the relative performance gains. For instance, we applied various machine learning algorithms to 50 cross-validation folds to avoid overfitting. The Ensemble Bagged Trees method reported the highest accuracy value of 98.7%, both with and without the application of the standardization method. This indicates that our more complex CNN and TL approach provides a significant improvement over simpler machine learning baselines.\n\nFurthermore, we conducted experiments with different architectures and augmentation techniques. For example, the EfficientNetB7 model without augmentation achieved the highest testing accuracy of 99.61%. Other architectures like InceptionV3, ResNet50, VGG-16, VGG-19, Xception, and MobileNetV1 also showed high accuracies, with values ranging from 99.14% to 99.57%. These results highlight the robustness and effectiveness of our approach across different models and augmentation strategies.",
  "evaluation/confidence": "In our study, we employed cross-validation to ensure the robustness of our results and to avoid overfitting. Specifically, each machine learning algorithm was applied to 50 cross-validation folds. This rigorous approach helps to provide a more reliable estimate of the model's performance and its generalizability to new, unseen data.\n\nRegarding confidence intervals for the performance metrics, they were not explicitly mentioned in our results. However, the use of cross-validation inherently provides a measure of variability in the performance metrics, which can be interpreted as a form of confidence interval. Each fold's performance can be considered a sample from the distribution of possible performances, and the variability across these folds gives an indication of the uncertainty in the estimated metrics.\n\nStatistical significance was not explicitly discussed in the context of comparing our method to others and baselines. However, the high accuracy values achieved, particularly with the Ensemble Bagged Trees method reaching 98.7%, suggest strong performance. Additionally, our study reported accuracies higher than 11 related studies, indicating competitive and potentially superior performance.\n\nIn summary, while confidence intervals were not explicitly provided, the use of cross-validation offers a measure of performance variability. The high accuracy values and comparisons with state-of-the-art studies suggest that our method is robust and potentially superior.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study utilized a dataset consisting of CT images, with a total of 15,535 images, split into 5,159 COVID-19 cases and 10,376 non-COVID-19 cases. The dataset was divided into an 85% training set and a 15% testing set. However, due to privacy concerns and the sensitivity of medical data, the raw images and evaluation files have not been released publicly.\n\nThe dataset was collected from different centers, which may introduce variations in image quality and encoding formats. These variations could potentially cause small errors in the evaluation process. Despite these challenges, the results obtained from our study are promising, and the proposed framework's concepts can be applied in hospitals and COVID-caring centers to develop more reliable systems.\n\nThe evaluation was conducted using various performance metrics, including accuracy, F1-score, precision, recall, and the area under the curve (AUC). These metrics were calculated for different experiments involving various deep learning architectures and data augmentation techniques. The highest testing accuracies were achieved using architectures like EfficientNetB7, InceptionV3, ResNet50, and MobileNetV1, with accuracies exceeding 99%.\n\nThe study also highlights the limitations associated with the unavailability of images and the need for improved data augmentation methods. Future work may involve addressing these limitations to further enhance the reliability and accuracy of the proposed framework."
}