{
  "publication/title": "Study of morphological and textural features for classification of oral squamous cell carcinoma by traditional machine learning techniques.",
  "publication/authors": "Rahman TY, Mahanta LB, Choudhury H, Das AK, Sarma JD",
  "publication/journal": "Cancer reports (Hoboken, N.J.)",
  "publication/year": "2020",
  "publication/pmid": "33026718",
  "publication/pmcid": "PMC7941561",
  "publication/doi": "10.1002/cnr2.1293",
  "publication/tags": "- Oral squamous cell carcinoma\n- Machine learning\n- Morphological features\n- Textural features\n- Biopsy images\n- Classification\n- Support vector machine\n- Logistic regression\n- Linear discriminant\n- K-nearest neighbors\n- Decision tree classifier\n- Cancer diagnosis\n- Medical imaging\n- Feature extraction\n- Cross-validation\n- Histopathological analysis\n- Nucleus segmentation\n- Pattern recognition\n- Supervised learning\n- Image processing",
  "dataset/provenance": "The dataset used in this study was collected from two diagnostic centers: Ayursundra Healthcare Pvt. Ltd. and Dr. B. Borooah Cancer Institute. A total of 40 biopsy slides were collected from 40 patients, with 13 slides containing normal cells and 27 slides containing malignant cells. From these slides, 118 normal cells and 334 malignant cells were cropped out to create the nuclei dataset.\n\nThe images were acquired using a Leica ICC50 HD microscope at a magnification of \u00d7400, resulting in images of size 2048 \u00d7 1536 pixels. The slides were initially graded according to the Broder's grading system and then grouped into \"normal\" or \"malignant\" categories. Only cases with confirmed histopathological correlation were included in the study.\n\nThis dataset is unique because there is no publicly available oral squamous cell carcinoma (OSCC) cell-level database that can be considered a benchmark dataset. Therefore, this indigenous dataset was prepared specifically for this study. The images can be found online at specified DOIs and GitHub repositories, making them available for further research and validation by the community.",
  "dataset/splits": "The dataset was divided into five parts for the purpose of five-fold cross-validation. This technique is used to evaluate the performance of the classifiers and to prevent overfitting, especially when dealing with a limited dataset.\n\nIn each fold, four parts of the dataset were used for training the classifier, while the remaining part was used for validation. This process was repeated five times, with each part of the dataset serving as the validation set once. Therefore, each fold contained approximately 80% of the data for training and 20% for testing.\n\nThe dataset consisted of 452 cells in total, with 118 normal cells and 334 malignant cells. Since the dataset was divided into five folds, each fold would contain approximately 362 cells for training and 90 cells for testing. The distribution of normal and malignant cells in each fold would be proportional to their representation in the entire dataset.",
  "dataset/redundancy": "In our study, we employed a five-fold cross-validation technique to ensure robust and reliable classification results. This method is particularly useful when dealing with limited datasets, as it helps to mitigate the risk of overfitting.\n\nThe dataset was divided into five parts. In each fold of the cross-validation, four parts were used for training the classifier, while the remaining part served as the test set. This process was repeated five times, with each part of the dataset serving as the test set exactly once. This approach ensures that every data point is used for both training and testing, providing a comprehensive evaluation of the classifier's performance.\n\nThe independence of the training and test sets was enforced by the cross-validation technique itself. In each fold, the test set was completely separate from the training set, ensuring that the classifier was evaluated on unseen data. This independence is crucial for obtaining an unbiased estimate of the classifier's performance.\n\nRegarding the distribution of the dataset, we worked with a total of 452 cells, comprising 118 normal cells and 334 malignant cells. This distribution is reflective of the real-world prevalence of these cell types, ensuring that our results are clinically relevant. Compared to previously published machine learning datasets in similar domains, our dataset size is modest but sufficient for the purposes of our study, given the rigorous cross-validation technique employed.\n\nIn summary, the five-fold cross-validation technique was used to split the dataset into training and test sets, ensuring independence and robustness in our classification results. The distribution of the dataset aligns with clinical realities, providing a solid foundation for our analysis.",
  "dataset/availability": "The data that support the findings of this study are available from the corresponding author upon reasonable request. The images can be found online at https://doi.org/10.1016/j.dib.2020.105114, https://doi.org/10.17632/ftmp4cvtmb.1 and https://github.com/Tabassum2019/A-histopathological-image-repository-of-normal-epithelium-of-Oral-Cavity-and-OSCC/blob/master/README.md. The data is not publicly available in a forum, but it can be accessed through the corresponding author. The data is available under the terms of the Creative Commons Attribution-NonCommercial License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited and is not used for commercial purposes.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are traditional supervised techniques, specifically Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Linear Discriminant Analysis (LDA), Logistic Regression, and Decision Tree classifiers. These are well-established methods in the field of machine learning and have been extensively used for various classification tasks.\n\nThe algorithms employed are not new; they are widely recognized and have been applied in numerous studies across different domains. The choice of these algorithms was driven by their effectiveness in handling classification problems, particularly in medical imaging and diagnostics. These techniques are robust and have been proven to deliver reliable results in similar contexts.\n\nThe decision to use these traditional machine-learning algorithms was influenced by several factors. Firstly, the dataset available for this study was not large enough to warrant the use of deep learning techniques, which typically require extensive data for training. Secondly, traditional machine-learning methods are cost-effective and can be implemented using standard computing resources, making them more accessible and practical for use in various settings, including remote areas or economically disadvantaged regions. Additionally, these algorithms can be trained efficiently using a CPU, which is more viable for widespread adoption compared to the GPU requirements of deep learning models.\n\nThe focus of this study was on developing an accurate algorithm for oral squamous cell carcinoma (OSSCC) detection, leveraging the strengths of these established machine-learning techniques. The results demonstrated high accuracy, particularly with the decision tree classifier, which achieved an accuracy of 99.78% in OSSC detection. This indicates that traditional machine-learning algorithms can be highly effective for medical diagnostic tasks, even with limited data.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the quality and consistency of the input data for the machine-learning algorithms. Initially, we manually cropped 452 cell nuclei from 40 biopsy slides, including 118 normal cells and 334 malignant cells. This manual cropping was essential to generate a reliable training dataset, preserving the original size and features of the cells.\n\nThe collected images varied in staining and illumination, which could affect the results. To address this, we applied color channeling as a preprocessing step. We converted the original red, green, and blue (RGB) components of the images into different color components: cyan, magenta, and yellow. Additionally, we calculated hue, saturation, and intensity (HSI) values. Among these, the cyan channel was chosen for further processing as it provided the best outcomes.\n\nTo eliminate illumination differences, we adjusted the contrast of the images using the `imadjust` function in MATLAB. This function maps the intensity values of the images, saturating 1% of the data at low and high intensities, thereby enhancing the image quality.\n\nAfter preprocessing, we segmented the nuclei from the background using a proposed segmentation technique. This step was vital for extracting morphological and textural features accurately. The segmented images retained the actual size information of the nuclei, which was crucial for feature extraction.\n\nFollowing segmentation, we extracted 522 morphological features from the nuclei. To reduce the dimensionality and select statistically significant features, we applied Karl Pearson's t-test, which reduced the feature set to 516 features. Subsequently, Principal Component Analysis (PCA) was applied to further reduce the feature set to 340 significant features. These two feature sets (452x516 and 452x340) were then used for classification.\n\nFor classification, we employed five different classifiers: Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Decision Tree, Logistic Regression, and Linear Discriminant Analysis. To ensure the robustness of our models and prevent overfitting, we used a five-fold cross-validation technique. This involved dividing the dataset into five parts, using four parts for training and one part for testing, and repeating this process five times. The average classification accuracy from these five tests was used to evaluate the performance of each classifier.",
  "optimization/parameters": "In our study, we initially extracted a total of 963 features from the cell images, comprising 522 morphological features and 441 textural features. To ensure that only statistically significant features were used for classification, we employed a two-level feature selection technique. The first level involved applying Karl Pearson's t-test to identify significant features, reducing the morphological feature set to 516 features and the textural feature set to 349 features. The second level involved using Principal Component Analysis (PCA) to further reduce the dimensionality of the feature sets. This process resulted in 340 significant morphological features and 103 significant textural features. These reduced feature sets were then used as input parameters for the classification models. The final combined feature set, consisting of 443 features, was used for the classification task. This rigorous feature selection process helped in enhancing the model's performance and reducing the risk of overfitting.",
  "optimization/features": "In our study, we initially extracted a total of 522 morphological features and 441 textural features from the nuclei of cells. To reduce the dimensionality and improve the classification performance, we performed feature selection using two methods: the t-test and Principal Component Analysis (PCA).\n\nThe t-test was applied to identify statistically significant features, reducing the morphological feature set to 516 features and the textural feature set to 349 features. Subsequently, PCA was used to further refine these feature sets, resulting in 340 significant morphological features and 103 significant textural features.\n\nFor the final classification, we combined the PCA-selected feature sets from both morphological and textural analyses, resulting in a combined feature set of 443 features. This combined set was then used as input for the classifiers.\n\nFeature selection was performed using the entire dataset, ensuring that the process was conducted independently of the training set to avoid data leakage and maintain the integrity of the validation process. This approach helped in mitigating the risk of overfitting and enhanced the generalization capability of the classifiers.",
  "optimization/fitting": "In our study, we employed several classifiers, including SVM, KNN, decision tree, logistic regression, and linear discriminant, to analyze two feature sets derived from morphological and textural features of nuclei. Given the limited dataset of 452 cells, there was a risk of overfitting. To mitigate this, we utilized a five-fold cross-validation technique. This method involved dividing the entire dataset into five parts, using four parts for training and one part for testing in each fold. This process was repeated five times, ensuring that each part of the dataset was used for validation once. The final classification accuracy was determined by averaging the results from all five folds.\n\nTo further address the risk of overfitting, we applied statistical tests and principal component analysis (PCA) to reduce the feature set. Initially, 522 morphological features were extracted. A t-test reduced this to 516 features, and subsequent PCA further narrowed it down to 340 significant features. This dimensionality reduction helped in focusing on the most relevant features, thereby reducing the complexity of the model and the risk of overfitting.\n\nAdditionally, we assessed the performance of each classifier using metrics such as sensitivity, precision, specificity, and overall accuracy. The receiver operating characteristic (ROC) curve was also plotted to evaluate the classifiers' performance. The decision tree classifier was ultimately selected as the most suitable due to its high accuracy and efficient training time, especially as the number of input data increased.\n\nIn summary, by employing cross-validation, feature reduction techniques, and thorough performance evaluation, we ensured that our models were neither overfitted nor underfitted, providing reliable and accurate classification results.",
  "optimization/regularization": "In our study, we employed a five-fold cross-validation technique to prevent overfitting. This method involves dividing the entire dataset into five parts. Four of these parts are used for training the classifier, while the remaining part serves as the test set to evaluate the classifier's performance. This process is repeated five times, with each part of the dataset serving as the test set once. The final classification accuracy is determined by averaging the results from all five tests. This approach helps to ensure that the model generalizes well to unseen data and mitigates the risk of overfitting, especially when dealing with limited datasets.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The model employed in our study is not a blackbox. It utilizes traditional machine learning techniques, which are generally more interpretable than deep learning models. The features used for classification are morphological and textural, which are clinically significant and biologically interpretable. These features are extracted from hand-cropped cell nuclei in biopsy images, making them directly relatable to pathological observations.\n\nFor instance, morphological features might include the size, shape, and structure of cell nuclei, which are visual characteristics that pathologists routinely examine. Textural features, on the other hand, capture the patterns and variations within the cell nuclei, providing additional insights into the cellular environment.\n\nThe decision tree classifier, which achieved the highest accuracy in our study, is particularly transparent. It operates by splitting the data into subsets based on the value of input features, creating a tree-like model of decisions. Each split is based on a single feature, making it easy to trace the decision-making process and understand which features are most influential in classifying a cell as malignant or normal.\n\nMoreover, the use of five-fold cross-validation ensures that the model's performance is robust and not due to overfitting, further enhancing the reliability and interpretability of the results. The features selected through statistical tests and principal component analysis are those that contribute most significantly to the classification task, providing a clear and concise set of criteria for diagnosis.",
  "model/output": "The model is a classification model. It was designed to distinguish between normal and malignant cells, specifically for the diagnosis of oral squamous cell carcinoma. The model employs various classifiers, including SVM, KNN, decision tree, logistic regression, and linear discriminant analysis, to categorize the cells based on their features. The performance of these classifiers was evaluated using metrics such as sensitivity, precision, specificity, and overall accuracy. The decision tree classifier demonstrated the highest accuracy, making it the most suitable for this task. The model's effectiveness was further validated using a confusion matrix and a receiver operating characteristic (ROC) curve, which showed an area under the curve (AUC) of 0.99, indicating a highly efficient classifier. The final feature set used for classification consisted of 443 principal component analysis (PCA)-selected features, combining both morphological and textural characteristics of the cells.",
  "model/duration": "The execution time of the model varied depending on the classifier used and the number of images in the dataset. For instance, when using a decision tree classifier, the training time increased with the number of images, ranging from approximately 2.1 seconds for 10 images to about 4.02 seconds for 400 images. Similarly, other classifiers like support vector machines (SVM) and k-nearest neighbors (KNN) also showed an increase in training time as the dataset size grew. This trend indicates that the model's training time is directly proportional to the size of the input data. Despite the variation in execution time, the decision tree classifier was ultimately selected for its efficiency and accuracy in classifying oral cancer cells based on morphological and textural features. The area under the curve (AUC) of the receiver operating characteristic (ROC) achieved 0.99, demonstrating the classifier's high performance and reliability.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method involved several steps to ensure its robustness and accuracy. Initially, a dataset consisting of 452 cells, including 118 normal cells and 334 malignant cells, was used. From these cells, 522 morphological features were extracted. To reduce the feature set, Karl Pearson's t-test was applied, resulting in 516 significant features. Further dimensionality reduction was achieved using Principal Component Analysis (PCA), which identified 340 significant features.\n\nTwo feature sets, one with 516 features and another with 340 features, were then fed into five different classifiers: Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Decision Tree, Logistic Regression, and Linear Discriminant Analysis. To mitigate the risk of overfitting, especially with a limited dataset, a five-fold cross-validation technique was employed. This involved dividing the dataset into five parts, using four parts for training and one part for testing, and repeating this process five times. The classification accuracy was determined by averaging the results of all five tests.\n\nThe performance of each classifier was assessed using metrics such as sensitivity, precision, specificity, and overall accuracy. These metrics were calculated using the formulas for true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). Additionally, Receiver Operating Characteristic (ROC) curves were plotted to further evaluate the classifiers' performance. The area under the curve (AUC) was also calculated to provide a comprehensive assessment of the classifiers' efficiency.\n\nThe decision tree classifier was ultimately selected as the most suitable for this work, demonstrating high accuracy and efficiency. The confusion matrix for the decision tree classifier was generated to visualize the distribution of true positives, true negatives, false positives, and false negatives. The ROC curve for the decision tree classifier showed an AUC of 0.99, indicating excellent performance. Furthermore, the training time for each classifier was analyzed, revealing that accuracy generally increased with the size of the training data. This evaluation process ensured that the proposed method was thoroughly tested and validated for its effectiveness in classifying cells as normal or malignant.",
  "evaluation/measure": "In our evaluation, we assessed the performance of the classifiers using several key metrics to ensure a comprehensive understanding of their effectiveness. The primary metrics reported include sensitivity, precision, specificity, and overall accuracy. These metrics are calculated using the formulas:\n\n- Sensitivity = (True Positives / (True Positives + False Negatives)) \u00d7 100%\n- Precision = (True Positives / (True Positives + False Positives)) \u00d7 100%\n- Specificity = (True Negatives / (True Negatives + False Positives)) \u00d7 100%\n- Overall Accuracy = ((True Positives + True Negatives) / (True Positives + False Positives + False Negatives + True Negatives)) \u00d7 100%\n\nThese metrics provide a detailed view of the classifier's performance by considering different aspects of the classification results. Sensitivity measures the ability of the classifier to correctly identify positive cases, while precision indicates the accuracy of the positive predictions made by the classifier. Specificity evaluates the classifier's ability to correctly identify negative cases, and overall accuracy gives a general measure of the classifier's performance across all cases.\n\nAdditionally, we plotted the receiver operating characteristic (ROC) curve to further assess the classifiers' performance. The area under the curve (AUC) of the ROC provides a single scalar value that summarizes the classifier's ability to distinguish between the positive and negative classes. An AUC of 0.99 was achieved, indicating that the built classifier is highly efficient.\n\nThe set of metrics used in our evaluation is representative of standard practices in the literature. Sensitivity, precision, specificity, and overall accuracy are commonly reported metrics in classification tasks, and the ROC curve is a well-established method for evaluating the performance of binary classifiers. This comprehensive approach ensures that our evaluation is thorough and comparable to other studies in the field.",
  "evaluation/comparison": "In our evaluation, we compared several standard segmentation techniques to determine the most effective method for segmenting nuclei in our dataset. Techniques such as Otsu's segmentation, Watershed segmentation, and maximally stable extremal regions (MSER) were initially applied. However, none of these methods alone provided satisfactory results. Otsu's method, while better than MSER and Watershed segmentation, still required enhancement. We found that combining Otsu's method with morphological operations like erosion and dilation yielded the best segmentation outcomes. This combined approach effectively eliminated unwanted artifacts and focused on the nucleus, providing a clearer and more accurate segmentation.\n\nFor feature extraction, we considered both morphological and textural features. Morphological features included area, perimeter, eccentricity, compactness, moments, and Fourier descriptors, which helped analyze the size and shape of the nuclei. Textural features were also extracted to capture the texture characteristics of the nuclei.\n\nIn terms of classification, we evaluated five different classifiers: SVM, KNN, decision tree, logistic regression, and linear discriminant analysis. Each classifier was tested using two feature sets derived from morphological and textural features, which were further refined using t-tests and principal component analysis (PCA). The decision tree classifier consistently performed the best, achieving the highest accuracy across different feature sets. This was further validated through five-fold cross-validation, which helped mitigate the risk of overfitting, especially with our limited dataset.\n\nThe performance of the classifiers was assessed using metrics such as sensitivity, precision, specificity, and overall accuracy. Additionally, receiver operating characteristic (ROC) curves were plotted to provide a visual representation of the classifiers' performance. The decision tree classifier not only achieved the highest accuracy but also demonstrated efficient training times, making it the most suitable choice for our work.\n\nIn summary, our method involved a thorough comparison of segmentation techniques, feature extraction methods, and classifiers. The decision tree classifier, combined with our optimized segmentation and feature selection process, proved to be the most effective for accurately classifying nuclei in our dataset.",
  "evaluation/confidence": "In our study, we employed a rigorous evaluation process to ensure the confidence and statistical significance of our results. We utilized five-fold cross-validation to assess the performance of our classifiers, which helps to mitigate the risk of overfitting and provides a more reliable estimate of model performance. This technique involves dividing the dataset into five parts, using four parts for training and one part for testing, and repeating this process five times with different folds. The final classification accuracy is the average of the five test results, offering a robust measure of the model's performance.\n\nTo evaluate the classifiers, we considered several performance metrics, including sensitivity, precision, specificity, and overall accuracy. These metrics were calculated using the formulas provided, which involve true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). Additionally, we plotted the receiver operating characteristic (ROC) curve to visually assess the performance of the classifiers. The area under the curve (AUC) was also computed, with an AUC of 0.99 indicating a highly efficient classifier.\n\nStatistical significance was ensured through the use of Karl Pearson's t-test and principal component analysis (PCA). The t-test was applied to the extracted features to select statistically significant ones, reducing the feature set from 963 to 516. PCA was then used to further reduce the feature set to 340, ensuring that only the most relevant features were considered for classification. This two-level feature selection technique helped to enhance the accuracy and reliability of our results.\n\nThe performance of the classifiers was also evaluated in terms of training time and accuracy as the number of input data increased. It was observed that the accuracy of the classifiers generally improved with a larger training dataset, demonstrating the scalability and effectiveness of our approach. The decision tree classifier was identified as the most suitable for this work, with a confusion matrix and ROC curve further validating its performance.\n\nIn summary, our evaluation process included robust statistical methods, cross-validation, and comprehensive performance metrics to ensure the confidence and significance of our results. The decision tree classifier showed exceptional performance, making it the preferred choice for our study.",
  "evaluation/availability": "The data that support the findings of this study are available from the corresponding author upon reasonable request. The images can be found online at specific digital object identifiers (DOIs) and on a GitHub repository. The data is not publicly released in its entirety, but interested parties can request access to the raw evaluation files from the corresponding author. The specific DOIs and GitHub link provide additional images and resources related to the study."
}