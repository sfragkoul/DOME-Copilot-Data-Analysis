{
  "publication/title": "Information Extraction from Clinical Texts with Generative Pre-trained Transformer Models.",
  "publication/authors": "Kim MS, Chung P, Aghaeepour N, Kim N",
  "publication/journal": "International journal of medical sciences",
  "publication/year": "2025",
  "publication/pmid": "40027192",
  "publication/pmcid": "PMC11866537",
  "publication/doi": "10.7150/ijms.103332",
  "publication/tags": "- Natural Language Processing\n- Medical Records\n- Access to Information\n- Medical Informatics\n- Generative Pre-trained Transformer Models\n- Information Extraction\n- Clinical Texts\n- Machine Learning\n- Electronic Health Records\n- Data Analysis",
  "dataset/provenance": "The dataset utilized in this study was derived from case reports published in open-access journals. These case reports were selected to ensure that they contained no protected health information (PHI), adhering to ethical standards and mitigating potential risks to patient privacy.\n\nThe dataset comprised three types of clinical texts: patient characteristics, medical history, and clinical test results. Specifically, it included 60 texts detailing patient characteristics, 50 texts outlining medical history, and 25 texts presenting clinical test results. These texts were extracted from a total of 60 case reports.\n\nThe choice of open-access journals ensured that the clinical texts were publicly available, facilitating accessibility for research purposes. This approach also aligned with the study's focus on evaluating the performance of GPT models in extracting information from well-structured clinical texts.\n\nNot applicable",
  "dataset/splits": "The dataset utilized in this study comprised three types of clinical texts extracted from case reports in open-access journals. These texts were categorized into three distinct splits based on their content:\n\n1. **Patient Characteristics**: This split contained 60 clinical texts focusing on patient characteristics.\n2. **Medical History**: This split included 50 clinical texts detailing medical history.\n3. **Clinical Test Results**: This split consisted of 25 clinical texts related to clinical test results.\n\nThe distribution of data points in each split was as follows:\n\n- **Patient Characteristics**: 60 data points.\n- **Medical History**: 50 data points.\n- **Clinical Test Results**: 25 data points.\n\nThese splits were used to evaluate the performance of GPT-3.5 and GPT-4 in extracting information from clinical texts. The models were tested using simple prompts and, when necessary, alternative decoding strategies or revised prompts with task-specific definitions to improve accuracy.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study were derived from case reports published in open-access journals. These case reports are publicly available and contain no protected health information (PHI). The specific clinical texts used, which include patient characteristics, medical history, and clinical test results, were extracted from 60 case reports. These texts were used as input for the GPT models to evaluate their performance in information extraction tasks.\n\nThe case reports were selected to ensure a diverse range of clinical scenarios, thereby enhancing the generalizability of the findings. The data splits, which involved dividing the texts into categories such as patient characteristics, medical history, and clinical test results, were designed to cover a broad spectrum of information types commonly found in clinical texts.\n\nThe use of open-access journals ensures that the data is freely accessible to the public, adhering to the principles of open science. This accessibility promotes transparency and reproducibility, allowing other researchers to verify and build upon the findings presented in this study. The absence of PHI in the selected case reports mitigates privacy concerns, ensuring that patient confidentiality is maintained throughout the research process.\n\nThe data, including the specific case reports and the extracted clinical texts, are not released in a public forum due to the need to protect the integrity of the original case reports and to comply with ethical guidelines. However, the methods and prompts used to extract information from these texts are detailed in the publication, enabling other researchers to replicate the study using their own datasets. The study adheres to ethical standards by utilizing publicly available data and ensuring that no PHI is included in the analysis.",
  "optimization/algorithm": "The optimization algorithm employed in our study primarily revolves around the use of large language models (LLMs) and their decoding strategies. The machine-learning algorithm class used is that of transformer-based models, specifically GPT-3.5 and GPT-4, which are variants of the Generative Pre-trained Transformer architecture. These models are not new; they have been widely used and studied in the field of natural language processing and beyond.\n\nThe decoding strategies applied to these models include the Greedy Approach, Self-Consistency, and First Valid Value. The Greedy Approach involves setting the temperature parameter to zero to eliminate randomness and elicit a deterministic response. Self-Consistency determines the final output through majority voting from multiple outputs generated with a higher temperature setting. First Valid Value selects the first valid output from multiple generations.\n\nThe choice of using these specific models and decoding strategies was driven by their proven capabilities in handling complex language tasks and their relevance to the medical domain. The focus of our publication is on the application of these models in medical text analysis, rather than the development of new machine-learning algorithms. Therefore, the algorithms were not published in a machine-learning journal but in a medical science journal, as the emphasis is on their practical application in healthcare.\n\nThe optimization process involved evaluating the performance of these models on specific tasks and applying alternative decoding strategies when performance was low. This iterative approach ensured that the models were fine-tuned to handle the nuances of medical text data effectively. The evaluation criteria included the accuracy of responses, particularly in tasks involving the extraction of patient characteristics and surgical diagnoses from clinical texts.",
  "optimization/meta": "The \"Meta-predictor\" subsection does not explicitly describe a meta-predictor model. However, the study does involve the use of multiple decoding strategies and evaluations of different GPT models, which can be seen as a form of ensemble or meta-learning approach.\n\nThe models evaluated include GPT-3.5 and GPT-4, which are large language models. The decoding strategies used are Greedy Approach, Self-Consistency, and First Valid Value. These strategies are applied to the models to generate outputs from clinical texts. The Greedy Approach is used initially, and if performance is low, alternative strategies like Self-Consistency and First Valid Value are employed. Self-Consistency involves majority voting among multiple outputs, while First Valid Value selects the first valid output from multiple generations.\n\nThe study does not explicitly state that data from other machine-learning algorithms is used as input. Instead, it focuses on the performance of GPT models with different decoding strategies. The evaluations are conducted on clinical texts containing specific information, such as height and weight for BMI extraction or medical history for disease verification.\n\nThe training data independence is not explicitly discussed in the context of a meta-predictor. However, the evaluations are conducted on specific tasks and clinical texts, and the performance of the models is assessed based on these tasks. The study mentions that two authors evaluated the outputs, ensuring consistency in the judgments.\n\nIn summary, while the study involves the use of multiple decoding strategies and evaluations of different GPT models, it does not explicitly describe a meta-predictor model that combines predictions from multiple machine-learning algorithms. The focus is on the performance of GPT models with different decoding strategies on specific clinical tasks.",
  "optimization/encoding": "In our study, the data encoding process involved several key steps to prepare clinical texts for analysis using machine-learning algorithms. Initially, we performed sentence embedding on clinical texts that exhibited low performance in specific tasks using the OpenAI API. The model employed for this embedding was 'text-embedding-ada-002,' which generated 1536-dimensional real-number vectors for each clinical text.\n\nFollowing the embedding process, we reduced the dimensionality of these vectors from 1536 to 2 dimensions using t-Distributed Stochastic Neighbor Embedding (t-SNE). This dimensionality reduction technique allowed us to visualize the data more effectively and to identify patterns and clusters within the embedded vectors. The resulting 2-dimensional vectors were then labeled as true or false responses based on the performance of the GPT models on the tasks with low performance.\n\nTo quantify the distinctness and definition of the clusters formed by these labels, we calculated the Silhouette score. This metric provided a quantitative measure of how well-separated the clusters were, indicating the effectiveness of the dimensionality reduction and the quality of the clustering. Additionally, we conducted statistical comparisons between the true and false responses using the mean values of the two components of the 2-dimensional vectors. Depending on the results of the Shapiro-Wilk normality test, we performed either Student's t-test or Wilcoxon rank sum test to assess the significance of these comparisons.\n\nThe statistical analyses and data visualization were carried out using R software (version 4.3.1). The data were presented as numbers or percentages, and we used McNemar\u2019s test to compare the ratio of correct and incorrect responses between GPT-3.5 and GPT-4. For multiple comparisons of accuracy among the decoding strategies\u2014Greedy Approach, Self-Consistency, and First Valid Value\u2014a Bonferroni correction was applied to adjust the p-values. A p-value of less than 0.05 was considered statistically significant.\n\nIn summary, our data encoding process involved embedding clinical texts into high-dimensional vectors, reducing their dimensionality using t-SNE, and performing statistical analyses to evaluate the performance of the GPT models. This approach allowed us to gain insights into the patterns and clusters within the data, ultimately enhancing the accuracy and reliability of our findings.",
  "optimization/parameters": "In our study, the primary parameter that was adjusted to control the randomness in the output of the GPT models was the temperature parameter. For the initial decoding strategy, known as the Greedy Approach, the temperature was set to zero. This setting eliminated randomness, ensuring that the model generated consistent responses for given queries. The default values were retained for all other parameters, as the focus was on evaluating the impact of the temperature setting.\n\nThe temperature parameter is crucial in determining the level of creativity and diversity in the model's responses. By setting it to zero, we aimed to achieve deterministic outputs, which was essential for tasks requiring precise and consistent information extraction from clinical texts.\n\nFor tasks where the performance of the GPT models was initially low, alternative decoding strategies were employed. In these cases, the temperature was set to 1, and the prompts were applied five times to generate multiple outputs. This approach allowed for the use of Self-Consistency and First Valid Value decoding strategies, which helped improve the model's performance by leveraging the variability in the outputs.\n\nThe selection of the temperature parameter values was based on established practices in the field of natural language processing. Setting the temperature to zero for the Greedy Approach ensured that the model's responses were reproducible and consistent, which is critical for tasks that require high accuracy and reliability. Conversely, using a temperature of 1 for the alternative decoding strategies introduced controlled randomness, enabling the model to explore different possible outputs and select the most appropriate one through majority voting or by identifying the first valid value.\n\nIn summary, the temperature parameter was the key input parameter adjusted in our study. Its values were selected based on the requirements of the decoding strategies and the need for consistent or varied outputs, depending on the task at hand.",
  "optimization/features": "In the optimization process, the input features were derived from clinical texts related to tasks where the GPT models demonstrated low performance. Sentence embedding was performed using the OpenAI API, specifically with the 'text-embedding-ada-002' model. This process resulted in 1536-dimensional real-number vectors for each clinical text.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, dimensionality reduction was applied to these high-dimensional vectors. The 1536-dimensional vectors were reduced to 2-dimensional real-number vectors using t-Distributed Stochastic Neighbor Embedding (t-SNE). This reduction was done to facilitate visualization and clustering of the data.\n\nThe dimensionality reduction process was conducted using the scikit-learn library, version 1.3.0. The resulting 2-dimensional vectors were labeled as true and false responses based on the performance of the GPT models on specific tasks. The formation of clusters for each label was confirmed through visualization, and the Silhouette score was calculated to quantify how well-defined and distinct each cluster was. This approach allowed for a more manageable set of features while retaining the essential information needed for analysis.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "In our study, we implemented several techniques to prevent overfitting and ensure the robustness of our findings. Given the relatively small number of case reports in our dataset, we were particularly mindful of the risk of overfitting. To mitigate this, we employed bootstrap resampling. This method helped us create a synthetic dataset that is representative of the broader population of clinical case reports, enabling better estimation of population confidence intervals. By generating 1000 bootstrap samples, we enhanced the reliability of our statistical analyses, particularly for the McNemar\u2019s test used to compare the ratio of correct and incorrect responses between GPT-3.5 and GPT-4.\n\nAdditionally, we applied the Bonferroni correction to adjust the significance level in our statistical hypothesis testing. This conservative approach helped us control the family-wise error rate, reducing the likelihood of false-positive discoveries. Specifically, when performing multiple comparisons of accuracy among the three decoding strategies\u2014Greedy Approach, Self-Consistency, and First Valid Value\u2014we multiplied the initially obtained p-values by 3. This adjustment ensured that our findings were statistically significant and not merely artifacts of multiple comparisons.\n\nThese regularization methods were crucial in maintaining the integrity of our results, especially given the constraints of our dataset. By carefully considering and implementing these techniques, we aimed to provide insights that are both reliable and generalizable to real-world clinical settings.",
  "optimization/config": "In our study, we utilized specific configurations and optimization strategies for the GPT models to ensure reproducibility and transparency. The hyper-parameter configurations, including the temperature settings and decoding strategies, were meticulously documented. For instance, the temperature parameter was set to zero for deterministic responses using the Greedy Approach, and to one for alternative strategies like Self-Consistency and First Valid Value. These settings were crucial for evaluating the models' performance under different conditions.\n\nThe optimization schedule involved applying prompts multiple times with varying temperature settings to generate diverse outputs. This process was essential for comparing the effectiveness of different decoding strategies. The model files and optimization parameters used in our experiments were accessed through the OpenAI API, which provides a standardized interface for interacting with the GPT models.\n\nRegarding the availability of these configurations, they are not explicitly provided in a separate repository or dataset due to the proprietary nature of the OpenAI API. However, the methods and parameters used are thoroughly described in the publication, allowing other researchers to replicate the experiments using the same API. The license for using the OpenAI API is governed by OpenAI's terms of service, which can be accessed on their official website.\n\nIn summary, while the specific model files and optimization parameters are not directly available for download, the detailed descriptions and methods provided in the publication enable reproducibility. The use of the OpenAI API ensures that the configurations and optimization strategies can be applied by other researchers following the same procedures outlined in our study.",
  "model/interpretability": "The models used in this study, specifically GPT-3.5 and GPT-4, are generally considered black-box models. This means that their internal workings are not easily interpretable, and it is challenging to understand exactly how they arrive at their outputs. These models operate based on complex neural networks that process vast amounts of text data to generate responses, making it difficult to trace the decision-making process step-by-step.\n\nHowever, efforts were made to gain some insights into the models' behavior through various analyses. For instance, sentence embedding and dimensionality reduction techniques, such as t-SNE, were employed to visualize and quantify the clustering of clinical texts based on the models' responses. This approach allowed for a visual inspection of how the models differentiated between true and false responses, providing a form of interpretability at a higher level.\n\nAdditionally, the use of alternative decoding strategies like Self-Consistency and First Valid Value offered some transparency into how the models could be guided to produce more reliable outputs. For example, the First Valid Value strategy, which selects the first non-\"none\" value from multiple outputs, demonstrated improved performance in extracting BMI, indicating that the models were capable of generating correct values but sometimes failed to utilize the available data effectively.\n\nFurthermore, the incorporation of task-specific definitions in the prompts significantly enhanced the models' performance. This suggests that providing clear, domain-specific information can make the models' decision-making process more transparent and aligned with the intended tasks. For instance, adding the BMI formula to the prompt led to a substantial improvement in the models' ability to calculate and provide BMI values, showcasing how explicit instructions can guide the models' behavior.\n\nIn summary, while the GPT models used in this study are inherently black-box, various techniques and strategies were employed to gain insights into their decision-making processes. These methods, including dimensionality reduction, alternative decoding strategies, and task-specific prompts, provided a level of interpretability that helped in understanding and improving the models' performance in extracting information from clinical texts.",
  "model/output": "The model in question is primarily used for classification tasks. It was applied to extract information from clinical texts, such as patient characteristics, presence or absence of specific diseases, and clinical test results. The outputs generated by the model were evaluated as either true or false based on their correctness. For instance, the model's ability to confirm the presence or absence of a disease was assessed, with GPT-4 achieving 100% accuracy in all instances, while GPT-3.5 had one incorrect classification. Additionally, the model's performance in extracting BMI from clinical texts containing height and weight values was evaluated using different decoding strategies. The model's outputs were also used to create embeddings and reduce dimensions for further analysis, indicating its use in classification rather than regression tasks.",
  "model/duration": "The execution time for the model varied depending on the tasks and strategies employed. Initially, prompts containing queries were applied to GPT models using the Greedy Approach as the decoding strategy. This approach involved setting the temperature parameter to zero to ensure deterministic responses, which likely expedited the process by eliminating randomness.\n\nFor tasks where the performance of the GPT models was initially low, alternative decoding strategies were applied. These included Self-Consistency and First Valid Value. The Self-Consistency method involved running the same prompts five times with the temperature set to 1, resulting in five outputs. This process was more time-consuming due to the multiple runs required for majority voting. The First Valid Value strategy also involved running the prompts five times, but it selected the first valid value from the outputs, which could potentially reduce the time compared to Self-Consistency.\n\nIn cases where the models still demonstrated low performance, a revised prompt containing task-specific definitions was reapplied. This step likely added additional time to the overall execution process.\n\nThe evaluation of the generated outputs was conducted by two authors, who assessed the responses as True or False. When judgments differed, consensus was reached, which could have added to the overall time required for evaluation.\n\nStatistical analyses and data visualization were performed using R software, and comparisons between decoding strategies were conducted using McNemar\u2019s test and Bonferroni correction. These analyses would have required additional computational time.\n\nOverall, the execution time was influenced by the decoding strategy used, the need for multiple runs, and the subsequent evaluation and statistical analysis processes.",
  "model/availability": "The source code for the models and the methods used in this study is not publicly released. However, the models utilized were accessed through the OpenAI API, which provides a method for users to programmatically interact with the GPT models. The specific models used were 'gpt-3.5-turbo-0613' and 'gpt-4-0613'. The software framework LangChain, version 0.0.235, was employed for developing applications using large language models. Additionally, Python, version 3.8.13, was used for coding the interactions with the models. The statistical analyses and data visualization were conducted using R software, version 4.3.1. For dimensionality reduction and calculating the Silhouette score, the scikit-learn library, version 1.3.0, was utilized. The specific versions of these tools and libraries are mentioned to ensure reproducibility of the methods and results presented in this study.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive assessment of the GPT models' performance in extracting information from clinical texts. Initially, prompts containing queries were applied to the GPT models using the Greedy Approach as the decoding strategy, with the temperature parameter set to zero to ensure deterministic responses. For tasks where the GPT models demonstrated low performance, alternative decoding strategies were applied. These included Self-Consistency, which involved majority voting among five outputs generated with a temperature setting of 1, and First Valid Value, which selected the first valid output from the five generated responses.\n\nThe evaluation process was conducted by two authors who independently assessed the outputs as true or false. In cases of disagreement, a consensus was reached to determine the final judgment. The evaluation criteria were stringent, considering responses incorrect if the models failed to compute and provide specific information such as BMI, sex, or surgery-related diagnoses, even when the necessary data was present in the clinical texts.\n\nTo further analyze the performance, dimensionality reduction techniques were applied. Sentence embedding was performed on clinical texts related to low-performance tasks using the OpenAI API, resulting in 1536-dimensional vectors. These vectors were then reduced to 2-dimensional vectors using t-Distributed Stochastic Neighbor Embedding (t-SNE). The 2-dimensional vectors were labeled as true or false based on the GPT models' responses. The formation of clusters for each label was visualized, and the Silhouette score was calculated to quantify the distinctness of the clusters.\n\nStatistical analyses were conducted to compare the mean values of the two components of the 2-dimensional vectors between true and false responses. Depending on the results of the Shapiro-Wilk normality test, either Student's t-test or the Wilcoxon rank sum test was performed. Additionally, McNemar\u2019s test was used to compare the ratio of correct and incorrect responses between GPT-3.5 and GPT-4, with 95% confidence intervals derived from 1000 bootstrap samples. For multiple comparisons of accuracy among the three decoding strategies, a Bonferroni correction was applied to adjust the p-values. A p-value of less than 0.05 was considered statistically significant.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we evaluated the outputs generated by GPT models using specific metrics to ensure a comprehensive assessment. The primary metric used was accuracy, where each response was labeled as True for correct answers and False for incorrect ones. This binary classification allowed for a clear evaluation of the models' performance in extracting information from clinical texts.\n\nTo determine the accuracy, two authors independently assessed the outputs, and in cases of disagreement, a consensus was reached. This method ensured reliability and reduced bias in the evaluation process. For tasks involving patient characteristics, such as calculating BMI or determining sex, specific criteria were established to classify responses as correct or incorrect. For instance, if the models failed to compute BMI despite having height and weight data, the response was marked as incorrect. Similarly, if sex could not be confirmed due to the absence of clear indicators, the response was considered incorrect.\n\nIn addition to accuracy, we employed statistical tests to compare the performance of different decoding strategies and models. McNemar\u2019s test was used to compare the ratio of correct and incorrect responses between GPT-3.5 and GPT-4, with 95% confidence intervals derived from 1000 bootstrap samples to enhance reliability. For multiple comparisons of accuracy among decoding strategies\u2014Greedy Approach, Self-Consistency, and First Valid Value\u2014a Bonferroni correction was applied to adjust the p-values, ensuring statistical significance.\n\nFurthermore, we utilized dimensionality reduction techniques, such as t-Distributed Stochastic Neighbor Embedding (t-SNE), to visualize and cluster the embeddings of clinical texts. The Silhouette score was calculated to quantify the distinctness of these clusters, providing a measure of how well-defined the clusters were. Comparisons between true and false responses were conducted using Student's t-test or Wilcoxon rank sum test, depending on the normality of the data.\n\nThese performance metrics are representative of standard practices in evaluating language models, particularly in the context of clinical text summarization and information extraction. The use of accuracy, statistical tests, and dimensionality reduction techniques aligns with established methods in the literature, ensuring that our evaluation is robust and comparable to other studies in the field.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of different decoding strategies to assess their impact on the performance of GPT models in handling clinical texts. We initially applied the Greedy Approach, which involves setting the temperature parameter to zero to ensure deterministic responses. This approach was used to extract information from clinical texts containing height and weight data but lacking BMI values.\n\nTo further evaluate the models' performance, we employed alternative decoding strategies, namely Self-Consistency and First Valid Value. Self-Consistency involves generating multiple outputs by setting the temperature to 1 and then determining the final output through majority voting. First Valid Value selects the first valid output from the generated responses. These strategies were applied to tasks where the GPT models demonstrated low performance with the Greedy Approach.\n\nWe also compared the performance of GPT-3.5 and GPT-4 using these decoding strategies. For instance, in extracting BMI from clinical texts, the First Valid Value strategy significantly improved the accuracy of GPT-3.5 compared to the Greedy Approach and Self-Consistency. Similarly, GPT-4 showed better performance with the First Valid Value strategy than with Self-Consistency.\n\nAdditionally, we revised the prompts to include task-specific definitions and reapplied them to both models. This revision further enhanced the models' accuracy, particularly for GPT-4, which achieved 100% accuracy in confirming the presence or absence of specific diseases.\n\nStatistical analyses, including McNemar\u2019s test and Bonferroni correction, were used to compare the ratios of correct and incorrect responses between the models and decoding strategies. These analyses provided a robust evaluation of the models' performance and the effectiveness of the decoding strategies.\n\nIn summary, our evaluation involved a comprehensive comparison of decoding strategies and prompt revisions to optimize the performance of GPT models in handling clinical texts. This approach allowed us to identify the most effective strategies for improving the accuracy and reliability of the models' outputs.",
  "evaluation/confidence": "In our study, we ensured that the evaluation of the GPT models' performance was rigorous and statistically sound. We employed several statistical methods to assess the significance of our results.\n\nFor comparing the ratio of correct and incorrect responses between GPT-3.5 and GPT-4, we used McNemar\u2019s test. To enhance the reliability of our findings, we derived 95% confidence intervals for the p-values using 1000 bootstrap samples. This approach provided a robust measure of the statistical significance of the differences observed between the two models.\n\nWhen performing multiple comparisons of accuracy among the three decoding strategies\u2014Greedy Approach, Self-Consistency, and First Valid Value\u2014we applied a Bonferroni correction. This correction involved multiplying the initially obtained p-values by 3 to account for the increased risk of Type I errors due to multiple comparisons. A p-value of less than 0.05 was considered statistically significant, ensuring that our claims of superiority were based on strong evidence.\n\nAdditionally, we conducted comparisons between true and false responses for the mean values of the two components of the two-dimensional vectors obtained after dimensionality reduction. Depending on the results of the Shapiro-Wilk normality test for residuals derived from a linear regression model, we performed either Student's t-test or Wilcoxon rank sum test. This approach ensured that the statistical tests used were appropriate for the data distribution, further strengthening the validity of our findings.\n\nIn summary, our evaluation methods included confidence intervals and statistical significance tests, providing a comprehensive and reliable assessment of the GPT models' performance.",
  "evaluation/availability": "The raw evaluation files used in this study are not publicly available. The study focused on comparing the performance of GPT-3.5 and GPT-4 models in extracting information from clinical texts, utilizing case reports from open-access journals. The evaluation process involved assessing the outputs generated by these models, with two authors independently evaluating the responses as true or false. In cases of disagreement, a consensus was reached. The evaluation criteria were clearly defined, particularly for tasks involving patient characteristics, such as calculating BMI and determining sex.\n\nThe study employed statistical methods, including McNemar\u2019s test and bootstrap sampling, to ensure the reliability of the findings. Additionally, dimensionality reduction techniques like t-SNE and the Silhouette score were used to analyze the performance of the models. However, the specific raw evaluation files, including the detailed outputs and intermediate results, were not released to the public. This decision aligns with ethical considerations, particularly the protection of any potential protected health information (PHI) that might have been inadvertently included in the evaluation process."
}