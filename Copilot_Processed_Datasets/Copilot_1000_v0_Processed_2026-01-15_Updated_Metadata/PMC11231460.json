{
  "publication/title": "Integrating fNIRS and machine learning: shedding light on Parkinson's disease detection.",
  "publication/authors": "Guevara E, Solana-Lavalle G, Rosas-Romero R",
  "publication/journal": "EXCLI journal",
  "publication/year": "2024",
  "publication/pmid": "38983780",
  "publication/pmcid": "PMC11231460",
  "publication/doi": "10.17179/excli2024-7151",
  "publication/tags": "- Parkinson's Disease\n- Functional Near-Infrared Spectroscopy\n- Machine Learning\n- Feature Selection\n- Genetic Algorithms\n- Logistic Regression\n- Cross-Validation\n- Classification Performance\n- Non-Invasive Diagnosis\n- fNIRS Data Analysis",
  "dataset/provenance": "The dataset used in this study was acquired from participants recruited at the Neurology Department of the Central Hospital \u201cDr. Ignacio Morones Prieto\u201d in Mexico. The data collection took place from October 2021 to October 2022, with participants providing signed informed consents in accordance with the Declaration of Helsinki.\n\nThe dataset consists of functional Near-Infrared Spectroscopy (fNIRS) signals recorded from twenty Parkinson's Disease (PD) patients and twenty healthy individuals. The PD patients were diagnosed by a neurologist using the criteria of the United Kingdom PD Society Brain Bank, with disease severity determined using the Hoehn and Yahr scale and the Movement Disorder Society-Sponsored Revision of the Unified Parkinson Disease Rating Scale (MDS-UPDRS, part III). The control group was matched in terms of age and sex, with cognitive functions assessed using the Montreal Cognitive Assessment (MoCA).\n\nEach participant's data includes 22 fNIRS signals recorded during a six-minute resting state, converted into three absorption contrasts: HbR (deoxyhemoglobin), HbO (oxyhemoglobin), and HbT (total hemoglobin). The signals were recorded using the portable fNIRS system Brite MKII, which consists of ten dual-wavelength LEDs, eight detectors, twenty long channels, and two short channels.\n\nThe dataset is available via Zenodo, with three folders corresponding to different tasks: a ten-second finger-tapping task, a two-minute walking task, and a six-minute resting state task. The code to analyze the fNIRS signals with machine learning for PD diagnosis is available on GitHub. This dataset has not been used in previous papers by the community.",
  "dataset/splits": "Not applicable",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The dataset used in this study is publicly available via Zenodo. It contains functional near-infrared spectroscopy (fNIRS) data from twenty Parkinson's Disease (PD) patients and twenty healthy individuals. The dataset is organized into three folders, each corresponding to a different task: twenty trials of a ten-second finger-tapping task, a two-minute walking task, and a six-minute resting state task, which is the task under analysis in this work.\n\nThe data is shared under a license that allows for reuse and further analysis, promoting transparency and reproducibility in research. The availability of this dataset ensures that other researchers can validate our findings, build upon our work, or use the data for different studies.\n\nTo access the dataset, researchers can visit the provided Zenodo link. The dataset includes the raw fNIRS signals recorded during the tasks, along with any preprocessed data used in our analysis. This comprehensive release of data supports the open science initiative and encourages collaboration within the scientific community.\n\nThe dataset was collected from participants who signed informed consent according to the Declaration of Helsinki, ensuring ethical standards were met. The data collection process was conducted at the Neurology Department of the Central Hospital \u201cDr. Ignacio Morones Prieto\u201d in Mexico from October 2021 to October 2022. This information is crucial for understanding the context and ethical considerations of the data collection process.",
  "optimization/algorithm": "The optimization algorithm employed in our study is a genetic algorithm, which falls under the class of evolutionary algorithms. This algorithm is not new; it has been widely used in various fields for feature selection and optimization tasks. The genetic algorithm was chosen for its ability to efficiently search large solution spaces and find near-optimal solutions.\n\nThe decision to use a genetic algorithm in this context, rather than publishing it in a machine-learning journal, is driven by the specific requirements of our research. Our primary focus is on integrating functional Near-Infrared Spectroscopy (fNIRS) with machine learning for the detection of Parkinson's Disease (PD). The genetic algorithm serves as a tool to enhance the feature selection process, which is crucial for improving the accuracy of PD detection.\n\nThe genetic algorithm was configured with specific parameters, including a crossover probability of 0.05 and a mutation probability of 0.03. It was run for 100 generations, each consisting of 1000 solutions (feature subsets). The fitness function used for selecting the best solutions in each generation was the accuracy of PD detection. This approach allowed us to identify the most relevant features from a high-dimensional feature set, ultimately leading to improved detection performance.\n\nThe use of a genetic algorithm in this study is justified by its effectiveness in handling complex feature selection tasks. By integrating it with an ensemble of feature ranking techniques, we were able to achieve remarkable detection accuracy, precision, recall, F1 score, and AUC, all reaching a value of 1. This demonstrates the potential of combining fNIRS and machine learning for efficient, non-invasive PD detection.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it employs an ensemble of feature ranking techniques followed by feature subset selection methods to enhance the performance of a logistic regression classifier for Parkinson's disease (PD) detection.\n\nThe feature ranking techniques used include elastic net, L1-norm SVM, Mean Absolute Difference (MAD), Mutual Information Gain (MIG), and Fisher score. These methods are applied to rank features based on their importance and relevance to the classification task. Following this, feature subset selection is performed using either Wrapper Feature Subset Selection (WFSS) or Genetic Algorithms (GA). These selection methods further refine the set of features to improve the classifier's performance.\n\nThe logistic regression model is then trained using the selected features. This approach ensures that the most informative features are used for classification, thereby enhancing the model's accuracy and efficiency. The use of ensemble feature selection combines the strengths of various methods to obtain an optimal feature subset, which in turn improves the classification performance.\n\nThe training data for the logistic regression model is independent of the data used in the feature ranking and selection processes. This independence is crucial for ensuring that the model generalizes well to new, unseen data. The performance of the model is evaluated using k-fold cross-validation, where k is set to 5 and 10, to assess its robustness and reliability.",
  "optimization/encoding": "In our study, we integrated functional Near-Infrared Spectroscopy (fNIRS) with machine learning for Parkinson's Disease (PD) detection. The data encoding and preprocessing involved several steps to ensure the fNIRS signals were suitable for machine-learning algorithms.\n\nInitially, we extracted a high-dimensional feature set from the fNIRS signals. For each participant, we calculated 396 statistical features per band, derived from six characteristics: maximum absolute value, average value, variance, skewness, average time between two consecutive zero crossings, and average time between a zero crossing and a peak value. Additionally, we conducted an analysis of the frequency spectrum of each band to extract six spectral features: average value, variance, skewness, kurtosis, energy, and dominant frequency.\n\nTo handle the high dimensionality of the feature set, we employed ensemble feature selection. This approach combined the strengths of various feature selection methods to obtain an optimal feature subset and enhance classification performance. We used feature ranking methods such as Mean Absolute Difference (MAD) filter, Mutual Information Gain (MIG) filter, Fisher\u2019s score, elastic net regression, and L1-norm Support Vector Machine (SVM). These methods evaluated features individually based on their discriminative power and information gain.\n\nFollowing feature ranking, we applied feature subset selection techniques. We used Wrapper Feature Subset Selection (WFSS) and Genetic Algorithms (GA) to further reduce the number of features. WFSS involved iteratively training a classifier with different feature subsets and selecting the one with the best performance. GA, on the other hand, used evolutionary principles to generate and evaluate feature subsets, progressively eliminating weaker subsets to improve classification performance.\n\nThe selected features were then used to train a logistic regression model for classification. Logistic regression mapped the feature vectors to probabilities using a sigmoid function, allowing for the minimization of a cost function during the learning process. This approach ensured that the most relevant features were used to accurately detect PD.\n\nIn summary, our data encoding and preprocessing involved extracting a comprehensive set of statistical and spectral features from fNIRS signals, followed by ensemble feature selection to reduce dimensionality and enhance classification performance. The selected features were then classified using a logistic regression model, resulting in accurate PD detection.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the feature selection setting. Initially, we extracted 792 features per participant from the fNIRS signals. To reduce this number and enhance classification performance, we employed ensemble feature selection techniques.\n\nIn the first experimental setting, we used an ensemble of feature ranking techniques, including elastic net, L1-norm SVM, MAD, MIG, and Fisher score. These techniques helped narrow down the top-rated features. Subsequently, we applied feature subset selection using either Wrapper Feature Subset Selection (WFSS) or Genetic Algorithms (GA). This two-stage process resulted in a reduced set of features, with the exact number varying based on the subset selection method used.\n\nIn the second experimental setting, we skipped the initial feature ranking step and directly applied feature subset selection using either WFSS or GA to the entire set of 792 extracted features. The number of selected features in this setting was generally higher compared to the first setting.\n\nThe final number of parameters (p) used in the model was determined by the feature subset selection process. For instance, in the first setting with GA, the size of the selected feature subset was 16 for 10-fold cross-validation and 18 for 5-fold cross-validation. In the second setting with GA, the size of the selected feature subset was 46 for 10-fold cross-validation and 48 for 5-fold cross-validation. These selected features were then used to train the logistic regression model for classification.",
  "optimization/features": "In our study, we initially extracted a high number of features from functional near-infrared spectroscopy (fNIRS) signals. Specifically, we calculated 396 statistical features per participant, derived from six characteristics per band and multiple channels. Additionally, six temporal features and six spectral features were computed for each band, resulting in a comprehensive set of features.\n\nTo manage this high-dimensional feature space, we employed feature selection techniques. We utilized an ensemble approach that combined multiple feature ranking methods, including the Mean Absolute Difference (MAD) filter, Mutual Information Gain (MIG) filter, Fisher\u2019s score, elastic net regression, and L1-norm Support Vector Machine (SVM). These methods were used to rank features based on their relevance and discriminative power.\n\nFollowing the ranking, we applied feature subset selection strategies. Two primary methods were used: Wrapper Feature Subset Selection (WFSS) and Genetic Algorithms (GA). WFSS involves iteratively evaluating different feature subsets using a classifier and selecting the subset that yields the best performance. GA, on the other hand, uses evolutionary principles to progressively improve the feature subset by selecting, crossing over, and mutating subsets based on their classification performance.\n\nThe feature selection process was conducted using the training set only, ensuring that the selected features were not influenced by the test data. This approach helped in reducing the complexity of the classification model and enhancing its performance.\n\nIn summary, we started with a large number of features and applied a rigorous feature selection process to identify the most relevant features for Parkinson's disease detection. This process involved both feature ranking and subset selection, all performed using the training data to maintain the integrity of the evaluation.",
  "optimization/fitting": "In our study, we began with a high-dimensional feature set, consisting of 792 features per participant. This number is indeed much larger than the number of training points, as we had data from only twenty Parkinson's Disease (PD) patients and twenty healthy individuals. To address the risk of overfitting, we employed ensemble feature selection methods. This approach combines the strengths of various feature selection techniques, including feature ranking methods like Mean Absolute Difference (MAD) filter, Mutual Information Gain (MIG) filter, Fisher\u2019s score, elastic net regression, and L1-norm Support Vector Machine (SVM). These methods were followed by feature subset selection techniques such as Wrapper Feature Subset Selection (WFSS) and Genetic Algorithms (GA).\n\nThe ensemble feature selection process helped to identify the most relevant features, reducing the feature set to a more manageable size. For instance, in one set of experiments, features ranked by at least two filters in the top 1% were selected to train a logistic classifier. This process was repeated for features ranked in the top 2% up to 10%, resulting in ten feature subsets. The subset with the highest accuracy was then selected. Additionally, the L1-norm SVM and elastic net regression methods were used to generate two corresponding feature subsets, which were combined with the subsets obtained from the filtering strategies.\n\nTo further mitigate overfitting, we used k-fold cross-validation (with k = 5 and 10) to evaluate the classification performance. This technique ensures that the model is trained and validated on different subsets of the data, providing a more robust estimate of its performance. The global performance metrics were obtained by averaging the metrics at each fold, which helps to ensure that the model generalizes well to unseen data.\n\nConversely, underfitting was addressed by ensuring that the feature selection process retained enough relevant information. The use of multiple feature ranking and subset selection techniques helped to capture the most informative features, preventing the model from being too simplistic. The genetic algorithm, in particular, was run for 100 generations with a large initial population of 1000 subsets, ensuring a thorough exploration of the feature space. The fitness function used for the genetic algorithm was accuracy, which drove the selection of the best solutions in each generation.\n\nIn summary, our approach effectively balanced the risks of overfitting and underfitting by using ensemble feature selection methods, k-fold cross-validation, and a thorough feature subset selection process. This resulted in a model with high detection performance for Parkinson's Disease, as evidenced by the accuracy, precision, recall, F1 score, and AUC metrics reported in our results.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and enhance the performance of our classification models. One of the key methods used was elastic net regression, which combines the strengths of Lasso and Ridge regression. Lasso regression adds an L1 penalty term to encourage sparsity in the feature set by shrinking the coefficients of irrelevant features to zero. Ridge regression, on the other hand, adds an L2 penalty term to shrink less relevant features towards zero. By integrating these two approaches, elastic net regression effectively reduces the complexity of the model and improves its generalization capability.\n\nAdditionally, we utilized L1-norm Support Vector Machines (SVM) for feature selection. This method constrains or regularizes the coefficients, forcing some of the parameter estimates to be zero. As a result, the corresponding features are discarded, leading to a more parsimonious model that is less likely to overfit the training data.\n\nFurthermore, we implemented wrapper feature subset selection (WFSS) and genetic algorithms (GA) for feature selection. These methods iteratively evaluate different feature subsets and select the one that yields the best classification performance. By focusing on the most relevant features, these techniques help in reducing the dimensionality of the data and mitigating the risk of overfitting.\n\nOverall, these regularization and feature selection techniques played a crucial role in ensuring that our models were robust and generalizable, thereby enhancing the reliability of our Parkinson's disease detection approach.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we employed a genetic algorithm for feature subset selection, which was run for 100 generations with each generation consisting of 1000 solutions. The genetic algorithm utilized a crossover probability of 0.05 and a mutation probability of 0.03, with accuracy serving as the fitness criterion.\n\nThe code used to analyze functional Near-Infrared Spectroscopy (fNIRS) signals with machine learning for Parkinson's Disease (PD) diagnosis is available on GitHub. The repository, accessible at [GitHub repository](https://github.com/GabrielSolana29/rs_fNIRS_PD.git), includes detailed steps to execute the code, allowing others to replicate our experiments and optimize the model further.\n\nAdditionally, the dataset containing fNIRS data from twenty PD patients and twenty healthy individuals is available via Zenodo. This dataset includes three folders corresponding to different tasks: a finger-tapping task, a walking task, and a resting state task. The data is freely accessible at [Zenodo dataset](https://zenodo.org/records/7966830).\n\nRegarding the license, the code and data are made available under terms that allow for academic and research use, ensuring that the community can build upon our work.",
  "model/interpretability": "The model employed in our study is not entirely a black box, as it incorporates several interpretable components and techniques that contribute to its transparency. The primary classification model used is logistic regression, which is inherently interpretable. Logistic regression models the relationship between the features and the dependent variable using a logistic function, providing probabilities that are easy to interpret. The coefficients in the logistic regression model indicate the strength and direction of the relationship between each feature and the outcome, making it straightforward to understand the impact of individual features on the classification.\n\nIn addition to the logistic regression model, the feature selection process also enhances the interpretability of the model. We utilized an ensemble of feature ranking techniques, including elastic net regression, L1-norm SVM, mean absolute difference (MAD) filter, mutual information gain (MIG) filter, and Fisher's score. These techniques rank features based on their discriminative power, allowing us to identify the most relevant features for classification. By selecting the top-ranked features, we reduce the complexity of the model and focus on the most informative features, making the model more interpretable.\n\nFurthermore, we employed wrapper feature subset selection (WFSS) and genetic algorithms (GA) for feature subset selection. These methods iteratively evaluate different feature subsets and select the one that yields the best classification performance. While these methods involve a search process, the final selected feature subset is interpretable because it consists of a reduced number of features that have been shown to be important for classification.\n\nOverall, the combination of logistic regression, feature ranking techniques, and feature subset selection methods used in our study results in a model that is more transparent and interpretable compared to black-box models. The use of interpretable components and techniques allows us to understand the relationship between the features and the outcome, as well as the importance of individual features in the classification process.",
  "model/output": "The model employed in our study is a classification model. Specifically, we utilized logistic regression for the classification task. This model was chosen for its ability to map feature vectors to probabilities using a sigmoid function, which is particularly well-suited for binary classification problems. In our case, the model was trained to distinguish between two classes: the presence or absence of Parkinson's Disease (PD) in participants. The logistic regression model was evaluated using metrics such as accuracy, precision, recall, F1 score, and the area under the curve (AUC), which are standard for assessing the performance of classification models. The model's performance was further validated using k-fold cross-validation, with k values of 5 and 10, to ensure robustness and generalizability of the results.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for analyzing functional Near-Infrared Spectroscopy (fNIRS) signals with machine learning to assist in Parkinson's Disease (PD) diagnosis is publicly available. It can be accessed via GitHub at the following link: https://github.com/GabrielSolana29/rs_fNIRS_PD.git. This repository includes detailed steps to execute the code, enabling other researchers to replicate and build upon the methods described in the study. The availability of this code promotes transparency and facilitates further advancements in the field of non-invasive PD detection using fNIRS and machine learning techniques.",
  "evaluation/method": "The evaluation of the proposed Parkinson's Disease (PD) detection method involved a rigorous process using k-fold cross-validation. Specifically, we employed 5-fold and 10-fold cross-validation techniques. In this approach, the feature vectors were partitioned into k folds. For each iteration, k-1 folds were used to train a logistic classifier, while the remaining fold was used to measure classification performance. This process was repeated k times, ensuring that each fold was used once as the validation set. The global performance metrics were then obtained by averaging the metrics across all folds.\n\nTo assess the classification performance, we utilized several key metrics: accuracy, precision, recall, F1 score, and the area under the curve (AUC). Accuracy represents the percentage of correct classification results. Recall indicates the probability that a PD detection is positive given that the participants are PD patients. Precision measures the percentage of PD cases detected as positives. The F1 score is the harmonic mean of precision and recall, providing a balanced measure of both. The AUC evaluates the model's ability to distinguish between PD patients and healthy participants.\n\nTwo main experimental settings were conducted. The first setting involved an ensemble of feature ranking strategies followed by feature subset selection using either Wrapper Feature Subset Selection (WFSS) or Genetic Algorithms (GA). The second setting involved feature subset selection using WFSS or GA without prior feature ranking. The logistic regression model was used for classification in both settings.\n\nThe results demonstrated that the first experimental setting, which included feature ranking, generally yielded higher performance metrics. Specifically, the use of GA in feature subset selection showed superior performance compared to WFSS. The genetic algorithm was run with an initial generation of 1000 subsets, producing 100 generations of solutions. The fitness function used for selecting the best solutions was accuracy. This approach not only improved detection performance but also reduced model complexity by selecting a smaller number of features.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our Parkinson's Disease (PD) detection approach. The metrics we reported include accuracy, precision, recall, F1 score, and the area under the curve (AUC). These metrics are widely recognized and used in the literature for evaluating classification performance, particularly in medical diagnostics.\n\nAccuracy measures the overall correctness of the classification results, providing a percentage of correctly identified instances out of the total instances. Precision focuses on the correctness of positive predictions, indicating the proportion of true positive cases among all predicted positives. Recall, also known as sensitivity, assesses the ability of the model to identify all relevant instances, calculating the proportion of true positives out of all actual positives. The F1 score is the harmonic mean of precision and recall, offering a balanced measure that is particularly useful when dealing with imbalanced datasets. Finally, the AUC provides a single scalar value that summarizes the performance of the classifier across all classification thresholds, with higher values indicating better performance.\n\nThese metrics collectively provide a robust evaluation of our PD detection model, ensuring that we capture various aspects of its performance. The choice of these metrics aligns with standard practices in the field, making our results comparable to other studies in medical diagnostics and machine learning.",
  "evaluation/comparison": "In our evaluation, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on assessing the performance of our proposed Parkinson's Disease (PD) detection approach using functional Near-Infrared Spectroscopy (fNIRS) analysis. We conducted two main sets of experiments to evaluate the effectiveness of different feature selection strategies.\n\nThe first set of experiments involved an ensemble of feature ranking techniques followed by feature subset selection using either Wrapper Feature Subset Selection (WFSS) or Genetic Algorithms (GA). The second set of experiments involved feature subset selection using WFSS or GA without any prior feature ranking.\n\nFor both sets of experiments, we used k-fold cross-validation (with k = 5 and 10) to evaluate the classification performance. The metrics used for performance assessment included accuracy, precision, recall, F1 score, and the area under the curve (AUC). These metrics provided a comprehensive evaluation of our PD detection approach.\n\nRegarding simpler baselines, our approach inherently includes a comparison to simpler models through the use of logistic regression as the classification algorithm. Logistic regression is a well-established and relatively simple baseline model in the field of machine learning. By using logistic regression, we ensured that any improvements in performance could be attributed to the feature selection strategies rather than the complexity of the classification model.\n\nIn summary, while we did not compare our method directly to publicly available methods on benchmark datasets, our evaluation included a thorough assessment of different feature selection strategies and the use of a simple baseline classification model. This approach allowed us to focus on the strengths and effectiveness of our proposed PD detection method.",
  "evaluation/confidence": "The evaluation of the proposed Parkinson's Disease (PD) detection approach involved rigorous performance assessment using k-fold cross-validation, specifically with k values of 5 and 10. The performance metrics included accuracy, precision, recall, F1 score, and the area under the curve (AUC). These metrics were calculated for different experimental settings, which varied in the implementation of feature selection strategies.\n\nThe results presented in the tables show the performance metrics for each experimental setting, but confidence intervals for these metrics are not explicitly provided. The tables report the exact values of the metrics, which indicate the performance of the models under the specified conditions. However, without confidence intervals, it is challenging to assess the statistical significance of the differences in performance between the various settings.\n\nThe experiments were designed to compare the effectiveness of different feature selection methods. The first set of experiments used an ensemble of feature ranking techniques followed by feature subset selection, either using Wrapper Feature Subset Selection (WFSS) or Genetic Algorithms (GA). The second set of experiments used only feature subset selection with WFSS or GA. The results showed that the combination of feature ranking and subset selection, particularly with GA, yielded the highest performance metrics.\n\nWhile the reported metrics suggest that the proposed method is effective, the lack of confidence intervals means that the statistical significance of these results cannot be definitively established. Future work could include the calculation of confidence intervals to provide a more comprehensive evaluation of the method's performance and its superiority over other approaches. Additionally, statistical tests could be conducted to compare the performance metrics across different experimental settings, ensuring that any observed differences are statistically significant.",
  "evaluation/availability": "The raw evaluation files are not available. However, the dataset used for the evaluation is publicly available. The dataset contains functional near-infrared spectroscopy (fNIRS) data from twenty Parkinson's Disease (PD) patients and twenty healthy individuals. It can be accessed via Zenodo at the following link: https://zenodo.org/records/7966830. The dataset includes three folders, each corresponding to a different task: twenty trials of a ten-second finger-tapping task, a two-minute walking task, and the task under analysis in this work, a six-minute resting state. The code to analyze fNIRS signals with machine learning to assist PD diagnosis is available on GitHub: https://github.com/GabrielSolana29/rs_fNIRS_PD.git. This link describes the steps to execute the code."
}