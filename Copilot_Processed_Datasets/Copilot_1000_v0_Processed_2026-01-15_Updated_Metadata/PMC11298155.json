{
  "publication/title": "Predicting the fine-scale spatial distribution of zoonotic reservoirs using computer vision.",
  "publication/authors": "Layman NC, Basinski AJ, Zhang B, Eskew EA, Bird BH, Ghersi BM, Bangura J, Fichet-Calvet E, Remien CH, Vandi M, Bah M, Nuismer SL",
  "publication/journal": "Ecology letters",
  "publication/year": "2023",
  "publication/pmid": "37737493",
  "publication/pmcid": "PMC11298155",
  "publication/doi": "10.1111/ele.14307",
  "publication/tags": "- Zoonotic diseases\n- Computer vision\n- Reservoir species\n- Spatial distribution\n- Machine learning\n- Environmental features\n- Rodent trapping\n- Land cover classification\n- Building classification\n- Disease intervention",
  "dataset/provenance": "The datasets used in our study were sourced from a combination of aerial photos and rodent trapping studies conducted in three towns in West Africa. The aerial photos were obtained from Bing and Google very high-resolution (VHR) tile servers. These images provided a detailed view of the study sites, with a resolution of approximately 0.22 square meters per pixel.\n\nThe rodent trapping data specifically focused on Mastomys natalensis, the primary reservoir of Lassa virus. This data was collected from previously published studies conducted in Guinea between 2003 and 2005, as well as a more recent study conducted in Sierra Leone between 2019 and 2020. The trapping datasets describe geotagged trap locations and indicate whether or not a trap captured an M. natalensis rodent.\n\nIn Sierra Leone, the data comes from a single town site, coded as SLTA. In Guinea, the data comes from two town sites, coded as GTA and GTB. The precise locations of the traps within Guinea are not known, so the trapping data was aggregated into date-stamped spatial blocks by overlaying a 50-square-meter grid within each town. This aggregation helps to better reflect the broader ranging behavior of the reservoir animals and removes any artifacts that might result from a particular spatial grid.\n\nThe trapping data was further refined by generating two spatial blocks for each location and date: one for indoor traps and one for outdoor traps. This distinction is important because trap success is generally higher inside buildings than outside. The aggregation procedure was performed for five randomly jittered 50-square-meter spatial grids to ensure robustness.\n\nThe datasets used in this study have not been previously published or used by the community in the same context. They represent a unique combination of high-resolution aerial imagery and detailed rodent trapping data, specifically tailored to understand the spatial distribution of M. natalensis and its association with anthropogenic features.",
  "dataset/splits": "The dataset was split into three main parts: training, validation, and test datasets. Each of these splits is comprised of one town\u2019s trapping data. Given that there are three towns, this results in six unique combinations of training, validation, and test towns.\n\nFor model training, the dataset is aggregated over five randomly jittered 50 m2 spatial grids. This means that for each of the six combinations, models are fit to a training dataset that includes data from a single town, aggregated over these five grids.\n\nThe validation process involves evaluating the fitted model on the town chosen for validation. Specifically, the model is applied separately to each of the five randomly jittered grids from the validation town, resulting in five estimates of mean-absolute-error (MAE) as applied to the validation dataset. These MAE estimates are then averaged together into a single validation MAE score, which is used to select the best hyperparameter combination.\n\nFor the test dataset, the fitted models are assessed on 25 randomly jittered sets of spatial blocks instead of five. This is done to develop robust estimates of model performance. The assessment is performed on those two models that performed best on the remaining training and validation towns. Model averaging is implemented when generating predictions from the two best models to increase the ability of the final model predictions to generalize to new areas.",
  "dataset/redundancy": "The datasets used in our study were sourced from aerial photos and rodent trapping studies conducted in three towns in West Africa. To evaluate the performance of our method, the datasets were split into training, validation, and test sets, each comprised of one town's trapping data. This resulted in six unique combinations of training, validation, and test towns.\n\nThe training and test sets are independent. This independence was enforced by ensuring that the data from each town was used exclusively in either the training, validation, or test set, but not in multiple sets simultaneously. For model training, we used the root mean square error as the loss function. The best hyperparameter set was selected by evaluating the fitted model on the town chosen for validation. Specifically, the fitted model was applied separately to each of the five randomly jittered grids from the validation town, resulting in five estimates of mean-absolute-error (MAE) as applied to the validation dataset. These MAE estimates were then averaged together into a single validation MAE score, which was ultimately used to select the best hyperparameter combination.\n\nTo minimize overfitting, we implemented early stopping on the number of tree fitting iterations. For each hyperparameter combination, the number of tree fitting iterations was limited to that which reduced the validation MAE over each 100 iteration cycle. For each train-validation-test fold, the hyperparameter combination that resulted in the lowest validation MAE score was chosen as the best hyperparameter combination.\n\nThe distribution of our datasets compares favorably to previously published machine learning datasets in the context of ecological studies. Our approach ensures that the models are trained and validated on independent datasets, which helps in assessing the generalizability of the models to new, unseen data. This method of splitting the dataset and validating the model performance is a robust approach that enhances the reliability and applicability of our findings.",
  "dataset/availability": "The data used in this study is not fully released in a public forum. However, key portions of the project files, including analysis scripts, are available on GitHub at https://github.com/Boyu-Zhang-UOI/Machine-Vision-for-Zoonotic-Reservoir-Density-at-Fine-Resolution. The full project repository is archived on Zenodo at https://doi.org/10.5281/zenodo.7717286. This ensures that the methods and analyses can be reproduced by other researchers. The specific datasets used, such as the aerial photos and rodent trapping data, are not publicly available due to privacy and logistical reasons. The aerial photos were sourced from Bing and Google very high resolution (VHR) tile servers, and the rodent trapping data came from previously published studies and a recently completed study. The data from Sierra Leone comes from a single town site, while data from Guinea comes from two town sites. Town names have been replaced with codes to preserve site privacy. The datasets describe geotagged trap locations and whether or not a trap captured a specific rodent species. The data availability statement ensures that the analytical framework and key scripts are accessible, promoting transparency and reproducibility in research.",
  "optimization/algorithm": "The machine-learning algorithm class used is Boosted Regression Trees (BRTs). These are ensemble models composed of many simple decision trees, each contributing a small effect on the final prediction. The trees are added iteratively to minimize a loss function that measures the discrepancy between model predictions and observed outcomes. BRTs are favored in spatial ecology due to their robustness against overfitting and their ability to capture nonlinear relationships in ecological data.\n\nThe BRT algorithm is not new; it is widely used in various fields, including spatial ecology. The choice to use BRTs in this study is driven by their proven effectiveness in handling complex, nonlinear relationships and their robustness in preventing overfitting. The focus of this publication is on applying these well-established methods to a specific ecological problem rather than developing a new machine-learning algorithm. Therefore, it is appropriate for this work to be published in an ecology journal rather than a machine-learning journal. The emphasis is on the ecological insights gained from the application of BRTs to predict the distribution of reservoir animals, which is crucial for understanding and managing zoonotic diseases.",
  "optimization/meta": "The models employed in this study do not function as meta-predictors. Instead, they utilize a single machine-learning method, specifically boosted regression trees (BRTs), to predict trapping success. The BRT models are trained using a variety of environmental features, including land cover characteristics, rainfall history, trap placement, and the number of consecutive nights of trapping.\n\nThe BRT models are trained and validated using data from different towns, ensuring that the training data is independent of the validation and test data. This approach helps to assess the models' ability to generalize to new, unseen locations. For each combination of training, validation, and test towns, the best hyperparameter combination is selected based on the lowest validation mean absolute error (MAE) score. This process is repeated for multiple combinations of towns to ensure robust model performance.\n\nThe final predictions are generated by averaging the outputs of the two best-performing BRT models that were trained and validated on data excluding the test town. This model averaging approach aims to enhance the generalizability of the predictions to new areas. The models are evaluated based on their ability to rank spatial blocks by trapping success, which is more interpretable and relevant for zoonotic disease research compared to predicting absolute reservoir density.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure that the environmental features were appropriately represented and ready for model training.\n\nFirst, we aggregated trapping data into date-stamped spatial blocks using a 50 m\u00b2 grid within each town. This spatial aggregation helped to better reflect the broader ranging behavior of reservoir animals. For each spatial block and date, we calculated trap success and the total number of traps laid. Since trap success is generally higher inside buildings than outside, we generated two spatial blocks for each location and date: one for indoor traps and one for outdoor traps.\n\nTo remove any artifacts resulting from a particular spatial grid, we performed the aggregation procedure for five randomly jittered 50 m\u00b2 spatial grids. This approach helped to ensure that our results were robust and not dependent on the specific grid alignment.\n\nWe extracted 42 land cover features by analyzing aerial images at different radii (25 m, 50 m, 100 m, 200 m, 500 m, and 1000 m) and classifying them into seven types: bare ground, tree cover, rice fields, natural grass, mound agriculture, burned ground, and water. Additionally, we included a category for clouds to account for obscured areas. These features were averaged across trap locations within each date-stamped spatial block.\n\nIn addition to land cover features, we included several other predictors presumed to be relevant to our sampling regime and the ecology of M. natalensis. These included monthly averaged rainfall for each month in the year preceding the block\u2019s visit date, resulting in 12 \"rainfall lags\" predictors. We also included a binary \"trap placement\" predictor indicating whether traps were placed inside a building (0) or outdoors (1). Furthermore, we added an integer-valued \"night\" predictor to account for potential decreases in trap success over consecutive nights of trapping.\n\nIn total, our framework used 92 predictors, categorized into building features (36), land cover features (42), rainfall features (12), trap placement (1), and night (1). These predictors were used to train boosted regression tree (BRT) models, which are ensemble models composed of many simple decision trees. The BRTs were trained using the XGBoost package in Python, with the root mean square error as the loss function. We implemented early stopping on the number of tree-fitting iterations to minimize overfitting.",
  "optimization/parameters": "In our study, we utilized a total of 92 predictors to train our boosted regression tree (BRT) models. These predictors were carefully selected based on their presumed relevance to the ecology of M. natalensis and our sampling regime. The predictors included features extracted from aerial images, such as land cover types and building density, as well as additional environmental and trapping-related variables.\n\nThe land cover features were derived from aerial imagery and included various types of land cover within different radii around trap locations. Specifically, we considered 42 land cover features, which were extracted and averaged across trap locations within each date-stamped spatial block. These features were chosen to capture the environmental context that might influence the presence of M. natalensis.\n\nIn addition to land cover, we included predictors related to rainfall history. Given that the reproductive cycles of M. natalensis are influenced by rainfall, we computed the monthly averaged rainfall for each month in the year preceding the date of each spatial block's visit. This resulted in 12 predictors, termed \"rainfall lags,\" which provided information about seasonal rainfall patterns relative to the trapping dates.\n\nWe also incorporated a binary \"trap placement\" predictor to account for whether traps were placed inside a building or outdoors. This predictor was included because previous studies have shown that M. natalensis are more likely to be found within human habitations.\n\nFurthermore, to account for potential decreases in trap success over consecutive nights of trapping, we included an integer-valued predictor called \"night,\" which described the number of consecutive nights of trapping that occurred on or before a spatial block's date.\n\nThe selection of these 92 predictors was based on a combination of ecological knowledge and empirical evidence. The land cover and building density features were chosen because they are known to be important for the habitat preferences of M. natalensis. The rainfall predictors were included due to the established relationship between rainfall and the reproductive cycles of these rodents. The trap placement and night predictors were added to capture variations in trapping success that might be influenced by human activity and trapping frequency.\n\nIn summary, the 92 predictors used in our model were selected to comprehensively capture the environmental and trapping-related factors that are likely to influence the presence and trapping success of M. natalensis. This selection process ensured that our models could learn the complex relationships between these variables and the observed trapping outcomes.",
  "optimization/features": "In our study, we utilized a total of 92 features as input for our models. These features encompassed various categories, including building characteristics, land cover types, rainfall history, trap placement, and the number of consecutive trapping nights.\n\nFeature selection was not explicitly performed in the traditional sense of reducing the number of features based on statistical methods or algorithms. Instead, we included features that were presumed to be relevant to our sampling regime and the ecology of the species under study. These features were chosen based on prior ecological knowledge and studies, ensuring that they were likely to be informative for our models.\n\nThe selection of these features was done independently of the training process. The features were determined based on ecological relevance and existing literature, rather than being selected or optimized based on the performance on the training data. This approach ensured that the features used were grounded in ecological theory and empirical evidence, providing a robust foundation for our modeling efforts.",
  "optimization/fitting": "In our study, we employed boosted regression tree (BRT) models to predict the spatial distribution of a reservoir species. The number of predictors used in our framework was indeed large, totaling 92, which included features extracted from aerial images, rainfall history, trap placement, and the number of consecutive nights of trapping. However, the number of training points was sufficiently large to mitigate concerns about overfitting.\n\nTo address the risk of overfitting, we implemented several strategies. First, we used early stopping during the model training process. Specifically, we limited the number of tree-fitting iterations to that which reduced the validation mean absolute error (MAE) over each 100 iteration cycle. This approach ensured that the model did not continue to train beyond the point where it started to overfit the training data.\n\nAdditionally, we employed a cross-validation strategy where the dataset was split into training, validation, and test datasets. For each of the six unique combinations of training, validation, and test towns, models were fit to a training dataset and evaluated on a validation dataset. The hyperparameter combination that resulted in the lowest validation MAE score was selected as the best model. This process was repeated for each fold, ensuring that the model's performance was robust and generalizable.\n\nFurthermore, we used model averaging to increase the ability of the final model predictions to generalize to new areas. For a given test town, predictions were generated using the average of the two models that performed best on the remaining training and validation towns. This approach helped to reduce the variance and improve the stability of the predictions.\n\nTo rule out underfitting, we ensured that the models were complex enough to capture the underlying patterns in the data. The BRT models are ensemble models composed of many simple decision trees, each having a small effect on prediction. Trees are added iteratively to reduce a loss function that measures the discrepancy between model predictions and observed outcomes. This iterative process allows the models to learn nonlinear relationships present in the ecological data.\n\nOverall, our approach combined early stopping, cross-validation, and model averaging to effectively manage the risk of both overfitting and underfitting, ensuring that the models were robust and generalizable.",
  "optimization/regularization": "To prevent overfitting in our models, we employed several regularization techniques. One key method was early stopping during the tree-fitting iterations. Specifically, for each hyperparameter combination, we limited the number of iterations to those that reduced the validation mean absolute error (MAE) over each 100-iteration cycle. This approach ensured that the model did not continue to train beyond the point where it started to overfit the training data.\n\nAdditionally, we used a model averaging approach when generating predictions. This involved averaging the predictions from the two best-performing models for a given test town. This technique helped to increase the generalizability of the final model predictions to new areas by reducing the variance and improving the robustness of the predictions.\n\nFurthermore, we implemented hyperparameter tuning to select the best combination of hyperparameters for each model. This process involved evaluating different hyperparameter settings on the validation dataset and choosing the combination that resulted in the lowest validation MAE. This step was crucial in ensuring that the models were not overly complex and could generalize well to unseen data.\n\nOverall, these regularization methods\u2014early stopping, model averaging, and hyperparameter tuning\u2014were essential in preventing overfitting and enhancing the performance and reliability of our models.",
  "optimization/config": "The hyperparameter configurations and optimization schedule used in our study are reported in detail. Specifically, we provide information on the maximum allowed tree depth, the proportion of columns sampled at each tree-fitting iteration, the proportion of training data used to generate each tree, the number of tree-fitting iterations, and the minimum loss reduction required to make a further partition on a leaf node of the tree. These details are crucial for replicating our models and understanding the optimization process.\n\nThe hyperparameter combinations we tested are described in the Appendix, which includes the specific values used for each parameter. This ensures transparency and allows other researchers to replicate our experiments or build upon our work.\n\nRegarding model files and optimization parameters, we do not explicitly mention the availability of these files in the provided context. However, the detailed description of the hyperparameters and the optimization process should enable others to implement similar models.\n\nThe license under which these details are made available is not specified in the provided context. Typically, such information would be included in the supplementary materials or the data availability statement of the publication. Researchers interested in accessing these details should refer to the full publication or contact the authors for more information.",
  "model/interpretability": "The models we developed, specifically the boosted regression tree (BRT) models, are not entirely black-box but do have some level of interpretability. BRTs are ensemble models composed of multiple decision trees, which inherently provide a degree of transparency. Each tree in the ensemble makes decisions based on a subset of the predictors, and the final prediction is an aggregation of these individual tree predictions. This structure allows for the examination of variable importance, which indicates the contribution of each predictor to the model's accuracy.\n\nVariable importance can be quantified by the gain, or the relative increase in model accuracy, provided by each predictor. This information is crucial for understanding which features are most influential in predicting trapping success. For instance, we can identify that certain land cover types, building densities, or rainfall patterns are more significant predictors. This interpretability is particularly useful in ecological studies, where understanding the underlying factors driving rodent trapping success is essential.\n\nMoreover, the BRT models allow for the visualization of partial dependence plots, which show the relationship between a predictor and the predicted outcome, marginalizing over the values of all other predictors. This can help in understanding how changes in a specific predictor, such as building density or rainfall, affect the predicted trapping success.\n\nIn summary, while BRT models are more interpretable than some other machine learning models, they still require careful analysis to fully understand the relationships they capture. The ability to assess variable importance and visualize partial dependencies provides valuable insights into the ecological factors influencing rodent trapping success.",
  "model/output": "The model employed in our study is primarily a regression model, specifically a Boosted Regression Tree (BRT) model. This type of model is used to predict the success of rodent trapping within specific spatial blocks. The BRT models are trained to learn the relationships between various environmental features and the observed trapping success. These features include building density, land cover types, rainfall history, and trap placement (inside or outside buildings). The models generate predictions for trapping success within each 50 m2 spatial block, providing a quantitative measure of the likelihood of capturing rodents in those areas.\n\nThe performance of the BRT models is evaluated using metrics such as mean absolute error (MAE) and pairwise ranking metrics. The models demonstrate significant positive correlations between predicted and observed trapping success, although the absolute accuracy of the predictions varies. The BRT models are particularly effective at ranking areas by trapping success, outperforming a random model in most cases. However, their predictive ability is less reliable within houses compared to outside, where they show superior performance.\n\nIn addition to the BRT models, a simpler \"Buildings\" model is also used. This model predicts trapping success based solely on building density, as identified through a computer vision module. The \"Buildings\" model performs surprisingly well, attributing its success to extensive ecological research that highlights building density as a key predictor of rodent occurrence. This model's performance is similar to that of the BRT models when applied to spatial blocks outside of houses.\n\nOverall, the regression models provide valuable insights into the spatial distribution of rodents, helping to identify areas with higher trapping success. The models' predictions are visualized through maps that show the predicted trapping success across different towns, aiding in the understanding of rodent distribution patterns and the associated risks.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The method was evaluated using a rigorous cross-validation approach to ensure its robustness and generalizability. Specifically, we employed a train-validation-test fold strategy. For each combination of hyperparameters, the number of tree fitting iterations was limited to the point where the validation mean absolute error (MAE) was minimized over each 100 iteration cycle. The best hyperparameter combination for each fold was selected based on the lowest validation MAE score.\n\nTo assess the models' performance on unseen data, we used a test town dataset comprised of 25 randomly jittered sets of spatial blocks. This approach was chosen to develop robust estimates of model performance. For a given test town, the assessment was performed on the two models that showed the best performance on the remaining training and validation towns. Model averaging was implemented to enhance the ability of the final model predictions to generalize to new areas.\n\nThe evaluation focused on the models' ability to rank spatial blocks by trapping success, as this has direct implications for research on zoonotic diseases. The ranking ability was quantified by determining the models' success in correctly identifying which block had higher trapping success in pairs of 50 m2 spatial blocks randomly sampled from the test town. This approach is easily interpretable and facilitates efficient detection and management of zoonotic diseases.\n\nThe performance of the models was compared with two simpler models: a null model that randomly ranks spatial blocks and a \"Buildings\" model that ranks blocks based on building density within a 100 m radius. The \"Buildings\" model uses only the computer vision module of our pipeline, leveraging the known association between M. natalensis rodents and human habitation. This comparison helped to contextualize the performance of our full pipeline, which includes both computer vision and regression modules.",
  "evaluation/measure": "In our evaluation, we primarily focused on the models' ability to rank spatial blocks by trapping success, as this has direct implications for research on zoonotic diseases. We used pairwise ranking metrics to quantify this ability. Specifically, we reported the performance of our Boosted Regression Tree (BRT) models, a \"Buildings\" model, and a \"Random\" null model. The BRT and \"Buildings\" models achieved pairwise ranking metrics of 0.787 and 0.778, respectively, while the \"Random\" model had a metric of 0.506. These metrics indicate that our BRT models and the \"Buildings\" model significantly outperform the null model, demonstrating meaningful predictive power.\n\nAdditionally, we assessed the models' performance on inside-house and outside-house spatial blocks separately. Both the BRT and \"Buildings\" models showed poor predictive ability inside houses, performing no better than random. However, outside houses, both models demonstrated superior performance compared to the \"Random\" model.\n\nWe also evaluated the models' ability to predict absolute trapping success, finding that while there was a significant positive correlation between predicted and observed values, the absolute accuracy of predictions was poor. This evaluation was conducted using mean absolute error (MAE) scores, which provided a quantitative measure of the models' predictive performance.\n\nOur set of metrics is representative of the literature, focusing on ranking ability and absolute prediction accuracy. The use of pairwise ranking metrics is particularly relevant for applied research contexts where relative ranking is more important than absolute prediction. The inclusion of MAE scores aligns with common practices in evaluating regression models. Overall, our performance measures provide a comprehensive assessment of the models' predictive capabilities in both ranking and absolute prediction tasks.",
  "evaluation/comparison": "To evaluate the performance of our models, we compared them to two simpler baselines. The first baseline, referred to as the \"Random\" model, assigns a random score between zero and one to each spatial block. This model serves as a naive prediction regarding relative trapping success and does not utilize any information from our pipeline, including the computer vision or regression modules.\n\nThe second baseline, called the \"Buildings\" model, assigns a score to each spatial block based on the density of buildings within a 100-meter radius of the block's center point. This measurement is derived directly from the output of the computer vision module. The \"Buildings\" model leverages only the first module of our pipeline, focusing on a feature of hypothesized ecological importance. We chose building density because extensive ecological research has shown that M. natalensis rodents tend to be associated with human habitation.\n\nThe comparison of these models was conducted to assess their ability to rank spatial blocks by trapping success. This ranking is crucial for practical applications, such as focusing viral surveillance and distributing edible baits containing vaccines for reservoir animals more efficiently. The results showed that our method, using Boosted Regression Trees (BRT) in the regression module, significantly outperformed the \"Random\" model. However, it only marginally outperformed the \"Buildings\" model, which relies solely on building density. This indicates that, in this specific system, the simpler approach using building density performs quite well due to the quality of on-the-ground ecological research identifying building density as an important predictor of M. natalensis occurrence.\n\nAdditionally, we investigated the models' performance separately for trapping success inside and outside of houses. Both the BRT and \"Buildings\" models showed poor predictive ability within houses, performing no better than a random ranking. In contrast, when applied to spatial blocks outside of houses, both models demonstrated superior performance compared to the \"Random\" model. This analysis highlights the limitations of relying solely on aerial imagery and the need for complementary on-the-ground investigations to fully understand spillover risk.",
  "evaluation/confidence": "The evaluation of our method's performance includes several key aspects that provide confidence in the results. The performance metrics, such as mean absolute error (MAE) and pairwise ranking metrics, are calculated across multiple folds of training, validation, and testing datasets. This cross-validation approach ensures that the results are robust and not dependent on a single split of the data.\n\nFor the ranking ability of the models, we quantified the model\u2019s ability to correctly determine which block has higher trapping success in pairs of 50 m2 spatial blocks. The models were assessed on a test town dataset comprised of 25 randomly jittered sets of spatial blocks, which helps in developing robust estimates of model performance. The pairwise ranking metrics for the BRT, Buildings, and Random models were 0.787, 0.778, and 0.506, respectively. These metrics indicate that the BRT model significantly outperforms the Random model, demonstrating meaningful predictive power.\n\nStatistical significance is addressed by comparing the performance of different models. For instance, the BRT model's performance is compared to the Buildings model and the Random model. The results show that the BRT model marginally outperforms the Buildings model, which uses only the computer vision module to predict trapping success based on building density. This comparison highlights the added value of the regression module in the BRT model.\n\nAdditionally, the performance of the models is evaluated separately for trapping success inside and outside of houses. This decomposition helps in understanding the contexts in which the models perform well and where they struggle. For example, both the BRT and Buildings models show poor performance in predicting trapping success within houses, indicating that relative trap success within houses cannot be predicted using the current features.\n\nOverall, the evaluation provides a comprehensive assessment of the model's performance, including confidence intervals and statistical significance. The results demonstrate that the BRT model has meaningful predictive power and is superior to the Random model, with marginal improvements over the Buildings model. This evaluation builds confidence in the method's ability to rank areas according to predicted reservoir trapping success, which is crucial for applied research contexts such as zoonotic disease management.",
  "evaluation/availability": "Not enough information is available."
}