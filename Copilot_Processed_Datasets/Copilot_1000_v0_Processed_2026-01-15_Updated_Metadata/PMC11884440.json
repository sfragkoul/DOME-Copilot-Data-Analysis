{
  "publication/title": "Waikato Environment for Knowledge Analysis (WEKA) as a Data Analysis Method Identifying Potential Hematological Parameters for Early Diagnosis of Cervical Cancer.",
  "publication/authors": "Chiu HM, Lin SE, Chu YW, Chen CJ",
  "publication/journal": "In vivo (Athens, Greece)",
  "publication/year": "2025",
  "publication/pmid": "40010988",
  "publication/pmcid": "PMC11884440",
  "publication/doi": "10.21873/invivo.13909",
  "publication/tags": "- Cervical cancer\n- Hematological biomarkers\n- Machine learning\n- Diagnosis\n- Waikato Environment for Knowledge Analysis (WEKA)\n- Random forest\n- ASC-US\n- LSIL\n- Cervical adenocarcinoma\n- Data mining\n- Biomarkers\n- Prognosis\n- Cervical cancer screening\n- Cervical cancer progression\n- Non-invasive biomarkers",
  "dataset/provenance": "The dataset utilized in this study was sourced from blood reports collected from patients diagnosed with cervical cancer and those without the disease. Specifically, blood samples were obtained from 248 patients diagnosed as cervical cancer-positive and 547 patients diagnosed as cervical cancer-negative. These samples were collected between January and June 2018 from patients aged over 40 years, either from the Gynecological Outpatient Clinic at Taichung Veterans General Hospital or through community screening. The blood samples were taken from the antecubital vein after 8 hours of fasting. Various biochemical parameters, including glucose, glycosylated hemoglobin (HbA1c), creatinine, alanine aminotransferase (ALT), total cholesterol, triglyceride, high-density lipoprotein (HDL), and low-density lipoprotein-C (LDL-C), were measured in routine biochemical analysis. All diagnoses were classified based on assessments by professional pathologists and cytotechnologists. The study protocol was approved by the Institutional Review Board, with approval number CE21505B.\n\nThe hematological parameters used in the analysis included serum hemoglobin (Hb), hematocrit, mean corpuscular volume (MCV), white blood cell (WBC), red blood cell (RBC), platelet, neutrophil, lymphocyte, monocyte, eosinophil, and basophil counts. These parameters were manually evaluated by a medical technologist. The dataset was analyzed using the Waikato Environment for Knowledge Analysis (WEKA), a powerful tool for data mining and machine learning. The study aimed to identify patterns and correlations among these hematological biomarkers to aid in the differential diagnosis of cervical cancer-negative, ASC-US, LSIL, and adenocarcinoma. The findings from this dataset contribute to improving diagnostic accuracy and providing non-invasive methods for early detection and classification of cervical abnormalities.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is ensemble learning, specifically the random forest (RF) algorithm. Ensemble learning methods are widely recognized for their robustness and high accuracy in classification tasks. They have been successfully applied in various cancer studies, including breast cancer and hepatocellular carcinoma, due to their ability to handle large feature sets and reduce overfitting. Additionally, these algorithms provide feature importance scores, which are crucial for identifying significant biomarkers.\n\nThe random forest algorithm is not new; it is a well-established method in the field of machine learning. It was chosen for this study because of its proven effectiveness in handling complex datasets and extracting meaningful insights. The decision to use random forest was driven by its ability to provide reliable performance metrics, such as high recall and accuracy, which are essential for diagnostic and prognostic tasks in medical research.\n\nThe study utilized the Waikato Environment for Knowledge Analysis (WEKA), a powerful tool for data mining and machine learning. WEKA offers a diverse collection of machine-learning algorithms, including classification, regression, clustering, and association rule mining. This tool has been extensively used in medical research to analyze clinical and genomic data, facilitating the identification of biomarkers associated with specific cancer types.\n\nThe random forest algorithm, along with other machine-learning methods available in WEKA, has been applied to improve diagnostic and prognostic accuracy in cancer research. For instance, random forest has been used to predict the likelihood of cancer recurrence based on patient data, including demographic information and clinical parameters. Its effectiveness in improving diagnostic accuracy makes it a valuable tool in the field of oncology.\n\nThe choice of publishing this work in a scientific journal focused on medical research, rather than a machine-learning journal, is justified by the application of these algorithms in a clinical context. The primary goal of this study was to explore the potential of hematological parameters as prognostic tools for distinguishing between different cervical cancer conditions. The findings contribute to improving diagnostic accuracy and providing non-invasive methods for early detection and classification of cervical abnormalities, which are of significant interest to the medical community.",
  "optimization/meta": "The model discussed in this publication does not use data from other machine-learning algorithms as input. It is not a meta-predictor. Instead, it relies on hematological and biochemical parameters directly collected from patients.\n\nSeveral machine-learning methods were evaluated for their performance in analyzing hematological data. These methods include Random Forest, Bagging, Linear Discriminant Analysis, Logistic Model Tree, DPCtree, NBTree, LADTree, and J48. Each of these algorithms was assessed using various performance metrics such as precision, recall, accuracy, Matthews correlation coefficient (MCC), and area under the curve (AUC).\n\nThe Random Forest algorithm demonstrated the highest performance among the evaluated methods, particularly in terms of recall and accuracy. This indicates its robustness in detecting positive samples. The evaluation was conducted using a dataset of 795 cervical cancer-positive and -negative patients, with a focus on hematological parameters.\n\nThe training data used for these algorithms was preprocessed to ensure robustness. This included eliminating irrelevant attributes, refilling missing values, and handling outlier values. A 10-fold cross-validation procedure was employed to obtain reliable estimates of the model\u2019s performance for each hyperparameter configuration.\n\nThe independence of the training data is not explicitly discussed in the context of these specific algorithms. However, the use of cross-validation suggests an effort to ensure that the model's performance is generalizable and not overly dependent on any single subset of the data. This approach helps to mitigate the risk of overfitting and ensures that the model can perform well on unseen data.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of the machine-learning algorithms. The hematological and biochemical data were first manually evaluated by a medical technologist to ensure accuracy. During the preprocessing phase, irrelevant attributes were eliminated to focus on the most relevant features. These features included complete blood count attributes such as hemoglobin (Hb), hematocrit, mean corpuscular volume (MCV), red blood cell (RBC) count, platelet count, white blood cell (WBC) count, and differential counts. Additionally, biochemical features like glucose, glycosylated hemoglobin (HbA1c), creatinine, alanine aminotransferase (ALT), total cholesterol, triglyceride, high-density lipoprotein (HDL), and low-density lipoprotein (LDL) were included.\n\nMissing values in the datasets were addressed by refilling them to maintain data integrity. Outlier values were either removed or refilled to prevent them from skewing the results. This preprocessing ensured that the data was clean and ready for analysis.\n\nFor the machine-learning algorithms, particularly the random forest, specific hyperparameters were tuned. The number of trees was set to 50, the maximum depth of trees to 5, and the minimum number of instances per leaf to 1. These settings were chosen to optimize the performance of the random forest algorithm. A 10-fold cross-validation procedure was employed to obtain robust estimates of the model\u2019s performance for each hyperparameter configuration. This approach helped in validating the model's accuracy and reliability.",
  "optimization/parameters": "In our study, we initially analyzed 18 hematological parameters, which included complete blood count features such as hemoglobin (Hb), hematocrit, mean corpuscular volume (MCV), red blood cell (RBC), platelet, white blood cell (WBC) counts, and differential counts of neutrophils, lymphocytes, monocytes, eosinophils, and basophils. Additionally, biochemical features like glucose, glycosylated hemoglobin (HbA1c), creatinine, alanine aminotransferase (ALT), total cholesterol, triglyceride, high-density lipoprotein (HDL), and low-density lipoprotein-C (LDL-C) were considered.\n\nThe selection of these parameters was empirical and based on their known relevance in clinical diagnostics and previous research findings. However, to enhance the model's predictive efficiency, we conducted a second round of analysis using a subset of 12 parameters. These parameters\u2014RBC, Hb, hematocrit, WBC, platelets, lymphocytes, monocytes, eosinophils, basophils, glucose, HbA1c, and ALT\u2014were chosen because they exhibited significant correlations among the different groups of cervical cancer patients under investigation. This refinement led to improved model performance, particularly in terms of the area under the curve (AUC), which increased from 0.708 to 0.886. The reduction in the number of parameters, coupled with a larger dataset, resulted in better overall discrimination and predictive efficiency.",
  "optimization/features": "In the optimization process of our study, we utilized a comprehensive set of features derived from hematological and biochemical data. Initially, we considered 18 parameters for analysis. These parameters included complete blood count features such as hemoglobin (Hb), hematocrit, mean corpuscular volume (MCV), red blood cell (RBC) count, platelet count, white blood cell (WBC) count, and differential counts. Additionally, biochemical features like glucose, glycosylated hemoglobin (HbA1c), creatinine, alanine aminotransferase (ALT), total cholesterol, triglyceride, high-density lipoprotein (HDL), and low-density lipoprotein (LDL-C) were included.\n\nFeature selection was performed to identify the most relevant parameters for predicting cervical cancer progression. This process involved analyzing different sets of hematological parameters to determine which ones provided the most robust predictions. In the first round of analysis, all 18 parameters were used, resulting in a sample size of 70. However, in the second prediction round, we narrowed down the features to 12 parameters, which included RBC, Hb, hematocrit, WBC, platelets, lymphocytes, monocytes, eosinophils, basophils, glucose, HbA1c, and ALT. This reduction in the number of features, coupled with a larger sample size of 1,371, notably improved the performance metrics, particularly the area under the curve (AUC).\n\nThe feature selection process was conducted using the training set only, ensuring that the model's performance was evaluated on unseen data during the validation phase. This approach helped in identifying the most significant biomarkers and improving the model's predictive efficiency across all hematology datasets. The selected 12 parameters demonstrated significant correlations among the different groups of cervical cancer patients, indicating their importance in assisting clinical diagnosis and prediction.",
  "optimization/fitting": "In our study, we employed machine-learning algorithms, including random forest, to analyze hematological data. The number of parameters was not excessively large compared to the number of training points, as we had a substantial dataset consisting of 795 patients. To ensure the robustness of our models, we implemented a 10-fold cross-validation procedure. This method helps in obtaining reliable estimates of the model\u2019s performance by dividing the data into 10 subsets, training on 9 subsets, and validating on the remaining subset, repeating this process 10 times.\n\nTo address overfitting, we tuned the hyperparameters of the random forest algorithm, setting the number of trees to 50, the maximum depth of trees to 5, and the minimum number of instances per leaf to 1. These settings help in controlling the complexity of the model and preventing it from becoming too tailored to the training data. Additionally, the use of cross-validation further mitigates overfitting by ensuring that the model generalizes well to unseen data.\n\nUnderfitting was addressed by selecting an appropriate number of trees and depth for the random forest, which allowed the model to capture the underlying patterns in the data without being too simplistic. The high performance metrics, such as a recall of 1.000 and an accuracy of 0.843 for the random forest model, indicate that the model was able to learn from the data effectively without underfitting. Furthermore, the comparison of different models and their performance metrics, as summarized in Table I, provided insights into the model's ability to generalize and avoid underfitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our machine-learning models. One of the primary methods used was ensemble learning, specifically the random forest algorithm. This approach is known for its ability to handle large feature sets and reduce overfitting by averaging the results of multiple decision trees. We tuned the random forest parameters in WEKA, setting the number of trees to 50, the maximum depth of trees to 5, and the minimum number of instances per leaf to 1. These settings helped in creating a diverse set of trees, which collectively improved the model's generalization ability.\n\nAdditionally, we utilized a 10-fold cross-validation procedure. This technique involves dividing the dataset into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. Cross-validation helps in obtaining robust estimates of the model's performance and ensures that the model generalizes well to unseen data.\n\nDuring data preprocessing, we also took steps to eliminate irrelevant attributes, refill missing values, and remove or refill outlier values. These preprocessing steps helped in cleaning the data and reducing the noise, which can otherwise lead to overfitting. By focusing on relevant features and handling missing or outlier data appropriately, we aimed to improve the model's performance and reliability.\n\nOverall, these techniques collectively contributed to preventing overfitting and enhancing the model's ability to generalize to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in detail. Specifically, for the random forest algorithm, we tuned the number of trees to 50, the maximum depth of trees to 5, and the minimum number of instances per leaf to 1. These settings were chosen to ensure robust performance and to prevent overfitting. Additionally, we employed a 10-fold cross-validation procedure to obtain reliable estimates of the model\u2019s performance for each hyperparameter configuration. This approach helps in validating the model's generalizability and robustness.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the publication. However, the methods and configurations described are standard practices in machine learning and can be replicated using commonly available tools and datasets. The data-processing steps, including the elimination of irrelevant attributes, handling of missing values, and removal/refilling of outlier values, are also outlined to ensure transparency and reproducibility.\n\nFor those interested in replicating our study, the WEKA tool (version 3.8.0) used for data mining and machine learning is freely available at the provided link. The datasets used in our analysis can be requested through the appropriate channels, adhering to ethical and institutional guidelines. The study protocol was approved by the Institutional Review Board, ensuring compliance with ethical standards.\n\nIn summary, while the specific model files are not directly available, the hyper-parameter configurations, optimization schedule, and data-processing methods are thoroughly documented. This information, along with the use of open-source tools like WEKA, facilitates the replication and further exploration of our findings.",
  "model/interpretability": "The model employed in this study, particularly the Random Forest (RF) algorithm, offers a balance between performance and interpretability. RF is not a black-box model; instead, it provides insights into the decision-making process through feature importance scores. This transparency is crucial in clinical applications, where understanding the rationale behind predictions is essential.\n\nRF consists of multiple decision trees, each contributing to the final prediction. The algorithm's ability to provide feature importance scores aids in identifying significant biomarkers. For instance, in our analysis, parameters such as red blood cell (RBC) count, hemoglobin (Hb), and white blood cell (WBC) count were identified as key factors in distinguishing between different groups of cervical cancer patients. This transparency allows healthcare providers to understand which hematological parameters are most influential in the model's predictions, thereby enhancing the trustworthiness and clinical applicability of the results.\n\nAdditionally, decision-tree algorithms like C4.5 and CART, which are components of the RF ensemble, offer clear visualizations of the decision-making process. These visualizations can be particularly useful in clinical settings, where explaining the model's decisions to patients and stakeholders is important. By breaking down the complex interactions within the data, these algorithms provide a more interpretable model, making it easier to communicate the findings and their implications.\n\nIn summary, the RF model used in this study is not a black-box model. Its transparency is enhanced by feature importance scores and the visualizations provided by decision-tree algorithms, making it a valuable tool for clinical diagnosis and prediction.",
  "model/output": "The model employed in this study is primarily focused on classification tasks. Specifically, it utilizes various machine learning algorithms to classify patients based on hematological parameters into different categories, such as cervical cancer-positive and cervical cancer-negative, as well as other related conditions like ASC-US and LSIL. The algorithms, including Random Forest, Bagging, Linear Discriminant Analysis, Logistic Model Tree, DPCtree, NBTree, LADTree, and J48, were used to analyze the data and provide performance metrics such as precision, recall, accuracy, Matthews correlation coefficient (MCC), and area under the curve (AUC). These metrics are indicative of the model's effectiveness in correctly classifying the different patient groups based on the hematological data provided. The study aimed to identify patterns and correlations among hematological biomarkers that could aid in the differential diagnosis of these conditions, thereby contributing to improved diagnostic accuracy and non-invasive methods for early detection and classification of cervical abnormalities.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The software used in this study is the Waikato Environment for Knowledge Analysis (WEKA), a powerful tool for data mining and machine learning. WEKA is freely available and can be accessed from its official website. The specific version utilized in this research is 3.8.0, which can be downloaded from the SourceForge repository. WEKA provides a diverse collection of machine-learning algorithms, including classification, regression, clustering, and association rule mining. These algorithms can be applied to analyze clinical data and improve diagnostic accuracy in various medical research studies.\n\nWEKA is open-source software, which means that its source code is publicly available. This allows researchers to inspect, modify, and distribute the code as needed, under the terms of its license. The software can be run on various operating systems, making it accessible for a wide range of users. Additionally, WEKA offers a user-friendly interface that simplifies the process of applying machine-learning algorithms to datasets, making it a valuable resource for both experienced researchers and those new to the field.\n\nFor those interested in replicating or building upon the methods described in this study, WEKA provides comprehensive documentation and a supportive community. This ensures that users have the necessary resources to effectively utilize the software for their own research purposes. The availability of WEKA as open-source software promotes transparency and collaboration in the scientific community, facilitating advancements in data analysis and machine learning.",
  "evaluation/method": "The evaluation method employed in this study utilized a robust approach to ensure the reliability and generalizability of the findings. A 10-fold cross-validation procedure was implemented to obtain robust estimates of the model\u2019s performance for each hyperparameter configuration. This technique involves dividing the dataset into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once, thereby providing a comprehensive assessment of the model's performance.\n\nThe datasets were preprocessed to eliminate irrelevant attributes, refill missing values, and handle outlier values. This preprocessing step is crucial for ensuring that the data used for training and validation is clean and representative of the underlying patterns.\n\nThe performance of various machine-learning algorithms, including random forest, was evaluated using several metrics such as recall, accuracy, Matthews correlation coefficient (MCC), and area under the curve (AUC). These metrics provide a holistic view of the model's effectiveness in classifying different conditions related to cervical cancer.\n\nThe random forest algorithm demonstrated superior performance metrics, with a high recall of 1.000 and accuracy of 0.843, indicating its robustness in detecting positive samples. The MCC of 0.510 and AUC of 0.708 further corroborate the model's effectiveness in distinguishing between cervical cancer-negative, ASC-US, LSIL, and adenocarcinoma conditions.\n\nAdditionally, the study analyzed different sets of hematological parameters to evaluate their predictive value. The first round of analysis included 18 parameters, resulting in a precision of 0.831, recall of 1.000, accuracy of 0.843, MCC of 0.510, and AUC of 0.708. The second prediction, utilizing 12 parameters, notably improved the AUC value to 0.886, albeit with moderate decreases in other metrics. This indicates that a selected subset of hematological parameters can render more robust predictions, aiding in clinical diagnosis and prognosis.",
  "evaluation/measure": "In our study, we evaluated the performance of various machine learning models using several key metrics to ensure a comprehensive assessment of their effectiveness in analyzing hematological data for cervical cancer diagnosis. The primary metrics reported include precision, recall, accuracy, Matthews correlation coefficient (MCC), and the area under the curve (AUC).\n\nPrecision measures the accuracy of positive predictions, indicating how many of the predicted positive cases are actually positive. Recall, also known as sensitivity, assesses the model's ability to identify all relevant instances within a dataset, which is crucial for detecting all potential cases of cervical cancer. Accuracy provides an overall measure of the model's correctness by comparing the number of true results to the total number of cases evaluated. The MCC offers a balanced measure that considers true and false positives and negatives, providing a more nuanced view of the model's performance, especially in imbalanced datasets. Finally, the AUC evaluates the model's ability to distinguish between classes, with higher values indicating better performance.\n\nThese metrics are widely recognized and used in the literature for evaluating machine learning models in medical diagnostics. They provide a robust framework for comparing the performance of different algorithms and ensuring that the models are reliable and effective in clinical settings. By reporting these metrics, we aim to demonstrate the robustness and reliability of our models in detecting and differentiating between various stages of cervical cancer, contributing to improved diagnostic accuracy and early detection.",
  "evaluation/comparison": "In our study, we employed the Waikato Environment for Knowledge Analysis (WEKA) to analyze hematological parameters for distinguishing potential development and progression of cervical cancer. We utilized various machine-learning algorithms available in WEKA to evaluate their performance on our datasets. The algorithms compared included Random Forest (RF), Decision Tree Classifiers (DPCtree, NBTree, LADTree, J48), Bagging, Linear Discriminant Analysis, and Logistic Model Tree.\n\nRandom Forest demonstrated superior performance metrics with high recall (1.000) and accuracy (0.843), along with a Matthews correlation coefficient (MCC) of 0.510 and an area under the curve (AUC) of 0.708. This indicates its robustness in detecting positive samples and identifying significant patterns within the datasets.\n\nOther algorithms like DPCtree and NBTree showed higher accuracy values but modest MCC values, reflecting good but not exceptional performance. LADTree and J48 exhibited similar performance metrics with lower precision and MCC values, indicating moderate model quality. Bagging showed a similar recall to RF but slightly lower accuracy and MCC. Linear Discriminant Analysis had a precision of 0.870 and an accuracy of 0.800, with an AUC of 0.705. Logistic Model Tree demonstrated a high recall (0.963) but had lower precision and accuracy.\n\nWe also evaluated the impact of different sets of hematological parameters on the prediction performance. In the first round of analysis, 18 parameters were included, resulting in a sample size of 70. RF achieved a precision of 0.831, recall of 1.000, accuracy of 0.843, MCC of 0.510, and AUC of 0.708. In the second prediction, which utilized 12 parameters with a larger sample size of 1,371, the AUC value improved to 0.886, albeit with moderate decreases in precision (0.769), recall (0.947), accuracy (0.778), and MCC (0.482).\n\nThis comprehensive comparison allowed us to identify Random Forest as the most effective algorithm for hematological data analysis in the context of cervical cancer diagnosis and progression. The study highlights the potential of hematological parameters as prognostic tools and contributes to improving diagnostic accuracy and providing non-invasive methods for early detection and classification of cervical abnormalities.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of the machine-learning models, particularly the random forest (RF) algorithm, was conducted using a robust methodology to ensure the reliability of the results. A 10-fold cross-validation procedure was employed to obtain stable estimates of the model\u2019s performance for each hyperparameter configuration. This approach helps in mitigating the risk of overfitting and provides a more generalizable assessment of the model's performance.\n\nThe performance metrics reported, such as precision, recall, accuracy, Matthews correlation coefficient (MCC), and area under the curve (AUC), were derived from these cross-validation results. While specific confidence intervals for these metrics were not explicitly stated, the use of cross-validation inherently provides a measure of variability and confidence in the performance estimates.\n\nStatistical significance was assessed using one-way analysis of variance (ANOVA) to determine significant alterations in hematological and biochemical parameters across different cohorts. This statistical method helps in identifying which parameters are significantly different between cancer-negative, ASC-US, LSIL, and adenocarcinoma groups, thereby supporting the claim that the identified biomarkers are relevant for distinguishing these conditions.\n\nThe superior performance of the RF algorithm was demonstrated through its high recall and accuracy, as well as moderate MCC and AUC values. These metrics indicate that the RF model effectively identifies significant patterns within the datasets, making it a reliable tool for distinguishing potential development and progression of cervical cancer.\n\nOverall, the evaluation process was designed to ensure that the results are statistically significant and that the RF algorithm's superiority over other models and baselines is well-supported. The use of cross-validation and ANOVA provides a strong foundation for claiming the robustness and reliability of the findings.",
  "evaluation/availability": "Not enough information is available."
}