{
  "publication/title": "Construction of a 5-feature gene model by support vector machine for classifying osteoporosis samples.",
  "publication/authors": "Hu M, Zou L, Lu J, Yang Z, Chen Y, Xu Y, Sun C",
  "publication/journal": "Bioengineered",
  "publication/year": "2021",
  "publication/pmid": "34622712",
  "publication/pmcid": "PMC8806423",
  "publication/doi": "10.1080/21655979.2021.1971026",
  "publication/tags": "- Osteoporosis\n- Differentially expressed genes\n- Protein\u2013protein interaction\n- Support vector machine\n- Gene signature\n- Bioinformatics\n- Machine learning\n- Gene expression\n- Biomarkers\n- Classification model",
  "dataset/provenance": "The dataset used in this study was obtained from the Gene Expression Omnibus (GEO), a public repository for gene expression data. Specifically, the datasets utilized were GSE56116, GSE62402, GSE35959, GSE13850, GSE56814, GSE56815, and GSE7429. These datasets contain clinical follow-up data and RNA-seq data of osteoporosis cases, providing gene expression profiles essential for our analysis.\n\nThe GSE35959 dataset served as the training set, while GSE62402, GSE13850, GSE56814, GSE56815, and GSE7429 datasets were used for validation. Each dataset includes samples from both normal and osteoporosis cases, with varying numbers of data points. For instance, GSE35959 comprises 9 normal and 5 osteoporosis samples, while GSE62402 includes 5 high bone mineral density (BMD) and 5 low BMD samples.\n\nThese datasets have been previously used in the community for various studies related to osteoporosis and other medical conditions. The availability of these datasets in the GEO repository ensures that they have been vetted and are suitable for research purposes. The specific datasets chosen for this study were selected based on their relevance to osteoporosis research and the quality of the data they contain.",
  "dataset/splits": "In our study, we utilized seven datasets from the Gene Expression Omnibus (GEO) to construct and validate our support vector machine (SVM) classifier for osteoporosis. The datasets used were GSE56116, GSE62402, GSE35959, GSE13850, GSE56814, GSE56815, and GSE7429.\n\nThe dataset GSE35959 served as the training set, containing 9 normal samples and 5 osteoporosis samples. For validation, we used five datasets: GSE62402 with 5 high bone mineral density (BMD) samples and 5 low BMD samples, GSE13850 with 20 high BMD samples and 20 low BMD samples, GSE56814 with 42 high BMD samples and 31 low BMD samples, GSE56815 with 40 high BMD samples and 40 low BMD samples, and GSE7429 with 10 high BMD samples and 10 low BMD samples.\n\nThe dataset GSE56116 was used for screening differentially expressed genes (DEGs) and contained 3 normal samples and 10 osteoporosis samples. This dataset was not used for training or validation of the SVM classifier.",
  "dataset/redundancy": "The datasets used in this study were obtained from the Gene Expression Omnibus (GEO) database. The datasets were split into a training set and multiple validation sets to ensure independence between the training and test data. The GSE35959 dataset was designated as the training set, while the GSE62402, GSE13850, GSE56814, GSE56815, and GSE7429 datasets were used for validation purposes.\n\nTo enforce independence, different datasets were used for training and validation. This approach helps to prevent data leakage and ensures that the model's performance is evaluated on unseen data, which is crucial for assessing its generalizability. The training set consisted of gene expression profiles from normal and osteoporosis samples, allowing the support vector machine (SVM) classifier to learn the distinguishing features between the two categories. The validation sets, comprising different samples, were used to test the classifier's accuracy and robustness.\n\nThe distribution of samples in the datasets varied, with some datasets having a balanced number of normal and osteoporosis samples, while others had an imbalance. For instance, the GSE35959 training set included 9 normal and 5 osteoporosis samples. In contrast, the GSE13850 validation set had 20 high bone mineral density (BMD) and 20 low BMD samples. This variation in sample distribution is consistent with many previously published machine learning datasets in the field of bioinformatics, where the availability of balanced datasets is often challenging. The use of multiple validation sets with different distributions helps to evaluate the model's performance across various scenarios and ensures that it is not overly dependent on the specific characteristics of the training data.",
  "dataset/availability": "The data supporting the findings of this study are openly available in several datasets. These datasets include GSE35959, GSE62402, GSE13850, GSE56814, GSE56815, and GSE7429. Each of these datasets can be accessed through the Gene Expression Omnibus (GEO) database, which is a public repository for gene expression data. The specific URLs for accessing these datasets are provided in the publication.\n\nThe availability of these datasets ensures that the research can be replicated and verified by other researchers. The data includes gene expression profiles for both normal and osteoporosis samples, which were used to develop and validate the support vector machine (SVM) classifier. The datasets were processed to match probes to genes, and those matched to multiple genes were removed, while multiple probes matching to the median of a gene were kept to acquire the gene expression profile. This processing ensures the consistency and reliability of the data used in the study.\n\nThe datasets were used to construct and verify the prediction accuracy of the SVM classifier. The GSE35959 dataset served as the training set, while the other datasets were used for validation. The performance of the SVM classifier was evaluated using metrics such as sensitivity, specificity, and area under the ROC curve (AUC). The high accuracy and AUC values demonstrated the effectiveness of the SVM classifier in distinguishing osteoporosis samples from normal samples.\n\nThe open availability of these datasets, along with the detailed methods and results provided in the publication, allows for transparency and reproducibility in the research. This ensures that the findings can be independently verified and built upon by the scientific community.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Support Vector Machine (SVM). SVM is a well-established supervised machine-learning technique widely used for classification and pattern recognition tasks.\n\nThe SVM algorithm employed in our research is not new. It has been extensively used in various fields, including bioinformatics, for its ability to handle high-dimensional spaces and perform well with small sample sizes. The algorithm's effectiveness in classifying complex biological data, such as gene expression profiles, has been demonstrated in numerous studies.\n\nThe reason the SVM algorithm was not published in a machine-learning journal is that our focus was on applying this established method to a specific biomedical problem\u2014namely, the diagnosis of osteoporosis. Our work contributes to the field of bioengineering and medical research by showcasing the practical application of SVM in developing a diagnostic model for osteoporosis. The model's performance was evaluated using multiple datasets, demonstrating its high accuracy, sensitivity, and specificity. This application-driven approach is more aligned with the scope of journals in bioengineering and medical sciences, where the emphasis is on the practical implications and clinical relevance of the research.",
  "optimization/meta": "The model employed in this study is not a meta-predictor. It specifically utilizes the Support Vector Machine (SVM) algorithm for classification tasks. SVM is a supervised machine-learning technique known for its effectiveness in classification and pattern recognition. The SVM algorithm operates by establishing a multidimensional hyperplane that optimally distinguishes between two classes, maximizing the margin between the data clusters. This is achieved through the use of a nonlinear kernel function, which converts the input space into a multi-dimensional space, thereby enhancing its discriminant ability.\n\nThe SVM classifier was trained and validated using multiple datasets obtained from the Gene Expression Omnibus (GEO). The GSE35959 dataset served as the training set, while the GSE62402, GSE13850, GSE56814, GSE56815, and GSE7429 datasets were used for validation. The model's performance was evaluated based on its classification accuracy, sensitivity, specificity, and the area under the ROC curve (AUC). The results demonstrated high accuracy and reliability in distinguishing osteoporosis samples from normal samples, indicating the effectiveness of the SVM classifier in this context.\n\nThe training and validation datasets were carefully selected to ensure independence, with no overlap between the training and validation samples. This independence is crucial for assessing the model's generalization ability and preventing overfitting. The SVM classifier's performance was consistently high across different validation datasets, further confirming its robustness and reliability in diagnosing osteoporosis.",
  "optimization/encoding": "The data used in this study was collected from the Gene Expression Omnibus (GEO) database, specifically from datasets GSE56116, GSE62402, GSE35959, GSE13850, GSE56814, GSE56815, and GSE7429. These datasets contained clinical follow-up data and RNA-seq data of osteoporosis cases, providing gene expression profiles.\n\nFor the chip data, probes were matched to genes. Probes that matched to multiple genes were removed, while multiple probes matching to the same gene were averaged to obtain the median gene expression value. This process ensured that each gene had a single expression value, simplifying the data and making it suitable for analysis.\n\nThe dataset GSE35959 served as the training set, while GSE62402, GSE13850, GSE56814, GSE56815, and GSE7429 were used as validation datasets. This division allowed for the construction and verification of the prediction accuracy of the support vector machine (SVM) classifier.\n\nDifferentially expressed genes (DEGs) were identified using the Limma package in R. Genes were considered DEGs if they had an adjusted p-value of less than 0.05 and an absolute fold change greater than 2. This stringent criteria ensured that only significant genes were selected for further analysis.\n\nThe gene expression profiles were then used to train the SVM classifier, which was employed to classify osteoporosis and normal samples. The classifier's accuracy was assessed using sensitivity, specificity, and the area under the curve (AUC) with the pROC package in R. This comprehensive approach ensured that the data was appropriately encoded and pre-processed for the machine-learning algorithm, leading to reliable and accurate results.",
  "optimization/parameters": "In our study, we utilized a Support Vector Machine (SVM) model for classifying osteoporosis samples. The model was developed using five hub genes identified from the GSE35959 training dataset. These genes were selected based on their differential expression and their roles in the protein-protein interaction (PPI) network.\n\nThe selection of these five genes as input parameters for the SVM model was driven by several factors. Initially, we identified 310 differentially expressed genes (DEGs) between normal and osteoporosis samples. These DEGs were enriched in biological processes such as positive regulation of protein secretion, cytokine secretion, neutrophil-mediated immunity, and neutrophil activation. We then constructed a PPI network using these DEGs and applied various algorithms (Degree, MNC, Closeness, and MCC) to identify key hub genes. The five genes\u2014CCR1, CD33, HCK, LILRB2, and CYBB\u2014were consistently highlighted as significant in these analyses.\n\nThese five genes were used as features in the SVM model. The model's performance was evaluated across multiple datasets, including GSE35959, GSE62402, GSE13850, GSE56814, GSE56815, and GSE7429. The high accuracy, sensitivity, and specificity achieved in these datasets validated the effectiveness of these five genes as reliable biomarkers for osteoporosis diagnosis.",
  "optimization/features": "In our study, we utilized a Support Vector Machine (SVM) classifier to distinguish between osteoporosis and normal samples. The input features for this classifier consisted of five specific genes, which were identified through a rigorous process involving differentially expressed genes (DEGs) analysis and protein-protein interaction (PPI) network construction.\n\nFeature selection was indeed performed to identify these five hub genes. This process involved several steps, including the analysis of gene expression profiles from multiple datasets obtained from the Gene Expression Omnibus (GEO). The Limma package in R was used to screen for DEGs between normal and osteoporosis samples, focusing on genes with an adjusted p-value of less than 0.05 and an absolute fold change greater than 2.\n\nThe PPI network was then established using interaction data from the Human Protein Reference Database, and hub genes were identified using various algorithms such as Closeness, MCC, MNC, and Degree. These hub genes were further analyzed to develop an expression spectrum and an SVM classification model.\n\nImportantly, the feature selection process was conducted using the training dataset (GSE35959) only. This ensured that the model's performance could be validated on independent datasets without bias. The selected features demonstrated high classification accuracy, sensitivity, and specificity across multiple validation datasets, indicating their reliability as biomarkers for osteoporosis diagnosis.",
  "optimization/fitting": "In our study, we employed a Support Vector Machine (SVM) algorithm for classification, which is particularly advantageous for high-dimensional data with a limited number of training samples. This approach helps to simplify computational complexity and is well-suited for scenarios where the number of features (parameters) is much larger than the number of training points.\n\nTo address the potential issue of overfitting, we utilized several strategies. Firstly, the SVM algorithm inherently includes a regularization parameter that helps to control the complexity of the model, thereby reducing the risk of overfitting. Additionally, we validated our model using multiple independent datasets, ensuring that the model's performance was consistent across different samples. The high classification accuracy and area under the ROC curve (AUC) values observed in both training and validation datasets further support the robustness of our model and indicate that overfitting was effectively mitigated.\n\nConversely, to rule out underfitting, we carefully selected relevant features and hub genes that were significantly associated with the condition being studied. The use of a comprehensive set of differentially expressed genes (DEGs) and the construction of a protein-protein interaction (PPI) network helped in identifying key biomarkers. The high sensitivity and specificity of our model across various datasets demonstrate that the model is not overly simplistic and captures the essential patterns in the data.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a black-box model. It is based on a support vector machine (SVM) classifier, which is inherently interpretable to a certain extent. The SVM classifier uses a set of five specific genes (CCR1, CD33, HCK, LILRB2, and CYBB) as features to distinguish between osteoporosis samples and normal samples. These genes were identified through a systematic bioinformatics approach involving the analysis of differentially expressed genes and protein-protein interaction networks.\n\nThe transparency of the model is evident in several ways:\n\n* The model relies on a clear and defined set of features, namely the expression levels of the five identified genes. This makes it possible to understand which biological factors are contributing to the classification decision.\n* The SVM algorithm itself is interpretable in the sense that it defines a hyperplane in the feature space that separates the two classes. The coefficients of this hyperplane can provide insights into the importance of each feature in the classification task.\n* The model's performance was validated across multiple datasets, demonstrating its robustness and generalizability. This validation process provides further confidence in the model's interpretability and reliability.\n\nIn summary, the SVM classifier developed in this study is transparent and interpretable, relying on a well-defined set of biological features and a clear mathematical framework for classification. This transparency is crucial for understanding the biological mechanisms underlying osteoporosis and for translating the model into clinical practice.",
  "model/output": "The model developed in this study is a classification model. It is designed to distinguish between osteoporosis samples and normal samples. The model utilizes a support vector machine (SVM) algorithm, which is a supervised machine learning technique widely used for classification tasks. The SVM classifier was constructed based on five feature genes identified from the training dataset. The performance of the model was evaluated using various metrics such as sensitivity, specificity, and the area under the receiver operating characteristic (ROC) curve. The model demonstrated high accuracy in classifying samples across multiple datasets, indicating its effectiveness in predicting and classifying osteoporosis.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the diagnostic model involved multiple datasets to ensure its robustness and accuracy. Initially, a support vector machine (SVM) classification model was developed using five hub genes from the GSE35959 training dataset. This model demonstrated perfect classification accuracy, sensitivity, and specificity, with an area under the ROC curve (AUC) of 1.\n\nTo validate the model's performance, it was tested on several independent datasets. In the GSE62402 dataset, all samples were correctly classified, maintaining 100% accuracy, sensitivity, specificity, and an AUC of 1. The GSE13850 dataset showed a classification accuracy of 87.5%, with a sensitivity of 80%, specificity of 95%, and an AUC of 0.875. The GSE56814 dataset achieved a high classification accuracy of 94.5%, with a sensitivity of 87%, specificity of 100%, and an AUC of 0.935. The GSE56815 dataset had a classification accuracy of 93.8%, sensitivity of 97.5%, specificity of 90%, and an AUC of 0.938. Finally, the GSE7429 dataset showed perfect classification with 100% accuracy, sensitivity, specificity, and an AUC of 1.\n\nThese results indicate that the SVM classification model effectively distinguishes osteoporosis samples from normal samples. The five genes used in the model are reliable biomarkers for diagnosing osteoporosis. However, it is noted that further biological validation with a larger sample size is necessary before clinical application.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our diagnostic model for osteoporosis. The primary metrics reported include classification accuracy, sensitivity, specificity, and the area under the Receiver Operating Characteristic (ROC) curve (AUC).\n\nClassification accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. This metric provides an overall indication of how well the model performs in distinguishing between osteoporosis samples and normal samples.\n\nSensitivity, also known as the true positive rate, assesses the model's ability to correctly identify osteoporosis samples. It is crucial for understanding how well the model can detect the condition when it is present.\n\nSpecificity, or the true negative rate, evaluates the model's ability to correctly identify normal samples. This metric is important for ensuring that the model does not falsely classify normal samples as having osteoporosis.\n\nThe AUC provides a single scalar value that summarizes the performance of the model across all classification thresholds. An AUC of 1 indicates perfect classification, while an AUC of 0.5 suggests performance no better than random chance.\n\nThese metrics were chosen because they are widely accepted and used in the literature for evaluating diagnostic models. They provide a comprehensive view of the model's performance, covering aspects such as overall accuracy, the ability to detect positive cases, and the ability to correctly identify negative cases. The use of these metrics ensures that our results are comparable to other studies in the field, allowing for a more robust evaluation of our model's effectiveness.",
  "evaluation/comparison": "In our study, we employed a Support Vector Machine (SVM) classifier to distinguish between osteoporosis and normal samples. The SVM algorithm was chosen for its ability to handle high-dimensional data with a limited number of training samples, making it suitable for our dataset. The SVM classifier was constructed using a set of five hub genes identified from the GSE35959 training dataset. This model demonstrated high accuracy, sensitivity, and specificity across multiple validation datasets, including GSE62402, GSE13850, GSE56814, GSE56815, and GSE7429.\n\nWhile our focus was on the performance of the SVM classifier, we acknowledge that comparing our method to publicly available benchmarks and simpler baselines could provide additional insights. However, such comparisons were not explicitly conducted in this study. The SVM's performance was evaluated independently on various datasets, showcasing its robustness and reliability in classifying osteoporosis samples. Future work could involve direct comparisons with other machine learning algorithms and simpler baselines to further validate the effectiveness of our approach.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe performance metrics for the SVM classification model were evaluated across multiple datasets, providing a robust assessment of its accuracy and reliability. The metrics included sensitivity, specificity, accuracy, and the area under the ROC curve (AUC). For the training dataset, the model achieved a perfect score of 100% for sensitivity, specificity, and accuracy, with an AUC of 1. This indicates that the model was able to perfectly distinguish between osteoporosis and normal samples in the training data.\n\nIn the validation datasets, the model also performed exceptionally well. For instance, in the GSE62402 dataset, all samples were correctly classified, resulting in a 100% sensitivity, specificity, and accuracy, with an AUC of 1. Similarly, in the GSE7429 dataset, the model achieved 100% sensitivity, specificity, and accuracy, with an AUC of 1. These results suggest that the model generalizes well to new, unseen data.\n\nHowever, it is important to note that while the performance metrics are impressive, confidence intervals and statistical significance tests were not explicitly mentioned. This means that while the model shows high accuracy, the variability and statistical significance of these results are not quantified. Future studies could benefit from including confidence intervals and statistical tests to provide a more comprehensive evaluation of the model's performance and its superiority over other methods or baselines.",
  "evaluation/availability": "The raw evaluation files used in this study are publicly available. The datasets utilized for the construction and validation of the diagnostic model can be accessed through the Gene Expression Omnibus (GEO) database. Specifically, the datasets include GSE35959, GSE62402, GSE13850, GSE56814, GSE56815, and GSE7429. These datasets are openly available and can be retrieved from the GEO database using the provided accession numbers. The data is made available under the terms and conditions specified by the GEO database, ensuring that researchers can access and utilize the information for further studies and validations."
}