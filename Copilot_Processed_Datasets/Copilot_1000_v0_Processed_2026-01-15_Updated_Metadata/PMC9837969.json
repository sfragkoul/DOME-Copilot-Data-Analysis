{
  "publication/title": "Profiles of autism characteristics in thirteen genetic syndromes: a machine learning approach.",
  "publication/authors": "Bozhilova N, Welham A, Adams D, Bissell S, Bruining H, Crawford H, Eden K, Nelson L, Oliver C, Powis L, Richards C, Waite J, Watson P, Rhys H, Wilde L, Woodcock K, Moss J",
  "publication/journal": "Molecular autism",
  "publication/year": "2023",
  "publication/pmid": "36639821",
  "publication/pmcid": "PMC9837969",
  "publication/doi": "10.1186/s13229-022-00530-5",
  "publication/tags": "- Autism\n- Genetic Syndromes\n- Support Vector Machine\n- Behavioral Signatures\n- Social Communication Questionnaire\n- Classification Accuracy\n- Adaptive Behavior\n- Rare Genetic Conditions\n- Machine Learning\n- Autism Spectrum Disorder",
  "dataset/provenance": "The dataset used in this study was sourced from one of the largest cross-syndrome databases in the UK, held at a UK-based university. This database was established in 2003 and includes retrospective baseline data collected up until 2018. The total sample initially comprised 1702 individuals with genetic syndromes associated with intellectual disability (ID) and 264 autistic individuals with varying levels of adaptive skills.\n\nThe analysis included 1582 individuals with genetic syndromes and 258 autistic individuals who did not have a known genetic syndrome, all over four years of age. The genetic syndrome groups varied in sample sizes and included Angelman syndrome (AS, n = 154), Cri du Chat syndrome (CdCS, n = 75), Cornelia de Lange syndrome (CdLS, n = 199), fragile X syndrome (FXS, n = 297), Prader\u2013Willi syndrome (PWS, n = 278), Lowe syndrome (LS, n = 89), Smith\u2013Magenis syndrome (SMS, n = 54), Down syndrome (DS, n = 135), Sotos syndrome (SS, n = 40), Rubinstein\u2013Taybi syndrome (RTS, n = 102), 1p36 deletion syndrome (n = 41), Phelan-McDermid syndrome (PMS, n = 35), and tuberous sclerosis complex (TSC, n = 83).\n\nThe database initially included eight behavioural and health measures, along with diagnostic information such as the presence or absence of a genetic syndrome. Over time, more measures and groups, including autistic individuals without a genetic syndrome, were added. This database represents the largest longitudinal data on individuals with genetic syndromes associated with ID in the UK.\n\nThe dataset has been used in previous studies, notably by Bruining et al. and more recently by Lee et al., who adopted a support vector machine (SVM) learning approach to generate fine-grained descriptions of autistic characteristics in individuals with these genetic syndromes. The current study aims to replicate and extend these findings in a larger and more diverse sample.",
  "dataset/splits": "The dataset was split into two halves for the purpose of identifying the optimal parameters for the Support Vector Machine (SVM) model. One half served as the training set, and the other half served as the test set. This split was done to ensure that at least fifteen participants from each syndrome group were included in the training set, which was crucial for determining the parameters with the highest accuracy.\n\nAfter identifying the best combination of gamma and cost parameters, the model was then trained and tested on the entire sample size. This approach helped to reduce any potential overestimation or underestimation of classification accuracy for certain groups. The entire dataset consisted of 1582 individuals with genetic syndromes associated with intellectual disability and 264 autistic individuals with varying levels of adaptive skills. The dataset was derived from one of the largest cross-syndrome databases in the UK, which was established in 2003 and had its last follow-up completed in 2018.",
  "dataset/redundancy": "The dataset was split into two halves to identify the optimal parameters for the support vector machine (SVM) model. One half served as the training set, and the other half as the test set. This split ensured that the training and test sets were independent, which is crucial for evaluating the model's performance accurately.\n\nTo address the issue of unequal sample sizes across different syndrome groups, at least fifteen participants from each syndrome group were included in the training set. This approach helped to ensure that the model was trained on a representative sample of each group, reducing the risk of bias towards larger groups.\n\nThe final model was then trained and tested on the entire sample size. This step further helped to reduce any potential overestimation or underestimation of classification accuracy for certain groups, providing a more robust evaluation of the model's performance.\n\nThe distribution of the dataset in this study is notably larger and more diverse compared to previously published machine learning datasets in this domain. This large and diverse sample enables a greater understanding of how variation in sample size affects misclassification patterns for individual syndromes. For instance, the classification accuracy for the Down syndrome group was higher in this study with a larger sample size compared to previous studies. This suggests that larger sample sizes can improve classification accuracy, although the misclassification patterns themselves do not vary significantly with sample size.",
  "dataset/availability": "The data used in this study is not publicly available. The dataset was compiled from one of the largest cross-syndrome databases in the UK, held at a UK-based university. This database includes retrospective baseline data collected from 2003 to 2018, encompassing various behavioral and health measures, as well as diagnostic information. The dataset includes individuals with genetic syndromes associated with intellectual disability and autistic individuals with varying levels of adaptive skills.\n\nThe specific data splits used for training and testing the support vector machine (SVM) model were not detailed in terms of public release. The dataset was divided into training and test sets to identify the optimal parameters for the SVM model. One half of the dataset served as the training set, and the other half as the test set. Additionally, an item-level analysis was conducted to evaluate each of the Social Communication Questionnaire (SCQ) items within each group.\n\nThe ethical considerations and governance reviews ensured that the data was handled responsibly. Ethical approval was granted by the Coventry Research Ethics Committee, and the study underwent institutional governance review. Participants and their parents/carers were recruited via syndrome support groups and associations, with favorable ethical approval ensuring the protection of participant data.\n\nGiven the sensitive nature of the data, which includes personal and genetic information, it is not publicly available. Access to the data would likely require specific permissions and adherence to ethical guidelines to ensure the privacy and security of the participants.",
  "optimization/algorithm": "The machine-learning algorithm class used is Support Vector Machines (SVM). This is a well-established and widely used algorithm in the field of machine learning, particularly for classification tasks. The SVM approach was adopted to provide better predictive accuracy of genetic groups of the thirteen genetic syndromes based on their SCQ scores.\n\nThe SVM algorithm used is not new. It is a well-known method that has been extensively studied and applied in various domains. The technical specifications of the SVM model were consistent with previously identified optimal parameters, such as the use of a radial kernel, the choice of cross-validation method, and the approach to generating gamma and cost parameters.\n\nThe reason the SVM algorithm was not published in a machine-learning journal is that the focus of the study was not on developing a new machine-learning algorithm but rather on applying an established method to a specific problem in the context of genetic syndromes and autism spectrum disorder. The study aimed to classify individuals with genetic syndromes into their appropriate genetic groups based on their SCQ scores, utilizing the SVM algorithm's strengths in handling high-dimensional data and maximizing the separation between different categories. The SVM approach has been previously used in similar studies, and the current work builds upon this existing methodology to address the specific research questions related to genetic syndromes and autism.",
  "optimization/meta": "The model employed in this study does not utilize data from other machine-learning algorithms as input. Instead, it relies on a Support Vector Machine (SVM) approach for classification. The SVM maps training exemplars to high-dimensional space to maximize the separation between different categories, constructing hyperplanes to separate these categories.\n\nThe SVM model adopted a multiclass classification approach, which involves training multiple binary classifiers. This method uses a 'one-to-one' or 'one-against-one' approach, where for k classes, k(k-1)/2 binary classifiers are trained. Each data point is assigned to a 'predicted' class based on the most frequently chosen class by these binary classifiers.\n\nRegarding the independence of training data, the model was trained and tested on the entire sample size after identifying the optimal combination of gamma and cost parameters. This process involved splitting the entire dataset into two halves, with one half serving as the training set and the other as the test set. This splitting ensures that the training data is independent from the test data, helping to reduce over or underestimation of classification accuracy for certain groups.\n\nThe model's performance was further optimized using a random search of gamma and cost parameter values, evaluating the accuracy of the SVM classifier for each combination. The combination yielding the highest accuracy was selected, ensuring robust and independent training and testing phases.",
  "optimization/encoding": "The data encoding process involved using the lifetime version of the Social Communication Questionnaire (SCQ), which includes all 40 items. Traditional binary scoring (1 = Yes, 0 = No) was not used due to the heterogeneity of language abilities across the sample. Instead, an additional score of 2 was introduced for six language-related items to indicate the absence of language use, rather than the absence of autistic-related characteristics. This approach allowed for the inclusion of all items for all participants, capturing language heterogeneity effectively. The coding of all items, including the language items, was processed as categorical by the model. This encoding method enabled the model to generate a unique pattern of responses for each syndrome group, with the score of 2 not being weighted as more important than a score of 1 or 0. If a group tended to score 2, 1, or 0 on most language items, this scoring pattern helped create a distinctive profile for that group. This encoding strategy was crucial for building an accurate Support Vector Machine (SVM) model that could classify individuals into their respective genetic syndrome groups based on their SCQ scores.",
  "optimization/parameters": "In our study, the Support Vector Machine (SVM) model utilized two key parameters: gamma and cost. These parameters are crucial for optimizing the model's performance.\n\nThe selection of these parameters was guided by a random search approach, where up to 100 combinations of gamma and cost values were explored. This method allowed us to evaluate the model's accuracy for each combination and identify the pair that yielded the highest accuracy. To ensure robustness, the dataset was split into two halves: one for training and the other for testing. This split helped in determining the optimal parameters while maintaining a balance across different syndrome groups, with at least fifteen participants from each group included in the training set.\n\nAfter identifying the best combination of gamma and cost parameters, the model was trained and tested on the entire sample. This step was essential for reducing any potential overestimation or underestimation of classification accuracy for specific groups. The final model adopted a multiclass classification approach, reflecting the training of multiple binary classifiers to achieve mutual linear separation between all classes.",
  "optimization/features": "The study utilized the Social Communication Questionnaire (SCQ) to assess individuals with genetic syndromes. The SCQ consists of 40 items, which were used as input features for the Support Vector Machine (SVM) model. These items were included in their entirety, with an additional scoring mechanism introduced for language-related items to better capture the heterogeneity of language abilities across the sample.\n\nFeature selection was performed to identify the most and least important items for each syndrome group. This selection was based on the contribution of each item to the classification results, with scores ranging from 0 to 100. The criteria for selection included a score of 20 or lower for the least important items and a score of 50 or higher for the most important items. This process helped in interpreting the results and understanding the variability across different syndrome groups.\n\nThe feature selection process was conducted using the entire dataset, ensuring that the identified important features were robust and generalizable. This approach allowed for a more focused analysis of the key items that contributed significantly to the classification accuracy of the SVM model. The selection criteria were data-driven and exploratory, aligning with previous research in the field.",
  "optimization/fitting": "The fitting method employed in this study involved the use of a Support Vector Machine (SVM) with a radial kernel. The SVM maps training exemplars to high-dimensional space, maximizing the separation between different categories. This approach inherently helps to manage the complexity of the model and the risk of overfitting, as it focuses on finding the optimal hyperplane that best separates the classes.\n\nTo address the potential issue of overfitting, especially given the high-dimensional space, several strategies were implemented. Firstly, a random search was conducted to optimize the gamma and cost parameters, evaluating up to 100 combinations. This process helped in identifying the combination of parameters that yielded the highest accuracy, thereby reducing the risk of overfitting. Additionally, n-fold cross-validation was used, where n-1 observations were used to build the SVM classifier, and the remaining observation was used for validation. This method provided an independent estimate of the model's accuracy on the entire sample, further mitigating overfitting concerns.\n\nTo ensure that the model was not underfitting, the dataset was split into two halves: one for training and the other for testing. This split ensured that the model was trained on a sufficient number of observations, allowing it to capture the underlying patterns in the data. Furthermore, the inclusion of at least fifteen participants from each syndrome group in the training set helped in maintaining a balanced representation, which is crucial for avoiding underfitting.\n\nThe final SVM model adopted a multiclass classification approach using a 'one-to-one' or 'one-against-one' strategy. This method involved training multiple binary classifiers to achieve mutual linear separation between every two classes. The decision values of these binary classifiers were used to generate predicted probabilities for each class, providing an alternative way to assess the confidence of the SVM predictions. This comprehensive approach ensured that the model was neither overfitting nor underfitting, thereby achieving a robust classification accuracy.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our Support Vector Machine (SVM) model. One key method involved the use of cross-validation, specifically n-fold validation. This technique helps to provide an independent estimate of the model's accuracy by using n-1 observations to build the classifier and leaving one observation out for validation. This process is repeated for each observation in the dataset, ensuring that every data point is used for both training and testing.\n\nAdditionally, we optimized the model by determining the best values for the gamma and cost parameters. This was achieved through a random search of up to 100 combinations of these parameters. The performance of the model was evaluated for each combination, and the set of values that yielded the highest accuracy was selected. This approach helps to fine-tune the model and reduce the risk of overfitting by ensuring that the parameters are not overly tailored to the training data.\n\nTo further mitigate overfitting, we split the entire dataset into two halves: one for training and the other for testing. This split ensured that the model was trained on a subset of the data and then tested on a separate subset, providing a more reliable estimate of its performance. Moreover, we ensured that at least fifteen participants from each syndrome group were included in the training set, which helped to balance the sample sizes and reduce the likelihood of overfitting to any particular group.\n\nLastly, after identifying the optimal parameters, the model was trained and tested on the entire sample size. This step helped to reduce any potential overestimation or underestimation of classification accuracy for certain groups, thereby enhancing the generalizability of the model.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in this study are reported in detail. Specifically, the support vector machine (SVM) model employed a radial kernel, and the optimal values for gamma and cost parameters were determined through a random search involving up to 100 combinations. The dataset was split into training and test sets to identify the best parameters, ensuring that at least fifteen participants from each syndrome group were included in the training set. This approach helped in reducing over or underestimation of classification accuracy for certain groups.\n\nThe model's performance was evaluated using n-fold validation, where n-1 observations were used to build the SVM classifier, and the remaining observation was used for validation. This method provided an independent estimate of the model's accuracy across the entire sample.\n\nThe final SVM model adopted a multiclass classification approach, using a 'one-to-one' or 'one-against-one' strategy to handle multiple classes. The decision values of the binary classifiers were used to generate predicted probabilities for each class, offering an alternative way to assess the confidence of the SVM predictions.\n\nRegarding the availability of model files and optimization parameters, the study utilized the libSVM library via the SVM function in the e1071 library in R. This information is publicly accessible and can be used by other researchers. The specific details of the model files and optimization parameters are not explicitly provided in the text, but the methods and libraries used are well-documented and widely available in the scientific community. The study adheres to standard practices in reporting, ensuring reproducibility and transparency.",
  "model/interpretability": "The model employed in this study is not a black-box model. It utilizes a Support Vector Machine (SVM) approach, which inherently provides some level of interpretability. The SVM maps training examples to a high-dimensional space to maximize the separation between different categories, constructing hyperplanes to separate these categories. This process allows for a clear understanding of how the model differentiates between classes.\n\nThe interpretability of the model is further enhanced by the use of a 'one-to-one' or 'one-against-one' approach for multiclass classification. This method involves training multiple binary classifiers to gain mutual linear separation between every two classes. The final output of the SVM model assigns each data point to a 'predicted' class, which is the most frequently chosen class by the binary classifiers. This approach provides insights into how individual classifiers contribute to the overall classification decision.\n\nAdditionally, the decision values of the binary classifiers can generate predicted probabilities for each class. These probabilities offer an alternative way to assess the confidence of the SVM predictions, adding another layer of interpretability. The model's parameters, such as gamma and cost, were optimized using a random search, and the best combination was selected based on accuracy. This systematic approach to parameter tuning ensures that the model's decisions are based on well-defined criteria.\n\nThe study also conducted an item-level analysis, evaluating each item within the Social Communication Questionnaire (SCQ) for its contribution to the model's predictions. This analysis identified the top five items that contribute the most and the least to the model for each syndrome group. For example, items like 'reciprocal conversation' and 'odd phrases' were among the top contributors for several groups, while items like 'unusual interests' and 'inappropriate facial expressions' were among the least contributors. This detailed item-level analysis provides clear examples of how specific features influence the model's decisions, making it more transparent.\n\nFurthermore, the model's validity was tested by correlating the predicted probabilities with the number of individuals correctly assigned to their relevant genetic group. Strong, positive correlations emerged, highlighting the model's ability to accurately predict group membership based on the SCQ scores. This correlation analysis adds to the model's interpretability by demonstrating the relationship between predicted probabilities and actual classification accuracy.",
  "model/output": "The model employed in this study is a classification model. Specifically, it is a Support Vector Machine (SVM) model designed for multiclass classification. This model maps data points to a high-dimensional space to achieve mutual linear separation between every two classes. The final output of the SVM model assigns each data point to a 'predicted' class, which is the most frequently chosen class by the binary classifiers. This approach allows for the classification of individuals into different genetic syndrome groups based on their characteristics.\n\nThe model uses a 'one-to-one' or 'one-against-one' approach, where for k classes, k(k-1)/2 binary classifiers are trained. This method ensures that each pair of classes is compared, and the final classification is determined by the most frequently chosen class across these comparisons.\n\nIn addition to classification accuracy, the decision values of the binary classifiers can generate predicted probabilities for each class. These probabilities provide an alternative way to assess the confidence of the SVM predictions. The model's performance was evaluated using various metrics, including classification accuracy and the predicted probabilities for each genetic syndrome group.\n\nThe study also conducted an item-level analysis to evaluate the contribution of each item within the Social Communication Questionnaire (SCQ) to the model's predictions. This analysis helped identify the most and least important items for each syndrome group, providing insights into the specific characteristics that contribute to the classification results.\n\nOverall, the SVM model demonstrated substantial classification accuracy, particularly for groups with distinct characteristics. However, some groups showed lower accuracy due to frequent misallocation to other genetic syndrome groups. The model's validity was further tested by correlating the predicted probabilities with the number of individuals correctly assigned to their relevant genetic group, highlighting the model's robustness and reliability.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed for the study involved a robust approach to ensure the accuracy and validity of the support vector machine (SVM) model. The model was built using a radial kernel, which is known for its effectiveness in handling non-linear data. To optimize the model, a random search was conducted to determine the best combination of gamma and cost parameters, evaluating up to 100 different combinations. This process involved splitting the entire dataset into two halves, with one half used for training and the other for testing. This split ensured that at least fifteen participants from each syndrome group were included in the training set, addressing the issue of unequal sample sizes across different groups.\n\nThe model's performance was further validated using n-fold cross-validation, specifically leave-one-out cross-validation. This method involves using n-1 observations to build the SVM classifier and leaving one observation out for validation. This process was repeated for each observation in the dataset, providing an independent estimate of the model's accuracy across the entire sample.\n\nAdditionally, the study conducted a sensitivity analysis by including only participants who met or scored above the suggested cutoff scores for autism spectrum disorder (ASD) on the Social Communication Questionnaire (SCQ). This analysis aimed to assess whether variations in SCQ scores influenced the generation of the identified profiles. The results of this sensitivity analysis were comparable to the initial analysis, indicating that higher SCQ scores did not significantly affect the model's performance.\n\nThe validity of the prediction model was also tested by correlating the predicted probabilities with the number of individuals correctly assigned to their relevant genetic group. Strong, positive correlations were observed, highlighting the model's validity and its ability to accurately classify individuals into their respective genetic syndrome groups. This comprehensive evaluation method ensured that the SVM model was robust, reliable, and capable of providing accurate classifications for individuals with genetic syndromes.",
  "evaluation/measure": "In the evaluation of our model, several performance metrics were reported to provide a comprehensive assessment of its effectiveness. The primary metric reported was classification accuracy, which indicates the proportion of individuals correctly classified into their respective genetic syndrome groups. This metric was presented as a percentage, with the overall accuracy of the model being 55%. Additionally, the accuracy for each individual syndrome group was reported, allowing for a detailed understanding of the model's performance across different categories.\n\nTo further validate the model, post hoc predicted probabilities were analyzed. These probabilities reflect the confidence of the model's predictions for each group. Groups with higher classification accuracy, such as Angelman syndrome, fragile X syndrome, Prader-Willi syndrome, and Rubinstein-Taybi syndrome, also showed higher predicted probabilities for correct allocation. Conversely, groups with lower classification accuracy, like Lowe syndrome, Sotos syndrome, Tuberous sclerosis complex, and Phelan-McDermid syndrome, exhibited more equal predicted probabilities across different groups, indicating less confidence in the predictions.\n\nThe validity of the prediction model was also assessed by correlating the predicted probabilities with the number of individuals correctly assigned to their relevant genetic groups. Strong, positive correlations were observed, highlighting the model's robustness and reliability. This correlation analysis is consistent with previous studies, reinforcing the validity of our approach.\n\nA sensitivity analysis was conducted to ensure that variations in SCQ scores did not influence the generation of the identified profiles. Both the initial analysis, which included all participants, and the sensitivity analysis, which focused on participants meeting or exceeding the suggested cutoff scores for ASD on the SCQ, yielded comparable results. This consistency suggests that the model's performance is stable and not significantly affected by variations in SCQ scores.\n\nMisallocation patterns were also examined to understand the reasons behind poor predictions for certain groups. For instance, individuals from specific syndrome groups were frequently misclassified into other groups, such as those from Cri du Chat syndrome and Cornelia de Lange syndrome being misclassified into the Angelman syndrome group. This analysis provides insights into the challenges faced by the model and areas for potential improvement.\n\nIn summary, the performance metrics reported include classification accuracy, post hoc predicted probabilities, and correlation analysis. These metrics are representative of standard practices in the literature, ensuring a thorough and reliable evaluation of the model's performance. The inclusion of sensitivity analysis and misallocation patterns further enhances the comprehensiveness of the evaluation, providing a detailed understanding of the model's strengths and limitations.",
  "evaluation/comparison": "In our study, we employed a Support Vector Machine (SVM) approach to generate fine-grained descriptions of autistic characteristics in individuals with genetic syndromes. This method was chosen for its ability to provide better predictive accuracy of genetic groups based on Social Communication Questionnaire (SCQ) scores. The SVM approach was previously adopted by Bruining et al. and more recently by Lee et al., demonstrating its effectiveness in similar research contexts.\n\nTo evaluate the performance of our SVM model, we conducted a comparison with simpler baselines, such as Principal Component Analysis (PCA). PCA was used to investigate the extent of overlap between autism profiles across the thirteen genetic groups. However, PCA, as an unsupervised analysis, did not prove suitable for generating autism-related profiles for genetic syndromes. This is because PCA does not integrate knowledge of the genotype or classification approaches, instead providing a representation of the overlap between different individuals across groups. This limitation did not allow for the generation of autism-related profiles based on SCQ scores.\n\nThe SVM model, on the other hand, was able to accurately classify 55% of individuals with genetic syndromes into the appropriate genetic group. This multiclass approach allowed for the inclusion of genotype membership in the analysis, providing a more accurate and detailed classification. The validity of the prediction model was further tested by correlating the predicted probabilities with the number of individuals correctly assigned to the relevant genetic class/group. Strong, positive correlations emerged, highlighting the validity of the prediction model.\n\nIn summary, while simpler baselines like PCA were considered, the SVM approach proved to be more effective in achieving the study's aims. The comparison with PCA underscored the advantages of using a supervised learning method that can integrate genotype information and provide more accurate classifications.",
  "evaluation/confidence": "The evaluation of the Support Vector Machine (SVM) model's performance included several key metrics, but specific details about confidence intervals for these metrics are not provided. The primary performance metric reported is the classification accuracy, which is the percentage of individuals correctly classified into their respective genetic syndrome groups. For instance, the overall accuracy of the SVM model is reported as 55%.\n\nThe statistical significance of the results is implied through the use of established methods and comparisons with previous studies. The model's validity was tested by correlating predicted probabilities with the number of individuals correctly assigned to their genetic groups, showing strong, positive correlations. This suggests that the model's predictions are reliable and statistically significant.\n\nAdditionally, the model's performance was compared with other analytical approaches, such as Principal Component Analysis (PCA), which did not integrate genotype information and thus did not allow for the generation of autism-related profiles based on SCQ scores. This comparison highlights the superiority of the SVM approach in accurately classifying individuals into their genetic syndrome groups.\n\nThe sensitivity analysis, which included participants who met or scored above the suggested cutoff scores for Autism Spectrum Disorder (ASD) on the SCQ, generated comparable results to the initial analysis. This indicates that variation in SCQ scores did not influence the generation of the identified profiles, further supporting the robustness and statistical significance of the model's performance.\n\nIn summary, while specific confidence intervals for the performance metrics are not detailed, the use of established methods, comparisons with previous studies, and the consistency of results across different analyses suggest that the model's performance is statistically significant and reliable.",
  "evaluation/availability": "Not enough information is available."
}