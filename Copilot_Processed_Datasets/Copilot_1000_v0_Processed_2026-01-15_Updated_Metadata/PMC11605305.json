{
  "publication/title": "SIGMAP: an explainable artificial intelligence tool for SIGMA-1 receptor affinity prediction.",
  "publication/authors": "Lomuscio MC, Corriero N, Nanna V, Piccinno A, Saviano M, Lanzilotti R, Abate C, Alberga D, Mangiatordi GF",
  "publication/journal": "RSC medicinal chemistry",
  "publication/year": "2025",
  "publication/pmid": "39618965",
  "publication/pmcid": "PMC11605305",
  "publication/doi": "10.1039/d4md00722k",
  "publication/tags": "- Machine Learning\n- Drug Discovery\n- Classification Models\n- Model Validation\n- Fingerprinting\n- Support Vector Machines\n- Gradient Boosting\n- Extreme Gradient Boosting\n- Predictive Power\n- Sensitivity and Specificity\n- SHAP Analysis\n- Cross-Validation\n- Applicability Domain\n- Molecular Descriptors\n- Chemoinformatics",
  "dataset/provenance": "The dataset used in this study was sourced from ChEMBL version 33. Specifically, 2967 entries were extracted, all annotated exclusively with Ki values. The extraction was based on the target ID (CHEMBL4153) assigned to the S1R protein, with the guinea pig (Cavia porcellus) as the target organism. This approach was chosen to ensure the dataset was as extensive and homogeneous as possible. The guinea pig S1R is considered a valuable model for studying human S1R in preclinical research due to its high conservation among mammals, with a 93% amino acid sequence identity observed between human and guinea pig S1Rs.\n\nTo ensure data quality, a rigorous filtering process was implemented. Only entries marked as tested with a \"binding\" assay type, lacking any warnings in the 'data_validity_comment' field, and not indicating 'Not Determined' in the 'comment' field were retained. This refinement resulted in a dataset of 2896 compounds. The final curated dataset, referred to as SIGMA1-DB, comprises 2018 chemicals in SMILES format along with their corresponding experimental pKi mean values. This dataset was split into a training set (TS) and a validation set (VS) using a rational approach that maintained an equal proportion of compounds with high S1R affinity (S(+)) and low or absent S1R affinity (S(\u2212)). The TS includes 1615 compounds, while the VS includes 403 compounds.",
  "dataset/splits": "The dataset was split into two main parts: a training set (TS) and a validation set (VS). The training set comprises 1615 compounds, while the validation set includes 403 compounds. The split was done to maintain an equal proportion of compounds with high S1R affinity (S(+)) and low or absent S1R affinity (S(\u2212)) in both sets. Specifically, the training set contains 882 S(+) and 733 S(\u2212) compounds, and the validation set contains 220 S(+) and 183 S(\u2212) compounds. This split was achieved using the RDKit Diversity Picker node, which generates Morgan fingerprints for each SMILES string and selects the most diverse molecules based on the Tanimoto distance. The goal was to ensure structural variability across the datasets, which was illustrated using a t-distributed stochastic neighbor embedding (t-SNE) analysis based on nine physicochemical properties of the molecules.",
  "dataset/redundancy": "The dataset was split into a training set (TS) and a validation set (VS) using a rational approach. The RDKit Diversity Picker node was employed to generate Morgan fingerprints for each SMILES string, ensuring that the most diverse molecules were selected based on the Tanimoto distance. This method is known for its effectiveness in virtual screening procedures.\n\nThe dataset was divided into two classes: S(+) for chemicals with high S1R affinity and S(\u2212) for those with low or absent S1R affinity. The TS comprised 80% of the dataset, resulting in 1615 compounds, while the VS included the remaining 403 compounds. The split maintained an equal proportion of S(+) and S(\u2212) compounds in both sets, with 882 S(+) and 733 S(\u2212) in the TS, and 220 S(+) and 183 S(\u2212) in the VS.\n\nTo illustrate the structural variability, a t-distributed stochastic neighbor embedding (t-SNE) analysis was performed based on nine physicochemical properties of the molecules. These properties were calculated using the Canvas molecular descriptor node and then standardized. The score plot of the first two t-SNE dimensions showed the distribution of ligands in the resulting 2D chemical space, confirming the diversity and independence of the TS and VS.\n\nThe approach ensured that the training and validation sets were independent, with the VS representing a diverse subset of the overall dataset. This method aligns with best practices in machine learning to prevent data leakage and ensure robust model validation. The distribution of the dataset compares favorably with previously published machine learning datasets, emphasizing the importance of diversity and representativeness in chemical space.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. These include Random Forest (RF), K-Nearest Neighbors (KNN), Gradient Boosting (GB), Extreme Gradient Boosting (XGB), and Support Vector Machine (SVM). These algorithms are not new and have been extensively used in various applications, including drug discovery and cheminformatics.\n\nThe choice of these algorithms was driven by their proven effectiveness in handling complex datasets and their ability to provide robust predictive models. The algorithms were optimized using a 5-fold cross-validation approach, which involved splitting the dataset into training and validation sets multiple times to ensure the stability and generalizability of the models.\n\nThe decision to use these specific algorithms was based on their ability to handle different types of molecular fingerprints, such as AtomPair, Morgan, MACCS, Torsion, and CSFP. Each algorithm was tuned with different hyperparameters to identify the best-performing models. For instance, the number of trees, tree depth, learning rate, and other parameters were optimized to enhance the predictive power of the models.\n\nThe algorithms were implemented using the KNIME Analytics Platform, which provides a user-friendly interface for building and validating machine-learning models. The platform's flexibility allowed for the integration of various fingerprint types and the application of different machine-learning techniques.\n\nThe focus of this study was on the application of these algorithms to predict the affinity profile of S1R ligands, rather than on the development of new machine-learning algorithms. Therefore, the algorithms were chosen for their relevance to the specific problem at hand and their ability to provide reliable and interpretable results. The results demonstrated that SVM consistently yielded the highest specificity and Matthews correlation coefficient values, making it the top-performing algorithm among those considered.",
  "optimization/meta": "Not enough information is available.",
  "optimization/encoding": "In our study, we employed five different types of molecular fingerprints to encode the chemical structures represented by SMILES strings. These fingerprints were computed using the RDKit Fingerprint KNIME node and included Atom Pairs, Morgan, MACCS, and Torsion fingerprints. Additionally, we computed CSFP fingerprints using a Python script. Each fingerprint provided a binary representation indicating the presence or absence of specific molecular features.\n\nThe Atom Pairs fingerprint, consisting of 1024 bits, captures atomic environments and shortest path separations between atom pairs within the molecule. The Morgan fingerprint, also known as Extended-Connectivity Fingerprint (ECFP4), uses a radius of 2 and 1024 bits to encode circular substructures. The MACCS fingerprint, with 166 bits, is based on substructure keys and identifies the presence of specific molecular fragments. The Torsion fingerprint, comprising 1024 bits, is derived from topological torsion descriptors, which consider the spatial arrangement of atoms.\n\nFor the CSFP fingerprints, we followed the approach reported by Bajorath et al., where each chemical substructure is encoded by a binary vector indicating the presence or absence of particular characteristics. This method ensures a comprehensive representation of the molecular features.\n\nTo pre-process the data, we performed hyperparameter tuning using a 5-fold cross-validation (5-CV) to identify the optimal settings for each classification algorithm. For K-Nearest Neighbors (K-NN), we used a grid search to optimize two key parameters. For Random Forest (RF), Gradient Boosting (GB), Extreme Gradient Boosting (XGB), and Support Vector Machine (SVM), we employed Bayesian optimization to reduce computational costs and enhance performance. This rigorous tuning process ensured that each algorithm was configured to achieve the best possible performance with the given fingerprints.",
  "optimization/parameters": "In our study, we optimized various parameters for different machine learning algorithms to enhance their predictive power for SIGMA-1 receptor affinity. The number of parameters (p) varied depending on the algorithm used. For instance, the Random Forest (RF) algorithm had parameters such as the number of trees, tree depth, and the number of neighbors to consider. The Gradient Boosting (GB) algorithm included parameters like the number of boosting rounds, learning rate, and maximum tree depth. The Extreme Gradient Boosting (XGB) algorithm had parameters such as maximum depth, eta, and gamma. The Support Vector Machine (SVM) algorithm included parameters like the kernel type, nu, and gamma. The K-Nearest Neighbors (KNN) algorithm had parameters such as the number of neighbors to consider and whether to weight neighbors by distance.\n\nThe selection of these parameters was based on a hyperparameter tuning process performed using 5-fold cross-validation (5-CV). This method involved splitting the data into five subsets, training the model on four subsets, and validating it on the remaining subset. This process was repeated five times, each time using a different subset for validation. The parameters that yielded the best performance metrics, such as accuracy, sensitivity, and specificity, were selected for each algorithm. This rigorous tuning process ensured that the models were optimized for the task of predicting SIGMA-1 receptor affinity, aligning with our goal of minimizing false positives in the early stages of drug discovery.",
  "optimization/features": "In our study, we utilized five different types of molecular fingerprints to represent each chemical in the dataset. These fingerprints served as the input features for our classification algorithms. The fingerprints computed were:\n\n* Atom pairs (1024 bits)\n* Morgan (radius 2, 1024 bits)\n* MACCS (166 bits)\n* Torsion (1024 bits)\n* CSFP (custom binary representations)\n\nEach fingerprint type captures different aspects of the molecular structure, providing a comprehensive set of features for our models. The total number of features (f) varies depending on the fingerprint type used, ranging from 166 to 1024 bits.\n\nFeature selection was not explicitly performed as a separate step. Instead, we evaluated the performance of different fingerprint types to identify the most effective representation for describing the chemicals in our dataset. This approach allowed us to indirectly select the most informative features by choosing the fingerprint type that yielded the best model performance.\n\nThe identification of the optimal fingerprint type was conducted using a 5-fold cross-validation (5-CV) procedure on the training set. This ensured that the feature selection process was performed using the training data only, maintaining the integrity of the validation and test sets.",
  "optimization/fitting": "In our study, we employed five different classification algorithms: Random Forest (RF), K-Nearest Neighbors (K-NN), Gradient Boosting (GB), Extreme Gradient Boosting (XGB), and Support Vector Machine (SVM). Each algorithm was optimized using hyperparameter tuning performed on a 5-fold cross-validation (5-CV) to ensure robust performance and to avoid overfitting.\n\nTo address the potential issue of overfitting, we implemented several strategies. Firstly, we used cross-validation, which helps in assessing the model's performance on different subsets of the data. This technique ensures that the model generalizes well to unseen data. Secondly, we employed regularization techniques specific to each algorithm. For instance, in gradient boosting and XGB, we used parameters like lambda and alpha to control overfitting. For SVM, we used gamma and other kernel parameters to manage the model complexity. Additionally, we monitored the performance metrics across multiple iterations and ensured that the standard deviation of accuracy was below 0.02, indicating stability and reliability of the models.\n\nUnderfitting was addressed by carefully selecting and tuning the hyperparameters. For example, we varied the number of trees, tree depth, and learning rate in the ensemble methods to ensure that the models were complex enough to capture the underlying patterns in the data. We also used different types of fingerprints to represent the molecular structures, which provided a rich feature set for the models to learn from. The use of multiple fingerprints (AtomPair, Morgan, Torsion, MACCS, CSFP) ensured that the models had diverse and informative inputs, reducing the risk of underfitting.\n\nFurthermore, we prioritized specificity (SP) in the 5-fold cross-validation process, which is crucial for minimizing false positives in the early stages of drug discovery. This focus on SP helped in fine-tuning the models to be more discriminative, thereby avoiding underfitting. The models were also validated using an external dataset, which further confirmed their generalizability and robustness.\n\nIn summary, through careful hyperparameter tuning, use of regularization techniques, and validation on multiple datasets, we ensured that our models neither overfit nor underfit the data. The consistent performance across different validation steps and the low standard deviation in accuracy metrics support the reliability and generalizability of our models.",
  "optimization/regularization": "In our study, several regularization methods were employed to prevent overfitting and ensure the robustness of our models. One of the key techniques used was hyperparameter tuning, which involved optimizing various parameters for each model through a 5-fold cross-validation process. This approach helped in selecting the best parameters that generalized well to unseen data, thereby reducing the risk of overfitting.\n\nAdditionally, we utilized different algorithms that inherently include regularization techniques. For instance, the Support Vector Machine (SVM) algorithm with a Radial Basis Function (RBF) kernel includes regularization parameters such as gamma and lambda, which control the complexity of the model and help in preventing overfitting. Similarly, the Gradient Boosting (GB) and Extreme Gradient Boosting (XGB) algorithms incorporate regularization through parameters like gamma, lambda, and alpha, which regulate the model's complexity and prevent it from fitting the noise in the training data.\n\nFurthermore, the Random Forest (RF) and K-Nearest Neighbors (KNN) algorithms were also employed. In the case of RF, the use of different subsets of attributes for each tree and the control of tree depth helped in reducing overfitting. For KNN, the consideration of a specific number of neighbors and the weighting of neighbors by distance contributed to the model's robustness.\n\nOverall, these regularization techniques ensured that our models were not only accurate but also generalizable to new, unseen data, thereby minimizing the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available in the supplementary material. Specifically, the optimized parameters for each trained model, based on hyperparameter tuning performed on a 5-fold cross-validation, are detailed in Table S1. This table includes configurations for various algorithms such as Random Forest (RF), K-Nearest Neighbors (KNN), Gradient Boosting (GB), XGBoost (XGB), and Support Vector Machines (SVM). Each algorithm's parameters, such as the number of trees, tree depth, learning rate, and other relevant settings, are clearly listed.\n\nThe supplementary information is provided under the license of the Royal Society of Chemistry, ensuring that the data is accessible for further research and validation. This transparency allows other researchers to replicate our findings and build upon our work, fostering collaboration and advancement in the field. The supplementary material can be accessed through the journal's website, where it is made available to readers and researchers.",
  "model/interpretability": "The model developed in our study is not a black-box model. We have implemented explainable artificial intelligence (XAI) methods to enhance its transparency and interpretability. Specifically, we used two local post hoc XAI methods: Shapley Additive exPlanations (SHAP) and Contrastive Explanations.\n\nSHAP is a feature attribution-based method that explains black-box predictions by assigning each input feature a numerical value, called the Shapley value, indicating its contribution to the prediction. In our work, each molecule is described by one of the selected fingerprints, such as AtomPair, Morgan, Torsion, MACCS, or CSFP. The features correspond to the bits of the fingerprint, where each bit indicates the presence or absence of specific characteristics. SHAP quantifies the contribution of each molecular feature, with more positive or negative contributions indicating a stronger influence towards a positive or negative affinity prediction. This method offers a complete explanation by distributing the prediction value fractionally across all features.\n\nTo make the analysis actionable, we also implemented Contrastive Explanations. This method provides users with both similar and dissimilar (counterfactual) examples. Similar examples enhance the robustness of the classifier by confirming its stability within the chemical prediction space. Counterfactual examples, on the other hand, suggest small structural changes necessary to alter the prediction. This analysis was achieved by generating structural analogs of the input molecule using the same fingerprint but with different structural modifications.\n\nFor instance, compounds generated from a high-affinity binder (S(+)) are predicted positively by the model, while those generated from a low-affinity binder (S(\u2212)) are predicted negatively. These results demonstrate the model's stability and robustness in its predictions even when small structural modifications are made to the input molecule.\n\nIn summary, the model's interpretability is significantly enhanced through the use of SHAP and Contrastive Explanations, making it more transparent and trustworthy. These methods provide clear insights into how each feature contributes to the prediction and suggest actionable changes to improve the model's performance.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict whether a compound will have high affinity (S(+)) or low affinity (S(-)) for the sigma-1 receptor (S1R). The model uses various fingerprints to describe the molecular structures and employs different algorithms, with support vector machines (SVM) yielding the highest performance metrics. The output of the model includes several quality metrics such as sensitivity (SE), specificity (SP), accuracy (ACC), area under the curve (AUC), Matthews correlation coefficient (MCC), and positive likelihood ratio (+LR). These metrics indicate the model's ability to correctly classify compounds into high-affinity and low-affinity categories. The model's performance was validated using internal and external datasets, demonstrating its robustness and real-world applicability. Additionally, explainability methods like SHAP and Contrastive Explanations were implemented to provide insights into the model's predictions, making it more transparent and trustworthy.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the models developed in this study is not publicly released. However, the top-performing classifier, based on the SVM algorithm and Morgan fingerprints, is accessible through a freely available web platform named SIGMAP. This platform allows users to submit their query molecules either by drawing the 2D structure using the integrated JSME canvas applet or by inputting the SMILES string of the molecule. For batch processing, users can upload a text file containing a list of SMILES strings. The platform generates predictions regarding the affinity of each compound toward the S1R receptor, providing results as \"YES\" for high affinity and \"NO\" for no affinity. In cases of high affinity, a prediction confidence estimated by the KNIME predictor node is also provided. Additionally, the platform offers information on the reliability of the predictions based on the applicability domain of the model. For unique query molecules, SIGMAP provides SHAP and Contrastive Explanation-based analyses to offer insights into the structural changes necessary to modify the predictions.",
  "evaluation/method": "The evaluation of the developed models involved a comprehensive process to ensure their robustness and predictive power. Initially, a 5-fold cross-validation (5-CV) approach was employed to perform hyperparameter tuning and assess the models' ability to predict S1R affinity. This method involved splitting the dataset into five subsets, training the models on four subsets, and validating on the remaining one, repeating this process five times with different subsets. The metrics computed for each model were averaged across these five iterations to provide a stable and reliable evaluation.\n\nFollowing the 5-CV, all 25 developed classifiers underwent internal validation using a validation set (VS) obtained from the SIGMA1-DB split, comprising 403 compounds. This step confirmed the trends observed in the 5-CV procedure, with all models achieving high sensitivity (SE) and area under the curve (AUC) values. Notably, the gradient boosting (GB) algorithm demonstrated high AUC values when using both AtomPair and Torsion fingerprints.\n\nTo further validate the top-performing model, two external datasets (ES1 and ES2) were used. ES1 consisted of 46 compounds, and ES2 consisted of 39 compounds, both extracted from the ChEMBL database and other studies. The model successfully predicted a significant number of compounds in these external sets, further demonstrating its real-world applicability.\n\nAdditionally, an explainability analysis was conducted using SHAP (SHapley Additive exPlanations) to provide insights into the model's predictions. This analysis helped clarify how each bit of the fingerprint contributed to the output, enhancing the transparency and interpretability of the selected model.\n\nOverall, the evaluation process included rigorous cross-validation, internal and external validation, and explainability analysis to ensure the models' reliability and practical applicability in drug discovery.",
  "evaluation/measure": "In our study, we evaluated the performance of our models using a comprehensive set of metrics to ensure a thorough assessment of their predictive power. The primary metrics reported include sensitivity (SE), specificity (SP), accuracy (ACC), Matthews correlation coefficient (MCC), area under the ROC curve (AUC), negative likelihood ratio (\u2212LR), and positive likelihood ratio (+LR). These metrics provide a holistic view of the models' performance, covering various aspects of classification quality.\n\nSensitivity measures the proportion of true positives correctly identified by the model, while specificity assesses the proportion of true negatives. Accuracy gives an overall measure of correct predictions, including both true positives and true negatives. The Matthews correlation coefficient is particularly valuable as it considers all four categories of the confusion matrix, providing a balanced measure of classification performance. The AUC evaluates the model's ability to distinguish between positive and negative samples, with higher values indicating better performance. The likelihood ratios, both positive and negative, offer insights into how much the model's predictions increase or decrease the probability of a compound being in a particular class.\n\nThis set of metrics is representative of standard practices in the field of machine learning and drug discovery. It aligns with the metrics commonly reported in the literature, ensuring that our evaluation is both rigorous and comparable to other studies. By including a diverse range of metrics, we aim to provide a comprehensive understanding of our models' strengths and weaknesses, facilitating their application in real-world scenarios.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of various machine learning algorithms and molecular fingerprints to identify the most effective model for our study. We employed five classification algorithms: Random Forest (RF), K-Nearest Neighbors (K-NN), Gradient Boosting (GB), Extreme Gradient Boosting (XGB), and Support Vector Machine (SVM). Each algorithm was tested using five different types of molecular fingerprints: Atom Pairs, Morgan, MACCS, Torsion, and CSFP. This approach allowed us to assess the performance of different combinations of algorithms and fingerprints.\n\nTo ensure robustness, we performed hyperparameter tuning using grid search for K-NN and Bayesian optimization for RF, GB, XGB, and SVM. This process helped us identify the optimal settings for each algorithm, which were then used in a 5-fold cross-validation (5-CV) to evaluate performance. The metrics considered included sensitivity (SE), specificity (SP), accuracy (ACC), Matthews correlation coefficient (MCC), area under the ROC curve (AUC), negative likelihood ratio (\u2212LR), and positive likelihood ratio (+LR).\n\nOur results indicated that SVM consistently yielded the highest specificity values, ranging from 0.81 to 0.86, regardless of the fingerprint used. This suggests that SVM is particularly effective in minimizing false positives, which is crucial for the early stages of drug discovery. Additionally, SVM-based classifiers achieved the highest MCC values, further supporting their superior performance.\n\nTo select the top-performing model, we compared the quality metrics of all SVM-based classifiers. The model developed using the Morgan fingerprint outperformed the others, achieving high values for sensitivity (SE = 0.94), specificity (SP = 0.86), accuracy (ACC = 0.90), AUC (AUC = 0.90), MCC (MCC = 0.81), and positive likelihood ratio (+LR = 6.85). This model was chosen as the best-performing model due to its balanced and superior performance across multiple metrics.\n\nWe also conducted additional validation using two external datasets (ES1 and ES2) to evaluate the robustness of the top-performing model. The model successfully predicted 34 out of 46 compounds for ES1 and 27 out of 39 for ES2, demonstrating its real-world applicability.\n\nIn summary, our evaluation involved a thorough comparison of multiple algorithms and fingerprints, with a focus on minimizing false positives. The SVM algorithm, particularly when combined with the Morgan fingerprint, showed the best performance, making it the optimal choice for our study.",
  "evaluation/confidence": "The performance metrics presented in this study have been computed across multiple iterations to ensure stability and reliability. Specifically, the accuracy (ACC) of all models shows a standard deviation value below 0.02, indicating strong stability across different subsets of the test set used for validation. This consistency supports the robustness of the models' predictive power.\n\nTo evaluate the models' performance, several quality metrics were considered, including sensitivity (SE), specificity (SP), accuracy (ACC), Matthews correlation coefficient (MCC), and the area under the ROC curve (AUC). These metrics provide a comprehensive assessment of the models' ability to correctly classify compounds. The AUC, in particular, reflects the probability that positive compounds are ranked higher than decoys, with values ranging from 0 (miss-classifiers) to 1 (ideal-classifiers). The models consistently achieved high AUC values, often exceeding 0.80, which demonstrates their strong discriminative capability.\n\nThe positive likelihood ratio (+LR) and negative likelihood ratio (\u2212LR) were also computed to assess the informativeness of the classification models. A higher +LR value indicates a more informative model, as it increases the probability of a compound being correctly classified as positive relative to its initial probability. The models generated using the XGB and SVM algorithms, in particular, yielded interesting +LR scores, further supporting their effectiveness in minimizing false positives.\n\nThe statistical significance of the results was ensured through rigorous validation procedures. Internal validation was conducted using a validation set obtained from the SIGMA1-DB split, comprising 403 compounds. Additionally, external validation was performed using two datasets (ES1 and ES2) consisting of compounds not included in the training set. The model successfully predicted a significant number of compounds in these external datasets, further demonstrating its real-world applicability and robustness.\n\nIn summary, the performance metrics presented in this study are supported by multiple iterations and validation procedures, ensuring their reliability and statistical significance. The models' high AUC values and +LR scores, along with their consistent performance across different datasets, provide strong evidence of their superiority and effectiveness in the early stages of drug discovery.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. However, the software tool SIGMAP, which was employed in the evaluation process, is freely accessible in a GitHub repository. This repository contains the necessary resources for replicating the evaluation procedures described in our work. The availability of SIGMAP allows researchers to utilize the same methodologies and tools that we used, ensuring transparency and reproducibility in their own studies."
}