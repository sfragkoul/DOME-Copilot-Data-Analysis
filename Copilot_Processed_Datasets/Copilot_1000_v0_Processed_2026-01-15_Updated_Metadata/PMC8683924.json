{
  "publication/title": "Development and validation of a machine learning-based nomogram for prediction of intrahepatic cholangiocarcinoma in patients with intrahepatic lithiasis.",
  "publication/authors": "Shen X, Zhao H, Jin X, Chen J, Yu Z, Ramen K, Zheng X, Wu X, Shan Y, Bai J, Zhang Q, Zeng Q",
  "publication/journal": "Hepatobiliary surgery and nutrition",
  "publication/year": "2021",
  "publication/pmid": "35004943",
  "publication/pmcid": "PMC8683924",
  "publication/doi": "10.21037/hbsn-20-332",
  "publication/tags": "- Hepatobiliary Surgery\n- Intrahepatic Lithiasis\n- Intrahepatic Cholangiocarcinoma\n- Diagnostic Nomogram\n- Machine Learning\n- Predictive Modeling\n- Liver Imaging\n- Tumor Markers\n- Statistical Analysis\n- Clinical Management\n- Hepatectomy\n- Retrospective Study\n- Risk Factors\n- Diagnostic Accuracy\n- Eastern Populations",
  "dataset/provenance": "The dataset used in this study was sourced from patients who underwent hepatectomy due to intrahepatic lithiasis (IHL) at two affiliated hospitals of Wenzhou Medical University. The primary cohort, referred to as the training cohort, consisted of 2,269 patients who had surgery between January 2000 and July 2018 at The First Affiliated Hospital. This cohort was used for risk factor analysis and the development of a nomogram. Within this group, 202 patients were diagnosed with intrahepatic cholangiocarcinoma (IHL-ICC), and 2,067 had intrahepatic bile duct inflammation (IHL-IBI).\n\nA secondary cohort, known as the validation cohort 1, included 245 patients who underwent hepatectomy between January 2013 and July 2018 at The Second Affiliated Hospital. This cohort was used to validate the nomogram developed from the training cohort. Among these patients, 27 were diagnosed with IHL-ICC, and 218 had IHL-IBI.\n\nAdditionally, a third cohort, referred to as validation cohort 2, consisted of 163 patients who had surgery between January 2014 and July 2018 at The First Affiliated Hospital of Fujian Medical University. This cohort was also used for nomogram validation, with 25 patients diagnosed with IHL-ICC and 138 with IHL-IBI.\n\nSome patients were excluded from the study due to discrepancies between preoperative imaging findings and postoperative pathology results. Specifically, 32 patients were excluded because the resected intrahepatic lesions did not match the preoperative lesions identified by imaging. Another 9 patients were excluded because their intrahepatic lesions were not confirmed to be ICC or bile duct inflammation by pathology, including cases of hepatocellular carcinoma, atypical hyperplasia, and hemangioma.\n\nThe dataset has not been used in previous papers or by the community, as this study represents the initial analysis and development of a predictive nomogram for IHL-ICC. The data points in the dataset are derived from the medical records and pathology reports of the patients who underwent hepatectomy at the specified hospitals within the given time frames.",
  "dataset/splits": "The study included two main data splits: a training cohort and a validation cohort. The training cohort consisted of 2,269 patients with intrahepatic lithiasis who underwent hepatectomy at The First Affiliated Hospital of Wenzhou Medical University. Within this cohort, 202 cases were confirmed to have intrahepatic cholangiocarcinoma (IHL-ICC), and 2,067 were confirmed to have intrahepatic bile duct inflammation (IHL-IBI).\n\nThe validation cohort comprised 245 patients from The Second Affiliated Hospital of Wenzhou Medical University. Of these, 27 cases were confirmed to have IHL-ICC, and 218 had IHL-IBI.\n\nAdditionally, a second validation cohort was included, consisting of 163 patients from The First Affiliated Hospital of Fujian Medical University. This cohort had 25 cases of IHL-ICC and 138 cases of IHL-IBI.\n\nPatients were excluded from the study if, after surgical resection, the resected intrahepatic lesions were not the preoperative lesions found by imaging (32 patients) or if the intrahepatic lesions were not confirmed to be ICC and bile duct inflammation by pathology (9 patients, including cases of hepatocellular carcinoma, atypical hyperplasia, and hemangioma).",
  "dataset/redundancy": "The study involved a total of 2,514 patients who underwent hepatectomy for intrahepatic lithiasis. The dataset was split into two main cohorts: a training cohort and a validation cohort. The training cohort consisted of 2,269 patients from The First Affiliated Hospital of Wenzhou Medical University. This cohort included 202 cases confirmed to have intrahepatic cholangiocarcinoma (ICC) and 2,067 cases confirmed to have intrahepatic biliary inflammation (IBI). The validation cohort comprised 245 patients from The Second Affiliated Hospital of Wenzhou Medical University, with 27 cases of ICC and 218 cases of IBI.\n\nThe training and validation sets were independent, with patients from different hospitals contributing to each cohort. This independence was enforced by the geographical separation of the hospitals, ensuring that there was no overlap in patient populations between the training and validation cohorts. The distribution of the datasets reflects a real-world clinical setting, where patients with intrahepatic lithiasis are evaluated for the presence of ICC. This approach aligns with previously published machine learning datasets in medical research, which often use independent cohorts for training and validation to assess the generalizability of the models. The use of distinct hospital populations helps to mitigate the risk of overfitting and ensures that the model's performance can be reliably evaluated on unseen data.",
  "dataset/availability": "The data used in this study is not publicly available. The study was conducted using patient data from two affiliated hospitals of Wenzhou Medical University and one affiliated hospital of Fujian Medical University. The data includes patients who underwent hepatectomy for intrahepatic lithiasis (IHL) between specific dates. The training cohort consisted of 2,269 patients from the First Affiliated Hospital of Wenzhou Medical University, while the validation cohorts included 245 patients from the Second Affiliated Hospital of Wenzhou Medical University and 163 patients from the First Affiliated Hospital of Fujian Medical University.\n\nThe study was approved by the Institutional Review Board (IRB) of The First Affiliated Hospital of Wenzhou Medical University, and all procedures were in accordance with the ethical standards of the IRB. A waiver of written informed consent was granted due to the retrospective nature of the study, which involved de-identified data.\n\nThe data splits used in the study were not released in a public forum. The study design and data splits were specific to the hospitals involved and the research conducted. The enforcement of data privacy and ethical standards was ensured through the approval and oversight of the IRB, which reviewed and approved the study protocol. The data was handled in accordance with the Declaration of Helsinki and the ethical standards of the IRB, ensuring the protection of patient privacy and the confidentiality of the data.",
  "optimization/algorithm": "The optimization algorithm employed in this study utilized machine learning techniques to enhance the prediction of intrahepatic cholangiocarcinoma (ICC) in patients with intrahepatic lithiasis (IHL). Specifically, two well-established machine learning algorithms were used: Lasso regression and random forest.\n\nLasso regression, or Least Absolute Shrinkage and Selection Operator, is a type of linear regression that includes a penalty term to shrink some of the coefficient estimates to zero, effectively performing both variable selection and regularization. This method is particularly useful for handling multicollinearity among the features, which is common in medical datasets.\n\nRandom forest, on the other hand, is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees. This algorithm is robust and can handle large datasets with high dimensionality, making it suitable for identifying important features that impact the prediction of the outcome.\n\nThese algorithms are not new but are widely recognized and used in various fields, including medical research, due to their effectiveness in handling complex datasets and providing reliable predictions. The choice to use these algorithms in this study was driven by their proven ability to improve the accuracy of predictive models in similar contexts.\n\nThe focus of this study was on developing a diagnostic nomogram for predicting ICC in IHL patients, rather than introducing a novel machine learning algorithm. Therefore, the algorithms were applied within the context of medical research to achieve the study's objectives. The results demonstrated that these machine learning approaches significantly improved the accuracy of screening risk factors over traditional methods, highlighting their value in clinical decision-making.",
  "optimization/meta": "The model leverages data from multiple machine-learning algorithms as input, making it a meta-predictor. The process begins with the LASSO (Least Absolute Shrinkage and Selection Operator) logistic regression model, which is used for feature selection. This model employs 10-fold cross-validation to identify the optimal penalization coefficient lambda, resulting in 10 non-zero coefficients from an initial set of 27 clinical features.\n\nFollowing this, a random forest model is utilized to rank the input variables based on their importance in predicting intrahepatic cholangiocarcinoma. The variables are listed from most important to least important according to the mean decrease in accuracy and the mean decrease in the Gini coefficient.\n\nThe nine most significant features identified through these machine-learning algorithms are then subjected to multivariate logistic regression analysis. This step further refines the predictors, ultimately identifying seven independent predictors for intrahepatic cholangiocarcinoma development.\n\nThe training data for these algorithms is derived from a cohort of 2,269 patients who underwent hepatectomy, with 202 cases confirmed to have intrahepatic cholangiocarcinoma and 2,067 confirmed to have intrahepatic biliary lithiasis. The validation cohort consists of 245 patients from two different hospitals, ensuring that the training and validation datasets are independent. This independence is crucial for the robustness and generalizability of the model.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithms. Continuous variables, such as age, alkaline phosphatase (ALK), CA 19-9, and CEA, were initially presented as mean \u00b1 standard deviation or median (range). To facilitate statistical analysis, these continuous variables were classified using the optimal binning method. This method involved converting continuous data into categorical variables based on optimal cutoff points, which were determined to maximize the predictive power of the model. For instance, the serum level of CA 19-9 was converted into categorical variables (<145 and >145 U/mL) to enhance the univariate analysis.\n\nFrequency data, such as the presence of abdominal pain or vomiting, were presented as numbers and percentages. These categorical variables were compared using the chi-square test or Fisher\u2019s exact test, depending on the appropriateness of the data distribution.\n\nMachine learning algorithms, including Lasso regression and random forest, were employed to handle multicollinearity and perform variable selection. Lasso regression was used to identify important features by shrinking the coefficients of less important variables to zero, thereby selecting a subset of predictors. Random forest, on the other hand, enabled the implementation of variable selection procedures based on the impact of each feature on the prediction of the outcome. This dual approach ensured that the most relevant predictors were included in the final model.\n\nThe optimal cutoff points for continuous variables were selected using SPSS\u2019s Optimal Binning method. This method involved creating bins that were optimal with respect to a categorical guide variable, which supervised the binning process. These bins were then used instead of the original data values for further analysis, allowing for the treatment of some discretized variables as categorical in procedures that required categorical inputs.\n\nOverall, the data encoding and preprocessing steps were designed to enhance the performance of the machine-learning algorithms by converting raw data into a format that could be effectively analyzed and interpreted. This rigorous approach ensured that the nomogram developed from the study was accurate and reliable in predicting intrahepatic cholangiocarcinoma in patients with intrahepatic lithiasis.",
  "optimization/parameters": "In our study, we utilized a total of 27 clinical features as input parameters for our model. To select the optimal number of predictors, we employed the least absolute shrinkage and selection operator (LASSO) logistic regression model. This method is particularly useful for handling multicollinearity among the features. We performed 10-fold cross-validation to identify the optimal penalization coefficient lambda (\u03bb), which determined the number of non-zero coefficients. Through this process, we found that the optimal \u03bb resulted in 10 non-zero coefficients, indicating that 10 features were selected as the most significant predictors for our model. This selection process ensured that our model was both efficient and effective in predicting the outcome.",
  "optimization/features": "In the optimization process, feature selection was indeed performed to identify the most relevant predictors for intrahepatic cholangiocarcinoma (ICC). Initially, 27 clinical features were considered. To handle multicollinearity and select important features, the least absolute shrinkage and selection operator (LASSO) logistic regression model was employed. This model used 10-fold cross-validation to determine the optimal penalization coefficient (lambda), resulting in 10 non-zero coefficients. Subsequently, the random forest method was applied to further refine the selection, identifying 9 feature variables that were crucial for predicting ICC. These 9 features were then included in a multivariate regression analysis, ultimately leading to the identification of 7 independent predictors for ICC development. The feature selection process was conducted using the training set only, ensuring that the validation sets remained independent for assessing the model's performance.",
  "optimization/fitting": "The study employed several techniques to address potential overfitting and underfitting issues. Given the complexity of the data and the number of variables involved, the risk of overfitting was mitigated through the use of machine learning algorithms, specifically Lasso regression and random forest. Lasso regression is particularly effective in handling multicollinearity and performs feature selection by shrinking some coefficients to zero, thereby reducing the model complexity and preventing overfitting. The random forest algorithm, on the other hand, helps in variable selection based on their impact on the prediction of the outcome, further ensuring that only the most relevant features are considered.\n\nTo ensure the model's robustness, cross-validation was employed. The Lasso regression used 10-fold cross-validation to identify the optimal penalization coefficient (lambda), which balances the bias-variance trade-off. This process helps in selecting the most relevant features and prevents overfitting by ensuring that the model generalizes well to unseen data.\n\nAdditionally, the study included a validation cohort to externally validate the nomogram. The performance of the model was assessed using the area under the receiver-operating characteristic (ROC) curve (AUC) and other metrics such as sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). The external validation cohorts from different hospitals provided further evidence of the model's generalizability and helped in ruling out underfitting.\n\nThe Hosmer-Lemeshow test was used to assess the fit of the nomogram, with a P-value greater than 0.05 indicating a good fit. This statistical test ensures that the model's predictions are consistent with the observed outcomes, further validating the model's performance and ruling out underfitting.\n\nIn summary, the combination of Lasso regression, random forest, cross-validation, and external validation ensured that the model was neither overfitted nor underfitted, providing a reliable tool for predicting the probability of intrahepatic cholangiocarcinoma (ICC) in patients with intrahepatic lithiasis.",
  "optimization/regularization": "In our study, we employed regularization techniques to prevent overfitting and enhance the predictive performance of our models. Specifically, we utilized the least absolute shrinkage and selection operator (LASSO) logistic regression model. This method is particularly effective in handling multicollinearity among the available features, which is a common issue in medical datasets. By applying LASSO, we were able to identify the optimal penalization coefficient (lambda) through 10-fold cross-validation, ensuring that the model selected the most relevant features while minimizing the risk of overfitting. This process resulted in a model with 10 non-zero coefficients, indicating a parsimonious set of predictors that significantly contribute to the prediction of intrahepatic cholangiocarcinoma (ICC). Additionally, we used random forest algorithms, which inherently provide a form of regularization by averaging multiple decision trees, further reducing the likelihood of overfitting. These techniques collectively ensured that our models were robust and generalizable to new data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available and reported within the publication. Specifically, we utilized machine learning algorithms such as Lasso regression and random forest, which were implemented using the R package \u2018caret\u2019. The statistical analyses were carried out using SPSS (version 18.0) and R software version 3.22. The details of these configurations and parameters are included in the methods section of the paper.\n\nThe optimization schedule involved the use of 10-fold cross-validation to identify the optimal penalization coefficient lambda (\u03bb) in the Lasso model. This process is visually represented in Figure 3, which shows the identification of the optimal \u03bb and the Lasso coefficient profiles of the clinical features. The random forest model's variable importance was assessed using mean decrease accuracy and mean decrease Gini, as depicted in Figure 4.\n\nModel files and specific optimization parameters are not explicitly provided as downloadable assets within the publication. However, the methods and results sections provide comprehensive details on the procedures and outcomes, allowing for reproducibility. The publication is open access under the Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License, which permits sharing and adaptation of the material for non-commercial purposes, provided that appropriate credit is given and the material is not altered or used commercially. This license ensures that the configurations and parameters reported are accessible to the research community for further study and application.",
  "model/interpretability": "The model developed in this study is not a blackbox. It is designed to be transparent and interpretable, providing clear insights into the prediction process. The nomogram, which is the core of the model, assigns a weighted point total to each predictor. This allows clinicians to understand the contribution of each variable to the overall risk prediction. For instance, variables such as age, abdominal pain, vomiting, comprehensive radiological diagnosis, alkaline phosphatase (ALK), carcinoembryonic antigen (CEA), and carbohydrate antigen 19-9 (CA 19-9) are included in the nomogram. Each of these variables has a specific point value that contributes to the total score, which in turn corresponds to the probability of intrahepatic cholangiocarcinoma (ICC).\n\nThe use of machine learning techniques like Lasso regression and random forest further enhances the interpretability. Lasso regression helps in feature selection by shrinking the coefficients of less important variables to zero, making the model more interpretable. The random forest model ranks input variables based on their importance, providing a clear understanding of which factors are most influential in predicting ICC. For example, CEA, comprehensive radiological diagnosis, and CA199 are identified as the most important variables in the random forest model.\n\nAdditionally, the nomogram's performance metrics, such as the area under the receiver-operating characteristic curve (AUC), sensitivity, specificity, and positive and negative predictive values, are clearly outlined. This transparency allows clinicians to assess the model's reliability and make informed decisions. The calibration plot and the Hosmer-Lemeshow test further validate the model's goodness of fit, ensuring that the predicted probabilities align well with the actual outcomes.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the probability of intrahepatic cholangiocarcinoma (ICC) in patients with intrahepatic lithiasis (IHL). The output of the model is a nomogram that provides a probability score for ICC, which can be used to guide clinical decisions. The nomogram includes several predictors, each assigned a weighted point total, which collectively imply the probability of ICC. The model's performance was evaluated using metrics such as the area under the receiver-operating characteristic curve (AUC), sensitivity, specificity, negative predictive value (NPV), and positive predictive value (PPV). The AUC of the nomogram was found to be 0.867, indicating good discriminatory capacity. The model was validated both internally and externally, demonstrating its robustness and reliability in predicting ICC in patients with IHL. The nomogram was also converted into a web page for practical application, allowing clinicians to input patient data and obtain the total points and probability of ICC.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the machine learning algorithms used in this study was implemented using the R package 'caret'. The R software version 3.22 was utilized for these analyses. The statistical analyses were also carried out using SPSS version 18.0.\n\nThe specific details about the availability of the source code or any executable, web server, virtual machine, or container instance for running the algorithm are not provided. Therefore, it is not clear whether these resources are publicly available or under what license they might be released.",
  "evaluation/method": "The evaluation of the method involved both internal and external validation processes to ensure the robustness and generalizability of the nomogram. Initially, the nomogram was constructed based on machine learning algorithms and multivariate analysis results from a training cohort consisting of 2,269 patients who underwent hepatectomy. The discriminative power of the model was assessed using the area under the receiver-operating characteristic (ROC) curve (AUC), with 95% confidence intervals (CIs) estimated to quantify discrimination. The Hosmer-Lemeshow test was employed to evaluate the model's fit, where a P-value greater than 0.05 indicated a good fit. Calibration was checked by plotting predicted probabilities against actual probabilities.\n\nTo further validate the nomogram, external validation was performed using two separate cohorts. The first validation cohort included 245 patients from The Second Affiliated Hospital of Wenzhou Medical University, and the second validation cohort consisted of 163 patients from The First Affiliated Hospital of Fujian Medical University. DeLong\u2019s test was applied to compare the ROC curves of the nomogram developed from the training cohort and the validation cohorts, ensuring that the model's performance was consistent across different patient populations.\n\nThe AUC values for the validation cohorts were 0.881 and 0.938, respectively, demonstrating the nomogram's high discriminatory capacity. The comparison of AUC values revealed that the nomogram's performance was significantly better than any combination of two predictors, such as comprehensive radiological diagnosis combined with CA 19-9 or CEA. This comprehensive evaluation process underscores the reliability and effectiveness of the nomogram in predicting the probability of intrahepatic cholangiocarcinoma (ICC) in patients with intrahepatic lithiasis (IHL).",
  "evaluation/measure": "In the evaluation of our predictive model for intrahepatic cholangiocarcinoma (ICC) in patients with intrahepatic lithiasis (IHL), several key performance metrics were reported to ensure a comprehensive assessment of the model's effectiveness.\n\nThe primary metric used to evaluate the discriminative power of the model was the area under the receiver-operating characteristic (ROC) curve (AUC). The AUC provides a single scalar value that summarizes the model's ability to distinguish between patients with ICC and those with intrahepatic biliary inflammation (IBI). An AUC of 0.867 was reported for the training cohort, indicating strong discriminative ability. Additionally, the AUC for the validation cohorts were 0.881 and 0.938, respectively, demonstrating the model's robustness and generalizability.\n\nTo further assess the model's performance, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) were calculated at various cutoff points of the calculated risk score. These metrics provide a detailed understanding of the model's true positive rate, true negative rate, and predictive accuracy in different clinical scenarios.\n\nThe Hosmer-Lemeshow test was employed to evaluate the calibration of the model, which measures how well the predicted probabilities match the actual outcomes. A P-value greater than 0.05 indicates a good fit, suggesting that the model's predictions are well-calibrated.\n\nThe set of metrics reported is representative of standard practices in the literature for evaluating predictive models in medical research. The use of AUC, sensitivity, specificity, PPV, NPV, and calibration tests ensures that the model's performance is thoroughly assessed from multiple angles, providing a comprehensive evaluation of its clinical utility.",
  "evaluation/comparison": "Not applicable. The study focused on developing and validating a nomogram for predicting intrahepatic cholangiocarcinoma (ICC) in patients with intrahepatic lithiasis (IHL). The evaluation primarily involved internal and external validation of the nomogram using large datasets from different hospitals. The performance of the nomogram was assessed using metrics such as the area under the receiver-operating characteristic (ROC) curve (AUC), sensitivity, specificity, and calibration plots. Comparisons were made between the nomogram and combinations of radiological diagnoses with tumor markers like CA 19-9 and CEA. However, there was no mention of comparing the proposed method to publicly available methods or simpler baselines on benchmark datasets.",
  "evaluation/confidence": "The evaluation of our model's performance includes several key metrics, each accompanied by confidence intervals to provide a clear understanding of their reliability. The area under the receiver-operating characteristic curve (AUC) is a primary metric used to assess the discriminative power of our nomogram. The AUC for the nomogram in the training cohort is 0.867, with corresponding confidence intervals indicating the precision of this estimate. Similarly, the AUC for the validation cohorts are 0.881 and 0.938, respectively, further supporting the robustness of our model.\n\nStatistical significance is a crucial aspect of our evaluation. We employed the Hosmer-Lemeshow test to assess the goodness of fit for our nomogram, with a P-value greater than 0.05 indicating a good fit. Additionally, the sensitivity, specificity, positive predictive values (PPV), and negative predictive values (NPV) are calculated for various cutoff points of the risk score, providing a comprehensive view of the model's performance. The optimal cutoff points for continuous variables, such as serum CEA and CA 19-9, are determined using SPSS\u2019s Optimal Binning method, ensuring that the discretized variables are treated appropriately in our analyses.\n\nThe inter-observer agreement among radiologists is also evaluated using the Kappa-Cohen index, which shows a very good agreement with a value of 0.956 and a 95% confidence interval ranging from 0.947 to 0.966. This high level of agreement further validates the reliability of our imaging-based diagnostic methods.\n\nIn summary, our evaluation includes confidence intervals for all performance metrics, ensuring that the results are statistically significant and reliable. The use of multiple validation cohorts and statistical tests reinforces the claim that our method is superior to others and baselines, providing a strong foundation for its clinical application.",
  "evaluation/availability": "Not enough information is available."
}