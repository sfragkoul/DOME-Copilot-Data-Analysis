{
  "publication/title": "Epigenetic prediction of HIV frailty using ensemble learning of DNA methylation data",
  "publication/authors": "The authors who contributed to the article are as follows:\n\nXiaoying Zhang was responsible for the bioinformatics data processing and statistical analysis.\n\nYing Huang was involved in establishing the bioinformatics pipeline and analytical strategies.\n\nBeth E. Anderson contributed to the interpretation of findings and manuscript preparation.\n\nGang Peng was involved in the machine learning analysis.\n\nVincent C. Marconi, Michael J. Copenhaver, Thomas H. McCoy, and Kevin J. Black were involved in the manuscript preparation.\n\nHua Zhao contributed to the analytic strategy and manuscript preparation.\n\nJohn H. Krystal contributed to the interpretation of findings and manuscript preparation.\n\nAlicia C. White provided DNA samples and clinical data and contributed to the interpretation of findings and manuscript preparation.\n\nKe Xu was responsible for the study design, study protocol, sample preparation, data analysis, interpretation of findings, and manuscript preparation. All authors read and approved the final manuscript.",
  "publication/journal": "Clinical Epigenetics",
  "publication/year": "2018",
  "publication/pmid": "30545403",
  "publication/pmcid": "PMC6293604",
  "publication/doi": "https://doi.org/10.1186/s13148-018-0591-z",
  "publication/tags": "- Clinical Epigenetics\n- HIV Frailty\n- DNA Methylation\n- Machine Learning\n- Predictive Modeling\n- Veteran Aging Cohort Index\n- Tobacco Smoking\n- Epigenome-Wide Association Studies\n- Ensemble Learning\n- Biomarkers",
  "dataset/provenance": "The dataset utilized in this study is derived from genome-wide CpG sites, specifically focusing on DNA methylation markers. The primary dataset consists of 408,583 CpG sites, which were analyzed to predict HIV frailty using various machine learning methods.\n\nThe ensemble method selected a set of 698 CpGs that demonstrated the best performance in discriminating between poor and good prognosis. This set was validated in an independent sample, showing an area under the curve (AUC) of 0.78, indicating strong predictive efficiency.\n\nAdditionally, a penalized regression model, GLMNET, was used to select a smaller number of CpG sites from the same genome-wide dataset. GLMNET identified 1852 CpG sites, which also showed comparable predictive performance with an AUC of 0.76. However, the ensemble learning approach was more efficient in selecting a smaller number of features while maintaining high predictive accuracy.\n\nThe dataset has been used to validate the prediction of HIV frailty and all-cause mortality in HIV-infected individuals. The ensemble model built from the training set showed minimal overfitting and was successfully applied to differentiate good and poor HIV prognosis in independent samples. This suggests that the selected 698 CpGs are robust and biologically informative for predicting HIV outcomes.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "The datasets were split into two cohorts to ensure independence between the training and test sets. Cohort 1 was further subdivided into a training set and a test set with an 8:2 ratio. This split was done to build and validate the model within the same cohort before testing it on an independent cohort. The training set was used to develop the prediction model, while the test set within cohort 1 was used for initial validation through 10-fold cross-validation. To enforce independence, the model was then tested on cohort 2, which served as an entirely separate replication sample. This approach helped to minimize overfitting and ensured that the model's performance could be generalized to new, unseen data. The distribution of the datasets was designed to reflect real-world conditions, with a focus on high-dimensional data and the challenges of feature selection in the presence of noise and bias. This methodology aligns with best practices in machine learning for ensuring robust and reproducible results.",
  "dataset/availability": "The data associated with this publication is not publicly available in a forum. However, the article is distributed under the terms of the Creative Commons Attribution 4.0 International License. This license permits unrestricted use, distribution, and reproduction in any medium, provided appropriate credit is given to the original authors and the source. A link to the Creative Commons license must be provided, and any changes made should be indicated. The Creative Commons Public Domain Dedication waiver applies to the data made available in this article, unless otherwise stated. This means that the data can be freely used, but specific details about the data splits or enforcement of data release are not provided.",
  "optimization/algorithm": "The optimization algorithm employed in our study is based on ensemble learning, which is a class of machine-learning algorithms that combines the predictions from multiple models to improve overall performance. This approach is not new but has been widely recognized for its effectiveness in handling high-dimensional data and reducing overfitting.\n\nEnsemble learning was chosen because it allows for the integration of results from various machine-learning methods, such as GLMNET, SVM, RF, and XGBoost. By taking a weighted average of the predictions from these methods, we were able to optimize the selected features and limit the bias associated with any single method. This technique is particularly useful when dealing with unbalanced samples, as it typically improves the accuracy and stability of the model.\n\nThe decision to use ensemble learning in a clinical epigenetics study, rather than a machine-learning journal, is driven by the specific application and the nature of the data. The focus of our research is on linking molecular information, specifically DNA methylation, to clinical outcomes in HIV-infected individuals. Ensemble learning was selected for its ability to handle the complexities of epigenomic data, which includes a large number of features and potential noise. This approach enabled us to build a robust model that can predict HIV frailty and mortality more accurately.\n\nThe ensemble method demonstrated high reproducibility and better performance compared to individual machine-learning methods. For instance, the ensemble-based model selected a set of 698 CpGs that discriminated between poor and good prognosis with an area under the curve (AUC) of 0.73. This performance was validated in an independent sample, confirming the model's generalizability and minimal overfitting.\n\nIn summary, the optimization algorithm used in our study is ensemble learning, a well-established class of machine-learning algorithms. Its application in this context is justified by the need to handle high-dimensional epigenomic data and improve the prediction of clinical outcomes in HIV-infected individuals.",
  "optimization/meta": "The model employed in this study is indeed a meta-predictor, utilizing an ensemble learning approach. This method integrates the results from multiple machine learning algorithms to optimize feature selection and enhance model performance. The constituent machine learning methods include GLMNET, SVM, RF, and XGBoost. These algorithms were applied separately to build prediction models using various groups of CpG sites.\n\nTo ensure the robustness and generalizability of the model, the data was split into two cohorts. Cohort 1 was further subdivided into a training set and a test set with an 8:2 ratio. The training set was used to build the initial model, which was then validated through 10-fold cross-validation in the test set. The best-performing model from this process was subsequently tested in an independent replication set, which is cohort 2. This approach ensures that the training data is independent from the validation data, thereby reducing the risk of overfitting and enhancing the model's predictive accuracy. The ensemble method was constructed by weighing the vote of each CpG from the four machine learning methods, providing a more stable and accurate prediction model.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the quality and relevance of the input features. Initially, batch effects were removed using the removeBatchEffect function in limma with R to account for samples processed at different times and platforms. This step was crucial for maintaining consistency across the dataset.\n\nTo reduce redundant DNA methylation signals and noise, CpG sites with a false discovery rate (FDR) less than 0.5 from the epigenome-wide association study (EWAS) in cohort 1 were selected. This filtering process helped in focusing on the most informative features for predicting HIV frailty.\n\nThe samples in cohort 1 were then randomly divided into a training set and a test set with an 8:2 ratio. The training set was used to build the initial model, where each sample was labeled as either poor prognosis (VACS index > 50) or good prognosis (VACS index \u2264 50). The test set was employed to evaluate the model's performance through 10-fold cross-validation, ensuring that the best-performed model was identified and validated in an independent replication set.\n\nFor the machine learning process, a total of 997 CpGs from the EWAS (FDR < 0.1) were ranked based on their importance value using the GLMNET method. These CpG sites were then clustered into 21 groups, ranging from 2 to 997 sites with increments of 50 CpGs. This clustering approach allowed for a systematic evaluation of different feature sets.\n\nMultiple machine learning methods, including GLMNET, SVM, RF, and XGBoost, were applied separately to build prediction models using each CpG group. The parameters for these algorithms were fine-tuned using the R package caret to optimize performance. To mitigate the bias of individual methods, an ensemble learning approach was constructed using the caretEnsemble package. This ensemble method weighed the vote of each CpG from the four machine learning methods, enhancing the model's robustness and accuracy.\n\nThe ensemble-based model was evaluated using receiver operating characteristic (ROC) analysis in the test set. The best-performing features were further validated in the independent testing set (cohort 2) using the ensemble-based method. Sensitivity, specificity, and the area under the curve (AUC) were used to assess the model's performance, ensuring that it could effectively differentiate between good and poor HIV prognosis in independent samples.",
  "optimization/parameters": "In our study, we utilized an ensemble learning approach to select a set of 698 CpG sites as input parameters for our model. This selection was made to predict HIV frailty and other related outcomes. The choice of these 698 CpG sites was driven by their ability to discriminate between poor and good prognosis with the best performance, as validated through receiver operator characteristic curves and area under the curve (AUC) metrics.\n\nThe selection process involved several steps to ensure the robustness and relevance of the chosen features. Initially, epigenome CpGs were filtered based on their association with smoking, which is known to alter DNA methylation and is a significant factor in HIV-related mortality. This filtering step considerably reduced the number of features, focusing on those most likely to be informative.\n\nFollowing this, ensemble learning was applied, integrating results from multiple machine learning methods. This approach helped to optimize the selected features and mitigate the bias that can arise from using a single method. The ensemble method demonstrated high reproducibility and outperformed individual methods like GLMNET, which selected a larger number of CpG sites (1852) with comparable but less efficient performance.\n\nThe final set of 698 CpG sites was validated in an independent sample, showing an AUC of 0.78 and improved balanced accuracy, indicating minimal overfitting and strong predictive power. This set also included a majority of EWAS-significant CpGs, suggesting that the ensemble learning approach effectively selects biologically informative features.",
  "optimization/features": "In our study, we initially considered a large number of CpG sites as potential input features. To manage the high dimensionality of the data, we performed feature selection to identify informative features among the redundant or irrelevant data, background noise, and biased features.\n\nWe applied several approaches to guide the machine learning process. First, we filtered epigenome CpGs based on association analysis of DNA methylation sites with smoking. This step considerably reduced the number of features for model building. We rationalized using smoking-associated features because smoking alters DNA methylation, and smokers have higher mortality rates in the population when living with HIV.\n\nSecond, we employed ensemble learning based on the results of multiple machine learning methods to optimize the selected features and to limit the bias of each method. This data processing method typically improves the accuracy of the model when employing an unbalanced sample.\n\nThe ensemble method ultimately selected a set of 698 CpGs that discriminated poor and good prognosis with the best performance. Importantly, the majority of epigenome-wide association study (EWAS)-significant CpGs were included in the 698 CpGs, suggesting that ensemble learning enables the selection of biologically informative CpGs to predict HIV frailty.\n\nThe feature selection was performed using the training set only, ensuring that the selected features could be independently tested in a separate cohort. This approach helped us to select features with high accuracy to predict HIV outcomes.",
  "optimization/fitting": "The study employed several strategies to address the challenges of overfitting and underfitting in the context of high-dimensional data and predictive modeling.\n\nOverfitting is a significant concern when the number of parameters is much larger than the number of training points. To mitigate this, the sample was split into two cohorts. The first cohort was further subdivided into a training set and a test set with an 8:2 ratio. This division allowed for the model to be built and validated within the same cohort, reducing the risk of overfitting. Additionally, ensemble learning was utilized, which combines the results of multiple machine learning methods. This approach not only optimizes the selected features but also limits the bias of individual methods, thereby improving model stability and reducing overfitting.\n\nTo further validate the model's performance and ensure it generalizes well to new data, the best-performed model from the training set was tested in an independent replication set (cohort 2). The high area under the curve (AUC) and balanced accuracy in the replication set indicated that the model had minimal overfitting features and could effectively differentiate between good and poor HIV prognosis in independent samples.\n\nUnderfitting was addressed by using ensemble learning, which typically improves the accuracy of the model, especially when dealing with unbalanced samples. The ensemble method selected a set of 689 CpGs that discriminated poor and good prognosis with the best performance. The prediction efficiency was estimated using receiver operator characteristic curves, and the selected CpG set displayed a high AUC, suggesting that the model was not underfitting.\n\nMoreover, the study conducted a feature selection from a large number of CpG sites using GLMNET and compared it with the ensemble-based approach. Although GLMNET selected a larger number of CpG sites, the ensemble method was able to select a smaller number of features while maintaining comparable performance. This indicates that the ensemble method effectively balances the trade-off between bias and variance, avoiding both overfitting and underfitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our predictive models. One of the primary methods used was ensemble learning, which combines the results of multiple machine learning algorithms. This approach helps to optimize the selected features and mitigate the bias inherent in individual methods. Ensemble learning is particularly effective in handling unbalanced samples and improving model accuracy.\n\nAdditionally, we split our sample into two cohorts to address overfitting concerns. The first cohort was further subdivided into training and validation sets. This division allowed us to train our models on one subset and validate their performance on another, ensuring that the models generalized well to unseen data.\n\nAnother technique we utilized was feature selection based on the association of DNA methylation sites with smoking. By filtering epigenome CpGs in this manner, we significantly reduced the number of features, which helped in building more stable and less overfitted models.\n\nFurthermore, we conducted tenfold cross-validation for each CpG group, which provided a robust estimate of model performance and helped in identifying overfitting. The high sensitivity and relatively low specificity observed in the cross-validation process indicated the models' ability to generalize well to new data.\n\nOverall, these methods collectively contributed to the development of a reproducible and stable predictive model, minimizing the risk of overfitting and enhancing the reliability of our findings.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available. These details can be found in the supplementary materials accompanying the publication. Specifically, the configurations and parameters are provided in the additional files associated with the article.\n\nThe supplementary materials include several files that contain the necessary information for reproducibility. These files are distributed under the terms of the Creative Commons Attribution 4.0 International License. This license permits unrestricted use, distribution, and reproduction in any medium, provided that appropriate credit is given to the original authors and the source. A link to the Creative Commons license must also be provided, and any changes made to the materials should be indicated.\n\nThe supplementary files are accessible through the publication's online platform. Researchers and interested parties can download these files to review the hyper-parameter configurations and optimization parameters used in our study. This ensures transparency and allows others to replicate or build upon our work.",
  "model/interpretability": "The model employed in this study utilizes ensemble learning, which is often considered a black-box approach due to its complexity and the combination of multiple algorithms. However, the interpretability of the model is enhanced by the selection of a specific set of CpG sites. The ensemble method identified 698 CpGs that effectively discriminate between poor and good prognosis in HIV patients. This set includes a majority of EWAS-significant CpGs, indicating that the model is not entirely opaque. The inclusion of biologically informative CpGs suggests that the model's predictions are grounded in meaningful biological markers.\n\nThe performance of the model was validated using receiver operating characteristic curves, demonstrating an area under the curve (AUC) of 0.73 in the testing set and 0.78 in the replication sample. This consistency across different datasets indicates that the model generalizes well and is not overly fitted to the training data. The balanced accuracy of the model further supports its reliability.\n\nAdditionally, the study compared the ensemble method with individual machine learning techniques like RF and XGBoost, as well as a penalized regression model (GLMNET). While these methods showed high AUCs, the ensemble approach was able to select a smaller number of features, making it more efficient. The ensemble method also outperformed smoking status alone in predicting HIV frailty, highlighting the importance of DNA methylation markers.\n\nThe model's ability to predict all-cause mortality in HIV-infected individuals further validates its utility. The ensemble model's performance in predicting mortality supports the value of the selected 698-CpG set in assessing HIV outcomes. However, the model's performance in predicting resilient HIV-positive individuals was poor, likely due to an insufficient number of samples with excellent prognosis.\n\nIn summary, while the ensemble learning approach used in this study is complex and somewhat opaque, the selection of biologically relevant CpGs and the model's consistent performance across different datasets provide a level of interpretability. The model's ability to outperform individual methods and smoking status alone further supports its validity and usefulness in predicting HIV outcomes.",
  "model/output": "The model employed in this study is a classification model. It is designed to predict HIV frailty and mortality based on DNA methylation data. Specifically, the model uses an ensemble learning approach to select a set of 698 CpG sites that discriminate between poor and good prognosis in HIV-infected individuals. The performance of the model is evaluated using metrics such as the area under the curve (AUC) and balanced accuracy, which are typical for classification tasks. The model's predictions are validated in independent samples, demonstrating its ability to differentiate between high and low VACS index scores, which are indicative of HIV frailty. Additionally, the model's performance is compared to individual machine learning methods and smoking status alone, further confirming its classification capabilities.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its robustness and generalizability. Initially, the samples were divided into a training set and a test set with an 8:2 ratio. A model was built using the training set, where each sample was labeled as either poor prognosis (VACS index > 50) or good prognosis (VACS index \u2264 50). The model's performance was then assessed using 10-fold cross-validation within the training set. This process helped in identifying the best-performing model, which was subsequently tested on an independent replication set.\n\nTo further validate the prediction results, the selected 698 CpGs from the discovery sample were tested in a replication sample (cohort 2). The area under the curve (AUC) for this validation was found to be 0.78 (95% CI 0.73~0.83), indicating minimal overfitting and the model's ability to differentiate between good and poor HIV prognosis in independent samples.\n\nAdditionally, the performance of individual machine learning methods, such as GLMNET, SVM, RF, and XGBoost, was compared to the ensemble method. While these methods showed high AUCs, their balanced accuracy was not as good as that of the ensemble method. The ensemble approach, which combined the predictions from multiple machine learning methods, was able to select a smaller number of features and link smoking-DNA methylation to HIV outcomes more effectively.\n\nThe evaluation also included testing the model's ability to predict all-cause mortality in HIV-infected individuals. The ensemble model was used to assess the predictive value of the 698 CpG sites for mortality, further supporting the model's utility in predicting HIV outcomes.",
  "evaluation/measure": "In the evaluation of our models, we primarily focused on the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) as our key performance metric. The AUC provides a single scalar value that summarizes the performance of the model across all classification thresholds, making it a comprehensive measure of model performance.\n\nWe reported the AUC values for different models and datasets. For instance, in one of our analyses, the ensemble method achieved an AUC of 73% with a 95% confidence interval ranging from 63% to 83% for predicting high HIV frailty using a set of 698 CpGs. This metric was also used to evaluate the performance of individual machine learning methods like Random Forest (RF) and XGBoost, which showed high AUCs but did not match the balanced accuracy of the ensemble method.\n\nAdditionally, we validated our model in an independent sample set, where the AUC was 78% with a 95% confidence interval from 73% to 83%. This validation step was crucial to ensure that our model generalizes well to new, unseen data and does not suffer from overfitting.\n\nWe also compared the performance of our ensemble learning approach with other methods. For example, a penalized regression model (GLMNET) selected a larger number of CpG sites (1852) and achieved a comparable AUC of 76%. However, the ensemble method was more efficient in selecting a smaller number of features while maintaining high predictive performance.\n\nIn summary, the AUC was our primary performance metric, and it was used consistently across different models and datasets. This metric is widely recognized in the literature for evaluating classification models, particularly in the context of medical and biological research. The use of AUC, along with balanced accuracy and other relevant metrics, provides a robust evaluation of our models' performance.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of various machine learning methods to evaluate their performance in predicting HIV frailty using CpG sites. We clustered CpGs into groups ranging from 2 to 997, with increments of 50, and applied four different machine learning methods: GLMNET, SVM, RF, and XGBoost. Each method was used to build prediction models for these CpG groups, and their performances were assessed using tenfold cross-validation.\n\nThe individual methods showed high sensitivity but relatively low specificity. To enhance predictive performance, we employed an ensemble learning approach that combined the predictions from these four methods. This ensemble method demonstrated superior balanced accuracy compared to the individual methods, indicating its effectiveness in integrating diverse predictive signals.\n\nAdditionally, we compared the ensemble method to a simpler baseline, GLMNET, which selected a larger number of CpG sites (1852) with comparable performance (AUC of 0.76). However, the ensemble method was more efficient, selecting fewer features (698 CpGs) while maintaining high predictive accuracy. This comparison highlighted the advantage of ensemble learning in selecting biologically informative CpGs and improving prediction efficiency.\n\nFurthermore, we validated the ensemble model in an independent replication sample, achieving an AUC of 0.78 and a balanced accuracy of 0.76. This validation step confirmed the robustness of the ensemble model and its minimal overfitting, making it applicable to differentiate good and poor HIV prognosis in independent samples.\n\nIn summary, our evaluation involved a thorough comparison with both simpler baselines and more complex machine learning methods, demonstrating the superior performance and efficiency of the ensemble approach in predicting HIV frailty.",
  "evaluation/confidence": "The evaluation of our method includes performance metrics with confidence intervals, providing a range within which the true performance is likely to fall. For instance, the area under the curve (AUC) for predicting high HIV frailty using the selected 698 CpGs is reported with a 95% confidence interval (CI). In the testing set, the AUC is 0.73 with a 95% CI of 0.63 to 0.83. Similarly, in the replication sample, the AUC is 0.78 with a 95% CI of 0.73 to 0.83. These intervals indicate the precision of our estimates and the reliability of our results.\n\nStatistical significance is also considered in our evaluation. The p-values associated with the performance metrics and the selection of CpGs are provided, demonstrating that the results are not due to random chance. For example, the ensemble method's ability to select biologically informative CpGs is supported by the inclusion of a majority of EWAS-significant CpGs within the 698 CpGs, with a p-value indicating strong statistical significance.\n\nComparisons with other methods, such as RF and XGBoost, show that while these methods have high AUCs, their balanced accuracy is not as good as the ensemble method. This suggests that our ensemble approach is superior in terms of overall performance. Additionally, the ensemble method's ability to select a smaller number of features compared to GLMNET, while maintaining comparable performance, further supports its superiority.\n\nThe validation in an independent sample set also confirms the robustness of our model, with an improved balanced accuracy of 0.76. This indicates minimal overfitting and the generalizability of our method to different datasets. The statistical significance of these results strengthens the claim that our ensemble method is effective in predicting HIV frailty.",
  "evaluation/availability": "The raw evaluation files for this study are available for public access. These files include supplementary materials that provide detailed data and results supporting the main findings of the paper. The files are distributed under the Creative Commons Attribution 4.0 International License. This license allows for unrestricted use, distribution, and reproduction in any medium, provided that appropriate credit is given to the original authors and the source. Additionally, a link to the Creative Commons license must be included, and any changes made to the materials should be indicated. The data made available in this article is also covered by the Creative Commons Public Domain Dedication waiver, unless otherwise specified. This ensures that the data can be freely used and shared by the research community."
}