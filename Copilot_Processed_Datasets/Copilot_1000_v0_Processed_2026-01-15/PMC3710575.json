{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- Faezeh Hosseinzadeh\n- Amir Hossein KayvanJoo\n- Mansuor Ebrahimi\n- Bahram Goliaei\n\nMansuor Ebrahimi is the corresponding author. He is affiliated with the Department of Biology at Basic Science School & Bioinformatics Research Group, Green Research Center, University of Qom, Qom, Iran. The specific contributions of each author to the paper are not detailed.",
  "publication/journal": "Not applicable",
  "publication/year": "2013",
  "publication/pmid": "23888262",
  "publication/pmcid": "PMC3710575",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Support Vector Machines\n- Lung Cancer\n- Machine Learning\n- Feature Selection\n- Protein Attributes\n- Microarray Analysis\n- Classification\n- Prediction Models\n- Data Cleaning\n- Gene Expression",
  "dataset/provenance": "The dataset used in this study was derived from gene symbols defined by microarray analysis in the GSEA database. The genes associated with two types of lung tumors, as well as those common between them, were obtained from this database. The dataset initially consisted of 114 records, with 59 classified as SCLC, 30 as NSCLC, and 25 as COMMON tumor classes. Each record had 1497 features computed. After removing duplicate, useless, and correlated attributes, the number of protein features for each record was reduced to 1089, resulting in a cleaned dataset named the Final Cleaned database (FCdb). This dataset was used in previous work to classify lung tumors based on important protein features using feature selection, tree induction, and clustering models. The same datasets were utilized in this experiment to introduce accurate prediction tools for lung cancer types based on important attributes of related proteins.",
  "dataset/splits": "The dataset was divided into 10 parts. For each iteration of the validation process, 9 parts were used as the training set, and the remaining part was used as the testing set. This procedure was repeated for 12 different testing sets, each derived from various attribute weighting models. These models included Information gain, Information gain ratio, Rule, Deviation, Chi Squared, Gini index, Uncertainty, Relief, SVM, PCA, SAM, and Maximum Relevance. The distribution of data points in each split was not explicitly detailed, but the dataset initially consisted of 59 records classified as SCLC, 30 records as NSCLC, and 25 records as COMMON tumor classes. After data cleaning, each record had 1089 features.",
  "dataset/redundancy": "The datasets were divided into 10 parts, with 9 parts used as the training set and the last part as the testing set. This approach ensures that the training and test sets are independent, as the data used for testing was not part of the training process. This method helps to prevent overfitting and provides a more reliable evaluation of the model's performance.\n\nTo further validate the models and prevent overfitting, cross-validation techniques were employed. Specifically, X-validation and X-wrapper validation methods were applied, and the procedure was repeated for 12 different testing sets derived from various attribute weighting models. These models included Information Gain, Information Gain Ratio, Rule, Deviation, Chi Squared, Gini Index, Uncertainty, Relief, SVM, PCA, SAM, and Maximum Relevance. The average accuracies and Kappa indices were then computed to assess the performance of the models.\n\nThe distribution of the datasets used in this study compares favorably with previously published machine learning datasets. The use of multiple attribute weighting models and cross-validation techniques ensures that the results are robust and generalizable. This approach helps to mitigate the risk of dataset redundancy and ensures that the models are trained and tested on diverse and representative data.",
  "dataset/availability": "The datasets used in this study are derived from the Gene Set Enrichment Analysis (GSEA) database, specifically focusing on the overrepresented genes in various types of lung tumors. This database is well-known for storing the results of experimental microarray analyses and is part of the Molecular Signatures Database (MSigDB), which is a collection of annotated gene sets used with GSEA software.\n\nThe main dataset, referred to as FCdb, was transformed into a suitable format for Support Vector Machine (SVM) analysis and scaled using grid search to ensure that attributes in greater numeric ranges did not dominate those in smaller ranges. This process helped in finding the optimal values for the operator parameters.\n\nThe dataset was divided into 10 parts, with 9 parts used as the training set and the last part as the testing set. This division was repeated for 12 different testing sets, including Information Gain, Information Gain Ratio, Rule, Deviation, Chi-Squared, Gini Index, Uncertainty, Relief, SVM, PCA, SAM, and Maximum Relevance. The average accuracies and Kappa indices were then computed to evaluate the performance of the models.\n\nThe datasets and the methods used for their preparation and analysis are described in detail within the publication, ensuring reproducibility. However, the specific datasets and their splits are not explicitly released in a public forum. The focus is on the methods and the results obtained from these datasets, rather than the raw data itself.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study primarily involves Support Vector Machines (SVM) and Artificial Neural Networks (ANN). These are well-established classes of algorithms in the field of machine learning, known for their effectiveness in classification and prediction tasks.\n\nThe specific SVM models employed include SVM, SVM Linear, SVM Lib, SVM Evolutionary, SVM PSO, SVM Fast, and SVM Hyper. These models are not entirely new but represent various implementations and optimizations of the SVM algorithm. The SVM Linear model, for instance, is noted for its efficiency in handling large datasets, while the SVM Evolutionary and SVM PSO models incorporate evolutionary algorithms and particle swarm optimization, respectively, to enhance performance.\n\nThe ANN models used are Auto MLp (Multilayer Perceptron), Neural Net, and Perceptron. These are also established algorithms in the field of neural networks. The Multilayer Perceptron is a feedforward artificial neural network model that maps sets of input data onto a set of appropriate outputs. The Perceptron, on the other hand, is a type of linear classifier used for supervised classification of inputs into one of two possible outputs.\n\nRegarding the publication venue, the focus of this study is on the application of these machine-learning algorithms to predict and detect types of lung tumors based on protein features. The novelty lies in the specific application and the combination of feature selection techniques with these algorithms, rather than in the algorithms themselves. Therefore, it is published in a domain-specific journal rather than a general machine-learning journal. The findings highlight the potential use of these algorithms in medical diagnostics, specifically in determining lung cancer tumors, which is the primary contribution of this work.",
  "optimization/meta": "The study employed a meta-predictor approach, integrating multiple machine learning models to enhance the prediction of lung tumor types. This meta-predictor utilized data derived from various machine learning algorithms as input. Specifically, the models included Support Vector Machines (SVM), Artificial Neural Networks (ANN), and Na\u00efve Bayes classifiers.\n\nThe SVM models used encompassed several variants, such as LibSVM, SVM Linear, SVM Evolutionary, SVM PSO, SVM Fast Large Margin, and SVM Hyper Hyper. These models were applied to 13 datasets, including the main dataset and those derived from attribute weighting methods like Information Gain, Information Gain Ratio, Rule, Deviation, Chi Squared, Gini Index, Uncertainty, Relief, SVM, PCA, SAM, and Maximum Relevance.\n\nFor the ANN models, three types were employed: Auto MLp, Neural Net, and Perceptron. The Neural Net model demonstrated the highest accuracy when applied to the SVM dataset, outperforming the other ANN models. The Na\u00efve Bayes classifiers included both the standard Na\u00efve Bayes and Na\u00efve Bayes Kernel models, with the standard Na\u00efve Bayes showing better performance.\n\nThe training data for these models was prepared from proteins involved in lung tumors, obtained from microarray analysis in the GSEA database. The dataset underwent cleaning to remove duplicate, useless, and correlated attributes, resulting in a final cleaned database with 1089 features. Feature selection was performed using twelve attribute weighting models, identifying important protein features.\n\nValidation methods, including X-validation and X-wrapper validation, were applied to prevent overfitting. The datasets were divided into training and testing sets, with the performance of the models evaluated using accuracy and Kappa indices. The results indicated that the Neural Net model running on the SVM dataset achieved the best accuracy, highlighting the effectiveness of combining machine learning algorithms for predicting lung cancer types.",
  "optimization/encoding": "The data encoding and preprocessing involved several steps to prepare the protein attributes for machine learning algorithms. Initially, proteins associated with two types of lung tumors were obtained from gene symbols defined by microarray analysis in the GSEA database, using the DAVID server. The original dataset consisted of 114 records, with 59 classified as SCLC, 30 as NSCLC, and 25 as COMMON tumor classes. For each record, 1497 features were computed.\n\nData cleaning was performed to remove duplicate, useless, and correlated attributes. This process reduced the number of protein features for each record to 1089, which is less than 28% of the original features. This cleaned dataset was named the Final Cleaned database (FCdb).\n\nFeature selection was conducted using twelve attribute weighting models, which assigned each feature a weight between 0 and 1. Features with weight values higher than 0.50, as determined by at least 50% of the weighting algorithms, were considered important protein features. The most important protein attributes were selected by more than 50% of the attribute weighting algorithms, including Information gain, Information gain ratio, Rule, Deviation, Chi Squared, Gini index, Uncertainty, Relief, SVM, and PCA.\n\nThe datasets were then scaled using grid search to avoid attributes in greater numeric ranges dominating those in smaller numeric ranges. This scaling helped in finding the optimal values for the operator parameters. The main database (FCdb) was transformed into SVM format, and the dataset was divided into 10 parts. Nine parts were used as the training set, and the last part was used as the testing set. This process was repeated for 12 different testing sets derived from various attribute weighting models, and the average accuracies and Kappa indices were computed.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the specific machine learning algorithm and the dataset employed. Initially, each record in the dataset contained 1497 features. However, after data cleaning to remove duplicate, useless, and correlated attributes, the number of features was reduced to 1089. This cleaned dataset was named the Final Cleaned database (FCdb).\n\nFeature selection was then performed using twelve attribute weighting models, which assigned a weight between 0 and 1 to each feature. Features with weight values higher than 0.50, as determined by at least 50% of the weighting algorithms, were considered important. This process helped in selecting the most relevant features for the prediction models.\n\nFor the Support Vector Machine (SVM) models, specific parameters such as Gamma and C were set to 0.0065 and 10, respectively. These parameters were chosen based on grid search methods to optimize the performance of the SVM models. The datasets used for training and testing the models included the main dataset (FCdb) and 12 additional datasets derived from various attribute weighting algorithms.\n\nThe selection of parameters was crucial for improving the accuracy and efficiency of the lung cancer detection models. By focusing on the most important features and optimizing the parameters, we aimed to enhance the predictive power of the models. The use of feature selection and attribute weighting not only reduced the dimensionality of the data but also improved the overall performance of the classification and prediction tasks.",
  "optimization/features": "In our study, we initially computed 1497 features for each protein record. However, through a data cleaning process, we removed duplicate, useless, and correlated attributes, reducing the number of features to 1089. This cleaned dataset is referred to as the Final Cleaned database (FCdb).\n\nFeature selection was indeed performed using twelve different attribute weighting models. These models assigned a weight between 0 and 1 to each feature. Features that received a weight higher than 0.50 from at least 50% of the weighting algorithms were considered important protein features. This process helped in identifying the most relevant features for distinguishing between different types of lung tumors.\n\nThe feature selection was conducted using the training set only, ensuring that the model's performance on unseen data was not compromised. This approach helped in improving the accuracy and efficiency of lung cancer detection by focusing on the most informative features.",
  "optimization/fitting": "In our study, we employed several strategies to address potential over-fitting and under-fitting issues. The dataset was divided into 10 parts, with 9 parts used for training and the last part reserved for testing. This approach helps to ensure that the model generalizes well to unseen data.\n\nTo prevent over-fitting, we utilized X-validation and X-wrapper validation methods. These techniques involve splitting the training data into multiple subsets and training the model on different combinations of these subsets. This process was repeated for 12 different testing sets, each derived from various attribute weighting methods such as Information Gain, Chi-Squared, and Relief. By averaging the accuracies and Kappa indices across these multiple runs, we obtained a more robust estimate of the model's performance.\n\nAdditionally, we applied the kernel trick in support vector machines (SVMs) to handle non-linear classification tasks. This method implicitly maps inputs into high-dimensional feature spaces, allowing the algorithm to fit the maximum-margin hyperplane in a transformed feature space. This approach helps to capture complex patterns in the data without explicitly computing the mapping, thereby reducing the risk of over-fitting.\n\nTo address under-fitting, we employed multiple machine learning models, including various SVM algorithms, artificial neural networks (ANNs), and Na\u00efve Bayes classifiers. Each model was evaluated on different datasets derived from attribute weighting methods. This comprehensive evaluation ensured that we selected the most appropriate model for predicting lung tumor types based on structural and physicochemical descriptors of proteins.\n\nFurthermore, we used feature selection techniques to identify the most important protein attributes. This step not only reduced the dimensionality of the data but also improved the model's accuracy and efficiency. The selected features, such as dipeptide composition and Moran autocorrelation, were crucial in distinguishing between different types of lung tumors.\n\nIn summary, by using cross-validation techniques, the kernel trick in SVMs, multiple machine learning models, and feature selection, we effectively managed to mitigate both over-fitting and under-fitting issues, ensuring reliable and accurate predictions.",
  "optimization/regularization": "To prevent over-fitting problems, cross-validation and wrapper validation methods were applied. The procedure was repeated for 12 different testing sets, including Information gain, Information gain ratio, Rule, Deviation, Chi Squared, Gini index, Uncertainty, Relief, SVM, PCA, SAM, and Maximum Relevance. The average of accuracies and Kappa indices was then computed. These techniques ensured that the models generalized well to unseen data, maintaining robust performance across various validation strategies.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the provided information. However, it is mentioned that grid search was employed to scale the datasets and find optimal values for operator parameters. This suggests a systematic approach to hyper-parameter tuning, although the specific configurations are not reported.\n\nThe optimization schedule and model files are also not explicitly mentioned. The study focuses on the application of various machine learning models, including different types of support vector machines (SVM), artificial neural networks (ANN), and Na\u00efve Bayes (NB), but does not provide detailed information on the optimization schedule or the availability of model files.\n\nRegarding the availability and licensing of the configurations and parameters, there is no information provided about where these details can be accessed or under what license they might be available. The study primarily reports on the performance of different models and validation methods, rather than the specifics of the optimization process or the availability of related files.\n\nIn summary, while the study provides insights into the performance of various machine learning models for predicting lung tumor types, it does not offer detailed information on the hyper-parameter configurations, optimization schedule, model files, or their availability and licensing.",
  "model/interpretability": "The models employed in this study encompass a mix of both black-box and transparent approaches. The Support Vector Machine (SVM) models, particularly those with complex kernels like SVM Evolutionary, SVM PSO, and SVM Hyper, tend to be more opaque, functioning as black-box models. These models, while powerful in prediction, do not readily offer insights into the decision-making process.\n\nIn contrast, the Artificial Neural Network (ANN) models, specifically the Neural Net and Perceptron, provide a degree of transparency. The Neural Net model, for instance, can be interpreted by examining the weights assigned to different input features. These weights indicate the importance of each feature in the prediction process, allowing for a clearer understanding of which structural and physicochemical attributes of proteins are most influential in detecting lung tumors.\n\nAdditionally, the Na\u00efve Bayes models offer a high level of interpretability. These models are based on probabilistic classifications, assuming independence between features. The probabilities assigned to each feature given a class provide a straightforward interpretation of how the model makes predictions. This transparency is beneficial for understanding the contributions of individual protein attributes to the classification of lung tumors.\n\nThe use of attribute weighting models, such as Information Gain, Relief, and Rule, further enhances the interpretability of the results. These models help in selecting the most relevant features, which can then be analyzed to understand their significance in the context of lung cancer detection. For example, features like dipeptide composition, Moran autocorrelation, and distribution descriptors were identified as crucial, providing clear examples of how specific protein attributes contribute to the predictive models.\n\nOverall, while some models in this study are inherently black-box, the inclusion of transparent models like Neural Net and Na\u00efve Bayes, along with attribute weighting techniques, ensures that the decision-making process can be interpreted and understood. This balance between predictive power and interpretability is essential for the practical application of these models in medical diagnostics.",
  "model/output": "The model is primarily focused on classification tasks. We employed various machine learning algorithms, including artificial neural networks (ANN) and Na\u00efve Bayes classifiers, to predict the type of lung tumor based on protein attributes. The ANN models used were Auto MLp (multilayer perceptron), Neural Net, and Perceptron (Single-layer Neural Networks). These models were run on multiple datasets to evaluate their accuracy and Kappa values, which are metrics commonly used in classification problems. Additionally, we utilized different kernel types such as C-SCV, radial, and dot to find the best accuracy in classification tasks. The Na\u00efve Bayes classifiers, including models using estimated normal distributions and kernel densities, were also applied to classify the type of lung tumor. The results from these models indicate that the primary objective was to classify lung tumor types accurately.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "To evaluate the performance of our machine learning models, we employed two primary validation methods: X-validation and X-wrapper validation. These methods were applied to prevent overfitting problems and to ensure the robustness of our models. The dataset was divided into 10 parts, with 9 parts used as the training set and the last part as the testing set. This process was repeated for 12 different testing sets, each derived from various attribute weighting methods such as Information Gain, Information Gain Ratio, Rule, Deviation, Chi-Squared, Gini Index, Uncertainty, Relief, SVM, PCA, SAM, and Maximum Relevance.\n\nFor each testing set, we computed the average accuracies and Kappa indices. The performance evaluator operator was used for classification tasks where the label attribute had a binomial value type. For polynominal classification tasks, the Polynominal Classification Performance Evaluator (PCPE) operator was employed, and accuracy and Kappa statistics were calculated.\n\nThe evaluation showed that the SVM Hyper model had the worst performance, with accuracies even lower than chance models. In contrast, the SVM and SVM Linear models demonstrated the best performance, with accuracies reaching up to 82%. When comparing the two validation methods, X-validation generally performed better than X-wrapper validation, although X-wrapper validation showed superior results when applied to the SVM, SVM Linear, and SVM Fast models.\n\nThe best accuracies were achieved when X-validation was applied to datasets created from SVM attribute weighting. For X-wrapper validation, the datasets that performed best were those derived from Deviation, Relief, and Rule methods. These results suggest that either SVM or SVM Linear would be the best candidate algorithms for predicting lung cancer if applied to SVM datasets.\n\nAdditionally, we evaluated three artificial neural network (ANN) models: Auto MLp, Neural Net, and Perceptron. The Neural Net model showed the best performance and highest accuracy when applied to the SVM dataset. The Perceptron model had the worst performance, while the accuracies of Auto MLp and Perceptron models were relatively high and nearly at the same levels when applied to Information Gain and SVM datasets. The Kappa indices were generally lower, with the best index obtained from the Neural Net model.\n\nFor Na\u00efve Bayes models, the best accuracy and Kappa index were achieved when they were run on the Maximum Relevance dataset. The results confirmed that the Na\u00efve Bayes model was better than the Na\u00efve Bayes kernel model. Overall, the Neural Net model running on the SVM dataset achieved the best accuracy of 88%, demonstrating the potential use of feature selection and prediction models in determining the type of lung cancer tumors.",
  "evaluation/measure": "In our evaluation, we primarily focused on two key performance metrics: accuracy and the Kappa index. Accuracy is reported as a percentage, indicating the proportion of correctly classified instances out of the total instances. This metric provides a straightforward measure of how well our models perform in predicting lung cancer types.\n\nThe Kappa index, on the other hand, is a statistical measure that assesses the agreement between the predicted and actual classifications, while accounting for the possibility of chance agreement. This metric is particularly useful in evaluating the performance of classification models, especially when dealing with imbalanced datasets.\n\nThese metrics are widely used in the literature for evaluating machine learning models in bioinformatics and medical research. Accuracy gives a clear picture of the model's predictive power, while the Kappa index provides a more nuanced understanding by considering the agreement beyond what would be expected by chance.\n\nIn our study, we applied these metrics to various models, including Support Vector Machines (SVM), Artificial Neural Networks (ANN), and Na\u00efve Bayes (NB). The results showed that the Neural Net model, when applied to the SVM dataset, achieved the highest accuracy of 88%. The Kappa index also confirmed the superior performance of this model, with the best index obtained from the Neural Net model.\n\nOverall, the use of accuracy and the Kappa index provides a comprehensive evaluation of our models' performance, ensuring that our findings are robust and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of various machine learning models to predict and detect types of lung tumors based on structural and physicochemical attributes of proteins. We evaluated three main types of machine learning models: Support Vector Machines (SVM), Artificial Neural Networks (ANN), and Na\u00efve Bayes (NB).\n\nFor SVM, we employed seven different models, including SVM, LibSVM, SVM Linear, SVM Evolutionary, SVM PSO, SVM Fast Large Margin, and SVM Hyper. These models were applied to 13 datasets derived from attribute weighting methods. The performance was assessed using X-validation and wrapper validation techniques. The results indicated that SVM and SVM Linear models generally showed the best performance, with accuracies reaching up to 82%. The SVM Hyper model, however, performed the worst, even falling below the accuracy of chance models.\n\nIn the case of ANN, we used three models: Auto MLp, Neural Net, and Perceptron. The Neural Net model demonstrated the highest accuracy, particularly when applied to the SVM dataset, achieving an accuracy of 87.73%. The accuracies for the three ANN models ranged from 52% to 86%, 53% to 83%, and 31% to 59%, respectively. The Kappa index, which measures the agreement between predicted and observed classifications, was also evaluated. The Neural Net model showed the highest Kappa index, reaching up to 80%.\n\nFor Na\u00efve Bayes, we compared the performance of the Na\u00efve Base and Na\u00efve Base Kernel models. The results showed that the Na\u00efve Base model outperformed the Na\u00efve Base Kernel model, with the best accuracy and Kappa index obtained when run on the Maximum Relevance dataset, achieving 77%.\n\nOverall, our findings suggest that the Neural Net model, when applied to the SVM dataset, provided the best accuracy for predicting lung tumor types. This indicates the potential effectiveness of combining feature selection with machine learning algorithms for accurate lung cancer prediction. The study also highlighted the importance of attribute weighting in improving processing time and achieving more accurate results. The most significant protein features selected by the weighting tools were dipeptide composition, Moran autocorrelation, and distribution descriptors.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not enough information is available."
}