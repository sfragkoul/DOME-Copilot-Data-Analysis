{
  "publication/title": "Development of novel machine learning model for right ventricular quantification on echocardiography\u2014A multimodality validation study",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Echocardiography",
  "publication/year": "2020",
  "publication/pmid": "32396705",
  "publication/pmcid": "PMC7383774",
  "publication/doi": "https://doi.org/10.1111/echo.14674",
  "publication/tags": "- Echocardiography\n- Right Ventricular Function\n- Machine Learning\n- Deep Learning\n- Cardiac Magnetic Resonance\n- Tricuspid Annulus\n- Automated Segmentation\n- RV Dysfunction\n- Convolutional Neural Networks\n- Medical Imaging",
  "dataset/provenance": "The dataset used in this study was derived from echocardiographic images of patients undergoing right ventricular (RV) functional assessment. The specific number of data points is not explicitly stated, but the study involved 101 patients, equating to 7791 frames. These frames were used to evaluate tricuspid annular shortening indices for RV functional assessment via both manual and automated machine learning (ML) segmentation.\n\nThe dataset included a diverse population of patients, with nearly one-third (31%) exhibiting RV dysfunction, defined as a right ventricular ejection fraction (RVEF) of less than 50% as determined by cardiac magnetic resonance (CMR) imaging, which served as the reference standard.\n\nThe data utilized in this study has not been explicitly mentioned as being used in previous papers or by the community. However, the methods and models employed, such as the modified U-net architecture and residual modules, have been previously demonstrated to show excellent performance in medical segmentation tasks. The dataset was specifically curated for this study to assess the performance of the automated segmentation model in comparison to manual segmentation and conventional RV indices.",
  "dataset/splits": "The dataset was split using a sixfold cross-validation procedure. This means that the data was randomly divided into six non-overlapping subsets. For each iteration of the cross-validation, the model was trained on five of these subsets and tested on the remaining one. This process was repeated six times, with each subset serving as the test set once. Therefore, there were six data splits, and each split contained an approximately equal number of data points, ensuring a balanced distribution across all splits. This method was chosen to better demonstrate the model's performance under a size-constrained dataset.",
  "dataset/redundancy": "The dataset was split using a sixfold cross-validation procedure. This method involves randomly dividing the data into six non-overlapping subsets. The model was trained on five of these subsets and tested on the remaining one. This process was repeated six times, each time using a different subset as the test set. This approach ensures that each model instance is tested on data it has not seen during training, maintaining the independence of the training and test sets.\n\nTo minimize the risk of overfitting, the neural network architecture, hyperparameters, cross-validation groupings, and training protocols were not modified after the model was exposed to the cross-validation dataset. This strict protocol helps to ensure that the model's performance is generalizable and not merely a result of tuning to the specific dataset.\n\nThe use of cross-validation was chosen over a simple train-test split because it better demonstrates the true performance of the model under a size-constrained dataset. This method provides a more robust evaluation by ensuring that the model's performance is consistent across different subsets of the data.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in medical imaging. The dataset includes a diverse range of patients, with a focus on those with coronary artery disease risk factors. This diversity helps to ensure that the model is trained on a representative sample of the population, enhancing its applicability in real-world scenarios. The successful segmentation in all cases, with minimal processing time and no need for user editing, further supports the robustness of the dataset and the model's performance.",
  "dataset/availability": "Not applicable",
  "optimization/algorithm": "The machine-learning algorithm class used is a convolutional neural network, specifically a modified U-net architecture. This type of network is well-established in the field of medical image segmentation and has demonstrated excellent performance in various applications.\n\nThe algorithm is not entirely new; it builds upon the U-net architecture, which is widely recognized and used in medical segmentation tasks. The modifications include the incorporation of residual modules, which improve gradient flow between adjacent layers and enhance classification accuracy. These residual modules help in preventing issues like vanishing or exploding gradients, which are common in deep neural networks.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of the study is on its application in medical imaging, specifically for the automated quantification of right ventricular function using echocardiography. The primary goal was to validate the performance of this deep learning model in a clinical context, rather than to introduce a novel machine-learning algorithm. The study aims to demonstrate the practical utility of existing deep learning techniques in improving the efficiency and reliability of image interpretation in medical diagnostics.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the model could effectively learn from the input images. The images underwent random transformations such as zoom, rotation, cropping to 224x224 pixels, horizontal and vertical flipping, and the addition of Gaussian noise. These augmentations helped to make the model more robust and generalizable by exposing it to a variety of image variations.\n\nThe model utilized a modified U-net architecture, which is well-suited for medical segmentation tasks. This architecture includes residual modules that improve gradient flow between adjacent layers, enhancing classification accuracy. The use of residual modules helps to mitigate issues like vanishing gradients, which can be problematic in deep networks.\n\nA weighted softmax/cross-entropy loss function was employed during training to address class imbalance. The majority of pixels in each image were nonannular, so class weights were assigned empirically: 0.2 for the nonannular class and 0.8 for the annular class. This weighting scheme ensured that the model did not become biased towards the more frequent class.\n\nThe RMSProp optimizer was used to apply incremental parameter updates, which is effective for handling sparse gradients and adapting the learning rate for each parameter. This optimization technique helped in stabilizing and accelerating the training process.\n\nOverall, the preprocessing steps and the choice of architecture and loss function were carefully selected to enhance the model's performance and reliability in segmenting medical images.",
  "optimization/parameters": "The model utilized a modified U-net architecture, which is known for its effectiveness in medical segmentation tasks. This architecture incorporates residual modules to enhance gradient flow between layers, thereby improving classification accuracy.\n\nThe selection of parameters was carefully managed to prevent overfitting. This was achieved by adhering strictly to the cross-validation protocol, where the neural network architecture, hyperparameters, cross-validation groupings, and training protocols remained unchanged after initial exposure to the cross-validation dataset. This approach ensures that the model's performance is generalizable and not merely optimized for the specific dataset used during training.\n\nThe model was trained using a weighted softmax/cross-entropy loss function to address class imbalance, with specific weights assigned to different classes. The optimization process employed RMSProp for incremental parameter updates, which helps in stabilizing and accelerating the training process.\n\nThe training and testing were conducted on a robust workstation equipped with four CPU cores, 64 GB of system memory, and a high-performance GPU with 11 GB of video memory. This hardware setup facilitated efficient processing and ensured that the model could handle the computational demands of the training process.\n\nIn summary, the model's parameters were selected and optimized through a rigorous process that included the use of residual modules, a weighted loss function, and strict adherence to cross-validation protocols. This approach ensured that the model was both accurate and generalizable, capable of performing well on new, unseen data.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The model employed in this study is a modified U-net architecture, which is known for its efficiency in medical segmentation tasks. This architecture includes residual modules that enhance gradient flow between adjacent layers, thereby improving classification accuracy.\n\nTo address the potential issue of overfitting, given the size-constrained dataset, sixfold cross-validation was utilized. This method involves randomly splitting the data into nonoverlapping subsets, training the model on all but one subset, and testing it on the remaining subset. This process was repeated for each of the six holdout subsets, and the test metrics were averaged per-case for the entire dataset. Importantly, no modifications were made to the neural network architecture, hyperparameters, cross-validation groupings, or training protocols after the model was exposed to the cross-validation dataset. This strict protocol ensures that the model's performance is a true reflection of its generalizability rather than an artifact of overfitting.\n\nAdditionally, a weighted softmax/cross-entropy loss function was used to combat class imbalance, with empirical class weights assigned to the nonannular and annular classes. This approach helps in balancing the learning process and preventing the model from being biased towards the majority class.\n\nThe model was built using the deep learning framework PyTorch and trained on a workstation equipped with a powerful GPU, ensuring efficient computation and parameter updates via the RMSProp optimizer. The successful application of the model across all cases, with minimal processing time and no user editing required, further supports its robustness and generalizability.",
  "optimization/regularization": "To prevent overfitting, several techniques were employed during the development and training of our machine learning model. Firstly, we utilized sixfold cross-validation, which involves randomly splitting the data into nonoverlapping subsets. This ensures that the model is trained on different subsets of the data and tested on a separate subset, providing a more robust evaluation of its performance.\n\nAdditionally, we maintained the integrity of the model's architecture, hyperparameters, cross-validation groupings, and training protocols without any modifications after the model was exposed to the cross-validation dataset. This approach helps to ensure that the model's performance is generalizable and not merely a result of overfitting to the specific training data.\n\nThe model architecture itself includes residual modules, which are designed to improve gradient flow between adjacent layers. This feature helps in mitigating issues related to vanishing or exploding gradients, thereby enhancing the model's ability to learn effectively from the data.\n\nFurthermore, a weighted softmax/cross-entropy loss function was used to address class imbalance. By assigning different weights to the classes, the model is encouraged to pay more attention to the minority class, reducing the risk of overfitting to the majority class.\n\nOverall, these techniques collectively contribute to the robustness and generalizability of the model, ensuring that it performs well on unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are not explicitly detailed in the publication. However, the model architecture is based on a modified U-net, which incorporates residual modules to enhance gradient flow and classification accuracy. The training process employed a weighted softmax/cross-entropy loss function to address class imbalance, with specific class weights assigned to the nonannular and annular classes. RMSProp was utilized for incremental parameter updates.\n\nThe software code pertaining to both the training and testing of the machine learning model is available online. It can be accessed at the following GitHub repository: https://github.com/akbra tt/RVTra cker. This repository likely contains the necessary details for reproducing the experiments, including the hyper-parameter configurations and optimization parameters.\n\nThe model was built using the deep learning framework PyTorch and was trained and tested on a workstation equipped with four CPU cores, 64 GB of system memory, and a graphics-processing unit (GPU) with 11 GB of video memory (NVIDIA GTX 1080 Ti). This setup ensures that the computational resources are sufficient for handling the training and testing processes efficiently.\n\nFor those interested in utilizing or further developing the model, the provided GitHub repository serves as a valuable resource. It offers the opportunity to explore the implementation details, experiment with different hyper-parameter settings, and potentially improve the model's performance. The availability of the code aligns with the principles of reproducibility and transparency in scientific research, allowing other researchers to build upon the work presented in this study.",
  "model/interpretability": "The model developed in this study is not a blackbox, as it leverages a modified U-net architecture, which is a type of convolutional neural network known for its transparency and interpretability in medical image segmentation tasks. The U-net architecture is designed to capture both contextual and spatial information, making it easier to understand how the model processes input data.\n\nOne of the key features of the model is the use of residual modules. These modules help improve gradient flow between adjacent layers, which not only enhances classification accuracy but also makes the model more interpretable. By facilitating better gradient flow, residual modules allow for more straightforward backpropagation, enabling researchers to trace how changes in input data affect the output.\n\nAdditionally, the model's architecture includes contracting and expanding pathways with concatenation, which helps in preserving spatial information. This design choice aids in understanding how different parts of the input image contribute to the final segmentation output. The use of convolutional blocks and rectified linear units (ReLU) further enhances the model's interpretability by providing clear, step-by-step transformations of the input data.\n\nThe model's performance metrics, such as sensitivity, specificity, and accuracy, are well-documented and compared against manual segmentation and conventional indices. This transparency in evaluation allows for a clear understanding of the model's strengths and limitations. Furthermore, the use of cross-validation ensures that the model's performance is robust and generalizable, providing additional confidence in its interpretability.\n\nIn summary, the model's architecture and training procedures are designed to be transparent, making it possible to understand how input data is processed and how the final segmentation output is generated. This transparency is crucial for building trust in the model's predictions and for further refining its performance.",
  "model/output": "The model developed in this study is primarily focused on segmentation and tracking tasks, rather than traditional classification or regression. It is designed to automate the process of tracking the tricuspid annulus in echocardiographic images, which involves identifying and delineating the annulus in each frame. This process can be seen as a form of pixel-wise classification, where each pixel in an image is assigned a label indicating whether it belongs to the annulus or not.\n\nThe model outputs segmentation maps that highlight the tricuspid annulus, from which various indices are derived. These indices include linear tricuspid annular displacement (LTAD) and circumferential tricuspid annular displacement (CTAD), which quantify the motion of the annulus. These outputs are used to assess right ventricular function, providing measurements that can be compared to manual segmentation and conventional echocardiographic indices.\n\nThe model's architecture is based on a modified U-net, which is well-suited for biomedical image segmentation tasks. It employs residual modules to improve gradient flow and classification accuracy. The use of a weighted softmax/cross-entropy loss function helps to address class imbalance, ensuring that the model performs well even when the majority of pixels in an image do not belong to the annulus.\n\nIn summary, while the model's primary output is a segmentation map, the derived indices from this map can be used for both classification (e.g., detecting right ventricular dysfunction) and regression tasks (e.g., quantifying annular displacement). The model's performance is evaluated by comparing these automated indices to manual segmentation and established echocardiographic measures.",
  "model/duration": "The model demonstrated exceptional efficiency in processing time. For all cases, the segmentation via machine learning required less than one second. This rapid processing time is a significant advantage, as it allows for quick and efficient analysis without the need for additional user editing. The minimal processing time ensures that the model can be integrated into clinical workflows seamlessly, providing timely results for right ventricular functional assessment.",
  "model/availability": "The source code pertaining to both the training and testing of the machine learning model has been made publicly available. It can be accessed online at a specified GitHub repository. This allows other researchers and practitioners to reproduce the results, modify the code, or integrate it into their own projects. The repository contains the necessary scripts and instructions to run the algorithm, facilitating its use without the need for additional user editing. The availability of this code promotes transparency and encourages further development and validation of the model in different settings.",
  "evaluation/method": "The evaluation of the machine learning model involved a comprehensive approach to ensure its accuracy and reliability. The model was initially trained and tested using sixfold cross-validation. This method involved randomly splitting the data into six non-overlapping subsets, allowing the model to be trained on five subsets and tested on the remaining one. This process was repeated six times, with each subset serving as the test set once. The performance metrics were then averaged across all subsets to provide a robust evaluation of the model's performance.\n\nTo minimize the risk of overfitting, the neural network architecture, hyperparameters, cross-validation groupings, and training protocols were not modified after the model was exposed to the cross-validation dataset. This strict protocol ensured that the model's performance was generalizable and not merely optimized for the specific dataset used during training.\n\nThe model's performance was evaluated by comparing the values of maximal displacement obtained from the automated segmentation with those from manual segmentation. Additionally, measurements from the automated segmentation maps were compared to standard echocardiographic indices and right ventricular ejection fraction (RVEF) on cardiac magnetic resonance (CMR), which was defined as the reference standard for RV functional assessment.\n\nStatistical methods, including Student's t-test for continuous variables, Bland-Altman analysis for inter- and intra-observer agreement, and intra-class correlation coefficients, were used to evaluate the associations between variables. These methods provided a thorough assessment of the model's diagnostic performance and reproducibility. The model demonstrated high negative predictive value and good diagnostic performance in relation to the CMR reference, indicating its potential for efficient and reliable RV assessment.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report several key metrics to evaluate the effectiveness of our automated segmentation model. These metrics include the mean difference and limits of agreement between automated and manual segmentation methods, as assessed using the Bland-Altman method. This approach provides insights into the agreement between the two methods, with the limits of agreement indicating the range within which most differences between the methods lie.\n\nWe also report intra-class correlation coefficients (ICC) to measure the reliability and consistency of the automated segmentation compared to manual segmentation. The ICC values indicate the degree of agreement, with higher values suggesting better reliability.\n\nAdditionally, we present bivariate correlation coefficients to evaluate the strength and direction of the relationships between variables derived from the automated segmentation and those from manual segmentation or other reference standards.\n\nLinear regression equations are used to model the relationships between the automated measurements and the reference standards, providing a quantitative assessment of how well the automated method predicts the reference values.\n\nThese performance metrics are chosen to provide a comprehensive evaluation of the model's accuracy, reliability, and agreement with established methods. The use of Bland-Altman analysis, ICC, correlation coefficients, and regression equations aligns with standard practices in the literature for evaluating segmentation models in medical imaging. This set of metrics ensures that our model's performance is thoroughly assessed and comparable to other studies in the field.",
  "evaluation/comparison": "The evaluation of our model involved a comprehensive comparison with established methods to ensure its robustness and accuracy. We compared the values of maximal displacement obtained from our automated segmentation against manual segmentation. This comparison was crucial for validating the performance of our model.\n\nIn addition to manual segmentation, we also compared our automated segmentation maps with standard echocardiographic indices and right ventricular ejection fraction (RVEF) measurements obtained from cardiac magnetic resonance (CMR). CMR is widely regarded as the reference standard for assessing right ventricular function, providing a benchmark against which our model's performance could be evaluated.\n\nWe did not perform a comparison to publicly available methods on benchmark datasets, nor did we compare our approach to simpler baselines. Our focus was primarily on validating our model against manual segmentation and established clinical standards. This approach allowed us to demonstrate the clinical relevance and accuracy of our automated segmentation method in a real-world setting.",
  "evaluation/confidence": "The evaluation of our machine learning model included a comprehensive assessment of its performance metrics, which were accompanied by confidence intervals to provide a clear understanding of their reliability. For instance, the area under the curve (AUC) for different measurements such as lateral and septal tricuspid annular displacement (LTAD and CTAD) were reported with 95% confidence intervals. This approach ensures that the performance metrics are not just point estimates but are accompanied by a range within which the true value is likely to fall, adding a layer of statistical confidence to our results.\n\nStatistical significance was a key consideration in our evaluation. We used Student's t-test for continuous variables and the method of Bland and Altman to assess inter- and intra-observer agreement. The Bland-Altman method provided mean differences and limits of agreement, which are crucial for understanding the variability and bias between different measurement methods. Additionally, we employed bivariate correlation coefficients, intra-class correlation coefficients, and linear regression equations to evaluate associations between variables. These statistical methods helped us determine whether the differences observed were statistically significant and not due to random chance.\n\nThe p-values obtained from these tests were used to determine statistical significance, with a two-sided p-value of less than 0.05 considered indicative of statistical significance. This rigorous statistical approach allowed us to confidently claim that our machine learning model performs well in relation to manual echo indices for the detection of CMR-evidenced right ventricular (RV) dysfunction. The model's performance was systematically tested and validated, demonstrating its potential to improve image interpretation efficiency and reliability.",
  "evaluation/availability": "The software code pertaining to both the training and testing of the machine learning model is publicly available. It can be accessed online at the provided GitHub repository. This repository contains the necessary code to replicate the experiments and evaluate the model's performance. The availability of this code ensures transparency and allows other researchers to verify the results or build upon the work."
}