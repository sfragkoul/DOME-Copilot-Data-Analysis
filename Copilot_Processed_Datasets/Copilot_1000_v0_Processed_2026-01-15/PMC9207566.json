{
  "publication/title": "Association between type of bystander cardiopulmonary resuscitation and survival in out-of-hospital cardiac arrest: A machine learning study",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Resuscitation Plus",
  "publication/year": "2022",
  "publication/pmid": "35734307",
  "publication/pmcid": "PMC9207566",
  "publication/doi": "10.1016/j.resplu.2022.100245",
  "publication/tags": "- Cardiac arrest\n- OHCA\n- Compression only CPR\n- Survival\n- Bystander CPR\n- Machine learning\n- Propensity score\n- Emergency medical services\n- Cardiopulmonary resuscitation\n- Out-of-hospital cardiac arrest",
  "dataset/provenance": "The dataset used in this study is sourced from the Swedish Registry for Cardiopulmonary Resuscitation (SRCR). This registry recorded a total of 106,966 patients over the period from 1990 to 2019. However, after applying specific exclusion criteria\u2014such as removing patients under 18 and over 100 years of age, those enrolled before 2015 or after 2019, and ensuring they were treated with either standard CPR (S-CPR) or compression-only CPR (CO-CPR) before the arrival of emergency medical services (EMS)\u2014the study population was narrowed down to 13,481 patients.\n\nThis dataset has been utilized to provide insights into the characteristics and outcomes of patients who experienced cardiac arrest, focusing on the types of bystander CPR administered. The analysis included variables that could be assessed up until the arrival of EMS, aiming to identify the strongest predictors of survival upon EMS arrival. The study employed various statistical models and machine learning techniques to evaluate the relative importance of these predictors and to compare the effectiveness of S-CPR and CO-CPR in terms of 30-day survival.",
  "dataset/splits": "The study population consisted of 13,481 patients. The dataset was not explicitly split into multiple subsets for training, validation, or testing. Instead, the data was filtered based on specific criteria. Initially, 106,966 patients were recorded in the Swedish Registry for Cardiopulmonary Resuscitation (SRCR) during 1990\u20132019. After excluding patients under 18 and over 100 years of age, excluding patients enrolled before 2015 or after 2019, and requiring that they be treated with standard CPR (S-CPR) or compression-only CPR (CO-CPR) before the arrival of emergency medical services (EMS), the final study population was determined.\n\nThe groups consisted of 5,293 patients who received S-CPR and 8,188 patients who received CO-CPR. The mean age in the S-CPR group was 67.4 years, with 32.3% being women, and the most common location for cardiac arrest (CA) was at home (64.2%). In the CO-CPR group, the mean age was 69.5 years, with 34.2% being women, and the most common location for CA was also at home (74.1%). Heart disease was the most common etiology for CA in both groups. The percentage of patients with a CA during exercise was slightly higher in the S-CPR group. There were no considerable differences in time from CA to EMS arrival, time from CA to first defibrillation, or time from CA to alarm between the groups. Time from CA to CPR start was somewhat longer in the CO-CPR group. Dispatcher-assisted CPR (DA-CPR) was more frequent in the CO-CPR group (66.0% vs 51.9%). Defibrillation by bystanders was performed in 19.6% of the CO-CPR group and 35.6% of the S-CPR group.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to the class of supervised learning methods, specifically designed for classification tasks. The algorithms employed include Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks. These are well-established algorithms in the field of machine learning and are widely used for predictive modeling.\n\nThe algorithms used are not new; they are established methods in the machine learning community. The choice to use these algorithms was driven by their proven effectiveness in handling complex datasets and their ability to provide robust predictions. The study aimed to leverage the strengths of these algorithms to build accurate propensity score models for covariate adjustment and matching.\n\nThe decision to use these algorithms in a medical study rather than publishing them in a machine-learning journal is due to the specific application and context of the research. The focus of this study is on the medical implications of bystander CPR in out-of-hospital cardiac arrest (OHCA), rather than the development of new machine-learning algorithms. The algorithms were selected for their ability to handle the large and complex dataset efficiently, ensuring that the propensity scores were accurately calculated and balanced. This approach allowed for a rigorous analysis of the association between type of bystander CPR and survival in OHCA, which is the primary objective of the study.",
  "optimization/meta": "In our study, we employed a comprehensive approach to build propensity score models, utilizing a variety of machine-learning algorithms to ensure robustness and accuracy. We constructed 12,008 different models using several leading frameworks for prediction on structured data, including Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks.\n\nThis approach can be considered a form of meta-predictor, as it leverages the outputs of multiple machine-learning methods to enhance the overall predictive performance. The models were compared based on their accuracy, with the GBM model achieving the highest mean accuracy of 0.665.\n\nTo ensure the independence of training data, we employed techniques such as 1-to-1 matching and propensity score weighting. These methods helped to balance the baseline covariates, making the comparison between different types of bystander CPR more reliable. The matching process allowed for the satisfactory balancing of most variables, with a few exceptions such as educational level of bystanders, dispatcher-assisted CPR, and whether the bystander connected a defibrillator.\n\nBy using a diverse set of machine-learning algorithms and ensuring the independence of training data through matching and weighting, we aimed to provide a thorough and unbiased analysis of the relationship between type of bystander CPR and 30-day survival.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps to ensure the data was suitable for analysis. Multiple imputation was used to handle missing data, assuming it was missing at random. The Multivariate Imputation by Chain Equations (MICE) algorithm was employed with 50 iterations to impute one complete dataset. The Predictive Mean Matching (PMM) method was utilized for imputing missing values, which allows for flexible imputation of both numerical and categorical data.\n\nFor the propensity score models, various machine learning techniques were applied, including Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks. These models were compared based on their accuracy, with the GBM model achieving the highest mean accuracy of 0.665.\n\nThe relative importance of early predictors of survival was calculated using a modified implementation of the random forest algorithm developed by Strobl et al. This method provides unbiased estimates of variable importance, accounting for correlations among predictors. The analysis included variables that could be assessed up until the arrival of the Emergency Medical Services (EMS), such as breathing status, initial rhythm, age, pulse at EMS arrival, witnessed status, location, etiology of the cardiac arrest, time from cardiac arrest to defibrillation, time from cardiac arrest to EMS arrival, consciousness at EMS arrival, and whether a bystander connected a defibrillator.\n\nStandardized mean differences (SMD) were used to compare characteristics between groups, with SMDs below 10% considered inconsequential. The Kaplan-Meier estimator was used to describe survival distributions, and the log-rank test was employed to compare these distributions. Bar charts were utilized for visualizing distributions in the location and cause of cardiac arrest.",
  "optimization/parameters": "In our study, we employed a comprehensive approach to model building, utilizing a variety of machine learning algorithms to determine the optimal parameters for predicting 30-day survival in relation to the type of bystander CPR. We constructed a total of 12,008 different models using six distinct algorithms: Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks. Each of these models was evaluated based on its accuracy, with the GBM model ultimately achieving the highest mean accuracy of 0.665.\n\nThe selection of parameters was not arbitrary but rather a result of extensive hyperparameter tuning across a grid. This process ensured that we explored a wide range of possible configurations to identify the most effective models. The graphical summary of all GBM models' accuracies across the hyperparameter grid is presented in Supplementary Fig. 4, providing a visual representation of the performance of different parameter settings.\n\nIn addition to accuracy, we also considered the balance of baseline covariates. The matching process allowed for the satisfactory balancing of most variables, with the exception of educational level of bystanders, dispatcher-assisted CPR, and whether the bystander connected a defibrillator. These unbalanced covariates were included in the logistic regression model to account for their potential influence on the outcomes.\n\nThe use of multiple models and extensive hyperparameter tuning ensured that our final selection of parameters was robust and well-suited to the data, providing reliable predictions of 30-day survival.",
  "optimization/features": "In our study, we utilized a total of 23 early predictors of survival as input features. These features included variables such as type of bystander CPR, age, sex, calendar year, various time intervals related to the cardiac arrest, location, witness type, bystander's profession and educational level, dispatcher-assisted CPR, defibrillator connection by bystander, and temporal factors like clock time and weekday.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, we focused on including variables that could be assessed immediately upon the arrival of emergency medical services (EMS). This approach ensured that the features were relevant and available at the critical moment of EMS arrival, providing actionable insights for predicting survival.\n\nThe selection of these features was based on their potential to influence survival outcomes and their availability at the time of EMS arrival. This method ensured that the models were built using the most relevant and timely information, enhancing their practical applicability in real-world scenarios.",
  "optimization/fitting": "The study involved building a total of 12,008 different models using various machine learning algorithms, including Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks. The models were compared based on their accuracy, with the GBM model achieving the highest mean accuracy of 0.665.\n\nTo address the potential issue of overfitting, given the large number of models and parameters relative to the training points, several strategies were employed. Firstly, the models were evaluated using a comprehensive hyperparameter grid, ensuring that the best-performing models were selected based on their generalization performance rather than their fit to the training data. Additionally, the study used cross-validation techniques to assess the models' performance on unseen data, which helps in identifying models that generalize well.\n\nUnderfitting was mitigated by using a diverse set of advanced machine learning algorithms, each capable of capturing complex relationships in the data. The inclusion of algorithms like GBM, XGBOOST, and neural networks, which are known for their ability to model non-linear relationships and interactions, ensured that the models were sufficiently flexible to capture the underlying patterns in the data. Furthermore, the use of multiple imputation to handle missing data helped in maximizing the power of the models by including more complete datasets.\n\nThe study also employed propensity score methods to balance covariates, which is crucial for reducing bias in observational studies. This approach involved calculating propensity scores using the model with the highest accuracy and using these scores for covariate adjustment, matching, and weighting. The balance of covariates was evaluated using standardized mean differences (SMDs), ensuring that the models were not underfitting by failing to account for important variables.\n\nIn summary, the study carefully managed the risk of overfitting and underfitting by leveraging a diverse set of advanced machine learning algorithms, comprehensive hyperparameter tuning, cross-validation, and robust statistical methods for covariate balancing. These measures ensured that the models were both flexible enough to capture complex patterns and generalizable to new data.",
  "optimization/regularization": "In our study, we employed several machine learning models, including Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks. These models inherently include regularization techniques to prevent overfitting.\n\nGradient Boosting and XGBOOST, for instance, use techniques like shrinkage (learning rate) and subsampling to reduce overfitting. Random Forest employs bootstrapping and feature randomization to ensure that the model generalizes well to unseen data. Logistic Regression can incorporate L1 (Lasso) or L2 (Ridge) regularization to penalize large coefficients, thereby preventing the model from becoming too complex.\n\nAdditionally, we built a comprehensive set of 12,008 different models across various hyperparameter grids. This extensive exploration helped us identify the model with the highest predictive accuracy and the best balance of baseline covariates, further ensuring that our results were robust and not overfitted to the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are not explicitly detailed in the main text. However, a graphical summary of all Gradient Boosting Machine (GBM) models\u2019 accuracies across the hyper-parameter grid is presented in Supplementary Fig. 4. This figure provides insights into the performance of different hyper-parameter settings.\n\nRegarding the availability of model files and optimization parameters, these specifics are not provided in the publication. The focus was on comparing the performance of various models, including GBM, Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks, using accuracy as the primary metric. The highest mean accuracy was achieved by the GBM model, with a value of 0.665.\n\nThe study emphasizes the use of propensity scores for covariate adjustment and matching, which were calculated using a comprehensive algorithm that evaluated 12,008 different models. The propensity scores were used to balance covariates and estimate treatment effects, but the exact model files and optimization parameters are not made available.\n\nFor those interested in replicating or building upon this work, the supplementary materials and figures provide a starting point for understanding the methods and results. However, the specific details required to reproduce the models exactly are not provided.",
  "model/interpretability": "The models employed in this study, including Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks, are generally considered to be black-box models. This means that while they can provide accurate predictions, the internal workings and the reasoning behind these predictions are not easily interpretable.\n\nHowever, efforts were made to enhance interpretability through the use of propensity scores. Propensity scores were calculated using various models, and the one with the highest prediction accuracy was selected. Additionally, the model that yielded the greatest balance of baseline covariates was also considered. This approach helped in understanding the balance of covariates and the effectiveness of the matching process.\n\nFor variable importance, it was noted that conventional methods like XGBOOST, GBM, and RF do not provide unbiased estimates of relative importance. Therefore, the validated software implementation of conditional variable importance for random forests by Strobl et al. was used. This method allows for a more transparent understanding of which variables are most influential in the model's predictions.\n\nIn summary, while the primary models used are black-box in nature, the use of propensity scores and conditional variable importance for random forests provided some level of interpretability. This ensured that the models were not only accurate but also transparent in terms of the variables that drove the predictions.",
  "model/output": "The model is a classification model. We built 12,008 different models using various machine learning algorithms, including Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks. These models were used to predict the type of bystander CPR, which is a classification task. The performance of these models was evaluated using accuracy as the primary metric. The GBM model achieved the highest mean accuracy of 0.665. Additionally, we used these models to compute propensity scores for covariate adjustment and matching, which were then used to analyze the association between the type of bystander CPR and 30-day survival. The models were built on imputed data using the Multivariate Imputation by Chain Equations (MICE) algorithm with the Predictive Mean Matching (PMM) method. The relative importance of variables, including the type of bystander CPR, was calculated using a modified implementation of the random forest algorithm developed by Strobl et al.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a comprehensive approach using various machine learning models to build propensity scores for covariate adjustment and 1-to-1 matching. A total of 12,008 different models were constructed using Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks. The models were compared based on their accuracy, with the GBM model achieving the highest mean accuracy of 0.665. This model was used for further analysis.\n\nThe performance of the models was assessed using accuracy as the primary metric. Additionally, the balance of baseline covariates was evaluated to ensure that the matching process adequately controlled for confounding variables. The matching allowed for satisfactory balancing of most variables, except for the educational level of bystanders, dispatcher-assisted CPR, and whether the bystander connected a defibrillator. These variables were adjusted for in subsequent analyses.\n\nThe evaluation also included the use of propensity score weights for inverse probability of treatment weighting (IPTW). This approach aimed to balance the distribution of baseline covariates between the compression-only CPR (CO-CPR) and standard CPR (S-CPR) groups. The results showed that the covariates were sufficiently balanced by the propensity score weights, indicating the effectiveness of the method in controlling for confounding variables.\n\nThe study further examined the association between the type of bystander CPR and 30-day survival using both the Average Treatment Effect (ATE) and the Average Treatment Effect on the Treated (ATT) approaches. The results indicated no significant differences in survival between CO-CPR and S-CPR in most analyses, with the exception of a few subgroups. The subgroup analysis including patients aged 73 years or older showed statistically significant odds ratios for S-CPR vs. CO-CPR, both in the ATE and ATT approaches. However, these findings were not considered conclusive due to the lack of significance after adjustment for multiple testing.\n\nIn summary, the evaluation method involved the use of multiple machine learning models to build propensity scores, with a focus on accuracy and covariate balance. The results demonstrated the effectiveness of the method in controlling for confounding variables and provided insights into the association between the type of bystander CPR and survival outcomes.",
  "evaluation/measure": "In our study, we primarily focused on accuracy as the key performance metric for evaluating the various models we built. We constructed a total of 12,008 different models using a range of machine learning algorithms, including Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks. Among these, the GBM model achieved the highest mean accuracy of 0.665.\n\nIn addition to accuracy, we also considered the balance of baseline covariates. For the propensity score models, we ensured that the covariates were sufficiently balanced, which is crucial for making valid comparisons between the groups. This balance was assessed using standardized mean differences (SMD), where SMDs below 10% (0.1) were considered inconsequential.\n\nWe also reported odds ratios for 30-day survival in relation to the type of bystander CPR. These odds ratios were calculated using both the Average Treatment Effect (ATE) and the Average Treatment Effect on the Treated (ATT) approaches, adjusting for propensity scores and other relevant variables.\n\nThe use of accuracy as a primary metric is consistent with common practices in the literature for evaluating predictive models. However, we acknowledge that accuracy alone may not capture all aspects of model performance, especially in imbalanced datasets. Future work could explore additional metrics such as precision, recall, and the area under the receiver operating characteristic curve (AUC-ROC) to provide a more comprehensive evaluation.\n\nNot applicable",
  "evaluation/comparison": "In our study, we employed a comprehensive approach to compare various machine learning models for predicting the type of bystander CPR and their associated survival outcomes. We built and evaluated 12,008 different models using a range of algorithms, including Gradient Boosting Machine (GBM), Support Vector Machine (SVM), Random Forest (RF), Logistic Regression (GLM), Extreme Gradient Boosting (XGBOOST), and neural networks. The models were compared based on their accuracy, with the GBM model achieving the highest mean accuracy of 0.665.\n\nTo ensure the robustness of our findings, we used multiple methods for covariate adjustment, including 1-to-1 matching and inverse probability of treatment weighting (IPTW). These methods helped balance the baseline characteristics of the groups receiving compression-only CPR (CO-CPR) and standard CPR (S-CPR), allowing for a fair comparison of their survival outcomes.\n\nWe did not directly compare our methods to publicly available benchmarks or simpler baselines, as our focus was on leveraging advanced machine learning techniques to handle the complexity of the data and the multitude of covariates involved. Instead, we prioritized the use of state-of-the-art algorithms and thorough validation techniques to ensure the reliability of our results. The matching allowed for satisfactorily balancing of all variables with the exception of educational level of bystanders, DA-CPR and whether the bystander connected a defibrillator.",
  "evaluation/confidence": "The study employed a rigorous approach to evaluate the performance metrics, ensuring robustness and reliability. Confidence intervals were indeed used, specifically 99% confidence intervals, to assess the statistical significance of the results. This choice was made to account for multiple comparisons and reduce the risk of type I errors. The use of such stringent confidence intervals underscores the commitment to maintaining high standards of statistical rigor.\n\nThe results indicated that in most analyses, there were no significant differences between the two types of bystander CPR (S-CPR and CO-CPR) in terms of 30-day survival. However, there were a few notable exceptions. For instance, in the subgroup of patients aged 73 years or older, the odds ratios for S-CPR versus CO-CPR were statistically significant, both in the Average Treatment Effect (ATE) and Average Treatment Effect on the Treated (ATT) analyses. Specifically, the odds ratios were 1.57 (99% CI 1.17\u20132.12) for ATE and 1.63 (99% CI 1.18\u20132.25) for ATT. Additionally, in one of the four analyses, men who received S-CPR had slightly higher survival, with an odds ratio of 1.21 (99% CI 1.02\u20131.43).\n\nIt is important to note that while these results were statistically significant, the study authors acknowledged the possibility of these findings being chance occurrences, despite the use of 99% confidence intervals. A Bonferroni correction, which would require a more stringent p-value threshold, would invalidate these significances. Therefore, the study concludes that it fails to safely reject the null hypothesis, suggesting no convincing difference in survival regarding the type of bystander CPR in out-of-hospital cardiac arrest (OHCA).\n\nThe methodological considerations highlighted the use of propensity scores for causal inference, which is considered the preferred approach in observational studies. The study employed a comprehensive algorithm to sift through various prediction models, ensuring that the propensity scores were calculated using the model with the highest prediction accuracy and the greatest balance of baseline covariates. This approach aimed to minimize bias and provide estimates closer to the true values.",
  "evaluation/availability": "Not enough information is available."
}