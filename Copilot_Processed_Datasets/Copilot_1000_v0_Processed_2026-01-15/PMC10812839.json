{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- Harshe et al. (The specific names of the authors in the \"Harshe et al.\" group are not provided.)\n- Zachary F. Lerner (Corresponding author)\n- Conner BC\n- Luque J\n\nThe specific contributions of each author are not detailed.",
  "publication/journal": "IEEE Robotics and Automation Letters",
  "publication/year": "2024",
  "publication/pmid": "38283263",
  "publication/pmcid": "PMC10812839",
  "publication/doi": "10.1109/ICORR55369.2022.9896581.",
  "publication/tags": "- Machine Learning\n- Plantar Flexor Activity\n- Neuromuscular Impairment\n- Exoskeleton\n- Gait Training\n- Biofeedback\n- Rehabilitation\n- Robotics\n- Neural Networks\n- Linear Regression",
  "dataset/provenance": "The dataset utilized in this study was collected from participants engaging with an exoskeleton during walking trials. The participants were instructed to plantarflex during the late stance phase across multiple sessions. During the first session, each participant underwent five one-minute walking trials with the exoskeleton, including one zero-torque trial and four bouts of plantar flexor resistance. The target non-dimensional walking speed was set at 0.35, though one participant did not achieve this speed. Each participant wore four wireless EMG sensors placed symmetrically on the lateral gastrocnemius and soleus muscles. The resistance torque was standardized at 0.137 Nm/kg.\n\nThe data collected included exoskeleton sensor data and EMG data, which were synchronized using key start and stop events in each trial. Between sessions, 11 features were extracted from the exoskeleton\u2019s sensor data. The EMG data were scaled to the mean activation of the highest ten steps from the zero-torque trial to isolate changes in recruitment caused by the resistive torque. The EMG data from the gastrocnemius and soleus muscles on each leg were summed to form a single metric reflecting the response from both muscles.\n\nThe dataset was used to train multilayer perceptron (MLP) architectures for each participant to predict plantar flexor recruitment. The models were validated using standard 3-fold cross-validation, with each dataset split into a training set (85%) and a test set (15%). The loss (MSE) was tracked over every epoch of learning for both sub-train and validation datasets to identify the optimal number of epochs and avoid overfitting.\n\nThe specific number of data points varies by participant, as indicated in the custom model architecture table. For example, participant 1 had 381 steps, while participant 3 had 659 steps. This variability reflects the individual differences in walking patterns and responses to the exoskeleton resistance.\n\nThis dataset has not been used in previous papers or by the community, as it is part of ongoing research aimed at developing a generalizable data-driven model for predicting plantar flexor activity across individuals with various neurological conditions and walking patterns. The ultimate goal is to create a model that does not require patient-specific modifications or additional training data, making it suitable for clinical practice.",
  "dataset/splits": "In our study, we employed a standard 3-fold cross-validation approach for model validation. This method involved splitting each dataset into three distinct folds. Each fold was then used as a test set while the remaining two folds served as the training set. This process ensured that each data point was used for both training and testing, providing a robust evaluation of our models.\n\nThe data was divided such that 85% of the data was allocated to the training set, and the remaining 15% was reserved for the test set. This distribution was maintained consistently across all three folds to ensure a balanced and representative evaluation.\n\nThe specific number of data points in each split varied depending on the participant and the trial, but the overall distribution followed the 85-15% rule. This approach helped in identifying the optimal number of epochs for training, thereby preventing overfitting and ensuring that the models generalized well to unseen data.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a multilayer perceptron (MLP), which is a type of artificial neural network. MLPs are well-established and widely used for their ability to model complex relationships and predict continuous output values.\n\nThe specific MLP implementations used in our research are not new algorithms but rather established techniques adapted for our particular application. We utilized the Scikit-learn library, a validated Python machine learning library, to implement our MLPs. This library is commonly used in the machine learning community and provides robust tools for building and evaluating MLPs.\n\nThe choice to use MLPs was driven by their proven effectiveness in handling both linear and non-linear functions, making them suitable for predicting plantar flexor recruitment during exoskeleton-assisted gait training. The generic MLP model had a three-layer architecture with a specific number of nodes in each layer, chosen based on pilot testing for optimal performance across participants. Additionally, custom MLPs were generated for each participant to further enhance prediction accuracy.\n\nThe decision to use MLPs in this context, rather than publishing them in a machine-learning journal, is because the focus of our work is on applying these algorithms to a specific biomedical problem. Our primary goal was to predict neuromuscular recruitment and develop a biofeedback system for improving gait training in individuals with cerebral palsy. The innovation lies in the application and validation of these models in a clinical setting, rather than in the development of new machine-learning algorithms.",
  "optimization/meta": "Not applicable",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the machine-learning algorithm could effectively learn from the input features. The input features for both custom and generic multilayer perceptron (MLP) models were derived from a processed subset of the exoskeleton\u2019s state variables during the stance phase of walking. These features included peak torque, peak angle, mean angle, peak force-sensitive resistor (FSR) values, mean FSR, peak angular velocity, mean angular velocity, peak positive angle, peak negative angle, and peak negative angular velocity. To manage the data efficiently, we used the mean and maximum values from each step as input features, which helped in predicting peak plantar flexor recruitment.\n\nAll input features were scaled to have a mean of zero and a standard deviation of one. This standardization is essential for ensuring that each feature contributes equally to the model's learning process, preventing features with larger scales from dominating the optimization process.\n\nFor the experimental data collection, participants wore wireless EMG sensors on the lateral gastrocnemius and soleus muscles. The EMG data were scaled to the mean activation of the highest ten steps from the zero-torque trial. This scaling helped isolate changes in muscle recruitment caused by the resistive torque, separate from the effects of adding mass to the body. The EMG data from the gastrocnemius and soleus muscles on each leg were summed to form a single metric that reflected the response from both muscles. This approach created a unified label for each step, which was used to train the MLP architecture for predicting plantar flexor recruitment.\n\nIn summary, the data encoding and preprocessing involved selecting relevant features from the exoskeleton\u2019s state variables, scaling these features, and standardizing the EMG data to create a consistent and informative input for the machine-learning algorithm. These steps were vital for ensuring the accuracy and reliability of the predictions made by the MLPs.",
  "optimization/parameters": "In our study, we utilized a variety of input parameters to train our models for predicting plantar flexor recruitment. The specific number of parameters, p, varied depending on the model architecture and the individual participant's data. For instance, our custom multi-layer perceptron (MLP) architectures had different numbers of nodes per layer, which directly influenced the number of parameters.\n\nThe selection of input parameters was guided by the features extracted from the exoskeleton\u2019s sensor data. We initially collected data from participants during walking trials, focusing on key metrics such as resistance torque, plantarflexion, and EMG sensor readings. These features were then processed to isolate changes in muscle recruitment caused by resistive torque.\n\nWe extracted 11 features from the exoskeleton\u2019s sensor data, which included metrics like peak force-sensing resistor (FSR) voltage, mean angle, and mean FSR during the stance phase. These features were ranked based on their impact on predicted plantar flexor recruitment using the linear model weights. The top features, such as peak FSR, mean angle, and mean FSR during the stance phase, were consistently important across participants.\n\nThe number of epochs for training was determined by analyzing the mean loss curves, which helped identify the optimal epoch count to avoid overfitting. This process ensured that our models were trained efficiently and accurately.\n\nIn summary, the number of parameters used in the model varied based on the architecture and the specific features extracted from the participant data. The selection of these parameters was informed by the importance of each feature in predicting plantar flexor recruitment, as determined by the linear model weights and the characteristic validation losses observed during training.",
  "optimization/features": "In the optimization process of our study, we utilized a total of 11 features as inputs for our models. These features were derived from the exoskeleton\u2019s state variables during the stance phase of walking. The specific features included peak torque, peak angle, mean angle, peak force-sensitive resistor (FSR) readings, mean FSR, peak angular velocity, mean angular velocity, peak rate of change of FSR, peak positive angle, peak negative angle, and peak negative angular velocity.\n\nFeature selection was not explicitly performed in the traditional sense, as we focused on a subset of processed exoskeleton state variables that were deemed relevant based on domain knowledge. The selection of these features was guided by their potential to capture the essential dynamics of plantar flexor recruitment during walking with resistance.\n\nThe mean and maximum values from each step were used as model input features to ensure that the data required to predict peak plantar flexor recruitment was comprehensive. All input features were scaled to have a mean of zero and a standard deviation of one prior to model input, which helped in standardizing the data and improving the model's performance.\n\nThe features were selected based on their relevance to the task and were not subjected to further reduction or selection processes using the training set. This approach ensured that the models were trained on a consistent set of features across all participants, maintaining the integrity of the comparative analysis.",
  "optimization/fitting": "In our study, we employed multilayer perceptron (MLP) architectures to predict plantar flexor recruitment, using both generic and custom models. The generic MLP had a three-layer architecture with a total of 12 nodes, while the custom MLPs varied in complexity, with layer numbers ranging from two to five and node numbers from one to ten per layer. The input features consisted of a subset of the exoskeleton\u2019s state variables from the stance phase of walking, totaling 11 features.\n\nTo address the potential issue of overfitting, given the relatively large number of parameters compared to the number of training points, we implemented standard 3-fold cross-validation. This process involved splitting each dataset into a training set (85%) and a test set (15%). The models were trained on the training set and validated on the remaining 15% of the data, which was not used during training. We tracked the mean squared error (MSE) loss over every epoch for both the training and validation datasets. By averaging the validation losses across the three folds, we generated a mean loss curve that displayed characteristic underfitting at low epoch counts and overfitting at large epoch counts. The epoch corresponding to the minimum mean-validation loss was identified as the optimal number of epochs for training, thereby avoiding overfitting.\n\nTo ensure that the models were not underfitting, we compared the performance of our MLPs against a linear model and a featureless model that predicted the mean of its label data. This comparison helped us identify meaningful learning rather than relative learning. The linear models provided insights into the importance of each exoskeleton data feature, and their accuracy was checked against the custom MLPs to assess the necessity of more complex models for prediction. The custom MLPs, which were tailored to each participant based on minimum mean squared error (MSE) of the validation set, generally showed higher accuracy than the generic models, indicating that they were appropriately complex for the task.\n\nIn summary, we used cross-validation and comparative modeling to balance the complexity of our MLPs, ensuring that they neither overfit nor underfit the data. This approach allowed us to develop robust models for predicting plantar flexor recruitment during exoskeleton-assisted gait training.",
  "optimization/regularization": "In our study, we implemented several techniques to prevent overfitting and ensure the robustness of our models. One key method involved using 3-fold cross-validation, where each dataset was split into a training set (85%) and a test set (15%). This approach allowed us to validate our models rigorously and ensure that they generalized well to unseen data.\n\nAdditionally, we monitored the loss (mean squared error) over every epoch of learning for both the training and validation datasets. By tracking these losses, we could identify the optimal number of epochs to stop training, thereby avoiding overfitting. The characteristic under-fitting at low epoch counts and over-fitting at large epoch counts guided us in selecting the epoch that yielded the minimum mean-validation loss. This process ensured that our models were neither too simple nor too complex, striking a balance that enhanced their predictive accuracy.\n\nFurthermore, we compared our multilayer perceptron (MLP) models to a linear model and a featureless model that predicted the mean of its label data. This comparison helped us identify meaningful learning rather than relative learning, ensuring that our models were not merely memorizing the training data but were genuinely learning the underlying patterns.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules used in our study are detailed within the publication. Specifically, the architecture and accuracy information for the Multi-Layer Perceptron (MLP) models, including the number of nodes per layer and the mean absolute percentage error for custom, generic, and linear models, are provided in Table II. This table offers insights into the configurations that yielded the most accurate predictions for plantar flexor recruitment.\n\nThe optimization parameters, such as the number of epochs for training different models, are also discussed. For instance, it is mentioned that the generic model was trained for 10 epochs, while the linear model was trained for 14 epochs. These details are crucial for replicating the experiments and understanding the optimization process.\n\nRegarding the availability of model files and optimization parameters, the publication does not explicitly state where these files can be accessed or under what license they are provided. However, the methods and results are thoroughly described, allowing other researchers to implement similar models and optimization techniques.\n\nFor those interested in the specific details of the hyper-parameters and optimization schedules, referring to the tables and figures within the publication, such as Figure 3 and Table II, will be beneficial. These resources provide a comprehensive overview of the configurations and parameters used in our study.",
  "model/interpretability": "The models used in our study include both multi-layer perceptron (MLP) architectures and linear regression models. The MLPs, particularly the custom and generic architectures, are more complex and can be considered black-box models. These models are powerful in capturing intricate patterns in the data but lack transparency, making it challenging to interpret the specific relationships between input features and predictions.\n\nOn the other hand, the linear regression models offer a higher degree of interpretability. These models provide clear insights into the relationships between the input features and the predicted plantar flexor muscle activity. For instance, the linear models allowed us to rank the impact of each variable on predicted plantar flexor recruitment. Features such as peak and mean plantar pressure measured from embedded force-sensitive resistors (FSRs), ankle angle and angular velocity, and exoskeleton torque were identified as the most predictive. This transparency is beneficial for understanding which factors are most influential in the model's predictions, making it easier to communicate and implement the findings in practical applications.\n\nThe similarity in accuracy between the linear models and the more complex MLPs was a surprising but welcome outcome. Linear models are simpler, easier to interpret, and faster to implement, which makes them less computationally expensive and more suitable for embedding directly into robotic systems. This interpretability is crucial for clinical applications, where understanding the underlying mechanisms is essential for effective treatment and rehabilitation.",
  "model/output": "The models used in this study are regression models. Specifically, we employed multilayer perceptron (MLP) regressions and linear regression models to predict continuous output values, namely the plantar flexor recruitment during gait training. The MLPs were chosen for their ability to fit both linear and non-linear functions, making them suitable for predicting the continuous output of plantar flexor recruitment. The linear regression models were used to evaluate the relative importance of each feature in predicting plantar flexor recruitment and to assess the necessity of more complex models.\n\nThe output of these models is the predicted change in plantar flexor recruitment, which was compared to measured values to compute model accuracy. The accuracy was then used to determine the effectiveness of the models in predicting plantar flexor muscle activity. The models were trained and validated using data from the stance phase of walking, with input features including peak torque, peak angle, mean angle, peak force-sensitive resistor (FSR) values, mean FSR values, peak angular velocity, mean angular velocity, and other relevant metrics. These features were scaled to have a mean of zero and a standard deviation of one before being input into the models.\n\nThe models were evaluated using statistical tests, including paired two-tailed t-tests, to determine significant differences in accuracy between the models. The results showed that the custom MLP architectures were more accurate than the generic MLP and linear models, with an average accuracy of 86.8%. The linear model had an average accuracy of 85.3%, which was similar to the generic MLP's accuracy of 84.9%. The output of these models was used to provide real-time biofeedback during walking trials, which significantly improved plantar flexor recruitment.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, we employed several methods to evaluate the performance and effectiveness of our models. We used standard 3-fold cross-validation to validate our artificial neural networks (ANNs) and linear models. Each dataset was split into a training set (85%) and a test set (15%), ensuring that the test datasets were not used to train the models. This approach helped us to assess the generalizability of our models.\n\nWe tracked the loss, specifically the Mean Squared Error (MSE), over every epoch of learning for both the training and validation datasets. By analyzing the characteristic validation losses relative to the training epochs, we identified the optimal number of epochs to stop training and avoid overfitting. The mean curve of validation losses showed underfitting at low epoch counts and overfitting at large epoch counts, allowing us to determine the epoch at which the model performed best.\n\nTo confirm the accuracy of our models, we computed model accuracy as one minus the percent error between predicted and measured changes in plantar flexor recruitment. We verified that the model prediction accuracies were normally distributed using the Lilliefors test for normality with an alpha set at 0.05. Paired two-tailed t-tests were then used to determine statistically significant differences in accuracy between the models, with statistical significance defined as \u03b1 < 0.05. We did not adjust our alpha values for multiple comparisons due to the exploratory nature of this work.\n\nAdditionally, we compared the predictions from our custom and generic Multi-Layer Perceptron (MLP) models to a linear model and a featureless model that predicted the mean of its label data. This comparison helped us identify meaningful learning rather than relative learning. The linear models were also analyzed to understand the importance of each exoskeleton data feature, with the absolute values of the weights ranked across the cohort to assess the features that had the largest impact on predicted recruitment.\n\nIn summary, our evaluation methods included cross-validation, loss tracking, statistical tests for accuracy, and comparisons with simpler models to ensure the robustness and validity of our findings.",
  "evaluation/measure": "In our study, we focused on several key performance metrics to evaluate the effectiveness of our models and the biofeedback system. The primary metric reported is model accuracy, which is calculated as one minus the percent error between predicted and measured changes in plantar flexor recruitment. This metric provides a clear indication of how well our models can predict muscle activity.\n\nWe also report the mean absolute percentage error for different model architectures, including custom and generic Multi-Layer Perceptron (MLP) models, as well as a linear model. This allows for a direct comparison of the performance of different architectures.\n\nIn addition to accuracy, we assessed the mean squared error across all participants and their observations. This metric gives insight into the overall performance and variability of the models.\n\nTo evaluate the impact of our biofeedback system, we measured the mean accuracy improvement relative to baseline across all participants. This metric helps to quantify the effectiveness of the biofeedback in enhancing muscle recruitment during gait training.\n\nFurthermore, we conducted statistical analyses using paired two-tailed t-tests to determine statistically significant differences in accuracy between the models. This ensures that the observed improvements are not due to chance.\n\nThe set of metrics reported in this study is representative of common practices in the literature for evaluating predictive models and biofeedback systems. Accuracy and error metrics are standard in machine learning evaluations, and the use of statistical tests to validate significance is a well-established method. The focus on muscle recruitment and gait training aligns with existing research in rehabilitation and human-robot interaction.",
  "evaluation/comparison": "In our study, we did not compare our methods to publicly available methods on benchmark datasets. Instead, our focus was on evaluating the performance of different models within our specific context of predicting plantar flexor recruitment during exoskeleton-assisted gait training.\n\nWe did, however, compare our models to simpler baselines. Specifically, we evaluated the performance of custom and generic Multi-Layer Perceptron (MLP) architectures against a linear model. The linear model served as a simpler baseline to assess the added value of more complex architectures. The comparison showed that while the custom MLP architectures were statistically more accurate than the generic models and the linear model, the linear model still demonstrated promising results with an average accuracy of 85.3%, which was similar to the generic MLP's accuracy of 84.9%. This comparison highlighted the effectiveness of the MLP models while also validating the potential utility of simpler, more interpretable models like linear regression. The linear model's performance was particularly notable, as it suggested that simpler models could be sufficient for certain applications, offering benefits such as easier implementation and lower computational expense.",
  "evaluation/confidence": "In our study, we employed several statistical methods to ensure the confidence and significance of our results. For model accuracy, we computed the mean absolute percent error between predicted and measured changes in plantar flexor recruitment. To confirm the normality of our model prediction accuracies, we used the Lilliefors test for normality with an alpha set at 0.05. This step was crucial for validating the assumptions required for subsequent statistical tests.\n\nWe utilized paired two-tailed t-tests to determine statistically significant differences in accuracy between the models. Statistical significance was defined as \u03b1 < 0.05. This approach allowed us to compare the performance of different models, including custom and generic Multi-Layer Perceptrons (MLPs) and a linear model. The results indicated that all three data-driven models showed effective learning relative to the baseline, with p-values less than 0.049 for all models. Specifically, the custom MLP architectures demonstrated higher accuracy compared to the generic MLP and linear models, with p-values less than 0.004.\n\nIn terms of biofeedback, we found that real-time plantar flexor recruitment biofeedback significantly increased mean peak recruitment by 23.6 \u00b1 15.7% relative to resistance only, with a p-value of 0.028. This indicates a statistically significant improvement in muscle recruitment when biofeedback was applied.\n\nError bars in our figures depict variance, providing a visual representation of the confidence intervals for our performance metrics. This visual aid helps in understanding the variability and reliability of our results across different participants and conditions.\n\nOverall, our statistical analyses and the presentation of variance through error bars ensure that our performance metrics are robust and that our claims of superiority over baselines and other methods are well-supported.",
  "evaluation/availability": "Not enough information is available."
}