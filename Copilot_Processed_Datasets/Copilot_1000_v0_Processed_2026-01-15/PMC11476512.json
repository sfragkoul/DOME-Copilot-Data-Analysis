{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- **HTL** and **WLG** designed the study.\n- **HHJ**, **PP**, and **YFQ** collected data.\n- **HHJ**, **SQT**, and **YKD** wrote the draft.\n- **HTL**, **WLG**, and **CG** contributed to the elaboration of the ideas developed in the manuscript and made critical amendments.\n- **GC**, **PP**, and **YFQ** contributed to the data collection and interpretation.\n- **DLH** and **YY** provided the statistical analysis.\n- All authors read and approved the final manuscript.",
  "publication/journal": "BMC Pediatrics",
  "publication/year": "2024",
  "publication/pmid": "39407181",
  "publication/pmcid": "PMC11476512",
  "publication/doi": "https://doi.org/10.1186/s12887-024-05141-y",
  "publication/tags": "- Congenital heart disease\n- Chest radiography\n- Deep learning\n- Differential diagnosis\n- Ventricular septal defect\n- Atrial septal defect\n- Medical imaging\n- Machine learning\n- Pediatric cardiology\n- Diagnostic accuracy",
  "dataset/provenance": "The dataset used in this study consisted of chest X-ray images of children. The images were collected from patients in a standing position, with instructions to inhale calmly. The X-ray machines used were from GE Healthcare, specifically the Discovery model from the USA. The dataset included a total of 1194 images, with 595 images of atrial septal defect (ASD) and 599 images of ventricular septal defect (VSD). The dataset was divided into training and validation sets, containing 960 samples (480 ASD and 480 VSD), and a test set with 115 ASD and 119 VSD cases.\n\nThe images were preprocessed by resampling them to a uniform size of 1024 \u00d7 1024 pixels to account for variations in original image sizes. The dataset was used to train and validate four different deep learning models: ResNet-CBAM, InceptionV3, EfficientNet, and ViT. Among these, InceptionV3 was selected as the final model due to its superior performance in differential diagnosis of ASD and VSD.\n\nThe study employed a fivefold cross-validation method to ensure the robustness of the results and to mitigate the impact of any potential imbalances in the dataset. This method involved randomly dividing the dataset into five segments, using four segments for training and one for testing, and repeating this process five times. This approach helped in reducing the risk of overfitting and ensured that the validation data varied with each iteration.\n\nThe dataset was not explicitly mentioned to have been used in previous papers or by the community, but the methods and models employed are based on established techniques in the field of medical image analysis and deep learning. The study aimed to contribute to the existing body of knowledge by demonstrating the effectiveness of deep learning models in assisting radiologists in the differential diagnosis of congenital heart diseases using chest X-ray images.",
  "dataset/splits": "The dataset used in this study was divided into three distinct splits: the training set, the validation set, and the test set. The entire dataset consisted of 1194 images, which included 595 images of atrial septal defect (ASD) and 599 images of ventricular septal defect (VSD).\n\nThe training and validation set combined contained a total of 960 samples. Within this combined set, there were 480 cases of ASD and 480 cases of VSD. The test set, on the other hand, consisted of the remaining images, totaling 234 samples. Specifically, the test set included 115 cases of ASD and 119 cases of VSD.\n\nThe distribution of data points in each split was designed to ensure a balanced representation of both ASD and VSD cases, facilitating robust training, validation, and testing of the deep learning models. This balanced approach helped in evaluating the models' performance accurately and reliably.",
  "dataset/redundancy": "The dataset used in this study consisted of 1194 chest X-ray images, with 595 images of atrial septal defect (ASD) and 599 images of ventricular septal defect (VSD). To ensure robust model training and evaluation, the dataset was divided into training, validation, and test sets. A total of 960 samples, comprising 480 cases of ASD and 480 cases of VSD, were allocated to the training and validation set. The remaining 115 cases of ASD and 119 cases of VSD were reserved for testing.\n\nTo mitigate the impact of potential data imbalance and ensure the independence of the training and test sets, a fivefold cross-validation method was employed. This involved randomly dividing the defect dataset into five segments, using four segments for training and reserving one for testing. Each test was supplemented with an additional segment of normal data, and this procedure was repeated five times. This approach helped to reduce discrepancies in results and minimize the risk of overfitting due to the imbalance in VSD and ASD cases.\n\nThe distribution of the dataset in this study is comparable to previously published machine learning datasets in the field of medical imaging. The use of a balanced dataset for training and validation, along with an independent test set, ensures that the model's performance is generalizable and not overly optimized for specific cases. This methodology is crucial for developing reliable deep learning models that can assist radiologists in the differential diagnosis of congenital heart diseases.",
  "dataset/availability": "The datasets used and analyzed during the current study are not publicly available. They can be obtained from the corresponding author upon reasonable request. This approach ensures that the data is shared responsibly and ethically, adhering to the guidelines set by the Ethics Committee of the Children\u2019s Hospital of Soochow University. The datasets include chest X-ray images of children, which are sensitive medical data. By making the data available upon request, we can maintain control over how the data is used and ensure that it is accessed only by authorized researchers who agree to use it in accordance with ethical standards and legal requirements. This method also allows for better tracking and accountability in the use of the data, which is crucial for maintaining the integrity and confidentiality of the information.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is convolutional neural networks (CNNs). Specifically, we employed several well-established CNN architectures, including ResNet-CBAM, InceptionV3, EfficientNet, and ViT. These models are widely recognized for their effectiveness in image classification tasks.\n\nThe InceptionV3 model, in particular, was selected for its unique architectural features, such as inception modules that capture a wide range of features from fine details to larger-scale patterns. This model demonstrated the best performance among the tested networks, achieving high accuracy, sensitivity, and specificity in differentiating between atrial septal defect (ASD) and ventricular septal defect (VSD) using children's chest X-ray images.\n\nWhile the algorithms used are not new, their application in the specific context of pediatric cardiac defect diagnosis is novel. The focus of our study was on the clinical application and diagnostic efficacy of these models rather than the development of new machine-learning algorithms. Therefore, publishing in a specialized machine-learning journal was not the primary objective. Instead, we aimed to highlight the practical benefits and potential improvements these models can bring to medical diagnostics, particularly in pediatric cardiology.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of the machine-learning algorithm. The dataset consisted of chest X-ray images, which were initially collected using digital X-ray machines with specific settings for tube current, tube voltage, and filming distance. These images were then resampled to a uniform size of 1024 \u00d7 1024 pixels to standardize the input for the deep learning models.\n\nThe preprocessing environment included an NVIDIA 3080Ti GPU with 12 GB memory, Python 3.9.7, Pytorch-GPU 1.10.2, SimpleITK 2.1.1, and Numpy 1.21.5, running on Windows 10. The batch size for training was set at 4, and the optimization function used was Adam. The weights were initialized using the default initializer in Pytorch.\n\nFour deep learning networks were trained and validated: ResNet-CBAM, InceptionV3, EfficientNet, and ViT. ResNet-CBAM integrated the ResNet network with the CBAM attention module, while InceptionV3 is known for its inception modules that capture a wide range of features. EfficientNet achieved excellent classification performance with a small number of parameters, and ViT represented a typical application of transformers in the image field.\n\nThe initial learning rate was set at 0.0001, with a dynamic learning rate adjustment strategy that reduced the learning rate to one-tenth of the original every 50 epochs. The training procedure stopped after 200 epochs.\n\nInceptionV3 was ultimately selected as the differential diagnostic network due to its unique architectural features, which include inception modules composed of multiple parallel convolutional and pooling layers at different kernel sizes. These modules enable the network to capture both fine details and larger-scale patterns, thereby improving its ability to represent complex visual information. Additionally, InceptionV3 incorporates factorization of convolutions, balancing model depth and computational efficiency.",
  "optimization/parameters": "In our study, we employed four different deep learning networks: ResNet-CBAM, InceptionV3, EfficientNet, and ViT. Each of these networks has a distinct architecture and thus a different number of parameters.\n\nResNet-CBAM integrates the ResNet network with the CBAM attention module, which is commonly used for medical image classification. This model has a moderate number of parameters, balancing complexity and computational efficiency.\n\nInceptionV3, one of the most commonly used classification networks, achieved good performance on various image classification tasks. It is characterized by its unique architectural feature of using inception modules, which are composed of multiple parallel convolutional and pooling layers at different kernel sizes. This design allows the network to capture a wide range of features, from fine details to larger-scale patterns, thereby improving its ability to represent complex visual information. InceptionV3 incorporates factorization of convolutions, balancing model depth and computational efficiency.\n\nEfficientNet is known for achieving excellent classification performance with a relatively small number of parameters, making it efficient in terms of computational resources.\n\nViT, or Vision Transformer, is a typical application of transformers in the image field. It leverages self-attention mechanisms to process image data, which can be highly effective but also parameter-intensive.\n\nAmong these models, InceptionV3 was ultimately selected as the differential diagnostic network due to its superior performance in our study. The selection of the model and its parameters was based on extensive performance comparisons and validation through fivefold cross-validation. This approach ensured that the chosen model was robust and generalizable to new data.\n\nThe initial learning rate for training was set at 0.0001, and a dynamic learning rate adjustment strategy was used, reducing the learning rate to one-tenth of the original every 50 epochs. The training procedure stopped after 200 epochs. This strategy helped in fine-tuning the model parameters to achieve optimal performance.",
  "optimization/features": "The input features for our deep learning models consisted of chest X-ray images. Specifically, we used posterior and anterior chest films collected from children. These images were taken using X-ray machines with specific parameters: tube current of 5-8 mA, tube voltage of 75-85 kV, and a filming distance of 180 cm. All images were resampled to a uniform size of 1024 \u00d7 1024 pixels to ensure consistency across the dataset.\n\nFeature selection in the traditional sense was not applicable since we were dealing with raw image data. Instead, the models were designed to automatically learn relevant features from the images during the training process. This approach leverages the capability of deep learning models to extract and utilize complex patterns directly from the pixel data.\n\nThe dataset included 1194 images, comprising 595 cases of atrial septal defect (ASD) and 599 cases of ventricular septal defect (VSD). The dataset was divided into training, validation, and test sets. The training and validation set contained 960 samples (480 ASD and 480 VSD), while the test set included 115 cases of ASD and 119 cases of VSD. This division ensured that the models were trained and validated on a substantial portion of the data, allowing for robust performance evaluation on the test set.",
  "optimization/fitting": "The fitting method employed in this study involved training four different deep learning networks: ResNet-CBAM, InceptionV3, EfficientNet, and ViT. The dataset consisted of 1194 images, with 960 samples used for training and validation, and the remaining 234 for testing. This dataset was divided into five segments for fivefold cross-validation, ensuring that each segment was used for testing once while the others were used for training. This approach helped mitigate discrepancies in results and reduce the risk of overfitting due to the imbalance in VSD and ASD cases.\n\nTo address the potential issue of overfitting, given the relatively small number of cases in the test set, fivefold cross-validation was employed. This method involved randomly dividing the dataset into five segments, using four segments for training and one for testing, and repeating this process five times. Additionally, a dynamic learning rate adjustment strategy was used, where the learning rate was reduced to one-tenth of its original value every 50 epochs. This strategy helped in fine-tuning the model and preventing it from overfitting to the training data.\n\nThe training procedure stopped after 200 epochs, which was determined to be sufficient for the models to converge without overfitting. The use of different convolutional network models and the incorporation of techniques like the CBAM attention module in ResNet-CBAM further enhanced the model's ability to capture relevant features without overfitting.\n\nTo ensure that the models were not underfitting, the performance of each model was thoroughly evaluated using metrics such as accuracy, sensitivity, specificity, and the area under the ROC curve (AUC). The models demonstrated high performance across these metrics, with InceptionV3 achieving the highest accuracy and sensitivity. The comparison between the deep learning models and radiologists using the Delong test and Kappa test showed that the models performed at least as well as, if not better than, the radiologists in differential diagnosis.\n\nIn summary, the fitting method involved a robust cross-validation strategy, dynamic learning rate adjustment, and thorough performance evaluation to ensure that the models neither overfitted nor underfitted the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our deep learning models. One of the primary methods used was fivefold cross-validation. This involved dividing the dataset into five segments, using four segments for training and one for testing, and repeating this process five times. This approach helped to mitigate discrepancies in results and reduce the risk of overfitting due to the imbalance in the number of cases of ventricular septal defect (VSD) and atrial septal defect (ASD).\n\nAdditionally, we used a dynamic learning rate adjustment strategy. The initial learning rate was set at 0.0001, and it was adjusted to one-tenth of the original every 50 epochs. This strategy helped in fine-tuning the model and preventing it from overfitting to the training data.\n\nWe also incorporated regularization techniques within our models. For instance, the InceptionV3 model, which was selected as the differential diagnostic network, includes factorization of convolutions. This architectural feature helps in balancing model depth and computational efficiency, thereby reducing the risk of overfitting.\n\nFurthermore, we ensured that the training procedure stopped after 200 epochs. This prevented the model from becoming too complex and overfitting to the training data. By implementing these regularization methods, we aimed to enhance the model's generalization ability and improve its performance on unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we utilized a standard normal distribution for Pytorch, with an initial learning rate set at 0.0001. The learning rate was dynamically adjusted to one-tenth of the original every 50 epochs, and the training procedure stopped after 200 epochs. The batch size was set at 4, and the optimization function used was Adam. The weights were initialized using the default initializer.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the datasets used and/or analyzed during the current study are available from the corresponding author upon reasonable request. The study was conducted in accordance with the Declaration of Helsinki (2013 revision), and the study protocol was approved by the Ethics Committee of the Children\u2019s Hospital of Soochow University. Written informed consent was provided by the parents or legal guardians of the children.\n\nThe authors declare no competing interests, and the work was partially supported by the Scientific Research Project of the Suzhou Health Commission. For further details or to access the datasets, interested parties can contact the corresponding author.",
  "model/interpretability": "The model employed in this study, particularly the InceptionV3 network, is not entirely a black-box model. To enhance interpretability, we utilized Grad-CAM (Gradient-weighted Class Activation Mapping) to visualize the regions of interest that the model focuses on during classification. This technique generates heat maps that highlight the areas in chest radiographs that contribute most to the model's decisions.\n\nFor instance, in the case of atrial septal defect (ASD) and ventricular septal defect (VSD), the heat maps revealed that the model paid more attention to specific regions in the upper lungs. For ASD, the red areas indicating higher attention were located in the right upper lung, while for VSD, these areas were in the left upper lung. This visualization not only helps in understanding which parts of the image the model finds most informative but also provides insights into the model's decision-making process, making it more transparent and interpretable.\n\nBy using Grad-CAM, we were able to demonstrate that the model's focus aligns with clinical knowledge, thereby increasing trust in its diagnostic capabilities. This approach allows clinicians to see how the model arrives at its conclusions, which is crucial for its acceptance and integration into clinical practice.",
  "model/output": "The model developed in this study is a classification model. It was designed to differentiate and diagnose atrial septal defect (ASD) and ventricular septal defect (VSD) using children's chest posterior-anterior X-ray images. The model outputs a classification into one of these two categories. Four different deep learning networks were trained and validated: ResNet-CBAM, InceptionV3, EfficientNet, and ViT. Among these, InceptionV3 demonstrated the highest performance and was selected as the differential diagnostic network. The model's output includes metrics such as accuracy, sensitivity, specificity, positive predictive value, negative predictive value, and the area under the ROC curve (AUC), which collectively indicate its effectiveness in classifying ASD and VSD. The model's performance was compared with that of radiologists, showing that it achieved diagnostic efficacy comparable to or better than that of radiology experts. Additionally, the model's internal workings were visualized using activation heat maps, which highlighted the regions of the X-ray images that the model focused on for its classifications.",
  "model/duration": "The training procedure for our deep learning models was conducted over 200 epochs. During this process, the learning rate was dynamically adjusted, being reduced to one-tenth of its original value every 50 epochs. This strategy helped in fine-tuning the model's performance over time. The initial learning rate was set at 0.0001, which was found to be effective for the convergence of the models.\n\nThe models were trained and validated in the same environment, ensuring consistency in the results. Four different deep learning networks were employed: ResNet-CBAM, InceptionV3, EfficientNet, and ViT. Among these, InceptionV3 was ultimately selected for its superior performance in differential diagnosis tasks. This network's unique architectural features, such as inception modules and factorization of convolutions, contributed to its high accuracy and efficiency.\n\nThe execution time for training these models varied depending on the complexity of the network and the computational resources available. However, the use of a dynamic learning rate adjustment strategy helped in optimizing the training time without compromising the model's performance. The models were evaluated using metrics such as accuracy, sensitivity, specificity, and the area under the ROC curve (AUC), which provided a comprehensive assessment of their diagnostic capabilities.\n\nIn summary, the training process was designed to be efficient and effective, with a focus on achieving high diagnostic accuracy. The use of dynamic learning rate adjustment and the selection of InceptionV3 as the final model were key factors in the success of this study.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive approach to assess the performance of deep learning models in differentiating between atrial septal defect (ASD) and ventricular septal defect (VSD) using children's chest X-ray images. A fivefold cross-validation method was implemented to ensure robust and reliable results. This method involved randomly dividing the dataset into five segments, using four segments for training and one for testing. This process was repeated five times, ensuring that each segment was used as the test set once, thereby mitigating discrepancies and reducing the risk of overfitting due to the imbalance in VSD and ASD cases.\n\nAdditionally, the model with the best performance during the fivefold cross-validation was further evaluated using an external test set. This external testing helped to validate the model's generalizability and performance on unseen data. The evaluation metrics included accuracy, sensitivity, specificity, positive predictive value, negative predictive value, area under the curve (AUC), and F1 score. These metrics provided a comprehensive assessment of the model's diagnostic performance.\n\nTo compare the diagnostic performance of the deep learning models with that of radiologists, 234 images in the validation group were visually diagnosed by two radiologists. The differences in diagnostic ability between the deep learning models and radiologists were compared using the Delong test. The Cohen Kappa test was used to assess the agreement between the deep learning models and radiologists, as well as between different radiologists. This comparative analysis helped to establish the clinical relevance and potential utility of the deep learning models in assisting radiologists in their diagnostic tasks.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our deep learning models in differentiating between ASD and VSD. The primary metrics reported include accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), the area under the ROC curve (AUC), and the F1 score.\n\nAccuracy measures the overall correctness of the model's predictions, providing a general sense of how well the model performs across all classes. Sensitivity, also known as the true positive rate, indicates the model's ability to correctly identify positive cases, which is crucial for detecting diseases. Specificity, or the true negative rate, assesses the model's capability to correctly identify negative cases, ensuring that non-disease cases are accurately classified.\n\nThe positive predictive value (PPV) and negative predictive value (NPV) offer insights into the probability that a positive or negative test result is correct, respectively. These metrics are particularly important in clinical settings where the consequences of false positives and false negatives can be significant.\n\nThe area under the ROC curve (AUC) provides a single scalar value that summarizes the model's performance across all classification thresholds. A higher AUC indicates better model performance in distinguishing between the two classes.\n\nThe F1 score is the harmonic mean of precision and recall, offering a balanced measure that is especially useful when dealing with imbalanced datasets. It provides a single metric that considers both the precision of positive predictions and the model's ability to find all positive instances.\n\nThese metrics collectively provide a robust evaluation of our models' performance, ensuring that we capture various aspects of model effectiveness. The choice of these metrics is aligned with standard practices in the literature, making our evaluation representative and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we did not perform a comparison to publicly available methods on benchmark datasets. Instead, we focused on comparing the performance of our deep learning models to that of radiologists. We trained and validated four deep learning networks: ResNet-CBAM, InceptionV3, EfficientNet, and ViT. Among these, InceptionV3 was selected as the differential diagnostic network due to its superior performance.\n\nTo assess the diagnostic performance, we compared the deep learning models with two radiologists who independently categorized cases as normal adenoids or adenoid hypertrophy. The differences in diagnostic ability were compared using the Delong test, and the agreement between the deep learning models and radiologists was assessed using the Cohen Kappa test.\n\nWe did not perform a comparison to simpler baselines. Our primary focus was on evaluating the effectiveness of advanced deep learning models in differentiating between ASD and VSD using children's chest X-ray images. The results demonstrated that InceptionV3 achieved the highest accuracy, sensitivity, and specificity among the models tested, indicating its strong potential for clinical application.",
  "evaluation/confidence": "The evaluation of our deep learning models involved a comprehensive assessment of their performance metrics, including accuracy, sensitivity, specificity, positive predictive value, negative predictive value, and the area under the ROC curve (AUC). These metrics were calculated for each of the four models: EfficientNet, InceptionV3, ResNet18_CBAM, and ViT.\n\nTo ensure the robustness of our results, we employed a fivefold cross-validation method. This approach involved randomly dividing the dataset into five segments, using four segments for training and one for testing, and repeating this process five times. This method helped mitigate discrepancies in results and reduce the risk of overfitting due to the imbalance in VSD and ASD cases.\n\nStatistical significance was assessed using the Delong test, which showed no significant difference between InceptionV3 and each radiologist in the differential diagnosis ability of imaging specialists for VSD and ASD. Additionally, the Cohen Kappa test was used to determine the consistency among radiologists, with a Kappa value of approximately 0.81 indicating excellent agreement.\n\nThe results demonstrated that the average accuracy, sensitivity, and specificity of the four deep learning models for the differential diagnosis of VSD and ASD across five different test datasets were high, exceeding 0.70, with an average AUC value greater than 0.80. Among these models, InceptionV3 achieved the highest accuracy rate of 0.872, with sensitivity, specificity, positive predictive value, and F1 score recorded at 0.975, 0.765, 0.811, and 0.886, respectively.\n\nThese findings suggest that our model could assist physicians in refining their differential diagnoses, thereby enabling them to diagnose patients more accurately. The statistical tests and cross-validation methods used provide confidence in the reliability and generalizability of our results.",
  "evaluation/availability": "The datasets used and analyzed during the current study are available from the corresponding author upon reasonable request. This approach ensures that the data can be accessed for verification or further research while maintaining control over its distribution."
}