{
  "publication/title": "Biomimetics 2023, 8, 313",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Biomimetics",
  "publication/year": "2023",
  "publication/pmid": "37504202",
  "publication/pmcid": "PMC10807651",
  "publication/doi": "10.3390/biomimetics8030313",
  "publication/tags": "- Biomimetics\n- Feature Selection\n- Optimization Algorithms\n- Statistical Analysis\n- Machine Learning\n- Classification\n- Decision Tree\n- Metaheuristic Algorithms\n- Performance Metrics\n- Data Analysis",
  "dataset/provenance": "The dataset used in our study is the Monkeypox Skin Image Dataset, which is freely available on Kaggle. This dataset is a valuable resource for researchers and medical professionals studying the monkeypox virus and its impact on human health. It comprises a collection of high-resolution images depicting various stages and manifestations of monkeypox infection on human skin. The dataset includes images of skin lesions, rashes, and other related dermatological conditions, providing a comprehensive visual representation of the disease.\n\nThe dataset consists of 770 images, which are divided into three subsets: 60% for training, 20% for validation, and 20% for testing. This division ensures that the model is trained, validated, and tested on different portions of the data, helping to assess its performance and generalization capabilities.\n\nThe dataset has been used in previous research and by the community to develop and validate computer vision algorithms and machine learning models aimed at automating the detection and classification of monkeypox-related skin conditions. By leveraging this dataset, researchers can gain insights into the visual characteristics of monkeypox and potentially contribute to the development of improved diagnostic tools and treatment strategies. The availability of such a comprehensive and specialized dataset promotes collaboration and facilitates advancements in the field of dermatology and infectious diseases.",
  "dataset/splits": "The dataset used in this study consists of 770 images. These images are divided into three primary splits: training, validation, and testing. The training set comprises 60% of the total images, the validation set includes 20%, and the testing set also contains 20%. This distribution ensures that the model is trained on a substantial portion of the data while reserving enough images for validation and testing to evaluate its performance accurately. The specific number of images in each split is as follows: 462 images for training, 154 images for validation, and 154 images for testing. This split allows for a comprehensive assessment of the model's ability to generalize from the training data to unseen validation and testing data.",
  "dataset/redundancy": "The dataset used in our study is the Monkeypox Skin Image Dataset, which is freely available on Kaggle. This dataset consists of 770 images, which were divided into three subsets: 60% for training, 20% for validation, and 20% for testing. This split ensures that the training and test sets are independent, which is crucial for evaluating the model's performance on unseen data.\n\nTo enforce the independence of the training and test sets, we carefully partitioned the dataset such that no images from the test set were included in the training or validation sets. This approach helps in assessing the model's generalization capability and prevents data leakage, which could otherwise lead to overoptimistic performance estimates.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets for similar tasks. The dataset provides a comprehensive visual representation of monkeypox, including images of skin lesions, rashes, and other related dermatological conditions. This diversity is essential for training robust models that can accurately detect and classify monkeypox cases.\n\nAdditionally, data augmentation techniques were applied to the training set to generate new images and prevent overfitting. This process increased the dataset size to 2500 images, enhancing the model's ability to generalize to new, unseen data. The augmentation techniques included flipping, rotation, shearing, and shifting, which helped in creating a more varied and representative training dataset.",
  "dataset/availability": "The dataset used in our study is publicly available and can be accessed through Kaggle. The Monkeypox Skin Image Dataset, which we adopted for our experiments, is freely accessible on the Kaggle platform. This dataset is a valuable resource for researchers and medical professionals studying the monkeypox virus and its impact on human health. It comprises a collection of high-resolution images depicting various stages and manifestations of monkeypox infection on human skin.\n\nThe dataset consists of 770 images, which are divided into three splits: 60% for training, 20% for validation, and 20% for testing. This division ensures that the model is trained, validated, and tested on distinct subsets of the data, promoting robust and generalizable performance.\n\nThe dataset is available under a license that allows for its use in research and development. Researchers can access the dataset by visiting the provided Kaggle link and following the instructions for data download and usage. The availability of this dataset in a public forum promotes collaboration and facilitates advancements in the field of dermatology and infectious diseases.\n\nTo enforce the proper use of the dataset, users are required to adhere to the terms and conditions specified by the dataset provider on Kaggle. This includes acknowledging the source of the data in any publications or presentations resulting from its use. By making the dataset publicly available and enforcing these guidelines, we aim to support the broader research community in their efforts to combat monkeypox and improve diagnostic tools.",
  "optimization/algorithm": "The optimization algorithm employed in our study is a decision tree classifier, which is a well-established machine-learning algorithm class. This classifier is optimized using a novel approach called the Dipper Throated Optimization (DTO) algorithm. The DTO algorithm is a population-based metaheuristic optimization technique designed to enhance the performance of the decision tree classifier by exploring all possible decision trees to improve classification accuracy.\n\nThe DTO algorithm is not a new machine-learning algorithm class but rather a new optimization technique tailored to improve the performance of existing classifiers. The decision to publish this work in a biomimetics journal, rather than a machine-learning journal, is driven by the focus of our research. Our study emphasizes the application of biomimetic principles to optimize machine-learning models for specific biomedical tasks, such as the classification of monkeypox images. This interdisciplinary approach aligns well with the scope and objectives of biomimetics journals, which often highlight innovative applications of nature-inspired methods in various scientific domains.",
  "optimization/meta": "The model presented in this publication does not function as a meta-predictor. Instead, it employs a combination of deep learning, transfer learning, and metaheuristic optimization techniques to enhance the performance of feature selection and classification methods for identifying skin lesions indicative of monkeypox.\n\nThe process begins with the use of deep learning and transfer learning approaches to extract relevant features from the data. Specifically, the GoogLeNet network is utilized within a deep learning framework to obtain the necessary features. These features are then refined using a binary form of the Dipper Throated Optimization (DTO) algorithm, which is a metaheuristic optimization approach.\n\nFollowing feature selection, a decision tree classifier is employed to classify the monkeypox images. The DTO algorithm is further used to optimize the decision tree classifier, aiming to discover the optimal decision tree model that improves classification accuracy. The efficacy of the optimized decision tree classifier is evaluated using various metrics, including accuracy, sensitivity, specificity, precision, recall, and F1-score.\n\nThe model does not integrate data from other machine-learning algorithms as input in a meta-predictor fashion. Instead, it focuses on optimizing the feature selection and classification processes through the use of advanced optimization techniques and deep learning methods. The training data used in this process is independent and specifically curated for the task of identifying monkeypox skin lesions.",
  "optimization/encoding": "In the optimization process, data encoding plays a crucial role in simplifying the problem and enhancing the efficiency of the feature selection algorithm. The continuous values of the input features are transformed into binary strings. This binary encoding is achieved by setting a threshold value, which determines which numbers are considered significant enough to be assigned binary values of 1 and 0, respectively. This step is essential as it reduces the search space, making the optimization problem more manageable.\n\nThe binary encoding method is particularly useful in feature selection tasks for machine learning, where the goal is to identify the most important characteristics from a large pool of data retrieved using deep neural networks. By converting continuous values into binary strings, the algorithm can more effectively evaluate and select the optimal subset of features.\n\nThis encoding process is a foundational step in the binary dipper throated optimization (bDTO) technique, which is inspired by the dipper bird's ability to dive deep into the water in pursuit of food. The binary encoding simplifies the optimization problem by reducing the search space, allowing the algorithm to focus on the most relevant features. This method has been shown to improve the performance of machine learning models by enhancing the accuracy and stability of the classification results.",
  "optimization/parameters": "In our study, the number of input parameters, denoted as p, refers to the features selected for the classification task. The initial set of features is extracted using deep learning frameworks, specifically GoogLeNet, which has been identified as the most effective among the networks tested. The features extracted by GoogLeNet are then subjected to a feature selection process using the binary dipper throated optimization (bDTO) algorithm.\n\nThe bDTO algorithm begins by encoding the continuous values of the input features into binary strings. This encoding simplifies the optimization problem by reducing the search space. During the initialization phase, a population of \"dipper birds\" is generated, where each bird represents a potential subset of features. The fitness function evaluates the quality of each feature subset, typically based on the accuracy of a classifier trained with that subset.\n\nThe selection of p, the number of features, is dynamic and determined through the optimization process. The bDTO algorithm iteratively refines the feature subsets by evaluating their fitness values. The optimal feature subset is chosen based on the fitness values, and this process continues until a stopping criterion is met. This criterion can be an absolute maximum runtime, a minimal increase in fitness value, or a combination of both.\n\nThe average select size, which indicates the typical number of features chosen by the algorithm, is one of the metrics used to assess the performance of the feature selection process. This metric provides an estimate of the model's complexity and the number of features required for acceptable performance. In our experiments, the average select size varied depending on the optimization algorithm used, with bDTO achieving the lowest average error and indicating the best performance among the other methods included in the experiment.",
  "optimization/features": "The input features for the classification task were initially extracted using deep learning frameworks, with GoogleNet being the most effective for identifying relevant features. Feature selection was performed to further refine the collected features. This process involved using various metrics such as best fitness, worst fitness, average error, average fitness, average select size, and standard deviation fitness to evaluate the performance of the chosen features.\n\nThe feature selection method employed was compared with other optimization algorithms, including binary particle swarm optimization (bPSO), binary whale optimization algorithm (bWOA), binary gray wolf optimization (bGWO), binary sine cosine (bSC), binary genetic algorithm (bGA), and binary firefly algorithm (bFA). The proposed feature selection method outperformed these other methods, demonstrating its superiority in selecting significant features necessary for classifying monkeypox cases.\n\nThe feature selection was conducted using the training set only, ensuring that the selected features were unbiased and generalizable to new, unseen data. This approach helped in achieving high classification performance, as evidenced by the improved accuracy, sensitivity, specificity, and F1-score after feature selection. The optimized decision tree classifier, which used the selected features as input, achieved an accuracy of 94.35%, indicating the effectiveness of the feature selection process.",
  "optimization/fitting": "The fitting method employed in this study involves a decision tree classifier optimized using the Dipper Throated Optimization (DTO) algorithm. This approach ensures that the model is both robust and generalizable, addressing concerns related to overfitting and underfitting.\n\nThe number of parameters in the decision tree model is inherently large due to the nature of tree-based algorithms, which can create complex structures with many splits. However, the DTO algorithm helps mitigate the risk of overfitting by systematically exploring the parameter space to find the optimal decision tree structure. This optimization process ensures that the model is not overly complex, thereby reducing the likelihood of overfitting.\n\nTo rule out overfitting, several metrics were evaluated, including accuracy, sensitivity, specificity, precision, recall, and F1-score. The results showed that the optimized decision tree classifier achieved high performance across these metrics, indicating that the model generalizes well to unseen data. Additionally, the feature selection process, which involved evaluating metrics such as best fitness, worst fitness, average error, average fitness, average select size, and standard deviation fitness, further ensured that only the most relevant features were used. This step is crucial in preventing the model from becoming too complex and overfitting the training data.\n\nConversely, underfitting was ruled out by ensuring that the model was sufficiently complex to capture the underlying patterns in the data. The DTO algorithm's ability to explore a wide range of possible decision trees allowed for the selection of a model that balanced complexity and performance. The classification results before and after feature selection demonstrated improved performance, with the optimized model achieving an accuracy of 94.35%. This indicates that the model is neither too simple nor too complex, thereby avoiding underfitting.\n\nIn summary, the fitting method employed in this study effectively addresses both overfitting and underfitting by leveraging the DTO algorithm for optimization and rigorous evaluation of performance metrics. This ensures that the decision tree classifier is robust, generalizable, and capable of accurately classifying monkeypox images.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was feature selection. By carefully selecting the most relevant features, we reduced the complexity of the model and minimized the risk of overfitting. This process involved using optimization algorithms to identify the most informative features, which significantly improved the model's generalization ability.\n\nAdditionally, we conducted extensive validation and testing to assess the stability and accuracy of our results. This included comparing the performance of our proposed methodology against other optimization algorithms. The histogram of accuracy achieved by our approach demonstrated high classification accuracy across most test cases, indicating the stability and reliability of our method.\n\nStatistical analyses, such as the analysis of variance (ANOVA) test, were performed to evaluate the significance of our feature selection algorithm. The results showed that our proposed algorithm differed significantly from other feature selection methods, further confirming its effectiveness in preventing overfitting.\n\nOverall, these techniques ensured that our models were not only accurate but also generalizable to new, unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model we proposed is not a black box. We have incorporated several techniques to ensure interpretability and transparency. One of the key aspects of our model's interpretability is the use of feature extraction and selection processes. By extracting relevant features from the input images and selecting the most informative ones, we can provide insights into what the model is focusing on to make its predictions. This is particularly important in medical diagnostics, where understanding the model's decision-making process can build trust among medical professionals.\n\nAdditionally, we utilized an optimized decision tree classifier, which is inherently interpretable. Decision trees break down the decision-making process into a series of if-then statements, making it easy to trace the path from input features to the final prediction. This transparency allows medical professionals to understand how the model arrives at its conclusions, which is crucial for diagnosing monkeypox accurately.\n\nWe also emphasized the importance of visualization in our approach. By visualizing the results and the decision-making process, we can provide clear examples of how the model interprets the input data. This includes showing which features are most influential in the classification process and how the model differentiates between monkeypox and non-monkeypox cases. Visualization tools help in making the model's internal workings more accessible and understandable, further enhancing its transparency.\n\nIn summary, our model's interpretability is achieved through feature extraction and selection, the use of decision trees, and visualization techniques. These elements work together to ensure that the model is not a black box but a transparent tool that can be trusted and understood by medical professionals.",
  "model/output": "The model discussed in this publication is a classification model. It is designed to identify and categorize cases of monkeypox using machine learning techniques. The primary goal is to classify images into categories that indicate the presence or absence of monkeypox.\n\nThe model employs a decision tree classifier, which is optimized using the DTO algorithm, a population-based metaheuristic optimization approach. This optimization aims to find the best decision tree model by exploring various possible decision trees to enhance classification accuracy.\n\nThe performance of the model is evaluated using several metrics, including accuracy, precision, recall, and F1-score. These metrics are derived from the confusion matrix, which compares predicted labels to actual labels. The confusion matrix includes true positives, true negatives, false positives, and false negatives, providing a comprehensive view of the model's classification performance.\n\nThe proposed model achieved an accuracy of 94.35%, which is higher than the accuracy obtained when the decision tree was optimized without the proposed feature selection method. This indicates that the model is effective in classifying monkeypox images accurately.\n\nThe model's performance was compared to other deep learning models such as AlexNet, ResNet50, and GoogLeNet, all of which were pre-trained. The proposed model outperformed these models in terms of accuracy, precision, recall, and F1-score, demonstrating its superiority in monkeypox detection.\n\nThe model's effectiveness was further validated by its performance on both training and test sets, showing its potential as a valuable tool for efficient clinical diagnosis. The use of both unaltered and enriched training data helped in improving the model's performance, especially when fewer instances were available.\n\nIn summary, the model is a classification model designed to detect monkeypox with high accuracy and efficiency. It utilizes an optimized decision tree classifier and has shown promising results in comparison to other deep learning models.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed methodology involved several key steps and metrics to ensure its robustness and effectiveness. The deep learning models used in this research were trained, tested, and validated using a specific dataset. The evaluation criteria included measures such as accuracy, precision, recall, and F1-score, which were computed using the confusion matrix. This matrix compares predicted labels to genuine ones, categorizing results into true positives, true negatives, false positives, and false negatives.\n\nTo assess the feature extraction process, various deep learning frameworks were evaluated. The results indicated that the features extracted using GoogleNet outperformed other deep networks in terms of accuracy, sensitivity, specificity, and F1-score, while maintaining a low p-value. This network was subsequently adopted for further steps in the proposed methodology.\n\nThe feature selection process was evaluated using metrics such as best fitness, worst fitness, average error, average fitness, average select size, and standard deviation of fitness. These metrics provided insights into the performance, complexity, and reliability of the selected feature subsets. The proposed feature selection method, compared to other optimization algorithms like binary particle swarm optimization (bPSO), binary whale optimization algorithm (bWOA), binary gray wolf optimization (bGWO), binary sine cosine (bSC), binary genetic algorithm (bGA), and binary firefly algorithm (bFA), demonstrated superior performance. It achieved the lowest average error, indicating the best performance among the other methods included in the experiment.\n\nStatistical analysis was conducted to study the properties of the proposed methodology. This included an analysis of variance (ANOVA) test and a Wilcoxon signed-rank test. The ANOVA test results showed a significant difference between the proposed classification approach and other methods, with a high F-value and a p-value less than 0.0001. The Wilcoxon signed-rank test further confirmed the statistical significance of the proposed methodology, with p-values less than 0.0001 for all comparisons.\n\nAdditionally, the performance of the proposed model was evaluated in terms of accuracy, precision, recall, and F1-score. The model achieved the highest accuracy score of 94.35%, outperforming other deep learning models like AlexNet, ResNet50, and GoogLeNet. The model's performance was also assessed using augmented data, which helped improve its robustness and generalizability. The proposed model showed promise as a valuable tool for the rapid and accurate diagnosis of monkeypox in clinical settings, potentially improving patient outcomes and reducing healthcare costs.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report several key metrics to evaluate the classification performance of our proposed method for monkeypox detection. These metrics include accuracy, precision, recall, F1-score, sensitivity, specificity, p-Value, and N-Value. Accuracy measures the overall correctness of the model's predictions, while precision and recall focus on the performance of the positive class predictions. The F1-score provides a balanced measure of precision and recall, especially useful when the costs of false negatives and false positives are equivalent. Sensitivity, also known as recall, indicates the model's ability to correctly identify positive cases, whereas specificity measures the model's ability to correctly identify negative cases. The p-Value assesses the statistical significance of the results, and the N-Value indicates the number of features considered.\n\nThese metrics are widely used in the literature for evaluating classification models, making our set of metrics representative and comprehensive. They provide a thorough assessment of the model's performance, covering various aspects of classification accuracy and reliability. By including these metrics, we ensure that our evaluation is robust and comparable to other studies in the field. This approach allows us to demonstrate the effectiveness and superiority of our proposed method in detecting monkeypox cases.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our proposed feature selection method against several other optimization algorithms, including binary particle swarm optimization (bPSO), binary whale optimization algorithm (bWOA), binary gray wolf optimization (bGWO), binary sine cosine (bSC), binary genetic algorithm (bGA), and binary firefly algorithm (bFA). This comparison was conducted using a set of evaluation criteria, such as best fitness, worst fitness, average error, average fitness, average select size, and standard deviation of fitness. The results, presented in Table 3, demonstrate that our proposed method outperforms the other feature selection methods in terms of achieving the lowest average error, indicating superior performance.\n\nAdditionally, we performed a statistical analysis using the analysis of variance (ANOVA) test to assess the significance of the differences between our proposed method and the other feature selection approaches. The ANOVA results, shown in Table 4, reveal a highly significant F-value and a very low p-value, suggesting that the variation in the outcome measure is primarily due to the feature selection technique used. This statistical evidence supports the effectiveness of our proposed method in selecting a significant set of features necessary for classifying monkeypox cases.\n\nFurthermore, we conducted an additional experiment to study the statistical properties of our proposed methodology compared to other methodologies used in optimizing the decision tree classifier. The results of this experiment, presented in Tables 7, 8, and 9, confirm the statistical difference between our proposed classification approach and the other approaches. The Wilcoxon signed-rank test results, in particular, indicate that our method achieves a higher median value and a significant p-value, further validating its superiority.\n\nIn summary, our evaluation involved a comprehensive comparison with publicly available methods and simpler baselines, demonstrating the robustness and effectiveness of our proposed feature selection method. The statistical analyses and performance metrics consistently show that our approach outperforms existing methods, making it a promising tool for feature selection in classification tasks.",
  "evaluation/confidence": "In the evaluation of our proposed methodology, we have conducted a thorough statistical analysis to ensure the robustness and significance of our results. To assess the confidence in our performance metrics, we have employed several statistical tests.\n\nFirstly, we performed an analysis of variance (ANOVA) test to compare the proposed methodology with other optimization algorithms used for the decision tree classifier. The ANOVA results, presented in the relevant table, show a significant F-value with a p-value less than 0.0001. This indicates that there is a statistically significant difference between the proposed method and the other approaches, confirming the superiority of our methodology.\n\nAdditionally, we conducted a Wilcoxon signed-rank test to further validate the statistical significance of our results. The Wilcoxon test results, also presented in the relevant table, show a p-value of 0.0001 for each comparison, which is well below the typical significance level of 0.05. This provides strong evidence that the differences observed are not due to random chance.\n\nFurthermore, we have included confidence intervals for the median values of our performance metrics. The 95% confidence intervals for the median are provided, showing a high actual confidence level of 98.71%. This indicates that we can be highly confident in the median values reported for our methodology.\n\nThe plots, including residual, homoscedasticity, QQ, and heat map, also support the significance of our findings. These visualizations confirm the statistical difference and the reliability of our proposed approach.\n\nIn summary, the performance metrics have associated confidence intervals, and the results are statistically significant. The ANOVA and Wilcoxon tests, along with the provided confidence intervals and visualizations, strongly support the claim that our proposed methodology is superior to other approaches and baselines.",
  "evaluation/availability": "Not enough information is available."
}