{
  "publication/title": "Comparison of Predictive Models for Keloid Recurrence Based on Machine Learning",
  "publication/authors": "The authors who contributed to the article are:\n\nYan Hao, Mengjie Shan, Hao Liu, Yijun Xia, Xinwen Kuang, Kexin Song, and Youbin Wang.\n\nYan Hao and Youbin Wang performed the research. Mengjie Shan, Hao Liu, and Youbin Wang designed the research study. Yan Hao and Xinwen Kuang contributed essential reagents or tools. Yijun Xia and Kexin Song analyzed the data. Yan Hao wrote the paper.",
  "publication/journal": "Journal of Cosmetic Dermatology",
  "publication/year": "2025",
  "publication/pmid": "39918034",
  "publication/pmcid": "PMC11803684",
  "publication/doi": "10.1111/jocd.70008",
  "publication/tags": "- keloid\n- machine learning\n- prediction model\n- recurrence\n- risk factors\n- logistic regression\n- decision tree\n- random forest\n- postoperative complications\n- inflammatory cells",
  "dataset/provenance": "The dataset used in this study was sourced from clinical data gathered from patients treated for keloids at the Department of Plastic and Cosmetic Surgery at Peking Union Medical College Hospital. The data collection period spanned from January 2015 to January 2019. Initially, data from 399 patients were gathered. However, after excluding patients with incomplete or low-quality follow-up data, the final dataset included 301 patients.\n\nThe dataset comprises 17 predictor variables, which include gender, age, surgical procedure, initial treatment status, history of infections, etiology, surgical site, postoperative complications, mean arterial pressure, body mass index, keloid activity assessment scale, preoperative white blood cell count, lymphocyte percentage, neutrophil percentage, monocyte percentage, eosinophil percentage, and hemoglobin levels. The outcome variable considered was the occurrence of keloid recurrence within a 2-year timeframe.\n\nThis dataset has not been previously used in other published papers or by the community, as it is specific to this study. The data was collected and curated specifically for the purpose of building and evaluating predictive models for keloid recurrence.",
  "dataset/splits": "The dataset was split into two parts: a training set and a testing set. The training set comprised 70% of the data, while the testing set contained the remaining 30%. Specifically, the training set consisted of 212 data points, and the testing set had 89 data points. This split was achieved using the 'createDataPartition' function from the 'caret' package in R.",
  "dataset/redundancy": "The dataset was split into a training set and a testing set using the 'createDataPartition' function from the 'caret' package in R. The dataset was randomly divided, with 70% of the data allocated to the training set and 30% to the testing set. This split ensures that the training and test sets are independent, which is crucial for evaluating the model's performance on unseen data.\n\nThe random splitting process helps to mitigate the risk of data leakage and overfitting, as the model is trained on one subset of the data and evaluated on a completely separate subset. This approach is standard in machine learning practices to ensure that the model's performance is generalizable to new, unseen data.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in similar domains. The use of a 70-30 split is a common practice that balances the need for a sufficiently large training set to learn patterns while reserving a significant portion for robust testing and validation. This method ensures that the model's performance metrics, such as accuracy, sensitivity, and specificity, are reliable and not overly optimistic due to overfitting.",
  "dataset/availability": "The data that support the findings of this study are available on request from the corresponding author. The data are not publicly available due to privacy or ethical restrictions. This means that the dataset, including the specific splits used for training and testing, is not released in a public forum. Instead, interested parties can request access to the data from the corresponding author. This approach ensures that the data is handled in accordance with privacy and ethical guidelines, preventing unauthorized access or misuse. The enforcement of these restrictions is managed through the request process, where the corresponding author reviews and approves access on a case-by-case basis.",
  "optimization/algorithm": "The machine-learning algorithms used in this study fall under the category of supervised learning models. These models are designed to learn relationships between data points using annotated training data, making them suitable for classification problems such as predicting disease recurrence.\n\nThe specific algorithms employed include logistic regression, decision trees, and random forests. Logistic regression is a straightforward and effective classification model that predicts binary outcomes based on various patient factors. It is known for its high computational efficiency and interpretability, making it a valuable tool for identifying risk factors and visualizing probability plots.\n\nDecision trees, on the other hand, use a tree-like structure to handle nonlinear data through a series of binary decisions. This model is intuitive and easy to understand, allowing for clear visualization and interpretation of the decision-making process. Decision trees can be adjusted and optimized as needed, providing flexibility in model development.\n\nRandom forests are an ensemble model that combines multiple decision trees. By randomly selecting features and samples, random forests create a robust model that can handle high-dimensional data and is particularly effective in dealing with noisy data. This ensemble approach enhances the model's predictive performance and generalizability.\n\nThese algorithms are well-established in the field of machine learning and have been widely applied in various medical research studies. They were chosen for their ability to handle the specific characteristics of the dataset and their proven effectiveness in predictive modeling. The decision to use these algorithms was based on their suitability for the research objectives and the need for a comparative analysis to determine the optimal model for predicting keloid recurrence.",
  "optimization/meta": "The models developed in this study do not utilize data from other machine-learning algorithms as input. Instead, they are built using a variety of predictor variables collected from patient data. These variables include gender, age, surgical procedure, history of infections, surgical site, postoperative complications, mean arterial pressure, body mass index, keloid activity assessment scale, and various blood test results.\n\nThe study employs three distinct predictive models for keloid recurrence: logistic regression, decision tree, and random forest. Each of these models is trained and evaluated independently using the same dataset, which is split into training and testing sets. The logistic regression model is a simple and effective classification model that predicts the likelihood of keloid recurrence based on various patient factors. The decision tree model uses a tree-like structure to classify data through a series of binary decisions, making it intuitive and easy to interpret. The random forest model is an ensemble of decision trees, which enhances its robustness and ability to handle high-dimensional and noisy data.\n\nThe training data for each model is derived from a dataset of 301 patients, ensuring that the data used for training is independent and not influenced by the outputs of other machine-learning algorithms. This independence is crucial for the validity and reliability of the models. The performance of each model is evaluated using various metrics, including accuracy, sensitivity, specificity, recall, precision, and the area under the receiver operating characteristic curve (AUC). The logistic regression model demonstrated the highest AUC, indicating its strong overall performance in predicting keloid recurrence. The decision tree model showed the highest accuracy and sensitivity, while the random forest model performed well in handling complex and noisy data.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of the machine-learning algorithms. We began by collecting clinical data from 301 patients who underwent treatment for keloids. The dataset included 17 predictor variables, such as gender, age, surgical procedure, history of infections, surgical site, postoperative complications, mean arterial pressure, body mass index, keloid activity assessment scale, and various blood cell counts.\n\nFor the logistic regression model, we used the 'tableStack' function from the 'epiDisplay' package to conduct univariate analysis on all predictor variables in the training set. Variables with a p-value less than 0.05 were selected as feature variables. We then employed the 'dplyr' and 'GGally' packages to visualize the correlations among the selected feature variables. The 'rms' package was used to perform multivariate regression analysis, and variables with a p-value less than 0.05 were included in the logistic regression model.\n\nFor the decision tree model, we utilized the 'rpart' package to build the model in the training set. To reduce overfitting, we applied the 'prune' function to the initial model. The 'rpart.plot' function was used for visualizing the decision tree model.\n\nFor the random forest model, we employed the 'randomForest' package. The 'varImpPlot' function was used to create a plot illustrating the ranking of variable importance. This helped in understanding which variables contributed most to the predictions made by the model.\n\nAll statistical analysis, model building, and visualization were conducted using the R software package (version 4.1.3). The dataset was randomly split into a training set (70%) and a testing set (30%) using the 'createDataPartition' function from the 'caret' package. This split ensured that the models were trained on a representative subset of the data and tested on an independent subset to evaluate their performance accurately.",
  "optimization/parameters": "In our study, we utilized 17 predictor variables as input parameters for our models. These variables included gender, age, surgical procedure, whether it was the initial treatment, history of infections, whether the etiology was iatrogenic, surgical site, postoperative complications, mean arterial pressure (MAP), body mass index (BMI), keloid activity assessment scale (KAAS), preoperative white blood cell count, lymphocyte percentage, neutrophil percentage, monocyte percentage, eosinophil percentage, and hemoglobin levels.\n\nThe selection of these parameters was based on a comprehensive review of relevant clinical data and literature. We aimed to include variables that were clinically significant and had the potential to influence the outcome of keloid recurrence. The dataset was gathered from 301 patients who underwent treatment for keloids, ensuring a robust and diverse set of input parameters for our models.\n\nFor the logistic regression model, univariate analysis was conducted on all predictor variables in the training set. Variables with a p-value less than 0.05 were selected as feature variables. This process ensured that only statistically significant variables were included in the multivariate regression analysis.\n\nIn the decision tree model, the 'rpart' package was utilized to build the initial model, and pruning was applied to reduce overfitting. The pruned model highlighted KAAS, MAP, and white blood cell count as the most important feature variables.\n\nThe random forest model, built using the 'randomForest' package, identified KAAS, MAP, and preoperative inflammatory status as key features. The importance of these variables was visualized using the 'varImpPlot' function, which ranked the variables based on their contribution to the model's accuracy and Gini index.\n\nOverall, the selection of input parameters was driven by a combination of clinical relevance and statistical significance, ensuring that our models were built on a solid foundation of meaningful and impactful variables.",
  "optimization/features": "In the optimization process of our models, we initially considered 17 predictor variables as potential input features. These features encompassed a range of clinical and demographic factors, including gender, age, surgical procedure details, treatment history, infection history, etiology, surgical site, postoperative complications, mean arterial pressure (MAP), body mass index (BMI), keloid activity assessment scale (KAAS), preoperative white blood cell count, and various blood cell percentages (lymphocyte, neutrophil, monocyte, eosinophil) along with hemoglobin levels.\n\nFeature selection was indeed performed to identify the most relevant variables for predicting keloid recurrence. This selection process was conducted using the training set only, ensuring that the testing set remained unbiased. The 'tableStack' function from the 'epiDisplay' package was utilized to perform univariate analysis on all predictor variables within the training set. Variables that exhibited a p-value of less than 0.05 were deemed statistically significant and were selected as feature variables for further analysis.\n\nSubsequently, the 'dplyr' and 'GGally' packages were employed to visualize the correlations among the selected feature variables. This step helped in understanding the relationships between different features and their potential impact on the outcome variable. The 'rms' package was then used to perform multivariate regression analysis on the feature variables in the training set, further refining the selection by including only those variables with a p-value of less than 0.05 in the final logistic regression model. This rigorous feature selection process ensured that the models were built using the most relevant and statistically significant predictors, enhancing their predictive performance and generalizability.",
  "optimization/fitting": "In our study, we employed three distinct machine learning models to predict keloid recurrence: logistic regression, decision tree, and random forest. Each model was built and evaluated using a dataset split into training and testing sets, with the training set comprising 70% of the data.\n\nThe decision tree model, known for its ability to capture complex interactions among variables, initially included a multitude of variables. However, to mitigate the risk of overfitting, which is a common issue with decision trees due to their tendency to incorporate many variables, we applied pruning. This technique helps to simplify the model by removing sections that provide little power in classifying instances, thereby enhancing its generalization to new data.\n\nThe random forest model, which aggregates multiple decision trees, inherently reduces overfitting by averaging the results of many trees. This ensemble method is robust in handling high-dimensional and noisy data, making it less prone to overfitting compared to a single decision tree. Additionally, we performed variable importance analysis to identify key features, ensuring that the model focused on the most relevant predictors.\n\nFor the logistic regression model, we conducted univariate and multivariate analyses to select significant variables. This approach helped in avoiding underfitting by ensuring that the model included relevant predictors. The logistic regression model, while simpler, provided a high AUC, indicating a good balance between sensitivity and specificity.\n\nTo further validate our models and rule out overfitting, we evaluated their performance on a separate testing set, which was not used during the training phase. This step is crucial for assessing the models' generalizability to new, unseen data. Additionally, we used bootstrapping methods to evaluate the best-performing model, providing a more robust estimate of its performance.\n\nIn summary, we addressed the risk of overfitting through pruning in the decision tree model, ensemble learning in the random forest model, and careful variable selection in the logistic regression model. The use of a separate testing set and bootstrapping methods ensured that our models were not overfitted and could generalize well to new data.",
  "optimization/regularization": "In our study, we employed regularization techniques to prevent overfitting, particularly in the decision tree model. Decision trees are known for their tendency to incorporate a multitude of variables, which can lead to overfitting. To mitigate this issue, we performed pruning on the decision tree model. Pruning involves removing sections of the tree that provide little power in classifying instances. This process helps to simplify the model, making it more generalizable to new data. After pruning, the model highlighted key feature variables such as KAAS, MAP, and white blood cell count as the most important, indicating that these factors are crucial in predicting keloid recurrence. This regularization method ensured that our model was robust and not overly complex, thereby improving its predictive performance.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models employed in this study exhibit varying degrees of interpretability, ranging from highly transparent to more complex, ensemble-based approaches.\n\nThe decision tree model is particularly notable for its transparency. It operates based on a tree-like structure, making decisions through a series of binary splits. Each node in the tree represents a decision based on a feature, and the branches represent the possible outcomes of those decisions. This structure allows for easy visualization and interpretation. For instance, the decision tree can clearly show which features, such as the keloid activity assessment scale (KAAS) or mean arterial pressure (MAP), are most influential in predicting keloid recurrence. This transparency makes it intuitive to understand the decision-making process and the importance of various features.\n\nThe random forest model, while more complex, also offers some level of interpretability. It consists of multiple decision trees, each contributing to the final prediction through voting or averaging. Although individual trees can be examined, the ensemble nature of the model makes it less straightforward to interpret compared to a single decision tree. However, feature importance can still be derived from the random forest, indicating which variables, such as KAAS and MAP, are most significant in the prediction process.\n\nLogistic regression, another model used, is also highly interpretable. It provides a clear relationship between the input features and the output probability of recurrence. The coefficients in the logistic regression model indicate the strength and direction of the relationship between each feature and the outcome. For example, the model can show how changes in neutrophil or lymphocyte percentages affect the likelihood of keloid recurrence. This makes it easier to understand the impact of individual features on the prediction.\n\nIn summary, while the decision tree and logistic regression models offer high levels of transparency, the random forest model, though more complex, still provides insights into feature importance. This range of interpretability allows for a comprehensive understanding of the factors influencing keloid recurrence predictions.",
  "model/output": "The model employed in this study is a classification model. Specifically, it is designed to predict the recurrence of keloids after surgical intervention and postoperative radiation therapy. The outcome variable is binary, indicating whether recurrence occurs within a 2-year timeframe. This makes it a binary classification problem.\n\nThree different models were developed and compared: logistic regression, decision tree, and random forest. Each model was evaluated using various performance metrics, including accuracy, sensitivity, specificity, recall, precision, kappa coefficient, and the area under the receiver operating characteristic curve (AUC). These metrics provide a comprehensive assessment of the models' predictive capabilities.\n\nThe decision tree model demonstrated the highest accuracy and sensitivity, indicating its effectiveness in identifying patients at risk of keloid recurrence. However, decision trees can be prone to overfitting, so pruning was performed to mitigate this issue. The pruned decision tree highlighted key feature variables such as the keloid activity assessment scale (KAAS), mean arterial pressure (MAP), and white blood cell count.\n\nThe random forest model, known for its robustness in handling high-dimensional and noisy data, performed well in both accuracy and sensitivity. It identified important features like KAAS, MAP, and preoperative inflammatory status, which are crucial for predicting recurrence risk.\n\nThe logistic regression model, while not the top performer in accuracy or sensitivity, had the highest AUC. This suggests that it balances sensitivity and specificity effectively, making it a strong contender for overall model performance. The univariate analysis in logistic regression revealed that neutrophil and lymphocyte percentages had statistical differences with recurrence, although these differences were not significant in multivariate analysis.\n\nIn summary, the models developed for predicting keloid recurrence are classification models. They were evaluated using standard metrics to determine their effectiveness, with each model showing unique strengths and areas of improvement.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed for the models involved a comprehensive assessment using the test dataset. The 'caret' package was utilized to evaluate model performance through confusion matrices, which allowed for the calculation of various metrics including accuracy, sensitivity, specificity, recall, precision, and the kappa coefficient. These metrics provided a detailed understanding of how well each model performed in predicting keloid recurrence.\n\nAdditionally, the 'pROC' package was used to compute the Area Under the Curve (AUC) and create Receiver Operating Characteristic (ROC) curves for the three models. The AUC is a critical metric that indicates the overall performance of the models, with higher values signifying better reliability. The ROC curves visually represent the trade-off between sensitivity and specificity across different threshold settings.\n\nThe best-performing model was further evaluated using the bootstrapping method, which involved resampling the data with replacement to create multiple simulated samples. This technique helped to assess the stability and robustness of the model's predictions.\n\nThe evaluation process also included a comparison of the models based on their performance metrics. The decision tree model demonstrated the highest accuracy and sensitivity, indicating its effectiveness in correctly identifying positive cases. However, it was also noted that decision trees can be prone to overfitting, which was addressed through pruning. The random forest model, known for its robustness, performed well in handling high-dimensional and noisy data, ranking second in accuracy and sensitivity. The logistic regression model, while not the highest in accuracy or sensitivity, had the highest AUC, suggesting its strength in balancing sensitivity and specificity.\n\nOverall, the evaluation method provided a thorough assessment of the models' predictive performance, highlighting their strengths and areas for improvement. This comprehensive evaluation is essential for ensuring the reliability and applicability of the models in clinical settings.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the predictive models for keloid recurrence. These metrics included accuracy, sensitivity, specificity, recall, precision, kappa coefficient, and the area under the receiver operating characteristic curve (AUC).\n\nAccuracy measures the overall correctness of the model's predictions, representing the probability of correctly predicting all samples. However, it can be misleading in cases of severe class imbalance.\n\nSensitivity, also known as recall for the positive class, indicates the model's ability to correctly identify positive instances, which in our context is the recurrence of keloids. It is crucial for understanding how well the model can detect true positive cases.\n\nSpecificity measures the model's ability to correctly identify negative instances, or non-recurrence cases. It is essential for assessing the model's performance in avoiding false positives.\n\nPrecision focuses on the correctness of the positive predictions made by the model. It is particularly important when the cost of false positives is high.\n\nThe kappa coefficient assesses the agreement between the predicted and actual outcomes, adjusting for the agreement that could be expected by chance. It provides a more robust measure of agreement, especially when dealing with imbalanced datasets.\n\nThe AUC provides a single scalar value that summarizes the performance of the model across all classification thresholds. It is particularly useful for comparing the overall performance of different models.\n\nThese metrics collectively offer a thorough evaluation of the models' predictive performance, ensuring that we capture various aspects of their effectiveness. The choice of these metrics is aligned with standard practices in the literature, providing a representative and comprehensive assessment of the models' capabilities.",
  "evaluation/comparison": "In our study, we did not perform a comparison to publicly available methods on benchmark datasets. Instead, we focused on developing and evaluating three specific predictive models\u2014logistic regression, decision tree, and random forest\u2014for predicting keloid recurrence after surgical intervention and postoperative radiation therapy.\n\nWe did, however, compare these models to simpler baselines. The logistic regression model served as a baseline due to its simplicity and effectiveness in handling binary classification problems. It provided a foundational comparison for more complex models like the decision tree and random forest.\n\nThe decision tree model was chosen for its ability to handle nonlinear data and provide interpretable results through a tree-like structure. This model allowed us to understand the decision-making process and visualize the structure and attributes of the decision tree.\n\nThe random forest model, an ensemble of decision trees, was included to handle high-dimensional data and demonstrate robustness in dealing with noisy data. This model provided a more complex baseline compared to the decision tree and logistic regression models.\n\nBy evaluating these models using various performance metrics such as accuracy, sensitivity, specificity, recall, precision, and the area under the receiver operating characteristic (ROC) curve (AUC), we were able to determine the strengths and weaknesses of each model. This comparative analysis helped us identify the most effective model for predicting keloid recurrence.",
  "evaluation/confidence": "The evaluation of the models included the calculation of various performance metrics such as accuracy, sensitivity, specificity, recall, precision, and the kappa coefficient. These metrics were computed using the 'caret' package, which provides robust tools for assessing model performance. Additionally, the area under the curve (AUC) and receiver operating characteristic (ROC) curves were generated using the 'pROC' package. The AUC values, in particular, are crucial as they provide a comprehensive measure of model performance, especially in scenarios where balancing sensitivity and specificity is essential.\n\nThe AUC values for the models were reported with their corresponding 95% confidence intervals (CIs). For instance, the logistic regression model had an AUC of 0.857 with a 95% CI of 0.782\u20130.931, indicating a high level of confidence in its performance. Similarly, the decision tree model had an AUC of 0.770 with a 95% CI of 0.657\u20130.883, and the random forest model had an AUC of 0.816 with a 95% CI of 0.73\u20130.902. These confidence intervals suggest that the models' performance metrics are statistically significant and reliable.\n\nTo further validate the robustness of the logistic regression model, a bootstrapping method was employed. This technique involves resampling the data with replacement to create multiple simulated samples, which are then used to estimate the model's performance. The results of the bootstrapping method provided additional confidence in the model's predictive capabilities.\n\nThe statistical significance of the models was also assessed through univariate and multivariate analyses. In the univariate analysis, several feature variables, such as age, KAAS, postoperative complications, etiology, neutrophil percentage, and lymphocyte percentage, showed statistical differences with recurrence (p < 0.05). In the multivariate regression analysis, KAAS and the occurrence of postoperative complications exhibited p < 0.05, indicating their strong association with the risk of recurrence. These findings support the claim that the models are superior in predicting keloid recurrence compared to baselines that do not consider these critical factors.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The data that support the findings of this study are available on request from the corresponding author. The data are not publicly available due to privacy or ethical restrictions."
}