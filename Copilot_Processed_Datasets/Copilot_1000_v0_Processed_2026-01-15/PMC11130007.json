{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to the article are:\n\n- N. Schr\u00f6ter\n- A. Rau\n- P. G. Arnold\n- J. A. Hosp\n- M. Rijntjes\n- W. H. Jost\n- C. Weiller\n- M. Reisert\n- E. Kellner\n- H. Urbach\n\nA. Rau was supported by the Berta-Ottenstein-Programme for Clinician Scientists, Faculty of Medicine, University of Freiburg. N. Schr\u00f6ter received grants from the Berta-Ottenstein-Programme for Clinician Scientists, Faculty of Medicine, University of Freiburg, and honoraria from AbbVie. M. Reisert received honoraria from AbbVie. E. Kellner is a shareholder of and receives fees from VEObrain GmbH. H. Urbach is co-editor of Clinical Neuroradiology, member of the Advisory Board of Biogen and received honoraria for lectures from Biogen, Eisai, and mbits. P. G. Arnold, J. A. Hosp, M. Rijntjes, W. H. Jost, and C. Weiller declare that they have no competing interests.",
  "publication/journal": "Neuroimage",
  "publication/year": "2023",
  "publication/pmid": "38289378",
  "publication/pmcid": "PMC11130007",
  "publication/doi": "https://doi.org/10.1007/s00062-023-01377-w",
  "publication/tags": "- Neurodegenerative Parkinson syndromes\n- MRI\n- Microstructural imaging\n- Macrostructural imaging\n- Support vector machine (SVM)\n- Diffusion tensor imaging (DTI)\n- Neurite orientation dispersion and density imaging (NODDI)\n- Diffusion microstructure imaging (DMI)\n- Parkinson's disease (PD)\n- Multiple system atrophy (MSA)\n- Progressive supranuclear palsy (PSP)\n- Healthy controls (HC)\n- Diagnostic performance\n- Artificial intelligence in medical imaging\n- Multicompartmental models\n- Biophysically motivated models\n- Mesoscopic approach\n- Tissue probability values\n- Diagnostic classification\n- Neuroimaging biomarkers",
  "dataset/provenance": "The dataset used in this study consists of MRI data from 209 patients diagnosed with neurodegenerative parkinsonian syndromes (NPS), including Parkinson's disease (PD), multiple system atrophy (MSA), and progressive supranuclear palsy (PSP). Additionally, the dataset includes 27 age-matched and sex-matched healthy controls (HC) from an in-house control cohort. The MRI data were collected between January 2018 and December 2021. The inclusion workflow and further characteristics of the participants are detailed in the study.\n\nThe MRI data were acquired using a 3-Tesla scanner with a 64-channel head and neck coil. The imaging protocol included high-resolution T1-weighted (T1w) and multishell diffusion MRI data. The T1w images were obtained using a 3D magnetization-prepared 180\u00b0 radiofrequency pulses and rapid gradient-echo (MP-RAGE) sequence, while the diffusion-weighted sequence was acquired with specific parameters to ensure high-quality data.\n\nThe dataset was split into a training cohort and a test subset in a 4:1 ratio, matched in terms of age, sex, and diagnoses. The training cohort consisted of 196 participants (115 PD, 35 MSA, 25 PSP, and 21 HC), and the test subset included 40 participants (21 PD, 6 MSA, 7 PSP, and 6 HC). This split ensured that the models could be trained and validated effectively.\n\nThe MRI data were processed using a local instance of the NORA platform. The T1w imaging datasets were automatically segmented into white and gray matter using CAT12. Diffusion-weighted images were rigidly coregistered to the T1w images using the SPM toolbox. Preprocessing of diffusion-weighted images included denoising, correction of Gibbs ringing artifacts, and upsampling to an isotropic resolution of 1.5 mm\u00b3.\n\nThe dataset has not been used in previous publications by the community, but the methods and tools employed, such as CAT12 and the SPM toolbox, are widely recognized and utilized in the field of neuroimaging. The study aims to demonstrate the complementary value of microstructural and macrostructural MRI in the discrimination of neurodegenerative parkinsonian syndromes.",
  "dataset/splits": "The dataset was split into two main subsets: a training cohort and a test cohort. The training cohort consisted of 196 participants, which included 115 patients with Parkinson\u2019s disease (PD), 35 with multiple system atrophy (MSA), 25 with progressive supranuclear palsy (PSP), and 21 healthy controls (HC). The test cohort comprised 40 participants, with 21 PD patients, 6 MSA patients, 7 PSP patients, and 6 HCs. The splits were matched in terms of age, sex, and diagnoses to ensure comparability between the training and test subsets.",
  "dataset/redundancy": "The dataset was split into training and test subsets in a 4:1 ratio. This split was done randomly but ensured that the subsets were matched in terms of age, sex, and diagnoses. The study included MRI data from 209 patients with neurodegenerative Parkinson syndromes (NPS) and 27 healthy controls (HC). The training and test sets were designed to be independent to prevent data leakage and ensure that the model's performance could be generalized to new, unseen data. This independence was enforced by the random split and matching process, which aimed to reflect the expected distribution of diagnoses in clinical practice. The distribution of the dataset is notable for having a larger Parkinson's disease (PD) group compared to other NPS and HC groups, which is representative of the typical clinical scenario. This distribution posed a challenge in differentiating between healthy controls and PD patients, but it also provided a realistic test of the model's diagnostic capabilities. The dataset's structure and split were chosen to balance the need for statistical power with the practical considerations of clinical application.",
  "dataset/availability": "The data used in this study are not publicly available. However, they can be made available from the authors upon reasonable request and with the approval of the ethics committee. This approach ensures that the data are shared responsibly and in accordance with ethical guidelines. The code used in the study is available in a public repository, which allows for transparency and reproducibility of the methods employed. This setup facilitates collaboration and verification of the results by other researchers in the field.",
  "optimization/algorithm": "The machine-learning algorithm class used is the support vector machine (SVM). Specifically, a linear SVM was employed for this study. This algorithm is well-established and widely used in various fields, including medical imaging and classification tasks.\n\nThe SVM used in this study is not a new algorithm. It has been extensively studied and applied in numerous research areas. The choice to use SVM in this context is due to its effectiveness in handling high-dimensional data and its ability to perform well in classification tasks, which are crucial for differentiating between neurodegenerative Parkinson syndromes and healthy controls.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of this work is on its application in medical imaging, particularly in the context of neurodegenerative Parkinson syndromes. The study aims to demonstrate the diagnostic value of combining macrostructural and microstructural MRI information using SVM, rather than introducing a new machine-learning algorithm. The primary contribution lies in the application and validation of existing techniques in a specific medical context, highlighting their practical utility and performance in clinical settings.",
  "optimization/meta": "The model employs a support vector machine (SVM) as its core classifier. This SVM is trained and optimized using various inputs derived from different imaging modalities and techniques. These inputs include tissue probability values (TPV), diffusion tensor imaging (DTI), neurite orientation dispersion and density imaging (NODDI), and diffusion microstructure imaging (DMI). Each of these inputs provides unique features that contribute to the model's diagnostic performance.\n\nThe SVM is developed using the Python package \"Scikit-learn,\" and it processes a total of 5939 features derived from the aforementioned imaging techniques. These features are normalized and sorted using the maximum marginal diversity algorithm to ensure that the most discriminative features are selected for training. The model is trained in a one-vs.-rest (OVR) classification scheme to differentiate between Parkinson\u2019s disease (PD), multiple system atrophy (MSA), progressive supranuclear palsy (PSP), and healthy controls (HC).\n\nThe SVM's performance is evaluated using the area under the receiver operating characteristic curve (AUC-ROC), and different combinations of input parameters are tested to identify the best-performing model. The use of multiple imaging modalities and techniques as inputs to the SVM suggests a meta-predictor approach, where the SVM integrates information from various sources to improve diagnostic accuracy. The training data for each imaging modality is derived from the same cohort of participants, ensuring that the data is independent and not overlapping between different modalities. This independence is crucial for the reliability and generalizability of the model's performance.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure optimal input for the support vector machine (SVM). Initially, parameter maps from diffusion tensor imaging (DTI), neurite orientation dispersion and density imaging (NODDI), and diffusion microstructure imaging (DMI) were separated into gray and white matter using a tissue probability value (TPV) threshold of 0.4. This threshold helped in attributing voxels to either gray or white matter, facilitating the extraction of relevant features.\n\nThe gray matter compartment was read using the AAL3 atlas, while the white matter part was analyzed with the JHU WMPM III atlas. Additionally, MRI metrics were extracted from the Human Motor Thalamus atlas. These atlases provided a structured way to map and analyze the brain regions of interest.\n\nThe extracted features included 638 TPV-derived features, 2124 features from DTI, 1584 from NODDI, and 1593 from DMI, totaling 5939 features with data available for all participants. To address the imbalance in group sizes, the class_weight parameter in the SVM was set to 'balanced'. This ensured that each class was given appropriate weight during the training process.\n\nPrior to training, the input parameters were normalized using the StandardScaler from the Scikit-learn library, which standardized the features to have a mean of 0 and a standard variance. This normalization step is crucial for improving the performance and convergence of the SVM.\n\nTo handle the high dimensionality of the features relative to the subgroup sizes, the input parameters were sorted using the maximum marginal diversity approach. This method involved distributing the normalized values of each input feature into 20 equally spaced bins for each group and then calculating the Kullback-Leibler divergence to measure the difference between the distributions. This step helped in selecting the most informative features for the SVM.\n\nA grid search approach was employed to find the optimal combination of the SVM parameter C and the number of input parameters. The parameter C varied between 0.01 and 100, and the number of input parameters ranged from the top 5% to 40%. This grid search was performed using fivefold cross-validation to ensure robust performance evaluation. The maximum number of input parameters was capped at 40% to reduce noise and prevent overfitting.",
  "optimization/parameters": "In our study, we investigated the diagnostic value of a total of 5939 features, which served as input parameters for the linear support vector machine (SVM). These features were derived from various imaging modalities and techniques, including tissue probability values (TPV), diffusion tensor imaging (DTI), neurite orientation dispersion and density imaging (NODDI), and diffusion microstructure imaging (DMI).\n\nTo address the challenge of having considerably different group sizes, we set the class_weight parameter to 'balanced'. This approach helps to handle imbalanced datasets by adjusting the weights of the classes during the training process.\n\nGiven the relatively small subgroup sizes in relation to the maximum number of input features, we employed a strategy to select the most informative features. We normalized the values of a given input feature and distributed them into 20 equally spaced bins separately for each group. Subsequently, we calculated the Kullback-Leibler divergence for the resulting group-wise histogram as a measure of the difference between the distributions. This method helped us to identify features with high discriminative power.\n\nTo determine the optimal combination of the linear SVM parameter C and the number of input parameters, we conducted a grid search approach. We varied the parameter C between 0.01 and 100 and the number of input parameters between the top 5\u201340%. This process was fivefold cross-validated and compared with respect to the area under the curve (AUC). The maximum number of input parameters was set to be below 40% to reduce noise and prevent overfitting. This systematic approach ensured that we selected the most relevant features for our model, enhancing its diagnostic performance.",
  "optimization/features": "The study utilized a total of 5939 features as input for the linear support vector machine (SVM). These features were derived from various imaging modalities and included 638 tissue probability value (TPV)-derived features, 2124 features obtained by diffusion tensor imaging (DTI), 1584 by neurite orientation dispersion and density imaging (NODDI), and 1593 by diffusion microstructure imaging (DMI).\n\nFeature selection was performed using the maximum marginal diversity algorithm. This approach was chosen due to the relatively small subgroup sizes in relation to the maximum number of input features. The algorithm distributes normalized values of a given input feature into 20 equally spaced bins separately for each group and calculates the Kullback-Leibler divergence for the resulting group-wise histogram as a measure of the difference between the distributions. This method ensures that the most discriminative features are selected for the SVM.\n\nThe feature selection process was conducted using the training set only, ensuring that the model's performance on the test set remains unbiased. This approach helps in reducing noise and preventing overfitting, thereby improving the generalizability of the model.",
  "optimization/fitting": "The number of input features was indeed much larger than the number of training points. To address this and prevent overfitting, several strategies were employed. Firstly, the input parameters were sorted using the maximum marginal diversity algorithm, which helps in selecting the most discriminative features. Secondly, a grid search approach was used to find the optimal combination of the linear SVM parameter C and the number of input parameters. This involved training different linear SVMs with C varying between 0.01 and 100 and the number of input parameters varying between the top 5\u201340%. The maximum number of input parameters was set to be below 40% to reduce noise and prevent overfitting. Additionally, the input parameters were normalized to have a mean of 0 and a standard variance using the StandardScaler from Scikit-learn. This normalization helps in ensuring that the model does not give undue importance to features with larger scales.\n\nTo rule out underfitting, the model's performance was evaluated using the area under the receiver operating characteristic curve (AUC-ROC) in a one-vs.-rest (OVR) classifier for different neurodegenerative conditions and healthy controls. The diagnostic performance was compared with respect to different inputs, both individually and in combination. This comprehensive evaluation ensured that the model was not too simplistic to capture the underlying patterns in the data. Furthermore, the use of a linear SVM, which is a relatively simple model, was justified by the nature of the data and the goal of achieving a balance between model complexity and performance. The model's performance was also validated using a test cohort, which provided an independent assessment of its generalizability.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our support vector machine (SVM) model. One key method involved the use of class weights to address the imbalance in group sizes. By setting the class_weight parameter to 'balanced', we ensured that the model gave appropriate importance to each class, mitigating the risk of the model being biased towards the larger classes.\n\nAdditionally, we normalized the input parameters using the StandardScaler from the Scikit-learn library. This process standardized the features to have a mean of 0 and a standard variance of 1, which helped in improving the convergence and performance of the SVM.\n\nAnother crucial step was the sorting of input parameters based on maximum marginal diversity. This technique helped in selecting the most informative features, reducing the dimensionality of the data and thereby preventing overfitting.\n\nFurthermore, we evaluated the model's performance using a separate test cohort, which was not used during the training phase. This approach allowed us to assess the generalization capability of the model and ensure that it performed well on unseen data. The combination of these techniques helped in building a robust and reliable SVM model for classifying neurodegenerative Parkinson syndromes and healthy controls.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available. The support vector machine (SVM) was developed using the Python package \"Scikit-learn\" (version 0.23.2). The specific configurations and parameters, such as the use of a linear SVM, the setting of class_weight to 'balanced', and the normalization of input parameters using the StandardScaler, are detailed in the methodology section. The code is available in a public repository, allowing for reproducibility and further investigation.\n\nThe article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution, and reproduction in any medium or format, as long as appropriate credit is given to the original authors and the source. This license ensures that the configurations and parameters discussed are accessible to the public for further research and application.",
  "model/interpretability": "The model employed in this study is not a black box. It utilizes a support vector machine (SVM), which is a type of supervised learning algorithm known for its interpretability. The SVM's decision-making process can be understood through the examination of its support vectors and the coefficients assigned to different features.\n\nThe SVM was trained using a combination of macrostructural and microstructural imaging features, including tissue probability values (TPV), diffusion tensor imaging (DTI), neurite orientation dispersion and density imaging (NODDI), and diffusion microstructure imaging (DMI). The model's performance was evaluated using the area under the receiver operating characteristic curve (AUC-ROC) for different input combinations.\n\nTo enhance interpretability, the maximum marginal diversity algorithm was used to identify regions with high diversity in group-specific marginal distributions. This algorithm revealed that regions such as the putamen, cerebellar peduncles, pons, pontine crossing tracts, pallidum, various cerebellar regions, and frontal white matter were particularly discriminative. Additionally, the SVM attributed high coefficient weights to widespread gray and white matter regions, including cortical areas like the cingulum, temporal, and frontal cortex.\n\nThese findings suggest that the model's decisions are not arbitrary but are based on biologically meaningful regions and features. The combination of TPV and DMI provided the best diagnostic performance, indicating that both macrostructural and microstructural information are valuable for classifying neurodegenerative Parkinson syndromes and healthy controls. The model's transparency is further supported by the fact that the regions identified as discriminative are consistent with known pathological alterations in these conditions.",
  "model/output": "The model developed is a classification model. Specifically, it is a linear support vector machine (SVM) designed to classify different neurodegenerative Parkinson syndromes and healthy controls. The SVM was trained and optimized using the area under the receiver operating characteristic curve (AUC-ROC) in a one-vs.-rest (OVR) classifier. The diagnostic performance of the SVM was evaluated using various inputs, including tissue probability values (TPV), diffusion tensor imaging (DTI), neurite orientation dispersion and density imaging (NODDI), and diffusion microstructure imaging (DMI), both individually and in combination. The model's performance was assessed using metrics such as sensitivity and specificity for different classes, including healthy controls, Parkinson\u2019s disease, multiple system atrophy, and progressive supranuclear palsy. The best-performing combination of inputs was found to be the combination of tissue probability values and diffusion microstructure imaging.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the algorithm developed in this study is publicly available. It can be accessed in a public repository. This allows other researchers to reproduce the results and build upon the work. The code is released under a license that permits use, sharing, adaptation, distribution, and reproduction, as long as appropriate credit is given to the original authors. This open-access approach facilitates further research and development in the field.",
  "evaluation/method": "The evaluation of the method involved a comprehensive approach to ensure the robustness and generalizability of the support vector machine (SVM) model. The cohort was randomly split into a training subset and a test subset in a 4:1 ratio, ensuring that both subsets were matched in terms of age, sex, and diagnoses. This split allowed for the training of the SVM on a substantial portion of the data while reserving a separate set for unbiased evaluation.\n\nThe SVM was trained and optimized using a grid search approach, varying the parameter C between 0.01 and 100 and the number of input parameters between the top 5\u201340%. This grid search was performed with fivefold cross-validation to compare the models based on the area under the receiver operating characteristic curve (AUC-ROC). The maximum number of input parameters was set to be below 40% to reduce noise and prevent overfitting.\n\nTo address the imbalance in group sizes, the class_weight parameter was set to 'balanced'. This ensured that the model gave appropriate weight to each class during training, mitigating the potential bias introduced by the differing group sizes.\n\nThe input parameters were normalized using the StandardScaler from the Scikit-learn library, ensuring that they had a mean of 0 and a standard variance. This normalization step is crucial for the SVM to perform effectively, as it ensures that all features contribute equally to the model.\n\nPrior to training, the input parameters were sorted using the maximum marginal diversity algorithm. This algorithm helps in selecting features that provide the most discriminative power, thereby improving the model's performance.\n\nThe diagnostic performance of the SVM was evaluated by comparing different inputs, including tissue probability values (TPV), diffusion tensor imaging (DTI), neurite orientation dispersion and density imaging (NODDI), and diffusion microstructure imaging (DMI), both individually and in combination. This evaluation helped in determining the best-performing combination of input parameters.\n\nThe performance of the SVM was assessed using sensitivity and specificity metrics for each class (healthy controls, Parkinson\u2019s disease, multiple system atrophy, and progressive supranuclear palsy). The results indicated that the model achieved satisfactory performance in classifying these conditions, with the combination of DMI and TPV showing the highest diagnostic value.\n\nIn summary, the evaluation method involved a rigorous process of data splitting, parameter optimization, feature selection, and performance assessment, ensuring that the SVM model was thoroughly validated and capable of discriminating between neurodegenerative Parkinson syndromes with high accuracy.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the diagnostic capabilities of our models. The primary metric reported is the area under the receiver operating characteristic curve (AUC-ROC), which provides a comprehensive measure of the model's ability to distinguish between different classes. Specifically, we reported the one-vs.-rest (OVR) ROC-AUC for each class, including healthy controls (HC), Parkinson\u2019s disease (PD), multiple system atrophy (MSA), and progressive supranuclear palsy (PSP). These AUC values indicate the model's performance in classifying each condition against all others.\n\nAdditionally, we reported sensitivities and specificities for each class, which measure the true positive rate and true negative rate, respectively. These metrics are crucial for understanding the model's accuracy in identifying true cases and correctly excluding non-cases.\n\nThe reported AUC values for the combination of tissue probability values and diffusion microstructure imaging were 0.88 for HC, 0.98 for PD, 1.0 for MSA, and 0.97 for PSP. The sensitivities were 67% for HC, 95% for PD, 67% for MSA, and 86% for PSP, while the specificities were 94% for HC, 95% for PD, 94% for MSA, and 97% for PSP. These metrics demonstrate the model's strong discriminative power, particularly for PD and PSP.\n\nWe also compared the performance of different input metrics individually, including diffusion tensor imaging (DTI), neurite orientation dispersion and density imaging (NODDI), and diffusion microstructure imaging (DMI). The AUC values for these metrics varied, with DMI generally showing better diagnostic performance compared to DTI and NODDI, although the differences did not reach statistical significance in the De Long test.\n\nThe set of metrics reported in our study is representative of the literature, as AUC-ROC, sensitivity, and specificity are standard performance measures in diagnostic studies. These metrics provide a clear and comprehensive evaluation of the model's diagnostic accuracy and reliability.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of different Support Vector Machine (SVM) inputs to evaluate their diagnostic performance in classifying neurodegenerative Parkinson syndromes (NPS) and healthy controls (HC). We assessed various MRI-derived metrics, including tissue probability values (TPV), diffusion tensor imaging (DTI), neurite orientation dispersion and density imaging (NODDI), and diffusion microstructure imaging (DMI).\n\nWe found that TPV alone performed inferiorly to each diffusion MRI (dMRI)-derived metric alone in both the training and test cohorts. Specifically, using DeLong\u2019s test for the training cohort, we observed a significant superiority of the dMRI-derived metrics over TPV in delineating patients with Parkinson\u2019s disease (PD). However, this finding did not reach significance in the test cohort.\n\nThe overall best diagnostic performance in the training cohort was achieved with the combination of TPV, DTI, and NODDI. This combination yielded high area under the curve (AUC) values: 0.95 for HC, 0.94 for PD, 0.99 for multiple system atrophy (MSA), and 0.96 for progressive supranuclear palsy (PSP). In the test cohort, the combination of DMI and TPV performed best, correctly classifying 85% of participants and 88% of patients. The corresponding one-vs-rest receiver operating characteristic (OVR-ROC) AUC values were 0.88 for HC, 0.98 for PD, 1.0 for MSA, and 0.97 for PSP.\n\nWe also compared the diagnostic performance of individual dMRI metrics. DMI showed better diagnostic performance compared to DTI or NODDI, although the differences were not statistically significant according to the DeLong test. The AUC values for DMI were 0.91 for HC, 0.94 for PD, 0.96 for MSA, and 0.99 for PSP, whereas the AUC values for DTI and NODDI were generally lower.\n\nIn summary, our comparisons revealed that combining macrostructural and microstructural information enhances the diagnostic performance of SVMs in classifying NPS and HC. The use of dMRI-derived metrics, particularly DMI, provided substantial added value over conventional macrostructural imaging.",
  "evaluation/confidence": "The evaluation of our method involved calculating performance metrics such as sensitivity, specificity, and the area under the curve (AUC) for different classifications. These metrics were derived from receiver operating characteristic (ROC) curves, which provide a visual representation of the trade-off between sensitivity and specificity.\n\nConfidence intervals for the performance metrics were not explicitly provided in the main text, but the use of statistical tests like DeLong's test indicates that comparisons between different models and inputs were conducted with statistical rigor. DeLong's test is used to compare the AUCs of different ROC curves, providing a way to assess whether the differences in performance are statistically significant.\n\nIn our study, the combination of diffusion microstructure imaging (DMI) and tissue probability values (TPV) showed the best performance in classifying neurodegenerative Parkinson syndromes and healthy controls. However, while DMI outperformed diffusion tensor imaging (DTI) and neurite orientation dispersion and density imaging (NODDI) in diagnostic performance, the differences did not reach statistical significance in DeLong's test. This suggests that although DMI showed better results, the sample size might not have been large enough to definitively prove its superiority.\n\nThe overall classification performance using a support vector machine (SVM) was satisfactory, with high AUC values for different conditions. For instance, the AUC for Parkinson\u2019s disease (PD) was 0.98, and for progressive supranuclear palsy (PSP), it was 0.97. These high values indicate strong discriminative power, but it is important to note that the classification between healthy controls (HC) and PD was particularly challenging, with one-third of HC subjects being erroneously assigned to the PD group. This highlights the need for further research and potentially larger sample sizes to improve the differentiation between these groups.\n\nIn summary, while the performance metrics are promising and indicate the potential of the combined approach, the lack of statistical significance in some comparisons and the challenges in differentiating between HC and PD suggest that further validation and larger studies are necessary to fully establish the superiority of the method.",
  "evaluation/availability": "The raw evaluation files are not publicly available. However, data are available from the authors upon reasonable request and approval of the ethics committee. The code used in the study is available in a public repository. The article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution, and reproduction in any medium or format, as long as appropriate credit is given to the original authors and the source. The images or other third-party material in this article are included in the article\u2019s Creative Commons license, unless indicated otherwise. If material is not included in the article\u2019s Creative Commons license and the intended use is not permitted by statutory regulation or exceeds the permitted use, permission must be obtained directly from the copyright holder."
}