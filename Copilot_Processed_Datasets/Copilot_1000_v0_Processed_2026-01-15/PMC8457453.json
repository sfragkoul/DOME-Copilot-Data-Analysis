{
  "publication/title": "Expanding HIV transmission network reconstruction",
  "publication/authors": "The authors who contributed to the article are:\n\n- Sepideh Mazrouee, who was involved in conceptualization, data curation, formal analysis, investigation, methodology, project administration, software, validation, visualization, and writing the original draft and review & editing.\n- Susan J. Little, who contributed to data curation, funding acquisition, and resources.\n- Joel O. Wertheim, who contributed to funding acquisition, supervision, and writing the review & editing.",
  "publication/journal": "PLOS Computational Biology",
  "publication/year": "2021",
  "publication/pmid": "34550966",
  "publication/pmcid": "PMC8457453",
  "publication/doi": "https://doi.org/10.1371/journal.pcbi.1009336",
  "publication/tags": "- HIV\n- Molecular Epidemiology\n- Transmission Networks\n- Machine Learning\n- Metadata Analysis\n- Genetic Sequencing\n- Public Health\n- Data Privacy\n- Supervised Learning\n- Cluster Identification",
  "dataset/provenance": "The dataset analyzed in this study is sourced from the San Diego Primary Infection Resource Consortium (PIRC). It comprises genetic and epidemiological metadata collected from 1192 individuals living with HIV between 1998 and 2019. The dataset includes nearly 80 demographic, baseline history, laboratory, and screening features. After filtering for missing values and performing feature elimination, a subset of features with low data missingness and high predictive value was selected. These features include age, birth sex, sexual orientation, race, transmission category, estimated date of infection, and first viral load date.\n\nThe dataset is highly skewed towards specific races, sexual orientations, and transmission categories. Approximately 47% of all individuals in this study were labeled as clustered, meaning they were grouped together based on a genetic distance of less than or equal to 0.015 substitutions per site. The remaining individuals were labeled as singletons, indicating no evidence of epidemiological relation. The clustered individuals reside in 171 clusters, with sizes ranging from 2 to 23. This dataset has been used to evaluate the effectiveness of our hybrid model for HIV transmission network reconstruction.",
  "dataset/splits": "The dataset was initially split into train-test sets with a 70 to 30 ratio. However, due to the highly skewed nature of the data towards specific categories, a more robust method was employed: k-fold cross-validation. This method involves randomly dividing the dataset into k groups, or folds, of approximately equal size. Specifically, 10-fold cross-validation was performed, where the dataset was split into 10 folds. In each iteration, one fold was used as the validation set, and the remaining 9 folds were used for training. This process was repeated until each fold had served as the validation set once. Additionally, to further mitigate bias and overfitting, repetitive and stratified cross-validation methods were also conducted. In each fold, the model was trained on over 1,000 nodes and evaluated on approximately 120 nodes. The distribution of data points in each split was designed to ensure that each fold had a good representation of the entire dataset, maintaining the integrity of the data's distribution across all splits.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study cannot be shared publicly due to the risk of violating patient privacy, as it is subject to HIPAA regulations. However, interested researchers can find information on how to apply for access to the data through the San Diego Primary Infection Resource Consortium (PIRC) website. The data includes genetic and epidemiological metadata gathered from 1998 to 2019 for 1192 individuals living with HIV in San Diego. The dataset comprises nearly 80 demographic, baseline history, laboratory, and screening features. After filtering for missing values and performing feature elimination, a subset of features with the lowest data missingness and high predictive values was used as the contextual feature space. This subset includes age, birth sex, sexual orientation, race, transmission category, estimated date of infection, and first viral load date. The HIV-1 sequence data is available through the NCBI Genome database.",
  "optimization/algorithm": "The machine-learning algorithms used in our study are well-established and widely recognized in the field. We employed decision tree, random forest, k-nearest neighbors, and support vector machine classifiers. These algorithms are not new but are applied in a novel context to enhance the reconstruction of HIV transmission networks.\n\nThe decision to use these specific algorithms was driven by their robustness and effectiveness in handling complex datasets, particularly those with imbalanced classes and high dimensionality. The choice of algorithms was also influenced by their ability to incorporate both genetic and non-genetic metadata, which is crucial for our study's objectives.\n\nThe reason these algorithms were not published in a machine-learning journal is that our focus is on applying these methods to a specific biological problem rather than developing new machine-learning techniques. Our work contributes to the field of computational biology by demonstrating the practical application of existing machine-learning algorithms to improve the understanding and reconstruction of HIV transmission networks.\n\nThe performance of these algorithms was evaluated using cross-validation techniques, including stratified and repetitive cross-validation, to ensure the results are robust and generalizable. The accuracy and other performance metrics, such as precision, recall, and F1-score, were assessed to validate the effectiveness of each classifier in distinguishing between clustered and singleton cases. The support vector machine, in particular, showed promising results, outperforming other classifiers in terms of accuracy.\n\nIn summary, while the machine-learning algorithms used are not novel, their application to the problem of HIV transmission network reconstruction is innovative. This approach leverages the strengths of established algorithms to provide new insights into the dynamics of HIV transmission, ultimately aiding in more effective public health interventions.",
  "optimization/meta": "The model presented in this study does not function as a meta-predictor. Instead, it employs a hybrid approach that combines unsupervised and supervised learning algorithms. The process begins with generating a labeled dataset from viral genetic data, which is then used to train classifiers. The classifiers utilized include decision tree, random forest, k-nearest neighbors, and support vector machine. These algorithms are trained using contextual metadata, such as demographic, transmission risk, laboratory, comorbidity, and social network data, in addition to genetic data.\n\nThe training data for these classifiers is derived from the genetic distances between viral sequences. Sequences with genetic distances below a predefined threshold are considered epidemiologically related and are labeled as clustered, while those above the threshold are labeled as singletons. This labeled dataset is then used to train the classifiers, which can subsequently predict the epidemiological relatedness of new HIV-positive cases based on their metadata.\n\nTo ensure the independence of the training data, cross-validation with 50 repetitions was performed. This approach helps to avoid estimation bias and confirms the robustness of the model's performance. The decision tree and random forest classifiers demonstrated the highest performance in differentiating clustered individuals from singletons, achieving over 80% accuracy, precision, recall, and F1-score. The Area Under the Curve (AUC) for these classifiers was reported at 97% for random forest and 94% for decision tree, further validating their effectiveness.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps to ensure the effective utilization of both genetic and non-genetic features. Initially, the genetic data of viral strains were used to compute pairwise genetic distances using the TN93 model. This distance metric was crucial for creating a graph where nodes represented individuals and edges represented genetic similarities.\n\nFor the non-genetic features, a comprehensive set of metadata was collected, including demographic information such as age, birth sex, sexual orientation, race, and transmission category. Additionally, clinical data like the estimated date of infection and the first viral load date were incorporated. These features were carefully selected to capture the diverse aspects of HIV transmission dynamics.\n\nThe dataset was highly skewed towards specific demographic groups, which necessitated the use of robust methods to handle data imbalance. K-fold cross-validation was employed, with K set to 10, to ensure that each fold had a good representation of the entire dataset. This approach helped in mitigating classification bias and overfitting concerns.\n\nThe preprocessing pipeline also included the creation of a labeled dataset from the viral genetic data. This labeled dataset was then used to train supervised learning algorithms. The metadata features were integrated with the genetic data to form a comprehensive feature space. This hybrid approach allowed the algorithms to learn the non-linear correlation patterns between patient metadata and transmission events.\n\nThe data was split into training and testing sets using a 70-30 ratio. However, to further validate the models, repetitive and stratified cross-validation methods were also conducted. These methods ensured that the models were evaluated on diverse subsets of the data, enhancing their generalizability and robustness.\n\nIn summary, the data encoding and preprocessing involved the integration of genetic and non-genetic features, the use of robust cross-validation techniques to handle data imbalance, and the creation of a labeled dataset for training supervised learning algorithms. This comprehensive approach enabled the effective reconstruction of HIV transmission networks beyond the molecular data.",
  "optimization/parameters": "In our study, the number of parameters (p) used in the model varies depending on the specific classifier and the features included in the metadata. The metadata consists of various non-genetic features associated with each individual, forming a feature vector for each instance. The dimensionality of this feature vector, which corresponds to the number of parameters, is determined by the number of meta-features considered.\n\nThe selection of meta-features was guided by their relevance to the epidemiological context and their potential to contribute to the classification task. We included features such as demographic information, behavioral data, and clinical characteristics, among others. The specific set of meta-features was chosen based on domain knowledge and preliminary analyses to ensure that they provided meaningful information for distinguishing between clustered and singleton cases.\n\nFor the distance metric used in the model, we employed the Euclidean distance (L2 norm) to measure the dissimilarity between pairs of individuals in the meta-feature space. This choice was made because it is a commonly used and intuitive measure of distance in multi-dimensional spaces.\n\nThe classifiers used in our study included decision trees, random forests, k-nearest neighbors, and support vector machines. Each of these classifiers has its own set of hyperparameters that were tuned during the model training process. For example, the random forest classifier used 120 estimators, and the k-nearest neighbors classifier used a number of neighbors equal to the number of clusters. These hyperparameters were selected based on cross-validation performance to optimize the classifiers' ability to accurately assign class labels.\n\nIn summary, the number of parameters (p) in our model is determined by the dimensionality of the meta-feature space, which was selected based on domain knowledge and preliminary analyses. The distance metric used was the Euclidean distance, and the classifiers' hyperparameters were tuned through cross-validation to enhance their performance.",
  "optimization/features": "The input features used in our study consist of a subset of demographic, baseline history, laboratory, and screening features. Initially, the dataset included nearly 80 such features. However, to enhance the predictive value and reduce data missingness, we performed backward feature elimination. This process resulted in a smaller, more robust set of features with high predictive values. The final set of non-genetic metadata utilized to train the classification algorithms includes age, birth sex, sexual orientation, race, transmission category, estimated date of infection, and first viral load date.\n\nFeature selection was indeed performed, and it was conducted using the training set only. This approach ensured that the feature selection process did not introduce any bias from the testing set, maintaining the integrity of our model's evaluation. The selected features were chosen based on their low data missingness and high predictive values, ensuring that the model could effectively utilize the available data to make accurate predictions.",
  "optimization/fitting": "The fitting method employed in this study involved training models with clusters of size 5 or more, using 50 repetitions of 10-fold cross-validation. This approach was chosen to ensure that the models were robust and generalizable, rather than overfitting to the training data.\n\nTo address the potential for overfitting, stratified cross-validation was performed. This method rearranges the data so that each fold has a good representation of the entire dataset, helping to detect and mitigate overfitting. Additionally, the performance of the support vector machine (SVM) was evaluated, and although it showed some overfitting concerns in certain repetitions, it ultimately outperformed other classifiers in terms of accuracy.\n\nThe accuracy achieved by the SVM was significantly better than that of a Dummy Uniform random classifier, indicating that the model was not underfitting. The decision tree and random forest classifiers also demonstrated high accuracy, precision, recall, and F1-scores, further supporting the effectiveness of the fitting method.\n\nIn summary, the use of stratified cross-validation and the comparison with a random classifier helped to rule out both overfitting and underfitting, ensuring that the models were well-fitted to the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. Initially, we used 10-fold cross-validation, which involves splitting the dataset into 10 folds, training the model on 9 folds, and validating it on the remaining fold. This process is repeated 10 times, with each fold serving as the validation set once. This method helps to ensure that the model generalizes well to unseen data.\n\nHowever, we also recognized the potential for overfitting, especially with the support vector machine (SVM) classifier, despite using a high value for K. To address this, we implemented stratified cross-validation. This technique rearranges the data so that each fold has a good representation of the entire dataset, further reducing the risk of overfitting.\n\nAdditionally, we performed repetitive cross-validation to validate the accuracy of our classifiers. This involved running the cross-validation process multiple times to ensure consistent performance. By combining these methods, we aimed to minimize overfitting and enhance the reliability of our classification models.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study is not entirely a black box, as it incorporates interpretable machine learning algorithms. Among the classifiers used, decision trees and random forests are particularly notable for their transparency. These models can be visualized and interpreted, allowing users to understand the decision-making process. For instance, decision trees provide a clear, hierarchical structure where each node represents a decision based on a feature, making it straightforward to trace the path leading to a specific classification. Random forests, being an ensemble of decision trees, maintain this interpretability to some extent, although they are more complex due to the aggregation of multiple trees.\n\nIn contrast, support vector machines (SVM) and k-nearest neighbors (k-NN) are less interpretable. SVM operates by finding a hyperplane that best separates the classes, which is not as intuitive to visualize or explain. Similarly, k-NN classifies based on the majority vote of the nearest neighbors, which can be difficult to interpret, especially in high-dimensional spaces.\n\nThe use of metadata features further enhances the interpretability of the model. By incorporating non-genetic features alongside the genetic information, the model can provide insights into which factors contribute most to the classification of individuals as clustered or singletons. This integration allows for a more comprehensive understanding of the underlying patterns in the data.\n\nOverall, while some components of the model are more opaque, the inclusion of decision trees and random forests, along with the use of interpretable metadata, ensures that the model is not entirely a black box. This balance between complexity and interpretability is crucial for building trust in the model's predictions and for facilitating further research and practical applications.",
  "model/output": "The model is a classification model. It is designed to assign binary labels to individuals, indicating whether they are part of a clustered group (potentially related to a molecular network) or singletons (no evidence of relatedness to the molecular network). Additionally, the model can assign unique cluster identifiers to clustered sequences, further classifying them into specific clusters.\n\nThe classification process involves several steps. First, a graph is created where nodes represent individuals and edges represent genetic distances between them. Nodes with genetic distances greater than a certain threshold are labeled as singletons. The graph is then clustered into connected components, with nodes in these components labeled as clustered. These binary labels (clustered vs. singleton) are used to train various classifiers, including decision tree, random forest, k-nearest neighbors, and support vector machine.\n\nThe model's performance is evaluated using metrics such as accuracy, precision, recall, and F1-score. Decision tree and random forest classifiers showed the highest performance in differentiating clustered individuals from singletons, with over 80% accuracy, precision, recall, and F1-score. The model also achieved high sensitivity and specificity, confirming its effectiveness in classification tasks.\n\nIn addition to binary classification, the model can identify specific clusters. Clusters of size 5 or more were used to test the extended hypothesis, with 43.8% of clustered individuals in the San Diego cohort dataset residing in 29 such clusters. The model's ability to handle larger clusters demonstrates its robustness and versatility in classification tasks.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the method described in the publication is publicly available. It can be accessed via GitHub at the following URL: https://github.com/smazrouee/MLMetadata. This repository provides an implementation of the machine learning approach used for HIV transmission network reconstruction. The code is released under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction, provided that the original authors and source are credited. This allows researchers and developers to utilize, modify, and build upon the provided code for their own studies and applications.",
  "evaluation/method": "The evaluation of the classifiers involved several robust methods to ensure the reliability and generalizability of the results. Initially, we used train-test sets with a 70 to 30 ratio. However, given the highly skewed nature of the dataset towards specific race, sexual orientation, and transmission category, we employed k-fold cross-validation. This method is known for its robustness against data imbalance. We performed a sensitivity analysis for K and chose K = 10, splitting the entire dataset into 10 folds. In each fold, one subgroup was used as the validation set, and the method was trained on the remaining 9 folds. This process was repeated until all folds had been used as the validation set.\n\nTo further mitigate any potential bias or overfitting, we conducted repetitive and stratified cross-validation. This involved rearranging the data so that each fold had a good representation of the entire dataset. The models were evaluated on their ability to automatically assign new positive cases to the correct class labels, either clustered (potentially related to the molecular network) or singleton (no evidence of relatedness to the molecular network).\n\nIn addition to binary classification, we trained classifiers with the genetic information of infected populations to identify clusters. We tested the hypothesis with larger clusters of size 5 or more, as smaller clusters might not provide enough resolution. The San Diego cohort dataset clusters of size 5 or more comprised 43.8% of all clustered individuals, residing in 29 clusters. We used cross-validation in multiple repetitions and stratified cross-validation to ensure the reliability of the results.\n\nThe performance of the classifiers was assessed using various metrics, including accuracy, precision, recall, F1-score, sensitivity, and specificity. The decision tree and random forest classifiers achieved the highest performance in differentiating clustered individuals from singletons using metadata, with over 80% in accuracy, precision, recall, and F1-score. The random forest and decision tree classifiers also achieved over 90% sensitivity and 80% specificity, confirming the performance measures achieved using test-train or cross-validation learning.",
  "evaluation/measure": "In our evaluation, we reported several performance metrics to comprehensively assess the classifiers' abilities. For the binary classification task of differentiating between clustered and singleton individuals, we presented the macro-average performance measures, including accuracy, precision, recall, and F1-score. These metrics provide a balanced view of the classifiers' performance, especially in the presence of class imbalances.\n\nAccuracy indicates the proportion of true results (both true positives and true negatives) among the total number of cases examined. Precision measures the proportion of true positive results among all positive results, while recall (or sensitivity) reflects the proportion of true positive results among all actual positives. The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n\nAdditionally, we reported sensitivity and specificity for each algorithm. Sensitivity, as mentioned earlier, is the same as recall, and specificity measures the proportion of true negative results among all actual negatives. These metrics are crucial for understanding the classifiers' performance in identifying both clustered and singleton individuals accurately.\n\nWe also generated Receiver Operating Characteristic (ROC) curves and calculated the Area Under the Curve (AUC) for the algorithms. The AUC provides an aggregate measure of performance across all classification thresholds, with higher values indicating better performance. The ROC curves and AUC values offer a visual and quantitative assessment of the classifiers' ability to distinguish between the two classes.\n\nThe reported metrics are representative of standard practices in the literature for evaluating classification models, particularly in the context of imbalanced datasets. By including a range of metrics, we aim to provide a thorough evaluation of the classifiers' performance, ensuring that our findings are robust and comparable to other studies in the field.",
  "evaluation/comparison": "In our evaluation, we compared the performance of our trained classifiers against a baseline method, specifically HIV-TRACE, which generates clustered/singleton labels on the entire dataset. This comparison was crucial to understand how our approach, which incorporates both genetic and metadata information, performs relative to existing methods.\n\nWe also evaluated the classifiers using simpler baselines to ensure that the improvements observed were not due to overfitting or other biases. For instance, we used a Dummy Uniform random classifier as a baseline for a 30-class classification problem. The results showed that our Support Vector Machine (SVM) prediction class assignment approach was, on average, an order of magnitude better than the random classifier, indicating that our method provides significant improvements over simple baselines.\n\nAdditionally, we performed a sensitivity analysis to determine the optimal number of folds for cross-validation. We chose K = 10, which means our entire dataset was split into 10 folds. This approach was robust against data imbalance and helped us to avoid overfitting. We further validated our models using repetitive and stratified cross-validation to preclude any possibility of bias.\n\nThe performance of our classifiers was assessed using various metrics, including accuracy, precision, recall, F1-score, sensitivity, and specificity. The decision tree and random forest classifiers achieved the highest performance in differentiating clustered individuals from singletons using metadata, with over 80% in accuracy, precision, recall, and F1-score. The random forest and decision tree classifiers also achieved over 90% sensitivity and 80% specificity, confirming the robustness of our approach.\n\nIn summary, our evaluation involved comparing our method to both publicly available methods and simpler baselines, ensuring that our results are reliable and indicative of genuine improvements in HIV transmission network reconstruction.",
  "evaluation/confidence": "To ensure the robustness of our evaluation, we employed multiple cross-validation techniques. We initially used 10-fold cross-validation, which involves splitting the dataset into 10 folds, training on 9 folds, and validating on the remaining fold. This process is repeated 10 times, ensuring that each fold serves as the validation set once. To further mitigate any potential bias or overfitting, we conducted 50 repetitions of 10-fold cross-validation. This approach helps in providing a more reliable estimate of model performance by averaging the results over multiple splits.\n\nAdditionally, we performed stratified cross-validation, which ensures that each fold has a representative distribution of the entire dataset. This is particularly important given the skewed nature of our dataset towards specific races, sexual orientations, and transmission categories.\n\nThe performance metrics, such as accuracy, precision, recall, and F1-score, were computed for each fold, and the results were averaged to provide a comprehensive evaluation. The use of multiple repetitions and stratified sampling helps in reducing the variance of the performance estimates, thereby increasing the confidence in our results.\n\nStatistical significance was assessed by comparing the performance of our models against a baseline random classifier. The results showed that our models, particularly the decision tree and random forest classifiers, significantly outperformed the random classifier. For instance, the random forest and decision tree classifiers achieved over 90% sensitivity and 80% specificity, which are statistically significant improvements over the baseline.\n\nFurthermore, we generated Receiver Operating Characteristic (ROC) curves and calculated the Area Under the Curve (AUC) for each algorithm. The AUC values for the random forest and decision tree classifiers were 97% and 94%, respectively, indicating a high level of discriminative power.\n\nIn summary, the use of repeated and stratified cross-validation, along with the comparison against a baseline random classifier, provides a high level of confidence in the performance metrics reported. The statistical significance of our results supports the claim that our method is superior to others and baselines.",
  "evaluation/availability": "Not enough information is available."
}