{
  "publication/title": "INASNET: Automatic identification of coronavirus disease (COVID-19) based on chest X-ray using deep neural network",
  "publication/authors": "The authors who contributed to this article are M. Perumal, A. Nayak, and R. P. Sreeetal. Their specific contributions to the paper are not detailed, but their collective work led to the development of a hybrid inception model for COVID-19 detection using X-ray images. This model aims to assist doctors and frontline workers in screening COVID-19 cases at the community level, providing a cost-effective and efficient alternative to existing detection methods. The model has been trained on complex datasets and optimized with batch normalization and dense layers to enhance detection efficiency. The authors have also compared their model's performance with other deep learning models, demonstrating its superior accuracy and suitability for real-time classification tasks.",
  "publication/journal": "ISATransactions",
  "publication/year": "2022",
  "publication/pmid": "35300854",
  "publication/pmcid": "PMC8892361",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Chest X-ray images\n- Novel coronavirus\n- COVID-19\n- Transfer learning\n- Dense model\n- Deep learning\n- Medical image analysis\n- SARS-CoV2\n- InceptionNet\n- Neural network architectures",
  "dataset/provenance": "For our study, we utilized open-source and publicly available chest X-ray datasets. The combined dataset was created by merging and modifying three distinct datasets, each containing COVID-19 images. These datasets are:\n\n1. COVID-19 Chest X-ray Dataset Initiative\n2. RSNA Pneumonia Detection Challenge dataset\n3. COVID-19 Image Data Collection\n\nThe combined dataset includes a total of 183 CXR images collected from 121 coronavirus-infected patients. Additionally, it contains 8066 normal patient cases and 5538 pneumonia patient cases. The dataset is imbalanced, with a significantly smaller number of COVID-19 infection images compared to the other two classes.\n\nThe dataset has been used in previous research and by the community. For instance, the COVID-19 Chest X-ray Dataset Initiative and the COVID-19 Image Data Collection have been referenced in other studies focusing on COVID-19 detection using medical imaging. The RSNA Pneumonia Detection Challenge dataset is widely used in the medical imaging community for developing and evaluating pneumonia detection algorithms.\n\nThe paper-related code is available publicly for open access, allowing other researchers to replicate and build upon our work. The code can be found at https://github.com/murukessanap/inceptionNasnet. This transparency ensures that our methodology and results can be verified and potentially improved by the broader scientific community.",
  "dataset/splits": "In our study, we utilized a combined dataset consisting of chest X-ray images to train and evaluate our model. The dataset was merged from three distinct sources: the COVID-19 Chest X-ray Dataset Initiative, the RSNA Pneumonia Detection Challenge dataset, and the COVID-19 Image Data Collection. This combined dataset includes images from three classes: normal, pneumonia, and COVID-19.\n\nThe dataset is split into training, validation, and testing sets. The training set is used to train the model, the validation set is used to tune the model's hyperparameters and prevent overfitting, and the testing set is used to evaluate the final performance of the model.\n\nThe distribution of data points in each split is as follows:\n\n* Training set: Contains the majority of the data points, including a significant number of normal and pneumonia cases, and a smaller number of COVID-19 cases.\n* Validation set: Contains a representative sample of each class, used to validate the model during training.\n* Testing set: Contains a separate set of images that the model has not seen during training or validation. This set is used to evaluate the model's performance on unseen data.\n\nSpecifically, the testing set contains 183 COVID-19 X-ray images collected from 121 coronavirus-infected patients. The total number of normal and pneumonia patient cases in the testing set is 8066 and 5538, respectively. This imbalance reflects the real-world scenario where COVID-19 images are less available compared to normal and pneumonia cases.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets used in our study are publicly available and open-source. Specifically, we utilized three distinct datasets for our experimental analysis:\n\n1. The COVID-19 Chest X-ray Dataset Initiative.\n2. The RSNA Pneumonia Detection Challenge dataset.\n3. The COVID-19 Image Data Collection.\n\nThese datasets were merged and modified to create a combined dataset that includes images of normal, pneumonia, and COVID-19 cases. The combined dataset contains a relatively small number of COVID-19 infection images compared to the other two classes. The COVID-19 images consist of 183 CXR images collected from 121 coronavirus-infected patients, while the total number of normal and pneumonia patient cases is 8066 and 5538, respectively.\n\nThe datasets are available for public access, and the related code for our paper is also publicly accessible on GitHub at https://github.com/murukessanap/inceptionNasnet. This ensures that other researchers can replicate our work and build upon it.\n\nThe availability of these datasets and the public release of our code align with our commitment to transparency and reproducibility in scientific research. By making our datasets and code publicly available, we aim to contribute to the broader scientific community and facilitate further advancements in COVID-19 detection and diagnosis.",
  "optimization/algorithm": "The optimization algorithm employed in our work leverages reinforcement learning to enhance the performance of our deep learning model. Specifically, we utilize Neural Architecture Search (NAS) to optimize the hyper-parameters and regularization parameters of our model. This approach is not entirely new but has been adapted and integrated into our hybrid model, which combines the strengths of both InceptionNet and NAS structures.\n\nThe NAS block in our model automates the convolution features in the inception layer, helping to optimize the hyper-parameters effectively. This integration allows our model to learn features from large datasets more efficiently. The NAS network is introduced parallel to the convolutional blocks and max-pooling layers, adding more convolutional neural network (CNN) feature maps to the network. This setup acts like a skip connection from the input to the fully connected layer, aiding in gathering wider function approximations and connecting distant features in the image.\n\nThe hill-climbing technique is used within the NAS framework, applying network morphism to optimize the network based on local search. This method finds the best solution through an incremental approach, ensuring that the system can accurately identify COVID-19 cases from X-ray images.\n\nWhile the core concepts of reinforcement learning and NAS are well-established in the machine learning community, our specific implementation and its application to COVID-19 detection using X-ray images are novel. The integration of these techniques into a hybrid model tailored for medical imaging represents a significant contribution to the field of medical diagnostics. This work was published in a transactions journal focused on applied sciences, highlighting its practical applications rather than purely theoretical contributions.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it is a hybrid approach that combines deep learning functionalities, specifically leveraging both supervised learning and reinforcement learning.\n\nThe proposed model, referred to as INASNET, is based on a combination of the NAS structure and InceptionNet. It utilizes convolutional neural networks (CNNs) to analyze X-ray images for COVID-19 detection. The model includes an inception block, which applies varied-size kernels simultaneously to create a wider network, and a NAS block, which optimizes hyper-parameters and regularization parameters through reinforcement learning.\n\nThe training process involves labeled datasets of X-ray images, including those of COVID-19 infected patients, pneumonia infected patients, and normal individuals. These datasets are sourced from various health institutes and hospitals and are available openly. The model aims to achieve high accuracy and efficiency in classifying these images, addressing issues like over-fitting through mechanisms such as label smoothing and regularization.\n\nThe performance of the model is evaluated using metrics like accuracy, precision, recall, and F1-score, with results indicating superior performance compared to other deep learning models like VGGNet, ResNet, InceptionNet, and NasNet. The model's design and training ensure that the data used is independent, focusing on the direct analysis of X-ray images without relying on predictions from other machine-learning algorithms.",
  "optimization/encoding": "In our study, the data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithm. We utilized chest X-ray images from open-source datasets, which included cases of COVID-19, pneumonia, and normal patients. These images were first normalized to standardize the pixel values, which helps in stabilizing and accelerating the training process. Batch normalization was applied to further reduce internal covariate shift, making the training more efficient.\n\nThe images were resized to a consistent dimension to maintain uniformity across the dataset. This step is essential for convolutional neural networks, as it ensures that the input size is compatible with the network's architecture. Additionally, data augmentation techniques such as rotation, flipping, and zooming were employed to artificially increase the diversity of the training set, helping the model to generalize better.\n\nLabel smoothing was incorporated to prevent overfitting by softening the hard targets (0 or 1) to values like 0.9 or 0.1. This technique encourages the model to be more confident in its predictions and reduces the likelihood of overfitting to the training data. The labels for the images were encoded using one-hot encoding, where each class (COVID-19, pneumonia, normal) was represented by a unique binary vector. This encoding scheme is compatible with the softmax activation function used in the final layer of our network, allowing the model to output probabilities for each class.\n\nTo handle the class imbalance, particularly the scarcity of COVID-19 images, we used techniques such as oversampling the minority class and adjusting the class weights during training. This ensures that the model does not become biased towards the majority class and can accurately identify COVID-19 cases. The preprocessing pipeline also included the removal of any metadata or annotations from the images to focus solely on the visual features relevant to the diagnosis.",
  "optimization/parameters": "In our proposed model, the number of parameters, p, is determined by the combination of the Inception and NAS blocks, along with the dense blocks used for feature extraction. The Inception blocks utilize varied kernel sizes to capture multi-scale features, which contributes to the overall parameter count. The NAS blocks, supported by reinforcement learning, optimize the hyper-parameters and convolutional features, further adding to the parameter set. Additionally, the dense blocks, which include dense layers, batch normalization, ReLU activation, and dropout layers, are designed to deepen the network without adding extra parameters, but they do contribute to the overall complexity and parameter count.\n\nThe selection of p was guided by the need for a balance between model complexity and computational efficiency. Given the large and varied dataset of X-ray images, including those of COVID-19 infected patients, pneumonia patients, and normal individuals, it was crucial to ensure that the model could generalize well without overfitting. The use of label smoothing and regularization mechanisms in the NAS block helped in preventing over-fitting problems, which is essential for maintaining a reasonable parameter count.\n\nThe model's architecture was designed to be computationally less expensive, focusing on creating a wider network rather than a deeper one. This approach helps in reducing the representation bottleneck and preventing the loss of information, which is vital for accurate disease prediction. The hill-climbing technique and network morphism were employed to optimize the network based on local search, ensuring that the selected parameters lead to accurate and efficient results.\n\nIn summary, the number of parameters, p, in our model is a result of the combined contributions from the Inception, NAS, and dense blocks. The selection of p was carefully considered to balance model performance and computational efficiency, with a focus on preventing over-fitting and ensuring accurate disease prediction.",
  "optimization/features": "The input features for our model consist of X-ray images, specifically focusing on three classes: COVID-19, pneumonia, and normal cases. These images are used directly as input without additional feature extraction or selection processes. The datasets used include the COVID-19 Chest X-ray Dataset Initiative, the RSNA Pneumonia Detection Challenge dataset, and the COVID-19 Image Data Collection. These datasets were merged and modified to create a comprehensive dataset for training and validation.\n\nThe dataset contains a total of 183 COVID-19 X-ray images from 121 coronavirus-infected patients, 8066 normal patient cases, and 5538 pneumonia patient cases. The images are used in their raw form, leveraging the deep learning capabilities of our hybrid model to automatically learn and extract relevant features. This approach ensures that the model can generalize well across different types of X-ray images, making it robust for real-time classification tasks.",
  "optimization/fitting": "In our study, we employed a hybrid deep learning model, INASNET, which combines the strengths of InceptionNet and NASNet architectures. This approach allows us to leverage a wide network with varied kernel sizes, reducing the risk of over-fitting that deeper networks often encounter.\n\nTo address the potential issue of over-fitting, given the large number of parameters in our model compared to the training points, we implemented several regularization techniques. Firstly, we incorporated a dropout layer, which randomly deactivates a fraction of neurons during training. This helps to prevent the model from becoming too reliant on specific neurons, thereby reducing over-fitting. Secondly, we used label smoothing, which adjusts the target labels to be less confident, encouraging the model to be more uncertain and less prone to over-fitting. Additionally, we utilized batch normalization, which stabilizes and accelerates training by normalizing the inputs of each layer. This technique also acts as a form of regularization, helping to prevent over-fitting.\n\nTo ensure that our model did not under-fit, we carefully designed our architecture to capture a wide range of features using the inception block, which applies varied kernel sizes simultaneously. This approach allows the model to learn both local and global features effectively. Furthermore, the NAS block optimizes the hyper-parameters and regularization parameters, ensuring that the model is well-tuned to the data. The use of a large and diverse dataset, including X-ray images of COVID-19, pneumonia, and normal cases, also helps in preventing under-fitting by providing a comprehensive set of examples for the model to learn from.\n\nThe performance of our model was evaluated using metrics such as accuracy, precision, recall, and F1-score, which showed that our hybrid approach achieved superior results compared to other deep learning models like VGGNet, ResNet, InceptionNet, and NASNet. The model's ability to generalize well to unseen data, as evidenced by its validation accuracy and loss, further confirms that over-fitting and under-fitting were effectively managed.",
  "optimization/regularization": "In our work, we employed several regularization techniques to prevent over-fitting and enhance the generalization capability of our model. One of the key methods used was the incorporation of a dropout layer within our hybrid network. The dropout layer helps to reduce the dependency of hidden units on specific outputs from previous layers, thereby improving the model's training efficiency and accuracy. By randomly dropping units during training, the network is forced to learn more robust features, which ultimately leads to better performance on unseen data.\n\nAdditionally, we utilized batch normalization, which aids in stabilizing and accelerating the training process. This technique involves calculating the mean and variance for mini-batches and normalizing the values, followed by scaling and shifting. Batch normalization helps in mitigating the internal covariate shift, making the training process more efficient and reducing the likelihood of over-fitting.\n\nFurthermore, we implemented label smoothing, which is another effective regularization technique. Label smoothing prevents the model from becoming too confident about its predictions by adjusting the target labels slightly. This approach encourages the model to distribute its predictions more evenly, thereby improving its robustness and generalization ability.\n\nThese regularization methods collectively contribute to the model's ability to generalize well on validation and test datasets, ensuring that it performs reliably in real-world scenarios.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. The specific configurations and schedules that were employed to achieve the reported results are explicitly mentioned to ensure reproducibility.\n\nThe model files, including the trained weights and architectures, are not directly provided within the publication. However, the code related to the paper is available publicly for open access. This code can be found at a specified GitHub repository, which allows other researchers to replicate the experiments and validate the findings.\n\nRegarding the license, the publication and its related resources are made available under permissions granted by Elsevier for unrestricted research re-use and analyses. This means that the information and code can be used freely for academic and research purposes, provided that the original source is acknowledged. This open access policy is in place to facilitate the broader scientific community's ability to build upon and verify the work presented.",
  "model/interpretability": "The model we have developed, INASNET, is a hybrid inception model designed for COVID-19 detection using X-ray images. While deep learning models are often considered black boxes due to their complex architectures and numerous parameters, our model incorporates several mechanisms that enhance its interpretability.\n\nFirstly, the use of a dense block in our model helps in feature extraction and maintains a feedforward nature in the network. Each layer in the dense block receives inputs from all preceding layers, and its output is passed to all subsequent layers. This structure allows for a clearer understanding of how features are propagated and transformed throughout the network.\n\nAdditionally, the inclusion of a batch normalization layer aids in stabilizing the learning process. By normalizing the inputs to each layer, batch normalization helps in reducing the internal covariate shift, making the training process more interpretable and efficient.\n\nThe model's performance is visualized using a confusion matrix, which provides a clear understanding of the classification results. The matrix shows the instances in the predicted class (rows) versus the actual class (columns), allowing for an analysis of true positives, true negatives, false positives, and false negatives. This visualization helps in interpreting the model's strengths and weaknesses in classifying COVID-19 cases.\n\nFurthermore, the model's training and validation processes are illustrated through various graphs comparing its performance with other deep learning models. These graphs include training accuracy, training loss, validation accuracy, and validation loss, providing insights into the model's learning behavior and generalization ability.\n\nIn summary, while INASNET is a complex deep learning model, its architecture and the use of visualizations like the confusion matrix and performance graphs enhance its interpretability. These elements allow for a better understanding of how the model makes predictions and its overall performance in detecting COVID-19 from X-ray images.",
  "model/output": "The model is a classification model designed for COVID-19 detection using X-ray images. It categorizes images into classes such as normal, pneumonia, and COVID-19. The model's performance is evaluated using metrics like accuracy, precision, recall, and F1-score, which are typical for classification tasks. The output of the model includes predictions for these classes, helping in the automated screening of COVID-19 cases.\n\nThe model achieves an accuracy of 98.84% on training data and 94.3% on test data, demonstrating its effectiveness in classifying X-ray images. It also shows superior performance compared to other deep learning models like VGGNet, ResNet, InceptionNet, and NasNet. The validation accuracy and loss graphs further illustrate the model's robustness and generalizability.\n\nThe confusion matrix provides a detailed breakdown of the model's performance, showing the true positives, true negatives, false positives, and false negatives. This helps in understanding the model's strengths and areas for improvement. The model's ability to handle real-time classification tasks and its resistance to overfitting make it suitable for practical applications in COVID-19 detection.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code related to the paper is publicly available for open access. It can be found on GitHub at the following URL: https://github.com/murukessanap/inceptionNasnet. This repository contains the necessary code to implement and run the proposed hybrid model for COVID-19 detection using X-ray images. The code is released under a license that allows for open access, enabling researchers and developers to use, modify, and distribute the code for further research and applications.",
  "evaluation/method": "The evaluation of our proposed method, INASNET, involved a comprehensive analysis using various metrics and comparisons with other deep learning models. We measured the performance of our model using metrics such as accuracy, precision, recall, and F1-score. These metrics were calculated based on the true positive, true negative, false positive, and false negative results obtained from the model's predictions.\n\nTo ensure the robustness of our evaluation, we used a combined dataset consisting of COVID-19, pneumonia, and normal chest X-ray images. This dataset was created by merging and modifying three distinct datasets, ensuring a diverse and representative sample for training and validation.\n\nThe performance of our model was compared with well-known deep learning models such as VGGNet, ResNet, InceptionNet, and NasNet. The comparison was done using validation loss, validation accuracy, and training loss. Our model demonstrated superior performance with the lowest average validation loss and the highest validation accuracy among the compared models.\n\nAdditionally, we visualized the performance of our model using a confusion matrix, which provided a clear understanding of the classification results. The confusion matrix helped in analyzing the statistics of our classification task, showing that our model had the best validation accuracy compared to other deep learning models.\n\nWe also addressed the issue of overfitting by implementing a regularization mechanism in the NAS block, ensuring that our model generalized well to unseen data. The results of our evaluation were promising and recognized by doctors and frontline workers, highlighting the effectiveness of our proposed method in COVID-19 detection using X-ray images.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to thoroughly assess the effectiveness of our model. These metrics include accuracy, precision, recall, and the F1 score. Accuracy measures the overall correctness of the model's predictions, providing a general sense of how well the model performs across all classes. Precision indicates the proportion of true positive predictions among all positive predictions, which is crucial for understanding the reliability of positive results. Recall, or sensitivity, measures the proportion of true positive predictions among all actual positives, highlighting the model's ability to identify all relevant cases. The F1 score, which is the harmonic mean of precision and recall, offers a balanced view of the model's performance, especially useful when dealing with imbalanced datasets.\n\nThese metrics are widely recognized and used in the literature for evaluating classification models, particularly in medical imaging. They provide a comprehensive view of the model's performance, ensuring that our results are both robust and comparable to other studies in the field. Additionally, we calculated true positives, true negatives, false positives, and false negatives to further analyze the model's performance in detail. This approach allows us to understand not just the overall accuracy but also the specific types of errors the model might be making, which is essential for refining and improving the model.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our proposed hybrid model, INASNET, with several well-established deep learning models to assess its performance. The models we compared against include VGGNet, ResNet, InceptionNet, and NasNet. These models were chosen because they are widely recognized and have been successfully applied in various image classification tasks.\n\nTo ensure a fair and comprehensive comparison, we used benchmark datasets that included X-ray images categorized into three classes: normal, pneumonia, and COVID-19. The datasets were merged and modified from three distinct sources: the COVID-19 Chest X-ray Dataset Initiative, the RSNA Pneumonia Detection Challenge dataset, and the COVID-19 Image Data Collection. This combined dataset provided a robust foundation for evaluating the models' performance across different types of chest X-ray images.\n\nWe measured the performance of each model using several key metrics, including accuracy, precision, recall, and F1-score. These metrics were calculated based on the true positive, true negative, false positive, and false negative rates. The results demonstrated that our hybrid model, INASNET, achieved superior performance compared to the other models. Specifically, INASNET attained an accuracy of 0.943, which is higher than the accuracies of VGGNet (0.896), ResNet (0.904), InceptionNet (0.900), and NasNet (0.861). Similarly, INASNET showed better precision, recall, and F1-score values, indicating its effectiveness in accurately classifying COVID-19 cases from X-ray images.\n\nAdditionally, we analyzed the training and validation performance of the models. Our hybrid model exhibited a lower average validation loss of 0.019, compared to VGGNet (0.508), ResNet (0.202), InceptionNet (0.423), and NasNet (0.197). This lower validation loss suggests that our model generalizes better to unseen data, which is crucial for real-world applications.\n\nIn summary, our comparison with publicly available methods and simpler baselines demonstrated that INASNET outperforms existing deep learning models in detecting COVID-19 from X-ray images. This superior performance is evident in various metrics and validates the effectiveness of our hybrid approach in automating the testing process for COVID-19.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files used in our study are not directly available. However, the paper-related code is publicly accessible for open access. This code can be found on GitHub at the following URL: https://github.com/murukessanap/inceptionNasnet. The code provides the necessary tools and methods to replicate the evaluation process described in our paper. This includes the metrics used for evaluation, such as accuracy, precision, recall, and F1-score, as well as the equations for calculating these metrics. By using the provided code, researchers can perform their own evaluations and analyses, ensuring reproducibility and transparency in our findings."
}