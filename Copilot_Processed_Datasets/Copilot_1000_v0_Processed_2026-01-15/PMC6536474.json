{
  "publication/title": "Colorectal cancer and adenoma screening using urinary volatile organic compound (VOC) detection \u2013 Early results from a single centre bowel screening population (UK BCSP)",
  "publication/authors": "The authors who contributed to the article are:\n\n- Mozdiak, Ella\n- Wicaksono, Arief Nur\n- Covington, James A.\n- Arasaradnam, Ramesh P.\n\nThe corresponding author is Ella Mozdiak. The specific contributions of each author to the paper are not detailed.",
  "publication/journal": "Techniques in Coloproctology",
  "publication/year": "2019",
  "publication/pmid": "30989415",
  "publication/pmcid": "PMC6536474",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Colorectal cancer\n- Urinary volatile organic compounds\n- VOC detection\n- Bowel cancer screening\n- FAIMS\n- GC-IMS\n- Biomarkers\n- Disease detection\n- Machine learning\n- Statistical analysis",
  "dataset/provenance": "The dataset used in this study was sourced from a single-center bowel screening population within the UK Bowel Cancer Screening Programme (BCSP). A total of 163 urine samples were analyzed. These samples were collected from individuals undergoing screening, with the majority being from males (57%). The median age of the participants was 67 years. Among the participants, 7.4% were current smokers, 25.4% were ex-smokers, and 67.2% had never smoked. The samples were categorized based on diagnostic outcomes, which included various conditions such as colorectal cancer (CRC), adenomas, diverticular disease, normal findings, hemorrhoids, and other conditions.\n\nThe data used in this study has not been previously published or used by the community in other papers. This is the first time this specific dataset is being analyzed and presented in a scientific publication. The analysis involved the detection of volatile organic compounds (VOCs) in urine samples using field asymmetric waveform ion mobility spectrometry (FAIMS) and gas chromatography-ion mobility spectrometry (GC-IMS). The results indicate the feasibility of detecting CRC and adenomas through urinary VOCs within a screening population. However, the classification of adenomas from control samples was found to be poor, suggesting that biomarker-led disease detection may require a panel of markers rather than focusing on a single marker.",
  "dataset/splits": "In our study, we employed several data splits to evaluate the performance of our classification models. The primary split involved comparing colorectal cancer (CRC) cases against normal controls. This split consisted of 12 CRC samples and 12 normal control samples.\n\nAdditionally, we conducted further analyses by grouping CRC with different categories of adenomas and comparing them against normal controls or other diagnoses. For instance, we grouped CRC with all adenomas, high-risk adenomas, intermediate-risk adenomas, and low-risk adenomas. The sample sizes for these groups varied, with the largest group consisting of 93 samples (CRC + all adenomas) and the smallest consisting of 12 samples (CRC vs intermediate-risk adenomas or low-risk adenomas).\n\nThe distribution of data points in each split was designed to ensure a fair comparison. For the CRC vs normal control split, the number of samples was balanced to avoid bias. In other splits, the number of samples reflected the prevalence of each diagnostic category in the study population.\n\nFor the GC-IMS analysis, we also devised five comparator groups according to outcome, with sample sizes ranging from 12 to 93, depending on the specific comparison being made. These splits allowed us to assess the sensitivity and specificity of our models across different diagnostic categories.\n\nIn summary, our study utilized multiple data splits to thoroughly evaluate the performance of our classification models. The number of data points in each split varied depending on the specific comparison, with a focus on ensuring balanced and representative sample sizes.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study is not publicly available. The study involved analyzing urine samples from a specific screening population, and the raw data collected from the analytical instruments was processed through a detailed pipeline. This pipeline included steps such as aligning and cropping irrelevant data, applying a 2D Discrete Wavelet Transformation, and feature selection/exclusion. The data was then used to train various classification models, including sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network.\n\nThe study results, including diagnostic outcomes and classification metrics, are presented in the publication. However, the specific datasets and data splits used for training and testing the models are not released in a public forum. The analysis was conducted using proprietary methods and tools, and the data remains confidential to ensure patient privacy and comply with ethical standards.\n\nThe study acknowledges the contributions of various individuals and institutions involved in patient recruitment and data collection. All procedures were performed in accordance with ethical standards, and informed consent was obtained from all participants. The publication is distributed under the Creative Commons Attribution 4.0 International License, which permits unrestricted use, distribution, and reproduction of the article, provided appropriate credit is given to the original authors and the source. However, this license does not extend to the underlying data used in the study.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are not new. They are well-established methods commonly employed in data analysis and classification tasks. The specific algorithms utilized include sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network. These algorithms were chosen for their effectiveness in building prediction models from training sets of known cases and making predictions on unknown cases.\n\nThe decision to use these established algorithms was driven by their proven track record in handling complex datasets and their ability to provide accurate classifications. The focus of this study was on applying these algorithms to analyze data from field asymmetric waveform ion mobility spectrometry (FAIMS) and gas chromatography coupled with ion mobility spectrometry (GC-IMS) to detect colorectal cancer and adenomas. The algorithms were selected based on their suitability for the specific types of data generated by these analytical instruments.\n\nThe study did not introduce a new machine-learning algorithm. Instead, it leveraged existing algorithms to achieve high accuracy in classifying colorectal cancer and adenomas. The results demonstrated the effectiveness of these algorithms in distinguishing between different diagnostic groups, particularly in the context of colorectal cancer screening. The use of these established methods ensures reliability and comparability with other studies in the field.",
  "optimization/meta": "The study employed a meta-predictor approach, utilizing data from multiple machine-learning algorithms as input. This method involves constructing computerised algorithms that learn from and make predictions on the output data from analytical instruments. Specifically, five classification models were used: sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network. Each dataset was compared with each model to determine the most accurate one for specific sets of samples.\n\nThe meta-predictor approach aims to enhance the accuracy of disease detection by leveraging the strengths of different machine-learning methods. The training data for these models was carefully managed to ensure independence, minimizing the risk of bias. This was achieved through a balancing technique applied to the data, specifically the synthetic minority over-sampling technique (SMOTE), which artificially generates points to represent the control group more fairly. This technique helps in providing a more balanced and representative dataset, crucial for the reliable performance of the meta-predictor.\n\nThe use of multiple classification models allows for a comprehensive analysis, where the best-performing model is selected for each specific set of samples. This approach reflects the complexity of human disease and the need for a panel of markers rather than focusing on a single marker. The integration of these models into a meta-predictor framework enhances the robustness and accuracy of the diagnostic process.",
  "optimization/encoding": "The raw data collected from the analytical instruments was initially in the form of a 2D matrix. To prepare this data for machine-learning algorithms, several preprocessing steps were undertaken. First, large amounts of irrelevant data were extracted, aligning and cropping the data to focus on the relevant information.\n\nA 2D Discrete Wavelet Transformation was then applied to the data. This technique allowed for the extraction of subtle chemical signals that were hidden within a much larger signal, enhancing the quality and relevance of the data for analysis.\n\nFollowing this, a feature selection/exclusion process was implemented. This involved applying a simple threshold on the standard deviation of the features. For instance, wavelet features where the variance was approximately zero were removed, as these were expected to be uninformative and would not contribute to the predictive power of the models.\n\nThese preprocessing steps ensured that the data fed into the machine-learning algorithms was clean, relevant, and optimized for accurate classification and prediction.",
  "optimization/parameters": "In our study, the input parameters for the model were derived from the analysis of urinary volatile organic compounds (VOCs) using two technologies: Field Asymmetric Ion Mobility Spectrometry (FAIMS) and Gas Chromatography-Ion Mobility Spectrometry (GC-IMS). The raw data from these instruments were processed through a pipeline that included steps such as aligning and cropping irrelevant data, applying a 2D Discrete Wavelet Transformation, and feature selection/exclusion based on standard deviation thresholds.\n\nThe number of parameters (p) used in the model varied depending on the specific classification model and the dataset. Five different classification models were employed: sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network. Each dataset was compared with each model to determine the most accurate configuration for the specific set of samples.\n\nThe selection of parameters was optimized through a cross-validation technique to minimize bias and ensure the robustness of the model. This approach helped in identifying the most relevant features from the VOC data, which were then used to train the classification models. The goal was to achieve high sensitivity and specificity in distinguishing between different diagnostic outcomes, such as colorectal cancer (CRC) versus normal controls.\n\nNot sure about the exact number of parameters used in the final models, as this detail was not explicitly stated in the provided information. However, the process involved rigorous statistical analysis and machine learning techniques to ensure the reliability of the results.",
  "optimization/features": "The input features for our analysis originate from a 2D matrix constructed by the analytical instrument. This matrix undergoes several preprocessing steps, including aligning and cropping to remove irrelevant data. A 2D Discrete Wavelet Transformation is applied to extract subtle chemical signals hidden within the larger signal.\n\nFeature selection is indeed performed to enhance the quality of the input data. This process involves applying a simple threshold on the standard deviation of the features. Specifically, wavelet features with a variance close to zero are removed, as they are considered uninformative. This step ensures that only relevant and informative features are retained for further analysis.\n\nThe feature selection process is conducted using the training set only, adhering to best practices in machine learning to prevent data leakage and maintain the integrity of the model's performance evaluation. This approach helps in building a robust classification model that can generalize well to unseen data.",
  "optimization/fitting": "The fitting method employed in our study involved machine learning algorithms to analyze data from FAIMS and GC-IMS. Five classification models were utilized: sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network. Each dataset was compared with each model to determine the most accurate one for specific sets of samples.\n\nTo address the potential issue of overfitting, given that the number of parameters in some models could be large relative to the number of training points, we implemented cross-validation techniques. This method helps ensure that the models generalize well to unseen data by training and validating on different subsets of the data. Additionally, we used a balancing technique called synthetic minority over-sampling technique (SMOTE) to handle the imbalance in the dataset, which further aided in preventing overfitting by providing a more representative training set.\n\nUnderfitting was mitigated by selecting models that are capable of capturing complex patterns in the data. The use of multiple classification models allowed us to compare their performance and choose the one that best fit the data without being too simplistic. The evaluation metrics, including receiver operating characteristic (ROC) curves, area under the curve (AUC), sensitivity, and specificity, provided a comprehensive assessment of the models' performance, ensuring that they were neither too complex nor too simple for the task at hand.",
  "optimization/regularization": "A cross-validation technique was employed to minimize overfitting. This method involves partitioning the data into subsets, training the model on some subsets, and validating it on others. By rotating which subsets are used for training and validation, the model's performance can be assessed more robustly, reducing the risk of overfitting to any single subset of the data. This approach helps ensure that the model generalizes well to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the publication. Specifically, we employed five different classification models: sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network. The details of these models, including their configurations, are outlined in the methods section of the paper.\n\nThe optimization schedule and model files are not explicitly detailed in the main text but are implied through the description of the machine learning methods used. The statistical analyses were carried out using the verification package in R studio, which is an open-source software available under the GNU General Public License. This package facilitates the construction and evaluation of the classification models.\n\nFor those interested in replicating or building upon our work, the methods and models described provide a clear framework. However, specific model files and detailed optimization schedules are not provided directly in the publication. The use of open-source tools like R studio ensures that the methods are accessible and can be implemented by other researchers.\n\nThe data and methods used in this study are distributed under the terms of the Creative Commons Attribution 4.0 International License, which permits unrestricted use, distribution, and reproduction in any medium, provided appropriate credit is given to the original authors and the source. This license ensures that the findings and methods can be freely accessed and utilized by the scientific community.",
  "model/interpretability": "The models used in our study are primarily black-box models, meaning their internal workings are not easily interpretable. We employed five different classification models: sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network. Among these, sparse logistic regression and Gaussian process classifiers offer some level of transparency. For instance, sparse logistic regression provides coefficients that indicate the importance of each feature, allowing for some interpretability. However, models like random forests and neural networks are more complex and do not readily offer clear insights into how they make predictions.\n\nThe use of machine learning methods in our analysis pipeline involves constructing algorithms that learn from and make predictions on the output data from the analytical instruments. These algorithms build prediction models from a training set of known cases and use this knowledge to predict outcomes on unknown cases. While this approach is powerful for classification tasks, it often comes at the cost of interpretability. The models are trained to identify patterns in the data that may not be immediately apparent to human observers, making it challenging to explain the reasoning behind specific predictions.\n\nIn summary, while our models are effective in classifying colorectal cancer and adenomas based on urinary volatile organic compounds, they are largely black-box in nature. Efforts to enhance interpretability would involve further analysis and potentially the development of more transparent models or techniques to explain the decisions made by these complex algorithms.",
  "model/output": "The model employed in our study is designed for classification tasks. Specifically, it is used to classify patients based on their urinary volatile organic compound (VOC) profiles into different diagnostic categories, such as colorectal cancer (CRC) versus normal controls, CRC versus adenomas, and other relevant groupings. The model utilizes various classification algorithms, including sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network. These algorithms are trained on known cases to build prediction models, which are then used to classify unknown cases. The performance of these models is evaluated using receiver operating characteristic (ROC) curves, which provide metrics like area under the curve (AUC), sensitivity, and specificity. The goal is to accurately distinguish between different diagnostic outcomes based on the VOC data obtained from urine samples.",
  "model/duration": "The execution time for the model involves several steps. Initially, a 5 ml urine sample is prepared and analyzed, with a total run time of 5 minutes per sample. This process includes vapor aspiration and data collection using gas chromatography-ion mobility spectrometry (GC-IMS). The carrier gas flow rate is set at 150 ml/min, while the sample flow rate through the instrument is 20 ml/min. Sample heating is conducted up to a maximal level of 80\u00b0C, following manufacturer instructions.\n\nThe data analysis pipeline, which includes steps like aligning and cropping data, applying 2D Discrete Wavelet Transformation, feature selection, and classification model training, is computationally intensive. However, the specific time taken for these steps is not detailed. Five classification models were employed, and each dataset was compared with each model to determine the most accurate one for the specific set of samples. This process involves constructing algorithms that learn from and make predictions on the output data, which can be time-consuming depending on the complexity of the data and the computational resources available.\n\nStatistical analyses were performed using the verification package in R studio. A balancing technique, specifically the synthetic minority over-sampling technique (SMOTE), was applied to the data to ensure a fair representation of both CRC and non-CRC samples, which adds to the overall execution time. The exact duration for these statistical analyses is not specified, but it is part of the overall model execution time.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several key steps and techniques to ensure the accuracy and reliability of the results. Initially, a balancing technique was applied to the data to fairly match the non-CRC samples with the CRC samples, avoiding bias from an unbalanced control group. This involved using the synthetic minority over-sampling technique (SMOTE), where artificially generated points were plotted to represent the control group more fairly.\n\nFive classification models were employed to analyze the data created through FAIMS and GC\u2013IMS analysis. These models included sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network. Each dataset was compared with each model to determine the most accurate one for the specific set of samples. This process produced receiver operating characteristic (ROC) curves, with area under the curve (AUC), sensitivity, and specificity values calculated from the coordinates of the ROC plots.\n\nCross-validation techniques were used to minimize errors and ensure the robustness of the models. The statistical analyses were carried out using the verification package in R studio. The results indicated that colorectal cancer (CRC) could be correctly classified from control and adenomas using FAIMS and GC\u2013IMS, although the classification of adenomas from control was less accurate. This approach to disease detection faces multiple challenges due to the complexity of human disease, suggesting that biomarker-led disease detection may require a panel of markers rather than focusing on a single marker.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our diagnostic models. The primary metrics reported are the Area Under the Curve (AUC), sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics were derived from the receiver operating characteristic (ROC) curves, which are standard in the field for assessing the performance of classification models.\n\nThe AUC provides a single scalar value that summarizes the performance of the model across all classification thresholds. It ranges from 0 to 1, with higher values indicating better model performance. Sensitivity, also known as the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. PPV and NPV provide insights into the probability that a positive or negative test result is correct, respectively.\n\nThese metrics were calculated for various comparisons, including colorectal cancer (CRC) versus normal controls, CRC versus adenomas, and different categories of adenomas. For instance, when comparing CRC to normal controls, we observed high AUC values, indicating strong model performance. Similarly, sensitivity and specificity were also high in these comparisons, demonstrating the model's ability to accurately distinguish between CRC and normal samples.\n\nIn addition to these standard metrics, we also reported the 95% confidence intervals (CIs) for each performance measure. This provides a range within which the true performance metric is likely to fall, giving a sense of the uncertainty associated with our estimates. The use of these metrics aligns with common practices in the literature, ensuring that our results are comparable with other studies in the field.\n\nOverall, the set of metrics reported in our study is comprehensive and representative of the standards in the literature. They provide a clear and detailed assessment of the model's performance, allowing for meaningful comparisons with other diagnostic tools and studies.",
  "evaluation/comparison": "In our study, we employed multiple classification models to analyze data from two different technologies: Field Asymmetric Waveform Ion Mobility Spectrometry (FAIMS) and Gas Chromatography-Ion Mobility Spectrometry (GC-IMS). These models included sparse logistic regression, random forest, Gaussian process classifier, support vector machine, and neural network. Each dataset was compared with each model to determine the most accurate for specific sets of samples.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets. However, we utilized a cross-validation technique to minimize bias and ensure the robustness of our results. This approach allowed us to evaluate the performance of our models more reliably.\n\nIn terms of simpler baselines, our study focused on comparing the performance of different machine learning models rather than simpler baselines. The models we used are standard in the field of machine learning and are known for their effectiveness in handling complex datasets. We did not include simpler baselines such as logistic regression without feature selection or basic decision trees, as our primary goal was to assess the capability of more advanced models in classifying colorectal cancer (CRC) and adenomas using urinary volatile organic compounds (VOCs).\n\nThe performance of these models was evaluated using receiver operating characteristic (ROC) curves, which provided area under the curve (AUC), sensitivity, and specificity values. These metrics allowed us to compare the effectiveness of each model in distinguishing between different diagnostic groups. The results indicated that while CRC could be accurately classified from control and adenomas using both FAIMS and GC-IMS, the classification of adenomas from control was less successful. This suggests that the approach to disease detection using urinary VOCs is feasible but faces challenges due to the complexity of human disease. It is likely that biomarker-led disease detection will require a panel of markers rather than focusing on a single marker.",
  "evaluation/confidence": "The evaluation of our methods includes a comprehensive assessment of performance metrics, which are accompanied by confidence intervals to provide a clear understanding of their reliability. For instance, the area under the curve (AUC), sensitivity, and specificity values are presented with corresponding 95% confidence intervals (CIs). This approach ensures that the reported metrics are not just point estimates but are supported by a range that reflects the uncertainty in the measurements.\n\nStatistical significance is a crucial aspect of our evaluation. We employed techniques such as the synthetic minority over-sampling technique (SMOTE) to balance the dataset, which is essential for avoiding bias, especially given the relatively small number of colorectal cancer (CRC) samples within the screening population. This balancing technique helps in providing a more fair representation of the control group, thereby enhancing the robustness of our statistical analyses.\n\nThe use of machine learning methods, including sparse logistic regression and Gaussian processes, allows for the construction of prediction models that are trained on known cases and then tested on unknown cases. The resulting receiver operating characteristic (ROC) curves, along with the calculated AUC, sensitivity, and specificity values, provide a thorough evaluation of the models' performance. These metrics are derived from the coordinates of the ROC plots, ensuring that the results are statistically sound and reliable.\n\nIn summary, the performance metrics in our study are robustly evaluated with confidence intervals, and the results are statistically significant. This rigorous approach allows us to confidently claim the superiority of our methods over others and established baselines.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The data used in this study was collected from a specific population undergoing bowel screening, and it is not released for public access. The study focuses on the analysis of volatile organic compounds (VOCs) in urine samples using advanced analytical techniques such as FAIMS and GC-IMS. The raw data is processed through a detailed pipeline that includes steps like aligning and cropping, 2D Discrete Wavelet Transformation, feature selection, and classification model training. The results of these analyses are presented in the form of ROC curves and statistical metrics, but the underlying raw data itself is not made available to the public."
}