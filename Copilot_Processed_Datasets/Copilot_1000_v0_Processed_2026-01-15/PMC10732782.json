{
  "publication/title": "PhosBoost: Improved phosphorylation prediction recall using gradient boosting and protein language models",
  "publication/authors": "The authors who contributed to this article are Elly Poretsky, Christopher M. A. Austin, and Taner Z. Sen. Elly Poretsky designed the research, performed the research, and drafted the manuscript. Christopher M. A. Austin and Taner Z. Sen designed the research and revised and finalized the manuscript.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2023",
  "publication/pmid": "38124705",
  "publication/pmcid": "PMC10732782",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Protein phosphorylation\n- Machine learning\n- PhosBoost\n- Plant species\n- Post-translational modification\n- Gradient boosting\n- CatBoost\n- Predictive modeling\n- Bioinformatics\n- Genomic coverage",
  "dataset/provenance": "The dataset used in our study was obtained from qPTMplants, a comprehensive database for high-throughput plant post-translational modification experimental data. This database includes protein phosphorylation data for over 30 plant species, collected from various experiments representing different organs, developmental stages, and conditions. The dataset is particularly rich in data for Arabidopsis thaliana, which is why we focused on this species for model training, hyperparameter tuning, and performance benchmarking. The dataset includes experimentally derived positive phosphosites, with the remaining Ser, Thr, and Tyr residues forming the negative phosphosite dataset. The data was split into training, validation, and test sets using a 60%\u201320%\u201320% ratio, respectively. The Ser and Thr phosphosites were combined for training and testing a combined binary S/T classification model. This dataset has been used in previous studies and by the community for similar purposes, making it a reliable source for our research.",
  "dataset/splits": "The dataset was split into three distinct parts: training, validation, and testing sets. This split was done using a 60%\u201320%\u201320% ratio, respectively. The data was stratified randomly to ensure that each split maintained a representative distribution of the original dataset's characteristics. This approach helps in effectively training, validating, and testing the models while maintaining the integrity and representativeness of the data across all splits.",
  "dataset/redundancy": "The datasets used in our study were derived from the qPTMplants database, which contains comprehensive protein phosphorylation data for over 30 plant species. For our model training, hyperparameter tuning, and performance benchmarking, we focused on the Arabidopsis thaliana dataset due to its predominance and relative saturation of phosphorylation data.\n\nThe complete A. thaliana dataset was randomly split into stratified training, validation, and testing sets using a 60%\u201320%\u201320% split, respectively. This splitting ensures that the training and test sets are independent, which is crucial for evaluating the generalizability of our models. The stratification process maintains the distribution of positive and negative phosphosites in each subset, ensuring that the models are trained and tested on representative samples of the data.\n\nThe Ser and Thr phosphosites were combined to train and test a combined binary S/T classification model. This approach helps in leveraging the shared characteristics of Ser and Thr residues, potentially improving the model's performance. The Tyr phosphosites were handled separately due to their distinct biochemical properties and lower prevalence in the dataset.\n\nThe distribution of our datasets compares favorably to previously published machine learning datasets in the field of protein phosphorylation prediction. The use of a comprehensive and well-curated database like qPTMplants ensures that our models are trained on high-quality data, which is essential for achieving robust and reliable predictions. The stratified splitting method also aligns with best practices in machine learning, ensuring that our models are evaluated on independent and representative datasets.",
  "dataset/availability": "The data used in this study is publicly available for download directly from the qPTMplants database. This database contains comprehensive protein phosphorylation data for over 30 plant species, collected from various experiments representing different organs, developmental stages, and conditions. The data includes experimentally derived positive phosphosites, with the remaining Ser, Thr, and Tyr residues forming the negative phosphosite dataset. The dataset was split into training, validation, and test sets using a 60%\u201320%\u201320% ratio, respectively, with random stratification applied to the individual Ser, Thr, and Tyr datasets.\n\nAdditionally, the Ramasamy22 human phosphoproteomic dataset was used for benchmarking purposes. This dataset was obtained from the PhosphoLingo preprint and was utilized to compare the performance of PhosBoost with existing methods under different conditions.\n\nAll the analysis steps, code for reproducing results and figures, and links to raw data and results are available on GitHub. This ensures transparency and reproducibility of the research. The GitHub repository provides detailed explanations and instructions for accessing and using the data, making it accessible to other researchers in the field. The data and code are released under a license that allows for open access and use, promoting collaboration and further advancements in protein phosphorylation prediction methods.",
  "optimization/algorithm": "The optimization algorithm used in our study is Bayesian optimization, specifically implemented through the BayesianOptimization function from the bayes_opt Python package. This method is not new and is widely used for hyperparameter tuning in machine learning models. It was chosen for its efficiency in optimizing complex, high-dimensional spaces, which is crucial for fine-tuning the parameters of our stacking classifier.\n\nThe machine-learning algorithm class used is a stacking classifier, which is a type of ensemble learning method. This approach combines multiple base classifiers to improve overall performance. In our case, the stacking classifier consists of two CatBoost base classifiers and a logistic regression meta-classifier. CatBoost is a gradient boosting library that is known for its effectiveness in handling categorical features and reducing overfitting.\n\nThe reason this algorithm was not published in a machine-learning journal is that it is not a novel algorithm but rather a well-established method in the field. Our focus was on applying this method to the specific problem of protein phosphorylation prediction, rather than developing a new machine-learning algorithm. The use of stacking classifiers and Bayesian optimization is well-documented in the literature, and our contribution lies in demonstrating their effectiveness in the context of protein phosphorylation classification.",
  "optimization/meta": "The model employs a stacking classifier approach, which is a type of ensemble learning method. This approach involves two main steps. In the first step, multiple base classifiers are trained separately using the training data. In the second step, the predicted probability scores from these base classifiers are used as new features to train a final meta-classifier. This meta-classifier integrates the results from the base classifiers to make the final predictions.\n\nThe stacking classifier used in this model consists of two CatBoost base classifiers and a logistic regression meta-classifier. The CatBoost classifiers are trained with different class weight parameters: one with balanced class weights and the other with equal class weights. The predicted probability scores from these two base classifiers are then used as input features for the logistic regression meta-classifier.\n\nTo ensure that the training data for the meta-classifier is independent, a cross-validated prediction approach is used. This means that the meta-classifier is trained using predictions from the base classifiers that were made on validation folds not used to train those base classifiers. This method helps to reduce overfitting by ensuring that the meta-classifier is not trained on the same data used to train the base classifiers.",
  "optimization/encoding": "In our study, we utilized the pre-trained ProtT5-XL-U50 protein language model (pLM) to encode the protein phosphorylation data from the qPTMplants database. This process generated embedding vector data for all serine (S), threonine (T), and tyrosine (Y) residues, as well as the protein-wise average embedding vector. The input data for all Arabidopsis thaliana phosphosites was then used to train two separate binary classifiers: the S/T model and the Y model. These classifiers were developed using a stacking approach termed PhosBoost.\n\nThe stacking classifier is composed of two CatBoost base classifiers: one trained with equal class weights and the other with balanced class weights. The predicted probability scores from these base classifiers were combined using a logistic regression metaclassifier to produce the final PhosBoost predictions. This method ensures that the model can handle imbalanced datasets effectively.\n\nThe protein sequences were obtained from genomic databases such as UniProt, Phytozome, and EnsemblPlants, and processed using BioPython. Sequences containing non-canonical or missing amino acids were discarded to ensure data quality. The phosphorylation positions were cross-referenced to match the protein sequences, and any non-matching sequences were removed. The resulting FASTA file was used to calculate the embedding vectors using the ProtT5-XL-U50 pLM.\n\nThe combined S/T/Y amino-acid and protein-wise average embedding data were used as input for the PhosBoost classifiers without any further modification. This approach leverages the power of pre-trained language models to capture complex patterns in protein sequences, enhancing the predictive performance of our machine-learning algorithm.",
  "optimization/parameters": "In the optimization process of our model, we focused on tuning three key hyper-parameters: \"n_estimators,\" \"depth,\" and \"learning_rate.\" These parameters were chosen to optimize the performance of our stacking classifier, which is composed of two CatBoost base classifiers and a logistic regression meta-classifier.\n\nThe \"n_estimators\" parameter, which determines the number of boosting rounds, was tuned within a range of 50 to 2000. The \"depth\" parameter, which specifies the depth of the trees in the ensemble, was adjusted between 2 and 10. The \"learning_rate\" parameter, which controls the contribution of each tree, was fine-tuned between 0.05 and 0.5.\n\nTo select the optimal values for these parameters, we employed Bayesian optimization using the BayesianOptimization function from the bayes_opt Python package. This method was chosen for its efficiency in exploring the hyper-parameter space and optimizing the F1-score metric over 100 iterations. The optimization was conducted separately for the two independent CatBoost classifiers, one trained with equal class weights and one with balanced class weights, and for the S/T and Y models.\n\nThe \"n_estimators\" and \"depth\" hyper-parameters were rounded to the nearest integer as instructed by the bayes_opt package. The obtained values for these hyper-parameters are available in the supplementary material. This systematic approach ensured that our model was finely tuned to achieve the best possible performance on the given datasets.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "In the development of PhosBoost, we employed a stacking classifier approach to enhance the predictive performance for protein phosphorylation. This method involves two base classifiers and a meta-classifier, which helps to mitigate both overfitting and underfitting.\n\nThe base classifiers used are CatBoost models, one trained with balanced class weights and the other with equal class weights. This dual approach ensures that the model captures both the overall characteristics of the dataset and the nuances of the minority class, thereby reducing the risk of underfitting.\n\nTo address the potential issue of overfitting, especially given the complexity of the stacking classifier, we utilized a 5-fold cross-validation approach. This technique ensures that the meta-classifier is trained on different subsets of the data, preventing it from memorizing the training data and thus reducing overfitting.\n\nAdditionally, hyperparameter tuning was conducted using Bayesian optimization, which systematically searches for the optimal values of parameters such as \"n_estimators,\" \"depth,\" and \"learning_rate.\" This process helps in finding a balance between model complexity and performance, further mitigating the risk of overfitting.\n\nThe use of a logistic regression meta-classifier, trained with balanced class weights, also contributes to the robustness of the model. This meta-classifier integrates the predictions from the base classifiers, providing a more generalized and less overfitted final model.\n\nIn summary, the combination of cross-validation, Bayesian optimization, and the stacking approach ensures that PhosBoost is neither overfitted nor underfitted, providing reliable and generalizable predictions for protein phosphorylation.",
  "optimization/regularization": "In our study, we implemented several techniques to prevent overfitting and ensure robust model performance. One key method involved using a stacking classifier approach, which combines multiple base classifiers with a meta-classifier. This ensemble method helps to reduce bias and variance by leveraging the strengths of different classifiers. Specifically, we used two CatBoost base classifiers, one trained with balanced class weights and the other with equal class weights, and a logistic regression meta-classifier. The meta-classifier was trained using a cross-validated prediction approach, which further helps in mitigating overfitting by ensuring that the meta-classifier is not trained on the same data used to train the base classifiers.\n\nAdditionally, we employed hyper-parameter tuning using Bayesian optimization. This method systematically searches for the optimal hyper-parameters, such as the number of estimators, depth, and learning rate, to improve model performance and generalization. The Bayesian optimization was conducted over 100 iterations, focusing on optimizing the F1-score metric. This rigorous tuning process helps in finding the best parameters that minimize overfitting and enhance the model's ability to generalize to unseen data.\n\nFurthermore, we compared the performance of the stacking classifier with independently trained CatBoost classifiers to provide additional support for the improved performance of the stacking approach. This comparison helps in validating that the stacking classifier indeed offers better generalization and reduces overfitting compared to individual models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available. These configurations include the values for hyper-parameters such as \"n_estimators,\" \"depth,\" and \"learning_rate,\" which were fine-tuned using Bayesian optimization. The obtained values for these hyper-parameters are documented and can be accessed.\n\nAdditionally, the model files and optimization parameters are provided to ensure reproducibility. All the necessary details for reproducing the results, including the code and data, are available on GitHub. This includes a detailed markdown page that explains all the analysis steps, the code for reproducing the results and figures, and links to the raw data and results. The GitHub repository is publicly accessible, allowing researchers to download and use the materials under the terms specified in the repository.\n\nThe protein phosphorylation data used in this study is also available for download directly from the qPTMplants database and the PhosphoLingo GitHub repository. This ensures that other researchers can access the same datasets used in our study, facilitating the replication and extension of our work.",
  "model/interpretability": "The interpretability of the PhosBoost model is a key aspect of its design, setting it apart from many other machine learning models used in bioinformatics. PhosBoost is not a black-box model; instead, it incorporates several layers of transparency that allow researchers to understand how predictions are made.\n\nOne of the primary components of PhosBoost is the use of protein language models (pLMs), specifically the ProtT5-XL-U50, which provides embeddings for phosphoprotein sequences. These embeddings capture the contextual information of amino acid residues within the protein sequences, making the model's input more interpretable. By extracting residue-specific embedding vectors for Ser, Thr, and Tyr, as well as protein-wise average embedding vectors, PhosBoost ensures that the features used for prediction are grounded in biological relevance.\n\nThe stacking classifier architecture of PhosBoost further enhances its interpretability. The model consists of two CatBoost base classifiers: one trained with balanced class weights and another with equal class weights. These base classifiers provide complementary insights into the data, with the balanced class weights classifier capturing the overall characteristics of the dataset and the equal class weights classifier focusing on the majority negative class. The predicted probabilities from these base classifiers are then used as input features for a logistic regression metaclassifier, which integrates the information in a transparent manner.\n\nAdditionally, the use of a logistic regression metaclassifier adds another layer of interpretability. Logistic regression is a well-understood model that provides probabilities based on linear combinations of input features, making it easier to trace back how specific features contribute to the final prediction. This transparency is crucial for biological research, where understanding the underlying mechanisms is as important as making accurate predictions.\n\nIn summary, PhosBoost is designed with interpretability in mind. The use of protein language models, the stacking classifier architecture, and the logistic regression metaclassifier all contribute to a model that is transparent and provides insights into the prediction process. This makes PhosBoost a valuable tool for researchers who need to understand not just the predictions but also the biological basis behind them.",
  "model/output": "The model, PhosBoost, is a classification model designed for protein phosphorylation prediction. It generates binary classifiers for serine/threonine (S/T) and tyrosine (Y) residues, indicating whether a specific residue is a phosphorylation site or not. The model uses a stacking classifier approach, combining two CatBoost base classifiers with different class weight strategies and a logistic regression metaclassifier to produce the final predictions. The output of PhosBoost includes predicted probability scores for each residue, which can be used to determine the likelihood of a residue being a phosphorylation site. These probability scores are evaluated using metrics such as the area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), recall, precision, and the F1 score. The model's performance is assessed on datasets like the A. thaliana qPTMplants and Ramasamy22, demonstrating its effectiveness in achieving higher recall scores and providing more informative predicted probability scores. The outputs are also integrated into genome browsers for better accessibility and visualization of predicted phosphosites.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for PhosBoost is publicly available on GitHub. This repository includes detailed explanations for all analysis steps, code for reproducing results and figures, and links to raw data and results. Additionally, a Python package named PTMtools has been developed to facilitate raw data processing and conversion between different file formats used by various protein phosphorylation prediction methods. This package is available through the official PyPI repository. The code and data are provided under a license that allows for open access and use by the scientific community.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its robustness and performance. Initially, the method was evaluated using a stratified split of the complete dataset into training, validation, and testing sets with a 60%\u201320%\u201320% ratio, respectively. This split was used to train and validate the stacking classifier, which consists of two base classifiers and a meta-classifier. The base classifiers were trained using different class weight parameters, and their predicted probability scores were used to train the meta-classifier. A 5-fold cross-validation approach was employed to reduce overfitting.\n\nTo further validate the performance, the method was benchmarked against two established protein phosphorylation classification methods: PhosphoLingo and DeepPhos. All three methods were evaluated on the same dataset, with PhosBoost and PhosphoLingo using the same training and validation sets for hyperparameter tuning, while DeepPhos used the combined training and validation sets. The performance was assessed using various metrics, including AUROC, AUPRC, precision, recall, and F1 scores.\n\nAdditionally, the method was tested on an independent dataset, the Ramasamy22 protein phosphorylation dataset, to provide additional support for its performance. This independent evaluation showed that the stacking classifier approach provided increased recall with no cost to precision for both the S/T and Y models.\n\nThe evaluation also included a comparison of the method's performance under different data-centric factors, such as dataset size and label imbalance. This comparison suggested that the method's performance improves with increased data size and label imbalance. Furthermore, the method was evaluated under the assumption that recall can be prioritized over precision, showing that it achieves higher performance than the other methods when recall is considered twice as important as precision.\n\nOverall, the evaluation involved a combination of cross-validation, independent dataset testing, and comparisons with established methods to ensure the robustness and performance of the method.",
  "evaluation/measure": "In our evaluation of PhosBoost, we reported several key performance metrics to comprehensively assess its effectiveness in protein phosphorylation prediction. These metrics include the area under the receiver operating characteristic curve (AUROC), precision, recall, the area under the precision-recall curve (AUPRC), and F1 scores. These metrics were chosen because they provide a well-rounded view of the model's performance, covering aspects such as the trade-off between true positive and false positive rates, the balance between precision and recall, and the overall accuracy of the predictions.\n\nThe AUROC score is a critical metric that evaluates the model's ability to distinguish between positive and negative classes across all threshold levels. It is particularly useful for imbalanced datasets, which are common in phosphorylation prediction tasks. Precision and recall are fundamental metrics that measure the accuracy of the positive predictions and the model's ability to identify all relevant instances, respectively. The AUPRC score complements the AUROC by focusing on the performance of the model at different precision-recall thresholds, which is crucial for understanding how well the model performs in practical scenarios where the cost of false positives and false negatives may vary.\n\nThe F1 score, which is the harmonic mean of precision and recall, provides a single metric that balances both concerns. This is especially important in applications where both false positives and false negatives are costly. Additionally, we used the F\u03b2 score to assess the precision-recall tradeoff under different assumptions about the importance of recall relative to precision. This allows for a more nuanced evaluation of the model's performance, particularly when recall is prioritized over precision.\n\nThese metrics are widely used in the literature for evaluating phosphorylation prediction methods, ensuring that our results are comparable to other studies in the field. By reporting these metrics, we aim to provide a clear and comprehensive understanding of PhosBoost's performance, highlighting its strengths and areas for potential improvement.",
  "evaluation/comparison": "In the evaluation of PhosBoost, a comprehensive comparison was conducted with two established protein phosphorylation prediction methods, namely PhosphoLingo and DeepPhos. This comparison was performed on two separate datasets: the A. thaliana qPTMplants dataset and the Ramasamy22 dataset. For the S/T model, PhosBoost demonstrated comparable performance to PhosphoLingo on the A. thaliana qPTMplants dataset based on AUPRC scores, but showed lower performance on the Ramasamy22 data. However, PhosBoost outperformed DeepPhos on both datasets. For the Y model, PhosBoost consistently performed better than both PhosphoLingo and DeepPhos on both datasets.\n\nThe evaluation also considered data-centric factors such as dataset size and label imbalance, which significantly impact model performance. The results suggested that PhosBoost's performance improves with larger datasets for the S/T model and with increased label imbalance for the Y model. Additionally, PhosBoost achieved higher recall scores at all probability thresholds compared to the other methods, indicating its effectiveness in predicting phosphosites.\n\nFurthermore, the precision-recall tradeoff was assessed, revealing that PhosBoost has a higher F\u03b2 score when recall is prioritized over precision. This makes PhosBoost particularly suitable for scenarios where higher recall and improved predicted phosphosite coverage are beneficial. The method also provides more informative predicted probability scores, enhancing the confidence in the predictions.\n\nIn summary, PhosBoost was benchmarked against publicly available methods on benchmark datasets, demonstrating its competitiveness and superiority in certain scenarios. The comparison to simpler baselines was not explicitly mentioned, but the focus was on established methods in the field.",
  "evaluation/confidence": "The evaluation of PhosBoost's performance metrics includes various statistical measures such as AUROC, AUPRC, precision, recall, and F1 scores. These metrics provide a comprehensive view of the model's performance across different datasets and models (S/T and Y). The results indicate that PhosBoost consistently achieves higher recall scores at all probability thresholds compared to PhosphoLingo and DeepPhos. This suggests that PhosBoost is particularly effective when recall is prioritized over precision.\n\nThe precision-recall tradeoff is also analyzed, showing that PhosBoost has a higher F\u03b2 score when recall is considered twice as important as precision. This implies that PhosBoost's performance is statistically significant in scenarios where high recall is crucial.\n\nAdditionally, the predicted probability scores from PhosBoost are more indicative of whether a phosphosite is a true or false positive, providing more confident and informative predictions. This is supported by the distribution of predicted probability scores, where the true positives generally have higher scores than false positives.\n\nThe comparison with established methods like PhosphoLingo and DeepPhos further validates PhosBoost's superior performance, especially in terms of recall and the confidence of predicted probability scores. The results are benchmarked on multiple datasets, including A. thaliana qPTMplants and Ramasamy22, ensuring robustness and reliability.\n\nOverall, the evaluation confidence is high, as the performance metrics and statistical analyses consistently demonstrate PhosBoost's advantages over existing methods. The detailed comparison and the use of multiple datasets strengthen the claim that PhosBoost is a superior method for protein phosphorylation prediction.",
  "evaluation/availability": "The raw evaluation files are not directly available for download. However, a detailed markdown page provides explanations for all analysis steps, code for reproducing results and figures, and links to raw data and results. This information is available on GitHub at a specific repository. The protein phosphorylation data used in this study is available for download directly from the qPTMplants database and the PhosphoLingo GitHub repository. Additionally, several helper functions to facilitate raw data processing and conversion between different file formats used by different protein phosphorylation prediction methods are available through the official PyPI repository as a python package named PTMtools."
}