{
  "publication/title": "Machine Learning and Prediction of All-Cause Mortality in COPD",
  "publication/authors": "The authors who contributed to the article are:\n\nMatthew Moll, Dandi Qiao, Elizabeth A. Regan, Gary M. Hunninghake, Barry J. Make, Ruth Tal-Singer, Michael J. McGeachie, Peter J. Castaldi, Raul San Jose Estepar, George R. Washko, James M. Wells, David LaFon, Matthew Strand, Russell P. Bowler, MeiLan K. Han, Jorgen Vestbo, Bartolome Celli, Peter Calverley, James Crapo, Edwin K. Silverman, Brian D. Hobbs, and Michael H. Cho.\n\nThe contributions to the paper were as follows:\n\nMatthew Moll, Dandi Qiao, Elizabeth A. Regan, Gary M. Hunninghake, Barry J. Make, Ruth Tal-Singer, Michael J. McGeachie, Peter J. Castaldi, Edwin K. Silverman, Brian D. Hobbs, and Michael H. Cho contributed to the study design.\n\nMatthew Moll, Gary M. Hunninghake, Michael J. McGeachie, Peter J. Castaldi, Raul San Jose Estepar, George R. Washko, James M. Wells, Edwin K. Silverman, Brian D. Hobbs, and Michael H. Cho contributed to the acquisition, analysis, or interpretation of the data.\n\nAll authors contributed to the critical revision of the manuscript for important intellectual content.\n\nMatthew Moll, Dandi Qiao, Michael J. McGeachie, Edwin K. Silverman, Brian D. Hobbs, and Michael H. Cho contributed to the statistical analysis.\n\nEdwin K. Silverman and Michael H. Cho obtained funding.",
  "publication/journal": "CHEST",
  "publication/year": "2020",
  "publication/pmid": "32353417",
  "publication/pmcid": "PMC7478228",
  "publication/doi": "https://doi.org/10.1016/j.chest.2020.02.079",
  "publication/tags": "- COPD\n- Mortality Prediction\n- Machine Learning\n- Random Survival Forests\n- COPDGene Study\n- ECLIPSE Study\n- Quantitative CT Imaging\n- Survival Analysis\n- BODE Index\n- Predictive Modeling\n- Chronic Obstructive Pulmonary Disease\n- Clinical Features\n- Spirometric Features\n- Imaging Features\n- Health Outcomes",
  "dataset/provenance": "The dataset used in this study is sourced from two large-scale studies focused on chronic obstructive pulmonary disease (COPD). The first study is the Genetic Epidemiology of COPD (COPDGene) study, which includes individuals with moderate to severe COPD. The second study is the Evaluation of COPD Longitudinally to Identify Predictive Surrogate Endpoints (ECLIPSE) study. Both studies have been instrumental in providing comprehensive data on COPD patients, including clinical, spirometric, and imaging features.\n\nThe COPDGene study contributed a significant number of data points, with 1,974 subjects used for training the models and 658 subjects used for testing within the same dataset. Additionally, the ECLIPSE study provided 1,268 subjects for external validation of the models. These datasets were carefully selected to ensure that the same variables could be examined across both studies, with a focus on features present in at least 80% of the subjects.\n\nThe data from these studies have been utilized in various research endeavors, including the development and validation of prognostic models for COPD. The COPDGene project has been supported by the National Institutes of Health and the COPD Foundation, with contributions from several pharmaceutical companies. The ECLIPSE study was funded by GlaxoSmithKline and has been used in multiple research papers to validate and compare different prognostic models. The datasets have been widely recognized and used by the scientific community to advance the understanding and management of COPD.",
  "dataset/splits": "There were two main data splits used in the study. The first split involved training models on 75% of the COPDGene sample, which consisted of 1,974 subjects, and testing them on the remaining 25% of the COPDGene sample, totaling 658 subjects. The second split involved training models on the same 75% of the COPDGene sample and testing them on the ECLIPSE sample, which included 1,268 subjects.\n\nThe COPDGene study included individuals with moderate to severe COPD, and the ECLIPSE study also focused on similar COPD patients. The characteristics of the subjects in both studies were analyzed, with notable differences in follow-up duration, BMI, FEV1 % predicted, and mortality rates. The COPDGene sample had a higher proportion of African American subjects and a slightly higher median FEV1 % predicted compared to the ECLIPSE sample. The ECLIPSE study had a higher proportion of individuals who died and differed in several quantitative CT imaging measures.",
  "dataset/redundancy": "The datasets used in our study were split to ensure robust training and testing of our models. Specifically, we utilized data from the COPDGene study, which included individuals with moderate to severe COPD. The COPDGene dataset was divided into a training set comprising 75% of the sample (1,974 participants) and a testing set comprising the remaining 25% (658 participants). This split was done randomly to ensure that the training and testing sets were independent.\n\nTo further validate our model, we employed an external validation approach using the ECLIPSE dataset. The models trained on 75% of the COPDGene sample were tested on the entire ECLIPSE sample, which consisted of 1,268 participants. This external validation is crucial as it helps to assess the generalizability of our model across different cohorts.\n\nThe independence of the training and testing sets was enforced through random splitting of the COPDGene dataset. Additionally, the ECLIPSE dataset served as a completely independent cohort for external validation, ensuring that our model's performance could be evaluated in a different population.\n\nCompared to previously published machine learning datasets in the field of COPD, our approach stands out due to the larger number of subjects and the longer follow-up periods. The BODE index, for instance, was developed using a smaller sample size and shorter follow-up duration. Our study included 1,974 subjects from the COPDGene study with a median follow-up of 6.4 years, providing a more comprehensive and robust dataset for model development and validation. This larger and more diverse dataset allows for more reliable and generalizable predictions of COPD mortality.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the random survival forest (RSF). This algorithm is well-established and has been previously applied in various predictive modeling tasks, particularly in survival analysis.\n\nThe RSF algorithm is not new; it has been developed and refined over time by the machine learning community. The decision to use RSF in our study was driven by its robustness and effectiveness in handling complex datasets, which include both clinical and imaging features.\n\nGiven that RSF is a well-known algorithm, it was not necessary to publish it in a machine-learning journal. Instead, our focus was on applying this established method to a specific medical problem\u2014predicting all-cause mortality in patients with COPD. By leveraging the strengths of RSF, we aimed to develop a model that outperforms existing clinical indices, such as the BODE index and its modifications. The results of our study demonstrate the utility of RSF in this context, highlighting its potential for improving mortality prediction in COPD patients.",
  "optimization/meta": "The model developed in this study is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it leverages a combination of clinical, spirometric, and imaging features to predict all-cause mortality in COPD patients.\n\nThe primary machine-learning method used is the random survival forest (RSF), which is employed for variable selection. The top features identified by the RSF are then used in a Cox regression model to create the machine learning mortality prediction (MLMP) in COPD model.\n\nThe training data for the models was derived from the COPDGene study, with 75% of the sample used for training and the remaining 25% used for testing. Additionally, the model was tested in the ECLIPSE sample, ensuring that the training and testing data were independent. This approach helps to validate the model's performance across different cohorts and reduces the risk of overfitting.",
  "optimization/encoding": "For the machine-learning algorithm, we began by selecting 30 clinical, spirometric, and imaging features as inputs. These features were chosen to ensure they were present in at least 80% of the cohort, allowing for consistent analysis across different datasets. The features included demographic information, clinical measurements, spirometric data, and quantitative CT imaging metrics.\n\nThe clinical features encompassed variables such as age, presence of diabetes, and other relevant health indicators. Spirometric features included measurements like FEV1 % predicted, FEV1/FVC ratio, and forced expiratory flow between 25% and 75% of the FVC. Imaging features involved quantitative CT metrics such as pulmonary artery-to-aorta ratio, mean wall area percent, and percentage of low attenuation areas.\n\nBefore applying the random survival forest (RSF) algorithm, we pre-processed the data to handle missing values and ensure consistency. Features displaying multicollinearity were excluded to avoid redundancy and improve the model's performance. The remaining features were then used to develop a Cox regression model, which was further refined to create the machine learning mortality prediction (MLMP) in COPD model.\n\nThe MLMP-COPD model was trained on a subset of subjects with moderate to severe COPD from the COPDGene study and tested on the remaining individuals from the same study, as well as on participants from the ECLIPSE study. This approach ensured that the model's predictive performance was validated across different cohorts, enhancing its generalizability and reliability.",
  "optimization/parameters": "In our study, we initially considered 30 clinical, spirometric, and imaging features as potential input parameters for our model. To ensure consistency across datasets, we selected features that were present in at least 80% of the subjects in both the COPDGene and ECLIPSE studies. This filtering process helped us to maintain a robust and comparable set of features.\n\nWe employed a random survival forest (RSF) algorithm for feature selection, which allowed us to identify the most important variables. The RSF algorithm ranked features based on their importance, and we used this ranking to select the most relevant features for our model. This approach helped us to balance prediction accuracy and model interpretability.\n\nBefore applying Cox regression, we excluded features that displayed multicollinearity to ensure that all variance inflation factors were below 10. This step was crucial to avoid redundancy and to maintain the stability of our model. The final set of features used in our Cox regression model included components of the BODE score, such as BMI, FEV1 % predicted, modified Medical Research Council dyspnea score, and exercise capacity assessed by the 6-minute walk distance (6MWD). Additionally, we included other clinical features like age and diabetes, spirometric features such as FEV1/FVC ratio and forced expiratory flow 25% to 75%, and imaging features like Pi10, mean wall area percent, % LAA < -950 HU, and PA:A ratio.\n\nThe final model incorporated a subset of these RSF-selected features, ensuring that our mortality prediction model was both accurate and interpretable. The specific features and their associated hazard ratios are detailed in the relevant tables and figures of our publication.",
  "optimization/features": "In the optimization process of our study, we initially considered a set of 30 clinical, spirometric, and imaging features as potential inputs for our random survival forest model. To ensure consistency and availability across both datasets, we selected features that were present in at least 80% of the subjects. Feature selection was performed using the training set only, ensuring that the model's performance could be validated on unseen data. The random survival forest algorithm was employed to identify the most important features, which were then used to develop a Cox regression model. This approach helped in balancing prediction accuracy and interpretability, ensuring that the selected features were both relevant and reliable for mortality prediction in COPD patients.",
  "optimization/fitting": "The fitting method employed in our study involved training models using a subset of data from the COPDGene study, specifically 75% of the sample, which amounted to 1,974 individuals. The remaining 25%, or 658 individuals, served as the test set. Additionally, models were also trained on the same 75% of the COPDGene sample and tested on the ECLIPSE sample, consisting of 1,268 individuals. This approach helped in validating the models' performance on an external dataset, reducing the risk of overfitting.\n\nTo address the potential issue of overfitting, given the number of parameters relative to the training points, we utilized random survival forests (RSF) for variable selection. This method helped in identifying the most important predictors of survival, thereby reducing the number of predictors and creating a more parsimonious model. The use of RSFs, along with traditional Cox regression, ensured that the model was not overly complex and could generalize well to independent cohorts. Furthermore, we performed external validation on the ECLIPSE dataset, which showed that the models retained improved prediction compared to existing indices like BODE and ADO, indicating that overfitting was effectively ruled out.\n\nTo mitigate underfitting, we selected a comprehensive set of 30 clinical, spirometric, and imaging features that were present in at least 80% of the subjects in both datasets. This ensured that the models had a rich set of predictors to work with, capturing the underlying patterns in the data. Additionally, the use of RSFs for variable selection and Cox regression for model building provided a balance between simplicity and accuracy, ensuring that the models were neither too simple to capture the data's complexity nor too complex to generalize well. The performance of the models on the external validation set further confirmed that underfitting was not a concern.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure that our model generalized well to independent cohorts. One of the key methods used was the random survival forest (RSF) for feature selection. This approach helped in identifying the most important predictors of survival, reducing the number of predictors and thus mitigating the risk of overfitting. By using RSFs for variable selection and then applying Cox regression, we developed a more parsimonious model that is less likely to overfit the data.\n\nAdditionally, we performed external validation of our model. The model was initially trained on a subset of the COPDGene sample and then tested on both the remaining COPDGene sample and an entirely separate ECLIPSE sample. This external validation step is crucial as it helps to assess the model's performance on data it has not seen during training, providing a more robust evaluation of its generalizability.\n\nWe also normalized imaging features across matched subsets of individuals from the COPDGene and ECLIPSE studies. This step aimed to reconcile differences in mean values and distributions of imaging features, further ensuring that our model's performance was not unduly influenced by dataset-specific characteristics.\n\nMoreover, we examined the calibration of our model by plotting expected vs. actual survival and using the Greenwood-Nam-D\u2019Agostino test. The results indicated that our model was well-calibrated, which is another indicator of its reliability and generalizability.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The MLMP-COPD model, while leveraging advanced machine learning techniques, is designed to be interpretable and not a black box. The model's development process included the use of random survival forests (RSF) for variable selection, which helped identify the most important predictors of mortality. These top predictors, such as 6-min walk distance, FEV1 % predicted, age, and the pulmonary artery-to-aorta ratio, are clinically meaningful and easily understandable.\n\nThe model's transparency is further enhanced by the use of Cox regression, a traditional statistical method, which allows for the calculation of regression coefficients. These coefficients provide insights into the relative contributions of each predictor to the overall risk of mortality. For instance, the model can show how changes in specific variables, like age or 6-min walk distance, influence the predicted survival outcomes.\n\nAdditionally, an online tool has been developed to allow researchers and clinicians to explore the contributions of the model's features to predicted COPD survival. This tool enables users to observe how altering input values affects predicted survival, making the model's decision-making process more transparent and understandable.\n\nThe model's performance was also compared with established indices like BODE and ADO, providing a benchmark for its interpretability. The MLMP-COPD model identified subjects at high risk of death based on variables not included in the BODE index, offering new insights into mortality prediction in COPD.\n\nIn summary, the MLMP-COPD model strikes a balance between leveraging advanced machine learning techniques and maintaining interpretability. The use of clinically meaningful predictors, Cox regression coefficients, and an online exploration tool ensures that the model's decision-making process is transparent and understandable.",
  "model/output": "The model developed in our study is a regression model, specifically a Cox regression model. This type of model is used for survival analysis, which is a branch of statistics for analyzing the expected duration until one or more events happen, such as death or disease recurrence. In our case, the model predicts all-cause mortality in individuals with COPD.\n\nThe model was built using features selected by a random survival forest algorithm, which is a machine learning technique designed for survival analysis. The top predictors of mortality identified by the model include the 6-minute walk distance, FEV1 % predicted, age, and the pulmonary artery-to-aorta ratio.\n\nThe performance of the model was evaluated using the C index, which is a measure of discrimination for survival models. The model achieved a C index of 0.7 in both the training and testing samples, indicating good predictive performance. The model also outperformed existing mortality indexes, such as the BODE index and its modifications, as well as the ADO index.\n\nThe model is available online, allowing for its application in clinical settings to aid in the prediction of all-cause mortality in individuals with COPD. The online tool can be accessed at the following link: https://cdnm.shinyapps.io/cgmortalityapp/.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the machine learning mortality prediction model in COPD is not publicly released. However, an online web application has been developed to facilitate the use of the model. This application allows users to explore the relative contributions of risk factors for all-cause mortality in COPD and is accessible at https://cdnm.shinyapps.io/cgmortalityapp/. The application provides a user-friendly interface for inputting patient data and observing how altering input values affects predicted survival. This tool is designed to aid in clinical decision-making and improve the understanding of mortality risks in COPD patients. The application is available for use, but specific details about the licensing terms are not provided.",
  "evaluation/method": "The evaluation of the MLMP-COPD model involved a comprehensive approach to ensure its robustness and generalizability. Initially, models were trained using 75% of the COPDGene sample, which consisted of 1,974 subjects, and tested on the remaining 25% of the COPDGene sample, comprising 658 subjects. This internal validation helped assess the model's performance within the same dataset.\n\nTo further validate the model's performance, an external validation was conducted using the ECLIPSE sample, which included 1,268 subjects. This step was crucial for evaluating the model's ability to generalize to different populations and ensuring that it was not overfitted to the training data.\n\nThe performance of the MLMP-COPD model was compared against established indices such as BODE, BODE modifications, and ADO. The comparison was done using C-statistics, which measure the discriminative ability of the models. The MLMP-COPD model demonstrated superior predictive performance across multiple cohorts of patients with moderate to severe COPD.\n\nAdditionally, the model's calibration was examined by plotting expected versus actual survival and using the Greenwood-Nam-D\u2019Agostino test. This analysis showed that the MLMP-COPD model was well-calibrated, indicating that its predicted probabilities of survival were accurate.\n\nTo address the variability in feature availability in clinical practice, the performance of prediction models excluding select features was also calculated. A Cox model built after excluding imaging features still improved prediction compared with updated BODE and ADO on the ECLIPSE validation sample. This suggests that the model's predictive power is robust even when certain features are not available.\n\nOverall, the evaluation method involved a combination of internal and external validation, comparison with established indices, and assessment of model calibration. This thorough approach ensures that the MLMP-COPD model is reliable and generalizable for predicting mortality in patients with COPD.",
  "evaluation/measure": "In our evaluation, we primarily reported the C index (also known as the concordance index) to assess the performance of our models. This metric is widely used in survival analysis and provides a measure of the model's ability to correctly predict the order of survival times. We compared the C indexes of our models with those of established indices such as BODE, updated BODE, and ADO.\n\nAdditionally, we used receiver operating characteristic (ROC) curves to visualize the performance of our models. The ROC curves allowed us to compare the true positive rate against the false positive rate at various threshold settings, providing a comprehensive view of the models' discriminative ability.\n\nWe also conducted statistical tests, such as the Greenwood-Nam-D\u2019Agostino test, to evaluate the calibration of our models. Calibration assesses how well the predicted probabilities match the actual outcomes, ensuring that the model's predictions are reliable.\n\nTo compare the performance of different models, we used the compareC package with the one-shot method. This approach allowed us to statistically compare the C indexes of our models with those of the reference models, providing evidence of significant improvements in predictive performance.\n\nThese performance metrics are representative of those commonly reported in the literature for survival analysis and model evaluation. The use of C indexes, ROC curves, and calibration tests ensures that our evaluation is thorough and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of various methods to evaluate the performance of our mortality prediction model. We compared our model with several publicly available methods, including the BODE index, ADO, and other traditional prediction models. These comparisons were performed on benchmark datasets, specifically the COPDGene and ECLIPSE studies, which included individuals with moderate to severe COPD.\n\nWe also performed comparisons with simpler baselines to ensure that our model's performance was not merely due to the complexity of the methods used. For instance, we found that combinations of feature selection methods and traditional prediction models performed similarly to more advanced methods. Specifically, the combination of using random survival forests (RSFs) for variable selection and Cox regression yielded the most parsimonious model. This result aligns with observations that simpler machine learning methods can perform similarly to or better than more advanced methods, depending on the dataset.\n\nAdditionally, we examined the performance of our model in different scenarios, such as excluding certain features like imaging data or the 6-minute walk distance (6MWD). Even when these features were removed, our Cox model still improved prediction compared to updated BODE and ADO on the ECLIPSE validation sample. This indicates that our model's robustness and generalizability are not solely dependent on the inclusion of advanced or complex features.\n\nIn summary, our evaluation included comparisons with publicly available methods and simpler baselines, ensuring a comprehensive assessment of our model's performance.",
  "evaluation/confidence": "The evaluation of our models included a thorough assessment of performance metrics, ensuring that the results were statistically significant and reliable. We used the C index to evaluate the predictive performance of our models, and this metric was accompanied by confidence intervals to provide a range within which the true value lies. This approach allowed us to quantify the uncertainty associated with our estimates.\n\nStatistical significance was a key consideration in our analysis. We compared our models against established benchmarks such as the BODE index, its modifications, and the ADO index. The results indicated that our models retained improved prediction capabilities compared to these benchmarks, with P-values less than 0.05 for all comparisons. This level of statistical significance suggests that the observed differences are unlikely to be due to chance, thereby strengthening the claim that our method is superior.\n\nAdditionally, we conducted calibration assessments using the Greenwood-Nam-D\u2019Agostino test. The results showed that miscalibration for our MLMP-COPD model was not statistically significant, which contrasts with the findings for the BODE score. This further supports the reliability and accuracy of our model.\n\nTo address the variability in feature availability in clinical practice, we also evaluated the performance of our prediction models after excluding select features. Even when imaging features were excluded, our Cox model still demonstrated improved prediction compared to updated BODE and ADO on the ECLIPSE validation sample, with P-values less than 0.05. This robustness indicates that our model can maintain its predictive power even when certain features are not available.\n\nIn summary, the performance metrics were rigorously evaluated with confidence intervals, and the results were statistically significant. This provides a strong basis for claiming that our method is superior to existing benchmarks and baselines.",
  "evaluation/availability": "Not enough information is available."
}