{
  "publication/title": "An Improved Training Algorithm Based on Ensemble Penalized Cox Regression for Predicting Absolute Cancer Risk",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2023",
  "publication/pmid": "37007865",
  "publication/pmcid": "PMC10061827",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Cancer Risk Prediction\n- Ensemble Penalized Cox Regression\n- Imbalanced Data\n- Bagging Ensemble Framework\n- Absolute Risk Model\n- Simulation Studies\n- False Discovery Rate\n- True Positive Rate\n- Receiver Operating Characteristic Curve\n- Breast Cancer Prediction\n- Cox Proportional Hazards Models\n- Variable Selection\n- Regularization\n- Machine Learning in Healthcare\n- Predictive Modeling",
  "dataset/provenance": "The dataset used in this study is derived from the Breast Cancer Cohort Study in Chinese Women (BCCS-CW). Specifically, the Shandong sub-database from this cohort was utilized to develop a breast cancer incidence risk predictor. The dataset includes individuals who have developed breast cancer, with the age of onset recorded as the age at first cancer diagnosis. It also includes individuals who have not yet developed breast cancer, with their age recorded at the baseline registration.\n\nThe dataset is imbalanced, with cases representing only 0.3% of the total data points, which is a significant challenge for traditional prediction models. To address this imbalance, the dataset was split into training and test sets. 70% of individuals from both the case and control groups were randomly selected to form the training set, while the remaining 30% of the control group was used as the test dataset.\n\nThe study involved six different simulation studies, each with 100 replicates, to assess model performance. The performance metrics calculated include mean false discovery rate, false omission rate, true positive rate, true negative rate, and areas under the receiver operating characteristic curve (AUC) values.\n\nThe dataset has been used previously in the community, particularly in the development of the classical Gail model, which is used for comparison in this study. The Gail model is a well-known tool for projecting individualized probabilities of developing breast cancer. The EPCR model, developed in this study, aims to improve upon the performance of the Gail model by addressing the challenges posed by imbalanced data.",
  "dataset/splits": "In our study, we performed data splits to evaluate the performance of the models. For each simulation setting, the simulated data were divided into two main parts. The first part, comprising 70% of the data, was used to train the models. The second part, consisting of the remaining 30%, served as the test dataset to compare model performance. This split was consistently applied across all simulation settings and replicate experiments.\n\nThe simulation study was repeated 100 times for each setting to ensure robustness and reliability of the results. Additionally, for each setting, bootstrap times were specified as 200, which further enhanced the stability and generalizability of the findings. The mean values of the evaluation metrics were calculated over these replicate experiments to assess the models' ability to correctly identify important predictors and their predictive performance for cancer onset.",
  "dataset/redundancy": "Not applicable",
  "dataset/availability": "The data used in this study is not publicly released in a forum. However, supplementary materials, including tables and figures, are available online. These can be accessed through the provided links, such as the baseline population characteristics of risk factors in the Shandong sub-dataset, which is available at https://weekly.chinacdc.cn/. Additionally, details of the factor importance measures for the EPCR model are also provided in the supplementary materials at the same link. The specific license for these supplementary materials is not mentioned.",
  "optimization/algorithm": "The optimization algorithm presented in this work is based on ensemble learning, specifically employing a Bagging framework. This approach is not entirely new, as Bagging has been previously used in various applications. However, the specific implementation in this study is novel, as it is applied to an ensemble penalized Cox regression (EPCR) model for predicting absolute cancer risk.\n\nThe EPCR model combines the strengths of penalized Cox regression with the ensemble learning technique of Bagging. This combination aims to improve the predictive performance, particularly in handling imbalanced datasets, which are common in cancer risk prediction.\n\nThe reason this algorithm was not published in a machine-learning journal is that the primary focus of this work is on its application in the medical field, specifically in cancer risk prediction. The development and validation of the EPCR model are tailored to address the challenges posed by imbalanced data in cancer incidence characteristics. The study includes simulation studies and an empirical study on a Breast Cancer Chinese Women database, demonstrating the model's effectiveness in real-world scenarios.\n\nThe EPCR procedure involves generating bootstrap datasets from the original data and training base learners using the penalized Cox regression algorithm. For each sample in the test set, the EPCR model achieves prediction by averaging the probability prediction values given by each of these base learners. This ensemble approach helps in reducing the false discovery rate for important variables, thereby achieving more accurate variable screening and improving the overall performance of cancer risk assessment tools.",
  "optimization/meta": "The model described in this publication employs an ensemble learning approach, specifically using a Bagging framework. This means that it is indeed a meta-predictor, as it aggregates the predictions from multiple base models.\n\nThe base models used in this ensemble are Penalized Cox Regression (PCR) models. These base models are trained independently on different bootstrap samples generated from the original dataset. This ensures that the training data for each base model is independent, which is a crucial aspect of the Bagging method.\n\nThe ensemble process involves averaging the probability predictions from these base models to make a final prediction. This approach leverages the strengths of multiple models to improve predictive performance, particularly in handling imbalanced data and high-dimensional datasets. The use of bootstrap sampling helps to reduce variance and enhance the robustness of the predictions.\n\nThe ensemble penalized Cox regression (EPCR) model is designed to predict disease onset, and its performance has been validated through simulation studies and an empirical study on a breast cancer cohort. The results indicate that the EPCR model outperforms traditional regression models, especially in scenarios with high censoring rates.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of our machine-learning algorithm. We began by handling the imbalanced nature of our dataset, which is a common challenge in cancer risk prediction due to the disparity between the number of cases and controls. To address this, we employed a Bagging ensemble framework, which is particularly adept at managing imbalanced data.\n\nThe preprocessing involved several key steps. First, we standardized the follow-up information to make full use of the longitudinal data available. This was essential for the penalized Cox regression (PCR) model, which served as our base predictor. The PCR model's ability to adapt to high-dimensional data was leveraged to handle the complexity of our dataset.\n\nWe also performed variable screening to identify significant risk factors. This process involved calculating metrics such as the false discovery rate (FDR), false omission rate (FOR), true positive rate (TPR), and true negative rate (TNR). These metrics helped us to ensure that the variables selected were both relevant and reliable.\n\nAdditionally, we simulated various censoring rates to test the robustness of our model under different conditions. This simulation allowed us to assess the model's performance across a range of scenarios, ensuring that it could generalize well to real-world data.\n\nOverall, the data encoding and preprocessing steps were designed to enhance the predictive performance of our ensemble penalized Cox regression model, making it more accurate and reliable for cancer risk assessment.",
  "optimization/parameters": "In our study, we utilized two different values for the number of parameters (p) in our models: 50 and 100. These values were chosen to simulate different scenarios and to assess the performance of our models under varying conditions.\n\nThe selection of p was not based on a specific optimization process but rather on the desire to create diverse simulation settings. For instance, in settings (A), (B), and (C), we used p = 100, while in settings (D), (E), and (F), we used p = 50. This variation allowed us to evaluate the robustness and adaptability of our models across different parameter spaces.\n\nAdditionally, the censoring rates were varied within these settings to further challenge the models. The censoring rate reflects the level of imbalance in the database, with higher rates indicating more imbalance and a lower percentage of cases. We observed that as the censoring rate increased, the mean false discovery rate (FDR) increased, and the mean true positive rate (TPR) and area under the curve (AUC) decreased for all models. However, the ensemble penalized Cox regression (EPCR) models, particularly the EPCR-LASSO and EPCR-elastic net (EN) models, consistently performed better than their competitors, even as the censoring rate increased.",
  "optimization/features": "In our study, we utilized a comprehensive set of features derived from the Shandong subset of the BCCS-CW database. The specific number of features (f) used as input is not explicitly stated, but it is clear that a wide range of variables were considered, including demographic factors, lifestyle habits, and medical history.\n\nFeature selection was indeed performed to identify the most influential variables. This process involved using the ensemble penalized Cox regression (EPCR) model, which incorporates methods like LASSO and elastic net to screen out important variables. The selection of predictors was based on a specified cutoff, ensuring that only variables with significant importance were retained.\n\nThe feature selection process was conducted using the training set only, adhering to best practices in machine learning to prevent data leakage and ensure the robustness of the model. This approach allowed us to maintain the integrity of the validation and testing phases, providing reliable performance metrics.\n\nThe importance of each variable was assessed using factor importance scores, as illustrated in Supplementary Figure S3. This figure highlights variables such as life satisfaction, dysmenorrhea, number of miscarriages, and breastfeeding as influential factors in the development of breast cancer. The red line in the figure indicates the importance score threshold that distinguished important from unimportant variables, ensuring that only the most relevant features were included in the final model.",
  "optimization/fitting": "In our study, we encountered scenarios where the number of parameters (p) was significantly larger than the number of training points (n). Specifically, we considered settings with n=1,000 and p=100, as well as n=1,000 and p=50. To address the potential issues of over-fitting and under-fitting, we employed several strategies.\n\nTo mitigate over-fitting, we utilized penalized regression techniques. These included LASSO (Least Absolute Shrinkage and Selection Operator) and Elastic Net (EN) penalties within the context of Cox regression models. These penalties help to shrink the coefficients of less important variables, effectively performing variable selection and reducing the model complexity. This approach is particularly useful when dealing with high-dimensional data, as it helps to prevent the model from fitting noise in the data.\n\nAdditionally, we implemented an ensemble framework, referred to as Ensemble Penalized Cox Regression (EPCR). This method combines multiple base models trained with LASSO or EN penalties, further enhancing the model's robustness and generalization ability. The ensemble approach helps to reduce the false Discovery Rate (FDR), indicating a lower probability of incorrectly screening out important variables.\n\nTo ensure that our models were not under-fitting, we compared the performance of different methods across various simulation settings with different censoring rates (30%, 50%, and 70%). The models were evaluated using metrics such as the Area Under the Curve (AUC), True Positive Rate (TPR), and True Negative Rate (TNR). The consistent performance of the EPCR models across different settings suggests that they effectively capture the underlying patterns in the data without being too simplistic.\n\nFurthermore, we observed that the EPCR models, particularly those with the LASSO penalty, performed better in variable screening and maintained high predictive accuracy. This indicates that our models strike a balance between complexity and simplicity, avoiding both over-fitting and under-fitting.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and enhance the model's generalization performance. Specifically, we utilized the Least Absolute Shrinkage and Selection Operator (LASSO) and the Elastic Net (EN) as penalty methods within our Cox regression models. These techniques are effective in handling high-dimensional data by introducing a penalty term to the loss function, which shrinks the coefficients of less important features and can even set some to zero, thus performing feature selection.\n\nAdditionally, we implemented an Ensemble Penalized Cox Regression (EPCR) approach. This method combines multiple base models, each trained with a LASSO or EN penalty, to improve the robustness and accuracy of the predictions. By aggregating the results from these base models, EPCR helps to mitigate the risk of overfitting and enhances the model's performance, particularly in scenarios with high-dimensional and low-sample-size data.\n\nThese regularization methods were crucial in ensuring that our models remained robust and generalizable, even when dealing with complex and high-dimensional datasets.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, the simulation settings and model configurations are outlined, including the number of bootstrap times, the split of simulated data into training and test sets, and the metrics used for evaluation.\n\nThe mean values of the evaluation metrics for the models across different simulation settings are presented in a table. This table includes the false discovery rate (FDR), false omission rate (FOR), true positive rate (TPR), true negative rate (TNR), and the area under the receiver operating characteristic curve (AUC) for each model.\n\nFor the empirical study, the baseline population characteristics and the performance of the models on a real-world cancer cohort are discussed. The AUC values for 3-year and 5-year predictions are provided for the EPCR model and the Gail model.\n\nThe supplementary materials, available at a specified URL, contain additional details such as factor importance scores and the workflow of the empirical study. These materials provide further insights into the model configurations and optimization parameters.\n\nThe publication does not explicitly mention the availability of model files or the license under which they are provided. However, the detailed descriptions and supplementary materials offer a comprehensive understanding of the configurations and optimization processes used in the study.",
  "model/interpretability": "The model we developed, the Ensemble Penalized Cox Regression (EPCR), is designed to be more interpretable than traditional black-box models. By leveraging an ensemble framework, the EPCR model provides insights into the importance of various predictors in disease occurrence.\n\nThe EPCR model quantifies the importance of each predictor through a majority-vote summary. This means that the importance of a predictor is determined by how frequently it is selected across multiple base models within the ensemble. Predictors that are consistently selected are deemed more important. This approach allows us to rank predictors based on their frequency of selection, providing a clear and interpretable measure of their significance.\n\nFor instance, in our empirical study, we identified that life satisfaction, dysmenorrhea, number of miscarriages, and breastfeeding were influential variables. This finding aligns with empirical data, demonstrating the model's ability to highlight meaningful predictors.\n\nAdditionally, the EPCR model uses a penalized partial likelihood estimator with an elastic net, which helps in variable selection and regularization. This method not only improves the model's predictive performance but also enhances its interpretability by reducing the number of irrelevant variables.\n\nThe use of the Bagging ensemble framework further enhances interpretability by averaging the predictions from multiple base models. This averaging process smooths out the variability and noise, making the final model more robust and easier to interpret.\n\nIn summary, the EPCR model is not a black-box but rather a transparent model that provides clear insights into the importance of various predictors. This transparency is achieved through the majority-vote summary and the use of penalized regression techniques, making the model both powerful and interpretable.",
  "model/output": "The model discussed in this publication is primarily focused on prediction tasks related to disease onset, specifically cancer. It employs an ensemble penalized Cox regression (EPCR) approach, which is a type of survival analysis model. This model is used to predict the probability of tumorigenesis over time, making it a regression model rather than a classification model. The EPCR model quantifies the importance of various predictors for disease occurrence, utilizing a majority-vote summary to assess the significance of each predictor across multiple base models.\n\nThe model's performance is evaluated using metrics such as the area under the receiver operating characteristic curve (AUC), false discovery rate (FDR), false omission rate (FOR), true positive rate (TPR), and true negative rate (TNR). These metrics provide a comprehensive view of the model's predictive accuracy and reliability. For instance, the AUC values for 3-year and 5-year predictions are reported, indicating the model's ability to discriminate between high-risk and low-risk individuals over different time horizons.\n\nIn the empirical study, the EPCR model demonstrated superior performance compared to traditional approaches like stepwise-AIC and stepwise-BIC, as well as other penalized regression methods such as LASSO and elastic net. The model's predictions are based on a variety of factors, including life satisfaction, dysmenorrhea, number of miscarriages, and breastfeeding, which were identified as influential variables through factor importance analysis.\n\nThe model's output includes probability estimates of disease onset for new individuals, which are derived from an ensemble of bootstrap samples. This ensemble approach helps to improve the robustness and generalizability of the predictions. The workflow of the empirical study involves standardizing survival data, training the EPCR model on a subset of the data, and validating its performance on test data, as well as comparing it against actual follow-up results.\n\nOverall, the model's output provides valuable insights into the risk factors associated with disease onset and offers a reliable tool for predicting individual risk profiles. The use of an ensemble approach and comprehensive evaluation metrics ensures that the model's predictions are both accurate and interpretable.",
  "model/duration": "The execution time for our models varied depending on the simulation setting and the specific model used. For each of the six simulation settings, we conducted 100 replicate experiments. In each experiment, the data was split into training and test sets, with 70% used for training and 30% for testing. The bootstrap times were specified as 200 for each setting.\n\nThe models we evaluated included both ensemble approaches (EPCR-LASSO and EPCR-EN) and traditional approaches (Stepwise-AIC, Stepwise-BIC, PCR-LASSO, and PCR-EN). The execution time for these models was influenced by the dimensionality of the predictors and the censoring rate.\n\nFor instance, in settings with higher censoring rates or more predictors, the models generally took longer to run due to the increased complexity and computational requirements. The ensemble approaches, particularly those using elastic net penalties, tended to perform slightly better in terms of accuracy but also required more computational resources.\n\nIn the empirical study, where we applied the EPCR model to a real-world cancer cohort, the execution time was also significant. The model was developed using a training set and then used to estimate the probability of breast cancer onset in the test group over three or five years. The bootstrap times were again specified as 200, and the model's performance was assessed using ROC curves.\n\nOverall, while the exact execution time varied, the models were designed to be efficient and practical for real-world applications, balancing computational demands with predictive accuracy. The use of R software and specific packages like \"glmnet,\" \"gbm,\" and \"pROC\" facilitated the implementation and evaluation of the models.",
  "model/availability": "The source code for the models and analyses presented in this publication is not publicly released. However, the analyses were performed using the R software, specifically version 4.1.2. The packages utilized include \"glmnet\" and \"gbm\" for constructing the Ensemble Penalized Cox Regression (EPCR) model, \"pROC\" for plotting the Receiver Operating Characteristic (ROC) curve, and \"Table1\" for creating demographic characteristics tables. These packages are available through standard R package repositories and can be installed and used by researchers interested in replicating or extending the work.\n\nWhile the specific code used in this study is not provided, the use of these well-documented R packages allows for reproducibility of the methods described. Researchers can refer to the documentation of these packages for guidance on implementing similar analyses. Additionally, the R software and the mentioned packages are freely available under open-source licenses, ensuring accessibility for the scientific community.",
  "evaluation/method": "The evaluation of the methods involved a comprehensive simulation study and an empirical study using real-world data. For the simulation study, six main settings were considered, varying the dimensionality of predictors and censoring rates. Each setting was replicated 100 times, with data split into training (70%) and test (30%) datasets. The performance of the models was evaluated using four metrics: false discovery rate (FDR), false omission rate (FOR), true positive rate (TPR), and true negative rate (TNR). Additionally, the area under the receiver operating characteristic curve (AUC) was calculated to assess the predictive performance of each model for cancer onset.\n\nIn the empirical study, the Ensemble Penalized Cox Regression (EPCR) model was applied to the Shandong sub-database from the Breast Cancer Cohort Study in Chinese Women (BCCS-CW). The onset of breast cancer was treated as the outcome event, with censoring data for individuals who had not yet developed breast cancer. The age at first cancer diagnosis was considered for cases, while the age at baseline registration was used for controls. The dataset was split into training (70%) and test (30%) sets. The EPCR procedure was performed on the training set to generate an absolute risk prediction model for breast cancer, which was then used to estimate the probability of onset in the test group over three or five years. The performance of the EPCR model was compared with a single Principal Component Regression (PCR) model and a classical Gail model using receiver operating characteristic (ROC) curves based on actual follow-up results. The analyses were conducted using R software, with specific packages used for model construction, ROC curve plotting, and table creation. Statistical significance was set at P<0.05.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to assess the effectiveness of our models in variable screening and prediction. These metrics include the False Discovery Rate (FDR), False Omission Rate (FOR), True Positive Rate (TPR), and True Negative Rate (TNR). These metrics are crucial for understanding how well our models can identify important predictors and avoid incorrect selections.\n\nThe FDR measures the proportion of incorrectly identified variables among those selected by the model. A lower FDR indicates better model performance in avoiding false positives. The FOR, on the other hand, assesses the proportion of truly important variables that the model fails to identify. A lower FOR is desirable as it indicates that the model is more likely to capture all relevant predictors.\n\nThe TPR, also known as sensitivity or recall, evaluates the model's ability to correctly identify important variables. A higher TPR means the model is effective in detecting true positives. Conversely, the TNR, or specificity, measures the model's ability to correctly identify unimportant variables. A higher TNR indicates that the model is good at avoiding false positives.\n\nAdditionally, we calculated the Area Under the Receiver Operating Characteristic Curve (AUC) for each model. The AUC provides a single scalar value that summarizes the model's performance across all classification thresholds. A higher AUC indicates better overall predictive performance.\n\nThese metrics are widely used in the literature for evaluating variable selection and predictive modeling, making our evaluation comprehensive and comparable to other studies in the field. By reporting these metrics, we aim to provide a clear and representative assessment of our models' performance in both simulation studies and real-world applications.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of various methods to assess their performance in predicting cancer onset. We evaluated both traditional approaches and more advanced ensemble methods across multiple simulation settings.\n\nFor the traditional approaches, we included stepwise procedures based on the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC). These methods are widely used and serve as strong baselines for comparison. Additionally, we employed penalized Cox regression models with LASSO (Least Absolute Shrinkage and Selection Operator) and Elastic Net penalties. These methods are known for their ability to handle high-dimensional data and variable selection.\n\nIn addition to these traditional methods, we also evaluated ensemble approaches. Specifically, we used Ensemble Penalized Cox Regression (EPCR) models with LASSO and Elastic Net penalties. These ensemble methods combine the strengths of multiple base models to improve predictive performance.\n\nOur simulation study considered six main settings, varying the dimensionality of predictors and censoring rates. For each setting, we performed 100 replicate experiments, splitting the data into training and test sets to compare model performance. We calculated mean values of four evaluation metrics: false discovery rate (FDR), false omission rate (FOR), true positive rate (TPR), and true negative rate (TNR). These metrics helped us assess the models' ability to correctly identify important predictors. Furthermore, we calculated the area under the receiver operating characteristic curve (AUC) for each model to evaluate their predictive accuracy.\n\nThe comparison included both simpler baselines and more complex methods, providing a thorough assessment of each approach's strengths and weaknesses. This rigorous evaluation ensures that our findings are robust and applicable to real-world scenarios.",
  "evaluation/confidence": "In our study, we conducted a comprehensive evaluation of various models using five key metrics: False Discovery Rate (FDR), True Positive Rate (TPR), True Negative Rate (TNR), and Area Under the Curve (AUC). These metrics were calculated over 100 replicate experiments for each simulation setting, providing a robust assessment of model performance.\n\nThe mean values of these metrics are presented in a table, offering a clear comparison across different models and settings. While the table provides mean values, it does not explicitly include confidence intervals for these metrics. However, the replication of experiments 100 times for each setting ensures that the results are statistically robust.\n\nTo determine the statistical significance of our findings, we employed standard statistical practices. Specifically, we used a significance level of P<0.05, which is a common threshold in scientific research to indicate that the results are unlikely to have occurred by chance. This level of significance was applied to various aspects of our analysis, including the comparison of model performance metrics.\n\nIn addition to the simulation study, we validated our proposed Ensemble Penalized Cox Regression (EPCR) model using a real-world dataset from the Shandong sub-database of the Breast Cancer Cohort Study in Chinese Women (BCCS-CW). This empirical study further supports the reliability and effectiveness of our model in predicting breast cancer risk.\n\nOverall, the combination of extensive simulation studies and real-world validation provides strong evidence of the superior performance of our proposed methods compared to traditional approaches and baselines. The use of established statistical significance thresholds ensures that our claims of superiority are well-founded and reliable.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study provides detailed results and metrics in the main text and supplementary materials, but the actual data files used for evaluation are not released. The supplementary materials include tables and figures that summarize the findings, such as population characteristics and factor importance scores. However, these are presented in a summarized format rather than as raw data files. The study does not specify any licensing information for the data, as it is not publicly distributed."
}