{
  "publication/title": "Multi-Platform, Multi-Site, Microarray-Based Human Tumor Classification",
  "publication/authors": "The authors who contributed to this article are:\n\nGreg Bloom, who is associated with the H. Lee Moffitt Cancer Center and the University of South Florida.\n\nIvana V. Yang, who is affiliated with The Institute for Genomic Research in Rockville, Maryland.\n\nDavid Boulware, who is associated with the H. Lee Moffitt Cancer Center and the University of South Florida.\n\nKa Yin Kwong, who is affiliated with The Institute for Genomic Research in Rockville, Maryland.\n\nDomenico Coppola, who is associated with the H. Lee Moffitt Cancer Center and the University of South Florida.\n\nSteven Eschrich, who is associated with the H. Lee Moffitt Cancer Center and the University of South Florida.\n\nJohn Quackenbush, who is affiliated with The Institute for Genomic Research in Rockville, Maryland.\n\nTimothy J. Yeatman, who is associated with the H. Lee Moffitt Cancer Center and the University of South Florida.\n\nGreg Bloom and Ivana V. Yang contributed equally to this work.",
  "publication/journal": "American Journal of Pathology",
  "publication/year": "2004",
  "publication/pmid": "14695313",
  "publication/pmcid": "PMC1602228",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Artificial Neural Networks\n- Tumor Classification\n- Gene Expression\n- Microarray Data\n- Machine Learning\n- Cancer Diagnosis\n- Feature Reduction\n- Kruskal-Wallis Test\n- Multi-Tissue Classifier\n- Clinical Application",
  "dataset/provenance": "The dataset utilized in our study was sourced from multiple platforms and performance sites, ensuring a comprehensive and diverse collection of data. We incorporated data from both cDNA and oligonucleotide microarray platforms, specifically the Affymetrix HU6800 and U95A GeneChips. The dataset included measurements from six different performance sites, covering 21 distinct tumor types, which account for over 95% of all human tumors. To ensure the robustness of our classifier, we selected only those datasets that included at least 10 independent measurements for each tumor type. This stringent criterion was essential to develop an accurate classifier, as fewer measurements in any single group would significantly reduce the classifier's reliability.\n\nThe dataset was further refined by identifying 5296 genes common to both Affymetrix platforms. From this set, we used the Kruskal-Wallis H-test to select a subset of 2000 discriminative genes. These genes were then used to train a series of artificial neural networks (ANNs) using appropriately scaled and normalized data. The training process involved 10 independent, randomly-selected training tumor sets, ensuring that the reported accuracy was not dependent on any individual training/test split.\n\nIn addition to the primary dataset, we also utilized data from various sources, including personal communications and previously published studies. This approach allowed us to compare our classification technique with other methods, such as support vector machines, and validate our results against established benchmarks. The integration of data from multiple sources and platforms not only enhanced the accuracy of our classifiers but also demonstrated the feasibility of creating a multi-tissue classifier capable of incorporating different data formats. This comprehensive dataset and methodology have enabled us to achieve high levels of accuracy in tumor classification, with potential applications in clinical settings.",
  "dataset/splits": "For the dataset splits, we utilized 10 random training and test set splits. Each split was stratified to ensure that the distribution of tumor types was consistent across both the training and test sets. For each microarray platform\u2014cDNA, oligonucleotide, and mixed\u201410 different stratified splits of the data were created. This approach allowed us to more accurately estimate the true generalization error rate of the classifier and assess the variance in predicting correct classifications.\n\nIn the case of the oligonucleotide classifier, for instance, we started with 5296 genes common to both Affymetrix platforms. We then selected 2000 genes with the lowest P values from the Kruskal-Wallis test for use in the classifier algorithm. Ten random train and test splits were used, with the training set consisting of approximately 75% of the entire tumor collection (around 5346 samples), and the test set consisting of the remaining 25% (around 1782 samples). This process was repeated for sequentially smaller numbers of genes until the ANN could no longer train effectively.\n\nFor the mixed-platform classifier, we selected 2252 genes common to all microarrays under consideration. We used 400 tumors representing a combination of all available array platforms and tumor types to train a series of 10 mixed-platform ANNs. The remaining 140 tumor samples were used as the test set. This approach ensured that the classifier could incorporate data from multiple performance sites and platforms, enhancing its robustness and applicability in a clinical setting.",
  "dataset/redundancy": "The datasets were split into training and test sets to ensure independence and to validate the classifier's performance. Specifically, ten random train and test splits were used, and the mean accuracy for the ten classifiers was calculated. This process was repeated for sequentially smaller numbers of genes until the artificial neural network (ANN) could no longer train effectively.\n\nTo enforce independence, the test set of data was not exposed to either the Kruskal-Wallis H-test or the ANN learning algorithm. This means that the test data was completely separate from the training data, ensuring that the classifier's performance was evaluated on unseen data. This approach helps to prevent overfitting and provides a more accurate estimate of the classifier's generalization error rate.\n\nThe distribution of errors across multiple tissue classes was relatively even, which is important for the robustness of the classifier. This even distribution suggests that the classifier performs consistently across different types of tumors, rather than being biased towards certain types.\n\nCompared to previously published machine learning datasets, the approach taken here ensures a high level of accuracy and reliability. The use of multiple performance sites and the combination of different microarray platforms (oligonucleotide and cDNA) further enhance the classifier's robustness and applicability in a clinical setting. The high accuracy rates achieved, even with a reduced number of genes, demonstrate the effectiveness of the feature reduction experiment and the importance of gene selection based on statistical significance.",
  "dataset/availability": "The data used in this study, including the data splits, are accessible through a public forum. Specifically, the supplemental data, which includes the list of calculated P values, accuracies of individual classifiers, and genes selected across training and test splits, can be found on a dedicated website. This website serves as the primary repository for all supplemental data related to the study.\n\nThe data is made available to ensure transparency and reproducibility of the results. The website provides a comprehensive set of information that includes the entire list of calculated P values, the average P value used in gene selection for each random data split, and the accuracies of the individual classifiers for different microarray platforms. This approach allows other researchers to verify the findings and potentially build upon the work.\n\nThe data is likely released under a standard academic license that permits use for research purposes, ensuring that the data can be utilized by the scientific community while protecting the intellectual property of the original researchers. The enforcement of data availability is maintained through the consistent updating and maintenance of the website, ensuring that the data remains accessible and reliable for future reference.",
  "optimization/algorithm": "The machine-learning algorithm class used is Artificial Neural Networks (ANNs). Specifically, a single hidden layer feed-forward, back-propagation neural network was employed. This type of neural network is well-suited for classification problems associated with complex microarray data sets because it requires no a priori assumptions about the relative importance of any particular gene in the classification.\n\nThe neural network package used was a locally modified version of Scott Fahlman\u2019s QuickProp neural network software. Modifications were made to provide a cleaner input/output interface and to operate within a Beowulf cluster environment. For these experiments, the quickprop modifications were disabled, making the classifier essentially a standard feed-forward back-propagation neural network.\n\nThe choice to use this specific type of neural network was driven by the need for a versatile algebraic construct that can arbitrarily closely approximate any nonlinear function. This makes ANNs an ideal tool for the classification problems encountered in this study. The learning rate was set to 1.0, and a momentum term of 0.2 was used, with training conducted in incremental mode.\n\nThe decision to use this particular algorithm in this context, rather than publishing it in a machine-learning journal, is likely due to the focus of the study. The primary goal was to develop a robust and accurate tumor classifier using microarray data, rather than to introduce a new machine-learning algorithm. The modifications made to the neural network software were practical adjustments to fit the specific requirements of the study, rather than fundamental innovations in machine-learning theory.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The classification technique employed is based on Artificial Neural Networks (ANNs), which are trained using gene expression data from microarray platforms. The ANNs are trained and validated using stratified splits of the data, ensuring that the training and test sets are independent. This approach involves using a feed-forward, back-propagation neural network with a single hidden layer and a sigmoid transfer function. The learning rate is set to 1.0, and the model is trained in incremental mode. The accuracy of the classifiers is estimated by running multiple random training and test set splits, providing a robust estimate of the true generalization error rate. The classifiers are constructed using data from various performance sites and tumor types, demonstrating the feasibility of incorporating multiple data formats and sources. The high level of accuracy achieved suggests that the model is effective in classifying tumors, including those that are difficult to diagnose using standard pathological methods.",
  "optimization/encoding": "For our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithm, specifically the Artificial Neural Network (ANN). We began by preparing total RNA from adenocarcinomas derived from various primary sites, ensuring that the tumors appeared nearly identical histologically despite their different origins. Labeled first-strand cDNA was then prepared and co-hybridized with labeled samples from a universal reference RNA, which consisted of equimolar quantities of total RNA from three cell lines. This process was replicated with dye-reversal to eliminate any fluor-specific effects.\n\nData normalization was performed using total intensity normalization. Dye-reversed hybridizations underwent replicate flip-dye trimming to eliminate inconsistent data, and the geometric mean was calculated for the remaining array elements. This step was essential to ensure that the data were comparable across different experiments.\n\nFor the cDNA classifiers, we used a comparison of expression measured in a tumor relative to that in a reference RNA sample. For the Affymetrix oligonucleotide-based platform, we labeled and hybridized our reference RNA to the HU6800 and U95A GeneChips and measured the expression for each gene. The measured expression level for each gene on the array was then scaled so that its average measured expression was equal to the average measured for our reference sample. These normalized expression measures were used as input to our classifier. We chose to use rescaled expression values rather than ratios because neural networks perform best when the input data have as wide a range as possible.\n\nFor cross-platform comparisons between cDNA and oligonucleotide data, an additional normalization step was performed. Common genes were identified across platforms using RESOURCERER. For each gene in common, expression levels for the reference RNA sample on the spotted arrays were averaged and compared to the expression measured for the reference RNA applied to the appropriate Affymetrix GeneChip to calculate a gene-specific scaling factor. This scaling factor was used to adjust the remaining data to make it comparable to the spotted arrays. Whenever multiple representatives of a single gene were represented on the array, their values were averaged. The final scaled values were used as input for the classifier.\n\nThe Kruskal-Wallis H-test, a nonparametric statistical test, was used to rank the importance of each gene. This test helped us identify genes that best distinguished tumor types by sorting them in ascending order by the P value assigned. A subset of genes was then selected from this list for use in constructing the ANNs. The entire list of calculated P values, including the average P value used in gene selection for each random data split, was made available in the supplemental data. This preprocessing ensured that our ANN could effectively classify tumor types based on the most informative genes.",
  "optimization/parameters": "In our study, the number of input parameters, or genes, used in the model varied depending on the specific classifier and the feature reduction experiments conducted. Initially, we used a set of 700 genes for the cDNA-based tumor classifier, selected using the Kruskal-Wallis H-test. These genes were chosen from a training set representing 75% of informative primary tumor hybridizations.\n\nFor the oligonucleotide-based classifier, we started with a larger set of 2000 genes, also selected using the Kruskal-Wallis H-test from a training set of tumors representing 75% of the entire tumor collection. These genes were chosen from a total of 5296 genes common to both Affymetrix platforms.\n\nTo investigate the minimal number of genes required for adequate classification, we performed a feature reduction experiment. We sequentially reduced the number of genes used in the classifier and evaluated the mean accuracy. This process continued until the ANN could no longer train effectively. We found that the classifier's accuracy remained relatively unaffected until the number of genes dropped below 400. When fewer than 25 genes were used, the classifier performed very poorly.\n\nThe selection of the number of genes was based on the Kruskal-Wallis H-test, which ranks genes by their P values to identify those that best distinguish tumor types. This nonparametric statistical test helped us to select the most informative genes for training the ANN. The entire list of calculated P values, including the average P value used in gene selection for each random data split, is available in the supplemental data.",
  "optimization/features": "In our study, we initially considered a large number of genes as potential input features for our classifiers. Specifically, we started with 5296 genes that were common to both Affymetrix platforms used in our analysis. To identify the most relevant genes for classification, we performed feature selection using the Kruskal-Wallis H-test. This statistical test helped us rank the genes based on their ability to distinguish between different tumor types. We selected the top 2000 genes with the lowest P values for use in our classifier algorithm.\n\nThe feature selection process was conducted using only the training set to ensure that the test set remained independent and unbiased. This approach helped us to avoid overfitting and to assess the true generalization error rate of our classifiers. We repeated this process for sequentially smaller numbers of genes until the artificial neural network (ANN) was no longer able to train effectively. Our experiments demonstrated that the accuracy of the classifier was relatively unaffected by the number of genes used in training until the number dropped below approximately 400. When fewer than 25 genes were used, the classifier performed very poorly, highlighting the importance of selecting an appropriate number of genes for accurate classification.",
  "optimization/fitting": "In our study, we employed artificial neural networks (ANNs) for tumor classification, which indeed have a large number of parameters compared to the number of training points. To address potential overfitting, we implemented several strategies. Firstly, we used a feature reduction experiment to identify the most significant genes for classification, starting with 2000 genes selected by the Kruskal-Wallis H-test and progressively reducing the number. This process helped in identifying a minimal gene set that still maintained high classification accuracy, demonstrating the robustness of the ANN.\n\nSecondly, we ensured that our classifiers were trained and validated on independent datasets. We performed 10 random train and test splits, calculating the mean accuracy across these splits. This approach helped in estimating the true generalization error rate and assessing the variance in predicting correct classifications. Additionally, we replicated the experiment using 10 independent, randomly-selected training tumor sets, ensuring that the reported accuracy was not dependent on any individual training/test split.\n\nTo further validate our results, we applied the trained ANNs to a blinded, independent test set that was not included in the gene selection via the Kruskal-Wallis test and was not exposed to the training algorithm. The high level of accuracy achieved on these independent test sets suggests that our data were not subject to overfitting.\n\nRegarding underfitting, we demonstrated that the ANN's accuracy was relatively unaffected by the number of genes used in training until the number dropped below a certain threshold. This indicates that the model was complex enough to capture the underlying patterns in the data. Moreover, the use of a nonparametric statistical screen to select discriminating genes ensured that the most informative genes were included in the classification process, further mitigating the risk of underfitting.",
  "optimization/regularization": "To prevent overfitting, several techniques were employed during the development of the classifiers. One key method involved using multiple random training and test set splits. Specifically, for each microarray platform (cDNA, oligonucleotide, and mixed), 10 different stratified splits of the data were created. A neural network was constructed from a training set and validated on the corresponding test set. This approach allowed for a more accurate estimation of the true generalization error rate for the classifier and helped assess the variance in predicting correct classifications.\n\nAdditionally, the number of genes used in the classifier was systematically reduced to determine the minimal gene set required for adequate tumor classification. This feature reduction experiment demonstrated that the neural network remained robust with respect to the number of input genes, and useful classification accuracies could still be obtained even with a significantly limited number of genes. This process helped in identifying the most informative genes and reducing the risk of overfitting to noise in the data.\n\nFurthermore, the classifiers were validated on independent, blinded data sets that were not exposed to either the Kruskal-Wallis H-test set or the ANN learning algorithm. This ensured that the classifiers were not overfitted to the training data and could generalize well to new, unseen data. The high level of accuracy achieved in predicting these independent test sets suggests that the data were not subject to overfitting, a potential pitfall of artificial neural networks.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we utilized a feed-forward, back-propagation neural network with a single hidden layer. The learning rate was set to 1.0, and a momentum term of 0.2 was applied. The network was trained in incremental mode. These details are provided to ensure reproducibility of our results.\n\nThe supplemental data, accessible via a provided URL, includes the entire list of calculated P values used in gene selection for each random data split. This data is crucial for understanding the gene selection process and the performance of our classifiers. The supplemental data also contains an electronic table of the accuracies of the individual cDNA, oligonucleotide, and mixed platform classifiers, which further supports the transparency and reproducibility of our findings.\n\nAdditionally, the feature reduction experiment, which involved sequentially reducing the number of genes used in the classifier, is summarized in the supplemental data. This experiment demonstrates the robustness of the neural network with respect to the number of input genes and provides insights into the minimal gene set required for adequate tumor classification.\n\nThe supplemental data is freely accessible on the website, ensuring that researchers can replicate our experiments and build upon our work. The data includes detailed information on the genes selected in common across all 10 training and test splits, as well as the accuracies achieved with different numbers of genes. This comprehensive reporting of our methods and results aims to facilitate further research and development in the field of microarray-based tumor classification.",
  "model/interpretability": "The model employed in our study is an Artificial Neural Network (ANN), which is inherently a black-box model. This means that while the ANN can effectively classify tumor types based on gene expression data, the internal workings and the specific contributions of individual genes to the classification decisions are not easily interpretable. The ANN operates by learning complex, nonlinear relationships between the input gene expression vectors and the target tumor types through a process of weighted combinations and iterative training.\n\nThe use of a single hidden layer feed-forward, back-propagation neural network further contributes to this lack of transparency. The standard sigmoid transfer function and the learning parameters, such as a learning rate of 1.0 and a momentum term of 0.2, are designed to optimize the network's performance but do not provide clear insights into how specific genes influence the classification outcomes.\n\nThe robustness of the ANN is evident in its ability to handle a large number of genes and to maintain high classification accuracy even when the number of genes is significantly reduced. However, this robustness comes at the cost of interpretability. The feature reduction experiment, which involved sequentially removing genes based on their significance, demonstrated that the ANN could still perform well with a smaller set of genes. This indicates that the network is capable of identifying and utilizing the most informative genes, but it does not provide a straightforward way to understand the biological significance of these genes.\n\nIn summary, while the ANN is a powerful tool for classifying tumor types with high accuracy, it lacks transparency in terms of how individual genes contribute to the classification decisions. The model's strength lies in its ability to handle complex, high-dimensional data and to generalize well to new, unseen data, but it does not offer clear, interpretable insights into the underlying biological processes.",
  "model/output": "The model employed in our study is a classification model. Specifically, we utilized Artificial Neural Networks (ANNs) to classify tumor types based on gene expression data. The ANNs were trained using input gene expression vectors paired with target vectors representing tumors with defined histological classifications. The goal was to predict the type of tumor based on the gene expression profiles. The classification accuracy was estimated by running multiple random training and test set splits, ensuring a robust evaluation of the model's performance. The results demonstrated high accuracy in classifying a variety of tumor types, indicating the effectiveness of the ANN as a classification tool in this context.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our classification method involved several rigorous steps to ensure its accuracy and robustness. We employed a leave-one-out cross-validation technique, which is a form of cross-validation used to assess the performance of a machine learning model. This method involves using a single observation from the dataset as the validation data, and the remaining observations as the training data. This process is repeated such that each observation in the dataset is used once as the validation data.\n\nAdditionally, we used stratified splits of the data to create 10 different training and test sets for each microarray platform (cDNA, oligonucleotide, and mixed). For each split, a neural network was constructed from the training set and validated on the corresponding test set. This approach allowed us to more accurately estimate the true generalization error rate of the classifier and assess the variance in predicting correct classifications.\n\nWe also conducted experiments to determine the minimal number of genes required for adequate tumor classification. This involved sequentially removing genes from the classifier and observing the impact on accuracy. The results showed that the classifier remained effective even with a reduced number of genes, demonstrating its robustness.\n\nFurthermore, we compared our approach directly with support vector machines using the same published training dataset. Our classification technique achieved an accuracy of 84%, which was comparable to other methods.\n\nTo validate the clinical applicability of our classifiers, we tested them on metastatic tumors, which are often challenging to diagnose. The classifiers correctly identified the site of origin for 84% of metastatic tumors to the liver, lung, and brain, further demonstrating their potential for clinical use.\n\nOverall, the evaluation methods used provided a comprehensive assessment of the classifier's performance, ensuring its reliability and potential for real-world applications.",
  "evaluation/measure": "In our evaluation, we primarily focused on classification accuracy as our key performance metric. This metric is reported as the percentage of correctly classified tumor samples out of the total number of samples in the test set. We calculated the mean accuracy across 10 random train and test splits to ensure the robustness of our results and to estimate the true generalization error rate.\n\nTo provide a comprehensive evaluation, we also reported the 95% confidence intervals for our accuracy measures. This statistical measure gives an estimated range of values which is likely to include the true accuracy of the classifier, providing a sense of the precision of our estimates.\n\nWe compared our approach directly with support vector machines using the same published training data set and a leave-one-out cross-validation method. This comparison allowed us to ensure that our classification technique was competitive with other established methods.\n\nAdditionally, we assessed the performance of our classifiers on metastatic tumors, which are often challenging to diagnose. We reported the accuracy rates for classifying metastatic tumors to the liver, lung, and brain from multiple sites of origin.\n\nOur evaluation also included an analysis of the effect of reducing the number of genes used in the classifier on its accuracy. This experiment helped us understand the robustness of our neural network-based classifiers and the minimal number of genes required for adequate classification.\n\nWhile we did not explicitly report other metrics such as precision, recall, or F1-score, our focus on accuracy and the use of confidence intervals provide a strong foundation for evaluating the performance of our classifiers. These metrics are commonly used in the literature for evaluating tumor classification models, making our reported metrics representative and comparable to other studies in the field.",
  "evaluation/comparison": "A comparison was conducted to ensure the robustness of our approach. Specifically, we compared our classification technique directly with support vector machines, a well-established learning algorithm. This comparison was performed using the same published training dataset and employed a leave-one-out cross-validation method. Our classification technique achieved an accuracy of 84%, demonstrating its effectiveness and reliability. This comparison helps to validate our method and shows that it can produce equivalent or superior results to other established techniques. Additionally, we explored the use of different gene sets to understand the impact on classifier accuracy. By sequentially removing genes from the oligonucleotide classifier, we found that the classifier's performance remained relatively stable until the number of genes dropped significantly. This indicates that our neural network is robust and can still achieve useful classification accuracies with a reduced number of genes. However, when the number of genes was further reduced to fewer than 25, the classifier's performance deteriorated, highlighting the importance of gene selection based on statistical significance.",
  "evaluation/confidence": "The evaluation of our classifiers includes confidence intervals for the performance metrics. For instance, when applying trained artificial neural networks (ANNs) to an independent test set, we achieved an accuracy of 88% with a 95% confidence interval ranging from 84.3% to 89.5%. This indicates a high level of confidence in our results, suggesting that the data were not subject to overfitting, a common concern with ANNs.\n\nTo further validate our approach, we replicated the experiment using 10 independent, randomly-selected training tumor sets. This ensured that the reported accuracy is not dependent on any specific training/test split of the data. Additionally, we compared our classification technique with support vector machines using a leave-one-out cross-validation on the same published training dataset. Our method resulted in an accuracy of 84%, demonstrating its robustness and reliability.\n\nThe statistical significance of our results is evident in the consistent performance across multiple experiments and platforms. The classifiers were able to correctly predict the pathology of a significant majority of test samples, and the error rates achieved are clinically acceptable. This consistency across different datasets and platforms underscores the reliability and generalizability of our method.",
  "evaluation/availability": "The raw evaluation files are not publicly available. However, supplemental data, including calculated P values, accuracies of individual classifiers, and lists of selected genes, can be accessed on a specific website. This supplemental data provides detailed insights into the evaluation process and the performance of the classifiers. The website is accessible to researchers and interested parties for further analysis and verification of the results."
}