{
  "publication/title": "GeNetOntology: A Gene Set Mining Tool for Gene Expression Data",
  "publication/authors": "The authors who contributed to the article are:\n\n- NSE, who performed the experiments, analyzed the data and results, prepared figures and tables, and wrote the manuscript.\n- MY, who conceived the ideas, designed the study, analyzed the results, and wrote the manuscript.\n- BB-G, who designed the study, analyzed the results, and wrote the manuscript.",
  "publication/journal": "Frontiers in Genetics",
  "publication/year": "2023",
  "publication/pmid": "37671046",
  "publication/pmcid": "PMC10476493",
  "publication/doi": "10.3389/fgene.2023.1139082",
  "publication/tags": "- Gene Expression\n- Gene Ontology\n- Machine Learning\n- Bioinformatics\n- Classifier\n- Biological Knowledge\n- Gene Selection\n- Gene Expression Datasets\n- Gene Set Enrichment\n- Protein-Protein Interaction\n- Glioma\n- Monte Carlo Cross-Validation\n- Gene Ranking\n- Gene Scoring\n- Gene Grouping\n- Biomarker Detection\n- Disease Signatures\n- Gene Annotation\n- Gene Expression Analysis\n- Computational Biology",
  "dataset/provenance": "The dataset used in our study consists of 11 gene expression datasets for various human complex diseases. These datasets were obtained from the Gene Expression Omnibus (GEO), a public repository hosted by the National Center for Biotechnology Information (NCBI). Each dataset includes both healthy samples, labeled as negative, and patient samples, labeled as positive. The datasets are represented as matrices, where genes (mRNAs) are listed in the columns and samples are listed in the rows. A special column labeled \"label\" indicates the class annotation for each row, specifying whether the sample is from a patient or a control.\n\nThe datasets cover a range of diseases, including glioma, Parkinson\u2019s disease, prostate cancer, lung cancer, colitis, leukemia, colorectal cancer, and pulmonary hypertension. The number of healthy samples and patient samples varies across the datasets. For instance, the dataset for glioma-derived stem cell factor effect on angiogenesis in the brain (GDS1962) includes 23 healthy samples and 157 patient samples. Similarly, the dataset for early-stage Parkinson\u2019s disease (GDS2519) contains 23 healthy samples and 50 patient samples.\n\nThese datasets have been utilized to evaluate the performance of our GeNetOntology algorithm and to compare it with other existing tools. The GEO accession numbers, titles, PubMed Identification numbers (PMID), disease names, and the numbers of cases and controls for each dataset are provided in a table within the publication. This information ensures transparency and reproducibility, allowing other researchers to access and verify the datasets used in our study.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets used in this study are publicly available at the Gene Expression Omnibus (GEO) at the National Center for Biotechnology Information (NCBI). These datasets can be retrieved using the cited accession numbers. The specific GEO accession numbers for the datasets used are GDS1962, GDS2519, GDS2545, GDS2547, GDS2771, GDS3257, GDS3268, GDS3837, GDS4206, GDS4516_4718, and GDS5499. These accession numbers are listed in the second column of Table 1 in the publication.\n\nThe GeNetOntology Knime workflow, which includes the methods and processes used to analyze these datasets, is freely available on GitHub. The link to access this workflow is provided in the data availability statement. This ensures that other researchers can replicate the study and use the same methods for their own research.\n\nThe datasets and the workflow are made available to promote transparency and reproducibility in scientific research. By providing access to the datasets and the workflow, we aim to facilitate further research and validation of our findings. The availability of these resources also allows for the exploration of new hypotheses and the development of improved methods for gene expression analysis.",
  "optimization/algorithm": "The optimization algorithm employed in our study is based on a Grouping\u2013Scoring\u2013Modeling (G-S-M) approach. This approach is not entirely new, as it has been utilized in the development of various computational tools. However, our specific implementation, termed GeNetOntology, is novel in its application to gene expression datasets using Gene Ontology (GO) terms as external biological knowledge.\n\nThe machine-learning algorithm class used is primarily the Random Forest classifier. This choice is driven by its robustness and ability to handle high-dimensional data, which is characteristic of gene expression datasets. The Random Forest algorithm is well-suited for feature selection and classification tasks, making it an appropriate choice for our study.\n\nThe reason GeNetOntology was not published in a machine-learning journal is that the primary focus of our work is on biological interpretation and the integration of biological knowledge into the machine learning model. Our aim is to deliver biologically relevant results and to detect disease signatures and novel gene sets with relations across a subset of GO terms for the disease under investigation. This biological context and the application of machine learning to biological data are more aligned with the scope of genetics and bioinformatics journals.\n\nThe GeNetOntology algorithm improves classification performance by utilizing GO terms as external biological information while selecting the most relevant genes from gene expression datasets. This approach allows for the creation of new biological knowledge and overcomes the limitations of traditional gene selection methods, which often lack biological interpretation. The use of GO terms provides a biologically meaningful way to group genes and identify highly correlated sets of GO terms related to the disease under investigation.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it employs a Grouping\u2013Scoring\u2013Modeling (G-S-M) approach to integrate biological knowledge into the machine learning model. The model focuses on selecting a set of features where different sets can be generated using pre-existing biological knowledge stored in databases or through a fully data-driven approach using statistical measures.\n\nThe process involves several components:\n\n1. **Component G**: This component generates sub-datasets for each Gene Ontology (GO) term. It extracts a sub-dataset from the gene expression dataset, including expression values for genes annotated with a specific GO term and the class labels of the samples.\n\n2. **Component S**: This component scores the GO terms by operating a machine learning algorithm (Random Forest) with internal Monte Carlo cross-validation (MCCV) on each sub-dataset. The scoring evaluates the classification performance of each GO term, and the mean accuracy value is used as the final score.\n\n3. **Component M**: This component builds the model by training a classifier (Random Forest) using the gene expression values of the genes annotated with the top-scoring GO terms. This procedure is repeated in a cumulative manner, merging genes annotated with successive top-scoring GO terms until all relevant GO terms are included.\n\nThe training data for each iteration is independent, as the model uses MCCV, where some samples are randomly selected for the training set, and the rest are used for the testing set in each iteration. This ensures that the training data is independent for each iteration, maintaining the integrity of the model's performance evaluation.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of the machine-learning algorithms employed. Initially, gene expression datasets were collected, which inherently contain a high number of features (genes) and a relatively small number of samples. These datasets were noisy and high-dimensional, necessitating careful preprocessing.\n\nTo address the imbalance in the dataset, an under-sampling approach was implemented. This method reduces the number of samples in the majority class to match the number of samples in the minority class, thereby mitigating bias in the size distribution of the datasets. The under-sampling ratio chosen was 1:2, which helped in balancing the class distribution and improving the model's performance.\n\nFor feature selection, various traditional methods were applied, including eXtreme Gradient Boosting (XGB), Information Gain (IG), Select K Best (SKB), and Fast Correlation-Based Filter (FCBF). These methods were used to identify the most relevant genes (features) associated with the disease, reducing the dimensionality of the data and enhancing the learning accuracy and training speed of the classifiers.\n\nThe preprocessing steps also involved calculating performance metrics such as accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). These metrics were evaluated using 10-fold cross-validation to ensure the robustness and generalizability of the results. The average values of these metrics over 10 iterations were reported for each dataset and feature set.\n\nAdditionally, the gene ontology (GO) terms were utilized to categorize genes into different biological processes (BP), cellular components (CC), and molecular functions (MF). The top-scoring GO terms were selected for further analysis, and the performance of the model was evaluated using these terms. This approach helped in identifying disease-related genes and understanding the molecular mechanisms underlying disease development.\n\nIn summary, the data encoding and preprocessing involved under-sampling to balance the dataset, applying feature selection methods to reduce dimensionality, and utilizing GO terms to categorize genes. These steps were essential for preparing the data for the machine-learning algorithms and ensuring the reliability and accuracy of the results.",
  "optimization/parameters": "In our study, the number of parameters used in the model varies depending on the specific gene expression dataset and the number of top-scoring Gene Ontology (GO) terms considered. The model utilizes the gene expression values of genes annotated with the top-scoring GO terms. For instance, in the GDS1962 dataset, using the top two scoring GO terms results in an average of 48.2 genes. This set of genes is sufficient to achieve a high AUC score of 0.98 for predicting glioma patients. The cumulative addition of top-scoring GO terms increases the number of genes considered, thereby potentially improving the model's performance. For example, using genes from the top 10 scoring GO terms can achieve an AUC of 1, but this comes at the cost of increasing the number of genes to 133.9 on average. Conversely, using just 32 genes can still yield a satisfactory AUC of 0.97, balancing model performance and complexity. The selection of the number of top-scoring GO terms and corresponding genes is guided by the trade-off between model performance and the practicality of measuring fewer genes.",
  "optimization/features": "In our study, we utilized gene expression values as input features. Specifically, a model was generated using the gene expression values of 48.2 genes, which successfully predicted glioma patients with a high AUC score. This indicates that a relatively small number of genes can be highly informative for disease prediction.\n\nFeature selection was indeed performed to identify the most relevant genes. Various traditional feature selection methods were applied, including eXtreme Gradient Boosting (XGB), Information Gain (IG), Select K Best (SKB), and Fast Correlation-Based Filter (FCBF). These methods were used to evaluate the importance of each gene in the context of the classification task.\n\nTo ensure the robustness of our feature selection process, it was conducted using only the training set. This approach helps to prevent data leakage and overfitting, ensuring that the selected features are truly representative of the underlying biological processes. By focusing on the training set, we maintain the integrity of the validation and test sets, allowing for an unbiased evaluation of the model's performance.\n\nAdditionally, we compared our approach with other solutions by applying different classifiers, such as Adaboost, Decision Tree (DT), LogitBoost, Random Forest (RF), SVM_opt, Stack_Logitboost_Kmeans, and Stack_SVM_Kmeans. For each dataset, the performance of each classifier and feature selection method was evaluated using the same number of features. This comprehensive evaluation allowed us to assess the effectiveness of our feature selection methods in conjunction with various classification algorithms.",
  "optimization/fitting": "In our study, we employed a method that inherently addresses the challenges of overfitting and underfitting, particularly in the context of high-dimensional gene expression data. The number of genes, or features, is indeed much larger than the number of training samples, a common scenario in transcriptomic analysis.\n\nTo mitigate overfitting, we utilized an under-sampling approach to handle the imbalanced dataset problem. This method reduces the number of samples in the majority class to match the number of samples in the minority class, thereby decreasing bias in the size distribution of datasets. Additionally, we performed 10-fold Monte Carlo cross-validation (MCCV) to ensure that our model's performance was robust and generalizable. This cross-validation technique helps in assessing the model's ability to predict new data, thus ruling out overfitting.\n\nConversely, to avoid underfitting, we employed a feature selection method that leverages Gene Ontology (GO) terms. This approach allows us to identify and use only the most relevant genes, ensuring that the model is complex enough to capture the underlying patterns in the data. We tested our model on various gene expression datasets and found that it achieved high performance metrics, such as AUC, accuracy, and sensitivity, indicating that underfitting was not a concern.\n\nFurthermore, we compared our method with traditional feature selection techniques and found that our approach, which incorporates biological knowledge through GO terms, outperformed or matched the performance of these traditional methods. This comparison provides additional confidence that our model is neither overfitting nor underfitting the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting, particularly when utilizing wrapper methods for feature selection. Wrapper methods, while effective in finding optimal feature sets, can be prone to overfitting due to their interaction with the learning algorithm. To mitigate this risk, we implemented a 10-fold Monte Carlo cross-validation (MCCV) procedure. This approach ensures that the model's performance is evaluated across multiple iterations, reducing the likelihood of overfitting to any single subset of the data.\n\nAdditionally, we addressed the issue of imbalanced datasets, which can also contribute to overfitting. We performed an under-sampling approach to balance the class distribution. This method decreases the number of samples in the majority class to match the number of samples in the minority class, thereby reducing bias and improving the model's generalization ability. The under-sampling ratio was set to 1:2, which helped in achieving a more balanced dataset for training.\n\nFurthermore, we compared our approach with traditional feature selection methods such as eXtreme Gradient Boosting (XGB), Information Gain (IG), Select K Best (SKB), and Fast Correlation-Based Filter (FCBF). By evaluating the performance of these methods alongside our proposed GeNetOntology, we ensured that our model's results were robust and not merely an artifact of overfitting. The consistent performance of GeNetOntology across different datasets and classifiers further validates its effectiveness in preventing overfitting.",
  "optimization/config": "The GeNetOntology workflow is publicly available and can be accessed via a GitHub repository. This repository contains the necessary files and configurations to replicate the experiments and utilize the workflow for further research. The workflow is implemented using the KNIME Analytics Platform, which supports scripts in both R and Python, providing flexibility in customization and extension.\n\nThe repository includes the complete workflow, which encompasses various nodes and meta-nodes designed to fulfill specific tasks within the GeNetOntology framework. These nodes handle different aspects of the workflow, from data preprocessing to model evaluation, ensuring a comprehensive and reproducible process.\n\nAll datasets used in the study are publicly available and can be retrieved from the Gene Expression Omnibus (GEO) at the National Center for Biotechnology Information (NCBI) using the provided accession numbers. This ensures transparency and allows other researchers to validate the findings or build upon the work.\n\nThe workflow and associated datasets are freely available under open-source licenses, promoting collaboration and further development in the scientific community. The availability of these resources supports the reproducibility of the results and encourages the application of GeNetOntology in various biomedical research contexts.",
  "model/interpretability": "The model GeNetOntology is designed to be transparent and interpretable, rather than a black-box model. It leverages biological knowledge, specifically Gene Ontology (GO) terms, to group genes and evaluate their contribution to the classification task. This approach allows for a clear understanding of which genes and biological processes are most relevant to the predictions made by the model.\n\nOne of the key features of GeNetOntology is its use of GO terms to create feature sets. By grouping genes based on their associated GO terms, the model can identify the most significant biological processes, cellular components, and molecular functions involved in the classification. This grouping provides a biological context for the features used in the model, making it easier to interpret the results.\n\nFor example, the model can rank GO terms based on their significance and provide a list of genes associated with these terms. This allows researchers to understand which biological processes are most important for the classification task. Additionally, the model can visualize the protein-protein interaction (PPI) networks of the genes annotated with the most significant GO terms, further enhancing the interpretability of the results.\n\nThe use of GO terms also allows for the cumulative performance evaluation of the model. By evaluating the performance of the model using different numbers of top-scoring GO terms, researchers can understand how the inclusion of additional biological processes affects the model's accuracy, sensitivity, and specificity. This cumulative approach provides a detailed view of the model's performance and the biological relevance of the features used.\n\nIn summary, GeNetOntology is a transparent and interpretable model that uses biological knowledge to group genes and evaluate their contribution to the classification task. This approach provides a clear understanding of the biological processes involved in the predictions made by the model, making it a valuable tool for researchers in the field of genomics.",
  "model/output": "The model in question is a classification model. It is designed to predict class labels, specifically for tasks such as identifying glioma patients. The model utilizes gene expression data and Gene Ontology (GO) terms to train a Random Forest classifier. The performance of the model is evaluated using metrics such as accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). These metrics are calculated over multiple iterations of cross-validation, indicating that the model's primary goal is to classify samples into distinct categories based on the input features.\n\nThe model's output includes performance tables that show the cumulative performance over different feature sets, which are combinations of genes annotated with top-scoring GO terms. These tables provide insights into how the model's performance improves as more relevant features are included. Additionally, the model generates ranked lists of GO terms and their associated genes, which are aggregated using a robust rank aggregation approach. These lists help identify the most significant biological processes, cellular components, or molecular functions related to the classification task.\n\nThe model's workflow involves several components, including generating sub-datasets for each GO term, scoring these sub-datasets using a machine learning algorithm, and building the classification model in a cumulative manner. The final output is visualized in an output panel, providing a comprehensive view of the model's performance and the biological insights derived from the analysis.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for GeNetOntology is publicly available and has been implemented using the KNIME Analytics Platform, which is an open-source data analysis tool. The workflow can be accessed via a public GitHub repository. This allows researchers to utilize, modify, and build upon the existing framework. The platform supports scripts in both R and Python, providing flexibility for further customization and integration with other tools. The workflow includes various nodes and meta-nodes that perform specific tasks, making it a comprehensive tool for gene ontology analysis. The availability of the source code under the General Public License (GNU) ensures that it can be freely used and distributed, fostering collaboration and innovation in the scientific community.",
  "evaluation/method": "The evaluation of GeNetOntology involved a comprehensive assessment using 11 different gene expression datasets, each representing various human complex diseases. These datasets were sourced from the Gene Expression Omnibus (GEO) and included both healthy and patient samples. The evaluation process utilized 10-fold Monte Carlo cross-validation (MCCV) to ensure robust performance metrics.\n\nFor each dataset, the performance was measured using several key metrics: accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). These metrics were calculated as the mean of values obtained over 10 iterations of the cross-validation procedure. This approach helped in assessing the model's ability to generalize across different datasets and disease types.\n\nAdditionally, an under-sampling technique was employed to address the issue of imbalanced datasets. This method involved reducing the number of samples in the majority class to match the number of samples in the minority class, thereby mitigating bias and ensuring a more balanced evaluation.\n\nThe evaluation also included a comparison with traditional feature selection methods such as eXtreme Gradient Boosting (XGB), Information Gain (IG), Select K Best (SKB), and Fast Correlation-Based Filter (FCBF). Various classifiers, including Adaboost, Decision Tree (DT), LogitBoost, Random Forest (RF), SVM_opt, Stack_Logitboost_Kmeans, and Stack_SVM_Kmeans, were applied to the same datasets. The performance of each classifier and feature selection method was evaluated using the same number of features as used by GeNetOntology.\n\nThe results demonstrated that GeNetOntology achieved high performance metrics, particularly in datasets like GDS1962, GDS3837, GDS4516_718, and GDS5499, where AUC, accuracy, and sensitivity values were notably high. For instance, the model using the gene expression values of 48.2 genes successfully predicted glioma patients with an AUC score of 0.98.\n\nOverall, the evaluation highlighted the effectiveness of GeNetOntology in leveraging gene ontology terms to classify and identify relevant sets of genes associated with various diseases, outperforming traditional gene selection approaches.",
  "evaluation/measure": "In our evaluation of GeNetOntology, we focused on several key performance metrics to assess the model's efficiency. These metrics include specificity, sensitivity, and accuracy, which are fundamental in evaluating the performance of classification models. Additionally, we utilized the area under the receiver operating characteristic curve (AUC) to approximate the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance.\n\nSpecificity, also known as the true negative rate, measures the proportion of actual negatives that are correctly identified by the model. Sensitivity, or recall, indicates the proportion of actual positives that are correctly identified. Accuracy provides an overall measure of the model's correctness by calculating the proportion of true results (both true positives and true negatives) among the total number of cases examined.\n\nThe AUC is particularly useful as it provides a single scalar value that summarizes the performance of the classifier across all classification thresholds. This metric is widely used in the literature and is considered representative of the model's ability to distinguish between positive and negative classes.\n\nThese performance measures were calculated as the average of 10-fold Monte Carlo cross-validation (MCCV) to ensure robustness and reliability. This approach helps in mitigating the risk of overfitting and provides a more generalizable assessment of the model's performance. The use of these metrics aligns with standard practices in the field, making our evaluation both comprehensive and representative of current methodologies.",
  "evaluation/comparison": "In the evaluation of our approach, we conducted a comprehensive comparison with various publicly available methods and simpler baselines to assess the performance of GeNetOntology. We utilized 11 different gene expression datasets, which are publicly accessible from the Gene Expression Omnibus (GEO). These datasets encompass a range of human complex diseases, including glioma, Parkinson\u2019s disease, prostate cancer, lung cancer, colitis, leukemia, colorectal cancer, and pulmonary hypertension.\n\nTo ensure a fair comparison, we applied several traditional feature selection methods, such as eXtreme Gradient Boosting (XGB), Information Gain (IG), Select K Best (SKB), and Fast Correlation-Based Filter (FCBF). Additionally, we employed different classifiers, including Adaboost, Decision Tree (DT), LogitBoost, Random Forest (RF), SVM_opt, Stack_Logitboost_Kmeans, and Stack_SVM_Kmeans. These methods and classifiers were tested on the same 11 gene expression datasets using 10-fold Monte Carlo Cross-Validation (MCCV).\n\nFor each dataset, we evaluated the performance of each classifier and feature selection method using the same number of features as those used by GeNetOntology. Our results indicated that, for most of the tested classifiers, the AUC of the XGB feature selection method showed higher performance compared to IG, SKB, and FCBF. We also plotted the average AUC values over seven different classifiers for the 11 datasets, demonstrating that GeNetOntology generates similar AUC values compared to other feature selection methods.\n\nIt is important to note that the primary goal of GeNetOntology is not to outperform other feature selection approaches but to identify significant ontology terms that have biological meaning. Even if the performance of GeNetOntology is similar to or slightly lower than that of other feature selection methods, the tool's contribution lies in finding the most informative Gene Ontology (GO) terms. These terms can help researchers understand the biological background of the disease under study.\n\nIn summary, our evaluation included a thorough comparison with publicly available methods and simpler baselines, providing a robust assessment of GeNetOntology's performance and its unique contributions to biological research.",
  "evaluation/confidence": "The performance metrics presented in our study include confidence intervals, specifically standard deviations, which provide a measure of the variability and reliability of the results. These metrics were calculated over 10 iterations of a cross-validation procedure, ensuring that the results are robust and not dependent on a single split of the data.\n\nThe results demonstrate statistically significant performance across various datasets. For instance, the area under the receiver operating characteristic curve (AUC) values for datasets such as GDS1962, GDS3837, GDS4516_718, and GDS5499 are notably high, indicating strong model performance. These high AUC values, along with other metrics like accuracy and sensitivity, suggest that the method is effective in classifying the datasets.\n\nComparative evaluations with other methods, such as maTE and PriPath, further support the superiority of our approach. The mean AUC values and the average number of genes used by GeNetOntology are plotted for different datasets, showing consistent performance across various gene expression datasets.\n\nAdditionally, the use of an under-sampling approach to handle imbalanced datasets ensures that the results are not biased by the size distribution of the classes. This method helps in reducing the bias and improving the reliability of the performance metrics.\n\nOverall, the confidence intervals and statistical significance of the results provide strong evidence that GeNetOntology is a superior method for selecting significant ontology terms with biological meaning, aiding researchers in understanding the biological background of the diseases under study.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being available. However, the datasets used in this study are publicly available at the Gene Expression Omnibus (GEO) at the National Center for Biotechnology Information (NCBI). These datasets can be retrieved using the cited accession numbers. The GEO accession numbers of the datasets used are provided in a table within the publication.\n\nThe GeNetOntology workflow itself is freely available on GitHub under the username malikyousef. This workflow is implemented in the open-source KNIME Analytics Platform, which operates under the General Public License (GNU). This means that the workflow can be accessed, modified, and distributed by anyone, following the terms of the GNU license.\n\nFor those interested in replicating the study or using the workflow for their own research, the GitHub repository provides a comprehensive resource. The datasets, while not directly included in the repository, are accessible through the GEO database, ensuring that all necessary components for evaluation are available to the public."
}