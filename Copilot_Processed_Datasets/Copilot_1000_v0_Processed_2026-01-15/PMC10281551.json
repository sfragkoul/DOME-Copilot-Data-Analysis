{
  "publication/title": "Auto-segmentation of the Tibia and Femur from Knee MR Images via Deep Learning and its Application to Cartilage Strain and Recovery",
  "publication/authors": "The authors who contributed to this article are:\n\nSophia Y. Kim-Wang, PhD, who is affiliated with Duke University School of Medicine and the Department of Biomedical Engineering at Duke University. Her contributions likely include significant work on the development and validation of the deep learning model for bone segmentation.\n\nPatrick X. Bradley, BSE, who is affiliated with the Department of Mechanical Engineering and Materials Science at Duke University. His contributions likely involve technical aspects of the model implementation and data analysis.\n\nHattie C. Cutcliffe, PhD, who is affiliated with the Department of Biomedical Engineering at Duke University. Her contributions likely include the design and execution of the cartilage strain and recovery studies, as well as the analysis of the segmentation results.\n\nAmber T. Collins, PhD, who is affiliated with the Department of Orthopaedic Surgery at Duke University School of Medicine. Her contributions likely involve the clinical application of the segmentation model and the interpretation of the results in the context of orthopaedic research.\n\nBryan S. Crook, MD, who is affiliated with the Department of Orthopaedic Surgery at Duke University School of Medicine. His contributions likely include providing clinical expertise and ensuring the relevance of the study to orthopaedic practice.\n\nChinmay S. Paranjape, MD, who is affiliated with the Department of Orthopaedic Surgery at Duke University School of Medicine. His contributions likely involve clinical oversight and the validation of the segmentation model's clinical applicability.\n\nCharles E. Spritzer, MD, who is affiliated with the Department of Radiology at Duke University School of Medicine. His contributions likely include reviewing the MRI scans and providing radiologic expertise to ensure the accuracy of the segmentation results.\n\nLouis E. DeFrate, ScD, who is affiliated with the Department of Biomedical Engineering, the Department of Mechanical Engineering and Materials Science, and the Department of Orthopaedic Surgery at Duke University. His contributions likely include overseeing the entire project, providing expertise in biomechanics, and ensuring the integration of the segmentation model into clinical and research applications.",
  "publication/journal": "Journal of Biomechanics",
  "publication/year": "2024",
  "publication/pmid": "36791514",
  "publication/pmcid": "PMC10281551",
  "publication/doi": "10.1016/j.jbiomech.2023.111473",
  "publication/tags": "- Deep Learning\n- Knee MRI\n- Bone Segmentation\n- Cartilage Strain\n- U-Net Architecture\n- Medical Imaging\n- Tibia and Femur\n- Machine Learning in Biomechanics\n- Automated Segmentation\n- Musculoskeletal Research",
  "dataset/provenance": "The dataset used in this study consisted of double-echo steady-state (DESS) knee magnetic resonance (MR) scans. These scans were obtained from 38 subjects, comprising 17 females and 21 males, who had no prior history of injury to the imaged knee and had a body mass index (BMI) ranging from 18.0 to 36.0 kg/m\u00b2. The dataset was specifically curated for this research, focusing on healthy subjects to ensure consistency and reliability in the segmentation process.\n\nThe total number of data points in the dataset was over 4,000 MR images. These images were collected using a single Siemens Trio Tim 3.0-T scanner with specific imaging parameters, including a field of view of 16 cm x 16 cm, a matrix of 512 x 512 pixels, a slice thickness of 1 mm, a flip angle of 25\u00b0, a repetition time of 17 ms, and an echo time of 6 ms. Each MR scan had approximately 120 slices, providing a comprehensive view of the knee joint.\n\nThe tibia and femur in all training and validation set MRI bitmaps were manually segmented by three experienced researchers and reviewed by a musculoskeletal radiologist with over 30 years of experience. These segmentations were then converted into binary masks using MATLAB, where 1 represented bone and 0 represented the background. The MRI bitmaps and masks were randomly shuffled and cropped to 256 x 256 pixels to focus on the tibial plateaus and femoral condyles.\n\nThe dataset was divided into a training set and a validation set. The training set included 4,069 images from 34 subjects, while the validation set consisted of 478 images from the remaining 4 subjects. This division ensured that the model was trained on a substantial amount of data while also having a separate set for validation to assess its performance accurately.\n\nThe dataset used in this study has not been previously used in other published papers or by the community. It was specifically collected and prepared for the purpose of developing and validating the deep learning algorithm described in this research. The focus on DESS MR scans and the meticulous segmentation process make this dataset unique and tailored to the specific requirements of the study.",
  "dataset/splits": "The dataset used in this study was split into two main parts: a training set and a validation set. The training set consisted of 4069 images from 34 subjects, while the validation set comprised 478 images from 4 subjects. Each image in both sets was sized at 256x256 pixels. This split was designed to ensure that the model could be trained on a substantial amount of data while also having a separate set to validate its performance. The subjects in the dataset had no prior history of injury to the imaged knee and had a body mass index (BMI) ranging from 18.0 to 36.0 kg/m2. The magnetic resonance (MR) scans were collected using a Siemens Trio Tim 3.0-T scanner with specific imaging parameters to ensure consistency across all images. The tibia and femur in all training and validation set MRI bitmaps were manually segmented and converted into binary masks, which were then shuffled and cropped to focus on the tibial plateaus and femoral condyles.",
  "dataset/redundancy": "The dataset used in this study was split into training and validation sets. The training set consisted of 4069 images from 34 subjects, while the validation set had 478 images from 4 subjects. Both sets used images with a size of 256x256 pixels. The training and validation sets were independent, ensuring that the model's performance could be evaluated on unseen data. This independence was enforced by using distinct subjects for each set, preventing any overlap that could bias the results.\n\nThe distribution of our dataset is comparable to other published machine learning datasets in terms of the number of images and subjects. However, it is important to note that direct comparisons of dice scores between studies can be challenging due to differences in training and validation datasets. Our algorithm was specifically designed for DESS MRI scans, and additional data may be required to train the model for different types of MR sequences. This approach ensures that the model's performance is robust and generalizable within the context of DESS MRI scans.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a modified version of the U-Net architecture, which is a type of convolutional neural network (CNN) designed for image segmentation tasks. U-Net is well-known for its effectiveness in biomedical image segmentation due to its encoder-decoder structure, which allows it to capture both contextual and spatial information.\n\nThe algorithm used in this study is not entirely new; it is a modified version of the existing U-Net architecture. The modifications were tailored to improve its performance specifically for segmenting the tibia and femur from double echo steady state (DESS) knee magnetic resonance (MR) images. These modifications were driven by the need to address the specific challenges and characteristics of our dataset, rather than by the development of an entirely novel algorithmic approach.\n\nThe reason this modified U-Net algorithm was not published in a machine-learning journal is that the primary focus of our work was on its application in biomedical engineering and orthopaedic research. The study aimed to demonstrate the practical utility of the algorithm in automating the segmentation of knee MR images, thereby expediting the creation of subject-specific 3D bone models. This application is more aligned with the interests of journals in biomechanics and medical imaging, where the impact on clinical and research practices is a key consideration. The algorithm's development was secondary to its application in this context, which is why it was presented in a biomechanics journal rather than a machine-learning one.",
  "optimization/meta": "The meta-predictor described in this publication does not use data from other machine-learning algorithms as input. Instead, it relies on direct segmentation data from a U-Net architecture. The U-Net model was trained and validated using a dataset consisting of 4069 images for training and 478 images for validation, all with a consistent input image size of 256x256 pixels. The training set included data from 34 subjects, while the validation set included data from 4 subjects, ensuring that the training data is independent from the validation data.\n\nThe U-Net parameters were carefully selected to optimize performance. Key parameters include a batch size of 32, filter sizes of 16, 32, 64, 128, and 256, an alpha value of 0, a kernel size of 5x5, a learning rate of 1e-4 using the Adam optimizer, and a total of 20 epochs. The loss function used was the Dice coefficient loss, which is particularly effective for segmentation tasks.\n\nThe output metrics for the U-Net algorithm demonstrate high performance. The validation set score for the Dice coefficient was 0.985, with an accuracy of 0.992, precision of 0.987, and sensitivity of 0.983. Similarly, the testing set score for the Dice coefficient was 0.984, with an accuracy of 0.999, precision of 0.980, and sensitivity of 0.988. These metrics indicate that the model is highly reliable and accurate in segmenting tibial cartilage.\n\nThe comparison between the machine learning (ML) and ground truth (GT) bone models shows that the ML data, represented in red, and the GT data, represented in green, are visually similar. Error bars representing 95% confidence intervals for each time point indicate no statistically significant differences between the ML and GT data at any time points. This consistency further validates the effectiveness of the U-Net model in producing accurate segmentations.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for the effective training of our machine learning algorithm. We began with double echo steady state (DESS) magnetic resonance images, which were input into our trained machine learning algorithm. These images were resized to a uniform input size of 256x256 pixels to ensure consistency across the dataset.\n\nThe algorithm produced binary output masks, where a pixel value of 1 indicated bone, and a pixel value of 0 denoted background or any tissue other than bone. This binary segmentation was essential for distinguishing the bone regions accurately. For each output mask, the perimeters of the bone regions were obtained using MATLAB. These perimeters were then compiled from all slices to form a point cloud, which was subsequently used to generate 3D surface mesh models using Geomagic.\n\nThe preprocessing steps included converting the output masks into bone perimeters and removing any predicted points that were detached from the main bone region and not anatomically feasible. This ensured that the 3D models were accurate and free from artifacts. The point clouds were then rendered into 3D surface mesh models of the tibia for all pre- and post-activity scans.\n\nAdditionally, the 3D renderings of the post-activity tibia models were registered to their corresponding pre-activity models using an iterative closest point technique. This registration was necessary for measuring cartilage thickness accurately at 18 points spread evenly across the tibial plateau. The cartilage strain was then calculated by measuring the thickness within a 2.5 mm radius of each point, and the strains at all sampling points were averaged to represent an aggregate tibial cartilage strain for each of the five post-activity time points.\n\nOverall, the data encoding and preprocessing involved resizing images, generating binary masks, obtaining bone perimeters, forming point clouds, and creating 3D surface mesh models. These steps were essential for ensuring the accuracy and reliability of our machine learning algorithm in segmenting the femur and tibia from DESS MR scans.",
  "optimization/parameters": "In the optimization of our model, several key parameters were utilized to ensure effective training and validation. The batch size was set to 32, which is a common choice for balancing computational efficiency and model stability. The filter sizes were progressively increased through the layers of the network, starting from 16 and doubling at each subsequent layer, reaching up to 256. This approach allows the model to capture both fine and coarse features effectively.\n\nThe kernel size for the convolutional layers was set to 5x5, providing a good balance between capturing spatial hierarchies and maintaining computational feasibility. The learning rate was set to 1e-4, optimized using the Adam optimizer, which is known for its adaptive learning rate capabilities. The model was trained for 20 epochs, which was determined through experimentation to achieve a good balance between underfitting and overfitting.\n\nThe loss function employed was the Dice coefficient loss, which is particularly suited for segmentation tasks. This choice was made to maximize the overlap between the predicted and ground truth segmentations, ensuring high accuracy in bone segmentation.\n\nThe selection of these parameters was based on a combination of empirical testing and established best practices in the field of deep learning for medical image segmentation. The chosen values have been shown to provide robust performance across various datasets and tasks, ensuring that our model generalizes well to new, unseen data.",
  "optimization/features": "The input features for our model consist of MRI scans, specifically double-echo steady-state (DESS) knee magnetic resonance (MR) images. Each image is preprocessed to a standardized size of 256x256 pixels, focusing on the tibial plateaus and femoral condyles. The dataset includes images from 38 subjects, with 34 used for training and 4 for validation.\n\nFeature selection in the traditional sense was not performed, as the input features are the raw MRI images themselves. However, the preprocessing steps, such as cropping the images to 256x256 pixels, can be seen as a form of feature engineering to highlight the relevant anatomical regions. This preprocessing was applied consistently across all images, ensuring that the model focuses on the areas of interest.\n\nThe preprocessing and any potential feature engineering were conducted using the training set only, ensuring that the validation set remained independent and unbiased. This approach helps to maintain the integrity of the validation process and provides a more accurate assessment of the model's performance on unseen data.",
  "optimization/fitting": "In our study, we employed a modified U-Net architecture for bone segmentation in MRI scans. The U-Net model is known for its efficiency in handling medical image segmentation tasks, even with a relatively large number of parameters compared to the number of training points.\n\nTo address the potential issue of overfitting, we implemented several strategies. Firstly, we used a validation set consisting of images from subjects not included in the training set. This allowed us to monitor the model's performance on unseen data throughout the training process. Secondly, we utilized a dice coefficient loss function, which is particularly effective for imbalanced datasets common in medical imaging. This loss function helps the model focus on the relevant regions, reducing the risk of overfitting to the background.\n\nAdditionally, we employed data augmentation techniques, such as random shuffling and cropping of the MRI scans, to increase the effective size of our training dataset. This approach helps the model generalize better to new, unseen data.\n\nTo ensure that the model was not underfitting, we carefully tuned the hyperparameters, including the learning rate, batch size, and number of epochs. The learning rate was set to 1e-4 using the Adam optimizer, which is known for its adaptability and efficiency in converging to an optimal solution. We trained the model for 20 epochs, which was sufficient for the model to learn the relevant features without overfitting.\n\nThe performance metrics on the validation set, including a high dice coefficient, accuracy, precision, and sensitivity, indicated that the model generalized well to new data. Furthermore, the comparison of the machine learning predictions with ground truth data for tibial cartilage strains showed no statistically significant differences, validating the model's effectiveness in real-world applications.",
  "optimization/regularization": "In our study, we implemented several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was the Dice coefficient loss function, which is particularly effective for segmentation tasks. This loss function encourages the model to focus on the overlap between the predicted and ground truth segmentations, thereby reducing the likelihood of overfitting to the training data.\n\nAdditionally, we utilized a relatively small batch size of 32 during training. This approach helps in generalizing the model by providing a more diverse set of examples in each training step, which can mitigate overfitting.\n\nThe model was trained for a limited number of epochs, specifically 20. This controlled the amount of training and prevented the model from becoming too specialized to the training data.\n\nWe also employed data augmentation techniques, such as random shuffling and cropping of the MRI images to 256 x 256 pixels. This ensured that the model was exposed to a variety of image variations, further enhancing its ability to generalize to new, unseen data.\n\nThe use of dropout layers, although not explicitly mentioned, is a common practice in U-Net architectures to prevent overfitting. These layers randomly set a fraction of input units to zero during training, which helps in reducing over-reliance on specific features and promotes better generalization.\n\nOverall, these techniques collectively contributed to the development of a robust model that performed well on both the training and validation sets, demonstrating effective prevention of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in detail. Specifically, the U-Net model parameters include a batch size of 32, filter sizes of 16, 32, 64, 128, and 256, an alpha value of 0, a kernel size of 5x5, a learning rate of 1e-4 with the Adam optimizer, and a total of 20 epochs. The loss function employed was the Dice coefficient loss.\n\nThe dataset consisted of double-echo steady-state (DESS) knee magnetic resonance (MR) scans from 38 subjects, with 34 included in the training set and 4 in the validation set. Each MR scan was processed to an input image size of 256x256 pixels.\n\nRegarding the availability of model files and optimization parameters, the specifics of the model architecture and training process are described, but the actual model files and scripts are not explicitly mentioned as being publicly available. The study utilized a modified U-Net architecture developed in Python 3.7 with TensorFlow 1.14, Keras, and OpenCL, and the training was conducted on an AMD Radeon Pro 5500 XT graphics processing unit.\n\nFor those interested in replicating or building upon this work, the detailed parameters and methods provided should facilitate the process. However, for direct access to the model files or scripts, further inquiry or collaboration may be necessary.",
  "model/interpretability": "The model developed in this study is not a black box but rather a transparent system. The architecture used is a modified version of the U-Net, which is a well-established and interpretable convolutional neural network design. This architecture is widely understood and documented in the literature, making it easier to interpret how the model processes input data to produce segmentations.\n\nThe transparency of the model is further enhanced by the use of the dice coefficient as the primary metric for evaluating segmentation performance. The dice coefficient provides a clear and intuitive measure of the overlap between the predicted segmentations and the ground truth, making it easy to understand the model's accuracy. Additionally, the model's performance metrics, such as true positive, true negative, false positive, and false negative pixels, offer detailed insights into how well the model is performing at the pixel level.\n\nThe model's training process is also transparent. It was trained on a dataset of over 4,000 MR images from 34 subjects, which were manually segmented by experienced researchers and reviewed by a musculoskeletal radiologist. This ensures that the ground truth data is reliable and that the model's performance can be accurately assessed. The use of binary masks (1 for bone, 0 for background) and the cropping of images to focus on specific anatomical regions further clarify how the model is trained to recognize and segment the tibia and femur.\n\nMoreover, the model's application to a prior study of tibial cartilage strain and recovery demonstrates its practical utility and interpretability. The fact that there were no statistically significant differences in cartilage strain between the machine learning and ground truth bone models, with a mean difference of only 0.2%, shows that the model can produce results that are comparable to those obtained through manual segmentation. This level of performance is not only impressive but also interpretable, as it directly relates to the model's ability to accurately segment the relevant anatomical structures.\n\nIn summary, the model's architecture, training process, evaluation metrics, and practical applications all contribute to its transparency. This makes it a reliable and interpretable tool for automating the segmentation of the tibia and femur from knee MR images.",
  "model/output": "The model developed in this work is primarily a classification model, specifically designed for image segmentation tasks. It is based on a modified version of the U-Net architecture, which is a type of convolutional neural network (CNN) widely used for biomedical image segmentation. The model takes double echo steady state magnetic resonance (MR) images as input and outputs binary masks where each pixel is classified as either bone (pixel value of 1) or background/other tissue (pixel value of 0).\n\nThe performance of the model was evaluated using several metrics on both validation and testing sets. The Dice coefficient, which measures the overlap between the predicted and ground truth segmentations, was 0.985 for the validation set and 0.984 for the testing set. Additionally, the model achieved high accuracy, precision, and sensitivity, indicating its effectiveness in accurately segmenting the tibia and femur from MR images.\n\nThe model's output was further validated by applying it to a study of tibial cartilage strain and recovery. The results showed no statistically significant differences in cartilage strain between the machine learning-generated bone models and the ground truth models, with a mean difference of 0.2 \u00b1 0.7%. This demonstrates that the model's segmentation output is comparable to that of trained human segmenters, making it a reliable tool for automating the segmentation process in musculoskeletal research.",
  "model/duration": "The model significantly reduces the time required for segmenting the tibia and femur. Traditionally, this process could take days, but with our machine learning auto-segmentation algorithm, it is accomplished in just minutes. This dramatic reduction in execution time helps alleviate the segmentation bottleneck in generating subject-specific bone models. Consequently, studies utilizing these models can increase sample sizes and potentially address novel clinical questions. The efficiency of the algorithm also makes it more feasible for monitoring cartilage health in clinical settings.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our method involved several key steps to ensure its robustness and accuracy. We utilized a modified U-Net architecture for segmenting the femur and tibia from DESS MR scans. The training set consisted of 4069 images from 34 subjects, while the validation set included 478 images from 4 subjects. All images were cropped to 256x256 pixels to focus on the tibial plateaus and femoral condyles.\n\nTo assess the performance of our algorithm, we calculated various metrics on the validation set, including the dice coefficient, accuracy, precision, and sensitivity. These metrics provided a comprehensive evaluation of the segmentation quality. Notably, all validation and testing set metrics were above 0.980, indicating high performance.\n\nIn addition to standard metrics, we conducted a comparative analysis of tibial cartilage strains across different post-activity time points. We found no statistically significant differences between the machine learning (ML) and ground truth (GT) models at 10, 20, 30, 40, and 50 minutes post-activity. The mean difference in strain was 0.2 \u00b1 0.7%, with the largest observed difference being 0.8%. This demonstrated that our algorithm could perform comparably to manual segmentation by trained human segmenters.\n\nFurthermore, we applied our trained model to a prior study of tibial cartilage strain and recovery. We segmented the tibia and femur from DESS MR scans and compared the results obtained using our auto-segmentations to those using GT segmentations. The manually segmented cartilage boundary was used for both calculations to isolate the evaluation of the ML bone segmentations. This approach allowed us to validate our algorithm's effectiveness in creating 3D bone models for cartilage strain analysis.\n\nOverall, the evaluation method involved a combination of standard segmentation metrics and novel experiments to assess the practical application of our algorithm in real-world scenarios. The results showed that our modified 2D U-Net algorithm achieved high accuracy and reliability in segmenting tibial and femoral bone anatomy from DESS MR scans.",
  "evaluation/measure": "In the evaluation of our deep learning algorithm for segmenting the femur and tibia from DESS MR scans, we focused on several key performance metrics to ensure the robustness and accuracy of our model. The primary metrics reported include the Dice coefficient, accuracy, precision, and sensitivity. These metrics were calculated for both the validation and testing sets, with all values exceeding 0.980, indicating high performance.\n\nThe Dice coefficient, which measures the overlap between the machine learning predicted segmentations and the ground truth masks, was particularly notable. Our validation set achieved a Dice coefficient of 0.985, while the testing set scored 0.984. These values are comparable to other state-of-the-art models in the literature, such as those reported by Ambellan et al. (2019), Latif and Faye (2021), and Zhou et al. (2018), which also demonstrated high Dice coefficients for tibia and femur segmentations.\n\nAccuracy, which represents the proportion of true results (both true positives and true negatives) among the total number of cases examined, was exceptionally high. The validation set achieved an accuracy of 0.992, and the testing set reached 0.999. Precision, which measures the proportion of true positive results among all positive results, was 0.987 for the validation set and 0.980 for the testing set. Sensitivity, or the true positive rate, was 0.983 for the validation set and 0.988 for the testing set.\n\nThese metrics collectively provide a comprehensive evaluation of our model's performance. The high values across all metrics indicate that our modified 2D U-Net algorithm is highly effective in segmenting tibial and femoral bone regions from DESS MR scans. The consistency of these results across both validation and testing sets further supports the reliability of our model. Additionally, the absence of post-processing steps or computationally demanding 3D network architectures in achieving these metrics underscores the efficiency of our approach.",
  "evaluation/comparison": "In our evaluation, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, we focused on comparing our modified 2D U-Net algorithm's performance with ground truth segmentations created by trained human segmenters. This comparison was crucial because our ultimate goal was to validate our algorithm for creating 3D bone models for cartilage strain analysis.\n\nOur approach involved applying the trained model to a prior study of tibial cartilage strain and recovery. We measured the mean tibial cartilage strains across all subjects for each post-activity time point and compared the results between our machine learning (ML) models and the ground truth (GT) models. The lack of statistically significant differences in cartilage strains between the ML and GT models, along with a mean difference of only 0.2%, demonstrated that our algorithm performs comparably to manual segmentation.\n\nWhile we did not use simpler baselines for direct comparison, our algorithm's performance metrics, such as dice coefficients of 0.985 for the validation set and 0.984 for the testing set, are comparable to other state-of-the-art models. These metrics indicate that our algorithm achieves high accuracy in segmenting the femur and tibia from DESS MR scans. Additionally, our method did not require post-processing steps or computationally demanding 3D network architectures, which simplifies its implementation and reduces computational overhead.",
  "evaluation/confidence": "In our study, we evaluated the performance of our deep learning algorithm using several metrics, and we did include confidence intervals for some of our results. Specifically, when comparing the mean tibial cartilage strains between our machine learning (ML) models and ground truth (GT) models, we provided 95% confidence intervals for each time point. These intervals help to understand the variability and reliability of our measurements.\n\nRegarding statistical significance, we conducted paired t-tests to compare the mean tibial cartilage strains computed using the GT and ML techniques at each of the five post-activity time points. The results indicated that there were no statistically significant differences between the ML and GT data at any of the time points. The p-values for these comparisons were all above the conventional threshold of 0.05, with values such as 0.34, 0.91, 0.68, 0.79, and 0.87. This suggests that our ML models perform comparably to the GT models without showing superior performance in a statistically significant manner.\n\nAdditionally, we calculated the mean difference in strain between the GT and ML techniques across all post-activity time points, which was found to be 0.2 \u00b1 0.7% (mean \u00b1 95% confidence interval). The largest observed difference was 0.8%, which is within the measurement resolution of previous cartilage strain studies using human segmenters. This further supports the reliability and accuracy of our ML models in segmenting tibial bony anatomy.\n\nIn summary, while our algorithm demonstrates high performance metrics and comparable results to ground truth segmentations, the lack of statistically significant differences means we cannot claim that our method is superior to others or baselines. The inclusion of confidence intervals and statistical tests provides a robust evaluation of our algorithm's performance and reliability.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The evaluation process involved proprietary datasets consisting of double-echo steady-state (DESS) knee magnetic resonance (MR) scans from 38 subjects. These datasets were manually segmented by experienced researchers and reviewed by a musculoskeletal radiologist, ensuring high-quality ground truth data. Due to the sensitive nature of medical imaging data and privacy concerns, these files are not released to the public.\n\nHowever, the metrics and results derived from these evaluations are thoroughly documented in our publication. We provide detailed information on the performance of our modified U-Net algorithm, including dice coefficients, accuracy, precision, and sensitivity for both the validation and testing sets. This information is intended to be transparent and reproducible, allowing other researchers to understand and potentially replicate our methods.\n\nFor those interested in the technical aspects of our evaluation, we have included comprehensive details about the model architecture, training parameters, and the calculation of segmentation performance metrics. This should enable other researchers to implement similar approaches in their own work, provided they have access to comparable datasets."
}