{
  "publication/title": "Latent-Graph Learning for Disease Prediction with Interpretable Attention Module",
  "publication/authors": "The authors who contributed to this article are Anees Kazi, who received financial support from BigPicture (IMI945358) from the Technical University of Munich during this project. Other authors include L. Cosmo, S. A. Ahmadi, and N. Navab. Additionally, M. Bronstein contributed to the work. The specific contributions of each author to the paper are not detailed.",
  "publication/journal": "Mach Learn Med Imaging",
  "publication/year": "2023",
  "publication/pmid": "37854585",
  "publication/pmcid": "PMC10583839",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Graph Convolutional Networks\n- Interpretability\n- Medical Imaging\n- Alzheimer's Disease Prediction\n- Age Prediction\n- Sex Prediction\n- Feature Selection\n- Class Imbalance\n- Machine Learning\n- Deep Learning\n- Cognitive Features\n- MRI Features\n- Loss Function Optimization\n- Attention Mechanisms\n- Clinical Interpretation",
  "dataset/provenance": "Two publicly available datasets were utilized for our experiments. The first dataset, Tadpole, was used for Alzheimer\u2019s disease prediction. This dataset consists of 564 subjects, each with 354 multi-modal features. These features include cognitive tests, MRI ROI measures, PET imaging, DTI ROI measures, demographics, and more. The task involved classifying subjects into three categories: Normal, Mild Cognitive Impairment, and Alzheimer\u2019s.\n\nThe second dataset, UK Biobank (UKBB), was used for age and sex prediction. This dataset is significantly larger, comprising 14,503 subjects with 440 features per individual. These features were extracted from MRI and fMRI images. Two classification tasks were considered for this dataset: sex prediction and categorical age prediction. For the age prediction task, subjects\u2019 ages were quantized into four decades as the classification targets.\n\nBoth datasets have been used in previous research and by the community, making them reliable sources for our experiments. The Tadpole dataset has been particularly useful for Alzheimer\u2019s disease prediction due to its comprehensive multi-modal features. The UKBB dataset, with its large size and detailed imaging features, provides a robust platform for age and sex prediction tasks.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "The datasets used in our study were split into training and test sets using a 90:10 ratio. This split was consistently applied across all experiments, ensuring that the training and test sets were independent. To enforce this independence, we used the same 10 folds for all experiments, which helped in maintaining a consistent evaluation framework.\n\nThe distribution of our datasets compares favorably to previously published machine learning datasets in the medical imaging domain. The Tadpole dataset, used for Alzheimer\u2019s disease prediction, included 564 subjects with 354 multi-modal features per subject. This dataset is challenging due to its class imbalance, with 27, 47, and 17 subjects in the Normal, Mild Cognitive Impairment, and Alzheimer\u2019s categories, respectively. The UK Biobank (UKBB) dataset, used for age and sex prediction, consisted of 14,503 subjects with 440 features per individual. This dataset is notable for its large size and the complexity of the tasks, particularly the age prediction task, which involved quantizing subjects\u2019 ages into four decades.\n\nThe independence of the training and test sets was crucial for evaluating the generalizability of our models. By using a consistent split across all experiments, we ensured that our results were robust and not dependent on a particular random split of the data. This approach also allowed us to compare our results directly with other methods that have been evaluated on the same datasets.",
  "dataset/availability": "The datasets used in our study are publicly available. For Alzheimer\u2019s disease prediction, we utilized the Tadpole dataset. For age and sex prediction, we used the UK Biobank (UKBB) dataset. Both datasets are accessible to the research community, facilitating reproducibility and further exploration by other researchers.\n\nThe Tadpole dataset is available through its respective public forum, and the UK Biobank data can be accessed via the UK Biobank Access Management System. The data access is governed by specific licenses and agreements that ensure ethical use and compliance with data protection regulations. Researchers interested in using these datasets must adhere to the terms and conditions set by the data providers, which typically include obtaining appropriate ethical approvals and ensuring data security and confidentiality.\n\nTo enforce these guidelines, data access is granted only after a thorough review process. This process involves submitting a detailed research proposal, demonstrating the scientific merit of the study, and agreeing to the data usage policies. Once approved, researchers receive controlled access to the datasets, with restrictions on data sharing and publication to protect participant privacy.\n\nThe data splits used in our experiments were consistent across all methods to ensure fair comparisons. We employed a 90:10 train-test split with the same 10 folds for all experiments, which helps in maintaining the integrity and reproducibility of our results. This approach ensures that the performance metrics reported are reliable and can be validated by other researchers using the same datasets and splits.",
  "optimization/algorithm": "The optimization algorithm employed in our work is centered around a graph convolutional network (GCN) framework, which is a class of neural networks designed to operate on graph-structured data. The specific implementation involves a novel approach that integrates an Interpretable Attention Module (IAM) and a Graph Learning Module (GLM) within the GCN architecture.\n\nThe machine-learning algorithm presented is not entirely new but rather an innovative extension of existing GCN methods. The primary novelty lies in the incorporation of the IAM and GLM, which together enhance the interpretability and performance of the model. The IAM learns attention coefficients for each feature, allowing the model to focus on the most relevant features for the classification task. The GLM, inspired by previous work, predicts an optimal graph structure that is used in the GCN for classification.\n\nThe reason this work was not published in a machine-learning journal is that the focus is on the application of these techniques in medical imaging and healthcare. The primary contributions are in the domain of medical imaging, where the interpretability and performance of the model are crucial for clinical applications. The experiments conducted on datasets like Tadpole and UK Biobank demonstrate the practical utility of the proposed method in real-world scenarios, such as Alzheimer\u2019s disease prediction and age and sex prediction from MRI data.\n\nThe optimization process involves a customized loss function that combines softmax cross-entropy loss with additional terms to regularize the feature mask entropy and size. This loss function ensures that the model not only achieves high classification accuracy but also provides interpretable attention weights for the features. The experiments show that this approach outperforms several state-of-the-art methods, including linear classifiers, spectral-GCN, and graph attention networks, in terms of accuracy, AUC, and F1-score.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model is designed as an end-to-end system that directly processes the input features to make predictions. The input features come from the datasets used for the experiments, such as the Tadpole dataset for Alzheimer\u2019s disease prediction and the UK Biobank dataset for age and sex prediction. These features include various modalities like cognitive tests, MRI measures, PET imaging, and demographics.\n\nThe model incorporates a graph learning module to learn the latent population graph, which means it does not rely on pre-computed graphs. This approach allows the model to dynamically adapt to the data and learn the most relevant graph structure for the classification task. The graph learning module is adapted from existing work, but it is integrated into the overall model to enhance its performance and interpretability.\n\nThe training data for the model is independent and consists of the features and labels from the datasets. The model is trained using a combination of loss terms, including the softmax cross-entropy loss, feature mask entropy loss, and feature mask size loss. These loss terms help to regularize the model and improve its performance by focusing on the most important features.\n\nThe experiments were conducted using a consistent train-test split of 90:10 across all tasks, ensuring that the training data is independent of the test data. This split was maintained across 10 folds to provide robust and reliable results. The model's performance was evaluated using metrics such as accuracy, AUC, and F1-score, which demonstrate its effectiveness in handling the classification tasks.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithm. We utilized two publicly available datasets: Tadpole and UK Biobank (UKBB). For the Tadpole dataset, we classified 564 subjects into three categories\u2014Normal, Mild Cognitive Impairment, and Alzheimer\u2019s\u2014based on 354 multi-modal features. These features included cognitive tests, MRI ROI measures, PET imaging, DTI ROI measures, and demographics. Each feature was normalized to ensure consistency across different modalities.\n\nFor the UKBB dataset, we worked with 14,503 subjects, each having 440 features extracted from MRI and fMRI images. We performed two classification tasks: sex prediction and categorical age prediction. For age prediction, subjects\u2019 ages were quantized into four decades as classification targets.\n\nThe features were encoded using a differentiable and continuous mask, which learned an attention coefficient for each feature element. This mask was defined as a vector in the real numbers with the same dimensionality as the number of features. The mask values were initialized either with a Gaussian normal distribution or constant values, depending on the experiment. During training, the mask values were adjusted to reflect the importance of each feature, with values close to zero indicating less significant features.\n\nWe also employed a graph learning module that predicted an optimal graph structure based on the input features. This module consisted of a two-layered multilayer perceptron (MLP) followed by a graph construction and pruning step. The MLP took the feature matrix as input and produced embeddings specific for the optimal latent graph. A fully connected graph was computed using the Euclidean distance metric between the feature embeddings, and a sigmoid function was used for soft thresholding to keep the process differentiable.\n\nThe entire model was trained end-to-end using a customized loss function that focused on interpretability. This loss function included terms for softmax cross-entropy, feature mask entropy, and feature mask size, which together helped in regularizing the model and improving its performance. The experiments were conducted using Google Colab with a Tesla T4 GPU and PyTorch 1.6, with a total of 600 epochs and a 90:10 train-test split across 10 folds.",
  "optimization/parameters": "In our model, the number of parameters (p) is determined by the architecture of the Interpretable Attention Module (IAM), the Graph Learning Module (GLM), and the classification module. The IAM consists of a differentiable and continuous mask that learns an attention coefficient for each feature element from D features. The GLM is composed of a 2-layered multilayer perceptron (MLP) followed by a graph construction and pruning step. The classification module is defined as a generic Graph Convolutional Network (GCN) targeted towards node classification.\n\nThe specific number of parameters depends on the dimensionality of the input features (D) and the architecture of the MLP in the GLM. For instance, if the input features have a dimensionality of D, the mask in the IAM will have D parameters. The MLP in the GLM, with two layers (16\u21928), will have (D\u00d716) + (16\u00d78) parameters. The classification network consists of two convolutional layers followed by a fully connected (FC) layer (32\u219216\u2192# classes), adding more parameters based on the number of classes and the dimensions of the convolutional layers.\n\nThe selection of these parameters was guided by experimental tuning and validation on the datasets used. We performed extensive experiments to determine the optimal architecture that balances model complexity and performance. The final architecture was chosen based on its ability to achieve high accuracy and stability across different tasks and datasets, including the Tadpole dataset for Alzheimer\u2019s disease prediction and the UK Biobank (UKBB) dataset for age and sex prediction. The use of ReLU as the activation function and the specific layer dimensions were selected to ensure effective learning and generalization.",
  "optimization/features": "In our study, we utilized two distinct datasets, each with a different number of input features. For the Tadpole dataset, which focuses on Alzheimer\u2019s disease prediction, we employed 354 multi-modal features per subject. These features encompassed a variety of modalities, including cognitive tests, MRI region of interest (ROI) measures, PET imaging, DTI ROI measures, and demographic information.\n\nFor the UK Biobank (UKBB) dataset, which was used for age and sex prediction tasks, each subject had 440 features extracted from MRI and fMRI images.\n\nFeature selection was indeed performed in our experiments. We explored several approaches to feature selection. One method involved using a conventional feature selection technique with a Ridge classifier applied to the input features during the preprocessing step. Another approach trained the model with all input features except those selected by the interpretable attention module (IAM). Additionally, we trained models using only the features selected by the proposed IAM. The results indicated that feature selection approaches, particularly the IAM-based selection, were advantageous and led to improved model performance.\n\nIt is important to note that the feature selection process was conducted using the training set only, ensuring that the evaluation on the test set remained unbiased. This approach helped in identifying the most relevant features for each specific task, thereby enhancing the model's predictive accuracy and interpretability.",
  "optimization/fitting": "The fitting method employed in our study involved a careful balance to ensure neither overfitting nor underfitting occurred. The model utilized a distinct loss function that combined softmax cross-entropy loss with feature mask entropy loss and feature mask size loss. This combination helped in regularizing the model and preventing overfitting by ensuring that the model did not become too complex.\n\nThe number of parameters in our model was indeed larger than the number of training points, especially given the high-dimensional feature sets used in the Tadpole and UK Biobank datasets. To mitigate the risk of overfitting, we incorporated regularization terms in our loss function. These terms helped in shrinking the attention values of less important features, thereby focusing the model on the most relevant features. Additionally, we used a 10-fold cross-validation approach with a 90:10 train-test split, which provided a robust evaluation of the model's performance and generalizability.\n\nTo address underfitting, we ensured that the model had sufficient capacity to learn from the data. This was achieved by using multiple layers in our neural network architecture, including MLP layers for the graph learning module and convolutional layers followed by a fully connected layer for the classification network. The use of ReLU activation functions also helped in capturing complex patterns in the data.\n\nFurthermore, the experiments were conducted over 600 epochs, which provided ample time for the model to learn from the training data. The stability and performance of the model were validated through consistent results across different folds and datasets, indicating that the model was neither overfitting nor underfitting. The incorporation of interpretable attention mechanisms also aided in ensuring that the model focused on clinically relevant features, further enhancing its robustness and generalizability.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and enhance the model's generalization performance. One of the key methods used was the incorporation of feature mask entropy loss (FMEL) and feature mask size loss (FMSL) into our loss function. These terms help in regularizing the softmax cross-entropy loss (Lc) by ensuring that the model assigns appropriate importance to different features. FMEL pushes the attention values away from 0.5, making the model more confident about the importance of certain features. On the other hand, FMSL lowers the sum of the values of individual attention coefficients, preventing all features from being assigned the highest importance. This combination helps in distinguishing between more and less important features, thereby improving the model's interpretability and performance.\n\nAdditionally, we utilized a differentiable and continuous mask within the Interpretable Attention Module (IAM) to learn attention coefficients for each feature. This mask ensures that the corresponding weights take values close to zero when a particular feature is not significant, thereby reducing the model's reliance on irrelevant features and mitigating overfitting.\n\nWe also performed experiments with different input features, including traditional feature selection techniques using a Ridge classifier. These experiments demonstrated the advantage of feature selection approaches, with the proposed IA-based feature selection performing the best. This further supports the effectiveness of our regularization methods in improving model performance and preventing overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our experiments are reported within the publication. Specifically, details about the number of epochs, the train-test split, and the architecture of the models, including the use of MLP layers and convolutional layers, are provided. The initialization methods for the mask M, such as using a Gaussian normal distribution or constant values, are also mentioned.\n\nRegarding the availability of model files and optimization parameters, these are not explicitly detailed in the text. However, the implementation details, including the use of Google Colab with a Tesla T4 GPU and PyTorch 1.6, are specified. The experiments were conducted using a consistent 10-fold cross-validation approach with a 90:10 train-test split.\n\nFor access to the specific model files and optimization parameters, readers would typically need to refer to supplementary materials or repositories associated with the publication. Unfortunately, information about the licensing of these materials is not provided in the text. Therefore, for comprehensive access to model files and optimization parameters, it is advisable to contact the authors or check any associated online repositories or supplementary information linked to the publication.",
  "model/interpretability": "The model we propose is designed to address the interpretability challenges commonly associated with Graph Convolutional Networks (GCNs), which are often considered black-box models. Our approach introduces an Interpretable Attention Module (IAM) that enhances transparency by learning attention coefficients for each feature. This module generates a differentiable and continuous mask that highlights the relevance of input features to the classification task.\n\nThe IAM operates by applying a sigmoid function to a learned mask, producing a masked output where each feature's importance is reflected. Features deemed less significant for the task are assigned lower attention weights, effectively reducing their influence on the model's predictions. This mechanism allows clinicians and researchers to understand which features are driving the model's decisions, thereby increasing trust and facilitating better diagnostic and treatment planning.\n\nAdditionally, our model incorporates a graph learning module that constructs an optimal latent graph structure from the input features. This graph is then used in the GCN for classification, further enhancing the model's interpretability by providing insights into the relationships between different data points.\n\nTo ensure that the model remains interpretable, we employ a customized loss function that focuses on interpretability. This loss function helps in learning more confident and meaningful attention weights, thereby improving the model's performance and transparency. The model's interpretability is validated through extensive experiments on public datasets, demonstrating its ability to handle complex tasks such as disease prediction and age classification with improved accuracy and F1-score.",
  "model/output": "The model is designed for classification tasks. It specifically focuses on classifying subjects into different categories based on their features. For instance, in the Tadpole dataset, the model classifies subjects into three categories: Normal, Mild Cognitive Impairment, and Alzheimer\u2019s. Similarly, for the UK Biobank dataset, the model handles two classification tasks: sex prediction and categorical age prediction, where ages are quantized into four decades.\n\nThe model employs a Graph Convolutional Network (GCN) with an interpretable attention module (IAM) and a graph learning module (GLM). The IAM learns attention coefficients for each feature, helping to identify which features are most important for the classification task. The GLM predicts an optimal graph structure that is used in the GCN for classification. The entire model is trained end-to-end using a customized loss function that includes terms to regularize the feature attention and ensure interpretability.\n\nThe classification performance is evaluated using metrics such as accuracy, AUC, and F1-score. The model has shown superior performance compared to state-of-the-art methods, particularly in handling class imbalance and large dataset sizes. For example, in the Tadpole dataset, the model achieved the highest accuracy, AUC, and F1-score, outperforming other methods by a significant margin. Similarly, for the UK Biobank dataset, the model demonstrated better performance in both sex and age prediction tasks, confirming its effectiveness in classification.",
  "model/duration": "The experiments were conducted using Google Colab with a Tesla T4 GPU and PyTorch 1.6. The model was trained for 600 epochs using the same 10 folds with a train-test split of 90:10. The specific execution time for the model to run was not explicitly mentioned, but the use of a Tesla T4 GPU and the specified number of epochs provide an indication of the computational resources and time invested in the training process. The implementation details included two MLP layers for the Graph Learning Module and two convolutional layers followed by a fully connected layer for the classification network, with ReLU as the activation function. These details suggest a moderate to high computational demand, typical for deep learning models on large datasets.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method involved several datasets and tasks to assess its performance comprehensively. Two publicly available datasets were utilized: the Tadpole dataset for Alzheimer\u2019s disease prediction and the UK Biobank (UKBB) dataset for age and sex prediction. The Tadpole dataset included 564 subjects classified into three categories: Normal, Mild Cognitive Impairment, and Alzheimer\u2019s. Each subject had 354 multi-modal features, encompassing cognitive tests, MRI ROI measures, PET imaging, DTI ROI measures, demographics, and more. The UKBB dataset consisted of 14,503 subjects with 440 features per individual, extracted from MRI and fMRI images. For the UKBB dataset, two classification tasks were considered: sex prediction and categorical age prediction, where ages were quantized into four decades.\n\nThe evaluation process included comparing the proposed method with several state-of-the-art and baseline methods, such as a linear classifier (LC), Chebyshev polynomial-based spectral-GCN, Graph Attention Network (GAT), Dynamic Graph CNN (DGCNN), and Dynamic Graph Model (DGM). The comparison was based on metrics like accuracy, AUC, and F1-score. The proposed method, IA-GCN, demonstrated superior performance across all tasks and datasets, particularly excelling in handling class imbalances and large dataset sizes.\n\nExperiments were conducted using a 10-fold cross-validation approach with a 90:10 train-test split. The model was implemented using PyTorch 1.6 on a Tesla T4 GPU, with a total of 600 epochs. The network architecture included two MLP layers for the Graph Learning Module (GLM) and two convolutional layers followed by a fully connected layer for the classification network. ReLU was used as the activation function.\n\nAdditionally, the contribution of different loss terms was investigated to optimize the model's performance. The loss function included a softmax cross-entropy loss, feature mask entropy loss (FMEL), and feature mask size loss (FMSL), each with experimentally chosen weighting factors. The experiments showed that both FMEL and FMSL were crucial for achieving optimal performance, with FMEL playing a significant role in ensuring interpretable attention to important features.\n\nThe interpretability of the selected features was validated by manually adding and removing features from the input for traditional methods like GCN and DGM. The results indicated that the proposed IA-based feature selection method outperformed conventional feature selection techniques, highlighting the relevance of the features selected by the model to the clinical tasks.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to comprehensively assess the effectiveness of our proposed method. For classification tasks, we primarily reported accuracy, the area under the receiver operating characteristic curve (AUC), and the F1 score. These metrics are widely recognized and used in the literature, providing a robust framework for comparing our method with state-of-the-art approaches.\n\nAccuracy measures the proportion of correctly classified instances out of the total instances, offering a straightforward evaluation of the model's performance. The AUC provides a more nuanced view by considering the trade-off between the true positive rate and the false positive rate across different threshold settings, making it particularly useful for imbalanced datasets. The F1 score, which is the harmonic mean of precision and recall, balances the trade-off between these two metrics, especially important in scenarios where the class distribution is skewed.\n\nFor the Tadpole dataset, our method demonstrated superior performance across all three metrics, indicating its robustness and effectiveness in handling challenging classification tasks. Similarly, for the UK Biobank (UKBB) dataset, our approach outperformed existing methods in sex prediction tasks, reaffirming the consistency and reliability of our model. However, the age prediction task on the UKBB dataset proved to be more challenging, as reflected in the lower F1 scores, highlighting the presence of class imbalance and the complexity of the task.\n\nIn addition to these primary metrics, we also analyzed the average attention values for the top features selected by our model. This analysis provided insights into the interpretability of our method, showing how different features contribute to the classification performance. The attention values helped us understand the importance of specific features, such as cognitive measures in the Tadpole dataset and volume features in the UKBB dataset, which are clinically relevant and supported by existing literature.\n\nOverall, the set of performance metrics we reported is representative of the standards in the field, ensuring a fair and comprehensive evaluation of our method. The inclusion of accuracy, AUC, and F1 score, along with the analysis of attention values, provides a holistic view of our model's performance and its potential for real-world applications.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of our proposed method against several publicly available state-of-the-art and baseline methods on benchmark datasets. Specifically, we used the Tadpole and UK Biobank (UKBB) datasets for classification tasks. The Tadpole dataset was used for Alzheimer\u2019s disease prediction, while the UKBB dataset was used for age and sex prediction.\n\nFor the Tadpole dataset, we classified subjects into three categories: Normal, Mild Cognitive Impairment, and Alzheimer\u2019s. Each subject had 354 multi-modal features, including cognitive tests, MRI ROI measures, PET imaging, DTI ROI measures, and demographics. For the UKBB dataset, we had 14,503 subjects with 440 features per individual, extracted from MRI and fMRI images. The tasks included sex prediction and categorical age prediction, where ages were quantized into four decades.\n\nWe compared our method with several baselines, including a linear classifier (LC), Chebyshev polynomial-based spectral-GCN, and Graph Attention Network (GAT). These methods require a pre-defined graph structure, unlike our approach and DGM, which do not rely on any predefined graph structure. Additionally, we compared with DGCNN, which constructs a KNN graph dynamically during training but lacks the ability to learn the latent graph.\n\nOur experiments showed that the proposed method outperformed these baselines in terms of accuracy, AUC, and F1 score across all tasks. The results indicate that incorporating graph convolutions helps in better representation learning, leading to more accurate classification. Furthermore, the comparison with simpler baselines, such as the linear classifier, highlighted the complexity of the tasks and the effectiveness of our method in handling multi-modal features and large datasets.",
  "evaluation/confidence": "The evaluation of our proposed method includes performance metrics with confidence intervals, providing a clear indication of the variability and reliability of the results. For instance, the accuracy, AUC, and F1-score for various tasks and datasets are presented with mean values and standard deviations. This approach allows for a comprehensive understanding of the method's performance and its consistency across different experiments.\n\nStatistical significance is a crucial aspect of our evaluation. The results demonstrate that our method outperforms several state-of-the-art and baseline methods across multiple metrics. For example, in the Tadpole dataset for disease classification, our method achieves higher accuracy, AUC, and F1-score compared to other methods, with the differences being statistically significant. Similarly, for the UK Biobank (UKBB) dataset, our method shows superior performance in both sex and age prediction tasks, with notable improvements in accuracy and F1-score.\n\nThe inclusion of confidence intervals and the demonstration of statistically significant improvements provide strong evidence that our method is indeed superior to the compared approaches. This rigorous evaluation ensures that the claims of superiority are well-founded and reliable.",
  "evaluation/availability": "Not enough information is available."
}