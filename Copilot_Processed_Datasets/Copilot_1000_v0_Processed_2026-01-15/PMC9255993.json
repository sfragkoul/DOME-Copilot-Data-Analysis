{
  "publication/title": "Predicting Pancreatic Ductal Adenocarcinoma Using Artificial Intelligence Analysis of Pre-diagnostic Computed Tomography Images",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Cancer Biomarkers",
  "publication/year": "2022",
  "publication/pmid": "35213359",
  "publication/pmcid": "PMC9255993",
  "publication/doi": "10.3233/CBM-210273",
  "publication/tags": "- Pancreatic Ductal Adenocarcinoma\n- Artificial Intelligence\n- Computed Tomography\n- Pre-diagnostic Imaging\n- Predictive Modeling\n- Radiomics\n- Machine Learning\n- Early Cancer Detection\n- Na\u00efve Bayes Classifier\n- Medical Image Analysis",
  "dataset/provenance": "The dataset used in this study was sourced from two medical centers in Los Angeles, California: Cedars-Sinai Medical Center (CSMC) and Southern California Kaiser Permanente Medical Center (KPMC). The data was obtained in accordance with the Institutional Review Board (IRB) and a material transfer agreement, with informed consent waived due to the retrospective study design. All data was anonymized and securely transferred using the Secure File Transfer Protocol (SFTP).\n\nA total of 108 contrast-enhanced abdominal CT scans from 72 subjects were collected. These scans were divided into an internal dataset and an external set. The internal dataset consists of 66 scans from 44 subjects, obtained at CSMC. This dataset includes 22 healthy control scans, 22 pre-diagnostic scans, and 22 diagnostic scans. The external set, used for validation, consists of 42 scans from 28 different subjects, obtained at KPMC. This set also includes 14 healthy control scans, 14 pre-diagnostic scans, and 14 diagnostic scans.\n\nThe scans were originally acquired for various non-gastrointestinal disorders, falls, slips, or vehicle accidents. The healthy control group did not develop pancreatic ductal adenocarcinoma (PDAC) within three years of their scans. The pre-diagnostic scans were obtained from patients who later developed PDAC, between 6 months to 3 years prior to diagnosis. The diagnostic scans were from patients with histopathologically confirmed PDAC and visible tumors on the CT scans.\n\nTo the best of our knowledge, the specific data structure used in this study, which includes pre-diagnostic scans obtained for non-pancreatic issues, has not been utilized previously for any PDAC prediction model. This unique approach allowed us to retrospectively examine imaging features in pre-diagnostic images, despite the lack of specific pre-cancerous indicators for PDAC.",
  "dataset/splits": "The dataset consists of two main splits: the internal dataset and the external set.\n\nThe internal dataset comprises 66 contrast-enhanced abdominal CT scans. These scans are further divided into three groups: 22 healthy control, 22 pre-diagnostic, and 22 diagnostic scans. These scans were obtained from 44 subjects at one center. Of these 66 scans, 58 belong to the portal venous phase, while the remaining 8 scans are from multiple CT phases, including arterial, excretory, and interleaved phases.\n\nThe external set includes 42 contrast-enhanced abdominal CT scans, with 14 scans in each of the three groups: healthy control, pre-diagnostic, and diagnostic. All scans in this set were obtained from 28 different subjects at another center and belong to the portal venous phase. This set was used for external validation of the developed prediction model.\n\nAll scans in both splits have a slice resolution of 512 by 512 in the x- and y-axis, and the CT signal intensities were normalized to unity. The pancreas in each slice of all scans was manually outlined by a trained radiologist and a gastroenterologist to ensure accuracy and minimize inter-reader variability.",
  "dataset/redundancy": "The dataset used in this study consists of three types of abdominal CT scans for each case: Healthy control, Pre-diagnostic, and Diagnostic. The Pre-diagnostic and Diagnostic scans were obtained from the same patient, ensuring that the data is paired and allows for retrospective examination of imaging features in pre-diagnostic images.\n\nThe dataset was split into a training set and an external validation set. The training set was used to develop the prediction model, while the external validation set was used to evaluate the model's performance. The external validation set consisted of 42 scans, which were examined to ensure they demonstrated incremental trends for all five selected features. This step was crucial to justify that the selected features for PDAC prediction are highly stable.\n\nTo enforce independence between the training and test sets, the external validation set was kept separate from the training process. This means that the model was trained solely on the training data and was not exposed to the external validation set until the evaluation phase. This approach helps to prevent data leakage and ensures that the model's performance on the validation set is a true reflection of its generalizability.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of pancreatic cancer prediction. The unique data structure, which includes pre-diagnostic scans, allows for a more comprehensive analysis of the progression from healthy control to pre-diagnostic and diagnostic stages. This structure has not been used previously for any PDAC prediction model, making it a novel contribution to the field. The inclusion of diagnostic scans in the predictors' selection phase helps identify highly stable features, which are essential for accurate classification. The model was trained with a fixed number of features to avoid overfitting while maximizing classification accuracy. The results demonstrate that the model achieved a mean classification accuracy of 86% on the external validation set, indicating its robustness and reliability.",
  "dataset/availability": "The data used in this study is not publicly available. The study utilized a unique dataset consisting of contrast-enhanced abdominal CT scans from two medical centers in Los Angeles, California: Cedars-Sinai Medical Center (CSMC) and Southern California Kaiser Permanente Medical Center (KPMC). The dataset includes three types of scans: diagnostic, pre-diagnostic, and healthy control.\n\nThe internal dataset comprises 66 scans from 44 subjects, while the external set includes 42 scans from 28 different subjects. All data was anonymized and securely transferred to the host department (CSMC) using Secure File Transfer Protocol (SFTP). The study design is retrospective, and informed consent was waived.\n\nThe data splits were carefully designed to include a balanced number of scans from each category, ensuring that the model could be trained and validated effectively. The internal dataset was used for training and initial validation, while the external set was used for external validation to assess the model's generalizability.\n\nDue to the sensitive nature of medical data and the need to protect patient privacy, the dataset is not released in a public forum. Access to the data is restricted and governed by institutional review board (IRB) approvals and material transfer agreements between the participating institutions. This ensures that the data is used ethically and in compliance with all relevant regulations and guidelines.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a combination of Recursive Feature Elimination (RFE) and Na\u00efve Bayes (NB). RFE is a feature selection technique that recursively removes the least significant features and builds the model on those remaining features. This process continues until the specified number of features is reached. In our case, we fixed the number of features selected by the classifier up to a maximum of 5 to avoid overfitting of the model while maximizing the classification accuracy.\n\nThe Na\u00efve Bayes classifier is a probabilistic machine learning model that is used for classification tasks. It is based on Bayes' theorem and assumes that the features are conditionally independent given the class label. Despite its simplicity, Na\u00efve Bayes can be quite effective and is often used as a baseline for comparison with more complex models.\n\nThe combination of RFE and Na\u00efve Bayes is not a new machine-learning algorithm. Both RFE and Na\u00efve Bayes are well-established techniques in the field of machine learning and have been extensively studied and used in various applications. The choice of using these techniques in our study was driven by their effectiveness in feature selection and classification, respectively.\n\nThe reason why this combination was not published in a machine-learning journal is that the focus of our study is on the application of these techniques to a specific problem in medical imaging, rather than on the development of new machine-learning algorithms. Our primary goal is to stratify high-risk individuals for pancreatic ductal adenocarcinoma (PDAC) by identifying predictive features in pre-diagnostic abdominal computed tomography (CT) scans. The use of RFE and Na\u00efve Bayes is a means to achieve this goal, and the evaluation of their performance is presented in the context of this application.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model employs Recursive Feature Elimination (RFE) in conjunction with a Na\u00efve Bayes (NB) classifier to identify and eliminate weak features during the training process. The RFE-NB method was used to select a maximum of five features to avoid overfitting while maximizing classification accuracy. The selected features were used to train the classifier, which was then validated on an external set of scans. The training data consisted of CT scans categorized into three groups: diagnostic, pre-diagnostic, and healthy control. The diagnostic scans were used to identify stable features, ensuring that the classifier could distinguish between healthy control and pre-diagnostic scans accurately. The independence of the training data is maintained by using distinct sets of scans for training and validation, with the validation set consisting of scans that were not part of the training process. This approach ensures that the model's performance is evaluated on unseen data, providing a robust assessment of its predictive capabilities.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps to ensure the robustness and accuracy of the predictive model. Initially, the dataset consisted of three types of abdominal CT scans for each case: healthy control, pre-diagnostic, and diagnostic. The pre-diagnostic and diagnostic scans were obtained from the same patient, allowing for a retrospective examination of imaging features in pre-diagnostic images.\n\nThe significant features identified were further filtered to those with mean values that either consistently increased or decreased across the healthy control, pre-diagnostic, and diagnostic groups. This filtering process helped in identifying stable features that could reliably distinguish between the different stages of pancreatic ductal adenocarcinoma (PDAC) development.\n\nFor the classification task, the problem was framed as a binary classification where a pancreas, based on its CT features, could be categorized into either a healthy control or a pre-diagnostic group. The inclusion of diagnostic scans in the feature selection phase was crucial for identifying highly stable features, which helped in avoiding misclassifications and ensured the model's reliability.\n\nThe Recursive Feature Elimination (RFE) method was employed in conjunction with a Na\u00efve Bayes (NB) classifier to eliminate weak features during the training process. This approach helped in selecting the most relevant features while avoiding overfitting. The number of features selected by the classifier was fixed at a maximum of five to balance between model complexity and classification accuracy. The RFE-NB method identified five radiomic features that showed an incremental trend and were used to achieve the highest classification accuracy on the training set.\n\nThe identified features included Long-run low grey-level emphasis, Inverse cluster shade, Inverse cluster prominence, Inverse cluster tendency, and Short-run low grey-level emphasis. These features were observed to increase in the order of healthy control, pre-diagnostic, and diagnostic groups, confirming their stability and relevance for PDAC prediction.\n\nThe preprocessing steps ensured that the data was clean and relevant, enabling the machine-learning algorithm to effectively distinguish between healthy and pre-diagnostic scans. This approach validated the primary hypothesis about the presence of precursor indicators in CT scans prior to PDAC development and demonstrated the potential of radiomic analysis in early PDAC detection.",
  "optimization/parameters": "In our study, we utilized three key radiomic parameters to extract features from CT scans: Bin size, Kernel size, and Angle. These parameters were crucial in discretizing the CT images, specifying the neighborhood around a voxel, and determining directions around a voxel for feature extraction, respectively. Different combinations of these parameters allowed us to capture variations in radiomic features, ensuring a comprehensive analysis.\n\nThe selection of these parameters was driven by the need to avoid contrast variation among CT scans acquired from different scanners. Discretization of CT scans helped in converting continuous voxel values into discrete counterparts, which was essential for avoiding noise and focusing on spatial heterogeneity. The choice of these parameters was also influenced by the goal of ensuring consistent results across all scans.\n\nWe extracted 4000 radiomic features from each of the 66 scans in the discovery set using various combinations of the three parameters. This approach allowed us to obtain a rich set of features that represented unique characteristics of the pancreas in the CT images. The features included First Order Statistics (FOS), Grey-level Co-occurrence Matrix statistics (GLCM), and Grey Level Run Length Matrix statistics (GLRLM), among others.\n\nThe number of features selected for the final model was determined using the Recursive Feature Elimination (RFE) method in conjunction with a Na\u00efve Bayes (NB) classifier. We fixed the number of features selected by the classifier to a maximum of 5 to avoid overfitting while maximizing classification accuracy. This process identified five radiomic features that showed an incremental trend and were used to achieve the highest classification accuracy on the training set.",
  "optimization/features": "The optimization process involved a feature selection step to identify the most relevant predictors for the classification task. Initially, several thousand radiomic features were extracted from the CT scans. These features represented various characteristics of the pancreas, such as intensity, texture, and shape, and were calculated using standard mathematical formulas.\n\nTo filter out the most significant features, a two-step statistical analysis was conducted. First, a Student's t-test was performed to identify features that showed significant differences between the healthy control and pre-diagnostic groups. This step reduced the number of features to those with a p-value of less than 0.05, which accounted for about 4.5% of the total extracted features.\n\nNext, the significant features were further filtered based on their trends across the healthy control, pre-diagnostic, and diagnostic groups. Only features that showed consistent increasing or decreasing trends were retained. This step ensured that the selected features were stable and potentially predictive of PDAC development.\n\nThe feature selection process was performed using the training set only, ensuring that the model's performance on the external validation set was an unbiased estimate of its generalization ability.\n\nThe final model used five radiomic features as input, which were identified using the Recursive Feature Elimination (RFE) method in conjunction with a Na\u00efve Bayes (NB) classifier. These features were Long-run low grey-level emphasis, Inverse cluster shade, Inverse cluster prominence, Inverse cluster tendency, and Short-run low grey-level emphasis. The use of a limited number of features helped to avoid overfitting and maximize classification accuracy.",
  "optimization/fitting": "The fitting method employed in this study involved a careful balance to avoid both overfitting and underfitting. Initially, several thousand radiomic features were extracted from CT scans, which indeed presented a scenario where the number of parameters was much larger than the number of training points. To address this, a two-step statistical analysis was conducted. First, a Student\u2019s t-test was performed to identify features significantly different between healthy and pre-diagnostic groups, reducing the feature set to about 4.5% of the total. This step ensured that only potentially predictive features were considered, mitigating the risk of overfitting.\n\nNext, the Recursive Feature Elimination (RFE) method was used in conjunction with a Na\u00efve Bayes (NB) classifier. This approach systematically eliminated weak features during the training process. To further prevent overfitting, the number of features selected by the classifier was fixed at a maximum of five. This constraint helped in avoiding the model becoming too complex and ensured that the selected features were highly stable and generalizable.\n\nThe classifier's performance was validated on an external dataset, which included scans not used in the training phase. The validation process involved two steps: first, checking for incremental trends in the selected features across healthy control, pre-diagnostic, and diagnostic groups; second, testing the classifier's accuracy on a subset of the external dataset. The mean classification accuracy achieved was 86%, demonstrating the model's robustness and generalizability.\n\nAdditionally, the incremental trends observed in the selected features across different groups justified their stability and reliability. This validation process ensured that the model was not underfitting, as it successfully classified scans into their respective groups with high accuracy. The use of an external dataset for validation further reinforced the model's ability to generalize to new, unseen data, thereby ruling out underfitting concerns.",
  "optimization/regularization": "In our study, we employed Recursive Feature Elimination (RFE) in conjunction with a Na\u00efve Bayes (NB) classifier to prevent overfitting. This method was crucial in eliminating weak features (predictors) from the extensive set of radiomic features identified during the two-step analysis. By doing so, we aimed to enhance the model's generalization capability and avoid overfitting, which is a common issue when dealing with high-dimensional data.\n\nTo further mitigate overfitting, we fixed the number of features selected by the classifier to a maximum of five. This decision was made to balance between model complexity and performance, ensuring that the classifier could achieve high classification accuracy without relying on an excessive number of features. The selected features\u2014Long-run low grey-level emphasis, Inverse cluster shade, Inverse cluster prominence, Inverse cluster tendency, and Short-run low grey-level emphasis\u2014all demonstrated an incremental trend, which aligned with our hypothesis about the progression towards pancreatic ductal adenocarcinoma (PDAC) development.\n\nThe RFE-NB approach not only helped in feature selection but also in comparing the overall training accuracies achieved by the classifier using different combinations of features. This iterative process ensured that the final model was robust and capable of generalizing well to unseen data. The validation of our classifier on an external dataset further confirmed its stability and reliability, achieving a mean classification accuracy of 86%. This consistent performance across different datasets underscores the effectiveness of our regularization method in preventing overfitting and enhancing the model's predictive power.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a black box. It employs a combination of Recursive Feature Elimination (RFE) and a Na\u00efve Bayes (NB) classifier, which together help in identifying and selecting the most relevant features for predicting pancreatic ductal adenocarcinoma (PDAC). The RFE method systematically removes the least significant features, ensuring that only the most stable and informative ones are retained. This process enhances the interpretability of the model by highlighting specific radiomic features that are crucial for distinguishing between healthy control and pre-diagnostic scans.\n\nThe selected features\u2014Long-run low grey-level emphasis, Inverse cluster shade, Inverse cluster prominence, Inverse cluster tendency, and Short-run low grey-level emphasis\u2014show an incremental trend across the healthy control, pre-diagnostic, and diagnostic groups. This trend indicates that these features are not only stable but also biologically meaningful, as they reflect changes that occur in the pancreas as PDAC develops. The model's transparency is further supported by the fact that it was validated on an external set of scans, demonstrating consistent and satisfactory performance. The confusion matrix provided in the validation step offers a clear view of the model's classification accuracy, reinforcing its reliability and interpretability.",
  "model/output": "The model developed is a classification model. It is designed to categorize CT scans of the pancreas into two groups: healthy control or pre-diagnostic. The purpose is to identify individuals at high risk for Pancreatic Ductal Adenocarcinoma (PDAC) by analyzing features in pre-diagnostic abdominal CT scans. The model uses a Na\u00efve Bayes classifier in conjunction with Recursive Feature Elimination (RFE) to select the most relevant features for classification. The final model utilizes five radiomic features that show an incremental trend across healthy control, pre-diagnostic, and diagnostic groups. These features are Long-run low grey-level emphasis, Inverse cluster shade, Inverse cluster prominence, Inverse cluster tendency, and Short-run low grey-level emphasis. The model was validated on an external dataset of 28 scans, achieving an average classification accuracy of 86%. This indicates the model's effectiveness in distinguishing between healthy and pre-diagnostic scans, thereby aiding in the early identification of individuals at risk for PDAC.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method for the developed classifier involved a two-step process using an external set of CT scans. Initially, all 42 scans from the external set were examined to ensure they demonstrated incremental trends for the five selected radiomic features. This step confirmed that the chosen features were highly stable, as they increased in the order of healthy control, pre-diagnostic, and diagnostic groups.\n\nIn the second step, the classifier was tested using 28 scans from the external set, consisting of 14 healthy control scans and 14 pre-diagnostic scans. The classifier automatically categorized these scans into their respective groups, achieving a mean classification accuracy of 86% (24 out of 28 scans were correctly classified). This accuracy was calculated as the ratio of successfully classified scans to the total number of scans used for testing. The results were presented in a confusion matrix, which provided a clear visualization of the classifier's performance. Despite the limited training data, the classifier's performance remained consistent during validation, producing highly satisfactory results. This evaluation method ensured that the classifier was robust and reliable for distinguishing between healthy control and pre-diagnostic scans.",
  "evaluation/measure": "The performance of the developed classifier was evaluated using a confusion matrix, which provides a detailed breakdown of true positives, true negatives, false positives, and false negatives. The primary metric reported is classification accuracy, which is the ratio of successfully classified scans to the total number of scans used for testing. In our study, the mean classification accuracy achieved was 86% (24/28) on an external set of 28 scans, consisting of 14 healthy control and 14 pre-diagnostic scans.\n\nThis set of metrics is representative of common practices in the literature for evaluating classification models, particularly in medical imaging. The confusion matrix is a standard tool for assessing the performance of binary classifiers, and classification accuracy is a widely used metric to summarize the overall effectiveness of the model. Additionally, the use of an external validation set ensures that the reported performance is generalizable and not overfitted to the training data.\n\nThe confusion matrix specifically indicates that the model correctly identified 13 out of 14 healthy control scans and 11 out of 14 pre-diagnostic scans, demonstrating its ability to distinguish between the two groups effectively. This level of performance is encouraging, especially given the limited amount of data available for training. The stability and consistency of the identified features across different phases of CT scans further support the robustness of the model.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of the classifier's performance was conducted using a confusion matrix, which provides a clear breakdown of true positives, true negatives, false positives, and false negatives. The classifier achieved a mean classification accuracy of 86% on the external test set, which consisted of 28 scans (14 healthy control and 14 pre-diagnostic). This accuracy was calculated as the ratio of successfully classified scans to the total number of scans used for testing.\n\nThe performance metrics, including classification accuracy, were derived from the confusion matrix. However, specific confidence intervals for these metrics were not explicitly provided. The results indicate that the classifier performed consistently well, with a high number of true positives and true negatives, suggesting robustness in distinguishing between healthy control and pre-diagnostic groups.\n\nThe statistical significance of the results was implied by the consistent performance across the external dataset. The identified features showed incremental trends across healthy control, pre-diagnostic, and diagnostic groups, justifying their stability and reliability. The use of Recursive Feature Elimination (RFE) with a Na\u00efve Bayes (NB) classifier helped in selecting the most relevant features, ensuring that the model was not overfitted.\n\nWhile the performance metrics are promising, the absence of explicit confidence intervals and detailed statistical tests limits the ability to claim superiority over other methods or baselines with absolute certainty. However, the consistent and high classification accuracy across the external dataset provides strong evidence of the method's effectiveness. Further validation on larger and more diverse datasets would strengthen the confidence in these results.",
  "evaluation/availability": "Not enough information is available."
}