{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "SAGE Open Nursing",
  "publication/year": "2023",
  "publication/pmid": "37435577",
  "publication/pmcid": "PMC10331222",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Artificial Intelligence\n- Diabetic Foot Ulcers\n- Prediction Models\n- Machine Learning\n- Neural Networks\n- Decision Trees\n- Diabetes Management\n- Healthcare Technology\n- Patient Outcomes\n- Medical Data Analysis",
  "dataset/provenance": "The dataset used in this study was collected from the National Institute of Diabetes and Endocrine Glands at Cairo University Hospital in Egypt. A purposive sample of 200 adult diabetic patients was included, all of whom had been living with diabetes for more than a year. The data collection process involved a structured interview questionnaire, which was divided into three parts. The first part covered demographic characteristics such as age, gender, level of education, place of residence, and income. The second part focused on medical data, including the duration of diabetes, family history, type of treatment, history of exercise, pain in the feet, and complications from diabetes. The third part involved in vivo measurements, specifically weight, height, body mass index, and blood sugar level.\n\nThe dataset was divided into two groups: one consisting of 82 patients who had foot ulcers and the other consisting of 118 patients who did not. This division was crucial for training and testing the machine learning models, specifically the Artificial Neural Network (ANN) and Decision Tree (DT), which were used to predict the occurrence of foot ulcers. The data collection period spanned from November 2022 to January 2023, ensuring a comprehensive and recent dataset for analysis. The dataset was also used to validate the reliability of the AI methods, with an accuracy of 97% achieved using the ANN.",
  "dataset/splits": "The dataset was divided into two primary groups: a training set and a testing set. This division is essential for creating and assessing the accuracy of the decision tree (DT) model. The training set is used to build the DT, while the testing set is used to evaluate the model's performance.\n\nThe dataset consists of 200 diabetic patients. The specific distribution of data points between the training and testing sets is not explicitly detailed, but it is implied that the division is done to ensure a comprehensive evaluation of the model.\n\nAdditionally, the study employs k-fold cross-validation with k equal to 10. This technique involves splitting the data into 10 subsets, or folds. The model is trained on 9 of these folds and tested on the remaining fold. This process is repeated 10 times, with each fold serving as the testing set once. This method helps to maximize the use of limited data and prevents overfitting in the machine learning models.",
  "dataset/redundancy": "The dataset used in this study consisted of medical data and in vivo measurements from 200 diabetic patients. To ensure robust model evaluation and to maximize the use of the limited data, k-fold cross-validation was employed. Specifically, 10-fold cross-validation was used, where the dataset was divided into 10 subsets. In each iteration of the cross-validation process, one subset was used as the testing set, and the remaining nine subsets were used as the training set. This process was repeated 10 times, with each subset serving as the testing set exactly once. This approach ensures that every data point is used for both training and testing, providing a comprehensive evaluation of the model's performance.\n\nThe training and testing sets are independent in each fold of the cross-validation process. This independence is enforced by the nature of k-fold cross-validation, where the data is randomly shuffled before being split into folds. This random shuffling helps to ensure that the distribution of data points in each fold is representative of the overall dataset, reducing the risk of bias and overfitting.\n\nComparing this approach to previously published machine learning datasets, the use of k-fold cross-validation is a standard practice, especially when dealing with small to moderately sized datasets. This method is particularly useful in medical research, where obtaining large datasets can be challenging due to privacy concerns and regulatory constraints. By using k-fold cross-validation, the study aims to achieve a balanced and reliable assessment of the model's performance, ensuring that the results are generalizable to new, unseen data.",
  "dataset/availability": "The dataset used in this study is not publicly available due to the sensitive nature of the medical information it contains. Privacy concerns and strict regulations surrounding patient data make it challenging to share large datasets openly. The study involved a purposive sample of 200 diabetic patients from the National Institute of Diabetes and Endocrine Glands at Cairo University Hospital. The data collection process ensured anonymity and confidentiality through coding the data. Ethical considerations were strictly adhered to, including obtaining informed consent from participants and approval from the institutional review board. The dataset was divided into training and testing sets using k-fold cross-validation to maximize the use of limited data and prevent overfitting in machine learning models. This approach allowed for robust evaluation of the models without compromising patient privacy.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are decision trees (DTs) and artificial neural networks (ANNs). These are well-established classes of algorithms in the field of machine learning.\n\nThe specific type of decision tree used is a random forest (RF), which is an ensemble learning method that operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe ANN used in this study is a multilayer perceptron, which is a class of feedforward artificial neural network. It consists of an input layer, two hidden layers, and an output layer. The input layer has 19 nodes, corresponding to the significant attributes identified from medical history and foot images. The first hidden layer has 19 nodes, the second hidden layer has 7 nodes, and the output layer has one node that indicates whether a sample has a foot ulcer or not.\n\nThese algorithms are not new; they have been extensively studied and used in various applications. The choice of these algorithms was driven by their effectiveness in handling the specific characteristics of the dataset, such as the small sample size and the need to capture non-linear relationships between features.\n\nThe study focuses on the application of these algorithms to the prediction of diabetic foot ulcers, which is a specific medical problem. Therefore, it is published in a nursing journal rather than a machine-learning journal. The primary goal is to contribute to the field of diabetic foot care by providing a reliable prediction model, rather than to introduce a new machine-learning algorithm.",
  "optimization/meta": "The proposed model employs a meta-predictor approach, specifically utilizing a random forest (RF) as part of its decision tree (DT) methodology. A random forest is an ensemble of multiple decision trees, functioning as a meta-estimator. This ensemble method leverages bagging and randomness to create a forest of negatively correlated trees, aiming to produce a more reliable committee prediction than any single tree.\n\nThe random forest spreads a class prediction, and the class with the most votes becomes the model's predictor. This approach ensures that the training data for each individual tree within the forest is independent, enhancing the robustness and generalizability of the model.\n\nThe model compares the performance of two classifiers: decision trees and artificial neural networks (ANNs). For decision trees, the random forest method is used, while for neural networks, various hidden layer structures are trained to find the optimal configuration. The ANN consists of an input layer, two hidden layers, and an output layer, with specific node configurations designed to predict the occurrence of foot ulcers.\n\nThe use of k-fold cross-validation, with k equal to 10, ensures that the model's performance is evaluated rigorously, maximizing the use of limited data and preventing overfitting. This technique is crucial given the sensitivity of medical data and the challenges in obtaining large datasets due to privacy concerns and regulatory constraints.",
  "optimization/encoding": "The data encoding process involved dividing the dataset into two groups: a training set for creating a decision tree (DT) and a testing set for evaluating the accuracy of the predictions. Each scenario's characteristics were initially provided as input data before selecting a feature to act as the choice for the given challenge (output data). For each input attribute, distinct value classes were established. If an attribute could only accept discrete values, each value was assigned its own class. For attributes with a range of possible numerical values, characteristic intervals representing several classes were created.\n\nThe dataset consisted of medical data and in vivo measurements of diabetic patients, with a total of 200 participants. Various attributes were considered, including the duration of diabetes, family history, type of treatment, history of exercise, pain in feet, complications from diabetes, body mass index, and blood sugar level. Each attribute was analyzed to determine its significance in predicting foot ulcers.\n\nThe data was pre-processed to ensure compatibility with the machine-learning algorithms. For instance, input foot images of varying sizes were resized using a bilinear interpolation method to standardize the input dimensions. This preprocessing step facilitated subsequent processing and improved the performance of the algorithms.\n\nThe artificial neural network (ANN) was trained using 19 significant features to optimize the weights between the input, output, and hidden layers. The goal was to minimize the sum of the total squared errors, with the weights being modified during training according to a learning parameter. The ANN consisted of multiple layers and nodes, and it was designed to classify instances into two classes: foot ulcers and non-foot ulcers.\n\nIn summary, the data encoding process involved dividing the dataset, establishing value classes for input attributes, and preprocessing the data to ensure compatibility with the machine-learning algorithms. The ANN was trained using significant features to optimize the weights and improve the accuracy of the predictions.",
  "optimization/parameters": "In our study, we utilized a total of 26 attributes initially. However, through a careful analysis of medical history and foot images, we identified that only 19 of these attributes were significant in predicting diabetic foot ulcers (DFUs). These 19 parameters were selected based on their relevance to the medical condition and their impact on the occurrence of DFUs. The selection process involved a thorough review of existing literature and expert consultation to ensure that the most pertinent features were included in our model. This reduction in the number of parameters helped in improving the model's performance and efficiency.",
  "optimization/features": "In our study, we utilized a total of 26 attributes initially. However, through a careful analysis of medical history and foot images, we identified that only 19 of these attributes were significant in predicting diabetic foot ulcers. This process involved feature selection to ensure that the most relevant features were used for training our models.\n\nThe feature selection was performed using the training set only, adhering to best practices in machine learning to prevent data leakage and ensure the robustness of our models. This approach helped us to focus on the most informative features, thereby improving the performance and generalizability of our predictive models.",
  "optimization/fitting": "In our study, we employed a neural network (ANN) and decision trees (DTs) to predict the occurrence of diabetic foot ulcers (DFUs). The ANN consisted of an input layer, two hidden layers, and an output layer. The first hidden layer had 19 nodes, corresponding to the input parameters, which were connected to 7 nodes in the second hidden layer. These, in turn, connected to 7 nodes in the third hidden layer, leading to a single output node that indicated the presence or absence of a foot ulcer.\n\nGiven the complexity of the ANN, with multiple layers and nodes, the number of parameters was indeed larger than the number of training points. To address the risk of overfitting, we utilized k-fold cross-validation with k equal to 10. This technique helps to maximize the use of limited data and prevents overfitting by ensuring that the model is trained and validated on different subsets of the data. Additionally, we carefully selected 19 significant features out of the initial 26 attributes based on medical history and foot images, which helped in reducing the complexity and the risk of overfitting.\n\nTo rule out underfitting, we trained the ANN using various hidden layer structures and node configurations to find the optimal architecture. This process ensured that the model was complex enough to capture the underlying patterns in the data without being too simplistic. Furthermore, we compared the performance of the ANN with that of decision trees, which provided a benchmark for evaluating the model's effectiveness. The ANN outperformed the DTs in terms of accuracy, sensitivity, specificity, and other evaluation metrics, indicating that it was appropriately fitted to the data.\n\nIn summary, we managed the balance between overfitting and underfitting by using k-fold cross-validation, feature selection, and extensive training of the ANN with different architectures. These methods ensured that our model was robust and generalizable to new data.",
  "optimization/regularization": "In our study, we employed k-fold cross-validation to prevent overfitting. Specifically, we used 10-fold cross-validation, which involves dividing the dataset into 10 subsets. The model is then trained on 9 of these subsets and tested on the remaining one, with this process repeated 10 times, each time using a different subset as the test set. This technique helps to ensure that the model generalizes well to unseen data by maximizing the use of limited data and reducing the risk of overfitting. Additionally, we utilized a relatively small dataset due to privacy concerns and strict regulations, making k-fold cross-validation particularly valuable in this context.",
  "optimization/config": "The configuration details for the models used in this study are not explicitly provided in the publication. The study mentions the use of decision trees (DTs) and artificial neural networks (ANNs) for predicting the occurrence of diabetic foot ulcers (DFUs). Specifically, random forests (RFs) were employed for the DTs, and the ANN consisted of an input layer, two hidden layers, and an output layer. The ANN was trained using 19 features to optimize the weights between the layers.\n\nHowever, the specific hyper-parameter configurations, optimization schedules, and model files are not detailed in the text. The study does not provide information on where these configurations can be accessed or under what license they might be available. The focus of the publication is on the experimental results and the comparison of the performance metrics between the DTs and ANNs, rather than the technical details of the model configurations.\n\nThe study does mention the use of MATLAB 2021 for all calculations and the employment of 10-fold cross-validation for training and testing the models. This indicates a rigorous approach to model validation, but it does not provide the granular details of the model configurations themselves.",
  "model/interpretability": "In our study, we employed two distinct models for predicting foot ulcers: Artificial Neural Networks (ANNs) and Decision Trees (DTs). The interpretability of these models varies significantly.\n\nANNs, particularly the type used in our proposed solution, are often considered black-box models. This means that while they can provide highly accurate predictions, the internal workings and the reasoning behind these predictions are not easily interpretable. The ANN consists of an input layer, two hidden layers, and an output layer. The input layer receives the parameters for each sample, which are then processed through the hidden layers. The output layer provides a binary indication of whether a sample has a foot ulcer or not. However, the specific contributions of each input parameter to the final prediction are not straightforward to discern.\n\nOn the other hand, Decision Trees offer a more transparent and interpretable model. Each tree in the random forest (RF) ensemble used in our study can be visualized and understood. The tree structure includes attribute nodes, which represent internal nodes, and decision leaves, which represent the final outcomes. Each attribute node has branches corresponding to distinct value classes, making it easy to follow the decision-making process. For instance, starting from the root node, one can trace the path through the tree based on the values of the input attributes, ultimately reaching a leaf node that represents the decision. This transparency allows for a clear understanding of how each attribute influences the prediction, making DTs a valuable tool for interpretability in medical diagnostics.\n\nIn summary, while ANNs provide robust predictive performance, they lack transparency. Decision Trees, however, offer a clear and interpretable structure, making them suitable for scenarios where understanding the decision-making process is crucial.",
  "model/output": "The model is a classification model. It is designed to predict whether a patient has a foot ulcer or not. The output layer of the artificial neural network contains one node that indicates the presence or absence of a foot ulcer. Similarly, the decision tree model classifies cases into different decision classes based on the input attributes, ultimately predicting whether a foot ulcer is present.\n\nThe evaluation metrics used, such as accuracy, sensitivity, specificity, and the area under the ROC curve, further confirm that the model's purpose is classification. The model's performance was assessed using these metrics, which are commonly used to evaluate classification models.\n\nThe experimental results showed that the artificial neural network outperformed the decision tree in terms of accuracy, sensitivity, specificity, and other evaluation metrics. This indicates that the model is effective in classifying foot ulcers based on the input data. The use of k-fold cross-validation ensured that the model's performance was reliable and generalizable to new data.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study involved a rigorous approach to ensure the robustness and generalizability of the findings. All calculations were performed using MATLAB 2021, and the performance of the models was compared using k-fold cross-validation, with k set to 10. This technique is particularly useful for maximizing the use of limited data and preventing overfitting in machine learning models.\n\nThe study focused on predicting the occurrence of foot ulcers using two classifiers: decision trees (DTs) and neural networks (ANNs). For the DTs, random forests (RFs) were utilized. The neural networks were trained with various hidden layers and node structures to identify the optimal configuration. The primary metric of interest was the accuracy of each classifier. However, sensitivity and specificity were also considered crucial, with sensitivity being particularly important in medical data to minimize false negatives.\n\nThe dataset consisted of 26 attributes, but only 19 were deemed significant based on medical history and foot images affecting diabetic foot ulcers (DFUs). Due to privacy concerns and the sensitive nature of medical data, obtaining large datasets is challenging. To address this, k-fold cross-validation was used to distribute the data into training and testing sets, ensuring that the models were evaluated on diverse subsets of the data.\n\nThe results indicated that the ANN outperformed the DT in terms of evaluation metrics. The ANN achieved an accuracy of 0.97 compared to the DT's 0.93. The ANN also demonstrated superior sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and F-score. The receiver operating characteristic (ROC) curves further supported these findings, with the ANN showing a smaller error rate in foot ulcer cases. The area under the ROC curve (AUC) for the ANN was 1.0, compared to 0.96 for the DT, indicating better overall performance.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to assess the effectiveness of our models in predicting foot ulcers. The primary metric we reported was accuracy, which measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. For our artificial neural network (ANN), we achieved an accuracy of 0.97, while the decision tree (DT) had an accuracy of 0.93.\n\nIn addition to accuracy, we also considered sensitivity and specificity. Sensitivity, also known as the true positive rate, is crucial in medical data as it indicates the proportion of actual positives that are correctly identified. Our ANN demonstrated superior sensitivity compared to the DT. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. Both models showed high specificity, but the ANN slightly outperformed the DT.\n\nWe also evaluated the positive predictive value (PPV) and negative predictive value (NPV). The PPV indicates the probability that subjects with a positive screening test truly have the disease, while the NPV indicates the probability that subjects with a negative screening test truly do not have the disease. The ANN had a PPV of 0.99 and outperformed the DT in terms of NPV.\n\nFurthermore, we reported the F-score, which is the harmonic mean of precision and recall (sensitivity). The ANN showed an increase in the F-score by 0.05 compared to the DT.\n\nThe receiver operating characteristic (ROC) curves were also analyzed, with the area under the ROC curve (AUC) serving as an additional performance metric. The ANN had an AUC of 1.0, indicating excellent performance, while the DT had an AUC of 0.96.\n\nThese metrics collectively provide a comprehensive evaluation of our models' performance. The ANN consistently outperformed the DT across most metrics, highlighting its effectiveness in predicting foot ulcers. Our choice of metrics aligns with standard practices in the literature, ensuring that our evaluation is representative and robust.",
  "evaluation/comparison": "In our study, we compared the performance of two classifiers: Decision Trees (DTs) and Artificial Neural Networks (ANNs). The comparison was conducted using a dataset of 200 samples, focusing on predicting the development of foot ulcers in diabetic patients. We employed k-fold cross-validation with k equal to 10 to ensure robust evaluation.\n\nFor the DTs, we utilized Random Forests (RFs), which are an ensemble of multiple DTs. This approach helps to create a more reliable prediction by combining the outputs of individual trees. The DTs were built using the Classification and Regression Trees (CART) algorithm, and the dataset was split into training and testing sets using five-fold cross-validation and leave-one-out cross-validation (LOOCV) techniques.\n\nOn the other hand, we trained ANNs with various hidden layers and node structures to find the optimal configuration. The ANN used in our proposed solution consisted of an input layer, two hidden layers, and an output layer. The first hidden layer contained 19 nodes corresponding to the input parameters, which connected to 7 nodes in the second hidden layer and then to 7 nodes in the third hidden layer. The output layer had one node indicating whether a sample had a foot ulcer or not.\n\nThe evaluation metrics included accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and F-score. The ANN outperformed the DT in all these metrics. Specifically, the ANN achieved an accuracy of 0.97 compared to the DT's 0.93. The sensitivity, specificity, and PPV of the ANN were also higher, demonstrating its superior performance in predicting foot ulcers.\n\nIn summary, while simpler baselines like DTs were considered, the ANN showed significant improvements in predictive performance. This comparison highlights the effectiveness of ANNs in handling complex, non-linear relationships in medical data, making them a valuable tool for predicting diabetic foot ulcers.",
  "evaluation/confidence": "The evaluation of our proposed model involved a thorough statistical analysis to ensure the reliability and significance of our results. We employed k-fold cross-validation with k equal to 10, which is a robust technique for maximizing the use of limited data and preventing overfitting. This method helps in providing a more accurate estimate of the model's performance by ensuring that each data point is used for both training and validation.\n\nIn terms of performance metrics, we focused on accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and the F-score. The artificial neural network (ANN) outperformed the decision tree (DT) across all these metrics. For instance, the ANN achieved an accuracy of 0.97 compared to the DT's 0.93. The sensitivity of the ANN was also superior, which is particularly important in medical data as it indicates a lower false negative rate. The specificity and PPV of the ANN were both 1 and 0.99, respectively, which are higher than those of the DT. Additionally, the ANN showed better performance in terms of NPV and had an increase in the F-score by 0.05 compared to the DT.\n\nThe receiver operating characteristic (ROC) curves further supported these findings. The ROC curve for the ANN was closer to the y-axis with an area under the curve (AUC) of 1.0, compared to the DT's AUC of 0.96. This indicates that the ANN provides a smaller error rate in predicting foot ulcer cases.\n\nStatistical significance was assessed using Pearson\u2019s chi-square test to analyze relationships between variables and determine the correlation with diabetic foot ulcers (DFUs). The results showed significant associations with variables such as place of residence and age, which are crucial for understanding the factors contributing to DFUs.\n\nOverall, the performance metrics and statistical analyses provide strong evidence that the ANN is a superior method for predicting foot ulcers in diabetic patients. The confidence intervals and statistical significance of our results support the claim that our method is effective and reliable.",
  "evaluation/availability": "Not enough information is available."
}