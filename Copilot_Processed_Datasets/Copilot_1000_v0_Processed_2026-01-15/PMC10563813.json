{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Proc SPIE Int Soc Opt Eng",
  "publication/year": "2023",
  "publication/pmid": "37818350",
  "publication/pmcid": "PMC10563813",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Deep Learning\n- Multiple Instance Learning\n- Histopathological Image Analysis\n- End-Stage Renal Disease\n- Whole Slide Imaging\n- Self-Attention Networks\n- Feature Extraction\n- Machine Learning\n- Medical Imaging\n- Predictive Modeling",
  "dataset/provenance": "The dataset utilized in this study was sourced from an existing cohort of 56 patients with type 2 diabetes. These patients were characterized in greater detail in prior work that focused on the integration of histology with urinary proteomics. The patients were recruited from Seoul National University College of Medicine, located in Seoul, Republic of Korea. The study was approved by the Institutional Review Board (IRB: H-1812-159-998).\n\nThe dataset includes a variety of patient data, such as demographics, medical history, kidney biopsy results, and blood test measurements taken at the time of the biopsy. Serum creatinine levels were used to determine the estimated glomerular filtration rate (eGFR). Additional creatinine data was collected one year and two years following the initial kidney biopsy to assess the progression to end-stage renal disease (ESRD). The focus of this work is on predicting longer-term ESRD, measured two years after the initial biopsy, using whole slide images (WSIs) extracted at the time of the initial biopsy. The biopsy WSIs were stained using a periodic acid-Schiff (PAS) procedure.\n\nThe dataset consists of 56 unique patients, each associated with a single WSI. Each WSI contains a variable number of segmented glomeruli, with an average of 16.6 glomeruli per WSI. The number of glomeruli ranges from a minimum of 2 to a maximum of 45. This dataset has been used in previous research, particularly in studies that integrated renal histology with urinary proteomics. The panoptic segmentation and feature extraction processes were informed by prior work, ensuring that the dataset is built upon established methodologies in the field.",
  "dataset/splits": "In our study, we employed a leave-one-out cross-validation approach, which resulted in 56 data splits. Each split consisted of 55 whole slide images (WSIs) for training and 1 WSI for testing. This process was repeated 56 times, ensuring that each WSI was used as the test sample exactly once. The distribution of data points in each split was consistent, with 55 training samples and 1 test sample per iteration. This method was chosen to mitigate overfitting challenges due to our relatively small sample size and to accurately estimate the generalizability of our framework.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not applicable",
  "optimization/algorithm": "The optimization algorithm employed in our study is the Adam optimizer. This is a well-established method for stochastic optimization, known for its efficiency and effectiveness in training deep learning models. It is not a new algorithm; it was introduced by Kingma and Ba in 2014 and has since become a standard choice in the machine learning community due to its adaptability and performance across various tasks.\n\nThe reason it was not published in a machine-learning journal in this context is that the focus of our work is on applying existing optimization techniques to a specific medical problem\u2014predicting the onset of end-stage renal disease (ESRD) from renal biopsy whole slide images (WSIs). Our contributions lie in the innovative application of these techniques within a multi-stage, hybrid AI framework that integrates deep learning-based segmentation, handcrafted histological feature extraction, nonlinear feature compression, self-attention instance pooling, and deep transformer networks. This framework aims to improve the accuracy of ESRD predictions compared to traditional methods like recurrent neural networks (RNNs), XGBoost, or logistic regression models.",
  "optimization/meta": "The meta-predictor in our study does not directly use data from other machine-learning algorithms as input. Instead, it leverages a multi-stage pipeline that integrates various components to predict end-stage renal disease (ESRD) two years after initial biopsy. The pipeline includes convolutional neural networks for panoptic glomeruli segmentation, expert-defined histological features, and a transformer-based self-attention network with a novel pairwise distance embedding.\n\nThe transformer network is the core of our prediction model, utilizing spatial pairwise distance embeddings and denoising autoencoders (DAEs) for feature reduction. This approach allows the model to aggregate variable-length sets of extracted glomeruli features into a fixed-dimensional whole slide image (WSI) context. The transformer module is composed of 8 layers with 8 attention heads per layer, and all hidden layers use 64 hidden units with Gaussian Error Linear Unit (GELU) activations.\n\nTo ensure the generalizability of our framework, we employed leave-one-out cross-validation. This process involves training 56 different models, each time using 55 WSIs for training and the remaining one for testing. This method helps mitigate overfitting challenges and accurately estimates the model's performance.\n\nRegarding the independence of training data, the leave-one-out cross-validation ensures that each WSI is used once as a test sample, while the remaining 55 WSIs are used for training. This approach guarantees that the training data is independent for each iteration, providing a robust evaluation of the model's performance.",
  "optimization/encoding": "The data encoding process involved several steps to prepare the histological images for machine learning algorithms. Initially, a panoptic segmentation step was performed to isolate glomeruli within each patient's whole slide image (WSI). Following segmentation, expert-defined features were extracted, including color, texture, and morphological attributes, as well as a binary indication of sclerosis and the two-dimensional centroid location of each glomerulus. This resulted in a comprehensive set of 316 numerical features per glomerulus.\n\nTo address the high dimensionality and potential noise in the feature set, a denoising autoencoder (DAE) was employed. The DAE consisted of an encoder with four fully connected layers that transformed the original 316-dimensional feature vectors into a compressed 16-dimensional representation. Each fully connected layer was followed by a rectified linear unit activation and a dropout layer with a 20% dropout rate. The decoder mirrored the encoder's architecture, aiming to reconstruct the input features from the compressed representation. The DAE was trained using an Adam optimizer with a learning rate of 0.001, L2 regularization of 0.0001, and dropout rate of 20%, minimizing the mean squared reconstruction error.\n\nThe DAE-encoded features were then used as inputs for the downstream machine learning models. For the transformer model, these encoded features were further processed through a fully connected layer with Gaussian error unit activation and 20% dropout, transforming each glomerulus vector into a hidden representation. These representations were then passed through a BERT-like transformer classifier, which introduced a special global classification token to capture the overall context among all glomeruli. The spatial relationships between glomeruli were incorporated using pairwise distance embeddings based on the Euclidean distance between glomerulus centroids, providing the model with spatial awareness.\n\nThis multi-stage encoding process ensured that the input data was both dimensionally reduced and contextually enriched, enabling the machine learning models to effectively learn and predict the two-year ESRD status.",
  "optimization/parameters": "In our study, the model's input parameters were carefully selected to balance complexity and performance, given the relatively small sample size. The transformer module, which is the core of our prediction model, consists of 8 layers, each with 8 attention heads. All hidden layers, including the feedforward component of the transformer encoder, use 64 hidden units. This configuration was chosen based on reasonable initial values and small deviation experiments to measure the effects of important parameters.\n\nThe denoising autoencoder (DAE) used for dimensionality reduction also has specific hyperparameters, which are detailed in a separate section. The baseline setting for our models included a dropout rate of 0.5, L2 weight regularization of 0.0001, and a learning rate of 0.01. These values were selected to mitigate overfitting challenges and to accurately estimate the model's generalizability.\n\nThe selection of these parameters was not exhaustive but rather focused on key aspects that significantly impact model performance. For instance, the dropout rate and L2 regularization help in preventing overfitting, while the learning rate affects the convergence speed and stability of the training process. The number of layers and attention heads in the transformer, along with the hidden units, were chosen to capture complex patterns in the data without overcomplicating the model.\n\nIn summary, the input parameters were selected through a combination of initial reasonable values and targeted experiments to ensure the model's effectiveness and generalizability. The specific values for dropout, L2 regularization, and learning rate were chosen based on their known benefits in similar models and datasets. The transformer's architecture, with 8 layers and 8 attention heads per layer, along with 64 hidden units, was designed to balance computational efficiency and model capacity.",
  "optimization/features": "The input features used in our study are derived from histological images of renal biopsies. Specifically, we extract a comprehensive set of 316 numerical features per glomerulus. These features include expert-defined color, texture, and morphological attributes, as well as a binary indication of sclerosis and the two-dimensional centroid location of each segmented glomerulus.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, we employed a denoising autoencoder (DAE) to reduce the dimensionality of the feature space. This approach helps to mitigate overfitting by transforming the original features into a more meaningful and compressed representation. The DAE consists of an encoder with four fully connected layers that reduce the dimensionality from 316 to 16 latent features. This dimensionality reduction step was crucial given our limited dataset size, ensuring that the model focuses on the most relevant information.\n\nThe DAE was trained independently for each cross-validation fold, using only the training data from that fold. This ensures that the dimensionality reduction process does not inadvertently use information from the test set, maintaining the integrity of the cross-validation procedure. The resulting compressed representations are then used as input to the downstream machine learning models, including the transformer network and other baseline models.",
  "optimization/fitting": "In our study, we addressed the challenge of having a relatively small sample size (N = 56) for training deep learning models, which inherently poses a risk of overfitting due to the large number of parameters compared to training points. To mitigate this, we employed several strategies.\n\nFirstly, we utilized a denoising autoencoder (DAE) for dimensionality reduction. This step transformed the high-dimensional feature space into a more compact and meaningful representation, helping to reduce noise and focus on relevant features. The DAE consisted of an encoder with four fully connected layers, reducing the original 316 features to 16 latent features. This dimensionality reduction helped in managing the complexity of the model and preventing overfitting.\n\nSecondly, we implemented leave-one-out cross-validation. This method involved training 56 different models, each time using 55 whole slide images (WSIs) for training and the remaining one for testing. This process ensured that each WSI was used as a test sample exactly once, providing a robust estimate of the model's generalizability and helping to rule out overfitting.\n\nAdditionally, we incorporated regularization techniques such as dropout and L2 regularization. Dropout was applied at a rate of 20% during training, which helped in preventing the model from becoming too reliant on specific neurons. L2 regularization was used to penalize large weights, further aiding in the prevention of overfitting.\n\nTo address underfitting, we carefully selected hyperparameters and performed small deviation experiments to measure the effects of important parameters. The transformer module consisted of 8 layers with 8 attention heads per layer, and all hidden layers used 64 hidden units with Gaussian Error Linear Unit (GELU) activations. We also used an Adam optimizer with a default learning rate of 1e-2 and a learning rate scheduler that automatically decreased the learning rate if the validation loss did not improve after 10 epochs. Training was halted if the loss on the validation set did not decrease after 20 epochs, ensuring that the model did not underfit by stopping training prematurely.\n\nIn summary, our approach combined dimensionality reduction, robust cross-validation, regularization techniques, and careful hyperparameter tuning to balance the risk of overfitting and underfitting, given the limited dataset size.",
  "optimization/regularization": "In our study, several regularization techniques were employed to prevent overfitting, particularly crucial given our relatively small sample size. One key method involved using dropout, a technique where randomly selected neurons are ignored during training. This helps to prevent the model from becoming too reliant on any single neuron, thereby improving generalization. We experimented with different dropout rates, including 0.2, 0.5, and 0.8, to observe their effects on model performance.\n\nAdditionally, L2 regularization was applied to penalize large weights in the model, which helps in reducing overfitting by discouraging complex models. We tested various L2 regularization strengths, such as 0, 1e-4, 1e-2, and 1e-6, to determine the optimal balance between bias and variance.\n\nAnother regularization technique used was the denoising autoencoder (DAE), which compresses and reconstructs the input data, effectively learning robust features that are less sensitive to noise. This process aids in reducing overfitting by ensuring that the model focuses on the most relevant features.\n\nFurthermore, we utilized leave-one-out cross-validation, a rigorous method where each sample is used once as a test set while the remaining samples form the training set. This approach ensures that the model's performance is evaluated on unseen data, providing a more accurate estimate of its generalizability.\n\nLastly, early stopping was implemented during training. If the validation loss did not improve after a specified number of epochs, the training process was halted. This prevents the model from overfitting to the training data by stopping the training when performance on the validation set starts to degrade.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in detail. The baseline settings included a dropout rate of 0.5, L2 weight regularization of 0.0001, and a learning rate of 0.01. Various deviations from these baseline settings were explored to measure the effects of specific parameters. For instance, different dropout rates, L2 regularization values, and learning rates were tested to understand their impact on model performance.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the methods and configurations used are described comprehensively, allowing for reproducibility. The study utilized a multi-stage transformer network, which included a denoising autoencoder (DAE) for feature reduction and a transformer module composed of 8 layers with 8 attention heads per layer. All hidden layers in the prediction model used 64 hidden units with Gaussian Error Linear Unit (GELU) activations.\n\nThe optimization process involved training models with an Adam optimizer, a batch size of 12 patients, and standard binary cross-entropy loss. Training was halted if the loss on the validation set did not decrease after 20 epochs, and a learning rate scheduler was used to automatically decrease the learning rate if the validation loss did not improve after 10 epochs.\n\nRegarding the availability and licensing of the reported configurations and schedules, the publication does not specify a particular license for the methods or code used. However, the detailed descriptions provided should enable other researchers to implement and reproduce the experiments described. For specific model files or code, interested parties would need to contact the authors directly, as these are not publicly available through the publication.",
  "model/interpretability": "The model developed in this work leverages transformer-based self-attention networks, which inherently offer a degree of interpretability. Unlike traditional black-box models, transformers are composed almost entirely of attention mechanisms. This design allows for enhanced transparency, as attention scores can be analyzed to understand how the model represents specific inputs.\n\nThe attention mechanisms in transformers compute alignment or similarity scores between vectorized representations of input elements, such as image patches or substrings. This process enables the model to capture context that is crucial for the task at hand. By examining the attention scores, one can gain insights into which elements of the input data the model focuses on to make predictions. This post-hoc analysis provides human-interpretable explanations, making it easier for pathologists and clinicians to understand the model's decisions.\n\nFor instance, in the context of whole slide imaging (WSI), the model can highlight specific glomeruli or regions within the slide that significantly influence the prediction of end-stage renal disease (ESRD). This level of interpretability is particularly valuable in medical applications, where understanding the rationale behind predictions is essential for building trust and facilitating patient-centered decision-making.\n\nMoreover, the use of positional encodings in self-attention networks allows for the representation of variable-length sets of input elements. This flexibility, combined with the ability to parallelize the processing of these elements, makes transformers highly scalable and efficient. The model's architecture, which includes convolutional neural networks for segmentation and expert-defined morphological features, further enhances its interpretability by integrating domain knowledge with data-driven contextualization.\n\nIn summary, the transformer-based model presented in this work is not a black-box but rather a transparent system. The attention mechanisms and positional encodings provide clear examples of how the model processes and interprets input data, offering valuable insights for medical professionals.",
  "model/output": "The model is designed for classification, specifically to predict the presence of end-stage renal disease (ESRD) two years after an initial biopsy. The primary output of the model is a binary classification indicating whether a patient will develop ESRD within the specified timeframe. The performance of the model is evaluated using several metrics, including the area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), accuracy, sensitivity, and specificity. These metrics provide a comprehensive assessment of the model's ability to correctly classify patients as either developing ESRD or not.\n\nThe model employs a multi-stage pipeline that integrates various components, including convolutional neural networks for glomeruli segmentation, expert-defined histological features, and a transformer-based self-attention network with a novel pairwise distance embedding. This approach allows the model to aggregate variable-length sets of extracted glomeruli features into a fixed-dimensional whole slide image (WSI) context, which is then used for prediction.\n\nThe transformer network, in particular, utilizes spatial pairwise distance embeddings based on Euclidean distances between glomeruli centroids. This spatial awareness significantly enhances the model's performance, as evidenced by the higher AUROC and other metrics when spatial information is included. The model's architecture includes 8 layers with 8 attention heads per layer, and all hidden layers use 64 hidden units with Gaussian Error Linear Unit (GELU) activations.\n\nIn addition to the transformer network, the study also compares the performance of other baseline models, such as XGBoost and logistic regression. These models use a tabular dataset created by averaging histological features and are evaluated using the same metrics. The results demonstrate that the transformer network with spatial embeddings outperforms these baseline models, highlighting the importance of spatial information in predicting ESRD.\n\nThe model's training process involves leave-one-out cross-validation to mitigate overfitting and accurately estimate generalizability. This process ensures that each patient's data is used once as a test sample, while the remaining data is used for training. The model is trained using an Adam optimizer with a default learning rate of 0.01, weight decay of 0.0001, and a batch size of 12 patients. Training is halted if the validation loss does not decrease after 20 epochs, and a learning rate scheduler is used to adjust the learning rate if the validation loss does not improve after 10 epochs.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our method focused on predicting the presence of end-stage renal disease (ESRD) two years after an initial biopsy, using only imaging features and centroid distances from each patient\u2019s whole slide images (WSIs). To ensure robust and generalizable results, we employed leave-one-out cross-validation. This approach involved training 56 different models, each time using 55 WSIs for training and the remaining one WSI for testing. This process was repeated until predictions were generated for all 56 patients.\n\nDuring each iteration, features were normalized, a separate denoising autoencoder (DAE) was trained, and a separate transformer prediction network was trained using only the 55 training samples. This method helped mitigate overfitting challenges due to our relatively small sample size.\n\nAll models were evaluated based on several metrics: area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), accuracy, sensitivity, and specificity. For each metric, 95% confidence intervals were generated using a bootstrapping procedure with 100 iterations. This comprehensive evaluation ensured that our results were statistically sound and reliable.\n\nAdditionally, we compared our multi-stage transformer network to several baseline approaches, including a previously established recurrent neural network (RNN) architecture, XGBoost, and logistic regression models. These baseline models used a tabular dataset created by averaging all 316 histological features. The comparison provided a benchmark to assess the performance of our transformer network, highlighting its strengths and areas for improvement.",
  "evaluation/measure": "In our study, we evaluated the performance of various models using a comprehensive set of metrics to ensure a thorough assessment of their predictive capabilities. The primary metrics reported include the area under the receiver operating characteristic curve (AUROC), the area under the precision-recall curve (AUPRC), accuracy, sensitivity, and specificity. These metrics were chosen to provide a well-rounded evaluation of the models' performance in predicting end-stage renal disease (ESRD) two years after initial biopsy.\n\nThe AUROC measures the ability of the model to distinguish between positive and negative classes across all threshold levels, providing a single scalar value that summarizes the trade-off between the true positive rate and the false positive rate. The AUPRC, on the other hand, focuses on the performance of the model in terms of precision and recall, which is particularly useful in imbalanced datasets where the positive class is rare.\n\nAccuracy provides an overall measure of the model's correctness, indicating the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall or true positive rate, measures the model's ability to correctly identify positive cases. Specificity, or the true negative rate, assesses the model's ability to correctly identify negative cases.\n\nThese metrics are widely used in the literature for evaluating predictive models, especially in medical and biological research. They offer a comprehensive view of model performance, covering different aspects of classification accuracy and robustness. By reporting these metrics, we aim to provide a clear and representative evaluation of our models' performance, allowing for comparisons with other studies in the field.",
  "evaluation/comparison": "In our evaluation, we compared our multi-stage transformer network to several baseline approaches to assess its performance in predicting the presence of ESRD two years after initial biopsy using only imaging features and centroid distances from each patient\u2019s WSI. We did not use publicly available benchmark datasets for this comparison.\n\nWe experimented with various baseline models, including a previously established RNN architecture from our prior work on predicting RPS classification of diabetic nephropathy. Additionally, we tested XGBoost and logistic regression baseline models using a tabular dataset created by averaging all 316 histological features.\n\nThe transformer network with no regularization, DAE-encoded features, and spatial pairwise distance embedding demonstrated the highest accuracy, achieving an AUROC of 0.97, AUPRC of 0.85, accuracy of 0.96, sensitivity of 1.00, and specificity of 0.95. In contrast, a similar transformer model without spatial awareness performed measurably worse across most metrics. The XGBoost baseline classifier performed reasonably well, yielding an AUROC of 0.81, AUPRC of 0.65, accuracy of 0.80, sensitivity of 0.62, and specificity of 0.88. Logistic regression, however, performed poorly and was not able to learn from the extracted features.\n\nThese comparisons highlight the effectiveness of our multi-stage transformer network in leveraging spatial histological interactions for accurate ESRD prediction.",
  "evaluation/confidence": "The evaluation of our models included several performance metrics, each accompanied by 95% confidence intervals to provide a measure of uncertainty. These metrics included the area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), accuracy, sensitivity, and specificity. The confidence intervals were generated using a bootstrapping procedure with 100 iterations, ensuring that the reported performance metrics are robust and reliable.\n\nTo assess the statistical significance of our results, we employed leave-one-out cross-validation. This method involves training 56 different models, each time using 55 whole slide images (WSIs) for training and the remaining one WSI for testing. This process was repeated for each WSI in the dataset, ensuring that every WSI was used as the test sample exactly once. This approach helps to mitigate overfitting and provides a more accurate estimate of the models' generalizability.\n\nThe results indicate that our multi-stage transformer network, particularly the version with no regularization, DAE-encoded features, and spatial pairwise distance embedding, outperformed other models and baselines. For instance, this model achieved an AUROC of 0.97 (95% CI: 0.90\u20131.00), which is significantly higher than the AUROC of 0.86 (95% CI: 0.66\u20130.99) achieved by a similar transformer model without spatial awareness. The confidence intervals do not overlap, suggesting that the difference in performance is statistically significant.\n\nSimilarly, the AUPRC, accuracy, sensitivity, and specificity of our top-performing model were also superior to those of the baselines, with non-overlapping confidence intervals in many cases. This provides strong evidence that our method is indeed superior to the other approaches evaluated.\n\nIn summary, the performance metrics include confidence intervals, and the results are statistically significant, supporting the claim that our method is superior to the baselines and other models evaluated.",
  "evaluation/availability": "Not enough information is available."
}