{
  "publication/title": "Deep Learning-Assisted Quantitative Susceptibility Mapping as a Tool for Grading and Molecular Subtyping of Gliomas",
  "publication/authors": "The authors who contributed to this article are:\n\n- Wenting Rui\n- Shengjie Zhang\n- Huidong Shi\n- Yaru Sheng\n- Fengping Zhu\n- YiDi Yao\n- Xiang Chen\n- Haixia Cheng\n- Yong Zhang\n- Ababikere Aili\n- Zhenwei Yao\n- Xiao-Yong Zhang\n- Yan Ren\n\nThe contributions of the authors to the paper are as follows:\n\n- Study concept and design: Wenting Rui, Shengjie Zhang, Huidong Shi, Xiao-Yong Zhang, and Yan Ren.\n- Data acquisition and analysis: Wenting Rui, Shengjie Zhang, Huidong Shi, Yaru Sheng, Fengping Zhu, YiDi Yao, Xiang Chen, Haixia Cheng, Yong Zhang, and Ababikere Aili.\n- Manuscript drafting: Wenting Rui and Shengjie Zhang.\n- Critical revision of the manuscript for important intellectual content: Zhenwei Yao, Xiao-Yong Zhang, Yan Ren, and Huidong Shi.",
  "publication/journal": "Magn Reson Imaging",
  "publication/year": "2022",
  "publication/pmid": "37325712",
  "publication/pmcid": "PMC10260708",
  "publication/doi": "https://doi.org/10.1007/s00401-015-1424-1",
  "publication/tags": "- Glioma\n- Magnetic Resonance Imaging (MRI)\n- Quantitative Susceptibility Mapping (QSM)\n- Deep Learning\n- Inception Convolutional Neural Network (CNN)\n- Glioma Grading\n- Molecular Subtyping\n- IDH1 Status\n- ATRX Status\n- Multi-modal MRI",
  "dataset/provenance": "The dataset used in this study was sourced from patients with clinically suspected gliomas who underwent a unified preoperative MR examination protocol. The study initially included 51 patients, but after excluding nine due to various reasons such as uncommon pathological diagnoses, image artifacts, and errors in QSM image processing, a total of 42 patients were enrolled. These patients were 18 female and 24 male, with a mean age of 47 years, ranging from 26 to 75 years.\n\nThe data used in this study included preoperative MR images, specifically QSM, T2 FLAIR, and T1WI + C sequences. These images were acquired using a 3.0T MRI system with an eight-channel phased-array head coil. The study designed three stratified detection tasks: detecting glioma grades, identifying gliomas with IDH1(+) or IDH1(\u2212), and detecting IDH1 mutated gliomas with ATRX(\u2212) or ATRX retention.\n\nThe dataset was analyzed using a deep learning approach, specifically an inception convolutional neural network (CNN), to explore the potential of DL-assisted QSM in glioma grading and molecular subtyping. The performance of the deep learning model was evaluated using various metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and F1-score. The results indicated that the combination of multi-modal MRI data, including QSM, T2 FLAIR, and T1WI + C, provided the best performance for the detection tasks.\n\nThe study also acknowledged some limitations, such as the small sample size and the underrepresentation of certain patient groups. Future studies plan to include multi-center QSM and perfusion MRI data to predict the molecular subtypes of other grade gliomas (OGG) and glioblastoma multiforme (GBM).",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "To address dataset redundancy, we implemented several strategies to ensure the independence and robustness of our training, validation, and test datasets. We conducted intensity normalization across each individual modality to avoid potential data gaps between the datasets. This step was crucial for maintaining consistency in the data distribution.\n\nWe employed fivefold cross-validation to alleviate the influence of dataset split bias. This method involves dividing the dataset into five subsets, where each subset is used once as the test set while the remaining four subsets are used for training. This process is repeated five times, ensuring that each data point is used for both training and testing, thereby enhancing the generalizability of our model.\n\nTo further minimize the impact of background noise, MRI slices were center cropped. Additionally, a binary mask was applied over specific slices, which served as a weak annotation to guide the classification task. This binary mask was concatenated in the channel dimension to provide additional guidance during the training process.\n\nFor multi-modality data, image slices from different modalities (e.g., T1WI + C, T2 FLAIR, QSM) were concatenated in the channel dimension. This approach allowed the model to leverage information from multiple sources, enhancing its ability to capture relevant features.\n\nThe distribution of our datasets compares favorably to previously published machine learning datasets in the field of glioma classification. By ensuring that the training and test sets are independent and by using cross-validation, we have mitigated the risk of overfitting and improved the reliability of our results. This rigorous approach to dataset management is essential for developing robust and generalizable machine learning models in medical imaging.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is deep learning, specifically convolutional neural networks (CNNs). The primary architecture employed is an inception CNN, which is designed to automatically extract efficient features from MRI slices for glioma classification. This architecture includes inception modules that capture potential biomarkers and enhance representation ability through multiple inception layers, followed by global average pooling and linear layers.\n\nThe inception CNN used in this study is not entirely new but has been adapted for the specific task of glioma classification. The inception module and pyramid module are known for their benefits in multi-scale feature extraction, which is crucial in medical image classification due to the small and discrete nature of regions of interest (ROIs). The adaptation includes the use of a consistency loss computed by the output of adjacent slices, inspired by semi-supervised learning strategies. This approach aims to mitigate overfitting problems that can arise from small sample sizes.\n\nThe reason this adapted algorithm was not published in a machine-learning journal is likely due to the focus of this study on its application in medical imaging, particularly in the context of glioma grading and molecular subtyping. The research emphasizes the integration of deep learning with quantitative susceptibility mapping (QSM) to improve diagnostic accuracy and feature extraction in medical imaging tasks. The study's contributions are more aligned with advancements in medical imaging and oncology rather than purely machine-learning innovations. Therefore, it was published in a journal that focuses on these interdisciplinary applications.",
  "optimization/meta": "The model employs a meta-predictor approach, integrating outputs from multiple machine-learning algorithms to enhance predictive performance. Specifically, the meta-predictor combines the results from an inception convolutional neural network (CNN), a standard CNN, a support vector machine (SVM), and a generalized linear model (GLM). These algorithms are used to compare and validate the effectiveness of the proposed inception CNN in three-modality fusion classification tasks.\n\nThe training data for these algorithms is split into folds, ensuring that each fold is the same across different models. This consistency in data splitting helps maintain independence and reduces the risk of data leakage, which is crucial for reliable model evaluation. The deep learning methods, including the inception CNN and standard CNN, are trained through loss backpropagation. The performance of these models is evaluated using metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and F1 score, computed from the confusion matrix. Additionally, receiver operating characteristic (ROC) curves and the area under the curve (AUC) are used to assess the discriminative ability of the models in the test dataset.",
  "optimization/encoding": "To prepare the data for the machine-learning algorithm, several preprocessing steps were undertaken. Intensity normalization was performed across each individual modality to avoid potential data gaps between the training, validation, and test datasets. This step ensures that the data from different sources is comparable.\n\nMRI slices were then center cropped to minimize the impact of background noise, focusing the analysis on the relevant regions. A binary mask was applied over specific slices, serving as a weak annotation to guide the classification task. This binary mask was concatenated in the channel dimension to provide additional guidance during the training process.\n\nThe proposed inception convolutional neural network (CNN) features two paths: one for annotated MRI slices and another for unlabeled data. For each path, three inception layers were employed to enhance the representation ability of the features extracted from the MRI slices. These layers are followed by a global average pooling layer and a linear layer, which help in capturing potential biomarkers for glioma classification.\n\nFor multi-modality data, image slices from different modalities (e.g., T1WI + C, T2 FLAIR, QSM) were concatenated in the channel dimension. This approach allows the model to leverage information from multiple sources simultaneously, improving the overall performance and robustness of the classification task.\n\nTo mitigate the influence of dataset split bias, fivefold cross-validation was used. The ratio of training, validation, and test datasets was set to 4:1:1, ensuring a balanced and comprehensive evaluation of the model's performance. This method helps in assessing the model's generalizability and reliability across different subsets of the data.",
  "optimization/parameters": "In our study, the deep learning model utilized an inception convolutional neural network (CNN) architecture, which is known for its ability to handle multi-scale features effectively. The model was designed to process three MRI modalities: T2 FLAIR, T1WI + C, and Quantitative Susceptibility Mapping (QSM). Each modality was concatenated in the channel dimension, allowing the model to leverage information from multiple sources simultaneously.\n\nThe inception CNN consisted of two main paths: a labeled path for annotated MRI slices and a label-free path for unlabeled data. Each path included three inception layers, followed by a global average pooling layer and a linear layer. The inception layers were crucial for capturing potential biomarkers for glioma classification by enhancing the representation ability of the model.\n\nThe selection of parameters in the model was guided by the need to balance complexity and performance. The inception layers, in particular, were chosen for their efficiency in extracting features at multiple scales, which is essential for the accurate classification of glioma grades and molecular subtypes. The use of fivefold cross-validation ensured that the model's performance was robust and not dependent on a specific dataset split.\n\nIn summary, the model's parameters were carefully selected to optimize its performance in glioma classification tasks. The inception CNN architecture, with its multi-scale feature extraction capabilities, played a significant role in achieving high accuracy and reliability in the results.",
  "optimization/features": "The input features for the proposed model consist of MRI slices from multiple modalities, specifically T1-weighted imaging with contrast (T1WI + C), T2 Fluid-Attenuated Inversion Recovery (T2 FLAIR), and Quantitative Susceptibility Mapping (QSM). These modalities are concatenated in the channel dimension, allowing the model to leverage multi-modal information.\n\nFor each MRI slice, intensity normalization is performed to avoid data gaps between the training, validation, and test datasets. Additionally, center cropping is applied to minimize the impact of background noise. A binary mask is used over specific slices, which serves as a weak annotation to guide the classification task. This binary mask is concatenated in the channel dimension to provide additional guidance during training.\n\nThe model employs an inception convolutional neural network (CNN) architecture, which includes two paths: one for annotated MRI slices and another for unlabeled data. Each path utilizes three inception layers to enhance the representation ability, followed by a global average pooling layer and a linear layer. This design allows the model to automatically extract efficient features from the MRI slices, capturing potential biomarkers for glioma classification.\n\nFeature selection is not explicitly mentioned as a separate step in the process. Instead, the model relies on the inception layers to selectively extract relevant features from the input MRI slices. The use of multi-modal data and the inception architecture inherently performs a form of feature selection by focusing on the most informative aspects of the input data.\n\nThe dataset is split using fivefold cross-validation, with a 4:1:1 ratio for training, validation, and test sets, respectively. This ensures that the model's performance is evaluated across different subsets of the data, reducing the risk of overfitting and providing a more robust assessment of its generalization capabilities.",
  "optimization/fitting": "In our study, we employed a deep learning approach using an inception convolutional neural network (CNN) for glioma classification. The model's architecture includes multiple inception layers, which are designed to capture multi-scale features from MRI slices. This design inherently involves a large number of parameters, potentially much larger than the number of training points, especially when dealing with medical imaging data which can be high-dimensional.\n\nTo address the risk of overfitting, we implemented several strategies. Firstly, we used intensity normalization across each modality to ensure consistency in the data. Additionally, we employed center cropping of MRI slices to minimize the impact of background noise. A binary mask was used as a weak annotation to guide the classification task, which was concatenated in the channel dimension. This mask helped in focusing the model's attention on the relevant regions of the MRI slices.\n\nWe also utilized a semi-supervised learning strategy with a consistency loss computed from the outputs of adjacent slices. This approach encouraged the model to produce similar outputs for nearby slices, thereby enhancing its robustness and generalizability. Furthermore, we employed fivefold cross-validation to alleviate the influence of dataset split bias, ensuring that the model's performance was evaluated across different subsets of the data.\n\nTo rule out underfitting, we ensured that the model had sufficient capacity to learn the complex patterns in the data. The use of inception modules allowed the model to extract features at multiple scales, which is crucial for medical image classification where the region of interest may be small and discrete. Additionally, the concatenation of multi-modality data (e.g., T1WI + C, T2 FLAIR, QSM) provided a richer feature set for the model to learn from, enhancing its representational ability.\n\nOverall, these strategies helped in balancing the model's complexity and ensuring that it neither overfitted nor underfitted the data, leading to robust and reliable performance in glioma classification tasks.",
  "optimization/regularization": "To prevent overfitting, several techniques were employed in our study. Firstly, intensity normalization was conducted across each individual modality to avoid potential data gaps between the training, validation, and test datasets. This step helps in standardizing the input data, making the model more robust and less likely to overfit to the specific intensity distributions of the training data.\n\nAdditionally, center cropping of MRI slices was performed to minimize the impact of background noise, focusing the model's attention on the relevant regions of the images. This technique helps in reducing the amount of irrelevant information that the model might otherwise learn, thereby improving its generalization ability.\n\nA binary mask was used as a weak annotation to guide the classification task. This mask was concatenated in the channel dimension, providing additional supervision without requiring extensive manual labeling. This approach leverages the available labeled data more effectively and helps in regularizing the model.\n\nThe proposed inception convolutional neural network (CNN) architecture includes two paths: one for annotated MRI slices and another for unlabeled data. This semi-supervised learning strategy helps in utilizing both labeled and unlabeled data, enhancing the model's ability to generalize from limited annotated samples.\n\nFor each path in the inception CNN, three inception layers were employed to enhance the representation ability. These layers are designed to capture multi-scale features, which are crucial for medical image classification tasks where the region of interest may be small and discrete. Following the inception layers, a global average pooling layer and a linear layer were used to further regularize the model and reduce the risk of overfitting.\n\nTo alleviate the influence of dataset split bias, fivefold cross-validation was leveraged. This technique ensures that the model's performance is evaluated across different subsets of the data, providing a more reliable estimate of its generalization ability. The ratio of training, validation, and test datasets was carefully considered to ensure a balanced and representative evaluation.\n\nIn summary, a combination of data normalization, center cropping, weak annotation, semi-supervised learning, and cross-validation was used to prevent overfitting and improve the model's generalization performance.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in our study is not entirely a black box. To enhance interpretability, we utilized Shapley value analysis and t-distributed stochastic neighbor embedding (t-SNE) to visualize the feature distribution of different MRI modalities and their contributions to the model output. Shapley values provide a way to understand the impact of each modality on the classification tasks, making the model more transparent. The spread of these values reflects the corresponding impacts on the model output for various classification tasks, such as differentiating other grade glioma (OGG) from glioblastoma multiforme (GBM), low-grade glioma (LGG) from high-grade glioma (HGG), and predicting molecular subtypes like IDH1 mutation status and ATRX expression loss. This approach allows us to identify which modalities are most influential in the decision-making process of the model. Additionally, t-SNE plots help in visualizing how well the features extracted by the inception network can identify and separate different classes, further aiding in the interpretability of the model.",
  "model/output": "The model is designed for classification tasks. Specifically, it focuses on classifying glioma grades and molecular subtypes using deep learning techniques. The classification tasks include differentiating between other grade glioma (OGG) and glioblastoma multiforme (GBM), low-grade glioma (LGG) and high-grade glioma (HGG), IDH1 mutation status, and ATRX expression loss. The model employs an inception convolutional neural network (CNN) to extract features from MRI modalities such as T2 FLAIR, T1-weighted imaging with contrast (T1WI + C), and quantitative susceptibility mapping (QSM). The performance of the model is evaluated using metrics such as accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and F1 score. The results indicate that the QSM modality, in particular, shows strong diagnostic accuracy and F1 scores in various classification tasks, highlighting its importance in glioma classification. The model's output is visualized using t-distributed stochastic neighbor embedding (t-SNE) and Shapley value analysis to illustrate the feature distribution and contribution of each modality to the model's predictions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method involved several key steps to ensure robustness and reliability. To mitigate dataset split bias, a fivefold cross-validation strategy was employed. This approach divides the dataset into five parts, using four parts for training and one part for validation, repeating this process five times with different partitions. The ratio of training, validation, and test datasets was set at 4:1:1.\n\nFor the classification tasks, specific labels were assigned to different glioma grades and molecular subtypes. For grading, the true labels were denoted as 1, 2, and 3, corresponding to grade II, III, and IV, respectively. For predicting IDH1 mutation, the labels were divided into two classes: positive (+) and negative (\u2212). Similarly, for predicting ATRX loss, the labels were \u2212 and +.\n\nThe performance of the models was evaluated using several metrics, including total prediction accuracy, sensitivity (recall), specificity, positive predictive value (PPV) or precision, negative predictive value (NPV), and F1 score. The F1 score is defined as the harmonic mean of sensitivity and PPV. Additionally, a receiver operating characteristic (ROC) curve was drawn, and the area under the curve (AUC) was calculated to assess the discriminative ability of the model in the test dataset.\n\nTo visualize the feature distribution of different modalities and their contribution to the model output, t-distributed stochastic neighbor embedding (t-SNE) and Shapley value analysis were used. The t-SNE plots helped in understanding how well the features extracted by the inception network could identify different glioma types. Shapley values provided insights into the impact of each modality on the model's output for various classification tasks.\n\nThe deep learning methods, including the inception convolutional neural network (CNN) and standard CNN, were trained through loss backpropagation. The performance of the proposed inception CNN was compared with other algorithms such as support vector machine (SVM), standard CNN (three-layer), and generalized linear model (GLM) in three-modality fusion classification tasks. This comprehensive evaluation ensured that the proposed method was thoroughly tested and validated.",
  "evaluation/measure": "In our study, we evaluated the performance of our deep learning model using a comprehensive set of metrics to ensure a thorough assessment of its capabilities in glioma grading and molecular subtyping. The primary metrics reported include accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and F1-score. These metrics were chosen because they provide a well-rounded view of the model's performance, covering aspects such as the overall correctness, the ability to identify positive cases, the ability to identify negative cases, and the balance between precision and recall.\n\nAccuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall, indicates the model's ability to correctly identify positive cases. Specificity measures the model's ability to correctly identify negative cases. PPV, or precision, is the proportion of true positives among all positive results. NPV is the proportion of true negatives among all negative results. The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in medical imaging, making our set of metrics representative and comparable to other studies in the field. Additionally, we used the area under the receiver operating characteristic curve (AUC-ROC) to assess the discriminative ability of the model. The AUC-ROC provides a single scalar value that summarizes the model's performance across all classification thresholds, offering a comprehensive view of its diagnostic capability.\n\nIn summary, the reported metrics are standard and representative in the field of medical imaging and classification tasks. They provide a detailed and balanced evaluation of the model's performance, ensuring that our findings are robust and comparable to other studies.",
  "evaluation/comparison": "To evaluate the effectiveness of the proposed inception convolutional neural network (CNN) for glioma classification, several comparisons were conducted with other machine learning and deep learning methods. These comparisons included support vector machine (SVM), standard CNN (three-layer), and generalized linear model (GLM). The evaluation was performed on three-modality fusion classification tasks, which involved combining different MRI modalities such as T2 FLAIR, T1WI + C, and QSM.\n\nThe performance metrics used for comparison included accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and F1 score. These metrics were computed using a confusion matrix, and the results were presented as mean values with standard deviations. Additionally, receiver operating characteristic (ROC) curves were drawn, and the area under the curve (AUC) was calculated to assess the discriminative ability of the models in the test dataset.\n\nThe comparisons were conducted using fivefold cross-validation to ensure robustness and to mitigate the influence of dataset split bias. This approach involved splitting the dataset into five parts, where four parts were used for training and one part for validation, repeating this process five times with different splits. The final performance metrics were averaged across the five folds.\n\nThe results of these comparisons demonstrated the superior performance of the proposed inception CNN in various glioma classification tasks. For instance, the inception CNN achieved higher accuracy and F1 scores compared to the other methods in differentiating between different glioma grades and molecular subtypes. This indicates that the inception CNN is more effective in capturing relevant features from the MRI modalities for glioma classification.\n\nIn summary, the evaluation involved a comprehensive comparison with publicly available methods and simpler baselines, ensuring that the proposed inception CNN's performance was rigorously assessed. The use of fivefold cross-validation and detailed performance metrics provided a thorough evaluation of the model's effectiveness in glioma classification tasks.",
  "evaluation/confidence": "The performance metrics presented in the study include confidence intervals, which are indicated by the mean \u00b1 standard deviation format. This format provides a measure of the variability and reliability of the results.\n\nThe study employs a fivefold cross-validation approach, which helps to ensure that the results are statistically significant and not due to random chance. This method involves dividing the dataset into five parts, training the model on four parts, and testing it on the remaining part. This process is repeated five times, with each part serving as the test set once. The performance metrics are then averaged across the five folds, providing a more robust estimate of the model's performance.\n\nAdditionally, the study compares the proposed method with several baseline algorithms, including support vector machine (SVM), standard convolutional neural network (CNN), and generalized linear model (GLM). The results demonstrate that the proposed method outperforms these baselines across various tasks, such as differentiating other grade glioma (OGG) from glioblastoma multiforme (GBM), low-grade glioma (LGG) from high-grade glioma (HGG), and predicting IDH1 mutation and ATRX expression loss.\n\nThe receiver operating characteristic (ROC) curves and the area under the curve (AUC) further support the superior performance of the proposed method. The mean AUC values for different tasks are provided, indicating the model's discriminative ability.\n\nOverall, the inclusion of confidence intervals, the use of fivefold cross-validation, and the comparison with baseline algorithms provide a strong basis for claiming that the proposed method is superior and statistically significant.",
  "evaluation/availability": "The raw evaluation files for our study are not publicly available. The data used in this research includes sensitive medical information and is subject to strict privacy regulations. Therefore, we have not released the raw evaluation files to the public. However, we have provided detailed performance metrics and methodology in our publication to ensure reproducibility and transparency. For specific inquiries or collaborations, interested parties can contact the corresponding authors. The publication is governed by the terms of the publishing agreement with Springer Nature, which outlines the rights and permissions for sharing and using the content."
}