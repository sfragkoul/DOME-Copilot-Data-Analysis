{
  "publication/title": "Machine Learning in HIV",
  "publication/authors": "The authors who contributed to the article are:\n\n- J. A. Roth\n- J. B\u00f6ni\n- M. Battegay\n- C. Marzolini\n- A. Rauch\n- H. F. G\u00fcnthard\n- R. D. Kouyos\n- C. A. Fux\n\nAll of these authors developed the study protocol and drafted the manuscript. Additionally, all authors critically reviewed the study protocol. G. R. and J. B\u00f6ni analyzed the data with input from J. A. Roth. All authors critically reviewed the manuscript and contributed to the design of the study. They also approved the final version of the manuscript.",
  "publication/journal": "The Journal of Infectious Diseases",
  "publication/year": "2021",
  "publication/pmid": "32386061",
  "publication/pmcid": "PMC8514185",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Machine Learning\n- Chronic Kidney Disease\n- HIV\n- Predictive Modeling\n- Data-Driven Approaches\n- Recurrent Neural Networks\n- Logistic Regression\n- Gradient Boosting\n- Epidemiological Cohorts\n- Personalized Medicine",
  "dataset/provenance": "The dataset used in this study was extracted from the Swiss HIV Cohort Study (SHCS) main database. This database comprises a vast collection of static and time-changing (dynamic) variables, which were often irregularly measured as part of the clinical routine.\n\nThe study initially considered 20,343 patients in the SHCS until October 10, 2018. However, several exclusion criteria were applied:\n\n* Patients with less than 3 creatinine measurements after January 1, 2002 (7,255 patients)\n* Patients with a baseline estimated glomerular filtration rate (eGFR) of 60 mL/min/1.73 m\u00b2 or less (299 patients)\n* Patients aged less than 18 years at baseline (19 patients)\n* Patients with less than 3 months of follow-up (9 patients)\n\nAfter applying these exclusions, 12,761 patients were included in the final analysis. This dataset was then split into three subsets for model training, validation, and testing:\n\n* Training set: 80% of the data (10,209 patients)\n* Validation set: 10% of the data (1,276 patients)\n* Test set: 10% of the data (1,276 patients)\n\nThe dataset includes a wide range of variables, totaling 64 static and 502 dynamic variables. These variables encompass various aspects such as demographic information, treatment details, laboratory results, and clinical data. The dynamic variables were measured irregularly, reflecting real-world clinical practice.\n\nThe dataset has been used to develop and evaluate machine learning models for predicting chronic kidney disease (CKD) in people living with HIV. The models were trained on the training set, validated on the validation set, and tested on the test set to ensure robust and generalizable performance. The study aims to leverage this comprehensive dataset to improve CKD prediction and potentially inform clinical decision-making.",
  "dataset/splits": "The dataset was divided into three distinct splits for the purpose of training, validating, and testing the machine learning models. The first split, designated as the training set, comprised 80% of the total data, amounting to 10,209 data points. This subset was used to train the models, allowing them to learn patterns and relationships within the data.\n\nThe second split, the validation set, constituted 10% of the dataset, totaling 1,276 data points. This subset was employed to tune the hyperparameters of the models and to perform model selection, ensuring that the models generalized well to unseen data.\n\nThe third split, the test set, also made up 10% of the dataset, with 1,276 data points. This subset was used to evaluate the final performance of the models, providing an unbiased assessment of their predictive accuracy.\n\nThe sampling process for the validation and test sets was conducted randomly without replacement and was stratified based on follow-up length and chronic kidney disease (CKD) status. This stratification ensured that both sets included a representative distribution of individuals who developed CKD and those who did not, maintaining the integrity of the model evaluation process.",
  "dataset/redundancy": "The datasets were split into three subsets: a training set, a validation set, and a test set. The validation and test sets were created by randomly sampling 10% of the study population without replacement. This sampling was stratified with respect to the follow-up length and CKD status. This means that 10% of individuals were first randomly sampled from the group that developed CKD, and then 10% were sampled from the group that did not develop CKD. The remaining 80% of the individuals comprised the training set.\n\nThe training and test sets are independent. This independence was enforced through the stratified sampling process, ensuring that the test set contained data that was not used during the training or validation phases. This approach helps to evaluate the model's performance on unseen data, providing a more reliable assessment of its predictive accuracy.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in terms of ensuring independence between training and test sets. The stratified sampling method helps to maintain a balanced representation of both CKD and non-CKD cases across the different subsets, which is crucial for developing robust predictive models. This method ensures that the model's performance can be generalized to new, unseen data, which is a key goal in machine learning research.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine learning algorithms used in this study are well-established and include a variety of approaches. These algorithms are not new and have been extensively used and validated in the field of machine learning. The algorithms employed are:\n\n* Multilayer perceptron, a type of feed-forward neural network with at least three fully connected layers.\n* Recurrent neural networks (RNNs), specifically the long short-term memory (LSTM) architecture, which is designed to handle sequential data.\n* Elastic net, a regularized linear logistic regression method that combines both L1 and L2 penalties.\n* Random forest models, which aggregate multiple decision trees to improve predictive accuracy and control over-fitting.\n* Gradient boosting machine, an ensemble method that builds models sequentially, each trying to correct the errors of the previous one.\n\nThese algorithms were chosen for their ability to handle different types of data and their proven effectiveness in predictive modeling tasks. The study focuses on applying these algorithms to predict chronic kidney disease (CKD) in individuals living with HIV, rather than introducing new machine learning algorithms. Therefore, the algorithms were not published in a machine-learning journal because the primary contribution of the study is in the application of these algorithms to a specific medical prediction problem, rather than the development of new algorithms.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "For the machine learning models, the data was extracted from the Swiss HIV Cohort Study main database, comprising both static and dynamic variables. The dynamic variables were often measured irregularly as part of the clinical routine. To handle this, the input information for each individual was a concatenation of the information from the two most recent hospital visits and the corresponding summary statistics (mean, median, maximum, standard deviation) from all previous visits. This approach allowed the models to capture both recent trends and long-term patterns in the data.\n\nFor the recurrent neural network-based methods, the visit sequence was used directly, as these models can process sequences of inputs. For the other machine learning methods, the visit sequence for each patient was derived from the considered observation period determined by the target prediction horizon. The last (most recent) visits referred to these derived sequences.\n\nMissing values were handled using zero imputation and median forward imputation strategies. Zero imputation was used for some models, while median forward imputation was used for others. The choice of imputation strategy depended on the specific model and the nature of the missing data.\n\nThe data was split into three subsets: a training set, a validation set, and a test set. The validation and test sets were created by randomly sampling 10% of the study population, stratified by follow-up length and CKD status. The remaining 80% of the individuals comprised the training set. This split ensured that the models were trained and evaluated on representative samples of the data.\n\nThe preparation and structuring of the datasets for machine learning training was time-consuming, requiring approximately one month of full-time work. The model selection procedure, particularly for the recurrent neural network-based models, was computing-intensive and required a high-performance computing cluster. The final model training was fast for all machine learning methods except for the recurrent neural network-based methods, which required approximately 30 minutes. Obtaining individual predictions with a trained model was fast for all machine learning methods.",
  "optimization/parameters": "In our study, we utilized a comprehensive set of input parameters for our machine learning models. Specifically, we used 64 static and 502 dynamic variables for the development of our full models. These variables encompassed a wide range of data, including 28 demographic variables, 159 variables related to treatment information, 93 laboratory variables, and 286 clinical variables.\n\nThe selection of these parameters was driven by the need to capture a broad spectrum of factors that could influence the prediction of chronic kidney disease (CKD). The static variables provided a foundational set of characteristics that remained constant over time, while the dynamic variables allowed us to incorporate time-varying data that could reflect changes in a patient's health status.\n\nFor our manually built logistic regression models, we focused on a subset of well-established predictors. These included HIV exposure through intravenous drug use, hepatitis C coinfection, birth year, estimated glomerular filtration rate, sex, CD4 cell count, hypertension, prior cardiovascular disease, and diabetes mellitus. We used the two most recent measurements of these variables along with summary statistics of all their previous measurements to ensure that our models could capture both recent trends and historical patterns.\n\nThe choice of parameters was informed by a combination of domain knowledge and empirical evidence. We aimed to balance the need for comprehensive data with the practical considerations of model complexity and computational efficiency. The final set of parameters was validated through rigorous model evaluation processes, ensuring that they contributed meaningfully to the predictive performance of our models.",
  "optimization/features": "In our study, we utilized a comprehensive set of input features for our machine learning models. Specifically, we incorporated 64 static variables and 502 dynamic variables, resulting in a total of 566 features. These features encompassed a wide range of demographic, treatment, laboratory, and clinical variables.\n\nFeature selection was not explicitly performed as a separate step. Instead, we relied on the inherent feature selection capabilities of the machine learning algorithms themselves. For instance, models like gradient boosting and neural networks can automatically identify and weigh the importance of different features during the training process. This approach allowed us to leverage the full spectrum of available data without manually pruning the feature set.\n\nTo ensure the robustness of our feature selection process, we adhered strictly to using the training set for model development and hyperparameter tuning. The validation set was used exclusively for model selection and hyperparameter optimization, while the test set remained untouched until the final evaluation. This strategy helped to prevent data leakage and ensured that our models' performance on the test set was a true reflection of their generalizability to unseen data.",
  "optimization/fitting": "The study utilized a substantial dataset derived from the Swiss HIV Cohort Study, comprising 12,761 individuals for the final analysis. The dataset was split into a training set (80%), a validation set (10%), and a test set (10%). This division ensured that the model had a sufficiently large number of training points to learn from, while also having separate validation and test sets to evaluate performance and prevent overfitting.\n\nThe machine learning models employed included multilayer perceptrons, recurrent neural networks (RNNs), and logistic regression models. These models were chosen for their ability to handle complex, nonlinear relationships in the data. The RNNs, in particular, were well-suited for processing temporal sequence data, which is characteristic of the clinical measurements in the study.\n\nTo address the potential for overfitting, several strategies were implemented. First, the dataset was split into training, validation, and test sets, ensuring that the model's performance could be evaluated on unseen data. Second, hyperparameter tuning was performed on the validation set, which helped in selecting the best-performing model configurations without directly optimizing on the test set. Additionally, the use of regularization techniques and dropout layers in the neural networks further mitigated overfitting.\n\nUnderfitting was addressed by ensuring that the models were complex enough to capture the underlying patterns in the data. The use of deep learning architectures, such as multilayer perceptrons and RNNs, provided the necessary capacity to learn from the data. Furthermore, the inclusion of a large number of features (64 static and 502 dynamic variables) ensured that the models had access to a rich set of information for making predictions.\n\nThe performance of the models was evaluated using multiple metrics, including the area under the receiver operating characteristic curve (ROC-AUC) and the area under the precision-recall curve (PR-AUC). These metrics provided a comprehensive assessment of the models' predictive performance, especially in the context of class imbalance, where most individuals did not develop chronic kidney disease (CKD).\n\nIn summary, the study employed a robust dataset and a variety of machine learning techniques to ensure that the models were neither overfitted nor underfitted. The use of separate validation and test sets, along with regularization techniques and comprehensive performance metrics, contributed to the reliability and generalizability of the results.",
  "optimization/regularization": "In our study, we employed regularization techniques to prevent overfitting, particularly in our elastic net models. Elastic net is a regularized, linear logistic regression method that combines both L1 (lasso) and L2 (ridge) penalties. This approach helps to shrink the coefficients of less important features, effectively performing both feature selection and regularization. By incorporating these penalties, we aimed to improve the generalization performance of our models on unseen data. This technique was crucial in managing the complexity of our dataset, which included a multitude of static and dynamic variables often measured irregularly.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not explicitly detailed in the main text. However, supplementary materials, such as Supplementary Appendix Table 3, provide additional details on the training algorithms used for specific models like recurrent neural networks. The optimization parameters and schedules are likely included in these supplementary materials, but the exact availability and licensing of these files are not specified.\n\nFor those interested in replicating the study or using the models, it would be advisable to refer to the supplementary materials or contact the authors for more detailed information on the hyper-parameter configurations and optimization parameters. The study emphasizes the use of a high-performance computing cluster for model training and selection, indicating that the process was computationally intensive. This suggests that the optimization parameters were carefully tuned to achieve the best performance.\n\nThe performance of various machine learning models is reported across different prediction horizons, with metrics such as F-score, precision, recall, ROC-AUC, and PR-AUC provided for each model. These metrics offer insights into the models' predictive capabilities and can guide further research or practical applications. The study also discusses the challenges faced during dataset preparation and model training, highlighting the complexity of working with real-world HIV cohort data.\n\nIn summary, while the main text does not provide exhaustive details on the hyper-parameter configurations and optimization parameters, supplementary materials and additional resources are likely available to support further inquiry. The study's focus on performance metrics and computational requirements underscores the rigor of the optimization process.",
  "model/interpretability": "The machine learning models developed for predicting chronic kidney disease (CKD) onset in individuals living with HIV are designed with interpretability in mind. While some machine learning algorithms, such as neural networks, can be considered black-box models due to their complexity, efforts have been made to enhance transparency.\n\nFor instance, the gradient boosting model provides variable importance scores, which indicate the significance of each predictor in the model's decisions. This allows for a clear understanding of which factors, such as estimated glomerular filtration rate (eGFR), are most influential in predicting CKD. Additionally, the output of these models includes predicted outcome probabilities and individual variable importance, which can be obtained for all applied machine learning algorithms. This information increases the interpretability and transparency of the models, making them more suitable for personalized prevention and treatment decisions.\n\nMoreover, the use of well-established metrics to measure the models' predictive power ensures comparability across different models and studies. This approach helps in understanding the performance and reliability of the models, further contributing to their transparency. The inclusion of a multitude of static and dynamic factors in the prediction models also enhances their interpretability, as it provides a comprehensive view of the variables influencing CKD prediction.",
  "model/output": "The models developed in this study are classification models. They are designed to predict the onset of chronic kidney disease (CKD) in individuals living with HIV. The primary output of these models is a binary classification indicating whether an individual is likely to develop CKD within a specified prediction horizon (90, 180, 270, or 365 days). The models use various machine learning algorithms, including multilayer perceptron, gradient boosting, random forest, elastic net, bidirectional recurrent neural networks, and bidirectional attention recurrent neural networks. These algorithms process input data, which includes static and dynamic variables from the individuals' medical records, to produce a probability score for CKD onset. The performance of these models is evaluated using metrics such as F-score, precision, recall, ROC-AUC, and PR-AUC, which measure the accuracy and reliability of the predictions. The models aim to provide individualized predictions to support clinical decision-making and improve patient outcomes.",
  "model/duration": "The execution time for our machine learning models varied significantly depending on the method used. The preparation and structuring of our datasets for machine learning training required approximately one month of full-time work. The model selection procedure for the recurrent neural network (RNN)-based approach was particularly computing-intensive, taking around 20 to 30 hours on a high-performance computing cluster. For other nonlinear approaches, the computing time for model selection was shorter, ranging from 1 to 2 hours each. The final model training was relatively fast for most methods, except for the RNN-based methods, which required about 30 minutes. Once the models were trained, obtaining individual predictions was quick, taking only a few minutes at most.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the machine learning models involved splitting the study data into three subsets: a training set, a validation set, and a test set. The validation and test sets were created by randomly sampling 10% of the study population, stratified by follow-up length and CKD status. This ensured that 10% of individuals who developed CKD and 10% who did not were included in each set. The remaining 80% of the individuals comprised the training set.\n\nEach machine learning method was applied to predict CKD events with adjusted hyperparameters to deliver accurate predictions on unseen data. The model selection and hyperparameter tuning process was performed on the validation set. Finally, the predictive performance of the best-performing model for each approach was evaluated on the test set.\n\nFour different evaluation scenarios were considered, each with a different prediction horizon: 90, 180, 270, and 365 days. The prediction horizon specifies how many days in advance the occurrence of CKD was aimed to be predicted, with the time of diagnosis determined by the second eGFR measurement of the CKD definition used.\n\nDue to the large CKD imbalance in the dataset, classification accuracy was not suitable for measuring the models' performance. Instead, five well-established measures for class imbalance scenarios were calculated: the F-score, precision, recall, area under the receiver operating characteristic curve (ROC-AUC), and area under the precision-recall curve (PR-AUC). These measures focus on the correct prediction of the minority class, which in this case is individuals with CKD onset.\n\nThe precision-recall curve plots recall versus precision for all possible decision thresholds. The F-score and PR-AUC reflect the model\u2019s prediction quality for CKD events. The receiver operating characteristic curve plots the false-positive rate against the true-positive rate for all possible decision thresholds. The ROC-AUC illustrates the ranking ability in binary classification, indicating the proportion of correctly classified predictions for pairs of individuals with and without the endpoint.\n\nFor model selection, the F-score was used for recurrent neural network-based approaches, while log loss was used for the remaining approaches. Due to the time-consuming nature of the model selection process, all experiments and relevant evaluation metrics were computed for one training, validation, and test split. The test set was considered fairly large, reflecting the predictive quality of the considered machine learning models.",
  "evaluation/measure": "In our study, we evaluated the performance of our models using a set of well-established metrics that are particularly suited for imbalanced datasets, such as ours, where the majority of individuals did not develop chronic kidney disease (CKD). We did not rely on classification accuracy due to the significant imbalance in our dataset.\n\nInstead, we calculated five key performance measures:\n\n1. **F-score**: This metric is the harmonic mean of precision and recall, providing a single score that balances both concerns. It is particularly useful in imbalanced datasets as it considers both false positives and false negatives.\n\n2. **Precision (Positive Predictive Value)**: This measures the proportion of true positives among all positive predictions. High precision indicates a low false positive rate.\n\n3. **Recall (Sensitivity)**: This measures the proportion of true positives among all actual positives. High recall indicates a low false negative rate.\n\n4. **Area Under the Receiver Operating Characteristic Curve (ROC-AUC)**: This metric evaluates the model's ability to distinguish between the positive and negative classes across all possible classification thresholds. An ROC-AUC of 0.80, for example, indicates that 80% of the time, the model correctly ranks a randomly chosen positive instance higher than a randomly chosen negative instance.\n\n5. **Area Under the Precision-Recall Curve (PR-AUC)**: This metric is particularly useful for imbalanced datasets. It plots precision against recall for different threshold values, providing a more informative picture of the model's performance on the minority class (in our case, individuals with CKD onset).\n\nThese metrics collectively provide a comprehensive evaluation of our models' performance, focusing on their ability to accurately predict CKD events. The use of ROC-AUC and PR-AUC, in particular, aligns with best practices in the literature for evaluating models on imbalanced datasets.",
  "evaluation/comparison": "For the evaluation of our machine learning models, we conducted a comprehensive comparison with simpler baselines to ensure the robustness and effectiveness of our approaches. We manually built logistic regression models, often referred to as short models, which served as a benchmark for comparison. These models were constructed using a set of well-established predictors, including HIV exposure through intravenous drug use, hepatitis C coinfection, birth year, estimated glomerular filtration rate, sex, CD4 cell count, hypertension, prior cardiovascular disease, and diabetes mellitus. The logistic regression models utilized the two most recent measurements of these variables along with summary statistics from all previous measurements.\n\nThis comparison allowed us to assess the performance of our data-driven machine learning models against a more traditional and straightforward approach. By evaluating both the logistic regression models and the more complex machine learning methods, we aimed to demonstrate the added value of incorporating a multitude of static and dynamic factors into our prediction models. The results of this comparison are detailed in our study, highlighting the improved performance of our machine learning models over the simpler baselines.",
  "evaluation/confidence": "The evaluation of our models focused on several well-established performance metrics, including the F-score, precision, recall, ROC-AUC, and PR-AUC. These metrics were chosen to address the class imbalance in our dataset, where most individuals did not develop CKD. The ROC-AUC and PR-AUC values ranged from 0.926 to 0.996 and from 0.631 to 0.956, respectively, indicating excellent to moderate performance across different prediction horizons and machine learning algorithms.\n\nHowever, specific details about confidence intervals for these performance metrics are not provided. The evaluation was conducted on a single training, validation, and test split due to the time-consuming nature of the model selection process. While the test set was fairly large, comprising 10% of the study population, the lack of multiple splits and confidence intervals means that the variability and statistical significance of the results are not fully quantified.\n\nThe results suggest that the machine learning models, particularly the full models, outperformed the manually built logistic regression models (short models) in most cases. This indicates that the inclusion of a multitude of static and dynamic factors in the prediction models likely contributed to their improved performance. Nonetheless, without explicit statistical tests or confidence intervals, it is challenging to definitively claim that one method is superior to others or to baselines with high confidence.",
  "evaluation/availability": "Not enough information is available."
}