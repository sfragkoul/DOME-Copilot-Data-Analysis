{
  "publication/title": "Investigation of robustness of hybrid artificial neural network with artificial bee colony and firefly algorithm in predicting COVID-19 new cases: case study of Iran",
  "publication/authors": "The authors who contributed to the article are:\n\nMohammad Javad Shaibani, Sara Emamgholipour, and Samira Sadate Moazeni.\n\nMohammad Javad Shaibani and Sara Emamgholipour were involved in the development of the hybrid artificial neural network models, specifically the ANN-ABC and ANN-FA models. They also played a significant role in the data collection and analysis, focusing on the COVID-19 confirmed cases in Iran. Their work included training the ANN model with the Levenberg\u2013Marquardt algorithm and evaluating the models using criteria such as R-squared and root-mean-square error.\n\nSamira Sadate Moazeni contributed to the simulation of COVID-19 new cases data in different countries using the proposed ANN-ABC and ANN-FA models. Her work helped in validating the robustness of these models in predicting COVID-19 cases globally.",
  "publication/journal": "Stochastic Environmental Research and Risk Assessment",
  "publication/year": "2021",
  "publication/pmid": "34608374",
  "publication/pmcid": "PMC8481113",
  "publication/doi": "10.1007/s00477-021-02030-6",
  "publication/tags": "- COVID-19\n- Artificial Neural Network\n- Artificial Bee Colony\n- Firefly Algorithm\n- Hybrid Model\n- Forecasting\n- Predictive Modeling\n- Epidemiology\n- Machine Learning\n- Public Health",
  "dataset/provenance": "The dataset used in this study consists of daily COVID-19 new cases. The data was collected from Our World in Data, covering the period from February 19, 2020, to July 25, 2021. This dataset comprises 523 daily observations. The input data for the models is the number of days (time), as the specific input data is unknown or may not exist. The dataset was divided into training and testing sets, with 392 observations (75% of the total data) used for training the network and 131 observations (25% of the total data) reserved for testing and validating the robustness of the models. This division ensures that the models are trained on a substantial amount of data while also having a sufficient test set to evaluate their performance accurately.",
  "dataset/splits": "The dataset used in this study consists of daily COVID-19 new cases. The data spans from February 19, 2020, to July 25, 2021, totaling 523 daily observations. This dataset was divided into two primary splits: training and testing.\n\nThe training set comprises 392 daily observations, which accounts for 75% of the total dataset. The testing set includes 131 observations, making up the remaining 25% of the data. This split ensures that the model is trained on a substantial portion of the data while reserving a significant portion for evaluating its performance.\n\nThe input data for the model consists of the number of days (time), as the specific input features were unknown or not available. The output data is the daily number of new COVID-19 cases. This approach allows the model to learn patterns over time and make predictions based on temporal data.",
  "dataset/redundancy": "The dataset used in this study consisted of daily confirmed COVID-19 cases. To ensure robust model training and evaluation, the dataset was randomly divided into training and test sets. Specifically, 75% of the data was allocated for training the models, while the remaining 25% was reserved for testing. This split was done randomly to ensure that the training and test sets were independent, which is crucial for evaluating the generalizability of the models.\n\nThe random split helps in mitigating the risk of data leakage, where information from the test set might inadvertently influence the training process. By ensuring independence between the training and test sets, the models' performance on unseen data can be more reliably assessed.\n\nRegarding the distribution of the dataset, it is not directly comparable to previously published machine learning datasets, as the focus here is on time-series data specific to COVID-19 cases. However, the approach of using a random split for training and testing is a standard practice in machine learning, ensuring that the models are evaluated on data they have not seen during training. This method helps in providing a more accurate assessment of the models' predictive performance.",
  "dataset/availability": "The data used in the simulations can be accessed publicly. Specifically, the dataset is available at the \"Our World in Data\" website, which provides comprehensive COVID-19 source data. This data includes daily observations of COVID-19 new cases, spanning from February 19, 2020, to July 25, 2021. The dataset consists of 523 daily observations, which were divided into training and testing sets. 75% of the data, amounting to 392 observations, was used for training the network, while the remaining 25%, or 131 observations, was reserved for testing and validating the robustness of the models.\n\nThe data is freely accessible to the public, allowing for reproducibility and further research. The specific URL for accessing the data is provided in the publication, ensuring that other researchers can easily obtain the same dataset used in the study. This transparency supports the verification of the results and encourages further exploration and validation of the models developed.",
  "optimization/algorithm": "The optimization algorithms used in this study are hybrid models that combine Artificial Neural Networks (ANN) with metaheuristic algorithms. Specifically, the Artificial Bee Colony (ABC) algorithm and the Firefly Algorithm (FA) are employed to enhance the performance of the ANN.\n\nThe ANN-ABC model integrates the ANN with the ABC algorithm, which is inspired by the foraging behavior of honey bees. The ABC algorithm is used to optimize the weights and biases of the ANN, aiming to improve its predictive accuracy. The number of bees in the ABC algorithm was carefully selected to balance between computational efficiency and solution accuracy. Through experimentation, it was found that using 40 bees provided the best trade-off, leading to improved forecasting robustness in both training and testing stages.\n\nSimilarly, the ANN-FA model combines the ANN with the Firefly Algorithm, which mimics the flashing behavior of fireflies. The FA is used to optimize the search area for finding the optimal solution in the ANN. The number of fireflies was also optimized, and it was determined that using 30 fireflies yielded the best results. This hybrid model demonstrated high robustness in approximating COVID-19 confirmed new cases, with R-squared values exceeding 99% in both training and testing stages.\n\nThese hybrid models were developed to address the limitations of traditional ANN algorithms, which may get trapped in local extrema and fail to find the global optimum. By incorporating metaheuristic algorithms, the hybrid models were able to achieve more accurate and reliable predictions. The choice of these specific algorithms was driven by their proven effectiveness in optimization problems and their compatibility with ANN architectures.\n\nThe development and validation of these hybrid models were conducted within the context of predicting COVID-19 new cases, highlighting their practical applicability in real-world scenarios. The results showed that both the ANN-ABC and ANN-FA models outperformed the standalone ANN, demonstrating their potential for improving predictive accuracy in complex and dynamic systems.",
  "optimization/meta": "The models developed in this study are hybrid models, specifically ANN-ABC and ANN-FA. These models are not traditional meta-predictors that use the outputs of other machine-learning algorithms as input. Instead, they enhance the performance of an Artificial Neural Network (ANN) by re-training it with different algorithms.\n\nThe ANN is initially developed and trained using the Levenberg\u2013Marquardt algorithm. After this initial training, the model is re-trained using either the Artificial Bee Colony (ABC) algorithm or the Firefly Algorithm (FA). This process aims to optimize the weights obtained by the ANN, thereby improving its predictive accuracy.\n\nThe input data for these models consists of the number of days (time) since the start of the observation period, as the specific input features are unknown or may not exist. The output data is the daily COVID-19 new cases. The dataset used for training and testing the models includes 523 daily observations collected from February 19, 2020, to July 25, 2021. Out of these, 392 observations (75% of the total dataset) are used for training the network, and 131 observations (25% of the total dataset) are used for testing and validating the robustness of the models.\n\nThe independence of the training data is ensured by randomly selecting the observations for training and testing. This random selection helps to mitigate any potential bias and ensures that the models are evaluated on unseen data, providing a more reliable assessment of their performance.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of our machine-learning algorithms. We focused on predicting daily new COVID-19 cases, which required a specific approach to data handling.\n\nThe input data consisted of the number of days since the start of the observation period, as the exact input features were unknown or not available. This approach allowed us to use time as a proxy for other potential influencing factors. The output data consisted of the daily new COVID-19 cases reported.\n\nThe dataset spanned from February 19, 2020, to July 25, 2021, comprising 523 daily observations. To train and validate our models, we split the data into training and testing sets. Specifically, 75% of the data (392 observations) were used for training the network, while the remaining 25% (131 observations) were reserved for testing and validating the model's robustness.\n\nBefore feeding the data into the machine-learning algorithms, we normalized the values to ensure that they were on a similar scale. This step is essential for improving the convergence speed and the overall performance of the neural networks.\n\nAdditionally, we employed a routine procedure to determine the optimal number of hidden neurons in our artificial neural network (ANN) models. This involved developing multiple ANN models with varying numbers of neurons and evaluating their performance using metrics such as the coefficient of determination (R\u00b2) and root mean square error (RMSE). The model with the highest R\u00b2 and lowest RMSE was selected as the optimal configuration.\n\nFor the hybrid models, after initial training of the ANN, we re-trained the model using new algorithms, specifically the Artificial Bee Colony (ABC) and Firefly Algorithm (FA). This hybrid approach aimed to enhance the model's ability to find the global optimum and improve its predictive accuracy.",
  "optimization/parameters": "In our study, the input parameters for the models were primarily the number of days, which served as the time variable. This choice was made because the input data were either unknown or not readily available. The output data consisted of the daily COVID-19 new cases.\n\nThe selection of the number of neurons in the hidden layer of the artificial neural network (ANN) was crucial for optimizing the model's performance. To determine the optimal number of neurons, we developed 24 different ANN models, each with a varying number of neurons. These models were evaluated based on their coefficient of determination (R\u00b2) and root mean square error (RMSE). The model with 17 neurons was selected as the optimal configuration because it achieved the highest overall rank when considering both training and testing stages.\n\nFor the hybrid models, specifically the ANN-ABC (Artificial Bee Colony) and ANN-FA (Firefly Algorithm), additional parameters were tuned. In the ANN-ABC model, the number of bees was a critical parameter. Through extensive testing, it was found that using 40 bees provided the best balance between accuracy and computational efficiency. For the ANN-FA model, the number of fireflies was optimized, and it was determined that 30 fireflies yielded the most effective results without significantly increasing computational time.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "In our study, we developed and optimized artificial neural network (ANN) models to predict COVID-19 cases. The ANN models were initially configured with a single hidden layer, which is sufficient for handling complex nonlinear problems. We employed the Levenberg\u2013Marquardt (LM) algorithm for training the network due to its efficiency and flexibility. The LM algorithm avoids the computation of the Hessian Matrix, making it one of the quickest backpropagation algorithms available.\n\nTo determine the optimal number of hidden neurons, we followed a routine procedure by developing 24 different ANN models. Each model was evaluated based on the coefficient of determination (R\u00b2) and the root mean square error (RMSE). A higher R\u00b2 value indicates better predictability, while a lower RMSE value ensures the robustness of the models. We ranked the models based on these criteria, with the model having the maximum R\u00b2 and minimum RMSE receiving the highest scores. The model with 17 neurons was selected as the optimal simulation due to its superior performance in both training and testing stages.\n\nTo address the risk of overfitting, we utilized a hybrid modeling approach by integrating the ANN with the Artificial Bee Colony (ABC) algorithm and the Firefly Algorithm (FA). These hybrid models, ANN-ABC and ANN-FA, were designed to enhance the accuracy and optimization of the ANN results. For the ANN-ABC model, we identified the optimum number of bees and iterations as 40 and 300, respectively. Similarly, for the ANN-FA model, we determined that 30 fireflies and approximately 300 iterations provided the best performance. Both hybrid models demonstrated improved predictive accuracy compared to the standalone ANN, with the ANN-FA showing slightly better results in most cases.\n\nIn summary, our approach involved developing multiple ANN models, evaluating them based on R\u00b2 and RMSE, and selecting the best-performing model. We then enhanced this model using hybrid algorithms to mitigate overfitting and improve predictive accuracy. This method ensured that our models were robust and capable of generalizing well to new data.",
  "optimization/regularization": "In our study, we employed hybrid models to enhance the accuracy and robustness of our predictions. The use of hybrid models, specifically ANN-ABC and ANN-FA, inherently serves as a form of regularization. These hybrid approaches help to prevent overfitting by incorporating optimization algorithms that guide the neural network towards better generalization.\n\nThe Artificial Bee Colony (ABC) algorithm and the Firefly Algorithm (FA) both introduce stochastic elements that help the model escape local minima, which is a common issue with traditional neural networks. By doing so, these algorithms assist in finding more globally optimal solutions, thereby reducing the risk of overfitting.\n\nAdditionally, the selection of the optimal number of neurons and the use of a single hidden layer in our initial ANN model were carefully considered to balance model complexity and performance. This careful tuning helps in preventing the model from becoming too complex and overfitting the training data.\n\nFurthermore, the division of our dataset into training and testing sets, with 75% of the data used for training and 25% for testing, ensures that the model's performance is evaluated on unseen data. This practice is crucial for assessing the model's generalization capability and for identifying any signs of overfitting.\n\nIn summary, the use of hybrid models, careful selection of model architecture, and rigorous evaluation on separate test datasets collectively contribute to the prevention of overfitting in our study.",
  "optimization/config": "The configuration details for the optimization process are thoroughly documented within the publication. The hyper-parameter configurations, including the number of neurons in the artificial neural network (ANN) models, are explicitly stated. For instance, the optimal ANN model was identified as having 17 neurons, which was then used as the basis for developing hybrid models like ANN-ABC and ANN-FA.\n\nThe optimization schedule is also clearly outlined. The Levenberg\u2013Marquardt (LM) algorithm was selected for training the ANN due to its efficiency and flexibility. The process involved developing 24 different ANN models, each evaluated based on the coefficient of determination (R\u00b2) and root mean square error (RMSE). The model with the highest overall rank, which had 17 neurons, was chosen for further hybrid model development.\n\nFor the hybrid models, specific parameters were tuned. In the ANN-ABC model, the number of bees was optimized, with 40 bees identified as the best configuration after evaluating various numbers of bees and iterations. Similarly, for the ANN-FA model, the number of fireflies was optimized, with 30 fireflies determined to be the most effective.\n\nThe model files and optimization parameters are not directly provided within the text, but the methods and results are thoroughly described, allowing for replication of the experiments. The publication does not specify a particular license for the use of the described methods or data, but it is implied that the information is available for academic and research purposes as per standard scientific publishing practices.",
  "model/interpretability": "The models developed in this study, including the Artificial Neural Network (ANN) and its hybrid versions (ANN-ABC and ANN-FA), are primarily black-box models. This means that while they are highly effective in predicting COVID-19 new cases, the internal workings and decision-making processes are not easily interpretable. The ANN models, in particular, use complex, non-linear relationships between input and output data, which are encoded in the weights and biases of the neural network layers. These relationships are not straightforward to decipher, making it challenging to understand how specific inputs influence the outputs.\n\nThe hybrid models, ANN-ABC and ANN-FA, incorporate optimization algorithms (Artificial Bee Colony and Firefly Algorithm, respectively) to enhance the performance of the ANN. These algorithms further complicate the interpretability by adding layers of optimization that are not transparent. The Firefly Algorithm, for instance, mimics the behavior of fireflies to find optimal solutions, and the Artificial Bee Colony Algorithm simulates the foraging behavior of bees. Both algorithms involve stochastic processes that are not easily traceable, adding to the black-box nature of the models.\n\nWhile the models are robust and effective in forecasting, their lack of interpretability is a limitation. This means that policymakers and healthcare professionals may find it difficult to understand the underlying factors contributing to the predictions. However, the models' strength lies in their ability to handle complex, non-linear data and provide accurate forecasts, which is crucial for short-term predicting and scenario-making, such as assessing the impact of vaccination or quarantine measures on COVID-19 new cases.",
  "model/output": "The model developed in this study is a regression model. It is designed to predict daily COVID-19 new cases, which is a continuous value. The performance of the model is evaluated using metrics such as the coefficient of determination (R\u00b2) and root mean square error (RMSE). A higher R\u00b2 value indicates better predictability, while a lower RMSE value signifies the robustness of the model. The model's output is the predicted number of daily COVID-19 cases, and it has been validated using both training and testing datasets. The optimal model, which includes 17 neurons in the hidden layer, achieved high R\u00b2 values for both training and testing stages, demonstrating its effectiveness in predicting COVID-19 cases.",
  "model/duration": "The execution time for the models varied depending on the specific configuration and the number of iterations or bees/fireflies used. For the ANN-ABC model, the optimal configuration was found with 40 bees and 1000 iterations. The models generally converged after around 300 repetitions, indicating that the majority of the computational effort was focused within this range. For the ANN-FA model, the optimal configuration involved 30 fireflies and 1000 iterations, with convergence typically occurring after approximately 300 iterations as well.\n\nThe computational time increased with a higher number of bees or fireflies, but beyond a certain point (around 40 bees for ANN-ABC and 30 fireflies for ANN-FA), the improvement in the solution was marginal. This balance between computational effort and solution accuracy was crucial in determining the optimal number of bees or fireflies for each model.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The robustness of the models was evaluated using two primary statistical metrics: the coefficient of determination (R\u00b2) and the root mean square error (RMSE). These metrics were employed to assess the performance of the models in predicting COVID-19 new cases.\n\nThe R\u00b2 value indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. A higher R\u00b2 value signifies better predictability power of the model. Conversely, the RMSE measures the average magnitude of the errors between predicted and actual values, with a lower RMSE indicating better model performance.\n\nThe models were trained using 75% of the total dataset, which consisted of 523 daily observations of COVID-19 new cases collected from February 19, 2020, to July 25, 2021. The remaining 25% of the dataset was used for testing and validating the robustness of the models. This approach ensured that the models were evaluated on data they had not seen during training, providing a more reliable assessment of their predictive performance.\n\nThe evaluation process involved developing multiple artificial neural network (ANN) models with varying numbers of hidden neurons. Each model was ranked based on its R\u00b2 and RMSE values during both the training and testing phases. The model with the highest R\u00b2 and lowest RMSE was identified as the optimal model. This systematic evaluation ensured that the selected model was robust and capable of accurately predicting COVID-19 new cases.",
  "evaluation/measure": "In our study, we employed two primary performance metrics to evaluate the robustness of our models: the coefficient of determination (R\u00b2) and the root mean square error (RMSE). These metrics are widely used in the literature and provide a comprehensive evaluation of model performance.\n\nThe coefficient of determination, R\u00b2, indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, where a value closer to 1 signifies a better fit of the model to the data. A higher R\u00b2 value demonstrates greater predictability power, making it a crucial metric for assessing model accuracy.\n\nOn the other hand, the root mean square error (RMSE) measures the average magnitude of the errors between predicted and actual values. It provides an absolute measure of fit, with lower values indicating better model performance. RMSE is particularly useful for understanding the scale of the errors, making it an essential metric for evaluating model robustness.\n\nBy reporting both R\u00b2 and RMSE, we ensure a balanced assessment of our models' performance. R\u00b2 provides an overall measure of fit, while RMSE offers insights into the magnitude of errors. This combination of metrics is representative of standard practices in the literature, allowing for a thorough and reliable evaluation of our models' predictive capabilities.",
  "evaluation/comparison": "In our study, we compared the performance of our proposed hybrid models, ANN-ABC and ANN-FA, with a simpler baseline model, the standard Artificial Neural Network (ANN). This comparison was conducted to evaluate the robustness and accuracy of our hybrid models in predicting COVID-19 new cases.\n\nThe standard ANN model was developed using a Perceptron architecture with one hidden layer, which is adequate for handling complex nonlinear problems. The Levenberg\u2013Marquardt algorithm was employed for training the network due to its efficiency and flexibility. We developed 24 different ANN models with varying numbers of hidden neurons to identify the optimal configuration. The models were evaluated using the coefficient of determination (R\u00b2) and root mean square error (RMSE) criteria. The model with 17 neurons achieved the highest overall rank based on these criteria.\n\nSubsequently, we enhanced the standard ANN by integrating it with the Artificial Bee Colony (ABC) algorithm and the Firefly Algorithm (FA), resulting in the ANN-ABC and ANN-FA hybrid models, respectively. These hybrid models were designed to improve the accuracy and optimization of the results obtained by the standard ANN.\n\nThe performance of the ANN-ABC and ANN-FA models was compared with the standard ANN across various datasets, including data from Iran, the US, India, Italy, Russia, and worldwide data. The results demonstrated that both hybrid models outperformed the standard ANN in terms of predictive accuracy. Specifically, the ANN-FA model showed superior performance in most cases, with R\u00b2 values ranging from 95% to over 99% across different regions. The ANN-ABC model also performed robustly, but the ANN-FA consistently achieved higher R\u00b2 values, indicating better predictive power.\n\nIn summary, our comparison with the simpler baseline model, the standard ANN, and publicly available methods highlighted the superior performance of our hybrid models, particularly the ANN-FA, in predicting COVID-19 new cases. This comparison underscores the effectiveness of integrating optimization algorithms with ANN to enhance predictive accuracy.",
  "evaluation/confidence": "The evaluation of the models in this study primarily focuses on the coefficient of determination (R\u00b2) and root mean square error (RMSE) as key performance metrics. These metrics are used to assess the robustness and accuracy of the models in predicting COVID-19 new cases.\n\nThe R\u00b2 value indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. A higher R\u00b2 value signifies better predictability. Conversely, a lower RMSE value indicates better model performance, as it measures the average magnitude of the errors between predicted and actual values.\n\nThe models were evaluated using a dataset of 523 daily observations, with 75% of the data used for training and 25% for testing. The performance of the models was assessed on both training and test datasets to ensure robustness.\n\nThe study developed two hybrid models, ANN-ABC and ANN-FA, to enhance the accuracy of the base ANN model. The ANN-ABC model, with 40 bees and 300 iterations, achieved an R\u00b2 of approximately 0.988 for both training and testing stages in Iran. Similarly, the ANN-FA model, with 30 fireflies and around 300 iterations, achieved an R\u00b2 of 0.995 for training and 0.994 for testing in Iran. These high R\u00b2 values indicate strong predictive performance.\n\nThe models were also tested on data from other countries, including the US, India, Italy, and Russia, as well as worldwide data. In most cases, the hybrid models outperformed the base ANN model, demonstrating their robustness and generalizability.\n\nHowever, confidence intervals for the performance metrics and statistical significance tests to claim superiority over other methods and baselines are not explicitly mentioned. Therefore, while the models show promising results, further statistical analysis would be necessary to confirm the statistical significance of these findings.",
  "evaluation/availability": "The raw evaluation files used in our simulations are publicly available. They can be accessed through the Our World in Data website, which provides comprehensive datasets on COVID-19 cases. The data includes daily observations of new COVID-19 cases from February 19, 2020, to July 25, 2021. This dataset was used to train and validate our models, with 75% of the data used for training and 25% for testing.\n\nThe source codes used in our study are inherently exclusive and might be provided under certain constraints. We have ensured that the data and methods used are transparent and reproducible, adhering to the standards of scientific research. For further details on data access and usage, please refer to the provided links and contact the authors for any specific inquiries regarding the source codes."
}