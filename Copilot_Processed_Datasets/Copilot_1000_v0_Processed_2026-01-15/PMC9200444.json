{
  "publication/title": "Deep learning using chest radiographs to identify high-risk smokers for lung cancer screening CT: Development and validation of a prediction model",
  "publication/authors": "The authors who contributed to the article are:\n\n- Lu\n- Raghu\n- Aerts\n- Hoffmann\n\nNot sure about the specific contributions of each author to the paper.",
  "publication/journal": "Annals of Internal Medicine",
  "publication/year": "2022",
  "publication/pmid": "32866413",
  "publication/pmcid": "PMC9200444",
  "publication/doi": "10.7326/M20-1868",
  "publication/tags": "- Deep learning\n- Lung cancer screening\n- Chest radiography\n- Risk prediction\n- Convolutional neural network\n- Smoking\n- Medical imaging\n- Artificial intelligence\n- Predictive modeling\n- Public health",
  "dataset/provenance": "The dataset used for the development and validation of the CXR-LC model was sourced from two major trials: the Prostate, Lung, Colorectal, and Ovarian (PLCO) Cancer Screening Trial and the National Lung Screening Trial (NLST). Specifically, the PLCO chest radiograph arm participants totaled 52,320 individuals. These participants were divided into model development and validation datasets, with 80% allocated for development and 20% for validation. The development dataset was further split into training and hyperparameter tuning subsets, comprising 33,485 and 8,371 participants, respectively.\n\nThe NLST external validation dataset included 5,493 participants who were enrolled by the American College of Radiology Imaging Network (ACRIN) and had an available baseline radiograph. It is important to note that the training, tuning, and validation datasets were independent, ensuring that each individual was included in only one dataset.\n\nFor the development dataset, all available T0 and T1 radiographs were included, totaling 85,748 images. This approach was taken to provide a large number of training examples, which is crucial for training a convolutional neural network (CNN). In contrast, the validation datasets considered only the baseline T0 radiograph for each participant, reflecting the intended use case of the model.\n\nThe datasets used in this study have been utilized in previous research and by the community. For instance, the PLCOm2012 is a validated lung cancer risk score that has been widely recognized for its state-of-the-art performance. It predicts 6-year incident lung cancer using a logistic regression model based on 11 inputs, including age, race, education, BMI, COPD status, personal and family history of cancer, smoking status, and other relevant factors. This risk score serves as a benchmark for comparing the performance of the CXR-LC model.",
  "dataset/splits": "There are three main data splits: model development, validation, and training/tuning.\n\nThe model development dataset consists of 52,320 participants from the PLCO chest radiograph arm. This dataset was further divided into training and hyperparameter tuning subsets. The training subset contains 33,485 participants, while the tuning subset has 8,371 participants.\n\nThe validation dataset is composed of 5,615 participants from the PLCO study who were current or former smokers. Additionally, there is an external validation dataset from the NLST study, which includes 5,493 participants enrolled by ACRIN who were in the chest radiography arm and had an available baseline radiograph.\n\nFor the development dataset, all 85,748 available T0 and T1 radiographs were included. This was done to provide a large number of training examples for the convolutional neural network. In contrast, for the validation datasets, only the baseline T0 radiograph was considered to reflect the intended use case.\n\nThe datasets were designed to be independent, ensuring that each individual was included in only one dataset. This independence is crucial for maintaining the integrity of the model's performance evaluation.",
  "dataset/redundancy": "The datasets used for the development and validation of the CXR-LC model were carefully split to ensure independence and avoid redundancy. The study utilized data from the Prostate, Lung, Colorectal, and Ovarian (PLCO) Cancer Screening Trial and the National Lung Screening Trial (NLST).\n\nThe PLCO chest radiograph arm participants, totaling 52,320, were divided into model development (80%) and validation (20%) datasets. The development dataset was further split into training (80%) and hyperparameter tuning (20%) subsets. This resulted in 33,485 participants for training and 8,371 for tuning. The remaining PLCO participants who were current or former smokers comprised the PLCO validation dataset, consisting of 5,615 individuals. The NLST external validation dataset included 5,493 participants who were in the chest radiography arm and had an available baseline radiograph.\n\nTo ensure independence, each individual was included in only one dataset. For the development dataset, all available T0 and T1 radiographs were included to provide a large number of training examples, a common data augmentation strategy. However, for the validation datasets, only the baseline T0 radiograph was considered to reflect the intended use case.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in terms of size and diversity. The inclusion of both PLCO and NLST data ensures a robust validation process, with the PLCO data used for internal validation and the NLST data providing an external validation cohort. This approach helps to generalize the model's performance across different populations and settings.",
  "dataset/availability": "The datasets used in our study are not publicly available. The data splits, including the development, tuning, and validation datasets, were created from the PLCO and NLST trials, which are not released in a public forum due to privacy and ethical considerations. The PLCO and NLST datasets contain sensitive health information, and their release is governed by strict data use agreements and institutional review board approvals.\n\nTo ensure the integrity and independence of the datasets, we divided the PLCO chest radiograph arm participants into model development (80%) and validation (20%) datasets. The development dataset was further split into training (80%) and hyperparameter tuning (20%) subsets. The NLST external validation dataset consisted of participants enrolled by ACRIN who were in the chest radiography arm and had an available baseline radiograph. Each individual was included in only one dataset to maintain independence.\n\nThe CXR-LC model, however, is publicly available on GitHub at https://github.com/circ-ml/CXR-LC. This repository includes the model architecture, development details, and instructions for use. The code and model weights are released under an open-source license, allowing researchers to reproduce our results and build upon our work. The data used to train and validate the model remains proprietary and is not included in the public repository.",
  "optimization/algorithm": "The machine-learning algorithm class used is a convolutional neural network (CNN), specifically a fusion CNN. This type of network is designed to integrate both image data and additional clinical information to make predictions.\n\nThe algorithm is not entirely new; it builds upon previous work, particularly an Inception V4 network that was trained to predict all-cause mortality. The approach leverages transfer learning, which involves taking a pre-trained model and fine-tuning it for a specific task. This method is commonly used in medical imaging to improve performance and efficiency.\n\nThe decision to develop and validate this model in a medical journal rather than a machine-learning journal is likely due to the specific application and the target audience. The focus is on the clinical utility and validation of the model for predicting lung cancer risk from chest radiographs, which is of primary interest to the medical community. The model's performance and its potential impact on clinical decision-making are the key aspects being highlighted, rather than the novelty of the machine-learning technique itself.",
  "optimization/meta": "The CXR-LC model is a fusion convolutional neural network (CNN) that integrates both imaging data and basic clinical information. This approach can be considered a form of meta-predictor, as it combines outputs from different sources to make predictions.\n\nThe imaging component of the model uses a transfer learning approach based on a previously developed CXR-risk model. This model is an Inception V4 network trained to predict all-cause mortality. The same development dataset split used for the CXR-risk model was also used for CXR-LC to avoid contamination of validation datasets. This ensures that the training data for the imaging component is independent of the validation data.\n\nIn addition to the imaging data, the CXR-LC model incorporates basic clinical information available in the electronic medical record (EMR), such as age, sex, and smoking status. This information is used alongside the imaging data to make predictions.\n\nThe model was developed in stages. Initially, the imaging branch was trained on both smokers and nonsmokers to expose the CNN to a wide range of chest X-ray appearances. Subsequently, the full fusion CNN was fine-tuned using data from smokers only. The final CXR-LC model was validated in current or former smokers, ensuring that the training and validation datasets remained independent.\n\nThe use of independent datasets for training and validation is a critical aspect of the model's development. This independence helps to ensure that the model's performance is generalizable and not overly fitted to the training data. The model's architecture and development process are described in detail in the appendix, providing transparency and reproducibility.",
  "optimization/encoding": "For the data encoding and preprocessing, we utilized a combination of techniques to ensure the machine-learning algorithm, specifically the convolutional neural network (CNN), could effectively learn from the input data.\n\nThe primary input for our model was chest radiograph images. To augment the dataset and expose the CNN to a wide range of appearances, we included both baseline (T0) and first follow-up (T1) radiographs during the training phase. This approach helped in training the model with a larger and more diverse set of images.\n\nIn addition to the radiograph images, we incorporated basic demographic and clinical information commonly available in electronic medical records (EMRs). This included age, sex, and smoking status. These features were encoded as categorical or numerical variables, depending on their nature.\n\nFor the imaging component, we employed a transfer learning approach using an Inception V4 network, which was initially trained to predict all-cause mortality. This pre-trained model served as a strong foundation, allowing us to fine-tune it for our specific task of predicting lung cancer incidence.\n\nData augmentation techniques were applied to the radiograph images to increase the diversity of the training set and to make the model more robust. This included random transformations such as rotations, flips, and adjustments in brightness and contrast.\n\nThe final dataset was split into independent training, tuning, and validation sets to ensure that the model's performance could be rigorously evaluated. The training set was used to learn the model parameters, the tuning set was used to optimize hyperparameters, and the validation sets were used to assess the model's generalization performance.\n\nOverall, the data encoding and preprocessing steps were designed to maximize the information available to the model while ensuring that the training process was efficient and that the model's performance could be reliably evaluated.",
  "optimization/parameters": "The model CXR-LC is a fusion convolutional neural network (CNN) that integrates a chest radiograph image with basic information commonly available in electronic medical records (EMR). This basic information includes age, sex, and smoking status.\n\nThe imaging component of the model utilizes a transfer learning approach based on a previous CXR-risk model, which is an Inception V4 network trained to predict all-cause mortality. This network was fine-tuned for the CXR-LC model.\n\nThe specific number of parameters in the model is not explicitly stated. However, the development process involved training the imaging branch on both smokers and nonsmokers to expose the CNN to a wide range of chest X-ray appearances. Subsequently, the full fusion CNN was fine-tuned using data from smokers only. This staged development approach ensured that the model could effectively learn from the diverse data while focusing on the target population.\n\nThe final CXR-LC model was validated in current or former smokers, aligning with the intended use case. The model's architecture and development details are described in the Appendix Section B. The decision to use specific parameters and the development stages were likely guided by the need to balance model complexity with performance and generalization to the target population.",
  "optimization/features": "The CXR-LC model utilizes a combination of imaging data and basic clinical information as input features. For the imaging component, a single chest radiograph is used. Alongside the radiograph, the model incorporates basic information commonly available in electronic medical records (EMRs), specifically age, sex, and whether the individual is currently smoking. This results in a total of four input features.\n\nFeature selection was not explicitly performed in the traditional sense, as the features used are standard clinical variables that are routinely collected and are known to be relevant to lung cancer risk assessment. The selection of these features was based on established clinical knowledge and their availability in the EMR, rather than a data-driven feature selection process.\n\nThe development of the model involved splitting the dataset into training, tuning, and validation sets. The training set was used to develop the initial model, and the tuning set was used to optimize hyperparameters. The validation sets were kept independent and were not used in any part of the model development process to avoid contamination and ensure unbiased evaluation. Therefore, the selection of input features was done independently of the validation datasets, ensuring that the model's performance could be reliably assessed.",
  "optimization/fitting": "The CXR-LC model employs a fusion convolutional neural network (CNN) that integrates a chest radiograph image with basic information such as age, sex, and smoking status. The model was developed using a transfer learning approach based on an Inception V4 network, which was initially trained to predict all-cause mortality. This approach leverages a pre-trained network, reducing the number of parameters that need to be learned from scratch, thus mitigating the risk of overfitting.\n\nTo further address overfitting, the development dataset was divided into training and hyperparameter tuning subsets. Additionally, data augmentation techniques were used, including the inclusion of multiple radiographs from the same individual, which effectively increased the diversity of the training data without increasing the number of unique participants. This strategy helps the model generalize better to new, unseen data.\n\nThe model's performance was validated on independent datasets, including an internal validation set from the PLCO study and an external validation set from the NLST study. These validation steps ensure that the model's predictions are reliable and not merely memorizing the training data.\n\nTo rule out underfitting, the model was trained in stages. Initially, the imaging branch was trained on both smokers and nonsmokers to expose the CNN to a wide range of chest X-ray appearances. Subsequently, the full fusion CNN was fine-tuned using data from smokers only. This staged training process ensures that the model captures relevant features without being too simplistic.\n\nThe final CXR-LC model was validated specifically in current or former smokers, aligning with its intended use case. The model's discrimination and calibration were assessed using metrics such as the area under the receiver operating characteristic curve (AUC) and the Expected/Observed (E/O) ratio, respectively. These evaluations provide confidence that the model is neither overfitting nor underfitting the data.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are available. The CXR-LC model, including the CXR filenames split into development and validation datasets, and the CXR-LC outputs used in the analysis, are published on GitHub at https://github.com/circ-ml/CXR-LC. This repository provides access to the necessary components for replication and further development. The data used for model development and validation, specifically the PLCO and NLST chest radiographs, are available by application from the National Cancer Institute (NCI) and the American College of Radiology Imaging Network (ACRIN). The specific license details for the GitHub repository are not provided, but it is common for such repositories to be open-source, allowing for community contributions and further research.",
  "model/interpretability": "The CXR-LC model incorporates a convolutional neural network (CNN) for the imaging component, which is inherently a black-box model. However, to enhance interpretability, gradient-weighted class activation maps (Grad-CAM) were generated from the imaging branch. These maps highlight the specific regions on the chest radiograph that contribute most significantly to the model's predictions. By visualizing these areas, clinicians can gain insights into which anatomical features or abnormalities the model is focusing on, thereby providing a level of transparency.\n\nThe use of Grad-CAM allows for a more interpretable model by showing which parts of the chest radiograph are influential in the prediction process. This can help in understanding the model's decision-making and in building trust among users, particularly in a medical context where interpretability is crucial. While the CNN itself remains a black-box, the integration of Grad-CAM offers a way to peek inside the model's reasoning, making it more transparent and understandable.",
  "model/output": "The model, referred to as CXR-LC, is a regression model. It outputs a continuous probability between 0 and 1, representing the 12-year risk of incident lung cancer. This probability is then mapped to an ordinal risk score categorized as low, indeterminate, high, and very high based on specific probability thresholds. The model's primary outcome is incident lung cancer, defined as all lung cancers diagnosed after enrollment, and it also considers lung cancer death as a secondary outcome. The risk probabilities are calibrated using Platt\u2019s Scaling technique and validated across different datasets, including the PLCO internal validation dataset and the NLST external validation dataset. The model's performance is assessed using metrics such as the area under the receiver operating characteristic curve (AUC) and the Expected/Observed (E/O) ratio, providing a comprehensive evaluation of its predictive accuracy.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the CXR-LC model is publicly available. It can be accessed via GitHub at the following URL: https://github.com/circ-ml/CXR-LC. This repository includes the model itself, along with the necessary files and instructions to facilitate its use. Additionally, the repository contains the CXR filenames split into development and validation datasets, as well as the CXR-LC outputs used in the analysis. This public release aims to promote reproducibility and further research in the field.",
  "evaluation/method": "The evaluation of the CXR-LC model involved a comprehensive approach using both internal and external validation datasets. The primary outcome measured was incident lung cancer, defined as all lung cancers diagnosed after enrollment. The secondary outcome was lung cancer death, determined by an independent adjudication committee based on medical records.\n\nThe model was developed using 52,320 participants from the PLCO chest radiograph arm, divided into training, tuning, and validation datasets. The training dataset included all available T0 and T1 radiographs to ensure a large number of examples for the convolutional neural network. For validation, only the baseline T0 radiograph was considered to reflect real-world use.\n\nThe CXR-LC model's performance was assessed using the area under the receiver operating characteristic curve (AUC), comparing it to CMS eligibility criteria and the PLCOm2012 risk model. Additionally, nested combinations of CXR-LC with CMS eligibility and PLCOm2012 were evaluated. Statistical significance was determined using DeLong\u2019s method for comparing correlated ROC curves.\n\nCalibration was assessed via the Expected/Observed (E/O) ratio in the PLCO validation dataset, which measures the number of expected incident lung cancers divided by the number of observed cancers during follow-up. Bootstrapped samples were used to compute p-values for the E/O ratio.\n\nTo facilitate comparison at a single operating point, sensitivity and specificity were evaluated at a screening population size defined by CMS eligibility. These metrics were compared using McNemar\u2019s test. The CXR-LC risk probabilities were converted into an ordinal risk score (low, indeterminate, high, and very high) based on 12-year probability thresholds.\n\nThe validation datasets included an internal set from PLCO and an external set from NLST, ensuring that the model's performance was tested on independent data. This rigorous evaluation process aimed to provide a thorough assessment of the CXR-LC model's effectiveness in predicting lung cancer risk.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report several key metrics to evaluate the performance of our CXR-LC model. These metrics are chosen to provide a comprehensive assessment of the model's effectiveness in predicting lung cancer risk.\n\nFirstly, we use the area under the receiver operating characteristic curve (AUC) to evaluate the model's discrimination ability. The AUC provides a single scalar value that summarizes the model's performance across all possible classification thresholds. We compare the AUC of our CXR-LC model to the CMS eligibility criteria and the PLCOm2012 risk model, as well as nested combinations of these models. To ensure the statistical validity of these comparisons, we compute 95% confidence intervals and p-values using DeLong's method.\n\nIn addition to the AUC, we assess the model's calibration using the Expected/Observed (E/O) ratio. The E/O ratio is defined as the number of expected incident lung cancers divided by the number of observed cancers during follow-up. This metric helps us understand how well the predicted probabilities align with the actual outcomes. We compute p-values for the E/O ratio using 1,000 bootstrapped samples to ensure the robustness of our findings.\n\nTo facilitate comparison at a single operating point, we also report sensitivity and specificity at a screening population size defined by CMS eligibility. These metrics are defined based on the model's predictions of future lung cancer risk and are compared using McNemar's test. This approach allows us to evaluate the model's performance in a real-world screening scenario.\n\nFurthermore, we convert the CXR-LC risk probabilities into an ordinal risk score (low, indeterminate, high, and very high) based on 12-year probability thresholds. This risk score provides a more interpretable and actionable output for clinical use.\n\nThe set of metrics reported in this subsection is representative of the literature on risk prediction models. The AUC is a standard metric for evaluating the discrimination ability of predictive models. The E/O ratio is commonly used to assess calibration, and sensitivity and specificity at a specific operating point are essential for understanding the model's performance in practical applications. By reporting these metrics, we aim to provide a thorough and transparent evaluation of our CXR-LC model's performance.",
  "evaluation/comparison": "In the evaluation of our model, we performed a comprehensive comparison with publicly available methods and simpler baselines to ensure robustness and validity. We compared our CXR-LC model against the CMS eligibility criteria and the PLCOm2012 risk model, both of which are well-established and widely used in clinical practice. The CMS eligibility criteria are based on the 2013 USPSTF recommendation, which includes factors such as age, smoking history, and current smoking status. PLCOm2012 is a logistic regression model that predicts 6-year incident lung cancer using 11 inputs, including age, race, education, BMI, COPD status, and smoking history.\n\nOur model was validated on independent datasets, including the PLCO internal validation dataset and the NLST external validation dataset. These datasets were carefully selected to reflect real-world scenarios and to ensure that the comparisons were fair and unbiased. The PLCO dataset included participants who were both CMS eligible and ineligible, while the NLST dataset included only CMS-eligible participants. This allowed us to assess the performance of our model across different populations and to compare it directly with the CMS eligibility criteria and PLCOm2012.\n\nIn addition to these comparisons, we also evaluated nested combinations of CXR-LC with CMS eligibility and PLCOm2012. This approach allowed us to explore how our model could be integrated with existing risk assessment tools to potentially improve overall performance. The discrimination of our model was assessed using the area under the receiver operating characteristic curve (AUC), and we used DeLong\u2019s method to compute confidence intervals and p-values for the comparison of correlated ROC curves.\n\nFurthermore, we assessed the calibration of our model using the Expected/Observed (E/O) ratio, which measures the number of expected incident lung cancers divided by the number of observed cancers during follow-up. This metric provided insights into how well our model\u2019s predictions aligned with actual outcomes, ensuring that it was not only discriminative but also reliable in clinical settings.\n\nOverall, our evaluation included a thorough comparison with publicly available methods and simpler baselines, ensuring that our model\u2019s performance was rigorously tested and validated.",
  "evaluation/confidence": "The evaluation of our model, CXR-LC, includes several performance metrics with associated confidence intervals to provide a comprehensive assessment of its effectiveness. The area under the receiver operating characteristic curve (AUC) is one of the primary metrics used, and it is accompanied by 95% confidence intervals. These intervals help to quantify the uncertainty around the AUC estimates, ensuring that the reported performance is robust and reliable.\n\nTo compare the performance of CXR-LC with other methods and baselines, such as CMS eligibility criteria and the PLCOm2012 risk model, we employed DeLong's method. This statistical approach allows for the computation of p-values, which indicate whether the differences in AUCs between models are statistically significant. By using DeLong's method, we can confidently claim that CXR-LC outperforms other methods if the p-values are below the conventional threshold of 0.05.\n\nAdditionally, we assessed calibration using the Expected/Observed (E/O) ratio, which measures how well the predicted risks match the actual observed outcomes. The E/O ratio is calculated using bootstrapped samples to provide p-values, ensuring that the calibration results are statistically significant. This step is crucial for validating that CXR-LC not only discriminates well between high and low-risk individuals but also provides accurate risk estimates.\n\nFurthermore, we compared sensitivity and specificity at a specific operating point defined by CMS eligibility. McNemar's test was used to determine the statistical significance of these comparisons, ensuring that any claimed improvements in sensitivity or specificity are backed by robust statistical evidence.\n\nOverall, the evaluation of CXR-LC is thorough and statistically rigorous, with confidence intervals and p-values providing the necessary evidence to support claims of superior performance compared to other methods and baselines.",
  "evaluation/availability": "The raw evaluation files for the CXR-LC model are not publicly available. However, the model itself is publicly accessible. The CXR-LC model can be found on GitHub at the repository https://github.com/circ-ml/CXR-LC. This repository provides the necessary tools and resources for others to utilize the model in their own research or clinical settings. The specific details regarding the license under which the model is released are not provided here, but they can typically be found within the repository's documentation or license file."
}