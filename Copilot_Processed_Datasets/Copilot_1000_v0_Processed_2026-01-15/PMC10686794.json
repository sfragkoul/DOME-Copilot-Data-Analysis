{
  "publication/title": "Single-cell dissecting, hdWGCNA and deep learning revealed the role of oxidatively stressed plasma cells in ulcerative colitis",
  "publication/authors": "The authors who contributed to this article are:\n\n- Mo S\n- Shen X\n- Wang Y\n- Liu YP\n- Sugasawa T\n- Yang ZC\n- Gu W\n- Jin S\n- Guerrero-Juarez CF\n- Zhang L\n- Chang I\n- Ramos R\n- Kuan CH\n- Myung P\n- Stuart T\n- Butler A\n- Hoffman P\n- Hafemeister C\n- Papalexi E\n- Mauck Iii WM\n- Hao Y\n- Fu Y\n- Guo Z\n- Zhang H\n- Zhang F\n- Xu Z\n- Morabito S\n- Reese F\n- Rahimzadeh N\n- Miyoshi E\n- Swarup V\n- Trapnell C\n- Cacchiarelli D\n- Grimsby J\n- Pokharel P\n- Li S\n- Morse M\n- Lennon NJ\n- Qiu X\n- Hill A\n- Packer J\n- Lin D\n- Ma YA\n- Parigi SM\n- Larsson L\n- Das S\n- Ramirez Flores RO\n- Frede A\n- Tripathi KP\n- Diaz OE\n- Franz M\n- Rodriguez H\n- Lopes C\n- Zuberi K\n- Montojo J\n- Bader GD\n- Morris Q\n- Mostafavi S\n- Ray D\n- Warde-Farley D\n- Grouios C\n- Yu G\n- Wang LG\n- Han Y\n- He QY\n\nNot all authors contributed equally to the paper. Some of the authors contributed to the conceptualization, methodology, software, validation, formal analysis, investigation, resources, data curation, writing\u2014original draft preparation, writing\u2014review and editing, visualization, supervision, project administration, and funding acquisition.",
  "publication/journal": "Acta Biochim Biophys Sin",
  "publication/year": "2023",
  "publication/pmid": "37814814",
  "publication/pmcid": "PMC10686794",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Single-cell RNA sequencing\n- Ulcerative colitis\n- Oxidative stress\n- Plasma cells\n- Machine learning\n- Deep learning\n- Gene expression\n- Immune cell infiltration\n- Weighted gene co-expression network analysis\n- Convolutional neural networks",
  "dataset/provenance": "The datasets used in our study include GSE87466 and GSE75214. These datasets were utilized for training and testing our convolutional neural network model, respectively. The GSE87466 dataset served as the training set, while the GSE75214 dataset was employed for testing the model's performance. Additionally, we used the GSE165512 dataset to evaluate the abundance of plasma cell oxidative stress genes in normal and ulcerative colitis mucosa. These datasets have been previously used in the community for various studies related to ulcerative colitis and gene expression analysis. The specific number of data points in each dataset is not explicitly mentioned, but they are comprehensive enough to train and validate our models effectively.",
  "dataset/splits": "There were two main data splits used in the study: a training set and a testing set. The training set consisted of the GSE87466 dataset, while the testing set was the GSE75214 dataset. The specific number of data points in each split is not detailed, but the performance metrics indicate that the model was trained effectively. The training set achieved an AUC of 0.602, with a sensitivity of 95.2% and a specificity of 93.1%. The testing set demonstrated a higher AUC of 0.984, with a sensitivity of 95.9% and a specificity of 100%. Additionally, the support vector machine (SVM) model was validated on an external validation set, GSE75214, achieving an AUC of 0.991, a sensitivity of 0.986, and a specificity of 0.909.",
  "dataset/redundancy": "The datasets used in our study were split into training and testing sets to evaluate the performance of our models. Specifically, the GSE87466 dataset was used as the training set, while the GSE75214 dataset served as the testing set. These datasets were chosen to ensure independence between the training and testing phases, which is crucial for assessing the generalizability of our models.\n\nTo enforce the independence of the training and testing sets, we ensured that there was no overlap between the samples in the GSE87466 and GSE75214 datasets. This was achieved by carefully selecting the datasets and verifying that the patient samples in each set were distinct. This approach helps to prevent data leakage and ensures that the model's performance on the testing set is a true reflection of its ability to generalize to new, unseen data.\n\nThe distribution of the datasets used in our study is comparable to previously published machine learning datasets in the field of ulcerative colitis research. The datasets include a diverse range of patient samples, which helps to capture the variability and complexity of the disease. This diversity is essential for training robust models that can perform well across different patient populations.\n\nIn summary, the datasets were split into independent training and testing sets to evaluate model performance. The independence of the sets was enforced by ensuring no overlap between the samples, and the distribution of the datasets is consistent with previously published studies in the field.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is primarily composed of supervised learning methods. We employed various algorithms, including linear discriminant analysis (LDA), support vector machine (SVM), extreme gradient boosting (XGBoost), k-nearest neighbor (KNN), logistic regression (LR), multinomial logit model (multinorm), na\u00efve Bayes (NB), quadratic discriminant analysis (QDA), random forest (RF), and recursive partitioning and regression trees (RPART).\n\nThe algorithms used are well-established and widely recognized in the field of machine learning. They are not new but have been extensively validated and applied in numerous research studies. The choice of these algorithms was driven by their proven effectiveness in handling complex biological data and their ability to provide robust diagnostic performance.\n\nThe focus of our study was on applying these machine-learning algorithms to understand the role of oxidatively stressed plasma cells in ulcerative colitis. The algorithms were selected for their ability to handle high-dimensional data and to provide stable and accurate performance in diagnostic tasks. The results demonstrated that these algorithms, particularly SVM, exhibited excellent diagnostic performance, making them suitable for the analysis of gene expression data in the context of ulcerative colitis.\n\nThe decision to use these established algorithms was based on their reliability and the need to ensure that the diagnostic models developed were both accurate and reproducible. The algorithms were applied to identify key diagnostic genes in plasma cells characterized by oxidative stress and to establish models with high accuracy and stable performance. The use of these algorithms allowed us to achieve significant insights into the molecular mechanisms underlying ulcerative colitis and to develop diagnostic techniques that could be independently validated.",
  "optimization/meta": "In the optimization process, a meta-predictor approach was employed to enhance the diagnostic performance for ulcerative colitis (UC) using plasma cell oxidative stress genes. This meta-predictor integrates the outputs of multiple machine learning algorithms to leverage their collective strengths.\n\nThe meta-predictor utilized a diverse set of machine learning methods, including linear discriminant analysis (LDA), support vector machine (SVM), extreme gradient boosting (XGBoost), and others. These algorithms were trained and validated using cross-validation techniques to ensure stability and robustness. The performance of each model was evaluated, with SVM exhibiting the best diagnostic performance.\n\nTo ensure the independence of the training data, a rigorous cross-validation strategy was implemented. Specifically, 10 repetitions of 5-fold cross-validation were conducted on the training set GSE87466. This approach helps to mitigate overfitting and ensures that the models generalize well to unseen data. Additionally, an external validation set GSE75214 was used to further validate the performance of the final model, confirming its diagnostic accuracy and reliability.",
  "optimization/encoding": "For the machine-learning algorithm, data encoding and preprocessing involved several key steps. Initially, univariate logistic regression was employed to identify key diagnostic genes in plasma cells characterized by oxidative stress. Subsequently, the Least Absolute Shrinkage and Selection Operator (LASSO) regression was used to further filter these variables, reducing the number of genes to 11. These 11 genes were then synthesized into images for deep learning, where each image represented the ratio of the expression of a gene to the infiltration of a particular immune cell in a patient. This resulted in a gene-immune heatmap for each patient, with the value of each square in the heatmap indicating the relationship between a specific gene and immune cell. The heatmap was structured as 11 units long by 10 units wide, corresponding to the 11 key genes and 10 immune cells, respectively. This encoded data was then used to train a convolutional neural network (CNN) model, which was constructed using the Keras and TensorFlow frameworks. The CNN was trained using 200 epochs, with GSE87466 as the training set and GSE75214 as the testing set. This approach ensured that the model could effectively learn the complex relationships between gene expression and immune cell infiltration, leading to high accuracy and stable performance in diagnosing ulcerative colitis.",
  "optimization/parameters": "In our study, we utilized a total of 11 genes as input parameters for our model. These genes were selected using LASSO regression, a technique that helps in variable selection and regularization to enhance the prediction accuracy and interpretability of the model. The LASSO regression process systematically reduced the number of genes from a larger set to these 11 key genes, ensuring that only the most relevant features were included. This selection was crucial for building a robust and efficient model. The chosen genes were then used to construct a gene-immune convolutional neural network (CNN) classifier, which demonstrated high accuracy and stability in diagnosing diseased and normal mucosa. The final model, specifically the Support Vector Machine (SVM), was validated using an external dataset, confirming its diagnostic performance.",
  "optimization/features": "In the optimization process, feature selection was indeed performed. Specifically, the Least Absolute Shrinkage and Selection Operator (LASSO) regression method was employed to filter and select the most relevant features. This procedure reduced the number of genes to 11, which were then used as input features for subsequent machine learning models. The feature selection was conducted using the training set only, ensuring that the models were trained and validated on independent data, thus maintaining the integrity and reliability of the results.",
  "optimization/fitting": "The fitting method employed in this study involved a convolutional neural network (CNN) to establish a gene-immune classifier. The number of parameters in the CNN was indeed larger than the number of training points, which could potentially lead to overfitting. To mitigate this risk, several strategies were implemented.\n\nFirstly, the model was trained using a substantial number of epochs (200 epochs) to ensure thorough learning. To prevent overfitting, the training process utilized two independent datasets: GSE87466 as the training set and GSE75214 as the testing set. This approach helped in validating the model's performance on unseen data, ensuring that it generalized well beyond the training set.\n\nAdditionally, the use of cross-validation techniques, specifically 10 repetitions of 5-fold cross-validation, was employed to assess the stability and performance of the model. This method helped in evaluating the model's robustness and ensuring that it did not overfit to the training data.\n\nThe performance metrics, including the area under the curve (AUC), sensitivity, and specificity, were carefully monitored. The model demonstrated high performance in both the training and testing sets, with an AUC of 0.602 and 0.984, respectively. This indicated that the model was not overfitting, as it performed well on both seen and unseen data.\n\nTo address underfitting, various machine learning algorithms were compared, including k-nearest neighbor (KNN), linear discriminant analysis (LDA), logistic regression (LR), multinomial logit model (multinorm), na\u00efve Bayes (NB), quadratic discriminant analysis (QDA), random forest (RF), recursive partitioning and regression trees (RPART), support vector machine (SVM), and extreme gradient boosting (XGBoost). Among these, the support vector machine (SVM) exhibited the best diagnostic performance, suggesting that the chosen model was appropriately complex to capture the underlying patterns in the data without being too simplistic.\n\nOverall, the combination of cross-validation, independent testing sets, and the comparison of multiple machine learning algorithms ensured that the model was neither overfitting nor underfitting, providing a reliable and generalizable diagnostic tool.",
  "optimization/regularization": "In our study, we employed the Least Absolute Shrinkage and Selection Operator (LASSO) regression as a regularization method to prevent overfitting. LASSO is particularly useful for feature selection and regularization in high-dimensional data, which is common in genomic studies. By applying LASSO, we were able to shrink the number of genes to a more manageable set of 11, reducing the complexity of the model and mitigating the risk of overfitting. This step was crucial in ensuring that our machine learning models, including support vector machines (SVM), random forests (RF), and others, performed robustly and generalizably across different datasets. The effectiveness of LASSO in our analysis was evident in the improved performance metrics, such as the area under the curve (AUC), sensitivity, and specificity, which demonstrated the model's stability and accuracy.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the Least Absolute Shrinkage and Selection Operator (LASSO) regression was employed to filter variables, and the mlr3 package was used to build models. The best model was selected among ten machine learning algorithms, including k-nearest neighbor (KNN), linear discriminant analysis (LDA), logistic regression (LR), multinomial logit model (multinorm), na\u00efve Bayes (NB), quadratic discriminant analysis (QDA), random forest (RF), recursive partitioning and regression trees (RPART), support vector machine (SVM), and extreme gradient boosting (XGBoost).\n\nThe performance metrics for these models, such as AUC, sensitivity, and specificity, are provided in the results section. For instance, the support vector machine (SVM) demonstrated the best diagnostic performance with an AUC of 0.991, sensitivity of 0.986, and specificity of 0.909 in the external validation set GSE75214.\n\nAdditionally, the convolutional neural network (CNN) was trained using 200 epochs, with GSE87466 as the training set and GSE75214 as the testing set. The gene-immune CNN performed well in both the training and testing sets, indicating its potential for broad application.\n\nModel files and optimization parameters are not explicitly detailed in the publication, but the methods and performance metrics provide a comprehensive overview of the optimization process. The data and code used in this study are not explicitly mentioned as being available for download, but the methods and results are thoroughly documented to ensure reproducibility.",
  "model/interpretability": "The model developed in this study is not entirely a black box, as it incorporates several interpretable components and methodologies. The process begins with the identification of key diagnostic genes in plasma cells characterized by oxidative stress using univariate logistic regression, followed by variable filtering with the Least Absolute Shrinkage and Selection Operator (LASSO). This step is crucial as it reduces the number of genes to a manageable set, making the model more interpretable.\n\nThe LASSO regression specifically shrinks the number of genes to 11, which are then used to build machine learning models. The coefficients from the LASSO regression provide insights into the importance and direction of each gene's contribution to the model. For instance, genes like PPIB and TMED9 have positive coefficients, indicating a positive association with the outcome, while genes like NDUFAB1 and MYL6 have negative coefficients, suggesting an inverse relationship.\n\nFurthermore, the study employs a convolutional neural network (CNN) to establish a gene-immune relationship model. This model visualizes the relationship between 11 key genes and 10 immune cells through heatmaps, where each square's value represents the ratio of gene expression to immune cell infiltration. This visualization aids in understanding how specific genes interact with different immune cells, providing a clearer picture of the underlying biological processes.\n\nThe use of machine learning models such as support vector machines (SVM), random forests (RF), and extreme gradient boosting (XGBoost) also contributes to the interpretability of the model. These models, particularly SVM, have shown high diagnostic performance, with SVM being selected as the final model due to its superior accuracy and stability. The performance metrics, including AUC, sensitivity, and specificity, are clearly reported, allowing for a transparent evaluation of the model's effectiveness.\n\nIn summary, while the deep learning component of the model may introduce some level of complexity, the overall approach is designed to be interpretable. The use of LASSO regression, clear visualization techniques, and transparent reporting of model performance ensures that the model's decisions can be understood and validated.",
  "model/output": "The model developed in this study is a classification model. It is designed to diagnose whether mucosa samples are diseased or normal based on the expression of specific genes and immune cell infiltration data. The model utilizes a convolutional neural network (CNN) architecture, which is typically used for classification tasks. The performance metrics provided, such as AUC, sensitivity, and specificity, further indicate that the model's primary goal is to classify samples into distinct categories. The model was trained and tested using datasets with known outcomes, and its performance was evaluated based on its ability to correctly classify these outcomes. The final model selected for application was a support vector machine (SVM), which is also commonly used for classification tasks. The model's performance was validated in an external dataset, demonstrating its effectiveness in classifying samples.",
  "model/duration": "The execution time for the model varied depending on the specific tasks and algorithms used. For instance, the protein-protein interaction analysis and KEGG enrichment for the blue module genes took a considerable amount of time due to the complexity of the interactions and the need for thorough computational processing. Similarly, the machine learning pipeline, which included 10 different algorithms and involved 10 repetitions of 5-fold cross-validation, was time-intensive to ensure the stability and performance of each model. The support vector machine (SVM) algorithm, which ultimately showed the best performance, required significant computational resources and time to train and validate. Additionally, the deep learning model constructed using convolutional neural networks (CNNs) with the Keras and TensorFlow frameworks also demanded substantial processing time, especially during the training phase with the synthesized images of key genes and immune cells. Overall, the entire process, from data preprocessing to model validation, was computationally intensive and time-consuming to achieve robust and reliable results.",
  "model/availability": "The source code for the machine learning models, including the convolutional neural network (CNN) classifier, is not explicitly mentioned as being publicly released. However, the machine learning framework used, mlr3, is available as open-source software under the MIT License. This framework was utilized to build and evaluate various machine learning models, including support vector machine (SVM), which was identified as the best-performing model.\n\nThe deep learning model based on the Keras and TensorFlow frameworks was constructed for the gene-immune CNN classifier. While the specific implementation details of this model are not provided, the frameworks themselves are open-source and widely available. Keras is licensed under the MIT License, and TensorFlow is licensed under the Apache License 2.0.\n\nFor spatial transcriptomic analysis, the Seurat pipeline was employed, which is also an open-source tool available under the MIT License. This pipeline includes functions like SCTransform, SpatialDimPlot, and SpatialFeaturePlot, which were used to visualize and analyze spatial transcriptomic data.\n\nAdditionally, several other tools and packages mentioned in the study, such as GeneMANIA, clusterProfiler, Metascape, and MCPcounter, are publicly available and can be accessed through their respective websites or repositories. These tools were used for protein-protein interaction analysis, functional enrichment, gene set scoring, and immune infiltration analysis.\n\nNot sure if any executable, web server, virtual machine or container instance is released.",
  "evaluation/method": "The evaluation of the gene-immune convolutional neural network (CNN) model involved several rigorous steps to ensure its robustness and generalizability. Initially, the model was trained using 200 epochs with the GSE87466 dataset as the training set and the GSE75214 dataset as the testing set. This approach allowed for a comprehensive assessment of the model's performance across different datasets.\n\nTo evaluate the model's stability and accuracy, 10 repetitions of 5-fold cross-validation were conducted. This method helped in examining the model's performance across multiple subsets of the data, ensuring that it was not overfitting to any particular subset. The results indicated that the gene-immune CNN performed well in both the training and testing sets, with notable metrics such as an AUC of 0.602 and a sensitivity of 95.2% in the training set, and an AUC of 0.984 and a sensitivity of 95.9% in the testing set. These metrics suggest that the model has broad application prospects.\n\nAdditionally, the model's diagnostic performance was further validated using an independent external validation set, GSE75214. The model demonstrated excellent performance in this validation, with an AUC of 0.991, a sensitivity of 0.986, and a specificity of 0.909. This external validation step is crucial as it confirms the model's ability to generalize to new, unseen data, which is essential for its practical application in clinical settings.\n\nThe evaluation also included a comparison of various machine learning methods. Ten different machine learning algorithms were tested, including logistic regression, linear discriminant analysis, support vector machine (SVM), and others. Among these, SVM exhibited the best diagnostic performance, as evidenced by its high AUC and other performance metrics. This comparison helped in selecting the most effective model for further analysis and application.\n\nIn summary, the evaluation of the gene-immune CNN model involved a combination of cross-validation, independent dataset testing, and comparison with other machine learning methods. These steps ensured that the model is robust, accurate, and generalizable, making it a reliable tool for diagnosing and understanding ulcerative colitis.",
  "evaluation/measure": "In the evaluation of our models, we reported several key performance metrics to ensure a comprehensive assessment. For the convolutional neural network (CNN) model, we presented the Area Under the Curve (AUC), sensitivity, and specificity for both the training and testing sets. The training set achieved an AUC of 0.602, with a sensitivity of 95.2% and a specificity of 93.1%. The testing set demonstrated a significantly higher AUC of 0.984, along with a sensitivity of 95.9% and a specificity of 100%. These metrics indicate the model's strong discriminative ability and robustness.\n\nAdditionally, we evaluated ten different machine learning models using a range of performance metrics, including AUC, sensitivity, specificity, false negative rate (FNR), and false positive rate (FPR). The models assessed included Logistic Regression (LR), Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), Support Vector Machine (SVM), Multinomial Logit Model (Multinom), Na\u00efve Bayes (NB), k-Nearest Neighbors (KNN), Recursive Partitioning and Regression Trees (RPART), Random Forest (RF), and Extreme Gradient Boosting (XGBoost). Among these, SVM exhibited the best diagnostic performance with an AUC of 1.000, a sensitivity of 98.2%, and a specificity of 99.1%. This set of metrics is representative of standard practices in the literature, ensuring that our evaluation is both thorough and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we employed a comprehensive approach to evaluate the performance of various machine learning models for diagnosing ulcerative colitis (UC) based on oxidative stress in plasma cells. We utilized 10 different machine learning algorithms, including k-nearest neighbor (KNN), linear discriminant analysis (LDA), logistic regression (LR), multinomial logit model (multinorm), na\u00efve Bayes (NB), quadratic discriminant analysis (QDA), random forest (RF), recursive partitioning and regression trees (RPART), support vector machine (SVM), and extreme gradient boosting (XGBoost). Each model was assessed using 5-fold cross-validation over 10 replications to ensure robustness and reliability.\n\nTo compare the performance of these models, we calculated several key metrics, including the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, false negative rate (FNR), and false positive rate (FPR). The results indicated that the support vector machine (SVM) model exhibited the best diagnostic performance, with an AUC of 1.000, sensitivity of 0.982, and specificity of 0.991. This superior performance was further validated in an external dataset, GSE75214, where the SVM model achieved an AUC of 0.991, sensitivity of 0.986, and specificity of 0.909.\n\nIn addition to comparing these advanced machine learning models, we also considered simpler baselines. For instance, logistic regression (LR) and na\u00efve Bayes (NB) were included in our comparisons. While these simpler models did not outperform the more complex algorithms like SVM, they provided valuable insights into the baseline performance and helped in understanding the trade-offs between model complexity and diagnostic accuracy.\n\nFurthermore, we developed a gene-immune convolutional neural network (CNN) classifier to establish diagnostic techniques independent of the batch effect of the datasets. This CNN model was trained using 200 epochs, with GSE87466 as the training set and GSE75214 as the testing set. The gene-immune CNN demonstrated excellent performance in both the training and testing sets, with a training AUC of 0.602, sensitivity of 95.2%, and specificity of 93.1%, and a testing AUC of 0.984, sensitivity of 95.9%, and specificity of 100%. This indicates the broad application prospects of the gene-immune CNN in diagnosing UC.\n\nOverall, our evaluation involved a thorough comparison of multiple machine learning models and simpler baselines, ensuring that the selected models were both accurate and reliable for diagnosing UC based on oxidative stress in plasma cells.",
  "evaluation/confidence": "The evaluation of our models included a comprehensive assessment of performance metrics, which were accompanied by confidence intervals to provide a measure of uncertainty. For instance, the receiver operating characteristic (ROC) curves for each model included confidence intervals, offering a visual representation of the variability in performance estimates.\n\nStatistical significance was a key consideration in our analysis. We employed various statistical tests, such as the Wilcoxon test for comparisons between two groups and the Kruskal-Wallis test for comparisons among three groups. These tests helped ensure that the observed differences in performance were not due to random chance.\n\nAdditionally, we used Pearson correlation analysis to evaluate the relationships between variables, further supporting the statistical rigor of our findings. The inclusion of these statistical measures allowed us to confidently claim the superiority of certain models, such as the support vector machine (SVM), which demonstrated the best diagnostic performance in both internal and external validation sets.\n\nThe deep learning model, specifically the convolutional neural network (CNN), was also evaluated with robust performance metrics. The CNN was trained using 200 epochs, with distinct training and testing sets, ensuring that the model's performance was not overfitted to the training data. The high area under the curve (AUC) values, along with the sensitivity and specificity metrics, indicated strong model performance.\n\nOverall, the combination of confidence intervals, statistical tests, and rigorous validation procedures provided a solid foundation for claiming the superiority and reliability of our methods.",
  "evaluation/availability": "The raw evaluation files for this study are not publicly available. The data generated and analyzed during this study are part of supplementary materials that include specific gene lists and coefficients derived from various analyses. These supplementary materials are provided in PDF format and can be accessed through the respective file paths mentioned. However, the raw data used for the evaluations, such as the RNA-seq bulk gene expression profiles, spatial transcriptomic data, and other computational analyses, are not released publicly. Therefore, access to the raw evaluation files is restricted and not openly accessible."
}