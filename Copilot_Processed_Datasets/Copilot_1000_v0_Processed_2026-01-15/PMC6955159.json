{
  "publication/title": "Collective Lymph Node Features Predict Rectal ypN0",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Chinese Journal of Cancer Research",
  "publication/year": "2019",
  "publication/pmid": "31949400",
  "publication/pmcid": "PMC6955159",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Radiomics\n- Lymph Nodes\n- Rectal Cancer\n- Neoadjuvant Chemoradiotherapy\n- Machine Learning\n- Predictive Modeling\n- Magnetic Resonance Imaging\n- Pathological Nodal Stage\n- Feature Extraction\n- Collective Features\n- Tumor Features\n- Logistic Regression\n- LASSO Algorithm\n- Cross-Validation\n- Statistical Analysis",
  "dataset/provenance": "The dataset used in this study was sourced from patients with locally advanced rectal cancer (LARC) who underwent neoadjuvant chemoradiotherapy (NCRT) followed by total mesorectal excision (TME) surgery. The inclusion criteria for the study were biopsy-proven primary rectal adenocarcinoma, LARC confirmed by pre-treatment MRI, no prior treatment, complete NCRT, and TME surgery after NCRT. Exclusion criteria included lack of pathological results, insufficient MRI scans, poor image quality, mucous adenocarcinoma, and lack of noticeable lymph nodes (LNs) on MRI.\n\nA total of 2,931 pre-NCRT LNs and 1,520 post-NCRT LNs were delineated from 215 patients. The number of LNs per patient was 13.6\u00b15.0 in pre-NCRT data and 7.1\u00b13.9 in post-NCRT data. The dataset was chronologically divided into a discovery cohort and a validation cohort. The study utilized high-resolution T2-weighted MRI images, which are considered effective for visualizing small LNs. The features extracted from these images included first-order gray level histogram features, second-order gray level co-occurrence matrix (GLCM) texture features, and geometric features.\n\nThe dataset has not been used in previous papers by the community, as this study proposes a novel method of using collective features from LNs to predict the pathological nodal stage of LARC. The collective features include statistical measurements such as maximum, minimum, mean, median value, and standard deviation of each feature from all visible LNs of each participant. Both pre-NCRT and post-NCRT features were used to measure the difference before and after treatment. The study aims to provide a supplementary tool for radiologists to perform preoperative individualized predictions of nodal stage for personalized medicine.",
  "dataset/splits": "The dataset was divided into two main cohorts: the discovery cohort and the validation cohort. The discovery cohort was used for training and initial evaluation of the models, while the validation cohort was used to test the final models.\n\nIn total, 2,931 pre-neoadjuvant chemoradiotherapy (pre-NCRT) lymph nodes (LNs) and 1,520 post-NCRT LNs were delineated from 215 patients across both cohorts. On average, there were 13.6 \u00b1 5.0 LNs per patient in the pre-NCRT data and 7.1 \u00b1 3.9 LNs per patient in the post-NCRT data.\n\nThe clinical characteristics of the patients in both cohorts were summarized, showing significant differences in age between the discovery and validation cohorts. However, there were no significant differences in gender, pre-NCRT TN-stage, and pathological yTN-stage between the two cohorts.\n\nThe Dice similarity coefficient (DSC) for region of interest (ROI) delineation by two radiologists was 0.93 for tumors and 0.87 for LNs. The intra-class correlation coefficient (ICC) values for all features between the delineations of the two radiologists ranged from 0.82 to 0.95, indicating high agreement.",
  "dataset/redundancy": "The dataset was divided into a discovery cohort and a validation cohort. The discovery cohort was used for training and validating the models through a 5-fold cross-validation process. This process involved splitting the data into five subsets, training the model on four of them, and validating it on the remaining one. This procedure was repeated five times, with each subset serving as the validation set once.\n\nThe validation cohort, on the other hand, was used to test the final models trained on the entire discovery cohort. This ensured that the training and test sets were independent, as the validation cohort was not used in any way during the training process.\n\nTo enforce independence, the features were carefully examined and redundant ones were removed. If the absolute value of the correlation coefficient between two features was larger than a specified hyperparameter, the feature with the smaller group difference was removed. This step helped in reducing overfitting and ensuring that the models generalized well to unseen data.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the field. The features were extracted from both pre- and post-neoadjuvant chemoradiotherapy (NCRT) data, providing a comprehensive view of the changes over time. The use of collective features from all visible rectal lymph nodes (LNs) ensured that the models captured the variability and complexity of the data, leading to more accurate predictions. The models were also balanced by properly weighting the positive and negative samples, which is crucial for maintaining a balance between the two classifications.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is logistic regression with L1 regularization, specifically the least absolute shrinkage and selection operator (LASSO). This method is well-established and not new. It was chosen for its ability to perform both feature selection and regularization, which helps to prevent overfitting by shrinking some coefficient estimates to zero. The use of LASSO is particularly suitable for high-dimensional data, where the number of features exceeds the number of observations.\n\nThe algorithm was not published in a machine-learning journal because the focus of the study is on the application of radiomics in predicting pathological nodal stage in locally advanced rectal cancer (LARC), rather than the development of new machine-learning techniques. The LASSO algorithm is a standard tool in the field of machine learning and statistics, and its implementation is well-documented in the literature. The innovation lies in the application of this algorithm to the specific problem of predicting ypN0 status using collective features from rectal lymph nodes (LNs) and primary tumors.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps. Initially, features were extracted from the region of interest (ROI) using a home-made program developed on the MATLAB platform. The intensity of all images was normalized by scaling into the range between 0 and 1. Voxels with intensities outside a specified range were rejected to ensure consistency in feature extraction.\n\nForty-one features were extracted from each lymph node (LN) and the primary tumor. These features included nine first-order gray level histogram features from the ROI volume, twenty-four second-order gray level co-occurrence matrix (GLCM) texture features, and eight geometric features from the whole volume and the slice with the largest ROI area. The mathematical expressions for these features are detailed in the supplementary materials.\n\nPrior to training, redundant features were examined and removed. If the absolute value of the correlation coefficient between two features exceeded a hyperparameter r, the feature with the smaller group difference was eliminated. This step helped in reducing the dimensionality of the data and focusing on the most relevant features.\n\nThe remaining features were then trained using the least absolute shrinkage and selection operator (LASSO) with L1 regularization. This method was chosen for its ability to perform both feature selection and regularization, thereby enhancing the model's predictive accuracy. The positive and negative samples were properly weighted to maintain a balance between the two classifications.\n\nThe hyperparameter \u03bb was tuned using 5-fold cross-validation to maximize the area under the curve (AUC) of the receiver operating characteristic (ROC) curve. This process ensured that the model was optimized for the best possible performance. After determining \u03bb, the model was trained with all data in the discovery cohort and subsequently tested in the validation cohort.",
  "optimization/parameters": "In the optimization process, the number of parameters (p) used in the model was carefully selected to balance between model complexity and overfitting. Initially, a large number of features were considered. For the lymph node (LN) model, 412 features were reduced to 156 using Student\u2019s t-test to remove insignificant features. Further reduction was done by removing redundant features with a correlation coefficient threshold of r=0.6, resulting in 7 features. These 7 features were then selected using the LASSO algorithm with L1 regularization. The hyperparameter \u03bb was determined through 5-fold cross-validation to maximize the area under the curve (AUC) of the receiver operating characteristic (ROC) curve.\n\nSimilarly, for the tumor model, 82 features were reduced to 25 using Student\u2019s t-test, and then further reduced to 8 features by removing redundant ones. Finally, 7 features were selected using the LASSO algorithm with L1 regularization, and the hyperparameter \u03bb was determined through 5-fold cross-validation.\n\nThe final models for both LN and tumor include 7 features each, which is approximately 1/5 of the number of ypN+ participants in the discovery cohort. This selection process ensures that the models are robust and not overly complex, thereby reducing the risk of overfitting.",
  "optimization/features": "In the optimization process, the input features for the models were initially quite extensive. For the lymph node (LN) model, 412 features were considered. These features were first reduced to 156 by removing insignificant features using Student\u2019s t-test. Subsequently, the 156 features were further reduced to 7 by eliminating redundant features with a correlation coefficient threshold of r=0.6. The final 7 features were selected using the LASSO algorithm with L1 regularization.\n\nFor the tumor model, 82 features were initially considered. These were reduced to 25 by removing insignificant features using Student\u2019s t-test. The 25 features were then reduced to 8 by eliminating redundant features. Finally, 8 features were selected using the LASSO algorithm with L1 regularization.\n\nFeature selection was performed using the training set only, ensuring that the validation set remained independent and unbiased. This process involved removing insignificant features through statistical tests and reducing redundancy to enhance the model's performance and generalization. The hyperparameter \u03bb was determined using 5-fold cross-validation to maximize the area under the curve (AUC) of the receiver operating characteristic (ROC) curve. This rigorous feature selection process ensured that the models were trained on the most relevant and non-redundant features, improving their predictive accuracy.",
  "optimization/fitting": "In our study, we employed a rigorous approach to ensure that our models were neither overfitting nor underfitting the data. Initially, the number of features was indeed much larger than the number of training points. To address this, we implemented a multi-step feature selection process.\n\nFirst, we used Student\u2019s t-test to remove features that showed no significant difference (P>0.05), reducing the initial set of features. Next, we applied a redundancy test to eliminate features that were highly correlated with each other, using a hyperparameter r to determine the threshold for correlation. This step helped in retaining only the most informative features.\n\nFollowing this, we utilized the least absolute shrinkage and selection operator (LASSO) with L1 regularization. LASSO is particularly effective in feature selection as it can shrink some coefficients to zero, effectively performing both feature selection and regularization. This method ensured that only the most relevant features were included in the final model, thereby mitigating the risk of overfitting.\n\nTo further validate our model, we employed 5-fold cross-validation to tune the hyperparameter \u03bb. This process involved dividing the data into five subsets, training the model on four subsets, and validating it on the remaining subset. This was repeated five times, with each subset serving as the validation set once. The hyperparameter \u03bb was chosen to maximize the area under the curve (AUC) of the receiver operating characteristic (ROC) curve, ensuring that the model generalized well to unseen data.\n\nAdditionally, we balanced the positive and negative samples to maintain an equilibrium between the two classifications. This step was crucial in preventing the model from being biased towards the majority class, which could lead to underfitting.\n\nIn summary, our approach involved a systematic reduction of features, the use of regularization techniques, and thorough validation methods to ensure that our models were neither overfitting nor underfitting the data. This meticulous process resulted in robust models that performed well on both the discovery and validation cohorts.",
  "optimization/regularization": "In our study, we employed the least absolute shrinkage and selection operator (LASSO) with L1 regularization to prevent overfitting. This method is particularly useful for feature selection and regularization in regression models. By incorporating L1 regularization, LASSO encourages sparsity in the model, effectively shrinking some coefficients to zero. This process helps in selecting only the most relevant features, thereby reducing the complexity of the model and mitigating the risk of overfitting.\n\nThe LASSO algorithm was used to determine the optimal hyperparameter \u03bb through 5-fold cross-validation. This technique involves dividing the data into five subsets, training the model on four subsets, and validating it on the remaining subset. This process is repeated five times, each time using a different subset as the validation set. The hyperparameter \u03bb that maximizes the area under the curve (AUC) of the receiver operating characteristic (ROC) curve is selected. This approach ensures that the model generalizes well to unseen data, enhancing its predictive performance and robustness.\n\nAdditionally, we performed feature reduction by removing redundant features based on a correlation threshold. If the absolute value of the correlation coefficient between two features exceeded a specified hyperparameter r, the feature with the smaller group difference was removed. This step further helps in reducing the dimensionality of the data and preventing overfitting by ensuring that only the most informative features are retained in the model.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the hyperparameter \u03bb for the LASSO algorithm was determined through 5-fold cross-validation, aiming to maximize the area under the curve (AUC) of the receiver operating characteristic (ROC) curve. For the LN-model, \u03bb was set to 0.0367, while for the tumor-model, it was set to 0.0111. The process of feature selection, including the removal of redundant features based on a correlation coefficient threshold (r=0.6), is also described. The final models, including the selected features and their respective weights, are listed in tables within the results section. However, the specific model files and optimization parameters are not explicitly provided in the publication. The study does not mention the availability of these files or any associated licenses.",
  "model/interpretability": "The model developed in this study is not entirely a black box, as it incorporates interpretable features and weights. The final models, both the LN-model and the tumor-model, include a limited number of features selected through a rigorous process involving statistical tests and regularization techniques. This process ensures that the models are not overly complex and that each feature contributes meaningfully to the predictions.\n\nThe LN-model, for instance, includes seven features, each with a specific weight indicating its importance in predicting the pathological nodal stage. These features are derived from collective measurements of lymph nodes (LNs), such as the maximum, minimum, mean, median values, and standard deviation of various metrics like gray level co-occurrence matrix (GLCM) correlation and skewness. The weights assigned to these features provide insights into their relative importance. For example, a positive weight indicates a positive relation with the probability of ypN+ (pathological nodal stage), while a negative weight suggests an inverse relationship.\n\nSimilarly, the tumor-model also consists of seven features, each with an associated weight. These features are derived from the primary tumor and include metrics like maximum signal intensity, skewness, and GLCM cluster shade, among others. The weights for these features help in understanding which tumor characteristics are most predictive of the pathological nodal stage.\n\nThe use of LASSO (Least Absolute Shrinkage and Selection Operator) with L1 regularization further enhances the interpretability of the models. LASSO not only selects the most relevant features but also shrinks the less important ones to zero, resulting in a sparse model. This sparsity makes it easier to interpret the model by focusing on the few features that have non-zero weights.\n\nIn summary, while the models leverage advanced machine learning techniques, they are designed to be interpretable. The selection of features and their corresponding weights provides clear insights into the factors that influence the predictions, making the models more transparent and understandable.",
  "model/output": "The model is a classification model. It is designed to predict the pathological nodal stage, specifically to distinguish between ypN0 and ypN+ stages. The output of the model is a predictive score that is compared to the actual pathological nodal stage of participants. The performance of the model is evaluated using metrics such as the area under the curve (AUC) of the receiver operating characteristic (ROC) curve, sensitivity, specificity, positive predictive value, and negative predictive value. The model uses logistic regression with L1 regularization, which is a common technique for binary classification problems. The final models, both the LN-model and the tumor-model, include a set of features selected through a process of feature reduction and regularization, aiming to maximize the predictive accuracy for the classification task.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The software used for feature extraction in this study was developed in-house on the MATLAB platform (version 2017b, MathWorks, Natick, MA, USA). Unfortunately, the source code for this specific implementation is not publicly available. However, the features extracted are standard radiomics features, and their mathematical expressions are described in the supplementary materials of the publication. This should allow other researchers to replicate the feature extraction process using their own MATLAB implementations or other radiomics software tools that support similar feature sets.\n\nRegarding the models themselves, the training and validation processes were conducted using standard machine learning techniques, including feature reduction via Student\u2019s t-test and LASSO with L1 regularization. The specific hyperparameters and methods used are detailed in the publication, enabling others to implement similar models. However, there is no publicly released executable, web server, virtual machine, or container instance for running the algorithm directly.\n\nFor those interested in replicating the study or applying similar methods, the detailed descriptions of the features, models, and statistical analyses provided in the publication should serve as a comprehensive guide. The supplementary materials also include additional information that may be helpful for implementation.",
  "evaluation/method": "The evaluation of the method involved a comprehensive process to ensure the robustness and accuracy of the models. Initially, redundant features were examined and removed based on a correlation coefficient threshold. The remaining features were then trained using the least absolute shrinkage and selection operator (LASSO) with L1 regularization. This process involved proper weighting of positive and negative samples to maintain a balance between the two classifications.\n\nTo tune the hyperparameter \u03bb, a 5-fold cross-validation was employed, aiming to maximize the area under the curve (AUC) of the receiver operating characteristic (ROC) curve. This step was crucial for optimizing the model's performance.\n\nAfter determining the optimal \u03bb, the model was trained using all data from the discovery cohort and subsequently tested on the validation cohort. This approach ensured that the model's performance was evaluated on an independent dataset, providing a more reliable assessment of its generalizability.\n\nStatistical analysis was conducted to compare continuous and categorical data. For continuous data, Student\u2019s t-test was used to compare age differences and to remove features with no significant difference (P>0.05). For categorical data, Pearson Chi-square test was used to compare differences in gender, T-stage, and N-stage. The likelihood-ratio test was applied if any cell had an expected count less than 5. The AUC of different methods was compared using the method proposed by DeLong et al. The maximum Youden index was used to determine the cutoff value for separating predicted ypN0 and ypN+. A two-sided P<0.05 was regarded as statistically significant.",
  "evaluation/measure": "In the evaluation of our models, we focused on several key performance metrics to assess their predictive capabilities. For both the discovery and validation cohorts, we reported the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curves. The AUC provides a comprehensive measure of the model's ability to distinguish between different classes, with higher values indicating better performance.\n\nIn addition to the AUC, we also reported sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). Sensitivity, also known as the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. PPV indicates the probability that a positive test result is a true positive, while NPV indicates the probability that a negative test result is a true negative.\n\nThese metrics were chosen to provide a well-rounded evaluation of the models' performance. The AUC gives an overall sense of the model's discriminative power, while sensitivity and specificity provide insights into the model's performance at a specific threshold. PPV and NPV are particularly important in clinical settings, where the consequences of false positives and false negatives can be significant.\n\nThe reported metrics are in line with common practices in the literature, ensuring that our results are comparable with other studies in the field. By including a range of performance measures, we aim to provide a thorough assessment of our models' effectiveness in predicting pathological nodal stages.",
  "evaluation/comparison": "In our study, we did not perform a comparison with publicly available methods on benchmark datasets. Instead, we focused on developing and validating our own models, specifically the LN-model and the tumor-model, using our own datasets.\n\nWe did, however, compare our models to a simpler baseline, which was the subjective evaluation by raters. This baseline involved two radiologists\u2014one junior and one senior\u2014who classified participants based on MRI protocols before and after neoadjuvant chemoradiotherapy (NCRT). The junior radiologist initially classified each participant, and the senior radiologist reviewed and corrected these classifications as necessary.\n\nThe performance of our models was evaluated using the area under the curve (AUC) of the receiver operating characteristic (ROC) curves. The LN-model demonstrated significantly higher AUC values compared to the tumor-model and the subjective evaluation by raters in both the discovery and validation cohorts. This indicates that our LN-model, which incorporates collective features from lymph nodes, outperforms both the tumor-model, which relies solely on primary tumor features, and the subjective evaluations by radiologists.",
  "evaluation/confidence": "The evaluation of the models includes confidence intervals for the performance metrics. The area under the curve (AUC) values for the lymph node (LN)-model, tumor-model, and subjective evaluations by raters are provided with 95% confidence intervals (CIs). For instance, the AUC of the LN-model in the discovery cohort is 0.818 with a 95% CI of 0.745\u22120.878, indicating a high level of confidence in this estimate. Similarly, the AUC of the tumor-model in the discovery cohort is 0.685 with a 95% CI of 0.602\u22120.760, and the AUC of the subjective evaluation by raters is 0.581 with a 95% CI of 0.496\u22120.663.\n\nStatistical significance is also considered in the evaluation. The LN-model's AUC is significantly larger than that of the tumor-model in both the discovery and validation cohorts. In the discovery cohort, the LN-model's AUC is significantly larger than the tumor-model's AUC with a Z-value of 2.09 and a P-value of 0.037. In the validation cohort, the LN-model's AUC is significantly larger than the tumor-model's AUC with a Z-value of 3.106 and a P-value of 0.002. These results suggest that the LN-model performs significantly better than the tumor-model in predicting the pathological nodal stage.\n\nAdditionally, the sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) are summarized for each model and the subjective evaluations. These metrics provide a comprehensive view of the models' performance and help in understanding their clinical utility. The LN-model demonstrates higher specificity and NPV compared to the tumor-model and subjective evaluations, which are crucial for reducing false positives and ensuring accurate predictions.",
  "evaluation/availability": "Not enough information is available."
}