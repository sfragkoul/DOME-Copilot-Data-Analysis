{
  "publication/title": "A semi-supervised learning approach for COVID-19 detection from chest CT scans",
  "publication/authors": "The authors who contributed to this article are:\n\nYong Zhang, who was responsible for conceptualization, writing the original draft, and funding acquisition.\n\nLi Su, who contributed to data curation, software development, and investigation.\n\nZhenxing Liu, who handled validation and visualization.\n\nWei Tan, who supervised the work and conducted investigations.\n\nYinuo Jiang, who performed validation and investigation.\n\nCheng Cheng, who reviewed and edited the writing.",
  "publication/journal": "Neurocomputing",
  "publication/year": "2022",
  "publication/pmid": "35765410",
  "publication/pmcid": "PMC9221925",
  "publication/doi": "10.1016/j.neucom.2022.06.022",
  "publication/tags": "- COVID-19\n- Computed tomography\n- Semi-supervised learning\n- Deep learning\n- Attention mechanisms\n- Chest CT scans\n- Medical imaging\n- Diagnostic algorithms\n- Machine learning\n- Data augmentation",
  "dataset/provenance": "The dataset used in our study consists of both labeled and unlabeled CT scans for evaluating methods in the diagnosis of COVID-19. The labeled CT dataset is a public collection compiled by He et al., which includes 349 positive and 397 negative CT scans. Positive samples are COVID-19 preprints from medRxiv and bioRxiv, while negative samples encompass CT scans of healthy individuals or those with other types of diseases. The unlabeled sample dataset is derived from various open-source COVID-19 CT image datasets used by researchers to accurately diagnose COVID-19 using CT images. We randomly selected 500 positive and 500 negative samples as unlabeled samples for training. This dataset has been utilized in previous research and by the community for similar diagnostic purposes.",
  "dataset/splits": "The dataset used in this study consists of both labeled and unlabeled CT scans for evaluating methods in the diagnosis of COVID-19. The labeled CT dataset contains 349 positive and 397 negative CT scans. The positive samples are COVID-19 preprints from medRxiv and bioRxiv, while the negative samples include CT scans of healthy individuals or those with other types of diseases. The unlabeled sample dataset is derived from several open-source COVID-19 CT image datasets and includes 500 positive and 500 negative samples for training.\n\nThe dataset is split into four parts: training, validation, and test sets for the labeled data, and a training set for the unlabeled data. The labeled dataset is divided as follows:\n\n* Training set: 191 COVID-19 positive and 234 normal samples.\n* Validation set: 60 COVID-19 positive and 58 normal samples.\n* Test set: 93 COVID-19 positive and 99 normal samples.\n\nThe unlabeled dataset consists of 500 COVID-19 positive and 500 normal samples, all used for training. This results in a total of 425 labeled samples for training, 118 for validation, and 192 for testing. The unlabeled training set contains 1000 samples.",
  "dataset/redundancy": "In our study, we utilized both labeled and unlabeled CT datasets to evaluate the proposed methods for COVID-19 diagnosis. The labeled CT dataset, collected by He et al., consisted of 349 positive and 397 negative CT scans. Positive samples were COVID-19 preprints from medRxiv and bioRxiv, while negative samples included CT scans of healthy individuals or those with other diseases. For the unlabeled dataset, we selected 500 positive and 500 negative samples from various open-source COVID-19 CT image datasets.\n\nThe datasets were split into training, validation, and test sets. The labeled dataset was divided into 191 training, 60 validation, and 93 test samples for COVID-19 cases, and 234 training, 58 validation, and 99 test samples for normal cases. The unlabeled dataset consisted of 500 training samples for both COVID-19 and normal cases. This splitting ensured that the training and test sets were independent, preventing data leakage and ensuring robust evaluation.\n\nTo enforce independence between the training and test sets, we carefully curated the datasets to ensure that there was no overlap between the samples used for training and testing. This was crucial for evaluating the generalizability of our models. The distribution of our datasets is comparable to previously published machine learning datasets in the medical imaging domain, with a focus on ensuring a balanced representation of both positive and negative cases.\n\nNot applicable.",
  "dataset/availability": "The data used in this study includes both labelled and unlabelled CT datasets for evaluating methods in the diagnosis of COVID-19. The labelled CT dataset is a public dataset collected by He et al., which contains 349 positive and 397 negative CT scans. The positive samples were COVID-19 preprints from medRxiv and bioRxiv, while negative samples include CT scans of healthy individuals or those with other types of diseases.\n\nThe unlabelled sample dataset is derived from several open-source COVID-19 CT image datasets used by researchers to accurately diagnose COVID-19 using CT images. We randomly selected 500 positive and 500 negative samples as unlabelled samples for training.\n\nThe data splits used in this study are detailed in Table 1, which presents the dataset information. The table specifies the number of samples used for training, validation, and testing in both the labelled and unlabelled datasets.\n\nRegarding the availability and licensing of the data, the labelled dataset is publicly available and can be accessed through the source cited by He et al. The unlabelled dataset is derived from open-source COVID-19 CT image datasets, which are also publicly accessible. The use of these datasets is in compliance with the licensing terms provided by their respective sources.\n\nThe enforcement of data availability and usage is ensured through the public nature of the datasets and the adherence to the licensing terms specified by the original data providers. This ensures that the data can be accessed and used by other researchers for similar studies, promoting reproducibility and further advancements in the field.",
  "optimization/algorithm": "The optimization algorithm employed in our study is based on semi-supervised learning, specifically leveraging the MixMatch technique. This approach is not entirely new but has been adapted and enhanced for our specific application in COVID-19 detection from chest CT scans. The MixMatch method combines consistency regularization and entropy minimization to effectively utilize both labeled and unlabeled data. This technique is particularly useful when labeled data is scarce, which is often the case in medical imaging.\n\nWe introduced modifications to the MixMatch technique to better suit our needs. These modifications include a new data enhancement method and an attention mechanism within a convolutional neural network. The attention mechanism helps the model focus on the most relevant areas of the CT scans, improving the accuracy and interpretability of the results.\n\nThe reason this work was published in a neurocomputing journal rather than a machine-learning journal is that the primary focus is on the application of these techniques to medical imaging, specifically for COVID-19 diagnosis. The enhancements to the MixMatch technique and the attention mechanism are tailored to address the challenges in medical image analysis, making it more relevant to a neurocomputing audience. The goal is to provide a practical solution for healthcare professionals, demonstrating the potential of semi-supervised learning in real-world medical applications.",
  "optimization/meta": "The model employs ensemble learning to integrate predictions from two distinct machine-learning strategies. This approach leverages the strengths of both semi-supervised and supervised learning methods. The semi-supervised learning model and the supervised learning model are trained simultaneously using different learning strategies. The final diagnosis results are obtained by combining the prediction scores from these two models through an ensemble learning layer. This layer uses a weighted sum of the prediction scores, where the weights are determined by the ensemble learning process. The formula used for this integration is:\n\nptotal = lp1 + (1 / C0) * p2\n\nHere, p1 represents the prediction score from the semi-supervised learning model, and p2 represents the prediction score from the supervised learning model. This ensemble approach ensures that the final predictions are robust and reliable, benefiting from the complementary strengths of both learning strategies. The training data for each model is independent, as they are trained separately and then combined to produce the final output.",
  "optimization/encoding": "The input shape of the CT images was resized to 256x256 pixels. Various data augmentation techniques were applied, including horizontal flipping, random cropping, and scaling. These augmentations help to increase the diversity of the training data and improve the model's robustness.\n\nThe labelled CT dataset used for evaluation consisted of 349 positive and 397 negative CT scans. Positive samples were COVID-19 preprints from medRxiv and bioRxiv, while negative samples included CT scans of healthy individuals or those with other types of diseases. Additionally, an unlabelled sample dataset was derived from several open-source COVID-19 CT image datasets. For training, 500 positive and 500 negative samples were randomly selected as unlabelled samples.\n\nThe training process involved using the Adam optimizer with a momentum of 0.9, weight attenuation of 0.0001, and a learning rate of 0.001. The minibatch size was set to 32. A cosine learning rate scheduler was employed to adjust the learning rate during training. All models were first trained from scratch on ImageNet and then fine-tuned on the specific dataset. The training was conducted on GTX 2080Ti GPUs with data parallelism.\n\nThe ensemble learning weight factor was set to 0.6, and the weighting factor of the unlabelled data loss function was set to 100. These factors were crucial in balancing the contributions of labelled and unlabelled data during the training process.",
  "optimization/parameters": "In our study, the model utilizes several key parameters that are crucial for its optimization and performance. The number of augmentations, denoted as K, is an important parameter that determines how many times the unlabelled samples are augmented. This parameter is selected based on empirical observations and is set to a value that balances computational efficiency and model performance.\n\nAnother critical parameter is the sharpening temperature, T, which is used to sharpen the probability distributions of the augmented unlabelled samples. This parameter is chosen to ensure that the model can effectively learn from the unlabelled data by emphasizing the most probable classes.\n\nThe network parameters, h, include all the learnable weights and biases within the neural network. These parameters are initialized randomly and are updated during the training process using the Adam optimizer. The learning rate for the optimizer is set to 0.001, and the momentum is set to 0.9, with a weight attenuation of 0.0001. These settings are chosen to ensure stable and efficient convergence of the model.\n\nThe loss function coefficient, k, is used to balance the contribution of the labelled and unlabelled data to the total loss. This parameter is set to a value that ensures that the model can effectively learn from both types of data.\n\nAdditionally, the ensemble learning weight factor, l, is set to 0.6. This factor is used to combine the prediction results of the models trained by semi-supervised learning and supervised learning. The weighting factor of the unlabelled data loss function, f, is set to 100 to ensure that the model can effectively learn from the unlabelled data.\n\nThe input shape of the CT images is resized to 256x256, and various data augmentations, including horizontal flipping, random cropping, and scaling, are applied to enhance the robustness of the model. The minibatch size is set to 32, which is chosen to balance the computational efficiency and the stability of the training process.\n\nOverall, these parameters are selected based on extensive experimentation and empirical observations to ensure that the model can achieve optimal performance in diagnosing COVID-19 from CT scans.",
  "optimization/features": "The input features for the models used in this study are derived from CT images. The images are resized to a shape of 256x256 pixels. Various data augmentations are applied, including horizontal flipping, random cropping, and scaling. These augmentations help to increase the diversity of the training data and improve the model's robustness.\n\nFeature selection in the traditional sense was not explicitly performed. Instead, the models leverage deep learning techniques to automatically learn and extract relevant features from the raw CT images. This approach allows the models to capture complex patterns and structures in the data that might be missed by manual feature selection methods.\n\nThe models are trained using a combination of labelled and unlabelled data. The labelled dataset consists of 349 positive and 397 negative CT scans, while the unlabelled dataset includes 500 positive and 500 negative samples. The models are first pre-trained on the ImageNet dataset and then fine-tuned on the specific CT dataset used in this study. This transfer learning approach helps to improve the performance of the models by leveraging knowledge gained from a large and diverse dataset.\n\nThe input features are processed through convolutional neural networks (CNNs), specifically ResNet50 and DenseNet121, which are used as feature extractors. These networks are capable of learning hierarchical representations of the input images, from low-level features like edges and textures to high-level features that are specific to the task of COVID-19 diagnosis.\n\nIn summary, the input features are the raw CT images, which are preprocessed and augmented to enhance the training process. The models automatically learn relevant features from these images without the need for manual feature selection. The use of pre-trained networks and fine-tuning on the specific dataset further enhances the models' ability to accurately diagnose COVID-19 from CT scans.",
  "optimization/fitting": "In our study, we employed a semi-supervised learning approach to address the challenge of limited labeled data, which is crucial for avoiding overfitting. The method involves using a combination of labeled and unlabeled data to train the model. Specifically, we utilized the MixMatch strategy, which is known for its effectiveness in semi-supervised learning. However, MixMatch can lead to overfitting when dealing with a small amount of labeled data. To mitigate this, we incorporated Training Signal Annealing (TSA). TSA gradually releases labeled samples during the training process, thereby reducing the risk of overfitting to the labeled data.\n\nThe TSA mechanism works by setting a threshold that decreases over time, allowing the model to focus more on unlabeled data as training progresses. This approach ensures that the model does not become overly reliant on the labeled data, which helps in generalizing better to new, unseen data.\n\nAdditionally, we used ensemble learning to combine the predictions from two different models. One model was trained using semi-supervised learning, while the other was trained using supervised learning. This ensemble approach helps in improving the robustness of the model by leveraging the strengths of both learning strategies.\n\nTo further enhance the model's performance, we employed data augmentation techniques such as horizontal flipping, random cropping, and scaling. These techniques help in increasing the diversity of the training data, which is essential for preventing underfitting.\n\nIn summary, our approach effectively balances the trade-off between overfitting and underfitting by using a combination of semi-supervised learning, TSA, ensemble learning, and data augmentation. These methods ensure that the model generalizes well to new data while avoiding the pitfalls of overfitting and underfitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and enhance the model's generalization. One key method was the use of Training Signal Annealing (TSA). This technique gradually removes labeled data from the loss function as the training progresses, thereby reducing the model's reliance on labeled examples and mitigating overfitting. The threshold for removing labeled data increases over time, ensuring that the model learns more robustly from the unlabelled data.\n\nAdditionally, we incorporated sophisticated data augmentation techniques following the MixMatch rules. These augmentations included horizontal flipping, random cropping, and scaling, which helped in creating a more diverse training dataset. This diversity is crucial for preventing the model from memorizing the training data and instead learning more generalizable features.\n\nWe also introduced a new data enhancement method that modifies the regularization term in MixMatch. This method focuses on areas that are difficult to distinguish, helping the model to better learn from the challenging parts of the CT scans.\n\nFurthermore, we designed a convolutional neural network based on attention mechanisms. This network is capable of extracting multi-scale features from the CT scans, ensuring that the model focuses on the relevant infected areas and improves its performance.\n\nThese combined techniques\u2014TSA, data augmentation, and attention-based feature extraction\u2014work together to create a robust model that is less prone to overfitting and more accurate in diagnosing COVID-19 from chest CT scans.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in the publication. Specifically, we utilized the Adam optimizer with a momentum of 0.9, weight attenuation of 0.0001, and a learning rate of 0.001. The minibatch size was set to 32. Additionally, we employed a cosine learning rate scheduler to adjust the learning rate during training. The ensemble learning weight factor was set to 0.6, and the weighting factor of the unlabelled data loss function was set to 100.\n\nThe model files and optimization parameters are not explicitly detailed in the publication, but the methods and configurations are described comprehensively. The models were first trained from scratch on ImageNet and then fine-tuned on the specific dataset used in this study. Training was conducted on GTX 2080Ti GPUs with data parallelism.\n\nRegarding availability and licensing, the publication is part of the COVID-19 resource centre hosted on Elsevier Connect. Elsevier has granted permission to make all its COVID-19-related research immediately available in PubMed Central and other publicly funded repositories, such as the WHO COVID database. This includes rights for unrestricted research re-use and analyses in any form or by any means with acknowledgement of the original source. These permissions are granted for free by Elsevier for as long as the COVID-19 resource centre remains active.",
  "model/interpretability": "The model's decision-making process is not inherently transparent, which is a common challenge with deep learning models. To address this, we have focused on enhancing the interpretability of our model, particularly for medical applications where transparency is crucial. We employ Grad-CAM visualizations to provide a clear understanding of how the model makes its predictions. These visualizations highlight the areas in the CT scans that the model focuses on when diagnosing COVID-19. By comparing the Grad-CAM outputs of our model with those of a baseline model, it becomes evident that our approach accurately identifies disease-related regions, unlike the baseline, which sometimes focuses on irrelevant parts of the image. This visual analysis not only increases the interpretability of the model but also builds trust among medical professionals who rely on these diagnostic tools.",
  "model/output": "The model is designed for classification, specifically for diagnosing COVID-19 from CT scans. It uses ensemble learning to combine the prediction results from two models trained with different learning strategies: semi-supervised learning and supervised learning. The final prediction is a weighted sum of the prediction scores from these two models.\n\nThe model's performance is evaluated using metrics suitable for classification tasks, such as the area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, and F1-score. These metrics indicate that the model is effective in classifying CT scans as either COVID-19 positive or negative.\n\nThe model's output is a diagnosis result, which is the final prediction of whether a CT scan indicates COVID-19 or not. This is achieved by integrating the prediction results from the two models using an ensemble learning layer. The ensemble learning layer assigns weights to the prediction scores from the semi-supervised and supervised learning models, respectively, to produce the final diagnosis result.\n\nThe model's performance is further validated through visualizations, such as Grad-CAM, which show that the model accurately focuses on disease-related areas in the CT scans. This visual evidence supports the model's ability to classify CT scans correctly.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method involved several key steps and metrics to ensure its effectiveness in diagnosing COVID-19 from CT scans. The method was implemented using PyTorch, with CT images resized to 256x256 and various data augmentations applied, including horizontal flipping, random cropping, and scaling. The Adam optimizer was used with a momentum of 0.9, weight attenuation of 0.0001, and a learning rate of 0.001. The minibatch size was set to 32. The ensemble learning weight factor was set to 0.6, and the weighting factor of the unlabelled data loss function was set to 100. A cosine learning rate scheduler was employed to adjust the learning rate during training. All models were first trained from scratch on ImageNet and then fine-tuned on the dataset. Training was conducted on GTX 2080Ti GPUs with data parallelism.\n\nTo evaluate the performance of the model, five different metrics were used: area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, and F1-score. These metrics provide a comprehensive assessment of the model's diagnostic capabilities. The highest score for each metric indicates the best performance of the model.\n\nThe experimental results demonstrated that the proposed method outperformed other semi-supervised learning algorithms in terms of accuracy and F1-score, although it had a slightly lower AUC score compared to one of the methods. The method's ability to accurately identify infection areas was highlighted, making it a reliable tool for diagnosing COVID-19 from CT scans. Additionally, Grad-CAM visualizations were used to interpret the network's predictions, showing that the proposed method could capture almost all significant regions affected by COVID-19, unlike the baseline model which focused on irrelevant areas.",
  "evaluation/measure": "In our evaluation, we employed a comprehensive set of performance metrics to thoroughly assess the effectiveness of our proposed model. The metrics we reported include the area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, and the F1-score. These metrics are widely recognized in the literature and provide a robust evaluation framework for classification tasks.\n\nThe AUC measures the model's ability to distinguish between positive and negative classes, offering a single scalar value that summarizes the performance across all classification thresholds. Accuracy provides the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall, indicates the model's ability to correctly identify positive cases, while specificity measures the model's ability to correctly identify negative cases. The F1-score is the harmonic mean of precision and recall, providing a balance between the two, especially useful when dealing with imbalanced datasets.\n\nThese metrics collectively offer a detailed view of the model's performance, ensuring that we capture various aspects of its diagnostic capabilities. By including these metrics, we aim to provide a transparent and comprehensive evaluation that aligns with established practices in the field.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our proposed algorithm against several publicly available semi-supervised learning (SSL) methods and state-of-the-art algorithms. These comparisons were conducted on benchmark datasets to ensure a fair and comprehensive evaluation.\n\nWe compared our method with four other SSL techniques:\n\n1. **Mean Teacher**: This method involves training a student model to predict the outputs of a teacher model, which is an exponential moving average of the student model.\n\n2. **Virtual Adversarial Training (VAT)**: This approach focuses on adversarial training under semi-supervised conditions, aiming to improve the model's robustness.\n\n3. **Interpolation Consistency Training (ICT)**: This method emphasizes consistency in predictions across interpolated examples, enhancing the model's generalization.\n\n4. **Self-Trans**: This technique integrates comparative self-supervised learning into the transfer learning process, adjusting network weights to reduce overfitting risks.\n\nAdditionally, we compared our method with simpler baselines, such as models without attention modules or SSL techniques. These comparisons highlighted the effectiveness of our approach in improving diagnostic accuracy and robustness.\n\nThe evaluation metrics used included the area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, and F1-score. Our method demonstrated superior performance across most metrics, indicating its reliability and effectiveness in identifying COVID-19 infection areas in CT scans.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files are not directly available. However, the COVID-19-related research, including the evaluation methods and results, is freely accessible through the COVID-19 resource centre hosted on Elsevier Connect. This resource centre provides information in English and Mandarin. The permissions granted by Elsevier allow for unrestricted research re-use and analyses of the content, as long as the original source is acknowledged. This means that the evaluation methods and results discussed in the study can be accessed and used for further research, subject to the terms and conditions specified by Elsevier."
}