{
  "publication/title": "Machine Learning for ICH",
  "publication/authors": "The authors who contributed to this article are:\n\n- Shengli Li: Conceptualization, methodology\n- Jianan Zhang: Data curation\n- Xiaoqun Hou: Formal analysis\n- Yongyi Wang: Formal analysis\n- Tong Li: Funding acquisition\n- Zhiming Xu: Project administration\n- Feng Chen: Visualization\n- Yong Zhou: Writing - original draft\n- Weimin Wang: Conceptualization\n- Mingxing Liu: Funding acquisition, writing - review & editing",
  "publication/journal": "J Korean Neurosurg Soc",
  "publication/year": "2024",
  "publication/pmid": "37661087",
  "publication/pmcid": "PMC10788551",
  "publication/doi": "https://doi.org/10.3340/jkns.2023.0118",
  "publication/tags": "- Machine Learning\n- Intracerebral Hemorrhage\n- Predictive Modeling\n- Support Vector Machine\n- Decision Tree\n- Artificial Neural Network\n- Logistic Regression\n- Clinical Outcomes\n- Medical Data Analysis\n- Neurosurgery",
  "dataset/provenance": "The dataset used in this study was sourced from patients who had undergone surgery for intracerebral hemorrhage (ICH) between January 2014 and October 2022. Initially, there were 331 cases considered. However, 104 patients were excluded based on specific criteria, such as ICH caused by arteriovenous malformation, aneurysm, or tumor, intra-ventricular hemorrhage, complications with serious organ failure, infections, blood system diseases, follow-up duration of less than 6 months, and missing data. This left us with 227 cases that met the inclusion criteria.\n\nAmong these, 71 patients had favorable outcomes, while 156 had unfavorable outcomes. The outcomes were assessed using the modified Rankin scale (mRS) at the 6-month follow-up, with mRS 0\u20132 indicating favorable outcomes and mRS 3\u20135 indicating unfavorable outcomes. The data included various clinical variables such as age, sex, hypertension, diabetes, systolic and diastolic blood pressure, Glasgow coma scale (GCS), midline shift, hematoma volume, and operation time.\n\nThis dataset was specifically curated for this study and has not been used in previous publications by our team or the broader community. The focus was on evaluating the predictive performance of different machine learning models, including Support Vector Machine (SVM), Decision Tree C5.0, Artificial Neural Network (ANN), and Logistic Regression (LR), to identify factors influencing patient outcomes.",
  "dataset/splits": "The study involved a dataset of 331 intracerebral hemorrhage (ICH) cases who underwent surgery between January 2014 and October 2022. Initially, 227 cases met the inclusion criteria. However, 104 patients were excluded due to various reasons such as intracerebral hemorrhage caused by arteriovenous malformation, aneurysm, or tumor, intra-ventricular hemorrhage, complications with serious organ failure, infections, blood system diseases, follow-up less than 6 months, and missing data.\n\nThe final dataset was split into two main groups based on outcomes: 71 patients had favorable outcomes (mRS 0\u20132), and 156 patients had unfavorable outcomes (mRS 3\u20135). The groups were compared across various variables, including age, hypertension, sex, BMI, hyperlipidemia, hematoma side and location, residual hematoma volume, operation time, and type. Significant differences were observed in the percentage of diabetes, systolic blood pressure (SBP), diastolic blood pressure (DBP), Glasgow coma scale (GCS), midline shift, and hematoma volume.\n\nAdditionally, the cases were further categorized based on the time to operating room (TOR) into three groups: less than 12 hours, between 12 and 36 hours, and more than 36 hours. It was found that patients who had surgery between 12 and 36 hours were more likely to have positive outcomes.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not applicable.",
  "optimization/algorithm": "The machine-learning algorithms used in our study are well-established and widely recognized in the field. We employed four different types of models: Support Vector Machine (SVM), Decision Tree C5.0, Artificial Neural Network (ANN), and Logistic Regression (LR). These algorithms are not new but are chosen for their robustness and effectiveness in handling complex datasets.\n\nThe SVM model demonstrated the best comprehensive prediction efficiency among the four models. It is known for its ability to handle high-dimensional spaces and is effective in cases where the number of dimensions exceeds the number of samples. The Decision Tree C5.0 model, on the other hand, is known for its simplicity and interpretability, making it useful for understanding the relationships between variables. The ANN model, with its ability to learn and make decisions based on data, is particularly useful for pattern recognition tasks. Lastly, the LR model is a classic statistical method that provides a baseline for comparison with more complex models.\n\nThese algorithms were selected because they represent a range of approaches to machine learning, from linear models to more complex, non-linear models. Each has its strengths and weaknesses, and by comparing them, we aimed to identify the most effective model for predicting outcomes in our specific context.\n\nThe choice to use these established algorithms rather than a new one is driven by the need for reliability and validation. These models have been extensively tested and validated in various applications, ensuring that our results are robust and comparable to existing literature. Publishing in a neurosurgical journal allows us to focus on the clinical implications and applications of these models, rather than the theoretical aspects of the algorithms themselves. This approach ensures that our findings are directly relevant to practitioners in the field.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of the machine-learning algorithms. We began by collecting a comprehensive dataset from the hospital's computerized medical records, which included various patient characteristics and clinical variables.\n\nThe dataset encompassed both categorical and continuous data. Categorical data, such as sex, presence of diabetes, hypertension, and hyperlipidemia, were expressed as percentages. Continuous data, including age, body mass index (BMI), systolic and diastolic blood pressure, midline shift, operation time, residual hematoma volume, and time to operating room (TOR), were expressed as means with standard deviations.\n\nFor categorical variables, we used appropriate encoding techniques to convert them into a format suitable for machine-learning models. This involved transforming categorical data into numerical values using methods like one-hot encoding or label encoding, depending on the specific requirements of each model.\n\nContinuous variables were standardized or normalized to ensure that they were on a similar scale, which is essential for models like Support Vector Machines (SVM) and Artificial Neural Networks (ANN) that are sensitive to the magnitude of input features. Standardization involved subtracting the mean and dividing by the standard deviation, while normalization involved scaling the data to a range between 0 and 1.\n\nWe also handled missing data by imputing values based on the mean or median of the respective variables, ensuring that the dataset was complete and ready for analysis. This step was particularly important given that missing data can significantly affect the performance of machine-learning models.\n\nStatistical analyses were performed using IBM SPSS Statistics 26 to evaluate the reliability of the models. We calculated various metrics, including the area under the receiver operating characteristic curve (AUC), specificity, sensitivity, accuracy, positive likelihood ratio (PLR), negative likelihood ratio (NLR), and diagnostic odds ratio (DOR). These metrics provided a comprehensive evaluation of the models' predictive performance.\n\nIn summary, the data encoding and preprocessing involved converting categorical data into numerical formats, standardizing or normalizing continuous variables, and handling missing data through imputation. These steps were essential for preparing the data for the machine-learning algorithms and ensuring the reliability and accuracy of the models.",
  "optimization/parameters": "In our study, we utilized several input parameters to build and evaluate our machine learning models for predicting outcomes in patients with intracerebral hemorrhage (ICH). The key parameters included time to operating room (TOR), midline shift, Glasgow coma scale (GCS), systolic blood pressure (SBP), diastolic blood pressure (DBP), hematoma volume, and the presence of diabetes. These variables were selected based on their clinical relevance and significance in previous studies.\n\nThe selection of these parameters was driven by both statistical analysis and clinical expertise. Initially, we identified variables that showed significant differences between patients with favorable and unfavorable outcomes. For instance, variables like diabetes, SBP, DBP, GCS, midline shift, and hematoma volume exhibited statistically significant differences between the two outcome groups. Additionally, continuous data such as TOR were categorized into meaningful intervals (<12 hours, \u226512 and \u226436 hours, and >36 hours) to better understand their impact on patient outcomes.\n\nThe importance of each variable was further assessed using machine learning models. For the Support Vector Machine (SVM) and Logistic Regression (LR) models, TOR emerged as the most significant variable. In contrast, the Decision Tree C5.0 and Artificial Neural Network (ANN) models highlighted midline shift, GCS, SBP, and DBP as critical factors. This multifaceted approach ensured that our models incorporated a comprehensive set of parameters, enhancing their predictive accuracy and reliability.\n\nIn summary, the selection of input parameters was a meticulous process that combined statistical rigor with clinical insights, resulting in a robust set of variables for our machine learning models.",
  "optimization/features": "In our study, we utilized several clinical variables as input features for our machine learning models. The specific features included time to operating room (TOR), midline shift, Glasgow coma scale (GCS), systolic blood pressure (SBP), diastolic blood pressure (DBP), diabetes, and hematoma volume.\n\nFeature selection was implicitly performed by evaluating the importance of each variable within the different models. For instance, in the Support Vector Machine (SVM) and Logistic Regression (LR) models, the time to operating room (TOR) was identified as the most significant variable. In contrast, the Decision Tree C5.0 and Artificial Neural Network (ANN) models highlighted midline shift, GCS, SBP, and DBP as crucial factors.\n\nThe importance values were determined using the training data, ensuring that the feature selection process was confined to the training set only. This approach helped in identifying the most relevant variables for predicting outcomes, thereby enhancing the models' predictive performance.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "Not applicable",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models we developed, including the Support Vector Machine (SVM), Decision Tree C5.0, Artificial Neural Network (ANN), and Logistic Regression (LR), vary in their levels of interpretability. The Decision Tree C5.0 model is particularly transparent, as it provides a clear, rule-based structure that can be easily interpreted. The rules derived from the training data directly indicate how different variables influence the predictions, making it straightforward to understand the decision-making process.\n\nThe Logistic Regression model is also relatively transparent. It provides coefficients for each variable, indicating their relative importance and the direction of their influence on the outcome. This allows for a clear interpretation of how changes in each variable affect the predicted probability of an unfavorable outcome.\n\nIn contrast, the SVM and ANN models are more black-box in nature. While they can provide high predictive accuracy, the internal workings of these models are less interpretable. For the SVM, the decision boundaries are defined by support vectors, which are not easily understandable without additional analysis. Similarly, the ANN model consists of layers of interconnected nodes, making it difficult to trace the exact path of how inputs lead to outputs.\n\nHowever, we did analyze the variable importance values across all models. For the SVM and LR models, the time to operating room (TOR) was found to be significantly more important than other variables. This insight helps in understanding that TOR plays a crucial role in predicting outcomes, even if the exact mechanisms within the SVM and ANN models are not transparent. For the Decision Tree C5.0 and ANN models, variables like midline shift, Glasgow Coma Scale (GCS), systolic blood pressure (SBP), and diastolic blood pressure (DBP) were also identified as important, providing some level of interpretability within these models.\n\nIn summary, while the Decision Tree C5.0 and Logistic Regression models offer clear interpretability, the SVM and ANN models are more opaque. However, by examining variable importance, we can gain some insights into the factors driving the predictions, even in the more complex models.",
  "model/output": "The models developed in this study are primarily classification models. They are designed to predict the outcome of spontaneous intracerebral hemorrhage (ICH) as either favorable or unfavorable. Specifically, four different machine learning models were employed: Support Vector Machine (SVM), Decision Tree C5.0, Artificial Neural Network (ANN), and Logistic Regression (LR). Each of these models was trained to classify patients into one of two outcome categories based on various clinical variables.\n\nThe performance of these models was evaluated using several metrics, including the area under the receiver operating characteristic curve (AUC), accuracy, specificity, sensitivity, positive likelihood ratio (PLR), negative likelihood ratio (NLR), and diagnostic odds ratio (DOR). The SVM model demonstrated the best comprehensive prediction efficiency among the four models, with an AUC of 0.91, accuracy of 0.92, specificity of 0.92, and sensitivity of 0.93.\n\nThe importance of different variables in predicting outcomes varied across the models. For the SVM and LR models, the time to operating room (TOR) was found to be significantly more important than other variables. In contrast, the Decision Tree C5.0 and ANN models highlighted midline shift, Glasgow Coma Scale (GCS), systolic blood pressure (SBP), and diastolic blood pressure (DBP) as key factors, with TOR also playing a notable role.\n\nThese classification models aim to identify patterns and relationships within the data that can accurately predict patient outcomes, thereby aiding in clinical decision-making and potentially improving treatment strategies for ICH patients.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, the evaluation of the machine learning models was conducted using several key metrics to assess their performance in predicting outcomes for patients with spontaneous intracerebral hemorrhage (ICH). The primary metric used was the area under the receiver operating characteristic curve (AUC), which provides a measure of the model's ability to distinguish between favorable and unfavorable outcomes. Additionally, we calculated specificity, sensitivity, accuracy, positive likelihood ratio (PLR), negative likelihood ratio (NLR), and diagnostic odds ratio (DOR) to provide a comprehensive evaluation of each model's predictive efficiency.\n\nThe models evaluated included Support Vector Machine (SVM), Decision Tree C5.0, Artificial Neural Network (ANN), and Logistic Regression (LR). Each model's performance was assessed using these metrics, allowing for a direct comparison of their predictive capabilities. The SVM model was found to achieve the best comprehensive prediction efficiency, with an AUC of 0.91, indicating strong discriminative power. The specificity, sensitivity, and accuracy of the SVM model were also high, further supporting its effectiveness in predicting ICH outcomes.\n\nThe evaluation process involved statistical analysis using IBM SPSS Statistics 26 for categorical and continuous data. Categorical data were expressed as percentages, while continuous data were presented as means with standard deviations. Comparisons between groups were made using the t-test or Mann-Whitney U test for categorical data and Fisher\u2019s exact tests or the chi-square test for continuous variables. A p-value of less than 0.05 was considered statistically significant, ensuring the reliability of the results.\n\nThe importance of various variables in the models was also analyzed. For the SVM and LR models, the time to operating room (TOR) was found to have a significantly higher importance value compared to other variables. This indicates that TOR is a critical factor in predicting ICH outcomes. In the Decision Tree C5.0 model, the sequence of importance values included midline shift, Glasgow coma scale (GCS), systolic blood pressure (SBP), and TOR. Similarly, the ANN model highlighted midline shift, TOR, diastolic blood pressure (DBP), and SBP as key variables.\n\nOverall, the evaluation method involved a rigorous statistical analysis and comparison of multiple metrics to ensure the reliability and validity of the models' predictive capabilities. The SVM model emerged as the most effective in predicting ICH outcomes, with TOR being a crucial factor in its predictive power.",
  "evaluation/measure": "In our study, we evaluated the performance of four machine learning models\u2014Support Vector Machine (SVM), Decision Tree C5.0, Artificial Neural Network (ANN), and Logistic Regression (LR)\u2014using a comprehensive set of metrics. These metrics included the area under the receiver operating characteristic curve (AUC), accuracy, specificity, sensitivity, positive likelihood ratio (PLR), negative likelihood ratio (NLR), and diagnostic odds ratio (DOR).\n\nThe AUC provides a measure of the model's ability to distinguish between positive and negative classes, with higher values indicating better performance. Accuracy reflects the proportion of true results (both true positives and true negatives) among the total number of cases examined. Specificity measures the true negative rate, while sensitivity measures the true positive rate. The PLR and NLR offer insights into how much a positive or negative test result will change the odds of having the condition. Finally, the DOR combines the PLR and NLR to provide a single measure of the effectiveness of the diagnostic test.\n\nThese metrics are widely recognized and used in the literature for evaluating the performance of machine learning models, particularly in medical and diagnostic contexts. They provide a robust and representative assessment of model performance, ensuring that our findings are comparable with other studies in the field. By reporting these metrics, we aim to offer a clear and comprehensive understanding of the predictive capabilities of each model, facilitating informed decision-making and further research.",
  "evaluation/comparison": "In our study, we did not perform a comparison to publicly available methods on benchmark datasets. Instead, we focused on evaluating the performance of four different machine learning models\u2014Support Vector Machine (SVM), Decision Tree C5.0, Artificial Neural Network (ANN), and Logistic Regression (LR)\u2014in predicting outcomes for patients with intracerebral hemorrhage (ICH).\n\nWe assessed each model's performance using several metrics, including the area under the receiver operating characteristic curve (AUC), accuracy, specificity, sensitivity, positive likelihood ratio (PLR), negative likelihood ratio (NLR), and diagnostic odds ratio (DOR). The SVM model demonstrated the best comprehensive prediction efficiency, with an AUC of 0.91, accuracy of 0.92, specificity of 0.92, and sensitivity of 0.93. The Decision Tree C5.0 model also showed strong performance with an AUC of 0.96, while the ANN and LR models had AUCs of 0.91 and 0.77, respectively.\n\nIn terms of simpler baselines, we did not explicitly compare our models to simpler baselines such as mean or median predictors. However, the evaluation metrics we used provide a clear indication of how well each model performs in predicting patient outcomes. The SVM model's superior performance suggests that it is a robust choice for this type of prediction task. The variable importance analysis further highlighted that the time to operating room (TOR) was a significant factor in the SVM and LR models, indicating its critical role in outcome prediction.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe performance metrics presented in this study include the area under the receiver operating characteristic curve (AUC), accuracy, specificity, sensitivity, positive likelihood ratio (PLR), negative likelihood ratio (NLR), and diagnostic odds ratio (DOR). These metrics were calculated for four different machine learning models: Support Vector Machine (SVM), Decision Tree C5.0, Artificial Neural Network (ANN), and Logistic Regression (LR).\n\nStatistical significance was determined using a p-value threshold of less than 0.05. This threshold was applied to various comparisons, including the differences in characteristics between patient groups and the performance of the machine learning models. For instance, significant differences were found in variables such as diabetes, systolic blood pressure (SBP), diastolic blood pressure (DBP), Glasgow coma scale (GCS), midline shift, and hematoma volume between the favorable and unfavorable outcome groups.\n\nThe SVM model demonstrated the highest comprehensive prediction efficiency, with an AUC of 0.91, accuracy of 0.92, specificity of 0.92, and sensitivity of 0.93. These metrics, along with the PLR, NLR, and DOR, indicate that the SVM model performed significantly better than the other models in predicting outcomes. The Decision Tree C5.0 model also showed strong performance with an AUC of 0.96, but its accuracy, specificity, and sensitivity were slightly lower than those of the SVM model.\n\nThe importance values of variables were also analyzed, with the time to operating room (TOR) being significantly more important in the SVM and LR models compared to other variables. This suggests that TOR is a critical factor in predicting outcomes, and its significance is statistically supported.\n\nIn summary, the performance metrics are robust and statistically significant, providing confidence in the superiority of the SVM model over the other models and baselines. The use of a p-value threshold ensures that the results are reliable and that the conclusions drawn are supported by strong statistical evidence.",
  "evaluation/availability": "Not applicable."
}