{
  "publication/title": "Identification of predictors and model for predicting prolonged length of stay in dengue patients",
  "publication/authors": "The authors who contributed to the article are:\n\nMd. Shahid Ansari, Dinesh Jain, Haripriya Harikumar, Santu Rana, Sunil Gupta, Sandeep Budhiraja, and Svetha Venkatesh.\n\nMd. Shahid Ansari, Dinesh Jain, and Haripriya Harikumar were the main contributors to the paper. Dinesh Jain is associated with the Department of Clinical Data Analytics at Max Super Specialty Hospital in New Delhi, India. Haripriya Harikumar is affiliated with the Applied Artificial Intelligence Institute and the Institute for Health Transformation at Deakin University in Geelong, VIC, Australia. Santu Rana, Sunil Gupta, and Sandeep Budhiraja are also associated with Max Super Specialty Hospital, with Sunil Gupta and Sandeep Budhiraja being part of the Department of Internal Medicine. Svetha Venkatesh is affiliated with the Applied Artificial Intelligence Institute at Deakin University.",
  "publication/journal": "Health Care Management Science",
  "publication/year": "2021",
  "publication/pmid": "34389924",
  "publication/pmcid": "PMC8363490",
  "publication/doi": "https://doi.org/10.1007/s10729-021-09571-3",
  "publication/tags": "- Patient\u2019s length of stay (LOS)\n- Dengue\n- Predictive models\n- Healthcare\n- Elastic-net\n- Random forest\n- Hospital resource management\n- Dengue patient care\n- Data mining in healthcare\n- Machine learning in medicine\n- Dengue diagnosis\n- Dengue treatment\n- Dengue prevention\n- Dengue control\n- Dengue epidemiology\n- Dengue patient outcomes\n- Dengue patient risk factors\n- Dengue patient management",
  "dataset/provenance": "The dataset used in this study was sourced from patients hospitalized under the department of Internal Medicine between February 2012 and September 2017 at Max group of hospitals in India. The cohort initially included 1360 patients diagnosed with dengue disease. However, the final dataset consisted of 1148 microbiologically confirmed dengue patients. These patients were confirmed using either the NS-1 antigen test for those presenting within 5 days of disease onset or the dengue serum immunoglobulin M test for those presenting after 5 days.\n\nThe dataset was constructed in three phases. The first phase involved extracting demographic and confirmed dengue diagnosis information. The second phase focused on gathering administrative and investigation data. The third phase collected radiological, procedure, and clinical-related data. The final dataset, used for predicting hospital length of stay (LOS) for dengue patients, excluded 212 patients due to the unavailability of platelet count test information.\n\nThe dataset contains a mix of demographic, administrative, investigation, and radiological characteristic features, including both categorical and numerical values. These features were selected to predict the length of stay in the hospital for dengue patients. The dataset is comprehensive, covering various aspects of patient information recorded during hospitalization.",
  "dataset/splits": "The dataset used in this study consists of a single split containing 1148 data points. This dataset includes demographic, administrative, investigation, and radiological characteristic features with both categorical and numerical values. The data points represent patients with serologically confirmed dengue infection, recorded from February 2012 to September 2017. The dataset was used to build predictive models for length of stay (LOS) in hospital, with LOS values binned into two classes: those with stays of 5 days or fewer, and those with stays longer than 5 days. The most frequent LOS is 4 days, while the least frequent is 1 day. The median LOS in the dataset is 4.03 days.",
  "dataset/redundancy": "The dataset was split into two subsets after the feature engineering process. The split was random, with 70% of the data allocated to the training set and 30% to the testing set. This division ensures that the training and test sets are independent, which is crucial for evaluating the performance of predictive models.\n\nTo enforce independence, the dataset was randomly shuffled before splitting. This randomization helps to mitigate any potential biases that might arise from the order of the data. By ensuring that the training and test sets are independent, we can more confidently assess the generalizability of our models to new, unseen data.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the medical field. The dataset includes a comprehensive range of features, such as demographic, administrative, investigation, and radiological characteristics. These features were carefully selected and engineered to improve the interpretability and predictive power of the models. The dataset also addresses the issue of missing values through a systematic imputation process, which enhances the quality and reliability of the data.\n\nThe target feature, length of stay (LOS), was binned into two classes: \u22645 days and >5 days. This binning is based on the observation that patients with dengue infection typically have an average hospital stay between 3 and 5 days. The most frequent LOS is 4 days, which aligns with the median LOS in the dataset. This binning strategy helps in building robust predictive models that can identify patients who are at risk of prolonged hospitalization and may require early aggressive intervention.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in this study falls under the category of ensemble learning and regularized regression techniques. Specifically, two primary machine-learning algorithms were utilized: logistic regression with elastic-net regularization and random forest.\n\nLogistic regression with elastic-net is a well-established method in the field of machine learning and statistics. It combines the penalties of L1 (lasso) and L2 (ridge) regularization to achieve both sparsity and stability in the model coefficients. This approach helps in handling multicollinearity and preventing overfitting, making it suitable for high-dimensional data.\n\nRandom forest is another widely used ensemble learning method. It constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees. This algorithm is known for its robustness and ability to handle large datasets with high dimensionality.\n\nNeither of these algorithms is new; they have been extensively studied and applied in various domains. The choice of these algorithms was driven by their proven effectiveness in predictive modeling and their ability to handle the complexities of the dataset, which includes a significant amount of missing data and a large number of features.\n\nThe algorithms were implemented using established libraries in R, specifically `glmnet` for logistic regression with elastic-net and `caret` for random forest. These libraries are well-documented and widely used in the machine learning community, ensuring reliability and reproducibility of the results.\n\nThe decision to use these algorithms was based on their ability to provide accurate predictions and their interpretability, which is crucial for clinical applications. The logistic regression model with elastic-net was found to perform better in predicting prolonged length of stay (LOS) for dengue patients, with an AUC of 0.75. This model was chosen for its balance between simplicity and performance, making it suitable for real-time feedback in clinical settings.",
  "optimization/meta": "Not applicable. The models used in the study are logistic regression with elastic-net and random forest, which are standalone machine-learning algorithms. There is no indication that a meta-predictor, which combines the outputs of multiple machine-learning algorithms, was employed. The study focuses on these two individual models and their performance in predicting the length of stay for dengue patients. The training data for these models was split into a training set (70%) and a testing set (30%), with 10-fold cross-validation used for fine-tuning the model parameters on the training dataset. This ensures that the training data is independent for each fold, but it does not involve combining multiple machine-learning methods into a meta-predictor.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to prepare the dataset for machine learning algorithms. Initially, we collected a wide range of predictors, including demographic information, admission type, investigation data, blood transfusion details, assisted ventilation, and radiological findings for dengue patients over the first 24 hours of hospitalization. These predictors were then transformed into categorical variables to enhance interpretability.\n\nFor laboratory measurements, we used standard reference ranges provided by the Max healthcare system to encode the data. Each measurement was categorized as 'normal', 'low', or 'high' based on these reference ranges. For example, hematocrit levels were classified as normal if they fell within specific ranges for men and women, low if below these ranges, and high if above. This approach was applied to various other laboratory features such as hemoglobin, total leucocyte count (TLC), lymphocytes, monocytes, neutrophils, eosinophils, and more.\n\nDemographic and clinical variables were also encoded into binary categories. For instance, gender was encoded as 1 for male and 0 for female. Age was divided into several bins, each represented by a binary variable (e.g., 1 for ages 0-10, else 0). Similarly, marital status, address, channel of admission, type of admission, and previous admission status were all converted into binary variables.\n\nTo handle missing data, we employed a three-step imputation process. Features with more than 50% missing values, such as PT, APTT, and basophils, were removed as they were deemed ineffective for analysis. For continuous features with less than 50% missing values, median imputation was used to replace missing values, addressing issues of non-normality and outliers. Regression imputation was applied to nominal and ordinal features, using a model with a high test AUC score to ensure the reliability of the imputed values.\n\nAfter preprocessing, the dataset was split into a training set (70%) and a testing set (30%). This split ensured that the model could be trained on a substantial portion of the data while still having a robust testing set to evaluate its performance. The final dataset included 389 independent variables and one dependent variable, encompassing administrative, demographic, pathology, radiology, and procedure-related features. This comprehensive encoding and preprocessing pipeline enabled us to build robust predictive models for length of stay (LOS) in dengue patients.",
  "optimization/parameters": "In our study, we initially collected 40 predictors using the available data for 24 hours of hospitalization. These predictors included various factors such as age, admission type, investigation data, blood transfusion, assisted ventilation, and radiological predictors related to dengue patients. Through feature engineering, we generated new features from these predictors, resulting in a total of 389 independent variables. However, not all of these variables were used in the final model.\n\nTo select the most relevant attributes, we employed several techniques, including information value, variable importance using random forest, recursive feature elimination using logistic regression, chi-square, and L1 feature selection methods. Each technique voted on whether to select a variable, and the variables with the highest votes were used in the modeling process. This approach ensured that only the most significant predictors were included in the final model.\n\nThe final number of parameters (p) used in the model was determined through this feature selection process. We did not specify an exact number of parameters, as the selection was data-driven and based on the votes from multiple feature selection techniques. This method allowed us to identify the most important features influencing the length of stay (LOS) for dengue patients, ensuring that our model was both efficient and effective.",
  "optimization/features": "In the optimization process, we initially collected 40 predictors using the available data for 24 hours of hospitalization. These predictors included demographic details such as age and gender, administrative data like type of admission, and clinical features including blood transfusion, assisted ventilation, and various laboratory and radiological measurements related to dengue patients.\n\nFeature engineering was then performed to generate new features from these predictors. For laboratory data, we used the standard lab reference range provided by Max healthcare system and coded them based on whether the values were below, within, or above the reference range. Other features were categorized into binary variables. This process resulted in a total of 389 independent variables and one dependent variable, encompassing administrative, demographic, pathology, radiology, and procedure-related data.\n\nFeature selection was performed to identify the most relevant attributes. We employed various techniques, including information value, variable importance using random forest, recursive feature elimination using logistic regression, chi-square, and L1 feature selection methods. Each technique voted on whether to select a variable, and the variables with higher votes were used in the modeling process. This ensured that only the most relevant features were included, enhancing the model's predictive performance.\n\nThe final dataset was then randomly split into two subsets: a training set (70%) and a testing set (30%). This split ensured that the feature selection process was performed using the training set only, maintaining the integrity of the testing data for unbiased evaluation.",
  "optimization/fitting": "In our study, we employed logistic regression with elastic-net regularization and random forest algorithms to predict the length of stay (LOS) for dengue patients. The number of parameters in our models was indeed larger than the number of training points, which is a common scenario in medical datasets due to the high dimensionality of features.\n\nTo address the risk of overfitting, we utilized regularization techniques. For the logistic regression model, elastic-net regularization was applied, which combines L1 and L2 penalties. This approach helps in sparsifying the weight vectors (L1 regularization) and limiting the weight values to protect against outliers (L2 regularization), thereby finding a stable and sparse weight vector. Additionally, we performed a grid search over 100 values for the regularization parameters \u03bb1 and \u03bb2, selecting the best combination with the lowest cross-validation error. This process ensured that our model generalized well to unseen data.\n\nFor the random forest model, we employed 10-fold cross-validation over 10 combinations of hyperparameter values, including the number of decision trees and the number of features. This method helps in selecting the optimal hyperparameters that minimize overfitting. We also set default values for other algorithm parameters, such as the number of trees (100), the Gini index for splitting, and the minimal number of observations required for forming terminal nodes (five). These settings, combined with cross-validation, helped in mitigating overfitting.\n\nTo rule out underfitting, we ensured that our models were complex enough to capture the underlying patterns in the data. For the logistic regression model, the elastic-net regularization allowed for a flexible combination of L1 and L2 penalties, enabling the model to adapt to the data's structure. For the random forest model, the use of multiple decision trees and the selection of an appropriate number of features at each split helped in capturing the complexity of the data.\n\nIn summary, we addressed the challenges of overfitting and underfitting through the use of regularization techniques, cross-validation, and careful selection of hyperparameters. These methods ensured that our models were robust and generalizable to new data.",
  "optimization/regularization": "In our study, we employed regularization techniques to prevent overfitting in our logistic regression model. Specifically, we used the elastic-net method, which combines both L1 and L2 regularization. L1 regularization, also known as lasso, helps in sparsifying the weight vectors by driving some coefficients to zero, effectively performing feature selection. L2 regularization, or ridge regression, limits the weight values to protect against outliers and ensures that the model generalizes well to unseen data. By linearly combining these two penalties, elastic-net can find a stable and sparse weight vector, thereby enhancing the model's predictive performance and reducing the risk of overfitting. This approach was crucial in handling the high-dimensional nature of our dataset and ensuring that our model remained robust and generalizable.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule for our models are detailed within the publication. Specifically, for the logistic regression with elastic-net, we conducted a grid search over 100 values for different combinations of \u03bb1 and \u03bb2, selecting the best parameters based on the lowest cross-validation error. For the random forest model, we performed 10-fold cross-validation over 10 combinations of hyperparameters, including the number of decision trees and the number of features. The default values for the random forest algorithm were set as follows: 100 trees, Gini index for splitting and computing variable importance, a minimum of five observations required for forming terminal nodes, and the square root of the number of variables used to split each node.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the algorithms were executed using R, with the glmnet library for logistic regression with elastic-net and the caret library for the random forest algorithm. These libraries are open-source and freely available, allowing for reproducibility of the models. The specific configurations and parameters used in our experiments can be inferred from the descriptions provided in the methods section.\n\nThe data used for training and testing the models is not made publicly available due to privacy and confidentiality concerns. However, the methods and techniques described in the publication can be replicated using similar datasets. The performance measures and results are thoroughly documented, providing a clear understanding of the models' effectiveness in predicting prolonged length of stay for dengue patients.",
  "model/interpretability": "The models employed in our study, namely logistic regression with elastic-net and random forest, offer varying degrees of interpretability. The logistic regression model with elastic-net regularization is relatively transparent. This model provides clear insights into the importance of different features by assigning coefficients to each variable. Positive coefficients indicate risky features, while negative coefficients signify safe features. For instance, haematocrit levels, both low and high, are identified as significant factors influencing the length of stay (LOS) for dengue patients. Specifically, haematocrit values below 40% and above 50% for men, and below 36% and above 46% for women, are associated with increased mean LOS. Additionally, low lymphocyte counts and previous admissions are highlighted as risk factors for prolonged LOS.\n\nIn contrast, the random forest model, while powerful in predictive performance, is more of a black-box model. It operates by constructing multiple decision trees, each contributing to the final prediction. Although it provides variable importance scores, these scores do not offer the same level of interpretability as the coefficients in the logistic regression model. The random forest model identifies the top 18 important variables, but the relationships between these variables and the outcome are less straightforward to interpret.\n\nOverall, the logistic regression with elastic-net model is more interpretable, making it easier for clinicians to understand the underlying factors influencing LOS. This transparency is crucial for practical applications, as it allows for targeted interventions and resource allocation based on clear, actionable insights.",
  "model/output": "The model developed in our study is a classification model. It is designed to predict whether a dengue patient will have a prolonged length of stay (LOS) in the hospital, specifically more than 5 days. The output of the model is a probability of prolonged LOS, which is then used to classify patients into two categories: those likely to have a prolonged stay and those not likely to have a prolonged stay.\n\nThe logistic regression with elastic-net and random forest models were used to achieve this classification. The logistic regression model with elastic-net regularization was found to be the best fit, with an area under the curve (AUC) of 0.75. This indicates that the model has a good ability to distinguish between patients who will have a prolonged LOS and those who will not.\n\nThe performance of the model was evaluated using several metrics, including sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). The model's performance was assessed on a test dataset consisting of 30% of the total data, which included 345 records.\n\nThe output of the model can be used to provide real-time feedback to clinicians, helping them to plan preventive interventions and manage hospital resources more efficiently. By identifying high-risk patients early, the model can aid in reducing the length of stay for dengue patients, potentially leading to improved health services and better resource allocation.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the models used in this study is not publicly released. However, the algorithms were executed using R, an open-source software application for statistical computing and data mining. The specific libraries used were glmnet for logistic regression with elastic-net and caret for the random forest algorithm. These libraries are publicly available and can be accessed through the Comprehensive R Archive Network (CRAN). The glmnet package is licensed under the GPL-2 | GPL-3 license, while the caret package is licensed under the GPL-3 license. While the exact implementations used in this study are not available, researchers can utilize these libraries to replicate the methods described in the paper.",
  "evaluation/method": "The evaluation method employed for our study involved a comprehensive approach to ensure the robustness and generalizability of our predictive models. We utilized a 70-30 split of the dataset, where 70% of the data was allocated for training the models, and the remaining 30% was reserved for testing their performance. This split allowed us to assess how well the models generalize to unseen data.\n\nFor fine-tuning the model parameters, we implemented 10-fold cross-validation on the training dataset. This process involved dividing the training data into ten folds, using nine folds to train the model and the remaining fold to evaluate its performance. This procedure was repeated ten times, with each fold serving as the validation set once, ensuring that every data point was used for both training and validation.\n\nTo evaluate the performance of our models, we assessed several key metrics. These included sensitivity or recall, precision or positive predictive value (PPV), and the area under the receiver operating characteristic curve (AUC). These metrics were derived from the confusion matrix, which includes true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN). Sensitivity, or recall, measures the proportion of actual positives correctly identified by the model. Precision, or PPV, indicates the proportion of predicted positives that are actually correct. The AUC provides a single scalar value that summarizes the performance of the model across all classification thresholds.\n\nAdditionally, we used statistical tests to determine significant differences between groups. The Kruskal-Wallis H test was employed to check for statistically significant differences between two or more groups of an independent variable on a continuous dependent variable. For categorical variables, the Chi-square test was used when expected frequencies were higher than 5, while Fisher\u2019s exact test was applied when expected table values were smaller than 5. A p-value of less than 0.05 was considered statistically significant.\n\nThe results were summarized using means \u00b1 standard deviation and median \u00b1 interquartile range (IQR) for continuous features. This detailed evaluation method ensured that our models were thoroughly tested and validated, providing reliable insights into their predictive performance.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to assess the effectiveness of our predictive models. These metrics include sensitivity or recall, precision or positive predictive value (PPV), and the area under the receiver operating characteristic curve (AUC). These measures are widely used in the literature and provide a comprehensive view of model performance.\n\nSensitivity, also known as recall, measures the proportion of actual positives that are correctly identified by the model. Precision, or PPV, indicates the proportion of predicted positives that are actually positive. Both metrics are crucial for understanding the model's ability to correctly identify positive cases and to minimize false positives.\n\nThe AUC is a single scalar value that summarizes the performance of the model across all classification thresholds. It provides an aggregate measure of performance across all possible classification thresholds, making it a robust metric for comparing different models.\n\nAdditionally, we computed the negative predictive value (NPV) and specificity. NPV measures the proportion of actual negatives that are correctly identified, while specificity measures the proportion of actual negatives that are correctly identified as such. These metrics are essential for understanding the model's performance in identifying negative cases and minimizing false negatives.\n\nWe used traditional performance measures based on the confusion matrix, which includes true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN). These values are used to compute PPV, NPV, sensitivity, and specificity, providing a detailed view of the model's performance.\n\nIn summary, our set of performance metrics is representative of standard practices in the field. These metrics allow for a thorough evaluation of model performance, ensuring that our models are robust and reliable for predicting prolonged hospital stays among dengue patients.",
  "evaluation/comparison": "In our evaluation, we compared several predictive models to assess their performance in predicting prolonged length of stay (LOS) for dengue hospitalization. We employed logistic regression with elastic-net regularization, random forest, and other methods like support vector machine (SVM) and extraTrees. However, SVM and extraTrees were excluded due to their unsatisfactory predictive performance.\n\nThe logistic regression model with elastic-net regularization was chosen for its ability to handle high-dimensional data and perform both variable selection and regularization. This method combines L1 and L2 penalties to achieve sparsity and stability in the weight vectors, making it robust against outliers.\n\nRandom forest, an ensemble of multiple decision trees, was also utilized. This method involves constructing individual decision trees from bootstrap samples of the data, using only a subset of predictors at each node. The random forest model was tuned via 10-fold cross-validation over various hyperparameter values, including the number of decision trees and the number of features.\n\nFor evaluation, we used traditional performance measures based on the confusion matrix, including sensitivity, precision, and the area under the receiver operating characteristic curve (AUC). These metrics provided a comprehensive assessment of each model's predictive accuracy and reliability.\n\nIn summary, while we did not compare our methods to publicly available benchmark datasets, we did perform a thorough comparison of different predictive models and baselines within our study. This approach allowed us to identify the most effective model for predicting prolonged LOS in dengue patients.",
  "evaluation/confidence": "In our evaluation, we determined statistically significant differences using a p-value threshold of less than 0.05. This threshold was applied to various statistical tests, including the Kruskal-Wallis H test for continuous dependent variables and the Chi-square test or Fisher\u2019s exact test for categorical variables, depending on the expected frequencies.\n\nFor the performance measures of our models, we assessed sensitivity, precision, and the area under the receiver operating characteristic curve (AUC). The AUC values for our models were reported as point estimates. However, confidence intervals for these performance metrics were not explicitly provided in the main text. The results indicated that the logistic regression model with elastic-net achieved an AUC of 0.75, while the random forest model had an AUC of 0.72. These values suggest that the logistic regression model with elastic-net has a good ability to predict prolonged hospitalization among dengue patients.\n\nThe statistical significance of the differences between the models was not explicitly stated in terms of confidence intervals for the performance metrics. However, the use of a p-value threshold of less than 0.05 for determining statistically significant differences in other parts of the analysis implies a rigorous approach to evaluating the significance of the results. The performance measures were calculated based on traditional classification metrics derived from the confusion matrix, ensuring a comprehensive evaluation of the models' predictive capabilities.",
  "evaluation/availability": "Not applicable"
}