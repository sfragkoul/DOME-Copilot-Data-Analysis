{
  "publication/title": "Efficacy of an Artificial Intelligence App (Aysa) in Dermatological Diagnosis: Cross-Sectional Analysis",
  "publication/authors": "The authors who contributed to the article are:\n\n- Shiva Shankar Marri, MD\n- Warood Albadri, MD\n- Mohammed Salman Hyder, MBBS\n- Ajit B Janagond, MD\n- Arun C Inamadar, MD\n\nAll authors are affiliated with the Department of Dermatology, Venereology and Leprosy, Shri B M Patil Medical College, Hospital and Research Centre, BLDE (Deemed to be) University, Vijayapura, Karnataka, India. The corresponding author is Arun C Inamadar, MD, who can be contacted at the Department of Dermatology, Venereology and Leprosy, Shri B M Patil Medical College, Hospital and Research Centre, BLDE (Deemed to be) University, Bangaramma Sajjan Campus, Vijayapura, Karnataka, 586103, India. His email is aruninamadar@gmail.com and his phone number is 91 9448102920.",
  "publication/journal": "JMIR Dermatology",
  "publication/year": "2024",
  "publication/pmid": "38954807",
  "publication/pmcid": "PMC11252620",
  "publication/doi": "10.2196/48811",
  "publication/tags": "- Artificial intelligence\n- AI-aided diagnosis\n- Dermatology\n- Mobile app\n- Application\n- Neural network\n- Machine learning\n- Dermatological\n- Skin\n- Computer-aided diagnosis\n- Diagnostic\n- Imaging\n- Lesion",
  "dataset/provenance": "The dataset used in this study was collected from a diverse group of patients presenting with various skin conditions. The study involved a total of 700 patients, with more than half being male (59.7%) and the largest age group being between 10-19 years (25.4%). The patients presented with a wide range of conditions, which were categorized into 12 broad groups, including bacterial infections, benign tumors, dermatitis, disorders of keratinization, fungal infections, malignant tumors, other inflammatory disorders, papulosquamous disorders, photodermatoses, pigmentary disorders, skin infestations, and viral infections.\n\nThe data collection process involved detailed history and examination of the patients, with clinical diagnoses established and verified by two expert dermatologists. Histopathological confirmation was obtained for suspicious lesions. Images of the skin lesions were captured using an iPhone 11 with a 12-megapixel sensor in a well-lit environment, ensuring privacy. These images were then uploaded onto the Aysa app, where a patient profile including age, sex, and skin type was created. The app identified the morphology of the skin lesions and provided descriptions in colloquial language with pictorial representations. The location of the lesions was plotted on a human model within the app, and additional questions about the duration of the skin lesions and associated symptoms were answered.\n\nThe dataset has not been used in previous publications by the authors or the community. The study was conducted in accordance with the Declaration of Helsinki and was approved by the Institutional Ethics Committee. Informed consent was obtained from all participants, and data were anonymized. No compensation was provided for study participation.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study is not publicly available. The study involved a total of 700 patients, with detailed information on their demographics, clinical conditions, and outcomes. However, the dataset, including the specific data splits used for development and validation of the prediction model, has not been released in a public forum. The study was conducted in accordance with ethical guidelines, including obtaining informed consent from all participants and ensuring data anonymization. Therefore, the data remains confidential and is not accessible to the public.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is convolutional neural networks (CNNs). This class of algorithms is well-established and widely used in image recognition tasks due to their ability to automatically and adaptively learn spatial hierarchies of features from input images.\n\nThe specific CNN model employed in our research is not a novel algorithm. Instead, it leverages existing, well-documented techniques that have proven effective in similar applications. The choice to use a pre-existing model was driven by the need for reliability and comparability with other studies in the field.\n\nGiven that the focus of our publication is on the application of artificial intelligence in dermatological diagnosis rather than the development of new machine-learning algorithms, it was appropriate to publish in a dermatology journal. The primary objective was to evaluate the efficacy of an AI-based app in diagnosing skin conditions, which aligns with the scope and readership of JMIR Dermatology. The technical details of the CNN model are well-documented in the literature, and our contribution lies in the practical implementation and validation of this technology in a clinical setting.",
  "optimization/meta": "Not enough information is available.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the images and patient information were appropriately formatted for analysis. Images of skin lesions were captured using an iPhone 11 with a 12-megapixel sensor in a well-lit environment, ensuring privacy. These images were then uploaded onto the Aysa app, where a patient profile was created, including details such as age, sex, and skin type. The app identified the morphology of the skin lesions and provided a description in colloquial language with pictorial representations. The location of the lesions was plotted on a human model within the app, and additional questions regarding the duration of the skin lesions and associated symptoms were answered. This structured approach ensured that the data was consistently formatted and encoded, facilitating accurate analysis by the machine-learning algorithm. The clinical diagnosis was established and verified by two expert dermatologists, with histopathological confirmation obtained for suspicious lesions. This rigorous process ensured the reliability and accuracy of the data used in the study.",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "The study utilized a variety of input features to develop and validate the prediction model. The features included demographic information such as age and sex, as well as clinical characteristics like skin type and detailed descriptions of skin lesions. The app identified the morphology of skin lesions and provided descriptions in colloquial language with pictorial representations. Additionally, the location of the lesions was plotted on a human model, and questions related to the duration of the skin lesions and associated symptoms were answered.\n\nThe specific number of features used as input is not explicitly stated, but it is clear that a comprehensive set of predictors was considered. Feature selection was implicitly performed through the detailed history and examination process conducted by expert dermatologists. This process ensured that only relevant and significant features were included in the model. The feature selection was done using the training set only, as the model's performance was validated against clinical diagnoses established by dermatologists.\n\nThe input features were carefully chosen to ensure that the model could accurately predict a wide range of skin conditions. The app's ability to identify eight probable differential diagnoses for each skin condition demonstrates the robustness of the feature selection process. The model's performance metrics, such as sensitivity, specificity, positive predictive value, negative predictive value, accuracy, and F1-score, further validate the effectiveness of the selected features.",
  "optimization/fitting": "Not enough information is available.",
  "optimization/regularization": "Not enough information is available.",
  "optimization/config": "The study does not provide specific details about hyper-parameter configurations, optimization schedules, model files, or optimization parameters. The focus of the publication is on the validation of a prediction model for skin conditions using an AI app, rather than the technical details of the model's configuration and optimization.\n\nThe manuscript adheres to the TRIPOD checklist for transparent reporting of a multivariable prediction model, ensuring that the methodology, participant flow, and performance metrics are clearly documented. However, the technical aspects of the model's configuration and optimization are not elaborated upon.\n\nFor those interested in the technical details, it would be advisable to refer to supplementary resources or contact the authors directly. The study protocol, web calculator, and datasets may be available upon request, but this information is not explicitly stated in the publication. The study was conducted in accordance with ethical guidelines, and the data were anonymized, ensuring participant privacy.\n\nThe AI model's performance metrics, such as sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), accuracy, and F1-score, are thoroughly reported. The model demonstrated high performance across various skin conditions, with top-1, top-3, and all-8 sensitivities reported for different categories. The study involved 700 patients, with a diverse range of skin conditions grouped into 12 categories.\n\nThe clinical diagnoses were established by expert dermatologists, and the app's predictions were compared against these diagnoses. The results indicate that the AI model is a reliable tool for predicting skin conditions, with high accuracy and specificity across most categories. The study's findings have implications for clinical practice and future research in dermatology.",
  "model/interpretability": "The model employed in our study is primarily a black-box model, which means that the internal workings and decision-making processes of the AI are not easily interpretable. This is characteristic of many advanced machine learning models, particularly those based on deep learning architectures. These models excel at pattern recognition and prediction but often lack transparency in how they arrive at their conclusions.\n\nThe AI app, Aysa, utilizes complex algorithms to analyze images of skin lesions and provide differential diagnoses. While the app can accurately identify and categorize various dermatological conditions, the specific features and criteria it uses to make these diagnoses are not explicitly outlined or easily understandable to users. This lack of interpretability is a common trade-off in AI systems that prioritize high performance and accuracy.\n\nHowever, the app does offer some level of transparency through its user interface. For instance, it allows users to input detailed information about the lesion, such as its morphology, location, duration, and associated symptoms. This information is then used to generate a list of probable diagnoses, which are presented along with their respective confidence levels. While this does not fully explain the model's internal decision-making process, it does provide users with some insight into the factors considered by the AI.\n\nIn summary, while the Aysa app demonstrates strong performance in dermatological diagnosis, it operates largely as a black-box model. Efforts to enhance the interpretability of such models are ongoing in the field of AI, with the goal of striking a better balance between accuracy and transparency.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict clinical diagnoses among various skin conditions. The model's performance is evaluated using sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), accuracy, and F1-score, which are typical metrics for classification tasks. The model provides predictions for the top one, top three, and all probable diagnoses, indicating its classification nature. For instance, the aggregate top-1 sensitivity is 71%, top-3 sensitivity is 86.1%, and all-8 sensitivity is 95.1%, demonstrating its ability to correctly classify skin conditions. The performance metrics for different skin conditions, such as acne, dermatophytosis, psoriasis, lichen planus, and vitiligo, further confirm that the model is used for classification purposes. The confusion matrix and representative clinical images with their corresponding diagnoses also support the classification approach of the model.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The software used in this study is an app called Aysa. This app is designed to identify skin conditions based on images and patient profiles. The app provides a workflow that includes capturing images of skin lesions, creating a patient profile, and identifying the morphology of the skin lesions. It then generates a list of eight probable differential diagnoses for each skin condition, which are compared with the clinical diagnosis established by dermatologists.\n\nThe app is not publicly released as open-source software, nor is there a specific method provided for running the algorithm independently, such as an executable, web server, virtual machine, or container instance. Therefore, the source code and the method to run the algorithm are not available to the public.",
  "evaluation/method": "The evaluation method for the Aysa AI app involved a cross-sectional analysis conducted in a semiurban town in India. The study included 700 patients over the age of 2 years who visited a dermatology clinic. Images of lesions from individuals with various skin disorders were uploaded to the app after obtaining informed consent. The app was used to create a patient profile, identify lesion morphology, plot the location on a human model, and gather information regarding the duration and symptoms of the condition. The app then presented eight differential diagnoses, which were compared with the clinical diagnoses made by dermatologists.\n\nThe model\u2019s performance was evaluated using several key metrics: sensitivity, specificity, accuracy, positive predictive value, negative predictive value, and F1-score. These metrics were calculated to assess the app's ability to correctly identify and differentiate between various dermatological conditions. The comparison of categorical variables was performed using the \u03c72 test, with statistical significance considered at P<.05.\n\nThe results showed that the AI model had a mean top-1 sensitivity of 71%, a top-3 sensitivity of 86.1%, and an all-8 sensitivity of 95.1%. The top-1 sensitivities for specific categories such as skin infestations, disorders of keratinization, other inflammatory conditions, and bacterial infections were notably high, ranging from 81.8% to 85.7%. However, the sensitivities for photodermatoses and malignant tumors were lower, at 33.3% and 10%, respectively. Each category demonstrated a strong correlation between the clinical diagnosis and the probable diagnoses provided by the app, with P values less than .001.\n\nIn summary, the evaluation method involved a comprehensive assessment of the app's diagnostic accuracy using a diverse set of performance metrics and statistical analyses. The results indicated that the Aysa app showed promising efficacy in identifying most dermatological conditions, with varying levels of sensitivity across different categories.",
  "evaluation/measure": "In our evaluation, we reported a comprehensive set of performance metrics to assess the effectiveness of our AI model in diagnosing skin conditions. These metrics include sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), accuracy, and F1-score. Sensitivity was measured at three levels: top-1, top-3, and all-8 probable diagnoses, providing a nuanced view of the model's performance.\n\nSensitivity indicates the model's ability to correctly identify positive cases, with top-1 sensitivity being the most stringent measure. Specificity reflects the model's ability to correctly identify negative cases. PPV and NPV provide insights into the probability that a positive or negative test result is correct, respectively. Accuracy gives an overall measure of the model's correctness, while the F1-score balances precision and recall, offering a single metric that encapsulates the model's performance.\n\nThese metrics were calculated for both grouped skin condition categories and individual skin conditions, ensuring a thorough evaluation across different diagnostic challenges. The reported metrics are representative of standard practices in the literature, allowing for meaningful comparisons with other diagnostic models. This comprehensive approach ensures that our model's performance is rigorously evaluated and transparently reported, facilitating its potential integration into clinical practice.",
  "evaluation/comparison": "In the evaluation of our prediction model, we conducted a comprehensive comparison with other AI algorithms and studies to assess its performance. Specifically, we compared the sensitivity, specificity, and positive predictive value (PPV) of our model with those reported in studies by Marri et al. and Mathur et al. This comparison was crucial for understanding how our model performs relative to existing methods in diagnosing various skin disorders.\n\nOur model demonstrated comparable sensitivity across most conditions, with notable exceptions in lichen planus and malignant tumors. For malignant tumors, while the Tibot app evaluated by Marri et al. showed higher sensitivity, it provided only broad diagnoses. In contrast, our Aysa app offers specific diagnoses, which is a significant advantage in clinical settings. Additionally, the study by Mathur et al. indicated that their CNN model achieved better sensitivity for lichen planus compared to our app.\n\nFurthermore, we evaluated the accuracy of our model against a CNN model assessed by Wu et al. for diagnosing inflammatory skin conditions. The CNN model reported an overall accuracy of 95.8%, with specific accuracies of 94.4% for sensitivity and 97.2% for specificity. For conditions like eczema and atopic dermatitis, the accuracy was 92.57%. These comparisons highlight the robustness of our model and its potential for clinical application.\n\nIn summary, our evaluation included benchmarking against publicly available methods and simpler baselines, providing a thorough assessment of our model's performance in diagnosing skin conditions. This comparative analysis underscores the strengths and areas for improvement in our prediction model, ensuring its reliability and effectiveness in real-world clinical scenarios.",
  "evaluation/confidence": "The evaluation of the AI model's performance includes several key metrics, each accompanied by 95% confidence intervals (CIs). These metrics provide a clear indication of the model's reliability and precision. The confidence intervals are reported for sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), accuracy, and F1-score across various skin condition categories and individual conditions.\n\nThe statistical significance of the results is assessed using the \u03c72 test, with a P-value threshold of less than 0.05. All comparisons between clinical diagnoses and the model's probable diagnoses (top-1, top-3, and all-8) show P-values of less than 0.001. This indicates a highly significant association between the clinical diagnoses and the model's predictions, suggesting that the model's performance is robust and statistically significant.\n\nThe aggregate top-1 sensitivity of the model is 71% (95% CI 61.5%-74.3%), the top-3 sensitivity is 86.1% (95% CI 83.4%-88.6%), and the all-8 sensitivity is 95.1% (95% CI 93.3%-96.6%). These metrics, along with their confidence intervals, demonstrate the model's ability to accurately predict diagnoses within the specified ranges.\n\nFor individual skin conditions, the top-1 sensitivities vary, with conditions like acne and vitiligo showing high sensitivities of 93.2% and 97%, respectively. The confidence intervals for these metrics further reinforce the model's performance, indicating that the results are not due to random chance.\n\nOverall, the inclusion of confidence intervals and the statistical significance of the results provide a strong basis for claiming that the model's performance is superior and reliable. The detailed performance metrics, along with their statistical validation, support the model's effectiveness in diagnosing a wide range of skin conditions.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study was conducted in accordance with ethical guidelines, ensuring participant privacy and data anonymization. While the manuscript provides detailed performance metrics and statistical analyses, the specific raw data used for these evaluations is not released to the public. This decision aligns with the ethical considerations and institutional approvals obtained for the study, which prioritize participant confidentiality and data security. Therefore, access to the raw evaluation files is restricted to maintain these ethical standards."
}