{
  "publication/title": "Insights into Imaging",
  "publication/authors": "The authors who contributed to this article are:\n\n- LZ, who was involved in conceptualization, data curation, formal analysis, methodology, and writing.\n- TW, who contributed to conceptualization, data curation, methodology, and resources.\n- GL, who handled project administration, resources, and supervision.\n- HZ, who was responsible for funding acquisition, project administration, resources, and supervision.\n\nAll authors have read and agreed to the published version of the manuscript.",
  "publication/journal": "Insights into Imaging",
  "publication/year": "2024",
  "publication/pmid": "38517610",
  "publication/pmcid": "PMC10959883",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- 3D T1 VISTA\n- Average surface distance\n- Cerebrovascular segmentation\n- Convolutional neural network\n- Dice similarity coefficient\n- Lenticulostriate artery\n- Middle cerebral artery\n- Precision\n- Sensitivity\n- Specificity\n- Time-of-flight magnetic resonance angiography\n- Deep learning\n- MRI\n- Cerebrovascular structures\n- Segmentation workflow\n- Medical imaging\n- Radiology\n- Clinical research\n- Dataset analysis\n- Model validation",
  "dataset/provenance": "The dataset used in this study comprises two main sources. The first is the Cerebrovascular Segmentation Dataset (CSD), curated by Chen et al. This dataset is publicly accessible and includes 45 volumes of Time-of-Flight Magnetic Resonance Angiography (TOF-MRA) data. The data was obtained using a 1.5 T GE MRI scanner from the IXI dataset. Each volume in the CSD is 1024 \u00d7 1024 \u00d7 92 in size, with a spatial resolution of 0.264 mm \u00d7 0.264 mm \u00d7 0.8 mm. The dataset was meticulously labeled by multiple radiologists, each with over three years of clinical experience, ensuring accurate ground truth annotation.\n\nThe second dataset is the MCA M1 segment with Lenticulostriate Artery (LSA) dataset (MLD). This dataset was collected from 107 patients, including both outpatients and inpatients, at our hospital between 2014 and 2018. The 3D T1 VISTA images in this dataset are 480 \u00d7 480 \u00d7 140 in size, with a spatial resolution of 0.4 mm \u00d7 0.4 mm \u00d7 0.4 mm. Voxel-level labeling of the image data was performed by a radiologist with more than three years of experience using ITK-SNAP. The labeled MCA and LSA were thoroughly reviewed by another radiologist with over ten years of experience. To avoid bias, the physicians processing the data were not aware of the clinical status of the patients.\n\nThe CSD has been used in previous studies, notably by Chen et al., who proposed a 3D adversarial network model called A-SegAN. This model achieved a Dice Similarity Coefficient (DSC) of 0.864 for cerebral vessel segmentation in TOF-MRA volumes. Our approach has been validated on both TOF-MRA and 3D T1 VISTA sequences, considering the segmentation of both the entire cerebral vasculature and smaller specific vascular segments, such as the lenticulostriate arteries. On the CSD test set, our method obtained a DSC value of 0.853. On the MLD test set, the DSC is 0.766 for the Middle Cerebral Artery (MCA) and 0.562 for the Lenticulostriate Artery (LSA), surpassing previous results achieved by other methods.",
  "dataset/splits": "The dataset used in this study consists of two main datasets: the Cerebrovascular Segmentation Dataset (CSD) and the Middle Cerebral Artery M1 Segment with Lenticulostriate Artery Segmentation Dataset (MLD).\n\nFor the CSD, there are four data splits: the sum, training, validation, and test sets. The sum set contains 45 data points. The training set includes 27 data points, the validation set has 9 data points, and the test set also contains 9 data points.\n\nFor the MLD, there are also four data splits: the sum, training, validation, and test sets. The sum set contains 107 data points. The training set includes 64 data points, the validation set has 21 data points, and the test set contains 22 data points.\n\nThese splits were designed to ensure a comprehensive evaluation of the models, allowing for robust training, validation, and testing phases. The distribution of data points in each split was carefully considered to maintain the integrity and reliability of the dataset.",
  "dataset/redundancy": "The datasets used in our study were split into four subsets: sum, training, validation, and test. For the Cerebrovascular Segmentation Dataset (CSD), the split was 45/27/9/9, and for the Middle Cerebral Artery M1 Segment with Lenticulostriate Artery Segmentation Dataset (MLD), it was 107/64/21/22. The training and test sets were designed to be independent to ensure unbiased evaluation of the models. This independence was enforced by ensuring that the data used for training did not overlap with the data used for testing. The distribution of the datasets in terms of demographic variables, such as age and sex, as well as clinical characteristics, was carefully analyzed to ensure representativeness and to detect any biases or imbalances. This process involved assessing image clarity, noise levels, and the presence of artifacts, which were crucial for maintaining the integrity and reliability of the datasets. The datasets were also evaluated for the accuracy and consistency of their labels to ensure that the cerebrovascular structures of interest were correctly identified. This thorough analysis provided comprehensive insights into the characteristics, quality, and feasibility of the datasets, guiding experimenters in critical aspects of cerebrovascular segmentation. The statistical information obtained from this analysis was used to assess the variabilities in vessel size, shape, and branching patterns, which are essential for accurate segmentation. Additionally, the distribution of any pathologies within the datasets, such as areas of stenosis or aneurysms, was considered, as these features may require specialized segmentation approaches. The heterogeneity of the patient population was also assessed to ensure that the segmentation method was robust across diverse patients. This detailed analysis is vital for ensuring the reliability and applicability of the segmentation workflow in real-world scenarios.",
  "dataset/availability": "The datasets generated and analyzed during this study are not publicly available. However, they can be obtained from the corresponding author upon reasonable request. This approach ensures that the data remains confidential and is used responsibly. The decision to keep the datasets private is due to the sensitivity of medical data and the challenges associated with accessing such information. This method helps maintain the integrity and security of the data while allowing for potential future collaborations and validations.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages deep learning models, specifically convolutional neural networks (CNNs) and Transformer-based architectures. These models are well-established in the field of medical image segmentation and have been extensively used for their ability to capture intricate details and contextual information.\n\nThe models utilized include V-Net, UNETR, and SwinUNETR. V-Net employs a residual network and multiscale residual modules to enhance the capture of fine details and contextual information. UNETR, on the other hand, is a Transformer-based model that utilizes self-attention mechanisms to effectively model pixel relationships. SwinUNETR combines the Swin Transformer with UNETR, incorporating a local perceptual window to improve performance.\n\nThese models are not new but have been adapted and optimized for cerebrovascular segmentation tasks. The choice to use these models in a medical imaging context rather than a machine-learning journal is driven by the specific requirements and challenges of medical image analysis. The focus is on applying and validating these models in a clinical setting to demonstrate their practical value and reliability in segmenting cerebrovascular structures.\n\nThe training process involved using a weighted combination of dice loss and focal loss to address the imbalance between foreground and background pixels, which is a common issue in medical imaging. This approach enhances the accuracy and robustness of the segmentation results. The models were trained on a powerful workstation equipped with multiple GPUs, ensuring efficient computation and convergence.\n\nIn summary, the optimization algorithm relies on established deep learning techniques tailored for medical image segmentation. The models were chosen for their proven effectiveness in capturing detailed vascular structures, and their application in this study highlights their potential in clinical settings.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the quality and consistency of the input data for our machine-learning algorithms. The preprocessing stage involved several essential steps: denoising, smoothing, resampling, and contrast enhancement.\n\nDenoising techniques, such as median filtering, were employed to reduce image noise and minimize interference from low-quality images during segmentation. This step improved the algorithm\u2019s performance by providing cleaner input data.\n\nSmoothing operations, like Gaussian smoothing, were used to eliminate discontinuous edges in the images, yielding more continuous and recognizable blood vessel structures. This process helped in creating smoother transitions within the images, making it easier for the algorithms to identify and segment the vascular structures accurately.\n\nResampling was not necessary in our case because the images in the same dataset had the same resolution. However, if needed, resampling would ensure a standardized spatial resolution across images, reducing generalization errors caused by sampling device disparities and providing a consistent size and resolution for model learning and inference.\n\nContrast enhancement techniques, such as histogram equalization or adaptive histogram equalization, were used to improve the visibility of vascular structures in the images. Specifically, we used mean filtering, Gaussian smoothing, intensity normalization, and adaptive histogram equalization for preprocessing. These techniques enhanced the contrast, making the blood vessels more distinct and easier to segment.\n\nAdditionally, data augmentation was performed to increase the diversity and robustness of the dataset. This involved applying various geometric transformations, including image rotation, flipping, and intensity changes. These transformations were introduced with a probability of 0.1 for each image during the training process, helping to create a more robust model that could generalize better to new, unseen data.\n\nDuring the model training phase, a 192 \u00d7 192 \u00d7 64 sized image patch was cropped from the entire volume of 3D data for use as input to the models. This patch size was chosen to balance the need for detailed information and computational efficiency.\n\nTo address the significant imbalance between foreground and background pixels due to the small proportion of cerebral vessels in the images, a weighted combined variant of dice loss and focal loss was used. This approach effectively handled the foreground-background pixel imbalance, enhancing the accuracy and robustness of the cerebrovascular segmentation.",
  "optimization/parameters": "In our study, we employed four different models for cerebrovascular segmentation: U-Net, V-Net, UNETR, and SwinUNETR. Each of these models has a distinct architecture and thus a different number of parameters.\n\nU-Net, a classic convolutional neural network, is known for its encoder-decoder structure with skip connections, which helps in enhancing segmentation accuracy. The exact number of parameters in U-Net can vary based on the specific implementation, but it typically ranges around a few million parameters.\n\nV-Net utilizes a residual network and multiscale residual modules to capture fine details and contextual information. This architecture generally results in a higher number of parameters compared to U-Net, often in the tens of millions.\n\nUNETR, a transformer-based model, leverages self-attention mechanisms to model pixel relationships effectively. The number of parameters in UNETR is significantly higher due to the transformer architecture, often reaching into the hundreds of millions.\n\nSwinUNETR combines the Swin Transformer and UNETR, where the Swin Transformer is a variant of the Transformer mechanism based on a local perceptual window. This model also has a high number of parameters, similar to UNETR, due to the complex transformer components.\n\nThe selection of these models and their respective parameters was based on their proven effectiveness in medical image segmentation tasks. We chose to compare these models to evaluate their performance in handling the specific challenges of cerebrovascular segmentation, such as the imbalance between foreground and background pixels and the need for capturing fine details in the vascular structures. The models were trained and validated using a fourfold cross-validation approach, ensuring robust performance evaluation across different subsets of the data.",
  "optimization/features": "The input features for the models used in this study are derived from 3D medical imaging data. Specifically, the models process image patches of size 192 \u00d7 192 \u00d7 64, which are cropped from the entire volume of 3D data during the preprocessing stage. These patches serve as the input features for the segmentation models.\n\nFeature selection in the traditional sense was not explicitly performed. Instead, the focus was on preprocessing the data to enhance the quality and consistency of the input features. This included steps such as denoising, smoothing, resampling, and contrast enhancement. These preprocessing techniques ensure that the input features are of high quality and suitable for the segmentation task.\n\nThe preprocessing steps were applied to the entire dataset, including both the training and validation sets. This approach ensures that the models are trained and validated on consistent and high-quality data, which is crucial for achieving reliable and accurate segmentation results. The use of a sliding window during prediction further ensures that the entire image is analyzed, providing comprehensive segmentation outcomes.",
  "optimization/fitting": "The fitting method employed in our study involved several strategies to address potential overfitting and underfitting issues. Given the complexity of the models used, such as U-Net, V-Net, UNETR, and SwinUNETR, the number of parameters was indeed much larger than the number of training points. To mitigate overfitting, we implemented fourfold cross-validation. This technique ensured that each subset of the data was used for both training and validation, thereby providing a robust evaluation of the model's performance across different data distributions.\n\nAdditionally, we utilized a combination of dice loss and focal loss to handle the significant imbalance between foreground and background pixels in the cerebrovascular images. This approach helped the model to focus on hard-to-classify pixels, enhancing the segmentation accuracy and robustness.\n\nTo further expedite model convergence and reduce training time, we implemented a warmup strategy. This strategy gradually increased the learning rate from a small value, allowing the model to learn more effectively in the early stages of training.\n\nDuring the training process, we monitored the model's performance on the validation set after every five rounds of each cross-validation fold. This frequent evaluation helped in adjusting hyperparameters, such as the learning rate, network structure, or regularization parameters, based on the model's performance. By selecting the model with the best performance on the validation set, we ensured that the final model was neither overfitted nor underfitted.\n\nMoreover, we employed data augmentation techniques, including image rotation, flipping, and intensity changes, to increase the diversity and robustness of the training data. These transformations were introduced with a probability of 0.1 for each image during the training process, helping the model to generalize better to unseen data.\n\nIn summary, the combination of cross-validation, loss function optimization, warmup strategy, frequent validation, and data augmentation ensured that our models were neither overfitted nor underfitted, leading to reliable and clinically applicable segmentation results.",
  "optimization/regularization": "In our study, we implemented several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was fourfold cross-validation. This involved partitioning the data into training and test sets at an 8:2 ratio. The training set was further divided into four equal subsets, with three subsets used for training and one for validation in each iteration. This process was repeated four times, using different subsets as validation data each time. This approach helped to effectively utilize the limited dataset for training and validation, mitigating the risk of overfitting to a specific data distribution.\n\nAdditionally, we employed data augmentation techniques to increase the diversity and robustness of the dataset. This included geometric transformations such as image rotation, flipping, and intensity changes. These transformations were applied with a probability of 0.1 for each image during the training process, helping to generalize the model better.\n\nWe also used a weighted combined variant of dice loss and focal loss to address the significant imbalance between foreground and background pixels in the images. This loss function effectively handles the pixel imbalance and focuses on hard-to-classify pixels, leading to improved accuracy and robustness in cerebrovascular segmentation.\n\nFurthermore, during model training, we utilized a warmup strategy to expedite model convergence and reduce training time. This strategy helps in stabilizing the training process and prevents the model from getting stuck in poor local minima, thereby reducing the risk of overfitting.\n\nThese techniques collectively ensured that our models were robust and generalizable, reducing the likelihood of overfitting to the training data.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not publicly available. The datasets generated and analyzed during the current study are not publicly available but are available from the corresponding author on reasonable request. The study utilized a workstation with 6 RTX 3090 GPUs, 2 Intel(R) Xeon(R) Silver 4310 CPUs, and 256 GB of RAM for model training and testing. The training process employed the AdamW optimizer with an initial learning rate of 0.0001 for 400 training epochs, utilizing a batch size of 1. A warmup strategy was implemented to expedite model convergence and reduce training time. The models used were three-dimensional segmentation models, including U-Net, V-Net, UNETR, and SwinUNETR. During training, a 192 \u00d7 192 \u00d7 64 sized image patch was cropped from the entire volume of 3D data for use as input to the models. The study also used a weighted combined variant of dice loss and focal loss to address the imbalance between foreground and background pixels, enhancing cerebrovascular segmentation. The model validation process involved evaluating the model using the validation set after every five rounds of each cross-validation fold, with the dice similarity coefficient (DSC) calculated as an internal performance metric. The study compared the performances of the models based on several metrics, including DSC, average surface distance (ASD), precision (PRE), sensitivity (SEN), and specificity (SPE). The results demonstrated that the integrated workflow combining CNN and Transformer models exhibited outstanding performance and capabilities, providing physicians with a powerful tool for visualizing vascular structures.",
  "model/interpretability": "The models employed in our study, including U-Net, V-Net, UNETR, and SwinUNETR, are primarily convolutional neural networks (CNNs) and transformer-based models, which are generally considered black-box models. These models do not inherently provide clear, interpretable insights into their decision-making processes. However, certain aspects of their architecture and training can offer some level of transparency.\n\nFor instance, V-Net utilizes a residual network and multiscale residual modules, which help in capturing fine details and contextual information. This architectural choice can be seen as a form of transparency, as it indicates the model's focus on preserving spatial hierarchies and detailed features. Similarly, UNETR leverages self-attention mechanisms, which allow the model to effectively capture long-range dependencies and relationships between pixels. This self-attention mechanism provides some interpretability by highlighting which parts of the input image are most relevant to the segmentation task.\n\nSwinUNETR combines the Swin Transformer with UNETR, incorporating a local perceptual window that restricts self-attention to local regions. This design choice can be interpreted as a way to balance global context and local detail, offering a clearer understanding of how the model processes information at different scales.\n\nDuring the training process, we used a combination of dice loss and focal loss to address the imbalance between foreground and background pixels. This loss function design provides insight into how the model handles class imbalances, focusing more on hard-to-classify pixels and improving the segmentation of cerebrovascular structures.\n\nAdditionally, the postprocessing steps, such as edge smoothing, region merging, and filtering, enhance the accuracy and quality of the segmentation results. These operations are transparent and can be understood as methods to refine and improve the initial segmentation outputs, making the final results more interpretable.\n\nWhile these models are not fully transparent, the architectural choices, loss functions, and postprocessing steps provide some level of interpretability. This allows researchers and clinicians to understand how the models process and segment cerebrovascular images, even if the exact decision-making process remains a black box.",
  "model/output": "The model is designed for segmentation, which is a type of classification task at the pixel level. It categorizes each pixel in a 3D medical image as belonging to a cerebrovascular structure or not. The models evaluated\u2014U-Net, V-Net, UNETR, and SwinUNETR\u2014are all three-dimensional segmentation models. They were trained to predict and segment cerebrovascular structures from MRI data.\n\nThe output of these models is a segmented image where each pixel is labeled according to whether it is part of a cerebrovascular structure or not. This segmentation is crucial for visualizing and analyzing the cerebrovascular system in medical imaging.\n\nThe performance of these models was assessed using several metrics, including the Dice Similarity Coefficient (DSC), average surface distance (ASD), precision (PRE), sensitivity (SEN), and specificity (SPE). These metrics help quantify the accuracy and reliability of the segmentation results.\n\nPostprocessing steps, such as edge smoothing, region merging, splitting, and filtering, were applied to enhance the accuracy and quality of the segmentation. These steps help in filling voids, connecting disjointed edges, merging small neighboring regions, and eliminating artifacts or mislabeling in the segmentation results.\n\nThe segmentation outcomes were visualized in three dimensions, allowing for a detailed observation of the feasibility and accuracy of the segmentation results. This visualization is essential for medical professionals to assess the performance of the models and their applicability in clinical settings.\n\nThe models were evaluated on two datasets: the CSD (Cerebrovascular Segmentation Dataset) and the MLD (Middle Cerebral Artery M1 Segment with Lenticulostriate Artery Segmentation Dataset). The results showed that SwinUNETR generally achieved the highest DSC and performed well across various metrics, indicating its effectiveness in cerebrovascular segmentation tasks.\n\nIn summary, the models are classification models at the pixel level, designed to segment cerebrovascular structures in 3D medical images. The output is a segmented image that can be visualized and analyzed for medical purposes. The performance of these models was thoroughly evaluated using standard metrics and postprocessing techniques to ensure accuracy and reliability.",
  "model/duration": "The models were trained and tested using a high-performance workstation equipped with 6 RTX 3090 GPUs, 2 Intel(R) Xeon(R) Silver 4310 CPUs, and 256 GB of RAM. The training process involved 400 epochs with a batch size of 1, utilizing the AdamW optimizer with an initial learning rate of 0.0001. To expedite convergence and reduce training time, a warmup strategy was implemented. The specific execution time for each model was not detailed, but the use of powerful hardware and optimization techniques suggests that the training and testing processes were efficient. The models were validated after every five rounds of each cross-validation fold, and the entire image was predicted using a sliding window of size 192 \u00d7 192 \u00d7 64. This approach ensured thorough evaluation and optimization of the models' performance.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our method involved a comprehensive approach to ensure its robustness and reliability. We utilized both public and privately collected datasets to validate our workflow's performance across diverse clinical scenarios. Specifically, we employed a public TOF-MRA dataset and constructed a black blood sequence dataset of cerebrovascular images. This allowed us to explore the workflow's generalization capabilities under different imaging modalities and conditions.\n\nOur evaluation focused on several key metrics to assess the segmentation performance. These metrics included the Dice Similarity Coefficient (DSC), which measures the overlap between the segmentation results and the reference standard, with values closer to 1 indicating better performance. Additionally, we used the Average Surface Distance (ASD) to evaluate the proximity of the segmentation results to the actual vessel boundaries, where smaller values signify better accuracy. Precision (PRE), Sensitivity (SEN), and Specificity (SPE) were also considered to provide a comprehensive assessment of the model's ability to correctly identify vascular structures and exclude nonvascular regions.\n\nWe conducted comparative analyses of various models, including U-Net, V-Net, UNETR, and SwinUNETR, to determine their strengths and suitable applications. For instance, V-Net showed exceptional performance in capturing structural information about blood vessel edges, while SwinUNETR excelled in the DSC metric. These results highlight the importance of selecting the appropriate model based on the specific requirements of the clinical scenario.\n\nFurthermore, we compared our results with those from other studies to benchmark our workflow's performance. Our models demonstrated competitive results, with DSC values approaching or exceeding those reported in previous research. This comparison underscores the effectiveness of our integrated workflow, which combines CNN and Transformer models to enhance segmentation accuracy and detail retention.\n\nIn summary, our evaluation method involved a thorough assessment using diverse datasets and multiple performance metrics. This approach ensured that our workflow is robust, reliable, and capable of handling complex and dynamic clinical scenarios.",
  "evaluation/measure": "In our study, we employed several key performance metrics to evaluate the effectiveness of our cerebrovascular segmentation workflow. These metrics include the Dice Similarity Coefficient (DSC), Average Surface Distance (ASD), Precision (PRE), Sensitivity (SEN), and Specificity (SPE). The DSC measures the overlap between the segmentation results and the reference standard, with values ranging from 0 to 1, where higher values indicate greater similarity. The ASD calculates the average distance between the segmentation result and the reference standard, assessing the proximity to the actual vessel boundary; smaller values indicate a closer approximation. Precision represents the ratio of correctly classified positive samples to the total number of samples classified as positive, with higher values implying more accurate identification of vessel structures. Sensitivity measures the ratio of correctly classified positive samples in the reference standard to the total number of positive samples, indicating the model's ability to capture vascular structures. Specificity evaluates the ratio of correctly classified negative samples to the total number of negative examples, with higher values indicating accurate exclusion of nonvascular regions.\n\nThese metrics are widely used in the literature for evaluating segmentation performance, ensuring that our results are comparable to other studies in the field. For instance, previous works by Wu et al. and Chen et al. also utilized the DSC metric, achieving values of 0.831 and 0.788, respectively, on public TOF-MRA datasets. Our approach, validated on both TOF-MRA and 3D T1 VISTA sequences, obtained a DSC of 0.853 on the CSD test set, which is competitive with these existing methods. Additionally, our workflow demonstrated strong performance in handling diverse vessel sizes, as evidenced by the DSC, ASD, PRE, and SPE metrics for LSA segmentation. This comprehensive set of metrics provides a robust evaluation of our segmentation workflow's capabilities and reliability in clinical scenarios.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of our proposed deep learning workflow with several publicly available methods on benchmark datasets. Specifically, we validated our approach on both TOF-MRA and 3D T1 VISTA sequences, focusing on the segmentation of the entire cerebral vasculature as well as smaller specific vascular segments, such as the lenticulostriate arteries.\n\nWe compared our results with those from other studies. For instance, Wu et al. proposed a weakly supervised cerebrovascular segmentation network that achieved a Dice Similarity Coefficient (DSC) of 0.831 on a public TOF-MRA dataset from the MIDAS data platform. Chen et al. demonstrated the generative consistency of TOF-MRA-based semi-supervised cerebrovascular segmentation, with their model achieving a best DSC of 0.788. Additionally, Chen et al. generated the publicly available Cerebrovascular Segmentation Dataset (CSD) and proposed a 3D adversarial network model called A-SegAN, which achieved a DSC of 0.864 for cerebral vessel segmentation in TOF-MRA volumes.\n\nOur method obtained a DSC value of 0.853 on the CSD test set, which is slightly lower than the 0.864 achieved by A-SegAN. This discrepancy may be due to the difference in the number of data points used for testing\u2014we used 9 data points, while A-SegAN used only 5. On the MLD test set, our method achieved a DSC of 0.766 for the middle cerebral artery (MCA) and 0.562 for the lenticulostriate artery (LSA), surpassing the 0.34 achieved by Ma et al. using HighRes3DNet. This improvement can be attributed to the more advanced Transformer structure employed in our approach.\n\nIn addition to comparing with state-of-the-art methods, we also evaluated simpler baselines such as U-Net, V-Net, and UNETR. These models were chosen for their established performance in medical image segmentation tasks. U-Net, a classic convolutional neural network, enhances segmentation accuracy through its encoder-decoder structure and skip connections. V-Net utilizes a residual network and multiscale residual module to capture fine details and contextual information. UNETR, a transformer-based model, leverages self-attention mechanisms to model pixel relationships effectively. SwinUNETR, which combines the Swin Transformer and UNETR, further improves performance by incorporating a local perceptual window.\n\nOur results demonstrated that SwinUNETR outperformed the other models in several metrics, including DSC, precision, sensitivity, and specificity, on the CSD test set. However, V-Net exhibited the best performance in the average surface distance (ASD) metric, indicating its strength in capturing structural information about blood vessel edges. On the MLD test set, SwinUNETR showed outstanding ability to segment cerebral vessels of different sizes, although it did not achieve the best MCA segmentation results. These findings highlight the distinct advantages and suitable scenarios of each model, emphasizing the importance of choosing the appropriate model based on specific requirements.",
  "evaluation/confidence": "The evaluation of our models included a thorough statistical analysis to ensure the reliability and significance of our results. We calculated performance metrics for each model and conducted a Shapiro\u2013Wilk test to assess the normality of the data distribution. For metrics where the p-value exceeded 0.05, we assumed normal distribution. In cases where the p-value was less than or equal to 0.05, we examined quantile\u2013quantile plots to confirm normality.\n\nTo compare the performances of different models, we employed one-way ANOVA, which provided F-statistics and corresponding p-values. A p-value less than 0.05 indicated statistically significant differences between the models' performances. This rigorous statistical approach ensured that our claims of superiority were backed by robust evidence.\n\nThe performance metrics of the models significantly differed for most metrics, except for a few specific cases where the p-values were slightly above the threshold (e.g., DSCM with p = 0.225, PREM with p = 0.325, and SPEM with p = 0.063). These exceptions highlight areas where further investigation may be needed to fully establish statistical significance.\n\nOverall, our evaluation process included confidence intervals and statistical tests to validate the performance of our models, providing a strong foundation for claiming the superiority of our methods over others and baselines.",
  "evaluation/availability": "The datasets generated and analyzed during the current study are not publicly available. However, they can be obtained from the corresponding author upon reasonable request. This approach ensures that the data remains secure and confidential, addressing concerns related to privacy and the sensitivity of medical information. The decision to restrict public access is also influenced by the need to maintain the integrity and reliability of the dataset, which includes thorough evaluations of image clarity, noise levels, and the presence of artifacts. By providing access on a case-by-case basis, we can better control the use of the data and ensure that it is utilized responsibly and ethically."
}