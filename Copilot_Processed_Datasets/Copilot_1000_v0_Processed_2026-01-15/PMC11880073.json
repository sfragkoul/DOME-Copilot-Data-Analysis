{
  "publication/title": "Prediction of the Extent of Blood\u2013Brain Barrier Transport Using Machine Learning and Integration into the LeiCNS-PK3.0 Model",
  "publication/authors": "The authors who contributed to this article are:\n\nBerfin G\u00fclave, who was involved in conceptualization, data collection, data analysis, model simulations, and writing the original draft, as well as reviewing and editing the manuscript.\n\nHelle W. van den Maagdenberg, who contributed to code checking, reviewing, and editing the manuscript.\n\nLuke van Boven, who assisted with data collection, data analysis, and model simulations.\n\nGerard J.P. van Westen, who reviewed and edited the manuscript.\n\nElizabeth C.M. de Lange, who contributed to conceptualization and writing the original draft, as well as reviewing and editing the manuscript.\n\nJ.G. Coen van Hasselt, who was involved in conceptualization and writing the original draft, as well as reviewing and editing the manuscript.",
  "publication/journal": "Pharmaceutical Research",
  "publication/year": "2025",
  "publication/pmid": "39930309",
  "publication/pmcid": "PMC11880073",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Quantitative Structure-Property Relationship (QSPR)\n- Machine Learning\n- Pharmacokinetics\n- Blood-Brain Barrier (BBB)\n- Microdialysis\n- CNS PBPK Modeling\n- Predictive Modeling\n- Feature Selection\n- Drug Distribution\n- Physicochemical Properties",
  "dataset/provenance": "The dataset used in this study was systematically collected through an extensive literature review focusing on studies that utilized the microdialysis approach in the rat central nervous system (CNS). The microdialysis method was deemed adequate if it involved collecting dialysate from the brain extracellular fluid (ECF) and correcting it with relative recovery to obtain unbound drug concentrations. The dataset comprises 98 microdialysis-measured Kp,uu,BBB values for various drugs, each with associated physico-chemical parameters. These values were either directly obtained from publications or calculated from reported unbound concentrations at steady state in the brain ECF and plasma. Additionally, the dataset includes values derived from the clearance in and out of the brain ECF or from the area under the curve (AUC) of unbound compounds in the brain ECF and plasma.\n\nThe dataset was log-transformed for use in the quantitative structure-property relationship (QSPR) model development. The physico-chemical properties of the drugs were generated using MOE software, with 3D molecular structures obtained from PubChem. The compounds were cleaned and subjected to energy minimization to ensure stable conformations, enhancing the reliability of the descriptors. A total of 375 physico-chemical properties were calculated for each compound.\n\nPrevious studies have developed QSPR models using various machine learning algorithms to predict Kp,uu,BBB values, often relying on data from the cerebral microdialysis approach (CMA) or a combination of CMA and in vivo microdialysis. However, these models frequently used smaller sample sizes or data derived from CMA, which can complicate interspecies translatability. The scarcity of models utilizing microdialysis data highlights the need for more physiologically relevant QSPR models. This study aims to address this gap by developing a rat QSPR model based on 98 in vivo microdialysis-derived Kp,uu,BBB values and comparing the predictive performance of multiple machine learning algorithms. The final model was integrated into the LeiCNS-PK3.0 CNS physiologically based pharmacokinetic (PBPK) model for further evaluation and application.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The training set consisted of 68 data points, while the test set contained 18 data points. Initially, 12 compounds in the training set were excluded due to high similarity to compounds in the test set, ensuring the independence of the test set. This exclusion was based on a Tanimoto similarity analysis, which identified these compounds as having a similarity greater than 0.7 to compounds in the test set. The chemical space of the training and test sets was compared using Principal Component Analysis (PCA), which showed appropriate overlap, indicating that the datasets were comparable.",
  "dataset/redundancy": "The dataset was split into training and test sets to evaluate the performance of the machine learning models. To ensure the independence of the test set, a Tanimoto similarity analysis was conducted based on the topological fingerprints of the training set molecules. This analysis identified 12 compounds in the training set that had high similarity (> 0.7) to compounds in the test set. These 12 compounds were excluded from further model development to maintain the independence of the test set.\n\nThe chemical space of the training and test sets was compared using Principal Component Analysis (PCA) within the first two principal components, which accounted for 52% of the variance (PC1 = 35% and PC2 = 17%). This analysis helped to ensure that the training and test sets had an appropriate overlap in their chemical space, which is crucial for the generalizability of the models.\n\nThe dataset consisted of 98 microdialysis-measured Kp,uu,BBB values for drugs with various physico-chemical properties. This dataset is larger than many previously published machine learning datasets for predicting Kp,uu,BBB, which often relied on smaller sample sizes or data derived from less physiologically relevant methods such as the cerebral microdialysis approach (CMA). The use of microdialysis data enhances the physiological relevance of the predictions, addressing a gap in the existing literature.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and belong to the supervised learning class. Specifically, the algorithms employed include Random Forest (RF), Support Vector Machines (SVM) with a linear kernel, K-nearest neighbors (KNN), Sparse Partial Least Squares (SPLS), and Partial Least Squares (PLS). These algorithms are widely recognized and have been extensively used in various domains, including quantitative structure-property relationship (QSPR) modeling.\n\nThe algorithms are not new; they have been developed and refined over many years and are implemented in widely-used machine learning packages in R, such as caret, kernlab, and spls. The choice of these algorithms was driven by their proven effectiveness in handling regression tasks and their ability to capture complex relationships in the data.\n\nThe focus of this study is on applying these algorithms to predict the unbound brain-to-plasma partition coefficient (Kp,uu,BBB), a critical parameter in pharmacokinetics, rather than on developing new machine-learning algorithms. Therefore, the algorithms were not published in a machine-learning journal but in a pharmaceutical research journal, as the primary contribution lies in the application and integration of these models into the LeiCNS-PK3.0 CNS PBPK model.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. Instead, it directly employs various machine learning algorithms to predict the partition coefficient (Kp,uu,BBB) based on microdialysis-derived data. The algorithms used include Random Forest (RF), Support Vector Machines (SVM), K-nearest neighbors (KNN), Sparse Partial Least Squares (SPLS), and Partial Least Squares (PLS). Each of these algorithms was trained and optimized independently using a dataset split into training and test sets. The training data for each algorithm was processed to ensure that it was independent, with appropriate overlap of the chemical space between the training and test sets verified through Principal Component Analysis (PCA).\n\nThe predictive performance of these algorithms was evaluated based on metrics such as the average cross-validated predictive performance (q2), root mean squared error (RMSE), and the coefficient of determination (R2). The Random Forest model was identified as the best-performing algorithm, with a q2 of 0.60 and an RMSE of 0.48. This model's performance was further validated using Y-randomization and applicability domain analysis, ensuring robustness and reliability in its predictions. The final model's predictions were integrated into the LeiCNS-PK3.0 CNS PBPK model to demonstrate its practical application in predicting CNS drug distribution.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for preparing the dataset for machine learning algorithms. Initially, a dataset containing 375 physico-chemical properties was generated using MOE software. The 3D molecular structures of the compounds were obtained from PubChem, with a few exceptions where 2D coordinates were used due to instability or complexity. The compounds were cleaned using the \"wash\" function, which involved disconnecting metal groups in simple salts and protonating/deprotonating strong acids and bases at pH 7.4. Energy minimization was performed using the Merck Molecular Force Field 94 (MMFF94x) to ensure that each compound was in its stable, low-energy conformation.\n\nThe dataset was then split into training and test sets, with 80% of the data allocated to the training set and 20% to the test set. Compounds with high similarity to the test set (Tanimoto similarity > 0.7) were excluded from the training set to ensure independence. Feature selection was conducted to remove descriptors with zero variance and those highly correlated (Pearson correlation > 0.8). The Boruta feature selection algorithm was applied to the remaining descriptors, resulting in 10 confirmed descriptors and 4 tentative descriptors, which were used for model building. The final dataset included 122 descriptors after removing near-zero variance and co-correlated descriptors. The log-transformed partition coefficient (logKp,uu,BBB) values were used as the target variable for the quantitative structure-property relationship (QSPR) model development.",
  "optimization/parameters": "In our study, we utilized a total of 122 descriptors after preprocessing the initial set of 375 descriptors. These descriptors were selected through a rigorous feature selection process that involved removing descriptors with near-zero variance and those that were highly correlated. Additionally, the Boruta feature selection algorithm was applied, resulting in 10 confirmed descriptors and 4 tentative ones, which were further used for model building.\n\nThe selection of these descriptors was crucial for ensuring that the model was trained on relevant and non-redundant features. The Boruta algorithm helped in identifying the most important descriptors by iteratively comparing the importance of actual features with randomized shadow features, retaining those with consistently higher importance. This process ensured that the final set of descriptors used in the model was both meaningful and effective in predicting the target variable.\n\nThe final model, specifically the Random Forest model, was trained using these selected descriptors. The tuning parameters for the Random Forest model, such as mtry, were optimized through a grid search with tenfold cross-validation and 200 repeats. This approach ensured that the model's performance was robust and that the selected parameters were optimal for predicting the logKp,uu,BBB values.",
  "optimization/features": "In the optimization process, the input features for the machine learning models were carefully selected and preprocessed. Initially, a dataset containing 375 physico-chemical properties was generated. To ensure the quality of the features, descriptors with near-zero variance and highly correlated descriptors were removed. This step reduced the number of descriptors to 122.\n\nFurther feature selection was performed using the Boruta algorithm on the training set only. This algorithm identified 10 confirmed descriptors and 4 tentative descriptors, resulting in a total of 14 descriptors that were used for model building. These descriptors included both 2D and 3D properties, ensuring a comprehensive representation of the chemical space. The final set of 14 descriptors was used as input features for the machine learning models, ensuring that only the most relevant and non-redundant features were included in the analysis.",
  "optimization/fitting": "The fitting method employed in this study involved training five different machine learning models using a dataset split into 80% for training and 20% for testing. The models included Random Forest (RF), Support Vector Machines (SVM), K-nearest neighbors (KNN), Sparse Partial Least Squares (SPLS), and Partial Least Squares (PLS). Each model underwent hyperparameter optimization through a tuning grid, with parameters such as mtry for RF, costs (C) for SVM, k for KNN, eta and K for SPLS, and ncomp for PLS.\n\nTo address the potential issue of overfitting, given the number of parameters relative to the training points, several strategies were implemented. Firstly, tenfold cross-validation with 200 repeats was used to ensure that the models generalized well to unseen data. This technique helps in assessing the model's performance and stability across different subsets of the data. Additionally, the Mahalanobis distance applicability domain analysis identified 16 outliers in the dataset, which were excluded to prevent them from unduly influencing the model's performance. Furthermore, Y-randomization validation was performed, where the target variable was randomly permuted, and the model-building process was repeated 30 times. This step helped in verifying that the model's predictive performance was not due to chance.\n\nTo mitigate underfitting, feature selection was rigorously conducted. Initially, descriptors with near-zero variance and highly correlated descriptors (Pearson correlation threshold of 0.8) were removed. Subsequently, the Boruta feature selection algorithm was applied, resulting in 14 confirmed and tentative descriptors that were deemed relevant for model building. This process ensured that only the most informative features were used, enhancing the model's ability to capture the underlying patterns in the data.\n\nThe predictive performance of the models was evaluated using metrics such as the average cross-validated prediction error (q2), root mean square error (RMSE), and the coefficient of determination (R2). The Random Forest model was selected as the best-performing model based on these metrics, demonstrating robust predictive performance on both the training and test sets. The final model's performance was further validated by checking the percentage of predictions within the twofold and threefold error ranges, ensuring that the model's predictions were reliable and accurate.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our machine learning models. One of the key methods used was tenfold cross-validation, which involved dividing the training dataset into ten subsets. The model was trained on nine of these subsets and validated on the remaining one, with this process repeated ten times, each time using a different subset as the validation set. This approach helps to ensure that the model generalizes well to unseen data.\n\nAdditionally, we performed hyperparameter optimization using 200 repeats. This involved systematically searching through a range of hyperparameter values to find the optimal settings for each machine learning algorithm. By tuning these parameters, we aimed to improve the model's performance and reduce the risk of overfitting.\n\nFeature selection was another crucial step in our preprocessing pipeline. We started by removing descriptors with near-zero variance and those that were highly correlated, as these do not contribute meaningful information to the model. Following this, we applied the Boruta feature selection algorithm, which iteratively compares the importance of actual features with randomized shadow features. This process helps to retain only the most relevant features, further reducing the risk of overfitting.\n\nMoreover, we conducted Y-randomization validation, where the target variable was randomly permuted, and the entire dataset preprocessing, model building, and evaluation process was repeated for 30 iterations. This technique helps to assess whether the model's performance is better than chance and to ensure that the relationships identified are not due to random noise.\n\nLastly, we performed an applicability domain analysis using the Mahalanobis distance to identify outliers in the dataset. This step helps to ensure that the model is applied within the chemical space for which it was trained, further enhancing its reliability and generalizability.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in detail within the publication. Specifically, the tuning parameters for each machine learning algorithm, such as `mtry` for Random Forest, `C` for Support Vector Machines, and `k` for K-nearest neighbors, are provided along with their respective ranges and steps. These details can be found in Table I, which outlines the average prediction performances for the train data using 10-fold cross-validation and 200 repeats with optimized tuning parameters.\n\nThe optimization schedule, including the use of tenfold cross-validation and 200 repeats for hyperparameter tuning, is also described. This process ensures that the models are robust and that the tuning parameters are optimized for the best predictive performance.\n\nRegarding model files, while the specific model files are not directly provided in the publication, the methods and parameters used to train the models are thoroughly documented. This allows for reproducibility by other researchers who wish to implement similar models.\n\nThe data and code used in this study are not explicitly mentioned as being available under a specific license. However, the detailed reporting of methods and parameters should facilitate replication and further research. For access to the specific datasets or code, interested parties may need to contact the authors directly.",
  "model/interpretability": "The model developed in this study is not a blackbox model. The interpretability of the model was enhanced through several steps.\n\nFirstly, a principal component analysis (PCA) was performed to evaluate the overlap of the chemical space of the train and test sets. This analysis helps in understanding the distribution and similarity of the compounds used in the training and testing phases.\n\nSecondly, the importance of each descriptor was estimated individually and ranked using the variable importance function in the R package caret. This process identified the most influential features contributing to the model's predictions, providing insights into the key physico-chemical properties that affect the partition coefficient (Kp,uu,BBB).\n\nAdditionally, the predictive descriptors within the QSPR model were evaluated in relation to the observed Kp,uu,BBB values. This evaluation helps in understanding how different descriptors influence the model's predictions and provides a clearer picture of the underlying mechanisms.\n\nFurthermore, the Mahalanobis distance applicability domain analysis was used to identify outliers in the dataset. This analysis helps in understanding the boundaries of the model's applicability and ensures that the predictions are reliable within the defined chemical space.\n\nIn summary, the model's transparency is achieved through the use of PCA for chemical space evaluation, variable importance ranking for feature selection, and Mahalanobis distance analysis for applicability domain identification. These steps ensure that the model is interpretable and that the predictions are based on understandable and relevant physico-chemical properties.",
  "model/output": "The model developed in this study is a regression model. It is designed to predict the unbound brain-to-plasma partition coefficient (Kp,uu,BBB), which is a continuous value. The quantitative structure\u2013property relationship (QSPR) model utilizes various machine learning algorithms, including random forest, support vector machines, K-nearest neighbors, and (sparse-) partial least squares, to estimate this parameter. The performance of these models was evaluated using metrics such as R2 and RMSE, which are commonly used in regression analysis to assess the predictive accuracy and error of the models. The best-performing model, a random forest, achieved an R2 value of 0.61 on the test data, indicating a moderate level of predictive performance for the Kp,uu,BBB values.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code used in this study is not publicly available due to intellectual property restrictions. Therefore, no executable, web server, virtual machine, or container instance has been released for public use. The data supporting the findings of this study are available within the article and its supplementary materials.",
  "evaluation/method": "The evaluation method employed for the machine learning models involved a rigorous process to ensure the robustness and reliability of the predictions. Initially, a tenfold cross-validation technique was used, repeated 200 times, to optimize the tuning parameters for each model. This approach helped in assessing the models' performance on different subsets of the data, providing a comprehensive evaluation of their predictive capabilities.\n\nThe predictive performance of the models was compared based on the average cross-validated predictive performance, denoted as q2. This metric represents the correlation between the observed and predicted values, squared. The model with the best predictive performance was selected for further evaluation.\n\nFor the selected model, additional metrics such as the root mean squared error (RMSE) and the coefficient of determination (R2) were calculated for both the train and test sets. These metrics provided insights into the model's accuracy and the proportion of variance explained by the model, respectively.\n\nFurthermore, the percentage of predictions within the twofold and threefold error ranges was determined. This analysis helped in understanding the model's precision and reliability in predicting the partition coefficient, Kp,uu,BBB.\n\nTo ensure that the model's performance was better than chance, Y-randomization was performed. This involved randomly permuting the target variable, logKp,uu,BBB, and repeating the dataset preprocessing, model building, and evaluation for 30 iterations. The results of this validation step confirmed that the model's performance was not due to random chance.\n\nAdditionally, an applicability domain analysis was conducted using the Mahalanobis distance. This analysis identified outliers in the dataset, ensuring that the model's predictions were reliable within the defined chemical space.\n\nThe final model's performance was also evaluated by integrating it into the LeiCNS-PK3.0 CNS PBPK model. Predictions for CNS PK profiles were generated for selected compounds, and the predicted brainECF profiles were overlaid with observed data points. This visual predictive check provided a practical evaluation of the model's performance in a real-world scenario.",
  "evaluation/measure": "In the evaluation of our machine learning models, several performance metrics were reported to ensure a comprehensive assessment of their predictive capabilities. The primary metrics used were the coefficient of determination (R\u00b2), the root mean square error (RMSE), and the average cross-validated prediction error (q\u00b2). These metrics were calculated for both the training and test sets to provide a clear picture of model performance.\n\nThe R\u00b2 value indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. An R\u00b2 value closer to 1 signifies a better fit of the model to the data. For our best-performing model, the Random Forest (RF), the R\u00b2 value on the test set was 0.61, which is considered acceptable and is in line with previously developed Quantitative Structure-Property Relationship (QSPR) models.\n\nThe RMSE measures the average magnitude of the errors between predicted and observed values, with lower values indicating better model performance. The RF model had an RMSE of 0.52 on the test set, demonstrating its ability to make accurate predictions.\n\nThe q\u00b2 value, calculated as the correlation between observed and predicted values squared, provides an estimate of the model's predictive power. The RF model achieved a q\u00b2 of 0.60 on the training set, indicating strong predictive performance.\n\nAdditionally, we evaluated the percentage of predictions within twofold and threefold error ranges. For the test set, 33.3% of predictions were within a twofold error, and 61.1% were within a threefold error. These results suggest that the model's predictions are reasonably accurate for a majority of the test cases.\n\nTo further validate the model's performance, Y-randomization was performed. This technique involves randomly permuting the target variable and evaluating the model's performance on the permuted dataset. The RF model showed a low R\u00b2 of 0.11 on the Y-randomized test set, indicating limited overfitting and confirming the robustness of the model.\n\nThe set of metrics reported is representative of standard practices in the field of QSPR modeling. The use of R\u00b2, RMSE, and q\u00b2, along with error range analysis and Y-randomization, provides a thorough evaluation of model performance. These metrics are commonly used in the literature to assess the predictive accuracy and reliability of QSPR models, ensuring that our evaluation is both comprehensive and comparable to other studies in the field.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "The evaluation of the machine learning models involved a rigorous process to ensure the confidence in the results. The performance metrics, such as the average cross-validated prediction error (q2), prediction error (R2), and root mean square error (RMSE), were calculated using 10-fold cross-validation and 200 repeats. This extensive validation process helps to provide a robust estimate of the model's performance and reduces the variability in the results.\n\nThe Random Forest (RF) model, which was selected as the best-performing model, showed a q2 of 0.60 and an RMSE of 0.48 on the training set. For the test set, the RF model achieved an R2 of 0.61 and an RMSE of 0.52. These metrics indicate that the model has a good predictive performance. Additionally, the Y-randomization validation, which involved permuting the target variable and repeating the model building and evaluation process 30 times, showed a low R2 of 0.11 on the test set. This result suggests that the model's performance is not due to chance and that there is limited overfitting.\n\nThe statistical significance of the results was further evaluated by checking the percentage of predictions within the twofold and threefold error ranges. For the test set, 33.3% of the predictions were within the twofold error range, and 61.1% were within the threefold error range. These percentages indicate that the model's predictions are reasonably accurate and reliable.\n\nMoreover, the applicability domain analysis using the Mahalanobis distance identified 16 outliers in the whole dataset. This analysis helps to ensure that the model's predictions are reliable within the chemical space of the training data. The overlap of the chemical space of the train and test sets, as observed in the Principal Component Analysis (PCA), further supports the confidence in the model's performance.\n\nIn summary, the evaluation process involved multiple validation steps, including cross-validation, Y-randomization, and applicability domain analysis. The performance metrics have associated standard deviations, providing confidence intervals for the results. The statistical significance of the results was demonstrated through error range analysis and comparison with other models. These evaluations collectively indicate that the RF model has a superior and reliable predictive performance.",
  "evaluation/availability": "Not enough information is available."
}