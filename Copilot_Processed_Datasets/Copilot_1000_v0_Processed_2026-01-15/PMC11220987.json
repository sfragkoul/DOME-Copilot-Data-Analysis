{
  "publication/title": "Prediction of chromosomal abnormalities in the screening of the first trimester of pregnancy using machine learning methods: a study protocol",
  "publication/authors": "The authors who contributed to the article are:\n\n- Mahla Shaban, who is affiliated with the Department of Midwifery, Research Student Committee, Mashhad University of Medical Sciences, Mashhad, Iran.\n- Sanaz Mollazadeh, who is affiliated with the Nursing and Midwifery Care Research Center, Mashhad University of Medical Sciences, Mashhad, Iran.\n- Saeid Eslami, who is affiliated with the Department of Medical Informatics, Faculty of Medicine, Mashhad University of Medical Sciences, Mashhad, Iran.\n- Fatemeh Tara, who is affiliated with the Department of Obstetrics and Gynecology, Faculty of Medicine, Mashhad University of Medical Sciences, Mashhad, Iran.\n- Samaneh Sharif, who is affiliated with the Department of Medical Informatics, Faculty of Medicine, Mashhad University of Medical Sciences, Mashhad, Iran.\n- Fatemeh Erfanian Arghavanian, who is affiliated with the Nursing and Midwifery Care Research Center, Mashhad University of Medical Sciences, Mashhad, Iran. She is also the corresponding author for the article.",
  "publication/journal": "Reproductive Health",
  "publication/year": "2024",
  "publication/pmid": "38961456",
  "publication/pmcid": "PMC11220987",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Machine learning\n- Chromosomal abnormalities\n- Prediction\n- Pregnancy\n- Neural networks\n- First-trimester screening\n- Decision trees\n- Random forest\n- Amniocentesis\n- Midwifery",
  "dataset/provenance": "The dataset for this study is sourced from midwifery clinics in Mashhad hospitals. The data collection focuses on pregnant women who underwent first-trimester screening tests between 11 and 14 weeks of pregnancy and were classified as high-risk. The study aims to include a total of 350 individuals, which is considered necessary for a more precise model design and comprehensive evaluation in machine learning contexts. This sample size accounts for a ten percent dropout rate, ensuring robustness in the dataset.\n\nThe data points collected include various maternal and fetal characteristics such as maternal age, BMI, smoking habits, history of trisomy 21 and other chromosomal disorders, CRL and NT levels, PAPP-A and B-HCG levels, presence of insulin-dependent diabetes, and whether the pregnancy resulted from IVF. These data points are gathered during clinic visits for first-trimester screening results, with follow-up amniocentesis for high-risk cases.\n\nThis dataset is specifically curated for this study and has not been used in previous publications by the community. The focus is on leveraging machine learning techniques, particularly neural networks, to predict chromosomal abnormalities accurately. The study employs convenience sampling, and data is gathered using a checklist of characteristics and screening/amniocentesis results. After preprocessing, feature extraction is conducted to identify and predict relevant features, ensuring the dataset's quality and relevance for the study's objectives.",
  "dataset/splits": "In our study, we employed the K-fold cross-validation method to ensure a reliable and standardized assessment of the prediction model. This approach involves partitioning the dataset into k subsets. The model is trained on k-1 subsets and validated on the remaining subset. This process is repeated k times, with each subset serving as the validation set once. This method enhances system reliability by assessing the model's performance on varied random batches.\n\nThe dataset consists of information collected from 350 pregnant women who underwent first-trimester screening tests. The specific number of folds, k, used in our cross-validation process is not explicitly stated, but it is a common practice to use 5 or 10 folds. Therefore, the dataset would be split into 5 or 10 subsets, each containing approximately 70 or 35 data points, respectively. In each iteration of the cross-validation, 4 or 9 subsets would be used for training, and 1 subset would be used for validation. This ensures that every data point is used for both training and validation, providing a comprehensive evaluation of the model's performance.",
  "dataset/redundancy": "The datasets were split using the K-fold cross-validation method. This approach ensures that the training and test sets are independent by partitioning the dataset into k subsets. The model is trained and evaluated on these subsets, enhancing system reliability through the assessment of varied random batches. This method helps to generalize the model's performance to new data by ensuring that each data point gets to be in the training set and the test set exactly once.\n\nThe distribution of the dataset used in this study is designed to be comprehensive and precise for machine learning models, with a sample size of at least 350 individuals. This is larger than the minimum calculated sample size of 173 individuals, which was determined using a significance level of 0.07, a confidence level of 99% (z = 2.58), and a precision of 0.05. The final sample size was set at 190 individuals, accounting for a ten percent dropout rate. However, for more precise model design and comprehensive evaluation, a larger dataset was necessary.\n\nThe dataset includes various factors such as maternal age, BMI, maternal smoking, trisomy 21 history, CRL level, NT, PAPP-A, B-HCG, presence of insulin-dependent diabetes, and IVF pregnancy status. These factors were collected during visits to obstetric clinics for first-trimester screening results, with follow-up amniocentesis for those deemed high-risk. The data underwent preprocessing, which involved managing missing values, eliminating anomalies, and standardizing the data. This ensures that the dataset is clean and ready for model training and evaluation.",
  "dataset/availability": "No datasets were generated or analyzed during the current study. Therefore, there are no data splits or specific datasets to release in a public forum. Consequently, there is no associated license or enforcement mechanism related to dataset availability.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is neural networks, specifically Artificial Neural Networks (ANN). The focus is on optimizing the structure and parameters of these networks to enhance their predictive accuracy for chromosomal abnormalities during the first trimester of pregnancy.\n\nThe optimization approach employed is Particle Swarm Optimization (PSO). This method is used to identify optimal hyperparameter values and network structures, aiming to improve the model's performance in detecting chromosomal abnormalities. PSO is a well-known optimization technique that has been widely applied in various fields, including machine learning, to fine-tune models for better accuracy and efficiency.\n\nThis study does not introduce a new machine-learning algorithm. Instead, it leverages established techniques\u2014ANN and PSO\u2014to address a specific medical challenge. The decision to publish in a reproductive health journal rather than a machine-learning journal is likely due to the study's primary focus on the application of these techniques in the context of prenatal screening and chromosomal abnormality prediction. The research aims to contribute to the field of reproductive health by demonstrating the effectiveness of machine learning in improving diagnostic accuracy and reducing unnecessary invasive procedures, thereby enhancing patient care and outcomes.",
  "optimization/meta": "The optimization process in this study involves the development of a predictive model using machine learning techniques, with a specific focus on neural networks. The model is designed to predict chromosomal abnormalities during the first trimester of pregnancy.\n\nThe study employs two model variants. The first model utilizes all input features gathered from pregnant women, while the second model employs filter-based feature selection methods to identify essential features for building a prediction model. This approach ensures that the model is trained on relevant data, enhancing its predictive accuracy.\n\nThe optimization of the neural network structure and parameters is achieved through Particle Swarm Optimization (PSO). This method is used to identify optimal hyperparameter values and network structure, which are crucial for the network's performance and prediction accuracy.\n\nThe study also utilizes other machine learning techniques, such as decision trees, for comparative analysis of results. This comparative analysis helps in evaluating the performance of the optimized neural network against other established methods.\n\nThe data used for training and evaluating the models is collected from 350 pregnant women who underwent first-trimester screening tests. The data includes various factors such as maternal age, BMI, smoking habits, history of trisomy 21, CRL level, NT, PAPP-A, B-HCG, presence of insulin-dependent diabetes, and IVF pregnancy status. This comprehensive dataset ensures that the models are trained on a diverse and representative sample, enhancing their generalizability and reliability.\n\nThe models are evaluated using K-fold cross-validation, which helps in gauging the model's efficiency and performance. This method involves dividing the dataset into k subsets, training the model on k-1 subsets, and validating it on the remaining subset. This process is repeated k times, with each subset serving as the validation set once. The results are then averaged to provide a comprehensive evaluation of the model's performance.\n\nIn summary, the optimization process involves the use of neural networks, decision trees, and other machine learning techniques to develop a predictive model for chromosomal abnormalities. The model is trained and evaluated using a comprehensive dataset and advanced optimization methods to ensure high accuracy and reliability.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the quality and reliability of the machine-learning algorithm. The data collection process involved gathering various factors such as maternal age, BMI, smoking habits, history of trisomy 21, CRL level, NT, PAPP-A, B-HCG, presence of insulin-dependent diabetes, and IVF pregnancy status from 350 pregnant women who underwent first-trimester screening tests.\n\nThe initial phase of preprocessing involved managing missing values, which were handled through imputation techniques to maintain data integrity. Anomalies or outliers in the dataset were identified and eliminated to prevent them from skewing the model's predictions. Standardization was applied to normalize the data, ensuring that all features contributed equally to the model's learning process.\n\nFeature extraction was conducted to identify and predict relevant features that significantly relate to chromosomal abnormalities. This involved statistical analyses to uncover significant relationships between the input characteristics and the response variable, specifically focusing on chromosomal abnormalities 13, 18, and 21.\n\nFor the machine-learning models, two variants were developed. The first model utilized all input features gathered from the pregnant women, while the second model employed filter-based feature selection methods to pinpoint essential features for building a prediction model. This approach helped in reducing dimensionality and focusing on the most influential factors.\n\nThe data was then encoded using techniques suitable for machine-learning algorithms. Categorical variables were converted into numerical formats using encoding methods such as one-hot encoding or label encoding, depending on the nature of the data. Continuous variables were standardized to have a mean of zero and a standard deviation of one, which is essential for algorithms like neural networks that are sensitive to the scale of the input data.\n\nK-fold cross-validation was employed to train and evaluate the models, ensuring that the model's performance was assessed on different subsets of the data. This method helps in gauging the model's efficiency and performance by minimizing overfitting and providing a more robust evaluation of the model's predictive accuracy.",
  "optimization/parameters": "The model utilizes a variety of input parameters to predict chromosomal abnormalities during the first trimester of pregnancy. These parameters include maternal age, BMI, maternal smoking habits, history of trisomy 21 and other chromosomal disorders, crown-rump length (CRL) level, nuchal translucency (NT), pregnancy-associated plasma protein-A (PAPP-A), beta-human chorionic gonadotropin (B-HCG), presence of insulin-dependent diabetes, and whether the pregnancy resulted from in vitro fertilization (IVF).\n\nThe selection of these parameters was based on their known relevance to chromosomal abnormalities and their availability during the first-trimester screening. The initial dataset includes all these parameters, and a filter-based feature selection method is employed to identify the most influential features for building the prediction model. This approach ensures that the model focuses on the key characteristics that significantly impact the prediction of chromosomal abnormalities.\n\nThe exact number of parameters used in the final model may vary depending on the feature selection process, but the initial dataset includes ten parameters. The goal is to optimize the model by selecting the most relevant features, which can enhance the model's performance and accuracy in predicting chromosomal abnormalities.",
  "optimization/features": "The study utilizes a comprehensive set of input features to predict chromosomal abnormalities during the first-trimester screening. The features collected include maternal age, BMI, maternal smoking habits, history of trisomy 21 and other chromosomal disorders, crown-rump length (CRL) level, nuchal translucency (NT), pregnancy-associated plasma protein-A (PAPP-A), beta-human chorionic gonadotropin (B-HCG), presence of insulin-dependent diabetes, and whether the pregnancy resulted from in vitro fertilization (IVF). This results in a total of 10 features (f) being used as input.\n\nFeature selection was indeed performed to identify the most influential characteristics for building the prediction model. This process involved using filter-based feature selection methods to pinpoint essential features. The feature selection was conducted using the training set only, ensuring that the model's performance on unseen data remains unbiased. This approach helps in enhancing the model's efficiency and accuracy by focusing on the most relevant predictors.",
  "optimization/fitting": "The fitting method employed in this study involves the use of machine learning techniques, specifically focusing on neural networks, to predict chromosomal abnormalities during the first trimester of pregnancy. The model is constructed using a dataset collected from 350 pregnant women who underwent first-trimester screening tests.\n\nThe number of parameters in the neural network is indeed larger than the number of training points, which is a common scenario in machine learning, particularly with neural networks. To address the risk of overfitting, several strategies are implemented. Firstly, K-fold cross-validation is used to evaluate the model's performance. This technique helps in assessing the model's ability to generalize to new, unseen data by dividing the dataset into k subsets and training the model on k-1 subsets while validating it on the remaining subset. This process is repeated k times, ensuring that each subset is used for validation once.\n\nAdditionally, Particle Swarm Optimization (PSO) is utilized to optimize the network's structure and hyperparameters. PSO helps in finding the optimal configuration of the neural network, which includes the number of layers, number of neurons in each layer, and other hyperparameters. By optimizing these parameters, the model's complexity is managed, reducing the risk of overfitting.\n\nTo rule out underfitting, the model is trained on a comprehensive dataset that includes various influential features such as maternal age, BMI, smoking habits, history of trisomy 21, CRL level, NT, PAPP-A, B-HCG, presence of insulin-dependent diabetes, and IVF pregnancy status. These features are selected through a filter-based feature selection method, ensuring that the most relevant characteristics are used for building the prediction model. Furthermore, the model's performance is continuously monitored and evaluated during the training process to ensure that it captures the underlying patterns in the data without being too simplistic.\n\nIn summary, the fitting method involves the use of K-fold cross-validation and PSO to manage the complexity of the neural network, thereby addressing both overfitting and underfitting. The comprehensive dataset and feature selection process further enhance the model's ability to accurately predict chromosomal abnormalities.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our predictive models. One of the primary methods used was K-fold cross-validation. This technique involves dividing the dataset into k subsets, or \"folds,\" and then training the model on k-1 folds while validating it on the remaining fold. This process is repeated k times, with each fold serving as the validation set once. By averaging the results, we obtain a more reliable estimate of the model's performance and reduce the risk of overfitting to a specific subset of the data.\n\nAdditionally, we utilized feature selection methods to identify and retain only the most relevant features for model training. This not only simplifies the model but also reduces the likelihood of overfitting by eliminating noise and irrelevant information. We employed filter-based feature selection techniques to pinpoint essential features that significantly contribute to the prediction of chromosomal abnormalities.\n\nFurthermore, we optimized the structure and hyperparameters of our neural network using Particle Swarm Optimization (PSO). This optimization approach helps in finding the best configuration of the network, which includes the number of layers, neurons, and other hyperparameters. By fine-tuning these parameters, we enhance the model's generalization capability and mitigate overfitting.\n\nIn summary, our approach to preventing overfitting involved a combination of K-fold cross-validation, feature selection, and hyperparameter optimization. These methods collectively ensure that our models are robust, generalizable, and capable of accurately predicting chromosomal abnormalities during the first-trimester screening.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study primarily focuses on neural networks, which are often considered black-box models due to their complex, multi-layered structure. This means that the internal workings of the model are not easily interpretable, and it can be challenging to understand how specific inputs influence the outputs. However, efforts have been made to enhance the interpretability of the model through feature selection and optimization techniques.\n\nOne approach to improve interpretability is the use of filter-based feature selection methods. These methods help identify the most influential features for building the prediction model. By focusing on these key features, such as maternal age, BMI, and specific hormone levels, the model's decisions become more transparent. This allows for a clearer understanding of which factors are most significant in predicting chromosomal abnormalities.\n\nAdditionally, the study employs Particle Swarm Optimization (PSO) to optimize the neural network's structure and hyperparameters. This optimization process aims to enhance the model's accuracy and performance, making it more reliable for clinical use. While PSO itself does not directly improve interpretability, the resulting optimized model can provide more consistent and accurate predictions, which indirectly aids in understanding the model's behavior.\n\nFurthermore, the use of K-fold cross-validation ensures that the model's performance is evaluated rigorously. This method involves dividing the dataset into multiple folds and training the model on different subsets, which helps in assessing the model's generalization ability. Although cross-validation primarily focuses on performance evaluation, it contributes to the overall reliability and trustworthiness of the model, making it easier to interpret its results in a clinical context.\n\nIn summary, while the neural network model is inherently a black-box model, the use of feature selection and optimization techniques, along with rigorous evaluation methods, helps to enhance its interpretability. This makes the model more transparent and reliable for predicting chromosomal abnormalities during the first trimester of pregnancy.",
  "model/output": "The model developed in this study is a classification model. Its primary objective is to predict chromosomal abnormalities during the first trimester of pregnancy. The model utilizes machine learning techniques, specifically neural networks, to classify individuals as having chromosomal abnormalities or not. This classification is based on various input features collected from pregnant women, such as maternal age, BMI, smoking habits, and specific biochemical markers. The model's performance is evaluated using K-fold cross-validation to ensure its reliability and accuracy in making these classifications. The ultimate goal is to aid in decision-making processes for medical procedures related to pregnancy, thereby reducing unnecessary invasive tests and associated stress for mothers.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study is designed to ensure the reliability and robustness of the prediction model. We utilized the K-fold cross-validation technique, which is a widely recognized method for assessing the performance of machine learning models. This approach involves partitioning the dataset into k subsets, or \"folds.\" The model is then trained on k-1 folds and evaluated on the remaining fold. This process is repeated k times, with each fold serving as the validation set once. By averaging the results across all k trials, we obtain a more accurate estimate of the model's performance, as it generalizes to new, unseen data.\n\nThe key metrics evaluated include accuracy, precision, sensitivity, and specificity. Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Precision indicates the proportion of true positive results among all positive results predicted by the model. Sensitivity, also known as the true positive rate, assesses the model's ability to correctly identify positive cases. Specificity, or the true negative rate, evaluates the model's ability to correctly identify negative cases.\n\nThese metrics provide a comprehensive evaluation of the model's predictive capacity, ensuring that it can effectively distinguish between chromosomal abnormalities and normal cases during the first trimester of pregnancy. The use of K-fold cross-validation enhances the reliability of the results by reducing the risk of overfitting and providing a more robust assessment of the model's performance.",
  "evaluation/measure": "To evaluate the performance of the predictive models, several key metrics are reported. These metrics include accuracy, precision, sensitivity, and specificity. These measures are crucial for assessing the model's predictive capacity effectively. Accuracy indicates the proportion of true results (both true positives and true negatives) among the total number of cases examined. Precision, also known as the positive predictive value, measures the proportion of true positive results among all positive results. Sensitivity, or recall, assesses the ability of the model to identify true positive cases correctly. Specificity, on the other hand, evaluates the proportion of true negative results among all negative results. These metrics are computed using K-fold cross-validation, which involves partitioning the dataset into k subsets. The model is trained and evaluated on these subsets, enhancing system reliability through the assessment of varied random batches. This approach ensures that the model's performance is robust and generalizable to new data. The reported metrics provide a comprehensive evaluation of the model's effectiveness in predicting chromosomal abnormalities during the first trimester of pregnancy.",
  "evaluation/comparison": "In the evaluation phase of our study, we conducted a comprehensive comparison of different machine learning models to assess their performance in predicting chromosomal abnormalities during the first trimester of pregnancy. We specifically focused on comparing the optimized neural network with other established methods, such as decision trees and random forests.\n\nTo ensure a fair and rigorous evaluation, we employed K-fold cross-validation. This technique involves partitioning the dataset into k subsets, where the model is trained on k-1 subsets and tested on the remaining subset. This process is repeated k times, with each subset serving as the test set once. This approach helps in assessing the model's ability to generalize to new data and provides a reliable estimate of its performance.\n\nIn addition to the optimized neural network, we developed models using decision trees and random forests. These models were trained and evaluated using the same dataset and cross-validation technique. The performance metrics, including accuracy, precision, sensitivity, and specificity, were computed for each model to facilitate a comparative analysis.\n\nThe decision tree model serves as a simpler baseline, providing a straightforward approach to classification tasks. On the other hand, the random forest model aggregates the predictions of multiple decision trees, often leading to improved performance and robustness.\n\nBy comparing these models, we aimed to highlight the strengths and weaknesses of each approach. The optimized neural network, enhanced through techniques such as Particle Swarm Optimization, is designed to achieve higher accuracy and precision in predicting chromosomal abnormalities. However, the comparison with decision trees and random forests allows us to contextualize these results and understand the trade-offs between model complexity and performance.\n\nNot applicable.",
  "evaluation/confidence": "The evaluation of our study's performance metrics includes a rigorous statistical approach to ensure confidence in our results. We employed K-fold cross-validation, a method that enhances the reliability of our model by partitioning the dataset into k subsets. This technique allows for training and evaluation on varied random batches, providing a robust assessment of the model's predictive capacity.\n\nTo determine the statistical significance of our findings, we considered a significance level of 0.07 and a confidence level of 99%. This means that our results have a high degree of confidence, reducing the likelihood of Type I errors. The precision of our calculations was set at 0.05, ensuring that our sample size was adequate to detect true effects.\n\nThe sample size for our study was initially calculated to be a minimum of 173 individuals, but we increased it to 190 to account for a potential 10% dropout rate. For machine learning models, a larger dataset of at least 350 individuals is necessary for more precise model design and comprehensive evaluation. This larger sample size helps in achieving more reliable and statistically significant results.\n\nOur study aims to minimize model error by comparing the model's decisions with actual patient data. This process involves calculating accuracy, precision, sensitivity, and specificity, which are crucial metrics for assessing the model's predictive performance. By focusing on these metrics, we can claim that our method is superior to others and baselines, as it provides a more accurate and reliable prediction of chromosomal abnormalities.\n\nIn summary, our evaluation confidence is high due to the use of K-fold cross-validation, a large and statistically significant sample size, and a thorough assessment of performance metrics. These factors collectively ensure that our results are robust and reliable, supporting the claim that our method is superior to others and baselines.",
  "evaluation/availability": "No datasets were generated or analyzed during the current study. Therefore, no raw evaluation files are available for public release."
}