{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to the article are:\n\n- CC and RR designed the experiments, analyzed the data and wrote the article with the help of ISK, EP and MP.\n- ED and EP performed the experiments and analyzed the data.\n- IK performed the experiments.\n- TP analyzed the data and produced the supplemental informations.",
  "publication/journal": "International Journal for Parasitology: Drugs and Drug Resistance",
  "publication/year": "2023",
  "publication/pmid": "38000094",
  "publication/pmcid": "PMC10709126",
  "publication/doi": "https://doi.org/10.1016/j.ijpddr.2023.11.002",
  "publication/tags": "- Essential Oils\n- Parasite Development\n- Machine Learning\n- Bioinformatics\n- Statistical Analysis\n- Drug Resistance\n- Zygote Formation\n- Ookinete Maturation\n- Chemical Composition\n- Classification Models\n- Parasitology\n- Data Pretreatment\n- Hyperparameter Optimization\n- GFP-Fluorescent Cells\n- Binary Classification\n- In Vitro Experiments\n- Natural Compounds\n- Antiparasitic Activity\n- Data Modeling\n- Bioactive Compounds",
  "dataset/provenance": "The dataset used in this study originates from experiments conducted to evaluate the effectiveness of essential oils (EOs) on zygote and ookinete formation. Specifically, sixty different EOs were tested at concentrations of 0.05% and 0.025%. The data points consist of the total number of GFP-fluorescent cells, which include both zygotes and ookinetes, counted in oil-treated and control samples. The mean values of these counts were calculated for each oil across different replicates.\n\nThe dataset includes statistical analyses such as the percentage of inhibition of fluorescent cells and the corresponding P-values from two-tailed, unpaired t-tests. Additionally, the zygote to ookinete conversion rate (CR) was calculated by dividing the number of fluorescent elongated ookinetes by the total number of fluorescent cells. The effectiveness of each EO was determined based on specific thresholds for inhibition percentages and P-values.\n\nThis dataset builds upon previous work and community knowledge, particularly in the field of machine learning and essential oil research. The chemical composition of each EO and the ratio values of GFP-fluorescent cells were used to develop classification models. These models were created using various algorithms, including random forest, logistic regression, support vector machine, gradient boosting, decision tree, and k-nearest neighbors, implemented in the scikit-learn library.\n\nThe dataset underwent preprocessing steps, including dimensionality reduction through principal component analysis (PCA) to extract varying percentages of explained variance. Components with low occurrence were eliminated to reduce bias in the modeling process. Different treatment/control thresholds were also considered to develop the best classification models.",
  "dataset/splits": "The dataset was split into four balanced datasets based on the activity of essential oils (EOs) at a concentration of 0.05%. The active/inactive ratios in these splits ranged from 11/49 to 15/45. This separation was aligned with an arbitrary classification where a percentage of inhibition greater than 95% was considered active. The splits were created to evaluate the effectiveness of different machine learning algorithms in classifying the EOs based on their chemical compositions and their impact on zygote to ookinete formation. The specific details of each split, such as the exact number of data points in each category, are not provided, but the overall distribution aimed to ensure a balanced representation of active and inactive EOs across the datasets.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "The data used in this study is not publicly available. The supplementary data related to this article can be found online, but it does not include the raw datasets used for the analysis. The supplementary material provides additional tables and figures that support the findings but does not release the specific data splits or the raw data used in the machine learning models.\n\nThe supplementary data is accessible through the provided DOI link, ensuring transparency and reproducibility of the results presented in the publication. However, the raw datasets and specific data splits are not made publicly available, and there is no public forum where these datasets can be accessed. The supplementary data is released under the terms of the journal's policies, which typically allow for academic use and sharing but may have restrictions on commercial use.\n\nThe enforcement of data availability is managed through the journal's policies and the institutional guidelines followed by the authors. These policies ensure that the data supporting the findings is available upon request to the corresponding author, maintaining a balance between data sharing and protecting intellectual property.",
  "optimization/algorithm": "The optimization algorithm employed in our study utilized machine learning techniques to develop classification models for evaluating the effectiveness of essential oils (EOs). The machine-learning algorithm class used included several well-established algorithms: random forest (RF), logistic regression (LR), support vector machine (SVM), gradient boosting (GB), decision tree (DT), and k-nearest neighbors (KNN). These algorithms were implemented using the scikit-learn library in Python.\n\nThe algorithms used are not new; they are widely recognized and commonly applied in the field of machine learning. The choice of these algorithms was driven by their proven effectiveness in handling classification problems and their ability to provide robust performance metrics. The decision to use these established algorithms was based on their reliability and the extensive research that supports their use in various scientific and practical applications.\n\nThe focus of our publication is on the application of these machine-learning algorithms to a specific biological problem, rather than the development of new algorithms. Therefore, it was appropriate to publish the findings in a journal that specializes in parasitology and drug resistance, as it aligns with the primary research question and the context of the study. The optimization process involved refining the models through iterative random searches and cross-validation to ensure high classification accuracy and reliability. This approach allowed us to identify the most effective EOs and understand their chemical compositions better.",
  "optimization/meta": "The optimization process involved multiple stages of machine learning modeling, but it does not explicitly describe a meta-predictor. Instead, it details a series of steps to refine and select the best models based on their performance metrics.\n\nThe initial phase involved generating coarse models using various machine learning algorithms, including random forest (RF), logistic regression (LR), support vector machine (SVM), gradient boosting (GB), decision tree (DT), and k-nearest neighbors (KNN). These models were evaluated using cross-validated Matthews correlation coefficient (MCC) values, with a threshold set at greater than 0.7.\n\nSubsequent refinements increased the number of random iterations and replications to enhance model performance. The final selection of models was based on achieving high MCC values, with additional evaluations using accuracy, F1 score, and receiver operating characteristic (ROC) AUC. The best-performing models were then analyzed for feature importance and partial dependence to interpret their effectiveness.\n\nThe process did not involve using the outputs of other machine-learning algorithms as input for a meta-predictor. Instead, it focused on optimizing individual models through iterative refinement and selection based on performance metrics. The training data for each model was independent, as the process involved separate runs and evaluations for each algorithm and hyperparameter combination.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the dataset was suitable for classification modeling. Initially, the chemical composition of each essential oil (EO) and the ratio values of GFP-fluorescent cells counted in EO-treated and control samples were imported into datasets. This data was then subjected to dimensionality reduction and transformation using principal component analysis (PCA) to extract varying percentages of explained variance (70%, 80%, 90%, 99%, and 100%). This step helped in reducing the dimensionality of the data while retaining most of the important information.\n\nAdditionally, components represented by an occurrence of 1\u20134 times were eliminated from the training set to reduce bias in modeling. This preprocessing step was crucial for improving the robustness and generalizability of the models. Different treatment/control thresholds (0.013, 0.015, 0.03, and 0.04) were used at the EO concentration of 0.05% to further refine the data encoding. These thresholds helped in binarizing the EOs into active or inactive categories, which was essential for the classification task.\n\nThe preprocessing also included the use of Python programming language (version 3.7) along with libraries such as Scikit-learn (sklearn) and Pandas. These tools were instrumental in handling the data, performing the PCA, and implementing the classification algorithms. The data was pretreated to ensure it was clean and ready for the machine-learning models, which included random forest (RF), logistic regression (LR), support vector machine (SVM), gradient boosting (GB), decision tree (DT), and k-nearest neighbors (KNN). The preprocessing steps were designed to enhance the performance and accuracy of the machine-learning models.",
  "optimization/parameters": "In our study, we employed a comprehensive machine learning modeling strategy to optimize the classification of essential oils (EOs) based on their effectiveness. The process involved multiple stages of hyperparameter tuning and model refinement.\n\nInitially, we generated coarse models using a dataset that underwent dimensionality reduction through principal component analysis (PCA). We extracted components that explained 70%, 80%, 90%, 99%, and 100% of the variance. This step helped in reducing the dimensionality of the data while retaining most of the relevant information.\n\nTo further refine the models, we increased the number of random hyperparameter combination runs to 1000 and replicated this process 50 times. This iterative approach aimed to achieve a cross-validated Matthews correlation coefficient (MCC) value greater than 0.7, which was set as an arbitrary threshold for model selection. Models that met this criterion were saved for further analysis.\n\nIn the final stage of optimization, we performed an extensive random search with 10,000 iterations, replicated 50 times, to identify models with cross-validated MCC values higher than 0.7. This rigorous process led to the selection of 34 optimized machine learning models, characterized by MCC values ranging from 0.701 to 0.840. These models demonstrated high classification ability, as evidenced by other statistical coefficients such as accuracy, F1 score, and ROC AUC.\n\nThe selection of the final models was based on the highest MCC values, ensuring that the chosen models were robust and reliable. The number of parameters (p) used in the model was determined through this iterative process of hyperparameter tuning and model refinement. The specific number of parameters varied depending on the algorithm and the threshold values used, but the focus was on achieving the highest possible MCC values.",
  "optimization/features": "The input features for the machine learning models were derived from the chemical composition of each essential oil (EO) and the ratio values of GFP-fluorescent cells counted in EO-treated and control samples. The dataset underwent a pretreatment process that included dimensionality reduction through principal component analysis (PCA) to extract varying percentages of explained variance (70%, 80%, 90%, 99%, and 100%). Additionally, components represented by an occurrence of 1\u20134 times were eliminated from the training set to reduce bias in modeling.\n\nFeature selection was performed using the training set only. This involved removing components that appeared infrequently to ensure that the models were not biased by rare or noise features. The specific number of features used as input is not explicitly stated, but the process involved reducing the dimensionality of the data to focus on the most relevant chemical components and their effects on the GFP-fluorescent cells.",
  "optimization/fitting": "The fitting method employed in this study involved a multi-stage machine learning modeling process designed to optimize classification performance while mitigating both overfitting and underfitting.\n\nInitially, coarse models were generated using a dataset that underwent dimensionality reduction through principal component analysis (PCA). This step helped in reducing the dimensionality of the data, ensuring that the number of parameters was manageable relative to the number of training points. The coarse models were run with 100 random hyperparameter combinations to identify models with acceptable statistical coefficients, specifically those with cross-validated Matthews correlation coefficient (MCC) values greater than 0.4.\n\nTo further refine these models and address potential overfitting, the random iteration count was increased to 1000, and the process was replicated 50 times or until a cross-validated MCC value greater than 0.7 was achieved. This iterative approach helped in selecting models that generalized well to unseen data, thereby reducing the risk of overfitting.\n\nFinally, to ensure optimization convergence and to rule out underfitting, an additional random search was conducted with 10,000 iterations, replicated 50 times. This extensive search aimed to identify models with cross-validated MCC values higher than 0.7, ensuring that the models were not only complex enough to capture the underlying patterns in the data but also simple enough to avoid overfitting.\n\nThe resulting 34 optimized models exhibited cross-validated MCC values ranging from 0.701 to 0.840, indicating a high level of classification ability. Other statistical coefficients, such as accuracy, F1 score, and ROC AUC, were also calculated to validate the models' performance. This comprehensive approach ensured that the models were neither overfitted nor underfitted, providing robust and reliable classification results.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our machine learning models. One of the key methods used was cross-validation, specifically leave-some-out cross-validation with stratified K-fold. This approach helped us to monitor the average value of the Matthews correlation coefficient (MCC) obtained from 50 random cross-validation iterations, providing a more reliable estimate of model performance.\n\nAdditionally, we performed hyperparameter tuning using random search with a high number of iterations. Initially, we ran 1000 random hyperparameter combination runs, replicated up to 50 times. This was followed by a more extensive search with 10,000 random combinations to fine-tune the models further. This extensive hyperparameter tuning helped in finding the optimal model parameters that generalize well to unseen data.\n\nWe also applied dimensionality reduction techniques, such as principal component analysis (PCA), to extract a significant portion of the explained variance (70%, 80%, 90%, 99%, and 100%) from the dataset. This reduction helped in mitigating the risk of overfitting by focusing on the most informative features.\n\nFurthermore, we eliminated components represented by an occurrence of 1\u20134 times from the training set to reduce bias in modeling. This step ensured that the models were not overly influenced by rare or noisy features.\n\nThe selection of the final models was based on the highest MCC values, which is a robust metric for evaluating the quality of binary classifications, especially when the classes are of different sizes. This metric, along with other statistical coefficients such as accuracy, F1 score, and ROC AUC, provided a comprehensive evaluation of the models' classification ability.\n\nBy combining these techniques, we aimed to build models that not only performed well on the training data but also generalized effectively to new, unseen data, thereby minimizing the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the process involved multiple stages of random hyper-parameter combination runs. Initially, 100 random combinations were run, followed by a more intensive search with 1000 combinations replicated 50 times. The final stage involved 10,000 random combinations to ensure thorough optimization.\n\nThe models generated through this process were evaluated using metrics such as accuracy, F1 score, and Matthews correlation coefficient (MCC). The best models, characterized by high MCC values, were further analyzed for their feature importance and partial dependence.\n\nRegarding the availability of model files and optimization parameters, the supplementary material provides extensive details. Tables S5 through S8 in the supplementary material contain the specific configurations and performance metrics of the 34 optimized machine learning models. These tables include cross-validated MCC values, accuracy, F1 scores, and ROC AUC, offering a comprehensive view of the models' performance.\n\nThe supplementary data, including the detailed tables and additional information, can be accessed online. The link provided in the appendix directs readers to the supplementary data, ensuring transparency and reproducibility of our findings.\n\nThe publication adheres to ethical standards and declares no conflict of interest, reinforcing the integrity of the reported research. The research was co-financed by the European Union and Greek national funds, with additional support from various grants and foundations. This funding information is also available in the acknowledgements section.",
  "model/interpretability": "The models developed in this study are not entirely black-box. To ensure interpretability, feature importance (FI) and partial dependence (PD) were investigated for the 34 best machine learning models. This approach allowed for the differentiation of chemical components that positively contribute to the effectiveness of essential oils (EOs) from those that have a negative or no impact on their inhibitory potency.\n\nThe feature importances were weighted (WFIs) to highlight the positive or negative contributions of various chemical components. Since the models, despite using different threshold levels and machine learning algorithms, exhibited comparable classification power, the WFIs for each model were calculated and aggregated into a consensus modeling approach. This involved averaging the WFIs for the thirty most important and the thirty least important chemical components.\n\nThe Skater library was employed to evaluate the importance of each chemical component individually through FI and PD. The FIs are based on an information theoretic criterion, measuring the entropy in the change of predictions through the perturbation of a given feature. Positive or negative values of FIs were determined by multiplying them with the Pearson correlation coefficient derived from the PD distribution. This method provided a clear understanding of how each chemical component influences the model's predictions, making the models more transparent and interpretable.",
  "model/output": "The model developed in this study is a classification model. It was designed to categorize essential oils (EOs) as either active or inactive based on their effects on zygote formation and ookinete maturation. The classification was performed using various machine learning algorithms, including random forest (RF), logistic regression (LR), support vector machine (SVM), gradient boosting (GB), decision tree (DT), and k-nearest neighbors (KNN). The model's performance was evaluated using statistical coefficients such as accuracy, F1 score, and ROC AUC, which indicated a high level of classification ability. The final optimized models achieved cross-validated Matthews correlation coefficient (MCC) values ranging from 0.701 to 0.840, demonstrating their effectiveness in distinguishing between active and inactive EOs.",
  "model/duration": "The execution time for the machine learning models varied across different stages of the modeling process. Initially, coarse models were generated with 100 random hyperparameter combination runs. This was followed by a more refined search with 1000 random iterations, replicated 50 times, to achieve a cross-validated Matthews correlation coefficient (MCC) value greater than 0.7. This step was crucial for ensuring that the models met the desired performance criteria.\n\nTo further optimize the models, an additional random search was conducted with 10,000 iterations, also replicated 50 times. This extensive search was aimed at identifying models with even higher cross-validated MCC values, ensuring robust and reliable performance.\n\nThe entire process involved multiple stages of hyperparameter tuning and model validation, which collectively contributed to the overall execution time. The use of stratified K-fold cross-validation with 50 random iterations further added to the computational effort, ensuring that the models were thoroughly evaluated and optimized.\n\nIn summary, the modeling process was iterative and computationally intensive, with significant time invested in hyperparameter tuning and model validation to achieve the best possible performance.",
  "model/availability": "The source code for the machine learning models developed in this study is not publicly released. The models were created using Python, specifically version 3.7, along with libraries such as Scikit-learn and Pandas. The modeling process involved several steps, including data pretreatment, dimensionality reduction through principal component analysis, and the application of various classification algorithms. However, the specific code and scripts used to generate these models are not available for public access. Additionally, there is no executable, web server, virtual machine, or container instance provided for running the algorithm.",
  "evaluation/method": "The evaluation of the models involved several rigorous steps to ensure their robustness and accuracy. Initially, a second level of investigation was conducted with 1000 random hyperparameter combination runs, replicated up to 50 times, using the same pretreatment settings of the saved coarse models. This was followed by a final hyperparameter combination selection, which involved running 10,000 random combinations. The best models were then thoroughly investigated and analyzed using key metrics such as accuracy (ACC), F1 score, and Matthews correlation coefficient (MCC). These metrics were crucial in evaluating and validating the binary classification models.\n\nTo further validate the models, a leave-some-out cross-validation (CV) method was employed, utilizing two groups through the stratified K-fold method. This process monitored the average value of MCC obtained from 50 random CV iterations. The selection of the final models was based on the highest MCC values, ensuring that only the most accurate and reliable models were chosen.\n\nThe models characterized by the highest MCC values were numerically and graphically evaluated using additional metrics such as receiver operating characteristic (ROC) and precision-recall (PR). This comprehensive evaluation ensured that the models not only performed well in terms of classification accuracy but also provided insights into their performance across different thresholds and conditions.\n\nThe importance of each chemical component present in the essential oils (EOs) was independently evaluated through feature importance (FI) and partial dependence (PD). This evaluation was conducted using the Skater library, which implements an information theoretic criterion to measure the entropy in the change of predictions through perturbation of a given feature. The weighted feature importance (WFI) for each chemical component was obtained by multiplying the corresponding FI with the Pearson correlation coefficient determined with the PD distribution. This approach allowed for a detailed understanding of how each chemical component contributed to the effectiveness of the EOs.",
  "evaluation/measure": "In the evaluation of our binary classification models, several performance metrics were employed to ensure a comprehensive assessment of their effectiveness. The primary metrics reported include accuracy (ACC), the F1 score, and the Matthews correlation coefficient (MCC). These metrics were chosen for their ability to provide a balanced view of model performance, especially in the context of imbalanced datasets.\n\nAccuracy measures the proportion of correctly classified instances out of the total instances, offering a straightforward indication of the model's overall performance. The F1 score, which is the harmonic mean of precision and recall, provides a single metric that balances the concerns of both false positives and false negatives, making it particularly useful for evaluating models on imbalanced datasets.\n\nThe Matthews correlation coefficient (MCC) is a more robust metric that takes into account true and false positives and negatives, providing a value between -1 and 1. An MCC of +1 represents a perfect prediction, 0 indicates no better than random prediction, and -1 indicates total disagreement between prediction and observation. This metric was particularly crucial in our evaluation, as it offers a more nuanced view of model performance compared to accuracy alone.\n\nAdditionally, the receiver operating characteristic (ROC) curve and the precision-recall (PR) curve were used to visually assess the trade-off between true positive rate and false positive rate, and between precision and recall, respectively. These curves, along with their respective area under the curve (AUC) values, provided further insight into the models' performance across different threshold settings.\n\nThe selection of these metrics aligns with common practices in the literature, ensuring that our evaluation is both rigorous and representative of standard methodologies in machine learning and classification tasks. The use of multiple metrics allowed us to validate the models from different perspectives, ensuring that the final selected models were robust and reliable.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "The evaluation of the models involved several performance metrics, including accuracy, F1 score, and Matthews correlation coefficient (MCC). These metrics were used to assess and validate the binary classification models. The models were validated using a leave-some-out cross-validation method with stratified K-fold, monitoring the average MCC value obtained from 50 random cross-validation iterations. This approach ensures that the results are robust and not dependent on a single split of the data.\n\nThe selection of the final models was based on the highest MCC values, indicating strong correlation between predicted and actual values. Additionally, the models were evaluated numerically and graphically using accuracy, MCC, receiver operating characteristic (ROC), and precision-recall (PR) curves. These evaluations provide a comprehensive view of the models' performance, ensuring that they are reliable and effective.\n\nStatistical significance was ensured by setting thresholds for the ratio of treated to control samples and using a probability value of less than 0.01. This rigorous statistical approach confirms that the observed effects are not due to random chance, providing confidence in the superiority of the method over baselines. The use of multiple performance metrics and statistical validation methods strengthens the claim that the models are superior and reliable.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study focused on the analysis of essential oils (EOs) and their effects on zygote to ookinete formation in vitro, utilizing machine learning models to evaluate and validate the binary classification models. The evaluation metrics used included accuracy, F1 score, and Matthews correlation coefficient (MCC). The models were validated through leave-some-out cross-validation using the stratified K-fold method, monitoring the average value of MCC obtained from 50 random cross-validation iterations. The selection of the final models was based on the highest MCC values. The importance of each chemical component present in the EOs was evaluated independently through feature importance (FI) and partial dependence (PD). However, the specific raw evaluation files and datasets used in this process have not been made publicly accessible."
}