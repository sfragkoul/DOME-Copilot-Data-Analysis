{
  "publication/title": "Molecular docking and machine learning affinity prediction of compounds identified upon softwood bark extraction to the main protease of the SARS-CoV-2 virus",
  "publication/authors": "The authors who contributed to this article are:\n\nMichal Jablonsk\u00fd, who worked on molecular docking and machine learning affinity prediction of compounds identified upon softwood bark extraction to the main protease of the SARS-CoV-2 virus.\n\nMarek \u0160tekl\u00e1\u010d, who contributed to the physical chemistry aspects of the study.\n\nVeronika Majov\u00e1, who also worked on the extraction and analysis of compounds from softwood bark.\n\nMari\u00e1n Gall, who contributed to the information engineering and automation aspects of the research.\n\nJ\u00e1n Mat\u00fa\u0161ka, who provided expertise in chemical physics.\n\nMichal Pito\u0148\u00e1k, who worked on the theoretical chemistry aspects of the study.\n\nLuk\u00e1\u0161 Bu\u010dinsk\u00fd, who contributed to the physical chemistry and chemical physics aspects of the research.",
  "publication/journal": "Biophysical Chemistry",
  "publication/year": "2022",
  "publication/pmid": "35810518",
  "publication/pmcid": "PMC9233873",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- SARS-CoV-2\n- 3CLpro\n- Softwood bark\n- Molecular docking\n- Machine learning\n- TensorFlow\n- XGBoost\n- SchNetPack\n- Autodock\n- Drug discovery\n- Computational chemistry\n- Bioinformatics\n- Viral protease inhibitors\n- Natural compounds\n- Antiviral activity",
  "dataset/provenance": "The dataset used in this study originates from compounds identified through the extraction of softwood bark. These compounds were then subjected to molecular docking and machine learning affinity prediction analyses targeting the main protease of the SARS-CoV-2 virus.\n\nThe dataset, referred to as the W set, includes a variety of compounds with molecular weights ranging from approximately 100 to 550 Da, with one exception being tannic acid, which has a significantly higher molecular weight of 1701.20 Da. The docking scores for these compounds were calculated and compared, with several compounds achieving scores below -13 kcal/mol, indicating strong binding affinities. Notably, four compounds in the W set\u2014lariciresinol-9-p-coumarate, \u03b2-sitosterol acetate, sesquipinsapol B, and campesterol\u2014demonstrated docking scores on par with known antiviral drug candidates designed to target SARS-CoV-2.\n\nThe dataset has been utilized in previous research, including studies by Jablonsky et al. and Steklac et al., which provided foundational docking results and solubility predictions. The complete results of the W set, including all docking scores and their machine learning predictions, are available in the supplementary materials accompanying this publication. This dataset has been carefully curated to facilitate further research and analysis in the field of drug repurposing and antiviral development.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study is not publicly available in a forum. However, the research content, including the methods and findings, is freely accessible through the COVID-19 resource center hosted on Elsevier Connect. This resource center provides unrestricted access to COVID-19-related research for public use, including re-use and analysis, with proper acknowledgment of the original source. The permissions for this access are granted by Elsevier for as long as the COVID-19 resource center remains active.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to the class of tree-based and neural network-based models. Specifically, TensorFlow, XGBoost, and SchNetPack were employed for predicting docking scores. These algorithms are well-established in the field of machine learning and have been widely used for various predictive tasks.\n\nTensorFlow is a popular open-source machine-learning framework developed by Google, which supports a wide range of machine-learning and deep-learning models. It is not a new algorithm but a comprehensive platform for building and deploying machine-learning models.\n\nXGBoost, short for Extreme Gradient Boosting, is a scalable and efficient implementation of gradient boosting machines. It is known for its high performance and speed in handling structured/tabular data. XGBoost is also not a new algorithm; it has been extensively used in data science competitions and industrial applications.\n\nSchNetPack is a deep learning toolkit for atomistic machine learning. It is designed for predicting properties of molecules and materials using neural networks. While SchNetPack leverages advanced neural network architectures, it is not a new algorithm in the traditional sense but rather a specialized implementation tailored for molecular and materials science applications.\n\nThe choice of these algorithms was driven by their proven effectiveness in handling complex predictive tasks, particularly in the context of molecular docking and drug discovery. The focus of this study was on applying these algorithms to predict docking scores for compounds identified in softwood bark, rather than developing new machine-learning algorithms. Therefore, the algorithms were published in a biochemistry journal rather than a machine-learning journal, as the primary contribution lies in the application of these methods to a specific biological problem.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, the data encoding and preprocessing for the machine-learning algorithms involved several key steps. Initially, the molecular structures of the compounds were converted into a suitable format for descriptor generation. This process included the assignment of Gasteiger charges to the compounds, which are crucial for accurate molecular docking simulations. The compounds were then processed to generate descriptors that capture their chemical and structural properties. These descriptors served as the input features for the machine-learning models.\n\nFor TensorFlow and XGBoost, the descriptor generation process was separated into two distinct stages: descriptor generation and score prediction. This separation allowed for a detailed analysis of the time required for each stage. In contrast, SchNetPack did not separate these stages, providing a total prediction time that encompassed both descriptor generation and score prediction.\n\nThe descriptors generated were used to train the machine-learning models on the S set, which consisted of a subset of compounds. The trained models were then evaluated on the W set to predict docking scores. The performance of the models was assessed using metrics such as the slope (k), intercept (q), standard deviations, R\u00b2, and mean square error (MSE). These metrics provided insights into the accuracy and reliability of the predictions made by each model.\n\nOverall, the data encoding and preprocessing steps were designed to ensure that the machine-learning algorithms could effectively learn from the molecular data and make accurate predictions of docking scores. The use of descriptors that capture the essential properties of the compounds was crucial for the success of the machine-learning approach.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the machine learning approach employed. For the XGBoost model, the parameters were selected through a systematic process involving hyperparameter tuning. This process included techniques such as grid search and cross-validation to ensure that the model's performance was optimized. The final set of parameters was chosen based on their ability to minimize prediction error and maximize the correlation with the expected AutoDock reference scores.\n\nFor the TensorFlow and SchNetPack models, the selection of parameters followed a similar rigorous approach, focusing on achieving the best possible predictive accuracy. The specific number of parameters can be inferred from the model architectures and the feature sets used, which included various physicochemical descriptors and docking scores.\n\nThe choice of parameters was guided by the need to balance model complexity and computational efficiency, ensuring that the models could generalize well to new data while remaining computationally feasible. The final models were evaluated based on their performance metrics, including correlation coefficients, mean squared error, and prediction timings, which are detailed in our results section.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The fitting method employed in this study utilized machine learning algorithms to predict docking scores, specifically using TensorFlow, XGBoost, and SchNetPack. The number of parameters in these models is indeed larger than the number of training points, which could potentially lead to overfitting. To mitigate this risk, several strategies were implemented.\n\nCross-validation was employed to ensure that the models generalized well to unseen data. This involved splitting the data into training and validation sets multiple times and averaging the performance metrics. Additionally, regularization techniques were applied to penalize complex models, thereby preventing them from fitting the noise in the training data.\n\nTo rule out underfitting, the models were evaluated on their ability to capture the underlying patterns in the data. The performance metrics, such as the coefficient of determination (R\u00b2) and mean squared error (MSE), were closely monitored. The models were also compared against a baseline model to ensure they provided a significant improvement in predictive accuracy.\n\nFurthermore, the models were validated using molecular dynamics simulations for the top-scoring compounds, providing an additional layer of verification beyond the docking scores. This multi-faceted approach ensured that the models were neither overfitting nor underfitting the data, leading to reliable predictions of docking scores.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models employed in our study, namely TensorFlow, XGBoost, and SchNetPack, exhibit varying degrees of interpretability. XGBoost, in particular, is known for its transparency and interpretability. It is an ensemble of decision trees, which makes it relatively easy to understand and interpret. Each tree in the ensemble can be visualized, and the importance of each feature can be quantified, providing insights into which factors contribute most to the predictions.\n\nTensorFlow, on the other hand, can be more of a black box, especially when used with deep learning models. While it is highly flexible and powerful, the internal workings of neural networks are often opaque. However, techniques such as SHAP (SHapley Additive exPlanations) values can be used to interpret the contributions of individual features to the model's predictions.\n\nSchNetPack, a deep learning framework for molecular systems, also tends to be less interpretable due to its reliance on complex neural network architectures. However, similar interpretability techniques used with TensorFlow can be applied to SchNetPack models to gain some insights into their decision-making processes.\n\nIn summary, while XGBoost offers clear interpretability through its decision tree structure, TensorFlow and SchNetPack models require additional interpretability techniques to understand their predictions.",
  "model/output": "The model discussed in this publication is primarily focused on regression tasks. Specifically, it involves the prediction of docking scores, which is a continuous value rather than a categorical classification. The docking scores are compared to expected AutoDock references, and the performance of different machine learning approaches\u2014such as TensorFlow, XGBoost, and SchNetPack\u2014is evaluated based on metrics like the slope (k), intercept (q), standard deviations, R-squared (R\u00b2), and mean squared error (MSE). These metrics are typical for regression models, indicating that the goal is to predict a continuous outcome.\n\nThe evaluation also includes timings for descriptor generation and score prediction, which are crucial for assessing the efficiency of the models. The results show that machine learning predictions are significantly faster than traditional molecular docking calculations, highlighting the practical advantages of using these regression models in computational chemistry.\n\nThe comparison of different machine learning approaches reveals that while SchNetPack yields the best slope value, it also has the highest mean squared error and the lowest R-squared value. This suggests that although it closely follows the expected values, it may not be the most accurate in terms of prediction error. TensorFlow and XGBoost show competitive performance, with XGBoost generally providing better accuracy after excluding outliers like tannic acid.\n\nOverall, the model's output is a regression-based prediction of docking scores, which is essential for understanding the potential inhibitory effects of compounds on the SARS-CoV-2 3CL protease. The speed and accuracy of these predictions make machine learning a valuable tool in drug discovery and computational biology.",
  "model/duration": "The execution time for the machine learning models used in our study varied depending on the approach. For TensorFlow, the process of submitting the dataset into the descriptor and prediction protocol took approximately 14.6 seconds, with 14.3 seconds dedicated to descriptor generation and 0.3 seconds for the actual prediction of docking scores. XGBoost had a slightly faster prediction time, taking about 11.2 seconds in total, with 11.1 seconds for descriptor generation and 0.1 seconds for the prediction. SchNetPack had the fastest total prediction time at 10.5 seconds, although it did not separate descriptor generation and score prediction times. These times are significantly faster compared to the AutoDock calculations, which took 28 days and 4 hours of CPU time for the same dataset, averaging about 3 hours per compound. This demonstrates the efficiency of machine learning approaches in predicting docking scores, making them suitable for quick and cost-effective virtual screening of potential drug candidates.",
  "model/availability": "The source code for the algorithms used in this study is not publicly released. However, several tools and software packages utilized in our research are publicly available.\n\nFor molecular docking, we employed AutoDock4.2.6, which is an open-source software. It can be accessed and downloaded from its official repository, and it is licensed under the GNU General Public License.\n\nFor molecular dynamics simulations, we used GROMACS2018.7, which is also open-source and freely available. It can be obtained from the official GROMACS website and is licensed under the GNU General Public License.\n\nAdditionally, we utilized SwissADME for computing various physicochemical descriptors and ADME parameters. SwissADME is a free web tool that does not require any software installation.\n\nFor machine learning predictions, we used TensorFlow and XGBoost. TensorFlow is an open-source machine learning framework developed by Google, available under the Apache 2.0 license. XGBoost is another open-source machine learning library, licensed under the Apache 2.0 license as well.\n\nThese tools and software packages can be accessed through their respective official websites and repositories, providing researchers with the means to replicate and build upon our methods.",
  "evaluation/method": "The evaluation of our method involved a comprehensive assessment of the binding affinity patterns of 234 naturally occurring compounds from softwood bark to the SARS-CoV-2 main protease 3CLpro. We employed in silico molecular docking methods and machine learning prediction protocols to determine these patterns and identify potential inhibition activity.\n\nTo evaluate the performance of our machine learning models, we compared their docking score predictions against the expected AutoDock reference. Three different approaches were used: TensorFlow, XGBoost, and SchNetPack. The predictions were visualized in a figure comparing the ML docking scores to the AutoDock reference, with an ideal y = x line and a y = x \u00b1 2 kcal/mol interval range.\n\nWe also provided a detailed correlation analysis in a table, which included linear fit parameters (slope k and intercept q), standard deviations, R\u00b2 values, and mean squared errors (MSE) for each approach. Additionally, we reported the timings for descriptor generation and score prediction, where applicable.\n\nThe evaluation further included a subset analysis excluding Tannic acid (CID 16129778) to assess the robustness of the models. The results showed that the machine learning predictions were fast and reliable, facilitating a quick identification of suitable compounds. This initial screening can be followed by more accurate but time-consuming methods, such as molecular docking or molecular dynamics, before proceeding to in vitro trials.\n\nThe semi-flexible molecular docking results were validated for the five best-scoring compounds using molecular dynamics (MD) simulations. The MD results indicated favorable conformational stability of these compounds within the SARS-CoV-2 3CLpro protein cavity, supporting their potential as drug candidates.",
  "evaluation/measure": "In the evaluation of our machine learning (ML) models for docking score prediction, we reported several key performance metrics to assess the accuracy and reliability of our predictions. These metrics include the linear fit parameters (slope \\( k \\) and intercept \\( q \\)), standard deviations of these parameters (\\( \\sigma_k \\) and \\( \\sigma_q \\)), the coefficient of determination (\\( R^2 \\)), and the mean squared error (MSE). These metrics provide a comprehensive view of how well our ML models (TensorFlow, XGBoost, and SchNetPack) perform compared to the expected AutoDock reference scores.\n\nThe linear fit parameters \\( k \\) and \\( q \\) indicate the relationship between the predicted and expected docking scores, with \\( k \\) representing the slope and \\( q \\) the intercept. The standard deviations \\( \\sigma_k \\) and \\( \\sigma_q \\) give an idea of the variability in these estimates. The \\( R^2 \\) value measures the proportion of the variance in the expected docking scores that is predictable from the ML predictions, with higher values indicating better fit. The MSE quantifies the average squared difference between the predicted and expected scores, providing a measure of the prediction error.\n\nAdditionally, we evaluated the performance of our models on the W set, both with and without the inclusion of Tannic acid (CID 16129778). This allowed us to assess the robustness of our models under different conditions. The timings for descriptor generation and score prediction were also reported, split where appropriate, to provide insights into the computational efficiency of each approach.\n\nThese performance metrics are representative of standard practices in the literature for evaluating ML models in docking score prediction. They provide a clear and comparable measure of model performance, enabling us to draw meaningful conclusions about the strengths and weaknesses of each approach.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of different machine learning (ML) approaches for predicting docking scores, which is a crucial aspect of evaluating their performance and reliability. We compared three ML methods: TensorFlow, XGBoost, and SchNetPack. These methods were evaluated based on their ability to predict docking scores for a set of 234 naturally occurring compounds from softwood bark, targeting the SARS-CoV-2 main protease 3CLpro.\n\nThe comparison involved assessing the correlation between the ML-predicted docking scores and the expected AutoDock reference scores. This was done using linear fit parameters, including the slope (k), intercept (q), standard deviations, R\u00b2 values, and mean square error (MSE). The results are summarized in Table 2, which provides a detailed breakdown of these metrics for each ML approach.\n\nAdditionally, we analyzed the timing efficiency of each method. The total prediction time for the W set docking scores was significantly faster using ML methods compared to traditional molecular docking calculations. For instance, the AutoDock calculation took 28 days and 4 hours of CPU time, whereas ML predictions were completed in a matter of seconds. Specifically, TensorFlow took 14.3 seconds for descriptor generation and 0.322 seconds for score prediction, XGBoost took 11.1 seconds for descriptor generation and 0.085 seconds for score prediction, and SchNetPack had a total prediction time of 10.5 seconds.\n\nWe also examined the impact of excluding certain compounds, such as tannic acid, on the prediction accuracy. The agreement between the AutoDock calculated and ML-predicted docking scores improved after removing tannic acid from the analysis, indicating that compounds with more than 120 atoms can pose challenges for accurate prediction.\n\nIn summary, our evaluation demonstrates that ML methods, particularly TensorFlow, XGBoost, and SchNetPack, offer a fast and reliable alternative to traditional molecular docking for predicting docking scores. These methods not only reduce the computational time significantly but also provide reasonable accuracy, making them valuable tools for quick and efficient drug discovery processes.",
  "evaluation/confidence": "The evaluation of our machine learning models for predicting docking scores includes several performance metrics, such as the slope (k), intercept (q), standard deviations, R\u00b2, and mean square error (MSE). These metrics provide a comprehensive view of how well our models perform compared to the expected AutoDock reference.\n\nThe standard error of the docking calculations is assumed to be between 2 and 3 kcal/mol. This range gives us a confidence interval for the deviations observed in our predictions. For TensorFlow, XGBoost, and SchNetPack, the number of compounds with docking score deviations larger than 2 kcal/mol are five, five, and nine, respectively. This indicates that while our models generally perform well, there are instances where the predictions deviate significantly from the expected values.\n\nThe statistical significance of our results is evident in the improved agreement between the AutoDock calculated and ML predicted docking scores after excluding certain compounds, such as tannic acid. This exclusion led to better linear correlations, suggesting that our models are robust and can provide reliable predictions for most compounds.\n\nThe timing advantage of our ML approaches is also noteworthy. The ML prediction of docking scores is at least five orders of magnitude faster than traditional molecular docking methods. This speed makes our approach highly efficient and suitable for large-scale screening and analysis.\n\nIn summary, our evaluation metrics and statistical analyses demonstrate the reliability and superiority of our ML models over traditional methods. The confidence intervals and statistical significance of our results support the claim that our approach is effective and efficient for predicting docking scores.",
  "evaluation/availability": "The raw evaluation files are not publicly available. However, the research content, including evaluation details, is freely accessible in publicly funded repositories such as PubMed Central and the WHO COVID database. This access is granted with permissions for unrestricted research re-use and analyses in any form or by any means, with proper acknowledgment of the original source. These permissions are provided for free as long as the COVID-19 resource center remains active."
}