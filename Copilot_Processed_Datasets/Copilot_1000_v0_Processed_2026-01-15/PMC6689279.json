{
  "publication/title": "Enabling data-driven clinical quality assurance: predicting adverse event reporting in clinical trials using machine learning",
  "publication/authors": "The authors who contributed to the article are Timoth\u00e9 M\u00e9nard, Yves Barmaz, Bj\u00f6rn Koneswarakantha, Rich Bowling, and Leszek Popko. Additionally, Antoinette Chan and Elaine (Min) Zou provided content review for the research.\n\nThe main authors were employed by Roche/Genentech at the time this research was completed. Their specific contributions to the paper are not detailed, but their involvement suggests roles in the development, testing, and implementation of the predictive model for detecting adverse event under-reporting in clinical trials. The model leverages machine learning techniques, particularly gradient boosting machines, to identify high-risk study sites and improve the efficiency of quality assurance processes. The authors' work is part of a broader effort to enhance clinical quality assurance through advanced analytics.",
  "publication/journal": "Drug Safety",
  "publication/year": "2019",
  "publication/pmid": "31123940",
  "publication/pmcid": "PMC6689279",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Machine Learning\n- Predictive Modeling\n- Adverse Event Detection\n- Under-reporting\n- Gradient Boosting Machines\n- Clinical Trials\n- Quality Assurance\n- Data Analysis\n- Risk-Based Approach\n- Statistical Learning",
  "dataset/provenance": "The dataset utilized in our study originated from clinical trials sponsored by Roche/Genentech. We compiled data from 104 completed studies, encompassing a variety of molecule types and disease areas. The dataset included information from 3231 individual investigator sites, involving 18,682 study subjects who participated in 288,254 study visits. All study subject data was used in a de-identified format to ensure privacy and compliance with ethical standards.\n\nTo mitigate the risk of under-reporting, we focused on data from completed and terminated clinical trials where adverse event (AE) reconciliation and source data verification (SDV) had been performed. This approach ensured the reliability and completeness of the data.\n\nThe dataset included six common patient data attributes across the studies: demographics, medical history, concomitant medications, vitals, visits, and adverse events. These attributes were selected following the Study Data Tabulation Model (SDTM) standard. Additionally, we incorporated study attributes available in the Roche Clinical Trial Management System (CTMS), such as study type, route of administration, concomitant agents, disease area, blinding, randomization, and study phase.\n\nMolecules were classified using the Anatomical Therapeutic Chemical (ATC) classification system to ensure clinical relevance in terms of AE reporting. Disease areas were categorized into groups such as healthy participants, malignancies, autoimmune diseases, neurodegenerative diseases, respiratory diseases, skin disorders, lung diseases, infectious diseases, and others. This classification reflects the populations enrolled in our clinical trials.\n\nThe dataset was curated to include a diverse range of clinical studies, ensuring that the model could generalize to the variety and volume of studies conducted. This comprehensive approach allowed us to develop a robust predictive model for detecting suspected AE under-reporting.",
  "dataset/splits": "In our study, we divided our dataset into three distinct splits: training, validation, and test sets. This division is a common practice in machine learning to ensure that the model is trained, tuned, and evaluated effectively.\n\nThe training set, which constitutes approximately 60% of the total data, was used to minimize the loss function and train the model parameters. The validation set, making up about 20% of the data, was employed to control for overfitting and to optimize the model's hyperparameters through grid search. The remaining 20% of the data was allocated to the test set, which was used to assess the model's generalization performance on new, unseen data.\n\nIt is important to note that the data could not be randomly assigned to these sets due to our focus on the count of adverse events reported by a single site. Instead, we worked with subsets of data corresponding to each site and assigned these subsets to the training, validation, and test sets. This approach ensured that data from the same site did not appear in more than one set, preventing data leakage and maintaining the integrity of our evaluation process.\n\nAdditionally, the test set was also utilized for simulating under-reporting scenarios, which helped us evaluate how well our model could detect under-reporting anomalies. This simulation was crucial as it allowed us to assess the model's performance in a controlled environment where real-world under-reporting data was not available.",
  "dataset/redundancy": "The datasets were split into training, validation, and test sets, with approximately 60% of the sites assigned to the training set, and 20% each to the validation and test sets. This split was not random; instead, it was stratified by molecule class to ensure representation of every class in each set. This stratification was crucial because the molecule class significantly influences the number of adverse events (AEs).\n\nThe training and test sets are independent. To enforce this independence, we worked on subsets specific to each site and assigned these subsets to the respective sets. This approach prevented data leakage, which could occur if a patient's data were present in more than one set. Additionally, we simulated under-reporting using the test set, further ensuring that the training and test sets remained independent.\n\nThe distribution of our datasets differs from many previously published machine learning datasets. Typically, datasets are split randomly, but in our case, the non-random split was necessary due to our focus on the count of adverse events reported by a single site. This required a more careful approach to ensure that the model's performance could be generalized to new, unseen data. The stratification by molecule class also sets our dataset distribution apart, as it ensures that each set contains a representative sample of different molecule classes, which is critical for the model's ability to predict AEs accurately.",
  "dataset/availability": "The data used in our study is not publicly available. The dataset was derived from Roche/Genentech-sponsored clinical trials, encompassing 104 completed studies across various molecule types and disease areas. It includes data from 3231 individual investigator sites, involving 18,682 study subjects who underwent 288,254 study visits. The data was used in a de-identified format to ensure privacy and compliance with regulatory standards.\n\nThe dataset was curated to include six common patient data attributes: demographics, medical history, concomitant medications, vitals, visits, and adverse events, following the Study Data Tabulation Model (SDTM) standard. Additionally, study attributes from the Roche Clinical Trial Management System (CTMS) were included, such as study type, route of administration, concomitant agents, disease area, blinding, randomization, and study phase.\n\nThe data was split into training, validation, and test sets. The training set was used to minimize the loss function with respect to the model parameters, the validation set to control for overfitting and to pick the hyper-parameters of the model via grid search, and the test set to assess the generalization performance to new data. The test set was also used for the simulation of under-reporting.\n\nThe data splits were not randomly assigned at the individual visit level due to the focus on the count of adverse events reported by a single site. Instead, subsets of visits were assigned to the training, validation, and test sets based on the site level.\n\nThe data was not released in a public forum due to the sensitive nature of clinical trial data and the need to protect patient privacy. The data was used internally within Roche/Genentech for the purposes of this study and for ensuring the quality and integrity of clinical trial data.",
  "optimization/algorithm": "The machine-learning algorithm class used is gradient boosting machines. This is a well-established ensemble method that builds predictive models by combining the outputs of multiple decision trees. It is not a new algorithm, having been inspired by gradient descent methods widely used in optimization.\n\nGradient boosting machines were chosen after evaluating several algorithms suitable for optimizing the loss function. Generalized linear models and neural networks were also considered, but neural networks were dismissed due to the limited signal-to-noise ratio, which did not justify the computational investment. Gradient boosting machines were found to provide the best performance among the tested algorithms.\n\nThe decision to use gradient boosting machines was influenced by their ability to achieve high accuracy through the aggregation of predictions from many trees in a weighted average. This iterative process of updating predictions with new trees that replicate the current gradient of the loss function makes gradient boosting machines a powerful tool for predictive modeling.\n\nThe implementation of gradient boosting machines was done using the Sparkling Water implementation of H2O, which allowed for easy scalability and potential export as a Spark application. This choice was made to ensure that the entire pipeline could be easily adapted to a cloud-based solution if needed.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it relies on a single machine learning algorithm, specifically gradient boosting machines, to optimize the loss function and make predictions. This approach was chosen after evaluating several algorithms, including generalized linear models and neural networks. Neural networks were dismissed due to the limited signal-to-noise ratio, which did not justify the computational investment. Gradient boosting machines were selected for their superior performance in this context.\n\nGradient boosting machines work by constructing an ensemble of regression trees. Each tree successively splits regions of the feature space and assigns values to these regions. The ensemble method aggregates the predictions of many trees in a weighted average, significantly improving accuracy compared to a single tree. This iterative process is inspired by gradient descent methods, which update predictions to minimize the loss function.\n\nThe data used for training, validation, and testing was carefully split to ensure independence. The training set was used to minimize the loss function, the validation set to control for overfitting and select hyperparameters, and the test set to assess generalization performance. This splitting was done at the site level to maintain the integrity of the data and ensure that the model could generalize to new, unseen data.\n\nIn summary, the model does not use data from other machine-learning algorithms as input. It is based solely on gradient boosting machines, and the training data was independently split to ensure robust model performance.",
  "optimization/encoding": "For the machine-learning algorithm, data encoding and preprocessing were crucial steps to ensure the features were in a suitable format for model training. Categorical variables, such as sex, ethnicity, disease area, molecule class, mechanism of action, and route of administration, were transformed using one-hot encoding. This technique converts categorical data into a binary matrix representation, allowing the algorithm to handle these variables effectively.\n\nContinuous variables, including age, were adjusted to follow a roughly normal distribution. Specifically, the age variable was raised to the power of 1.4. This transformation helped in normalizing the age distribution, making it more suitable for the machine-learning model.\n\nStandardization was applied to continuous variables to ensure they had a mean of zero and a standard deviation of one. This process is essential for algorithms that are sensitive to the scale of the input features, as it helps in improving the convergence speed and the overall performance of the model.\n\nBefore feeding the data into the machine-learning algorithm, features were selected and optimized through the minimization of a loss function. This process involved using machine learning algorithms to identify the most relevant features that contributed significantly to predicting adverse events.\n\nThe final model utilized 54 features, with the most influential ones including the number of previous visits made by the patient, the cumulative count of concomitant medications up to the current visit, and boolean indicators for specific disease types and administration routes. These features were carefully chosen to capture the most relevant information for predicting adverse events accurately.",
  "optimization/parameters": "In our study, we utilized a total of 54 features as input parameters for our machine learning model. These features were carefully selected to capture various aspects of patient visits, including demographic characteristics, medical history, concomitant medications, vital signs, and disease-specific attributes.\n\nThe selection of these features involved several steps. Initially, we projected all data attributes to the visit level. For demographic characteristics that were constant or had a direct dependence on the date, this process was straightforward. For medical history, we counted the events that occurred before each visit, as new entries from screening in the medical history section of the electronic case report form (eCRF) often correspond to adverse events (AEs) that should be reported. Similarly, we counted concomitant medications because the more drugs a patient receives, the more AEs they are likely to experience. From the vitals reported at each visit, we included blood pressure and its relative variation since the previous visit, as well as patient weight and its trends over the last three weeks.\n\nCategorical variables were one-hot encoded, the age variable was raised to the power of 1.4 to achieve a roughly normal distribution, and continuous variables were standardized. This preprocessing ensured that our features were in a suitable format for the machine learning algorithms.\n\nThe final set of 54 features was determined through optimization of a loss function, which helped in selecting the most relevant features for predicting the number of adverse events reported during a visit. The highest contributions came from features such as the number of previous visits made by the patient, the cumulative count of concomitant medications up to the current visit, whether the disease was a malignancy, whether the disease was pulmonary but non-malignant, and whether the administration was oral. These features were found to be the most informative in our model.",
  "optimization/features": "In our study, we utilized a total of 54 features as input for our model. These features were carefully selected and engineered to capture various aspects of patient visits and their medical history.\n\nFeature selection was indeed performed to identify the most relevant features for predicting adverse events. This process involved using machine learning algorithms to optimize a loss function, ensuring that the selected features contributed significantly to the model's predictive power.\n\nThe feature selection process was conducted using the training set only. This approach helps to prevent data leakage and ensures that the model's performance on the validation and test sets is a true reflection of its generalization capability. By relying solely on the training set for feature selection, we maintain the integrity of the validation and test sets, which are crucial for assessing the model's performance on unseen data.",
  "optimization/fitting": "The fitting method employed in our study utilized gradient boosting machines, which are known for their ability to handle a large number of parameters relative to the number of training points. To address potential overfitting, we implemented several strategies. Firstly, we used ensemble methods, which aggregate the predictions of many trees in a weighted average, thereby reducing the risk of overfitting that can occur with individual trees. Secondly, we employed regularization techniques within the gradient boosting framework to penalize complex models, ensuring that the model did not become too tailored to the training data. Additionally, we validated our model using a separate validation set, which helped in tuning hyperparameters and preventing overfitting.\n\nTo rule out underfitting, we ensured that our model was complex enough to capture the underlying patterns in the data. This was achieved by iteratively adding trees to the ensemble until the performance on the validation set plateaued, indicating that the model had captured the necessary complexity. Furthermore, we used cross-validation techniques to assess the model's performance across different subsets of the data, ensuring that it generalized well to unseen data. The use of a robust loss function, specifically the Poisson deviance for Poisson processes, also helped in fitting the model appropriately to the data distribution. Overall, these measures ensured that our model neither overfitted nor underfitted the data, providing a balanced and reliable predictive performance.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods we used was the splitting of our data into three distinct sets: training, validation, and test sets. The training set was used to minimize the loss function with respect to the model parameters. The validation set played a crucial role in controlling for overfitting and in selecting the optimal hyperparameters through a process called grid search. This approach helped us to fine-tune our model and avoid overfitting to the training data. Additionally, the test set was used to assess the model's generalization performance on new, unseen data, providing a reliable estimate of its real-world effectiveness.\n\nAnother important technique we utilized was feature engineering and selection. We carefully constructed features that were relevant to the prediction task, such as the number of previous visits, cumulative count of concomitant medications, and disease characteristics. We also applied one-hot encoding to categorical variables, standardized continuous variables, and transformed the age variable to achieve a roughly normal distribution. These preprocessing steps helped to reduce the complexity of the model and improve its generalization ability.\n\nFurthermore, we chose gradient boosting machines as our primary algorithm, which inherently includes regularization techniques. Gradient boosting machines build an ensemble of decision trees in a sequential manner, each tree trying to correct the errors of the previous ones. This iterative process helps to reduce overfitting by focusing on the most informative features and minimizing the impact of noise in the data.\n\nIn summary, our approach to preventing overfitting involved a combination of data splitting, feature engineering, and the use of a robust algorithm like gradient boosting machines. These techniques collectively ensured that our model was well-generalized and performed reliably on new data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in our study is not a blackbox but rather leverages interpretable machine learning techniques. We utilized gradient boosting machines, which are ensemble methods that aggregate the predictions of multiple decision trees. This approach allows for a certain level of interpretability. Each decision tree in the ensemble can be visualized and understood, showing how different features contribute to the final prediction. This transparency is crucial for stakeholders in clinical quality assurance, as it enables them to understand the reasoning behind the model's predictions. For instance, the model can highlight specific features or combinations of features that indicate a higher risk of under-reporting at a particular site. This interpretability helps build trust and facilitates the integration of the model into existing quality assurance workflows. Additionally, the use of a significance level score for each site allows for a clear ranking of sites by their risk of under-reporting, providing a straightforward metric for prioritizing investigations.",
  "model/output": "The model developed is primarily a classification model designed to detect suspected adverse event (AE) under-reporting in clinical trials. It focuses on identifying high-risk study sites that may be under-reporting AEs. The model uses a loss function that is minimized through machine learning techniques, specifically gradient boosting machines. This approach allows the model to iteratively improve its predictions by constructing an ensemble of regression trees, each trying to replicate the current gradient of the loss function.\n\nThe performance of the model is evaluated using the area under the receiver operating characteristic (ROC) curve (AUC-ROC). The model achieved AUC-ROC scores of 0.62, 0.79, and 0.92 for different scenarios of AE under-reporting (25%, 50%, and 75%, respectively). These scores indicate the model's ability to distinguish between sites that are under-reporting AEs and those that are not.\n\nThe model's output includes a significance level score for each site, which allows for the ranking of sites by their risk of under-reporting. This ranking is used to define alert levels (AL3, AL2, AL1, AL0), with AL3 indicating the highest risk. By focusing on the top 14% of high-risk sites, the model can detect a significant proportion of sites with varying levels of under-reporting. For example, it can identify 95% of small sites with no under-reporting, 80% of sites with 75% under-reporting, and so on.\n\nThe model's output is visualized in a dashboard, which provides a holistic and nearly real-time quality oversight for safety reporting. This dashboard is used by quality program leads, auditors, and other stakeholders to monitor and address potential under-reporting issues in clinical trials. The model's predictions trigger additional quality activities, such as audits, for sites that are flagged as high-risk.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for our machine learning model is not publicly released. However, the implementation of the gradient boosting machine used in our model is available through the Sparkling Water implementation of H2O. This allows our entire pipeline to be easily exported as a Spark application, facilitating deployment in various environments, including cloud-based solutions. The Sparkling Water implementation provides a robust framework for running the algorithm, ensuring scalability and performance. While the specific code used in our study is not open-source, the tools and libraries we utilized are accessible, enabling others to replicate similar approaches.",
  "evaluation/method": "The evaluation of our method involved several key steps to ensure its robustness and effectiveness in detecting under-reporting of adverse events (AEs) in clinical trials. We utilized the test set not only for evaluation but also for simulating under-reporting scenarios. This approach allowed us to assess how well our model could discriminate between under-reporting anomalies and normal behavior.\n\nTo simulate under-reporting, we selected a sample from the test set and artificially lowered the AE count for these sites. This process involved creating under-reporting pairs where the AE count was reduced based on predefined scenarios. These scenarios included a statistical approach, a fixed ratio reduction, and simulating complete absence of reporting. The negative cases from the test set, where under-reporting was not simulated, were then merged with the positive cases from the simulated under-reporting set to form the classification test set.\n\nWe constructed a Receiver Operating Characteristic (ROC) curve using the significance levels derived from the model. The ROC curve helped us evaluate the model's performance across different thresholds. The Area Under the Curve (AUC) values for the ROC curve were 0.62, 0.79, and 0.92 when tested at 25%, 50%, and 75% AE under-reporting scenarios, respectively. These values indicate the model's ability to correctly identify under-reporting at various levels of severity.\n\nThe model is currently being used by Quality Program Leads at Roche/Genentech on a limited number of ongoing studies. It is scheduled for full deployment in production by the end of 2019/2020, where it will be applied to all ongoing clinical studies. This deployment is part of a broader effort to leverage advanced analytics to enhance traditional clinical quality assurance approaches.\n\nFuture enhancements to the model include assessing alternative machine learning algorithms and integrating additional clinical study datasets and other data sources, such as geographical locations of studies and sites. These improvements aim to further refine the model's accuracy and applicability across diverse clinical trial settings.",
  "evaluation/measure": "In our evaluation, we primarily focused on the area under the Receiver Operating Characteristic (ROC) curve (AUC-ROC) as our key performance metric. This metric is widely used in the literature for evaluating the performance of binary classification models, as it provides a comprehensive measure of the model's ability to discriminate between positive and negative classes across all possible classification thresholds.\n\nFor our model, we reported the AUC-ROC for various under-reporting scenarios. Specifically, we achieved an AUC-ROC of 0.67 for the general case. For more targeted scenarios, our model performed exceptionally well, with an AUC-ROC of 0.97 for the zero scenario (small investigator site). Additionally, for scenarios with 25%, 50%, 67%, and 75% under-reporting at the site level, our model scored AUC-ROC values of 0.62, 0.79, 0.89, and 0.92, respectively. These results indicate that our model is particularly effective in detecting under-reporting in scenarios with higher levels of under-reporting.\n\nTo further assess the model's performance, we used Youden's J statistics to determine the optimal trade-off between the true positive rate (TPR) and the false positive rate (FPR). This allowed us to define alert levels (AL3, AL2, AL1, AL0) that prioritize study sites for further investigation. The TPR and corresponding FPR for each alert level are listed in a table, providing a clear indication of the model's performance in identifying under-reporting sites.\n\nThe reported metrics are representative of the current literature on model evaluation for similar tasks. The AUC-ROC is a standard metric for evaluating classification models, and the use of Youden's J statistics for optimizing the trade-off between TPR and FPR is a well-established practice. These metrics collectively provide a robust evaluation of our model's performance in detecting adverse event under-reporting in clinical trials.",
  "evaluation/comparison": "In our evaluation, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, we focused on comparing different algorithms suitable for optimizing our specific loss function. The algorithms considered included generalized linear models and gradient boosting machines. Neural networks were dismissed due to the limited signal-to-noise ratio, which did not justify the computational investment.\n\nWe conducted a thorough comparison between generalized linear models and gradient boosting machines. Both algorithms were tried, and gradient boosting machines were found to provide the best performance. This decision was based on empirical results rather than a comparison with external benchmarks.\n\nSimpler baselines were not explicitly mentioned as part of our evaluation process. Our primary focus was on selecting the most effective algorithm from the ones we deemed suitable for our task. The choice of gradient boosting machines was driven by their superior performance in our specific context, which involved detecting under-reporting in clinical trial data.\n\nThe evaluation of our model's performance was primarily based on the area under the receiver operating characteristic (ROC) curve (AUC) for different under-reporting scenarios. The model achieved AUCs of 0.62, 0.79, and 0.92 for 25%, 50%, and 75% under-reporting scenarios, respectively. These results indicated that our model was effective in detecting under-reporting, especially in scenarios with higher levels of under-reporting.\n\nIn summary, while we did not compare our method against publicly available benchmarks or simpler baselines, our evaluation was rigorous and focused on selecting the best-performing algorithm for our specific task. The gradient boosting machines were chosen based on their empirical performance, and the model's effectiveness was demonstrated through ROC curve analysis.",
  "evaluation/confidence": "The evaluation of our model's performance was conducted using simulated under-reporting scenarios due to the lack of real-world examples. We assessed the model using the area under the ROC curve (AUC-ROC) metric. For different scenarios, the model achieved varying AUC-ROC scores: 0.67 for the general case, 0.97 for the zero scenario (small investigator sites), and 0.62, 0.79, 0.89, and 0.92 for the 25%, 50%, 67%, and 75% under-reporting scenarios, respectively.\n\nTo determine the significance of these results, we used Youden\u2019s J statistics to find the optimal trade-off between true positive rates and false positive rates. This allowed us to define alert levels (AL3, AL2, AL1, AL0) that categorize sites based on their risk of under-reporting. The performance metrics for these alert levels indicate the proportion of true under-reporting sites that would be detected at each level.\n\nHowever, it is important to note that the significance levels computed were not well-calibrated probabilities. This is because the model did not fully capture the uncertainty in the prediction of visits and, by extension, patients. As a result, while the model performs well in detecting under-reporting at the site level, there is some uncertainty about how well this performance translates to the patient level.\n\nAdditionally, the model was trained solely on data from Roche/Genentech-sponsored clinical trials. Further validation with data from other sponsors and real-world datasets is planned to assess the generalizability of our findings. This will help in determining the statistical significance and confidence intervals of our performance metrics more robustly.\n\nIn summary, while the model shows promising results in detecting under-reporting, the lack of real-world labeled data and the need for further validation with diverse datasets mean that the confidence in these results is somewhat limited. Future work will address these limitations to provide more statistically significant and confident evaluations.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data originated from Roche/Genentech-sponsored clinical trials, which included de-identified information from 104 completed studies. These studies covered various molecule types and disease areas, involving 3231 individual investigator sites and 18,682 study subjects who underwent 288,254 study visits. The data set included attributes such as demographics, medical history, concomitant medications, vitals, visits, and adverse events, following the Study Data Tabulation Model (SDTM) standard. Additionally, study attributes from the Roche Clinical Trial Management System (CTMS) were considered, including study type, route of administration, concomitant agents, disease area, blinding, randomization, and study phase.\n\nThe data was curated and used to develop a predictive model for detecting suspected adverse event (AE) under-reporting. The model's performance was evaluated using different scenarios of AE under-reporting, and it achieved AUCs of the ROC curve of 0.62, 0.79, and 0.92 for 25%, 50%, and 75% under-reporting, respectively. The model is currently being used by Quality Program Leads at Roche/Genentech on a limited number of ongoing studies and is planned for deployment in production in the course of 2019/2020.\n\nDue to the sensitive nature of clinical trial data and the need to protect patient privacy, the raw evaluation files are not released to the public. However, the methodology and findings of the study have been published, providing insights into the development and evaluation of the predictive model. Future enhancements to the model may include the integration of additional clinical study data sets and other data sources, such as site/study geographical location, to further improve its performance and applicability."
}