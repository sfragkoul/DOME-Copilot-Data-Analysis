{
  "publication/title": "Robust Class Decomposition for Alzheimer's Progression Detection",
  "publication/authors": "The authors who contributed to this article are Maha M Alwuthaynani, Zahraa S Abdallah, and Reem S Al-Rikabi.\n\nMaha M Alwuthaynani was involved in the conceptualization, methodology, designing and carrying out the experiments, and writing, reviewing, and editing the manuscript.\n\nZahraa S Abdallah and Reem S Al-Rikabi have equal contributions in supervision, guidance, and research support.\n\nAll authors reviewed and approved the final version of the submitted manuscript.",
  "publication/journal": "Experimental Biology and Medicine",
  "publication/year": "2023",
  "publication/pmid": "38059336",
  "publication/pmcid": "PMC10854473",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Alzheimer's Disease\n- Mild Cognitive Impairment\n- Neuroimaging\n- Structural MRI\n- Machine Learning\n- Transfer Learning\n- Class Decomposition\n- Predictive Modeling\n- Cognitive Decline\n- Alzheimer's Disease Neuroimaging Initiative\n- sMCI\n- pMCI\n- Gender Analysis\n- Model Performance\n- Deep Learning",
  "dataset/provenance": "The dataset used in this study was obtained from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database. The ADNI is a public-private partnership launched in 2003, led by Principal Investigator Michael W. Weiner, MD. The primary goal of ADNI is to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessments can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimer\u2019s disease (AD).\n\nThe study utilized structural MRI (sMRI) data from the ADNI1, ADNI2, and ADNI-GO phases. The ADNI1 phase began in October 2004 and included 200 elderly control subjects, 200 participants with early AD, and 400 participants with MCI. The ADNI-GO phase, which started in 2009, evaluated 200 additional participants with early mild cognitive impairment (EMCI) and modified MR protocols. The ADNI2 phase, initiated in 2011, included 150 elderly controls, 100 people with EMCI, 150 people with late mild cognitive impairment (LMCI), and 150 people with mild AD. Additionally, the significant memory concern (SMC) cohort was added to ADNI2 to bridge the gap between healthy controls (HCs) and MCI, with 107 SMC subjects included.\n\nThe study constructed two datasets from the ADNI data. The first dataset, used to build the base classifier, included 89 3D T1-weighted magnetic resonance images from 89 subjects (45 patients with AD and 44 HCs). The second dataset comprised 467 3D T1-weighted baseline sMRI scans for patients with probable MCI. Based on a 36-month follow-up period, MCI subjects were divided into 146 probable MCI (pMCI) and 321 stable MCI (sMCI). The sMRI data were downloaded in DICOM format and converted to NIfTI format using MRIcron software. The images were preprocessed using FSL tools and Python libraries, including steps such as skull stripping, smoothing, and co-registration to Montreal Neurological Institute (MNI) space.\n\nThe ADNI dataset has been widely used in the community for similar studies. Previous research has employed this dataset to address the classification of sMCI and pMCI classes, often using transfer learning and pretrained networks trained on diverse cohorts, including cognitively normal (CN) and AD subjects. The dataset's extensive use in the literature underscores its value in advancing the understanding and detection of Alzheimer\u2019s disease progression.",
  "dataset/splits": "The dataset used in this study was obtained from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database. The data was split into two main datasets. The first dataset was used to build the base classifier and was trained on subjects with Alzheimer\u2019s disease (AD) and healthy controls (HC). The second dataset was used to retrain the model to recognize between stable mild cognitive impairment (sMCI) and progressive mild cognitive impairment (pMCI).\n\nThe data from the ADNI1, ADNI2, and ADNI-GO phases were utilized to construct these datasets. The ADNI1 phase included 200 elderly control subjects, 200 participants with early AD, and 400 participants with MCI. The ADNI-GO phase added 200 additional participants with early mild cognitive impairment (EMCI). The ADNI2 phase included 150 elderly controls, 100 people with EMCI, 150 people with late mild cognitive impairment (LMCI), 150 people with mild AD, and 107 subjects with significant memory concern (SMC).\n\nFor the experiments, each cohort underwent 5 separate runs using 5 distinct datasets with slices of 5, 15, 20, 30, and 40 to examine the optimal number of slices. Additionally, gender-specific analyses were conducted using 30 2D slices per subject for each cohort, producing three distinct gender-specific results for male, female, and combined (male and female) datasets.\n\nIn summary, the dataset was split into two main datasets for training the base classifier and retraining for sMCI and pMCI recognition. The experiments involved multiple runs with varying numbers of slices and gender-specific analyses.",
  "dataset/redundancy": "In our study, we utilized structural MRI (sMRI) data from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database, specifically from the ADNI1, ADNI2, and ADNI-GO phases. These phases provided a comprehensive dataset for our research, including various cohorts of subjects with different cognitive states.\n\nThe datasets were split into two primary groups. The first dataset was used to build a base classifier, which was trained on subjects with Alzheimer's disease (AD) and healthy controls (HCs). This model was subsequently retrained using data from mild cognitive impairment (MCI) patients to distinguish between stable mild cognitive impairment (sMCI) and progressive mild cognitive impairment (pMCI).\n\nTo ensure the independence of the training and test sets, we employed a rigorous approach. The base classifier was initially trained on AD and HC subjects, and then this trained model was fine-tuned using MCI data. This method helped in transferring knowledge from the well-defined classes (AD and HC) to the more nuanced classes (sMCI and pMCI), thereby enhancing the model's predictive accuracy.\n\nThe distribution of our datasets compares favorably with previously published machine learning datasets in the field of neuroimaging. The ADNI database is one of the most extensive and well-curated datasets available, providing a robust foundation for our research. The inclusion of multiple cohorts (ADNI1, ADNI2, and ADNI-GO) ensured that our model was tested across diverse populations, enhancing its generalizability and reliability.\n\nWe also conducted a gender analysis across all cohorts, which indicated that gender had no considerable impact on the performance of the models. The combined gender group typically revealed accuracies between or close to those of the male and female groups, demonstrating that gender has no noticeable impact on performance. This consistency across different gender groups further validates the robustness of our dataset and model.\n\nIn summary, our datasets were carefully split and independently validated to ensure the integrity and reliability of our findings. The use of the ADNI database, with its extensive and diverse cohorts, provided a strong foundation for our research, aligning well with previously published machine learning datasets in the field.",
  "dataset/availability": "The data used in this study were obtained from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database, which is publicly accessible at adni.loni.usc.edu. The ADNI database is a public-private partnership that aims to combine various biological markers and clinical assessments to measure the progression of mild cognitive impairment (MCI) and early Alzheimer\u2019s disease (AD).\n\nThe ADNI database includes a wealth of information, such as serial magnetic resonance imaging (MRI), positron emission tomography (PET), genetic profiles, blood, and cerebrospinal fluid biomarkers. The specific data utilized in this study include structural MRI (sMRI) from the ADNI1, ADNI2, and ADNI-GO phases. These phases encompass different cohorts of subjects, including those with stable mild cognitive impairment (sMCI) and progressive mild cognitive impairment (pMCI).\n\nThe ADNI database is designed to be a comprehensive resource for researchers, and the data are made available under specific terms and conditions to ensure ethical use and data integrity. The ADNI data usage agreement outlines the requirements for accessing and using the data, including proper citation of the ADNI database in any publications resulting from the use of the data.\n\nThe data splits used in this study were constructed from the ADNI database, with specific criteria for inclusion and exclusion of subjects based on their diagnostic status and follow-up periods. The first dataset was used to build a base classifier trained on Alzheimer\u2019s disease (AD) and healthy control (HC) subjects. This model was then retrained on MCI patients to differentiate between sMCI and pMCI.\n\nThe ADNI database enforces data usage policies through its data usage agreement, which mandates that researchers adhere to ethical guidelines and properly cite the ADNI database in their publications. This ensures that the data are used responsibly and that the contributions of the ADNI initiative are acknowledged.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is convolutional neural networks (CNNs). Specifically, we employed pretrained networks such as AlexNet and VGG19. These networks are well-established in the field of deep learning and have been widely used for various image classification tasks.\n\nThe algorithms used are not new; they are established models that have been extensively studied and applied in the literature. AlexNet and VGG19 are both popular architectures in the CNN family, known for their effectiveness in feature extraction and classification tasks. AlexNet was one of the pioneering models in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), while VGG19 is known for its deep architecture with 19 layers, which helps in capturing complex patterns in images.\n\nThe reason these algorithms were not published in a machine-learning journal is that they are foundational models that have already been thoroughly documented and validated in the literature. Our work focuses on applying these established models to a specific medical imaging task\u2014Alzheimer's progression detection\u2014rather than developing new machine-learning algorithms. By leveraging transfer learning, we transfer the knowledge gained from these pretrained models to improve the classification of stable mild cognitive impairment (sMCI) versus progressive mild cognitive impairment (pMCI). This approach allows us to address the challenges of limited annotated data and computational resources, making it a practical solution for medical imaging applications.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model employs a class decomposition transfer learning (CDTL) approach, which involves training a base classifier on structural magnetic resonance imaging (sMRI) data from cognitively normal (CN) and Alzheimer's disease (AD) subjects. This base classifier is then fine-tuned to distinguish between stable mild cognitive impairment (sMCI) and progressive mild cognitive impairment (pMCI) subjects. The process includes using a pretrained network, such as AlexNet and VGG19, to extract features and classify the data. The model utilizes transfer learning to leverage knowledge from the AD versus CN classification task to improve the sMCI versus pMCI classification task. The training data for the base classifier and the fine-tuned model are derived from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database, specifically from the ADNI1, ADNI2, and ADNI-GO phases. The datasets are constructed to ensure that the training data is independent, with subjects randomly split into training and test sets. The model's performance is evaluated using metrics such as accuracy, precision, recall, and the F1-score, demonstrating its effectiveness in distinguishing between sMCI and pMCI subjects.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the most informative and relevant data was used for training and testing. Initially, 3D structural MRI (sMRI) scans were re-sliced into 2D axial slices. This approach was chosen to address the challenges associated with handling high-resolution 3D images, which include large data volumes, computational complexity, and storage requirements.\n\nTo select the most informative 2D slices, two methods were employed. The first method utilized image entropy, calculated using the gray-level co-occurrence matrix (GLCM). This statistical method examines the spatial relationship among pixels, capturing intricate patterns and structures in an image. Slices were sorted in descending order based on their entropy values, with the most informative slices having the highest entropy. This method ensured that the central slices, which contain more data and higher information entropy, were prioritized.\n\nThe second method involved selecting the middle slices of the 3D images. This technique was based on the assumption that the middle slices cover essential brain regions such as the hippocampus, cortex, and ventricles, which are crucial for classification tasks. For the base classifier, 20 slices with the highest entropy were chosen from each subject. For the second dataset, 30 middle slices were extracted from each 3D image, ensuring a consistent anatomical representation across subjects.\n\nEach subject's brain was aligned to the MNI template to ensure specific brain regions were consistently included in the 2D slices. This alignment facilitated the extraction of slices with the same regions across different subjects. The axial image slices were then saved in the Joint Photographic Experts Group (JPEG) format, ready for feature extraction and classification.\n\nIn summary, the data encoding and preprocessing involved re-slicing 3D sMRI scans into 2D axial slices, selecting the most informative slices based on image entropy and centrality, aligning brains to the MNI template, and saving the slices in JPEG format. These steps ensured that the data used for training and testing the machine-learning algorithm was informative, consistent, and manageable in terms of computational resources.",
  "optimization/parameters": "In our study, we utilized a combination of AlexNet and VGG19 for feature extraction and classification tasks. AlexNet was fine-tuned with the top 13 layers adopted for the two classes, and it was trained using 200 epochs, 50-batch sizes, and the Adam optimizer with a learning rate of 0.0001. This setup involved a significant number of parameters, primarily determined by the architecture of AlexNet.\n\nFor the classification step, we used VGG19, a pretrained network on ImageNet, with the top two layers adjusted for the four classes produced by the class decomposition step. The exact number of parameters in these models is substantial, typical of deep learning architectures, but the specific count isn't explicitly detailed here as it's standard for these networks.\n\nThe selection of these parameters was based on established practices in deep learning and the specific requirements of our task. The choice of 200 epochs and a batch size of 50 was determined through empirical testing and is common in training deep neural networks to ensure convergence without overfitting. The learning rate of 0.0001 was selected to balance between convergence speed and stability during training.\n\nAdditionally, we employed Principal Component Analysis (PCA) to reduce the dimensionality of the features extracted by AlexNet, which helps in managing the computational complexity and improving the model's performance. The number of principal components retained was chosen to capture the majority of the variance in the data, ensuring that essential information was preserved while reducing noise.\n\nIn summary, the parameters used in our model are those inherent to the AlexNet and VGG19 architectures, along with hyperparameters like the number of epochs, batch size, and learning rate, which were selected based on standard practices and empirical performance.",
  "optimization/features": "In our study, the input features for the model were derived from structural MRI scans. Specifically, we utilized 2D axial slices extracted from 3D sMRI images. To ensure that the most informative slices were selected, we employed an image entropy method. This involved calculating the image entropy for each slice using the Gray-Level Co-occurrence Matrix (GLCM) and then sorting the slices in descending order based on their entropy values. The slices with the highest entropy were deemed the most informative.\n\nFor the base classifier, we selected 20 slices with the highest entropy from each subject. Additionally, we considered the anatomical significance of the middle slices, which are known to cover critical brain regions such as the hippocampus, cortex, and ventricles. Therefore, for the second dataset, we extracted 30 middle slices from each 3D image. This approach not only reduced computational complexity but also provided valuable data for the deep learning models.\n\nFeature extraction was performed using a pretrained AlexNet model, which was fine-tuned to capture relevant features from the 2D images. The top 13 layers of AlexNet were adopted for the two classes, cognitively normal (CN) and Alzheimer's disease (AD). After feature extraction, Principal Component Analysis (PCA) was applied to reduce the dimensionality of the feature space, which helped in enhancing the efficiency of the framework.\n\nClass decomposition was then performed using a K-means cluster with k=2 to divide the features of each class into two subclasses. This step was crucial in reducing the impact of noisy data and discovering hidden patterns within each class, thereby improving classification accuracy.\n\nIn summary, the input features consisted of 20 or 30 2D slices per subject, depending on the dataset. Feature selection was performed using the image entropy method and anatomical considerations, ensuring that the most informative slices were used. PCA was employed to reduce dimensionality, and class decomposition was applied to enhance classification performance. All feature selection and preprocessing steps were conducted using the training set only, ensuring that the model's performance was not biased by the test data.",
  "optimization/fitting": "The fitting method employed in our study involved a combination of transfer learning and class decomposition techniques to predict Alzheimer's disease progression. The model was initially trained using AlexNet to extract features from 2D images, with the top 13 layers fine-tuned for the two classes of interest. This approach allowed us to leverage a large number of parameters relative to the training data, which is a common scenario in deep learning.\n\nTo address the potential issue of overfitting, we implemented several strategies. First, we used a pretrained AlexNet model, which had already been trained on a large dataset (ImageNet), providing a robust starting point. Second, we employed data augmentation techniques, such as extracting 30 2D scans from the center of the 3D image, to increase the effective size of our training dataset. Additionally, we used ten-fold cross-validation to ensure that the model generalized well to unseen data. The use of Principal Component Analysis (PCA) to reduce dimensionality also helped in mitigating overfitting by focusing on the most significant features.\n\nTo rule out underfitting, we carefully tuned the model's hyperparameters, including the learning rate, batch size, and number of epochs. The Adam optimizer was used with a learning rate of 0.0001, which allowed for efficient convergence. The model was trained for 200 epochs with a batch size of 50, ensuring that it had sufficient time to learn the underlying patterns in the data. Furthermore, the use of a pretrained model (VGG19) for classification after feature extraction provided a strong baseline performance, reducing the risk of underfitting.\n\nThe class decomposition step, where features of each class were divided into subclasses using K-means clustering, also helped in improving the model's ability to capture the nuances of the data. This step ensured that the model could handle the complexity of the dataset without underfitting to the majority class.\n\nOverall, the combination of transfer learning, class decomposition, and rigorous validation techniques ensured that our model was neither overfitted nor underfitted, providing reliable predictions for Alzheimer's disease progression.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was class decomposition, which involves dividing complex classes, particularly minority classes, into smaller subclasses. This technique helps in improving classifier performance by reducing the impact of noisy data and discovering hidden patterns within each class. By applying clustering as a preprocessing phase for each class, we were able to re-label each cluster's instances with a new class label, thereby enhancing classification accuracy.\n\nAdditionally, we utilized transfer learning, which involves transferring knowledge from one domain to another. This approach is crucial for addressing the issue of insufficient training data and helps in leveraging the knowledge gained from training a model to recognize healthy individuals from Alzheimer's disease patients. This knowledge is then fine-tuned to distinguish between stable mild cognitive impairment (sMCI) and progressive mild cognitive impairment (pMCI).\n\nWe also employed principal component analysis (PCA) to reduce the dimensionality of the feature space. This step assists in reducing memory requirements and enhancing the framework's efficiency, which indirectly helps in preventing overfitting by focusing on the most relevant features.\n\nFurthermore, we used ten-fold cross-validation to train and validate our model. This technique ensures that the model generalizes well to unseen data by training on different subsets of the data and validating on the remaining subset. This process helps in assessing the model's performance more reliably and in reducing the risk of overfitting.\n\nIn summary, our approach to preventing overfitting included class decomposition, transfer learning, dimensionality reduction using PCA, and ten-fold cross-validation. These methods collectively contribute to the robustness and generalizability of our model.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed AlexNet for feature extraction, fine-tuning the top 13 layers for two classes. The network was trained using 200 epochs, batch sizes of 50, and the Adam optimizer with a learning rate of 0.0001. After feature extraction, Principal Component Analysis (PCA) was used to reduce dimensionality. For class decomposition, K-means clustering with k=2 was applied to divide the features of each class into subclasses. VGG19, pretrained on ImageNet, was then used for classification, with the top two layers adjusted for the four classes resulting from the decomposition step. Ten-fold cross-validation was utilized for training and validation.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the methods and configurations described are sufficient for replication. The study does not mention the availability of model files or specific optimization parameters in a publicly accessible repository or under a particular license. Therefore, while the configurations and schedules are reported, the actual model files and detailed optimization parameters are not readily available.",
  "model/interpretability": "The model employed in this study leverages a combination of transfer learning and class decomposition techniques, which inherently introduces some level of interpretability. The use of pretrained networks like AlexNet and VGG19, which are well-understood architectures, provides a foundational transparency. These networks have been extensively studied, and their layers are designed to capture specific features at different levels of abstraction, from edges and textures to more complex patterns.\n\nThe class decomposition step, where features of each class are divided into subclasses using K-means clustering, adds another layer of interpretability. By breaking down complex classes into smaller, more manageable subclasses, the model can better capture the nuances within the data. This process makes it easier to understand how different features contribute to the classification of stable mild cognitive impairment (sMCI) versus progressive mild cognitive impairment (pMCI).\n\nFurthermore, the use of Principal Component Analysis (PCA) for dimensionality reduction helps in visualizing the data in a lower-dimensional space, which can be more interpretable. PCA transforms the original features into a set of orthogonal components that capture the most variance in the data, allowing for a clearer understanding of the underlying structure.\n\nThe model's performance is evaluated using metrics such as accuracy, precision, recall, and the F1-score, which provide quantitative measures of its effectiveness. Additionally, confusion matrices and silhouette scores are used to assess the clustering phase and the model's ability to distinguish between different classes. These evaluations offer insights into the model's strengths and weaknesses, contributing to its interpretability.\n\nIn summary, while the model is not entirely transparent, the use of well-known architectures, class decomposition, and dimensionality reduction techniques enhances its interpretability. These methods allow for a better understanding of how the model makes predictions and how different features contribute to the classification process.",
  "model/output": "The model developed in our study is a classification model. It is designed to predict whether individuals with mild cognitive impairment (MCI) will convert to Alzheimer's disease (AD) within a specified time frame, typically 36 months. The model uses structural magnetic resonance imaging (sMRI) scans and employs a combination of transfer learning and class decomposition techniques.\n\nThe classification tasks involve distinguishing between stable MCI (sMCI) and progressive MCI (pMCI) subjects. The model was initially trained to differentiate between cognitively normal (CN) individuals and those with Alzheimer's disease (AD). This pretrained model was then fine-tuned to classify sMCI and pMCI subjects. The performance of the model was evaluated using various metrics, including accuracy, precision, recall, and the F1-score.\n\nThe model achieved high accuracy in predicting MCI-to-AD conversion, demonstrating its robustness across different datasets and gender groups. For instance, the model's accuracy ranged from 89.27% to 91.45% across different cohorts, with F1-scores indicating consistent performance. The use of 30 slices per subject was found to provide a good balance between comprehensive anatomical coverage and computational efficiency.\n\nIn summary, the model is a classification model that effectively predicts the conversion of MCI to AD, utilizing advanced techniques to enhance its predictive power and reliability.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method involved a comprehensive assessment across multiple cohorts and various experimental setups. The study utilized data from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI), specifically from the ADNI1, ADNI2, and ADNI-GO phases. These datasets included structural MRI (sMRI) scans from subjects with stable mild cognitive impairment (sMCI) and progressive mild cognitive impairment (pMCI).\n\nThe evaluation process included examining the model's performance with different numbers of slices, ranging from 5 to 40, to determine the optimal configuration. This was done using five distinct datasets for each slice count, ensuring a robust assessment. The performance metrics, including accuracy and F1 scores, were recorded for each slice configuration across the different cohorts.\n\nAdditionally, the study conducted gender-specific analyses to understand the impact of gender on model performance. This involved running experiments three times for each cohort, producing distinct results for male, female, and combined datasets. The outcomes highlighted differences in F1 scores between gender groups, although the overall impact of gender on performance was found to be minimal.\n\nThe robustness of the model was further evaluated using confusion matrices from prediction results across different datasets. This assessment showed that the proposed approach predicted the sMCI class significantly better than the pMCI class. The study also compared the model's performance with previous approaches, demonstrating its superiority in distinguishing pMCI from sMCI within 36 months.\n\nOverall, the evaluation method was rigorous and multifaceted, ensuring that the model's performance was thoroughly assessed across various dimensions.",
  "evaluation/measure": "In the evaluation of our model, we reported several key performance metrics to comprehensively assess its effectiveness. The primary metrics included accuracy, sensitivity, specificity, F1 score, and the area under the curve (AUC). Accuracy measures the overall correctness of the model's predictions, sensitivity (or recall) indicates the model's ability to identify positive cases, and specificity reflects its capability to correctly identify negative cases. The F1 score provides a balance between precision and recall, offering a single metric that summarizes the model's performance, especially useful when dealing with imbalanced datasets. The AUC evaluates the model's ability to distinguish between classes across all threshold levels.\n\nThese metrics are widely recognized and used in the literature for evaluating machine learning models, particularly in medical imaging and diagnostic tasks. They provide a robust set of measures that cover different aspects of model performance, ensuring a thorough evaluation. Accuracy gives a general sense of the model's performance, while sensitivity and specificity offer insights into how well the model handles positive and negative cases, respectively. The F1 score is crucial for understanding the model's performance in the context of imbalanced data, which is common in medical datasets. The AUC complements these metrics by providing a threshold-independent measure of the model's discriminative power.\n\nIn addition to these standard metrics, we also considered the standard deviation (SD) of the performance measures to assess the consistency and reliability of the model's predictions across different datasets and slices. This approach ensures that our evaluation is not only focused on average performance but also takes into account the variability and robustness of the model.\n\nOverall, the reported metrics are representative of the state-of-the-art in model evaluation, providing a comprehensive view of the model's strengths and areas for potential improvement. This set of metrics allows for a detailed comparison with other models in the literature, ensuring that our findings are both relevant and meaningful in the context of existing research.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our proposed model with several publicly available methods using benchmark datasets. This comparison was essential to demonstrate the robustness and effectiveness of our approach in detecting Alzheimer's progression, particularly in distinguishing between stable mild cognitive impairment (sMCI) and progressive mild cognitive impairment (pMCI).\n\nWe evaluated our model against various studies that have been used in the literature for similar or related tasks. Despite differences in datasets, data preparation strategies, dimensional reduction methods, and measurements, we found that the results of these methods are comparable. Our model outperformed other approaches in distinguishing pMCI from sMCI within 36 months, achieving an accuracy of 91.45%. This superior performance can be attributed to several strengths of our approach, including the use of transfer learning and class decomposition in the base classifier. These techniques address the issue of limited availability of annotated data and improve model performance by simplifying the learning of class boundaries.\n\nIn addition to comparing with more complex models, we also considered simpler baselines. For instance, we experimented with AlexNet to extract features from 2D images, fine-tuning the network to adapt it for our classification tasks. We used principal component analysis (PCA) to reduce dimensionality and K-means clustering to divide the features of each class into subclasses. This process helped in creating a more refined and effective classification model.\n\nFurthermore, we utilized VGG19, a pretrained network on ImageNet, to classify Alzheimer's disease (AD) versus cognitively normal (CN). The top layers of VGG19 were adjusted for the four classes produced by the class decomposition step. We employed ten-fold cross-validation to train and validate the model, ensuring its robustness and generalizability.\n\nOur comparison with simpler baselines and publicly available methods underscores the effectiveness of our approach. The use of transfer learning and class decomposition not only enhances the model's performance but also makes it more efficient and reliable in predicting sMCI versus pMCI. This comprehensive evaluation provides a clear indication of our model's superiority in detecting Alzheimer's progression.",
  "evaluation/confidence": "The evaluation of our model's performance includes confidence intervals for key metrics, providing a measure of the reliability of our results. Specifically, we report the area under the curve (AUC) with 95% confidence intervals across different cohorts and gender groups. For instance, in the ADNI1 cohort, the AUC for males is 0.97 with a confidence interval of (0.97, 0.98), indicating a high level of confidence in this estimate. Similarly, in the ADNI2 cohort, the AUC for females is 0.98 with a confidence interval of (0.97, 0.98), demonstrating consistent and reliable performance.\n\nThe statistical significance of our results is evident in the narrow confidence intervals, which suggest that the differences observed are unlikely to be due to random chance. For example, the combined gender category in the ADNI2 cohort has an AUC of 0.98 with a confidence interval of (0.97, 0.98), highlighting the robustness of our model's predictions. These intervals provide a clear indication that our model's performance is statistically significant and superior to other approaches, particularly in distinguishing between stable mild cognitive impairment (sMCI) and progressive mild cognitive impairment (pMCI) within 36 months.\n\nAdditionally, the model's performance metrics, such as accuracy, sensitivity, and specificity, are consistently high across various datasets and cohorts. The accuracy of our model in distinguishing pMCI from sMCI is 91.45%, which is notably higher than many previous studies. This superior performance is achieved through the use of transfer learning and class decomposition, which address the challenges of limited annotated data and class imbalances. The transfer learning approach leverages knowledge from predicting cognitively normal (CN) versus Alzheimer's disease (AD) to improve the model's ability to distinguish between sMCI and pMCI, further enhancing its reliability and statistical significance.",
  "evaluation/availability": "Not enough information is available."
}