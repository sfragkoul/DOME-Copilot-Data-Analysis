{
  "publication/title": "Mitochondria Autosegmentation by 3D Network",
  "publication/authors": "The authors who contributed to this article are:\n\n- **Chen Xiao**: Conceived and designed the network, developed the algorithm, and wrote the paper.\n- **Xiaochuan Chen**: Developed the image registration method.\n- **Wenjie Li**: Implemented the 3D connected algorithm and wrote the paper.\n- **Hao Huang**: Conceived of the method, gave the research direction, and provided feedback on experiments and results.\n- **Qing Xiao**: Conceived of the method, gave the research direction, and provided feedback on experiments and results.\n- **Lingyun Li**: Was instrumental in analyzing the biological statistics.\n- **Ling Wang**: Was instrumental in analyzing the biological statistics.",
  "publication/journal": "Frontiers in Neuroanatomy",
  "publication/year": "2018",
  "publication/pmid": "30450040",
  "publication/pmcid": "PMC6224513",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Mitochondria\n- Segmentation\n- 3D Convolutional Networks\n- Deep Learning\n- Electron Microscopy\n- Image Processing\n- Neural Networks\n- Biomedical Imaging\n- Data Augmentation\n- Biological Statistics",
  "dataset/provenance": "The datasets used in this study consist of both anisotropic and isotropic electron microscopy (EM) volumes, which are commonly employed for evaluating mitochondria segmentation. The primary datasets include the FIB-SEM dataset from a rat hippocampus and the ATUM-SEM dataset from a mouse cortex.\n\nThe FIB-SEM dataset was acquired by Graham Knott and Marco Cantoni at \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL). This dataset includes mitochondria annotations in two volumes: a training volume and a testing volume. The training dataset comprises a stack of 165 slices, measuring approximately 3.84 \u00d7 5.12 \u00d7 0.83 \u00b5m\u00b3 with a resolution of 5 \u00d7 5 \u00d7 5 nm\u00b3 per voxel. The testing dataset, also consisting of 165 slices, was obtained from a different part of the same specimen.\n\nThe ATUM-SEM dataset was acquired by the Institute of Neuroscience, Chinese Academy of Sciences (CAS). It includes 31 sections with thicknesses of approximately 50 nm, imaged through a Zeiss Supra55 microscope. The pixel size was set at 2 nm, and the dwell time was set at 2 \u00b5s. The ground truths were annotated by neuroanatomists using ImageJ with the TrakEm2 plug-in. This dataset corresponds to a volume of 17.2 \u00d7 16.8 \u00d7 1.6 \u00b5m\u00b3.\n\nBoth datasets have been used in previous studies and by the community for evaluating mitochondria segmentation methods. The FIB-SEM dataset is publicly available at http://cvlab.epfl.ch/data/em, and the ATUM-SEM dataset can be accessed at http://95.163.198.142/MiRA/mitochondria31. These datasets provide a valuable resource for facilitating neuroscience research and advancing the development of automated segmentation techniques.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets utilized in this study are publicly available to facilitate further research in neuroscience. The ATUM-SEM dataset can be accessed at http://95.163.198.142/MiRA/mitochondria31. This dataset includes original images and human-labeled ground truth corresponding to a volume of 17.2 \u00d7 16.8 \u00d7 1.6 \u00b5m\u00b3. Additionally, the FIB-SEM dataset is available at http://cvlab.epfl.ch/data/em. This dataset was acquired from a rat hippocampus and includes annotated training and testing volumes.\n\nThe datasets are released under terms that allow for their use in scientific research, ensuring that other researchers can replicate and build upon our findings. The availability of these datasets is enforced through the public access links provided, which host the data in a format that is easily downloadable and usable. This approach promotes transparency and reproducibility in scientific research, aligning with the principles of open science.",
  "optimization/algorithm": "The optimization algorithm used in our work is the adaptive moment estimation (Adam) algorithm. This is a well-established optimization technique commonly used in training deep learning models. It is not a new algorithm; it was introduced by Kingma and Ba in 2014 and has since become a standard choice in the deep learning community due to its efficiency and effectiveness in handling sparse gradients on noisy problems.\n\nAdam combines the advantages of two other extensions of stochastic gradient descent. Specifically, it computes adaptive learning rates for each parameter, which helps in faster convergence. The algorithm also maintains a moving average of the gradient and its square, which helps in stabilizing the training process.\n\nThe reason this algorithm is used in a neuroscience publication rather than a machine-learning journal is that our primary focus is on the application of deep learning techniques to the specific problem of mitochondria segmentation in electron microscopy (EM) data. The optimization algorithm is a crucial component of our method, but the novelty lies in how we apply and adapt it to this particular domain. Our work contributes to the field of neuroscience by providing a state-of-the-art method for mitochondria segmentation, which has significant implications for understanding neural structures and functions.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps to ensure the quality and suitability of the input data for the 3D convolutional network.\n\nThe datasets used included both anisotropic and isotropic electron microscopy (EM) volumes, which are commonly used for evaluating mitochondria segmentation. The datasets consisted of the ATUM-SEM dataset from a mouse cortex and the FIB-SEM dataset from a rat hippocampus. The ATUM-SEM dataset consisted of 31 sections with thicknesses of approximately 50 nm, imaged through a Zeiss Supra55 microscope. The FIB-SEM dataset included a stack of 165 slices, with a resolution of 5 \u00d7 5 \u00d7 5 nm\u00b3 per voxel.\n\nPreprocessing involved image registration and histogram equalization. For the ATUM-SEM data, which were unregistered, an image registration method was employed. This method involved searching for correspondences between adjacent sections using the SIFT-flow algorithm, calculating displacements for the identified correspondences, and warping the image tiles based on the new positions of these correspondences. The registration process aimed to align the serial sections accurately, which is crucial for 3D reconstruction and segmentation.\n\nHistogram equalization was applied to enhance the contrast of the images, making it easier for the network to distinguish between mitochondria and non-mitochondria regions. This step is essential for improving the performance of the segmentation algorithm, as it ensures that the input data have a consistent and enhanced dynamic range.\n\nAdditionally, the original stack images were divided into smaller images to avoid exceeding the memory of the GPU during training. For the ATUM-SEM dataset, the original images (size of 8,624 \u00d7 8,416 \u00d7 20) were divided into smaller images (size of 256 \u00d7 256 \u00d7 8). Similarly, the FIB-SEM stack images (size of 768 \u00d7 1,024 \u00d7 165) were divided into smaller images (size of 256 \u00d7 256 \u00d7 20). Data augmentation techniques, such as rotation and flipping, were used to enlarge the training dataset, resulting in over 6,000 images for training. These augmented images helped improve the robustness and generalization of the network.\n\nDuring inference, overlapping patches were used to ensure accurate segmentation near the edges of the patches. For the ATUM-SEM dataset, the patch size was 1,152 \u00d7 1,152 \u00d7 8, with a 256-pixel overlap in the xy-plane and a 5-pixel overlap in the z-plane. For the FIB-SEM dataset, the patch size was 448 \u00d7 576 \u00d7 20, with a 128-pixel overlap in the xy-plane and a 10-pixel overlap in the z-plane. This approach helped mitigate the influence of zero padding on segmentation accuracy near the edges.\n\nTest-time augmentation was also employed to further improve segmentation accuracy. The testing images were rotated by 90 degrees and flipped over the xy-plane and z-dimension before being passed into the network. The reverse transformation was applied to each probability map, and the average of all variations was taken as the final result. This technique enhanced the robustness of the segmentation results by leveraging multiple views of the input data.",
  "optimization/parameters": "In our proposed 3D fully convolutional network, the total number of parameters, denoted as p, is determined by the architecture of the network, which includes both the main classifier and the auxiliary classifiers. The network consists of a contracting path with 13 convolutional layers and an expansive path with 15 convolutional layers. Each convolutional layer contributes to the total number of parameters based on its kernel size, the number of input and output channels, and the use of batch normalization and activation functions.\n\nThe specific number of parameters can vary depending on the exact configuration of the network, such as the number of channels in each layer and the use of auxiliary classifiers. However, it is mentioned that the proposed network has significantly fewer trainable parameters compared to other 2D or 3D convolutional networks. For instance, the network with auxiliary outputs has approximately 1.1 million trainable parameters, which is much smaller than the 7.3 million parameters in a comparable 3D U-Net architecture.\n\nThe selection of the number of parameters was guided by the need to balance model complexity and computational efficiency. The use of residual blocks and summation-based skip connections helped in maintaining the effectiveness of the network while keeping the parameter count manageable. Additionally, the deeply supervised strategy with auxiliary classifiers ensured that the network could be trained effectively despite having fewer parameters.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The proposed 3D fully convolutional network was designed with a focus on efficiency and effectiveness, ensuring that the number of trainable parameters is significantly smaller than in other 2D or 3D convolutional networks. This design choice helps in mitigating the risk of overfitting, as a smaller number of parameters reduces the model's capacity to memorize the training data.\n\nTo further address overfitting, several strategies were employed. Data augmentation techniques, such as rotations and flips, were used to artificially enlarge the training dataset, providing the model with a more diverse set of examples to learn from. Additionally, test-time augmentation was applied, where the testing images were rotated and flipped before being passed through the network, and the results were averaged to improve the robustness of the segmentation.\n\nThe use of auxiliary classifiers also played a crucial role in enhancing the model's performance and preventing overfitting. These classifiers provided additional supervision during training, helping the network to learn more discriminative features.\n\nTo rule out underfitting, the network was trained for a sufficient number of epochs (30 epochs) with an appropriate learning rate and optimization algorithm (Adam). The training process was monitored to ensure that the model converged properly and achieved high accuracy on both the training and validation datasets.\n\nThe evaluation of the model's performance on different datasets, including the ATUM-SEM and FIB-SEM datasets, demonstrated its effectiveness in segmenting mitochondria accurately. The quantitative results, such as the F1 score and the number of true positives, false positives, and false negatives, further validated the model's ability to generalize well to unseen data, indicating that neither overfitting nor underfitting was a significant issue.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and improve the generalization of our 3D fully convolutional network for mitochondria autosegmentation.\n\nFirstly, we utilized a deeply supervised strategy by injecting auxiliary classifiers into the hidden layers of the network. These auxiliary classifiers helped propagate the back-propagation of the gradient back to the early layers, effectively alleviating the vanishing gradient problem and enhancing the learning of features at different levels.\n\nAdditionally, we incorporated a regularization term in our loss function. This term included weights for the auxiliary classifiers and a balancing parameter, which helped in controlling the contribution of each auxiliary classifier to the total loss. The regularization term also included L2 regularization, which penalized large weights and helped in preventing overfitting.\n\nData augmentation was another crucial technique we used to prevent overfitting. We divided the original large images into smaller patches and applied various transformations, such as rotations and flips, to create a larger and more diverse training dataset. This approach helped the network to learn more robust features and generalize better to unseen data.\n\nFurthermore, we used a small batch size and a low learning rate during the training process, which helped in stabilizing the training and preventing the network from overfitting to the training data. We also employed early stopping based on the validation loss to terminate the training process when the performance on the validation set started to degrade.\n\nOverall, these techniques helped us to build a robust and generalizable 3D fully convolutional network for mitochondria autosegmentation.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the network was optimized using the Adam optimizer with a learning rate of 0.0001, exponential decay rates for moment estimates \u03b21 of 0.9 and \u03b22 of 0.999, and an epsilon value of 10\u22128. The training process involved 30 epochs with a batch size of 2, and it took approximately 77 hours to complete on a K40 GPU.\n\nThe model architecture, including the 3D fully convolutional network with residual blocks and auxiliary classifiers, is thoroughly described. The implementation was done using the Keras deep learning library with a TensorFlow backend. The loss function employed was binary cross-entropy.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly mentioned in the provided context. Therefore, it is not clear whether the model files and optimization parameters are publicly available or under what license they might be distributed.",
  "model/interpretability": "The proposed network for mitochondria autosegmentation is not a blackbox model. It is designed to be interpretable through several key architectural choices. The network is a variant of the U-Net architecture, which consists of a contracting path and an expansive path. This structure allows for a clear understanding of how features are extracted and combined at different scales.\n\nThe contracting path contains 13 convolutional layers, while the expansive path contains 15 convolutional layers. Each path is divided into different stages that operate in different receptive fields, making it easier to trace how information flows through the network. The use of 3D residual modules in each stage further enhances interpretability. These modules consist of two 3D convolutional layers with a kernel size of 3 \u00d7 3 \u00d7 3, followed by batch normalization and exponential linear unit nonlinearity. The residual shortcut connections help in preserving the identity of the input features, making it easier to understand the contributions of each layer.\n\nAdditionally, the network employs summation-based skip connections, which fuse multilevel contextual information more thoroughly than concatenation-based connections. This design choice helps in incorporating global information from higher layers and local cues from lower layers, providing a clearer picture of how different levels of abstraction are integrated.\n\nThe deeply supervised strategy used in the network also contributes to its interpretability. By injecting auxiliary classifier layers into the hidden layers, the network can be trained to propagate gradients back to the early layers, alleviating the vanishing gradient problem. During training, the loss from these auxiliary classifiers is added to the total loss with a discount weight, ensuring that the network learns meaningful features at each stage.\n\nOverall, the architectural choices in the proposed network, such as the use of 3D residual modules, summation-based skip connections, and deeply supervised strategy, make it more interpretable compared to other blackbox models. These design elements provide clear examples of how features are extracted, combined, and refined at different stages of the network.",
  "model/output": "The model is designed for classification, specifically for the segmentation of mitochondria in 3D electron microscopy images. It utilizes a deeply supervised strategy with auxiliary classifiers to enhance training and mitigate the vanishing gradient problem. The network architecture is a variant of the U-Net, featuring a contracting path and an expansive path, both incorporating 3D residual modules to extract features effectively. During training, the loss from auxiliary classifiers is added to the total loss with specific weights, but these auxiliary networks are discarded during the testing phase. The output of the model is a segmentation map that classifies each voxel as either mitochondria or non-mitochondria, providing a detailed and accurate segmentation of the mitochondria in the input data. The model's performance is evaluated using metrics such as Jaccard, Dice, and Conformity percentages, demonstrating its effectiveness in achieving state-of-the-art results in mitochondria segmentation.",
  "model/duration": "The execution time of our proposed method varies depending on the dataset used. For the ATUM-SEM testing dataset, with a volume of 17.2 \u00d7 16.8 \u00d7 0.6 \u00b5m\u00b3, our method took 2,199 seconds to complete. This is faster than the Fusion-FCN method, which took 3,542 seconds, but slower than U-Net and 3D U-Net, which took 408 and 1,776 seconds, respectively. For the FIB-SEM testing dataset, with a volume of 3.8 \u00d7 5.1 \u00d7 0.8 \u00b5m\u00b3, our method took 356 seconds. In comparison, U-Net and 3D U-Net took 66 and 265 seconds, respectively. The longer execution time of our method can be attributed to its complex network structure. However, despite the longer execution time, our method offers improved detection and segmentation accuracy, which can significantly reduce human proofreading time. Future work will focus on optimizing the network structure to reduce computational complexity and improve the speed of the pipeline.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our method focused on both pixel-wise segmentation and 3D detection accuracy. For segmentation evaluation, we used standard metrics such as Jaccard, Dice, and Conformity percentages. These metrics provided a quantitative measure of the segmentation performance by comparing the predicted results with the ground truth.\n\nTo assess the detection accuracy in 3D, we first employed a connection method to perform mitochondria detection. This method involved calculating the intersection over union (IoU) of segmentations in adjacent slices to determine connectivity. Small connected components with an IoU smaller than a threshold of 0.1 were discarded to avoid biasing the counting estimations. The main procedure involved dividing the segmentations into disjoint sets, where each set represented a single mitochondrion. These results were then visualized using ImageJ to display 3D reconstructions.\n\nThe detection performance was evaluated by calculating the number of true positives (TPs), false positives (FPs), and false negatives (FNs). The F1 score, which is the harmonic mean of precision and recall, was used to measure the overall detection accuracy. An overlapping threshold of 70% was set for TPs to ensure robust detection performance.\n\nIn the ATUM-SEM dataset, which contained 273 mitochondria in 3D, our approach detected 255 TPs, 25 FPs, and missed 18 mitochondria (FNs). The F1 score for our detection method was 92.2% in anisotropy and 90.9% in isotropy, outperforming all baseline methods. This evaluation demonstrated the superiority of our method in both segmentation and detection tasks, achieving state-of-the-art results.",
  "evaluation/measure": "In our evaluation, we report several key performance metrics to comprehensively assess the effectiveness of our mitochondria segmentation and detection approach. These metrics include the Jaccard index, Dice coefficient, and conformity coefficient, which are widely used in the literature for evaluating segmentation accuracy. The Jaccard index measures the pixel-wise overlap between the ground truth and the segmentation results, providing a straightforward indication of segmentation accuracy. The Dice coefficient, similar to the Jaccard index, offers another measure of overlap but is often more sensitive to small changes in segmentation. The conformity coefficient is a more rigorous metric that provides better discrimination capabilities, making it particularly useful for detailed evaluations.\n\nFor detection performance, we focus on precision, recall, and the F1 score. Precision indicates the probability that detected mitochondria are true positives, while recall measures the probability that true mitochondria are successfully detected. The F1 score, which is the weighted average of precision and recall, offers a balanced view of the method's performance, especially when precision and recall are contradictory. We set a voxel-wise overlap threshold of 70% for true positives, ensuring that only predictions with substantial overlap with the ground truth are considered correct. This threshold is motivated by previous studies and provides a robust measure of detection accuracy.\n\nAdditionally, we evaluate the number of true positives (TPs), false positives (FPs), and false negatives (FNs) to provide a detailed breakdown of detection performance. This approach allows us to assess not only the overall accuracy but also the specific types of errors made by the method. By comparing our results with recent mitochondria segmentation methods on both ATUM-SEM and FIB-SEM datasets, we demonstrate that our approach achieves state-of-the-art performance across all reported metrics. This comprehensive set of metrics ensures that our evaluation is representative and aligned with the standards in the literature.",
  "evaluation/comparison": "In the evaluation of our method, a comprehensive comparison was conducted against several publicly available and state-of-the-art methods on benchmark datasets. Specifically, for the ATUM-SEM dataset, our approach was compared with methods from He et al. (2016), Ronneberger et al. (2015), \u00c7i\u00e7ek et al. (2016), Li et al. (2017a), and Xiao et al. (2018). The results demonstrated that our method, utilizing a 3D convolutional architecture, residual blocks, and deeply supervised strategy, achieved superior performance with a Jaccard index of 0.918, Dice coefficient of 0.957, and Conformity of 0.910.\n\nFor the FIB-SEM dataset, comparisons were made with methods from Lucchi et al. (2013), Rigamonti et al. (2014), \u00c7i\u00e7ek et al. (2016), and Oztel et al. (2017). Our method ranked just behind Oztel et al. (2017), which also employed a fully convolutional network but with additional post-processing steps. Notably, our method achieved these results without the need for post-processing, highlighting its efficiency and effectiveness.\n\nIn addition to these comparisons, simpler baselines were also evaluated. For instance, our method was compared against U-Net and 3D U-Net, demonstrating better qualitative results and detection accuracy. The use of a 3D fully residual convolution network in our approach was particularly beneficial for extracting 3D information and handling mitochondria segmentation in serial EM data. Furthermore, the deeply supervised and test-time augmentation strategies contributed to improving the accuracy of segmentation and detection.\n\nOverall, the comparisons showed that our method outperforms both simpler baselines and more complex state-of-the-art techniques, achieving state-of-the-art detection performance with an F1 score of 92.2% in anisotropy and 90.9% in isotropy. This was evident in the ATUM-SEM dataset, where our approach detected 255 true positives, 25 false positives, and missed 18 mitochondria out of 273. The qualitative comparisons in Figures 4 and 5 further illustrate the superiority of our method in reducing false positives and false negatives, thereby achieving better segmentation and detection results.",
  "evaluation/confidence": "The evaluation of our method includes several performance metrics such as the Jaccard index, Dice coefficient, conformity coefficient, precision, recall, and F1 score. However, specific confidence intervals for these metrics are not explicitly provided in the results. The performance is primarily demonstrated through comparisons with other methods, showing that our approach achieves state-of-the-art results on standard quality metrics.\n\nStatistical significance is implied through the consistent outperforming of our method across multiple datasets and metrics. For instance, on the ATUM-SEM dataset, our approach yields a Jaccard index of 91.8%, Dice coefficient of 95.7%, and conformity coefficient of 91.0%, which are higher than those of other methods. Similarly, on the FIB-SEM dataset, our method achieves a Jaccard index of 90.0%, indicating superior performance.\n\nThe detection accuracy is also evaluated, with an F1 score of 92.2% in anisotropy and 90.9% in isotropy, outperforming all baselines. This suggests that our method not only excels in pixel-wise segmentation but also in 3D mitochondria detection.\n\nWhile explicit p-values or confidence intervals are not provided, the qualitative and quantitative results strongly suggest that our method is statistically significant and superior to other approaches. The use of deeply supervised strategies and test-time augmentation further supports the robustness and accuracy of our results.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The evaluation was conducted using specific datasets, including the ATUM-SEM dataset and the FIB-SEM dataset. The ATUM-SEM dataset consists of images from a mouse cortex, while the FIB-SEM dataset is from a rat hippocampus. These datasets were used to train and test the proposed 3D convolutional network for mitochondria segmentation. The evaluation metrics used include the Jaccard index, Dice coefficient, conformity coefficient, precision, recall, and F1 score. These metrics were applied to assess the performance of the segmentation method on both datasets. The results demonstrate the effectiveness of the proposed method in accurately segmenting mitochondria in electron microscopy images."
}