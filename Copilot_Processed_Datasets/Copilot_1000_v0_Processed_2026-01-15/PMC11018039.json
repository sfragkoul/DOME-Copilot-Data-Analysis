{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are Serenay Cakar and F. G. Yavuz. Unfortunately, the specific contributions of each author to the paper are not detailed.",
  "publication/journal": "Journal of Applied Statistics",
  "publication/year": "2022",
  "publication/pmid": "38628450",
  "publication/pmcid": "PMC11018039",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Cognitive Science\n- Data Analysis\n- Machine Learning\n- Statistical Methods\n- Neuroimaging\n- Functional Near-Infrared Spectroscopy (fNIRS)\n- Electroencephalogram (EEG)\n- Mixed-Effects Models\n- Longitudinal Data\n- Hybrid ML Methods",
  "dataset/provenance": "The dataset utilized in this study originates from a cognitive science research study focused on the n-back task. The raw data was obtained from an open-access source, available in both vendor-agnostic and vendor-specific formats. This data was specifically prepared for analysis using detailed data processing methods described in the study.\n\nThe experiment involved twenty-six healthy participants, consisting of nine males and seventeen females, with ages ranging from 17 to 33 years. During the n-back experiment, participants were presented with a series of numbers as visual stimuli and were required to remember previously seen numbers based on the task conditions (0-back, 2-back, and 3-back). The data collected includes measurements of oxyhemoglobin (HbO) concentrations, which are indicative of cortical activity, using functional near-infrared spectroscopy (fNIRS) technology. The data points were collected at a sampling rate of 10.4 Hz from various locations on the participants' heads, as specified by the placement of detectors and sources.\n\nThe dataset has been used in previous research and is available for community access, ensuring reproducibility and further analysis by other researchers in the field. The open-access nature of the data allows for broader validation and application of the findings, contributing to the advancement of cognitive neuroscience research.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study is openly accessible in both vendor-agnostic and vendor-specific formats. This data pertains to the n-back task and was obtained from a cognitive science research study. The raw dataset was meticulously prepared for analysis using specific data processing methods detailed in the relevant sections of the publication. The data includes measurements from twenty-six healthy participants, encompassing variables such as HbO values, accuracy, mean response time, age, gender, session details, and n-back conditions. The data collection involved the use of NIRScout technology to gather optical density data at a sampling rate of 10.4Hz. The exact locations of the detectors and sources are specified, ensuring reproducibility. The timing and structure of the sessions, including instruction periods, task periods, and rest periods, are clearly outlined. This comprehensive approach ensures that the data is available for further research and validation, adhering to open science principles. The data is released under a license that permits its use for research purposes, fostering transparency and reproducibility in cognitive science studies.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are hybrid methods that combine aspects of linear mixed models (LMM) and machine learning (ML) techniques. These algorithms are designed to handle the nested structures and repeated measurements commonly found in cognitive data. The specific algorithms employed include Generalized Linear Mixed-Effects Model Tree (GLMM tree), Random Effects Expectation-Maximization Tree (RE-EM tree), Longitudinal Classification and Regression Tree (LongCART), and Gaussian Process Boosting (GPBoost).\n\nThese algorithms are not entirely new but represent a novel application in the context of cognitive data analysis. They have been chosen because they can effectively manage the dependencies among repeated measures, which is crucial for accurate modeling in neuroscience data. The use of these hybrid methods is particularly significant because they address the limitations of traditional LMMs, such as assumptions of normality and linearity, by incorporating more flexible, non-parametric approaches.\n\nThe decision to use these specific algorithms was driven by the need to overcome the assumption limitations of traditional methods, which often rely on the independence among measurement points. This assumption may not hold for repeated measurements, leading to potential biases in predictions. By using hybrid ML methods, we aim to provide a more robust and accurate analysis of cognitive data.\n\nThe algorithms were implemented using the R programming language to ensure consistency in method comparisons. This choice was made to facilitate the integration of these methods into existing analytical workflows and to leverage the extensive libraries and tools available in R for statistical and machine learning analyses.\n\nThe study does not focus on the development of entirely new machine-learning algorithms but rather on the application and comparison of existing hybrid methods. Therefore, publishing in a machine-learning journal was not the primary objective. Instead, the focus is on demonstrating the effectiveness of these methods in the context of cognitive data analysis, highlighting their advantages and disadvantages, and providing insights into their performance under different conditions.",
  "optimization/meta": "The models discussed in this study do not function as meta-predictors. Instead, they are individual machine learning algorithms designed to handle nested and repeated measurement structures in cognitive data. The algorithms compared include Generalized Linear Mixed-Effects Model Tree (GLMM tree), Random Effects Expectation-Maximization Tree (RE-EM tree), Longitudinal Classification and Regression Tree (LongCART), and Gaussian Process Boosting (GPBoost). Each of these methods is evaluated independently for its predictive performance and computational efficiency.\n\nThe study focuses on comparing the performance of these algorithms under various conditions, including data contamination and cross-validation. The aim is to understand how each algorithm performs when dealing with cognitive data that has a nested structure, where measurements are repeated within subjects. The results indicate that some algorithms, such as GLMM tree with a nested structure, tend to outperform others in terms of predictive accuracy and model performance metrics like RMSE, MSE, and MAE.\n\nThe independence of training data is a critical consideration in these models. Traditional regression models, including Linear Mixed Models (LMM), rely on assumptions such as normality and linearity, which may not hold for cognitive data with repeated measures. The machine learning algorithms used in this study are more flexible and can handle the nested structures and dependencies within the data without requiring strict assumptions. This flexibility makes them suitable for analyzing cognitive data, where the dependency among repeated measures is a significant factor.\n\nIn summary, the models discussed are not meta-predictors but individual machine learning algorithms tailored to handle the complexities of cognitive data. The study provides a comprehensive comparison of these algorithms, highlighting their strengths and weaknesses in predicting outcomes from cognitive research data.",
  "optimization/encoding": "The data used in this study was derived from cognitive neuroscience experiments, specifically involving functional near-infrared spectroscopy (fNIRS) measurements. The data structure is nested, with repeated observations taken from different brain locations within subjects. This nested structure is crucial for accurately modeling the dependency among repeated measures.\n\nThe data preprocessing involved several steps to ensure it was suitable for analysis with both statistical and machine learning methods. Initially, the data was cleaned to handle any missing values or outliers that could affect the model's performance. This included imputing missing values using appropriate techniques and removing or adjusting outliers to maintain the integrity of the dataset.\n\nNext, the data was normalized to ensure that all features contributed equally to the model. Normalization is particularly important in machine learning algorithms, as it helps in converging the optimization algorithms faster and more accurately. Standardization techniques, such as z-score normalization, were applied to scale the data.\n\nFeature engineering was also a critical step in the preprocessing pipeline. Relevant features were selected based on domain knowledge and exploratory data analysis. These features included measures of neural activity, such as Wavelet Transform Coherence (WTC), which is a metric for interpersonal neural synchrony. Additionally, fixed effects like conditions (e.g., cooperation levels) and regions of interest (e.g., left/right dorsolateral prefrontal cortex) were included in the models.\n\nThe data was then split into training and test sets to evaluate the performance of the models on unseen data. A 10% split was used, where 10% of the observations were randomly selected to form the test dataset, and the remaining 90% constituted the training dataset. This split ensured that the models were trained on a representative subset of the data and tested on a separate, independent subset.\n\nTo simulate the behavior of the methods in case of data contamination, the dataset was perturbed by adding values corresponding to 10 and 15 standard deviations from the mean response to randomly selected 10% of the values variable. This contamination allowed for the examination of how different algorithms perform under adverse conditions.\n\nIn summary, the data encoding and preprocessing involved cleaning, normalization, feature engineering, and splitting the dataset into training and test sets. These steps were essential to prepare the data for analysis with various statistical and machine learning methods, ensuring robust and reliable model performance.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the specific method and structure employed. For the Linear Mixed Models (LMM), the parameters included fixed effects for the significant variables identified through a backward elimination process, as well as random effects to account for the correlation within subjects. The significance of variables was determined using Likelihood Ratio Tests (LRTs) at a 5% significance level, ensuring that only relevant predictors were included in the final model.\n\nFor the Generalized Linear Mixed-Effects Model Trees (GLMM trees), the model parameters included both global random effects and local fixed effects. The GLMM tree algorithm, which is based on model-based recursive partitioning, allowed for the detection of interactions among subgroups of treatments in clustered data. This method partitioned the observations based on additional variables, estimating fixed-effect models in each separated portion of the data.\n\nThe selection of parameters was guided by statistical criteria such as the Akaike Information Criterion (AIC) for LMMs and the log-likelihood for GLMM trees. Different covariance structures were also considered, including Autoregressive processes of order 1 (AR(1)), Continuous AR(1), a general positive definite matrix, and a compound-symmetric matrix. The final model selection was based on the structure that yielded the lowest AIC value, indicating the best fit for the data.\n\nAdditionally, the GPBoost algorithm was constructed with different optimizer algorithms, including Gradient Descent (GD), Weighted Least Squares (WLS), Nelder-Mead (NM), and Broyden-Fletcher-Goldfarb-Shanno (BFGS). The performance metrics calculated from the GPBoost algorithm with different optimizer functions were compared to determine the most effective optimization technique.\n\nIn summary, the number of parameters and their selection were carefully considered to ensure the models were parsimonious and provided the best predictive performance. The use of statistical criteria and different covariance structures helped in identifying the most appropriate model for the given data.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "In our study, we employed several methods to ensure that our models neither overfit nor underfit the data. Overfitting is a concern when the number of parameters in a model is much larger than the number of training points, leading to a model that performs well on training data but poorly on unseen data. To mitigate this risk, we utilized cross-validation techniques. Specifically, we partitioned the original dataset into training and test sets, with 10% of the observations randomly selected to construct the test dataset. This approach allowed us to evaluate the model's performance on unseen data, providing a more reliable estimate of its generalization capability.\n\nAdditionally, we examined the relative changes in model performance metrics when the data was contaminated with high values. This involved adding values corresponding to 10 and 15 standard deviations from the mean response to randomly selected 10% of the values variable. The results, illustrated in Table 6, indicated that methods like GPBoost and LMM were less affected by contamination, exhibiting smaller changes in performance metrics. This robustness suggests that these models are less likely to overfit the data.\n\nUnderfitting, on the other hand, occurs when a model is too simple to capture the underlying patterns in the data. To address this, we compared the performance of various models, including GLMM trees, RE-EM trees, and GPBoost, with and without nested data structures. The GLMM tree with a nested structure consistently outperformed other methods in terms of RMSE, MSE, and MAE, indicating that it captured the complexities of the data more effectively. Furthermore, we constructed fitted versus actual values plots to visually assess how well the models' predictions aligned with the observed data. The scatter plots for the GLMM tree with and without nested structures, shown in Figure 4, demonstrated that the nested structure model's predictions were more closely aligned with the actual values, further confirming its superior performance.\n\nIn summary, through cross-validation, contamination analysis, and performance metric comparisons, we ensured that our models neither overfit nor underfit the data. The GLMM tree with a nested structure emerged as the most robust and accurate model, capable of generalizing well to unseen data.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models discussed in our study vary in their interpretability, ranging from transparent to more complex, black-box-like structures. Among the methods evaluated, the Generalized Linear Mixed-Effects Model Tree (GLMM tree) stands out for its interpretability. The GLMM tree is not a black-box model; instead, it provides a clear, tree-based structure that is relatively easy to interpret. This tree structure allows researchers to understand the relationships between predictors and the response variable in a straightforward manner. Each split in the tree represents a decision based on a predictor variable, making it possible to trace the path from the root to the leaves and understand how different factors influence the outcome.\n\nIn contrast, other methods like Gaussian Process Boosting (GPBoost) and Longitudinal Classification and Regression Tree (LongCART) are more complex and can be considered black-box models. These methods combine advanced statistical techniques and machine learning algorithms, which, while powerful, do not offer the same level of transparency as the GLMM tree. For instance, GPBoost integrates Gaussian processes with boosting, which can make the underlying relationships between variables less intuitive to decipher.\n\nThe Random Effects Expectation-Maximization Tree (RE-EM tree) and its unbiased variant also fall into a category that is somewhat less interpretable than the GLMM tree but more transparent than GPBoost. These models use expectation-maximization algorithms to handle random effects, which adds a layer of complexity but still allows for some level of interpretability through the tree structure.\n\nIn summary, while some of the models we evaluated are more opaque and can be challenging to interpret, the GLMM tree offers a clear and interpretable structure. This makes it a valuable tool for researchers who need to understand the underlying relationships in their data, rather than just relying on predictive accuracy.",
  "model/output": "The model discussed in this subsection is primarily focused on regression tasks. The performance of the models is evaluated using metrics such as RMSE (Root Mean Squared Error), MSE (Mean Squared Error), and MAE (Mean Absolute Error), which are commonly used to assess the accuracy of regression models. The fitted versus actual values plots further support this, as they are used to visualize the predictive performance of the regression models.\n\nThe GLMM tree, which includes indices nested within the subject variable, has been identified as the best-performing model in terms of these regression metrics. It demonstrates the lowest RMSE, MSE, and MAE values, indicating superior predictive accuracy compared to other methods. Additionally, the scatter plots of fitted versus actual values show that the GLMM tree with a nested structure provides predictions that are closely aligned with the actual values, reinforcing its effectiveness as a regression model.\n\nThe GPBoost algorithm, constructed with different optimizer algorithms, is also used for regression tasks. The performance metrics calculated from GPBoost, such as RMSE, further confirm its application in regression analysis. The algorithm's ability to handle clustered or longitudinal data without assuming a specific functional form makes it a versatile tool for regression modeling.\n\nIn summary, the models discussed in this subsection are regression models, with the GLMM tree and GPBoost algorithm being particularly notable for their predictive performance. The use of regression metrics and fitted versus actual values plots underscores the focus on regression tasks.",
  "model/duration": "The execution time of the models varied significantly depending on the method and whether a nested structure was included. The Linear Mixed Model (LMM) without a nested structure took approximately 0.11 seconds to run, while the LMM with a nested structure required about 0.95 seconds. The Generalized Linear Mixed-Effects Model Tree (GLMM tree) without a nested structure had a notably higher execution time of around 230.67 seconds, but this decreased to 105.63 seconds when a nested structure was included. The Random Effects Expectation-Maximization Tree (RE-EM tree) without a nested structure took about 5.18 seconds, reducing to 8.32 seconds with a nested structure. The Unbiased RE-EM tree followed a similar pattern, taking 4.11 seconds without a nested structure and 16.89 seconds with one. The GPBoost algorithm was the fastest, completing in virtually no time (0.00 seconds) without a nested structure and 0.10 seconds with one. These variations highlight the trade-offs between computational efficiency and model complexity, with more sophisticated models generally requiring more time to converge.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, the evaluation of the methods involved a comprehensive approach to assess both predictive performance and computational efficiency. We began by examining three key goodness-of-fit measures: Mean Squared Error (MSE), Root-Mean-Squared Error (RMSE), and Mean Absolute Error (MAE). These metrics were initially calculated for the full dataset to establish a baseline performance for each method.\n\nTo further evaluate the robustness of the methods, we introduced contamination into the data. This step simulated the behavior of the methods in the presence of unusual observations, allowing us to observe how each method handled outliers and noise. The relative changes in RMSE and MAE were compared across all methods to determine their resilience against contaminated data.\n\nAdditionally, we performed model validation using a train and test dataset approach. This involved splitting the data into training and testing sets to assess how well each method generalized to unseen data. The results from these evaluations were summarized to compare the fitting performances of the different methods.\n\nThe algorithms considered in this study included the Linear Mixed Model (LMM) and several hybrid machine learning methods such as Generalized Linear Mixed-Effects Model Tree (GLMM tree), Random Effects Expectation-Maximization Tree (RE-EM tree), unbiased RE-EM tree, Longitudinal Classification and Regression Tree (LongCART), and Gaussian Process Boosting (GPBoost). Each of these methods was evaluated under the same conditions to ensure a fair comparison.\n\nThe GLMM tree, particularly when including a nested structure, demonstrated the best predictive performance with the lowest MSE, RMSE, and MAE values. However, it is important to note that this method required the highest computational time, indicating a trade-off between accuracy and speed. The other methods were also evaluated for their performance metrics and computational efficiency, providing a comprehensive overview of their strengths and weaknesses.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to assess the effectiveness of the methods used. These metrics include the Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Squared Error (MSE). These metrics are widely recognized in the literature for evaluating the predictive performance of models, particularly in the context of repeated measurements and nested data structures.\n\nRMSE provides a measure of the average magnitude of the errors between predicted and actual values, giving more weight to larger errors. MAE, on the other hand, provides the average absolute errors without considering the direction, offering a straightforward measure of prediction accuracy. MSE is similar to RMSE but is not in the same units as the response variable, making it less interpretable directly but useful for comparative purposes.\n\nWe also examined the relative changes in these performance metrics when the datasets were contaminated. This allowed us to understand how robust each method is against unusual observations. Additionally, we implemented cross-validation to compare the predictive performances of the Linear Mixed Model (LMM) and hybrid machine learning methods on unseen datasets.\n\nThe methods evaluated include the Linear Mixed Model (LMM) with and without nested structure, Generalized Linear Mixed-Effects Model Tree (GLMM tree), Random Effects Expectation-Maximization Tree (RE-EM tree), unbiased RE-EM tree, Longitudinal Classification and Regression Tree (LongCART), and Gaussian Process Boosting (GPBoost). The GLMM tree with nested structure consistently showed the best performance in terms of RMSE, MSE, and MAE, although it required the highest computational time for convergence.\n\nOverall, the set of metrics used is representative of standard practices in the literature, ensuring a comprehensive evaluation of the models' predictive capabilities and robustness.",
  "evaluation/comparison": "In our study, we did not perform a comparison to publicly available methods on benchmark datasets. Instead, we focused on comparing the Linear Mixed Model (LMM) and hybrid machine learning (ML) methods specifically tailored to handle the unique characteristics of our cognitive dataset. This dataset was chosen because it had not been previously analyzed with appropriate methods, particularly those that account for the dependency structure between repeated observations.\n\nWe did not compare our methods to simpler baselines. Instead, we concentrated on evaluating the performance of LMM and various hybrid ML algorithms, such as the Generalized Linear Mixed-Effects Model Tree (GLMM tree), Random Effects Expectation-Maximization Tree (RE-EM tree), and Gaussian Process Boosting (GPBoost). These methods were selected because they can handle nested structures and repeated measurements, which are crucial for analyzing cognitive data.\n\nOur evaluation involved examining the predictive performances and computational speeds of these algorithms. We also considered the conceptual differences between these algorithms and the statistical methods used. The data was perturbed to simulate contamination, and the relative changes in performance metrics were compared. Additionally, cross-validation was implemented to assess the predictive performances of LMM and hybrid methods on unseen datasets.\n\nThe results indicated that the GLMM tree with a nested structure outperformed other methods in terms of model performance metrics, achieving the lowest Root Mean Square Error (RMSE), Mean Square Error (MSE), and Mean Absolute Error (MAE). However, the GLMM tree algorithm required the highest time for convergence compared to other methods.\n\nIn summary, our comparison focused on advanced methods suitable for cognitive data analysis, rather than simpler baselines or benchmark datasets. This approach allowed us to provide a detailed evaluation of the strengths and weaknesses of each method in the context of our specific dataset.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files used in this study are publicly available. The open raw data can be accessed at the following URL: http://doc.ml.tu-berlin.de/simultaneous_EEG_NIRS/. This data was gathered from a study on cognitive science research and includes vendor-agnostic and vendor-specific formats for the n-back task. The data was processed using the Modified Beer-Lambert Law to convert optical density measures to oxyhemoglobin (HbO) and deoxyhemoglobin (HbR) concentrations. The statistical analyses were conducted using HbO concentrations, as they are considered the most reliable measures for working on regional cerebral blood flow alterations. The data processing and analysis were performed using MATLAB and R programming languages."
}