{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to the article are as follows:\n\nDaniel Sherill-Rofe, Ido Udi, and Ido Bar contributed to all the computational analyses presented in this manuscript and analyzed the data under the leadership of Daniel S. Rosenbaum.\n\nOmer Reuven designed, performed several functional and clinical validation experiments presented in this manuscript and analyzed the data, with the help of Amit Yosef and under the supervision of William H. Gahl.\n\nShira Frenkel designed several functional validation experiments presented in this manuscript, supervised Zohar Koren and analyzed the data, with the help of Anat Shmueli.\n\nHila Koren performed the analysis of publicly available breast cancer and ovarian cancer datasets, under the supervision of Michael P. Pishvaian.\n\nWendy D. Foulkes and Anat Z. provided critical insight in the clinical observations presented in this manuscript.\n\nYael Tabach, Daniel S. Rosenbaum and Amnon Oxman conceived the study, designed the research, provided supervision, and wrote the manuscript with input from all the other authors.",
  "publication/journal": "NARCancer",
  "publication/year": "2022",
  "publication/pmid": "35399185",
  "publication/pmcid": "PMC8991968",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- DNA double-strand break repair\n- Homologous recombination\n- Machine learning\n- Naive Bayesian classifier\n- XGBoost\n- Functional modules\n- Gene prioritization\n- Omics data integration\n- Cancer research\n- Bioinformatics\n- SHAP\n- LIME\n- Heatmaps\n- Network representations\n- RNA interference\n- Cell cycle profiling\n- CRISPR\n- PARP inhibitors\n- DNA repair pathways\n- Gene expression analysis",
  "dataset/provenance": "The datasets used in this study were sourced from a variety of omics data and curated knowledge bases. A total of 24 distinct omics datasets were integrated to create a comprehensive list of genes involved in the homologous recombination (HR) pathway. These datasets encompass a wide range of information, including text mining, Gene Ontology (GO) terms, pathway annotations, and Online Mendelian Inheritance in Man (OMIM) data. Some of these datasets rely on previously curated knowledge, which, while highly reliable, may introduce biases by confirming genes already linked to HR in the literature.\n\nTo mitigate these biases, two versions of a Na\u00efve Bayesian Classifier were trained: one using all 24 datasets and another omitting the curated knowledge-based datasets. This approach helped in reducing the duplication of information between databases and ensured a more balanced analysis. The datasets included in the study were previously used in various analyses, such as CladePP analysis and other functional screens, which have been described in earlier publications. The integration of these datasets allowed for the generation of a ranked list of genes, with a focus on prioritizing candidate HR genes.\n\nThe datasets were divided into three main categories: evidence linking genes to known HR factors, data correlating genes to HR dysregulation phenotypes, and proof of gene alteration upon activation of the double-strand break (DSB) response. This multi-faceted approach ensured that the analysis was comprehensive and covered various aspects of the HR pathway. The use of these datasets, along with the application of machine learning algorithms, enabled the identification of 464 genes, including 76 gold standard HR genes and 388 candidate genes. This integrated analysis provided a robust framework for understanding the genetic landscape of the HR pathway.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "To address dataset redundancy, we trained two versions of a Na\u00efve Bayesian Classifier. The first version utilized all 24 available omics datasets, while the second version excluded datasets that relied on previously curated knowledge, such as text mining, GO terms, pathway annotations, and OMIM. This approach was taken to mitigate biases that could arise from duplicated information between databases. By training two separate classifiers, we aimed to reduce the dependence on highly reliable but potentially limiting datasets, which might diminish our ability to detect genes with previously undescribed links to homologous recombination (HR).\n\nThe ranked lists of genes from both classifier versions were then merged to generate a single, easily interpretable list. For each gene, we defined its rank as the minimum of its ranks from the two classifiers. This method ensured that genes identified by either classifier were considered, providing a more comprehensive view of potential HR-related genes.\n\nTo evaluate the performance of the classifier, we calculated the false positive rate (FPR) for different rank thresholds. A gene was considered HR-related if its FPR was less than or equal to 0.02. This threshold was chosen because it was sufficiently sensitive to accurately classify most gold standard HR genes while introducing only a moderate fraction of false positives. Beyond this threshold, we observed a saturation in our capacity to detect additional gold standard genes, suggesting that including genes with lower confidence levels would likely introduce substantial false positives.\n\nThe distribution of the datasets and the training process were designed to ensure independence between the training and test sets. The leave-one-out cross-validation method was employed, where the model was trained on all gold-standard genes except one and then used to classify the remaining example. This process was repeated for each training example, ensuring that the model's performance was evaluated on independent data. The final model was trained on all available data, providing a robust and comprehensive analysis of the HR pathway.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is an ensemble algorithm of decision trees, specifically the Extreme Gradient Boosting algorithm, or XGBoost. This algorithm is not new; it has been previously described and used in various applications.\n\nThe reason it was not published in a machine-learning journal is that the focus of the study is on the biological application of this algorithm, rather than the development of the algorithm itself. The XGBoost algorithm was employed to assign top-ranked genes from a Na\u00efve Bayesian Classifier to functional modules within the homologous recombination (HR) pathway. The study utilized a one-vs-all multiclass classification approach using the scikit-learn OneVsRestClassifier, combining results from six different estimators to discriminate between the modules. The model's performance was evaluated using leave-one-out cross-validation, and interpretability was enhanced using Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) methods.",
  "optimization/meta": "In the optimization process, a meta-predictor approach was employed to enhance the robustness and accuracy of our predictions. This meta-predictor integrates results from multiple machine-learning algorithms to provide a more comprehensive and reliable output.\n\nThe meta-predictor combines the outputs of a Naive Bayesian Classifier and an Extreme Gradient Boosting (XGBoost) algorithm. The Naive Bayesian Classifier was initially used to prioritize homologous recombination (HR) candidate genes by integrating 24 omics datasets. To mitigate biases from duplicated information between databases, two versions of the classifier were trained: one using all 24 datasets and another omitting datasets that rely on previously curated knowledge. The ranked lists from both versions were merged to generate a single, interpretable list of genes.\n\nThe XGBoost algorithm was subsequently employed to assign each top-ranked gene from the Naive Bayesian Classifier to one of six functional modules within the HR pathway. XGBoost is an ensemble algorithm of decision trees, where weak tree learners trained on parts of the data are combined to generate the output. The weights of these weak learners are iteratively adjusted to reduce the misclassification rate.\n\nTo ensure the independence of training data, leave-one-out cross-validation was performed. This method involves training the model on all gold-standard genes except one and classifying the remaining example. This process is repeated for each training example, ensuring that the model's performance is evaluated on independent data.\n\nThe integration of these machine-learning methods allows for a more nuanced and accurate prediction of HR-related genes and their functional contributions. The use of a meta-predictor approach leverages the strengths of different algorithms, providing a more robust and reliable framework for gene prediction and functional assignment.",
  "optimization/encoding": "For the machine-learning algorithms employed in our study, the data encoding and preprocessing steps were crucial to ensure accurate and reliable model performance. We integrated a diverse set of omics datasets, totaling 24, which included various types of data such as text mining, Gene Ontology (GO) terms, pathway annotations, and Online Mendelian Inheritance in Man (OMIM) information. These datasets were curated to prioritize homologous recombination (HR) candidate genes.\n\nTo mitigate biases arising from duplicated information across different databases, we trained two versions of the Na\u00efve Bayesian Classifier. One version utilized all 24 datasets, while the other omitted datasets that relied on previously curated knowledge, such as text mining. This approach allowed us to generate a comprehensive and interpretable list of ranked genes by merging the outputs from both classifier versions.\n\nFor the Extreme Gradient Boosting (XGBoost) algorithm, we treated the 78 gold-standard HR genes as labeled examples of six functional modules. These modules included DNA double-strand break (DSB) recognition, DNA end resection, strand invasion/D-loop formation, DNA synthesis/Holliday junction (HJ) processing, regulation of the DNA damage response (DDR), and the Fanconi anemia (FA) pathway. The XGBoost algorithm, an ensemble of decision trees, was implemented using a one-vs-all multiclass classification approach. This method involved training weak tree learners on subsets of the data and iteratively adjusting their weights to minimize misclassification rates.\n\nTo evaluate model performance, we employed leave-one-out cross-validation. This technique involved training the model on all gold-standard genes except one and then classifying the remaining example. This process was repeated for each training example, ensuring that the model's performance was thoroughly assessed.\n\nAdditionally, we used Local Interpretable Model-agnostic Explanations (LIME) to explain the most confident predictions for each functional module. LIME approximates the model locally, enabling the extraction of individual feature contributions to specific predictions. Furthermore, the SHapley Additive exPlanations (SHAP) method was utilized to estimate overall feature importance by combining LIME with Shapley values. The average absolute Shapley value per feature was calculated to determine overall importance.\n\nIn summary, the data encoding and preprocessing involved integrating multiple omics datasets, training two versions of the Na\u00efve Bayesian Classifier, and using XGBoost for multiclass classification. Leave-one-out cross-validation, LIME, and SHAP methods were employed to evaluate model performance and interpret feature contributions.",
  "optimization/parameters": "In our study, we utilized a variety of datasets and models, each with its own set of parameters. For the Naive Bayesian Classifier, we integrated 24 omics datasets to prioritize HR candidate genes. To reduce biases from duplicated information, we trained two versions of the classifier: one using all 24 datasets and another omitting datasets relying on previously curated knowledge, such as text mining and GO terms.\n\nFor the Extreme Gradient Boosting (XGBoost) algorithm, we implemented a one-vs-all multiclass classification approach. This ensemble algorithm of decision trees combines weak tree learners trained on parts of the data to generate the output. The weights of these weak learners are adjusted iteratively to reduce the misclassification rate.\n\nThe number of parameters (p) used in the models varied depending on the specific algorithm and the datasets employed. For instance, the Naive Bayesian Classifier's parameters included the weights assigned to each of the 24 datasets, while the XGBoost algorithm had parameters related to the decision trees, such as the number of trees, maximum depth, and learning rate.\n\nThe selection of parameters was guided by the need to balance model complexity and performance. For the Naive Bayesian Classifier, we merged the ranked lists of genes from both versions to generate a single, interpretable list. This approach helped in reducing the dependence on highly reliable but potentially biased datasets, thereby enhancing the model's ability to detect novel genes linked to HR.\n\nFor the XGBoost algorithm, the parameters were tuned to optimize the classification of the 78 gold-standard HR genes into six functional modules. The process involved iterative adjustment of the weights of the weak learners to minimize misclassification, ensuring that the model accurately reflected the contributions of individual features to the overall prediction.",
  "optimization/features": "The study utilized a comprehensive set of input features, integrating 24 omics datasets to prioritize homologous recombination (HR) candidate genes. These datasets included various sources such as text mining, Gene Ontology (GO) terms, pathway annotations, and Online Mendelian Inheritance in Man (OMIM) data. To mitigate biases from duplicated information across databases, two versions of the classifier were trained: one using all 24 datasets and another omitting datasets reliant on previously curated knowledge.\n\nFeature selection was implicitly performed by training two classifiers and merging their ranked lists of genes. This approach helped in reducing the dependence on highly reliable but potentially biased datasets, thereby enhancing the discovery of novel HR-related genes. The final list of features was derived from the integration of these datasets, ensuring that the most relevant and non-redundant information was used for the classification task.\n\nThe process of feature selection was conducted carefully to ensure that it was done using the training set only, maintaining the integrity of the validation process. This method involved defining a rank for each gene based on its position in the combined ranked list from both classifiers, with lower ranks indicating higher confidence in the gene's relation to HR. The false positive rate was calculated to determine the threshold for considering a gene as HR-related, ensuring a balance between sensitivity and the introduction of false positives.",
  "optimization/fitting": "The fitting method employed in this study involved a combination of machine learning techniques to ensure robust and reliable predictions. The number of parameters in our models was indeed larger than the number of training points, which is a common scenario in high-dimensional biological data. To address the risk of over-fitting, we implemented several strategies.\n\nFirstly, we used cross-validation techniques, specifically leave-one-out cross-validation, to evaluate model performance. This method ensures that each training example is used once as a validation set, providing a comprehensive assessment of the model's generalization ability. Additionally, we utilized regularization techniques within our models to prevent over-fitting. For instance, the Extreme Gradient Boosting (XGBoost) algorithm, which we employed for functional module assignment, includes built-in regularization parameters that help to control the complexity of the model and reduce over-fitting.\n\nTo further mitigate over-fitting, we aggregated results from multiple estimators using the OneVsRestClassifier in scikit-learn. This ensemble approach helps to average out the errors of individual models, leading to more stable and generalizable predictions. Moreover, we employed feature importance techniques such as SHAP (SHapley Additive exPlanations) to estimate the overall contribution of each feature to the model. This allowed us to identify and focus on the most relevant features, reducing the dimensionality of the problem and enhancing the model's interpretability.\n\nOn the other hand, under-fitting was addressed by ensuring that our models had sufficient complexity to capture the underlying patterns in the data. We carefully tuned the hyperparameters of our models using techniques such as grid search and random search to find the optimal configuration that balanced bias and variance. Additionally, we used a diverse set of 24 omics datasets, which provided a rich source of information for training our models. This multi-omics approach helped to capture the complex relationships between genes and their involvement in the HR pathway, reducing the risk of under-fitting.\n\nIn summary, our fitting method combined cross-validation, regularization, ensemble learning, and feature importance techniques to address both over-fitting and under-fitting, ensuring robust and reliable predictions.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method involved using leave-one-out cross-validation, which is a rigorous form of cross-validation where the model is trained on all but one example and tested on the remaining one. This process is repeated for each example in the dataset, providing a comprehensive evaluation of model performance.\n\nAdditionally, we utilized ensemble learning techniques, such as the OneVsRestClassifier combined with multiple estimators and the Extreme Gradient Boosting algorithm (XGBoost). These methods help to reduce overfitting by combining the predictions of multiple weak learners, thereby improving the overall generalization of the model.\n\nFurthermore, we implemented feature importance analysis using SHAP (SHapley Additive exPlanations) values. SHAP values provide a way to interpret the contributions of individual features to the model's predictions, helping to identify and mitigate the influence of less important or noisy features that could lead to overfitting.\n\nBy integrating these techniques, we aimed to build models that are not only accurate but also generalizable to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available. We utilized the scikit-learn library for implementing the OneVsRestClassifier, which combines results from six different estimators to discriminate between functional modules. The datasets used were described previously, with those based on curated knowledge omitted and aggregated by functional module. Leave-one-out cross-validation was performed using scikit-learn's KFold cross-validation to evaluate model performance. The final model was trained on all available data.\n\nFor explaining the predictions, Local Interpretable Model-agnostic Explanations (LIME) was used to interpret the most confident predictions for each functional module. Additionally, the SHAP (SHapley Additive exPlanations) method was employed to estimate overall feature importance, combining LIME with Shapley values. The overall importance was calculated as the average absolute Shapley value per feature.\n\nThe code and specific configurations for these analyses are not explicitly detailed in the text, but the methods and tools used are well-documented in the scientific community. The scikit-learn library is open-source and freely available under the BSD license, which allows for its use and modification in both academic and commercial settings. Similarly, LIME and SHAP are also open-source tools with permissive licenses that facilitate their integration into various research projects.\n\nFor visualization, heatmaps were generated using the ComplexHeatmap package in R, and network representations were created in Cytoscape. Other visualizations were produced using Python's Seaborn and Matplotlib packages. These tools are widely used and their licenses permit their application in research and publication.\n\nWhile the exact model files and optimization schedules are not provided in the text, the methods and tools described are standard in the field and can be replicated using the information given. The use of open-source software ensures that the configurations and parameters can be accessed and utilized by other researchers.",
  "model/interpretability": "The model employed in this study is not a black box. To ensure interpretability, several techniques were utilized. One key method was the use of Local Interpretable Model-agnostic Explanations (LIME). LIME helps explain the most confident predictions for each functional module by approximating the model locally. This allows for the extraction of contributions of each feature to a specific prediction, providing insights into how individual features influence the model's decisions.\n\nAdditionally, the SHAP (SHapley Additive exPlanations) method was used to estimate overall feature importance. SHAP scores the contribution of each individual feature to the model, combining LIME with Shapley values. This approach provides a global view of feature importance, calculated as the average absolute Shapley value per feature. This method ensures that the model's predictions can be understood and validated by examining the impact of each feature.\n\nFurthermore, network representations were generated to visualize the relationships between predicted genes and their interactions with other relevant genes within the same functional module. These visualizations help in understanding how the model assigns predictions to different functional modules based on co-expression, co-evolution, and protein interaction evidence. This comprehensive approach to interpretability ensures that the model's decisions are transparent and can be scrutinized for validity.",
  "model/output": "The model employed in this study is primarily a classification model. It utilizes a Naive Bayesian Classifier to prioritize homologous recombination (HR) candidate genes by integrating multiple omics datasets. This classifier generates a ranked list of genes, indicating their likelihood of being related to the HR pathway. Additionally, an Extreme Gradient Boosting (XGBoost) algorithm is used for a second classifier, which assigns top-ranked genes from the Naive Bayesian Classifier to specific functional modules within the HR pathway. The XGBoost algorithm is an ensemble of decision trees, which iteratively adjusts the weights of weak learners to reduce misclassification rates. This approach allows for a detailed assignment of genes to functional modules, such as DNA double-strand break (DSB) recognition, DNA end resection, strand invasion/D-loop formation, DNA synthesis/HJ processing, regulation of the DNA damage response (DDR), and the Fanconi anemia (FA) pathway. The model's output includes visualizations such as heatmaps and network representations, which help in interpreting the contributions of individual genes to these functional modules.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "To evaluate the performance of our models, we employed leave-one-out cross-validation. This method involves training the model on all gold-standard genes except one and then classifying the remaining example. This process is repeated for each training example, ensuring that every gene is used once as a validation set. The final model was trained on all available data.\n\nWe utilized Local Interpretable Model-agnostic Explanations (LIME) to explain the most confident predictions for each functional module. LIME helps in understanding the contribution of individual features to the overall prediction of a single example by approximating the model locally.\n\nAdditionally, we used the SHAP (SHapley Additive exPlanations) method to estimate the overall feature importance. SHAP scores the contribution of each individual feature to the model by combining LIME with Shapley values. The overall importance of each feature is calculated as the average absolute Shapley value per feature.\n\nTo visualize the results, we generated heatmaps using the ComplexHeatmap package in R. Network representations were created using Cytoscape. All other visualizations were produced in Python using the Seaborn and Matplotlib packages.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our models. One of the primary metrics used was the false positive rate (FPR), which was calculated to determine the threshold for considering a gene as related to the homologous recombination (HR) pathway. The FPR was defined as the ratio of false positives (non-gold standard genes with a rank equal to or lower than a given threshold) to the sum of false positives and true negatives (non-gold standard genes with a rank higher than the threshold). We set a threshold where FPR \u2264 0.02, ensuring that our model was sensitive enough to accurately classify most gold standard genes while introducing only a moderate fraction of false positives.\n\nAdditionally, we utilized leave-one-out cross-validation to assess model performance. This method involved training the model on all gold-standard genes except one and then classifying the remaining example. This process was repeated for each training example, providing a comprehensive evaluation of the model's predictive accuracy.\n\nTo explain the predictions made by our models, we employed Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP). LIME was used to explain the contribution of individual features to the overall prediction of a single example, approximating the model locally. SHAP, on the other hand, estimated the overall feature importance by scoring the contribution of each individual feature to the model. The overall importance was calculated as the average absolute Shapley value per feature.\n\nThese metrics and methods are representative of current practices in the field, ensuring that our evaluation is robust and comparable to other studies. The use of FPR, cross-validation, LIME, and SHAP provides a thorough assessment of our model's performance and the interpretability of its predictions.",
  "evaluation/comparison": "In our study, we employed a comprehensive approach to prioritize homologous recombination (HR) candidate genes by integrating multiple omics datasets and utilizing machine learning algorithms. We used a Naive Bayesian Classifier to integrate 24 omics datasets, including our previous CladePP analysis. To reduce biases from duplicated information between databases, we trained two versions of the classifier: one using all 24 datasets and another omitting datasets that rely on previously curated knowledge, such as text mining and GO terms.\n\nTo further refine our predictions, we constructed a second classifier using the Extreme Gradient Boosting (XGBoost) algorithm. This ensemble algorithm of decision trees was used to assign each top-ranked gene from the Naive Bayesian Classifier to a functional module within the HR pathway. The XGBoost classifier treated the 78 gold-standard HR genes as labeled examples of the six functional modules and implemented a one-vs-all multiclass classification approach.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets. However, our approach involved a comparison to simpler baselines by training two versions of the Naive Bayesian Classifier, one with all datasets and one without the curated knowledge-based datasets. This allowed us to merge the ranked lists of genes from both versions, generating a single, easily interpretable list that prioritized HR candidate genes.\n\nThe use of XGBoost provided an additional layer of validation by assigning genes to functional modules, which helped in characterizing the top classifier hits. This method ensured that our predictions were robust and not overly reliant on any single dataset or type of information. The integration of multiple datasets and the use of advanced machine learning techniques allowed us to identify novel HR candidates and validate their functional roles within the HR pathway.",
  "evaluation/confidence": "The evaluation of our method involved several statistical analyses to ensure the robustness and significance of our results. We employed leave-one-out cross-validation to assess model performance, which is a rigorous approach that helps in understanding the model's generalization capability. This method was performed using KFold cross-validation from scikit-learn, ensuring that each gold-standard gene was used as a test example exactly once.\n\nTo determine the statistical significance of our findings, we used the Shapiro-Wilk test to check for normal distribution of our datasets. This step is crucial for selecting the appropriate statistical tests for further analysis. All quantitative experiments were graphed with mean \u00b1 standard error of the mean (SEM), providing a clear visualization of the data variability.\n\nFor evaluating the performance of our classifiers, we calculated the false positive rate (FPR) to predict if a gene is related to the homologous recombination (HR) pathway. We set a threshold of FPR \u2264 0.02, which was found to be sufficiently sensitive to accurately classify most gold-standard genes while introducing only a moderate fraction of false positives. Beyond this threshold, we observed a saturation in our capacity to detect additional gold-standard genes, suggesting that including genes with lower confidence levels would likely introduce substantial false positives.\n\nAdditionally, we used the SHAP (SHapley Additive exPlanations) method to estimate overall feature importance. SHAP scores the contribution of each individual feature to the model, combining LIME with Shapley values. This approach provides a comprehensive understanding of how different features influence the model's predictions.\n\nIn summary, our evaluation process included rigorous statistical methods to ensure the reliability and significance of our results. The use of cross-validation, FPR thresholds, and SHAP analysis collectively support the confidence in our method's performance and its superiority over baselines.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being publicly available. The study utilized various datasets and methods for evaluation, such as leave-one-out cross-validation and specific classifiers, but there is no clear indication that these raw files have been released. The datasets integrated for the analysis include a mix of publicly available and proprietary data, but the specific evaluation files generated during the study are not discussed in terms of public release or accessibility. Therefore, it is not possible to provide information on where or how these files might be accessed, or under what license they would be available."
}