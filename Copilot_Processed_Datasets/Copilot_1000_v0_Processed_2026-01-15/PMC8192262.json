{
  "publication/title": "Diagnostic performance of StandardTM Q COVID-19 Ag test in symptomatic and asymptomatic subjects with different viral loads",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Journal of Infection and Public Health",
  "publication/year": "2021",
  "publication/pmid": "34175237",
  "publication/pmcid": "PMC8192262",
  "publication/doi": "10.1016/j.jiph.2021.06.002",
  "publication/tags": "- COVID-19\n- Diagnostic performance\n- Rapid antigen test (RAT)\n- RT-qPCR\n- Sensitivity and specificity\n- Machine learning\n- Support vector machine (SVM)\n- Random forest classification\n- Laboratory parameters\n- Clinical utility\n- Viral load\n- Demographic features\n- Clinical and radiological findings\n- Diagnostic accuracy\n- Cross-validation",
  "dataset/provenance": "The dataset used in this study was collected from 83 participants who provided nasopharyngeal and oropharyngeal swabs. These samples were obtained by trained health staff at isolation units. The swabs from each participant were combined in a viral transport medium and stored at -80\u00b0C until further analysis. The laboratory measurements were conducted at the Clinical Pathology Department, Faculty of Medicine, Zagazig University.\n\nThe data includes demographic, clinical, and laboratory characteristics of the enrolled subjects. The age range of the participants was 22 to 87 years, with a median age of 55.5 \u00b1 18.5. The majority of the participants were male (59%), and the remaining were female (41%). Sampling time post-symptoms was available for 70 participants, with samples collected between 0-7 days post-symptoms in 54.2% of the cases, between 8-16 days in 38.5%, and more than 16 days in 5.7%. Clinical data was available for 56.6% of the subjects, with most being symptomatic, showing symptoms such as fever, pharyngitis, chest pain, dyspnea, cough, and diarrhea. Radiological data was available for 44 participants, with 84% showing radiological findings.\n\nThe dataset also includes results from RT-qPCR and rapid antigen tests (RAT). The average Ct value for COVID-19 subjects was 31.1 \u00b1 7.4, with the majority being positive by RT-qPCR (83.1%). The diagnostic performance of the RAT was evaluated, showing a sensitivity of 78.2% and a specificity of 64.2%. The dataset was analyzed using various statistical and machine learning techniques, including support vector machine (SVM) models and random forest classification, to investigate the predictive accuracy of the RAT and identify important demographic and clinical parameters.",
  "dataset/splits": "The dataset was split into two main groups for analysis. The first group consisted of 68 subjects, for whom data on laboratory parameters was available. This group was used to investigate whether measuring blood parameters could enhance the predictive accuracy of the rapid antigen test (RAT) and thus raise its clinical utility. A support vector machine (SVM) model with Monte-Carlo cross-validation was applied to this dataset.\n\nThe second group included all 83 subjects enrolled in the study. This group was used to evaluate the diagnostic performance of the RAT against RT-qPCR results. The demographic and baseline clinical characteristics of these participants were summarized, with a median age of 55.5 \u00b1 18.5. More than half of the subjects were male (59%), and 41% were female. Sampling time post-symptoms was available for 70 participants, with the majority of samples collected between 0\u22127 days post-symptoms (54.2%).\n\nFor the SVM model, the singular value decomposition method was used to impute missing values. The performance of the top-ranked combination (best model) was evaluated for sensitivity, specificity, and accuracy using class probability analysis.\n\nIn summary, the dataset was primarily split into two groups: one for evaluating the predictive accuracy of the RAT with additional blood parameters (68 subjects) and another for assessing the diagnostic performance of the RAT against RT-qPCR results (83 subjects).",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study is not publicly available. However, the research content, including the methodology and results, has been made freely available in PubMed Central and other publicly funded repositories, such as the WHO COVID database. This availability is part of a broader initiative to provide unrestricted access to COVID-19-related research. The permissions for this access are granted for free and will remain active as long as the COVID-19 resource center is operational. This ensures that the findings can be used for further research and analysis by any means, with proper acknowledgment of the original source.",
  "optimization/algorithm": "The machine-learning algorithms used in this study were support vector machine (SVM) and random forest classification. These are well-established algorithms in the field of machine learning and are not new.\n\nThe SVM model was applied with Monte-Carlo cross-validation to investigate whether measuring blood parameters could enhance the predictive accuracy of the rapid antigen test (RAT) for COVID-19. The performance of the top-ranked combination of features was evaluated for sensitivity, specificity, and accuracy using class probability analysis.\n\nThe random forest classification was utilized to identify the demographic and clinical parameters that are most important in determining individuals with positive and negative results for both RAT and RT-qPCR. In both SVM and random forest models, the singular value decomposition method was used to impute missing values.\n\nThese algorithms were chosen for their robustness and ability to handle complex datasets, making them suitable for the analysis of COVID-19 diagnostic performance. The study focused on the application of these algorithms in a real-world setting to improve the diagnostic accuracy of RATs, rather than on the development of new machine-learning algorithms. Therefore, the algorithms were not published in a machine-learning journal but rather in a journal focused on infection and public health.",
  "optimization/meta": "The model employed in this study is a meta-predictor that leverages data from other machine-learning algorithms as input. Specifically, a support vector machine (SVM) model with Monte-Carlo cross-validation was utilized. This SVM model was applied to investigate whether measuring blood parameters could enhance the predictive accuracy of the rapid antigen test (RAT) and thus improve its clinical utility.\n\nThe SVM model was evaluated for sensitivity, specificity, and accuracy using class probability analysis. This analysis was conducted on data from 68 subjects, as the remaining 15 subjects lacked data on laboratory parameters.\n\nAdditionally, a random forest classification method was used to identify the demographic and clinical parameters that are most important in determining individuals with positive and negative results for both RAT and RT-qPCR. The singular value decomposition method was employed to impute missing values in both the SVM and random forest models.\n\nRegarding the independence of the training data, it is not explicitly stated whether the data used for training the SVM model and the random forest model were completely independent. However, the use of Monte-Carlo cross-validation suggests an effort to ensure robustness and generalizability of the model's performance. This cross-validation technique involves multiple iterations of training and testing on different subsets of the data, which helps to mitigate overfitting and ensures that the model's performance is evaluated on independent data splits.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps. Continuous variables, such as age, were expressed as median \u00b1 standard deviation and compared using the Mann-Whitney U test. Categorical variables were expressed as numbers and percentages and compared using the Chi-square or Fisher\u2019s exact test. For the machine learning models, the singular value decomposition method was used to impute missing values. This method is particularly useful for handling missing data in high-dimensional datasets. The support vector machine (SVM) model with Monte-Carlo cross-validation was applied to investigate whether measuring blood parameters could enhance the predictive accuracy of the rapid antigen test (RAT). The performance of the top-ranked combination (best model) was evaluated for sensitivity, specificity, and accuracy using class probability analysis. Additionally, random forest classification was utilized to identify the demographic and clinical parameters most important in determining individuals with positive and negative results for both RAT and RT-qPCR. These analyses were conducted using GraphPad Prism version 8.0.0 for Windows and the Metaboanalyst online server.",
  "optimization/parameters": "In our study, we utilized a support vector machine (SVM) model with Monte-Carlo cross-validation to evaluate the predictive accuracy of the rapid antigen test (RAT) when combined with various blood parameters. The model identified the top-ranked features that contributed most significantly to the prediction accuracy.\n\nThe highest prediction accuracy, 59.3%, was achieved by combining the RAT with hemoglobin (HB) and urea, which were the top two features. This indicates that these two parameters were the most influential in enhancing the predictive accuracy of the RAT.\n\nAdditionally, we explored the inclusion of other parameters such as serum ferritin and C-reactive protein (CRP), which formed the top five ranked features. However, the model that included all features together revealed a lower prediction accuracy of 48%.\n\nThe selection of these parameters was based on their frequency of being selected after cross-validation in the SVM model. This approach ensured that the most relevant and significant parameters were included in the final model, thereby optimizing its performance.",
  "optimization/features": "In our study, we utilized a total of 14 laboratory measurements as input features. These features included hemoglobin (HB), urea, platelet count, white blood cell count (WBC), creatinine, alanine aminotransferase (ALT), aspartate aminotransferase (AST), lactate dehydrogenase (LDH), serum ferritin (S. ferritin), C-reactive protein (CRP), prothrombin time (PT), international normalized ratio (INR), and polymorphonuclear leukocytes (PNL).\n\nFeature selection was indeed performed to identify the most important parameters that could enhance the predictive accuracy of the rapid antigen test (RAT). This process involved using a support vector machine (SVM) model with Monte-Carlo cross-validation. The selection of top-ranked features was based on their frequency of being selected after cross-validation. The most accurate classifier was achieved with the top 3 features, which were HB, urea, and S. ferritin. This combination yielded the highest prediction accuracy of 59.3%.\n\nThe feature selection process was conducted using the entire dataset, ensuring that the selected features were robust and generalizable. This approach helped in identifying the key parameters that significantly influenced the results of both the RAT and RT-qPCR, thereby improving the model's performance.",
  "optimization/fitting": "The study utilized machine learning models, specifically a support vector machine (SVM) with Monte-Carlo cross-validation and random forest classification, to enhance the predictive accuracy of the rapid antigen test (RAT) for COVID-19 diagnosis. The number of parameters considered in the models was relatively large compared to the number of training points, as data from 68 subjects were used for the analysis. To address the potential issue of overfitting, Monte-Carlo cross-validation was employed. This technique involves repeatedly splitting the data into training and validation sets, ensuring that the model's performance is evaluated on unseen data multiple times. This process helps to generalize the model's performance and reduces the risk of overfitting.\n\nAdditionally, the singular value decomposition (SVD) method was used to impute missing values, which further aided in stabilizing the model and preventing overfitting. The random forest classification model was utilized to identify the most important demographic and clinical parameters that influence the results of both RAT and RT-qPCR. This approach helped in selecting the most relevant features, thereby reducing the complexity of the model and mitigating the risk of overfitting.\n\nTo rule out underfitting, the models were evaluated for sensitivity, specificity, and accuracy using class probability analysis. The performance of the top-ranked combination of features was assessed, and the best model was identified based on its predictive accuracy. The SVM model, combined with the top-ranked features, achieved a predictive accuracy of 59.3%, indicating that the model was sufficiently complex to capture the underlying patterns in the data without being too simplistic.\n\nFurthermore, the study acknowledged the limitations of the small sample size and the unavailability of some participants' data, which could potentially affect the model's performance. However, the use of cross-validation and feature selection techniques helped to ensure that the models were robust and generalizable. The real-world application of the models in a clinical setting further validated their practical utility.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was Monte-Carlo cross-validation, which helps in assessing the model's performance and generalization ability by repeatedly splitting the data into training and validation sets. This technique is particularly useful in preventing overfitting by providing a more reliable estimate of the model's performance on unseen data.\n\nAdditionally, we utilized singular value decomposition (SVD) to impute missing values. SVD is a powerful dimensionality reduction technique that can help in reducing the complexity of the data, making the model less prone to overfitting. By transforming the data into a lower-dimensional space, SVD helps in capturing the most important features while discarding the noise, thereby improving the model's generalization.\n\nFurthermore, we applied support vector machine (SVM) models, which inherently include regularization parameters that control the trade-off between achieving a low training error and a low testing error. This regularization helps in preventing the model from becoming too complex and overfitting the training data.\n\nIn summary, our approach to preventing overfitting involved the use of Monte-Carlo cross-validation, singular value decomposition for imputing missing values, and the inherent regularization properties of SVM models. These techniques collectively ensured that our models were robust and generalizable to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed a support vector machine (SVM) model with Monte-Carlo cross-validation to enhance the predictive accuracy of the rapid antigen test (RAT). The performance of the top-ranked combination was evaluated for sensitivity, specificity, and accuracy using class probability analysis. This analysis was conducted on data from 68 subjects, as the remaining 15 subjects lacked data on laboratory parameters.\n\nAdditionally, random forest classification was utilized to identify the most important demographic and clinical parameters in determining individuals with positive and negative results for both RAT and RT-qPCR. In both the SVM and random forest models, the singular value decomposition method was used to impute missing values.\n\nThe software tools and versions used for these analyses are also specified. GraphPad Prism version 8.0.0 for Windows was used for various statistical analyses, including the generation of receiver operating characteristic curves and contingency tables. Metaboanalyst online server was employed for additional data analyses.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the publication. However, the methods and tools used are well-documented, allowing for reproducibility by other researchers. The publication is available under a license that permits unrestricted research re-use and analyses, as long as the original source is acknowledged. This ensures that the findings and methods can be accessed and utilized by the scientific community for further research and validation.",
  "model/interpretability": "The model employed in this study is not a black box. To enhance the interpretability, a support vector machine (SVM) model with Monte-Carlo cross-validation was utilized. This approach allowed for the evaluation of the performance of top-ranked combinations, focusing on sensitivity, specificity, and accuracy through class probability analysis.\n\nAdditionally, random forest classification was used to identify the most important demographic and clinical parameters in determining positive and negative results for both the rapid antigen test (RAT) and RT-qPCR. This method provides transparency by highlighting key features that contribute to the model's predictions.\n\nFor instance, the highest prediction accuracy (59.3%) was achieved by combining the RAT with hemoglobin (HB) and urea, indicating these as top-ranked features. Further analysis with the top five features\u2014including S. ferritin and CRP\u2014showed slightly lower but still significant accuracy. This transparency allows for a clear understanding of which parameters are most influential in the model's decisions.\n\nThe use of singular value decomposition to impute missing values also adds to the model's robustness and interpretability, ensuring that all available data is utilized effectively. Overall, the combination of SVM and random forest classification provides a transparent and interpretable model, making it easier to understand the underlying factors contributing to the predictions.",
  "model/output": "The model employed in this study is a classification model. Specifically, a support vector machine (SVM) model with Monte-Carlo cross-validation was used. This model was applied to enhance the predictive accuracy of the rapid antigen test (RAT) by incorporating blood parameters. The performance of the top-ranked feature combination was evaluated using class probability analysis, focusing on sensitivity, specificity, and accuracy. Additionally, a random forest classification was utilized to identify the most important demographic and clinical parameters for determining positive and negative results for both RAT and RT-qPCR. The model's output includes the classification of subjects as either positive or negative for COVID-19 based on the combined features. The highest prediction accuracy achieved was 59.3% when combining RAT with hemoglobin (HB) and urea. The model's sensitivity was 75.4%, correctly identifying 43 out of 57 true positive subjects, and its specificity was 81.8%, correctly identifying 9 out of 11 true negative subjects. The misclassified subjects are labeled in the relevant figures.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the specific algorithms used in this study is not publicly released. However, the software used for data analysis and machine learning modeling is publicly available. GraphPad Prism version 8.0.0 for Windows was used for various statistical analyses and generating figures. This software is commercially available from GraphPad Software, San Diego, California, USA, and can be accessed through their official website.\n\nAdditionally, the MetaboAnalyst online server was utilized for certain analyses. MetaboAnalyst is an open-source, web-based platform for comprehensive metabolomics data analysis. It is freely available to the public and can be accessed online. The specific version used in this study is referenced in the publication.\n\nFor the machine learning models, such as the support vector machine (SVM) with Monte-Carlo cross-validation and random forest classification, standard algorithms were employed. These algorithms are widely available in various programming languages and libraries, such as Python's scikit-learn, which is open-source and freely available under the BSD license.\n\nThe singular value decomposition method used for imputing missing values is also a standard statistical technique available in many software packages, including R and Python. The specific implementation details and any custom scripts used for these analyses are not publicly released.\n\nIn summary, while the specific source code for the custom analyses is not available, the primary software tools and algorithms used are either commercially available or open-source and can be accessed by researchers.",
  "evaluation/method": "The evaluation of the method involved several steps to assess the diagnostic performance of the rapid antigen test (RAT) and to determine if combining laboratory parameters could enhance its predictive accuracy.\n\nFirst, the diagnostic performance of the RAT was evaluated against RT-qPCR using various metrics such as sensitivity, specificity, and accuracy. These metrics were calculated using contingency tables that contained the numbers of each outcome. The confidence intervals for these metrics were calculated using the Wilson-Brown method.\n\nTo further assess the diagnostic power of the RAT, a receiver operating characteristic curve (ROC) was generated. The area under the curve (AUC) provided another assessment of the diagnostic performance.\n\nAdditionally, a support vector machine (SVM) model with Monte-Carlo cross-validation was applied to investigate whether measuring blood parameters could enhance the predictive accuracy of the RAT. The performance of the top-ranked combination (best model) was evaluated for sensitivity, specificity, and accuracy using class probability analysis. This analysis was conducted on data from 68 subjects, as the remaining 15 subjects lacked data on any of the laboratory parameters.\n\nRandom forest classification was utilized to identify the demographic and clinical parameters that were most important in determining individuals with positive and negative results for both RAT and RT-qPCR. In both the SVM and random forest models, the singular value decomposition method was used to impute missing values.\n\nThe diagnostic performance of the RAT was also evaluated in different subgroups of participants, including gender, symptomatology, radiological findings, and days post-symptom onset. This allowed for a more detailed understanding of how various factors might influence the test's accuracy.\n\nOverall, the evaluation method combined statistical analysis, machine learning techniques, and subgroup analysis to provide a comprehensive assessment of the RAT's diagnostic performance and the potential benefits of integrating laboratory parameters.",
  "evaluation/measure": "In our study, we evaluated the diagnostic performance of the StandardTM Q COVID-19 Ag test using several key metrics. The primary metrics reported include sensitivity, specificity, and accuracy. Sensitivity, which measures the proportion of true positive results among those who are actually positive, was found to be 78.2%. This indicates that the test correctly identified 78.2% of the COVID-19 positive cases as determined by RT-qPCR. Specificity, which measures the proportion of true negative results among those who are actually negative, was 64.2%. This means that the test correctly identified 64.2% of the COVID-19 negative cases. The accuracy of the test, which is the overall proportion of true results (both true positives and true negatives) among the total number of cases tested, was reported for different subgroups of participants. For example, the accuracy for male participants was 71.4%, while for female participants it was 79.4%. These metrics are representative of those commonly reported in the literature for rapid antigen tests, allowing for a meaningful comparison with other studies. Additionally, we used a support vector machine model to evaluate the performance of top-ranked feature combinations in predicting COVID-19 positive subjects, with the most accurate classifier achieving an accuracy of 59.3% for the top 3-feature combination. This approach provides a more nuanced understanding of the test's performance beyond simple sensitivity and specificity measures.",
  "evaluation/comparison": "In our study, we conducted a thorough evaluation of the StandardTM Q COVID-19 Ag test by comparing it with the RT-qPCR assay, which is considered the gold standard for COVID-19 diagnosis. This comparison was essential to understand the diagnostic performance of the rapid antigen test (RAT) in real-world settings.\n\nWe utilized a support vector machine (SVM) model with Monte-Carlo cross-validation to investigate whether measuring blood parameters could enhance the predictive accuracy of the RAT. This model was applied to data from 68 subjects, as the remaining 15 subjects lacked data on laboratory parameters. The SVM model helped us evaluate the sensitivity, specificity, and accuracy of the RAT by analyzing class probability.\n\nAdditionally, we employed a random forest classification model to identify the demographic and clinical parameters that are most important in determining positive and negative results for both RAT and RT-qPCR. This approach allowed us to understand the key factors influencing the test outcomes and to compare the performance of the RAT with the RT-qPCR assay.\n\nThe diagnostic performance of the RAT was assessed using various subgroups of participants, including gender, symptomatology, radiology findings, and days post-symptom onset. This subgroup analysis provided insights into how the RAT performs under different conditions and helped us compare its effectiveness with the RT-qPCR assay.\n\nOverall, our study involved a comprehensive comparison of the RAT with the RT-qPCR assay, using both machine learning models and subgroup analyses. This evaluation was crucial for understanding the strengths and limitations of the RAT in COVID-19 diagnosis and for determining its potential role in clinical settings.",
  "evaluation/confidence": "The evaluation of the StandardTM Q COVID-19 Ag test involved several performance metrics, including sensitivity, specificity, and accuracy, which were accompanied by confidence intervals. For instance, the sensitivity of the test was reported as 78.2%, with a confidence interval indicating the range within which the true sensitivity is likely to fall. This provides a measure of the reliability of the sensitivity estimate.\n\nStatistical significance was also considered in the analysis. For example, the Ct values between RAT-positive and RAT-negative subjects were found to be significantly different, with a P-value of less than 0.0001. This indicates a strong statistical evidence that the difference in Ct values is not due to random chance.\n\nThe diagnostic performance of the test was further evaluated using a support vector machine (SVM) model with Monte-Carlo cross-validation. The model's performance was assessed for sensitivity, specificity, and accuracy, providing a robust evaluation of the test's diagnostic capabilities. The highest prediction accuracy of 59.3% was obtained when combining the RAT with hemoglobin (HB) and urea, suggesting that these laboratory parameters could enhance the predictive accuracy of the RAT.\n\nAdditionally, the receiver operating characteristic (ROC) analysis yielded an area under the curve (AUC) value of 0.7, with a confidence interval and a P-value of 0.02. This AUC value indicates the test's ability to discriminate between COVID-19 positive and negative cases, with the confidence interval and P-value providing information on the statistical significance of this discrimination.\n\nOverall, the evaluation included confidence intervals for key performance metrics and statistical significance tests, ensuring that the results are reliable and that the claims about the test's performance are supported by robust statistical evidence.",
  "evaluation/availability": "The raw evaluation files are not available for public access. The data used in this study is not publicly released due to privacy and ethical considerations. However, the results and analyses presented in the publication are thoroughly detailed, allowing for reproducibility of the methods and findings. The study adheres to ethical guidelines and ensures the confidentiality of participant information. For those interested in the methodologies and analyses, the publication provides comprehensive descriptions of the statistical and machine learning techniques employed, enabling other researchers to replicate the processes using their own datasets."
}