{
  "publication/title": "Exponentially Increasing Trend of Infected Patients with COVID-19 in Iran: A Comparison of Neural Network and ARIMA Forecasting Models",
  "publication/authors": "The authors who contributed to the article are:\n\nLeila Moftakhar, who is part of the Student Research Committee, Department of Epidemiology, Shiraz University of Medical Sciences, Shiraz, Iran.\n\nMozhgan Seif, who is part of the Department of Epidemiology, Faculty of Biostatistics, School of Health, Shiraz University of Medical Sciences, Shiraz, Iran.\n\nMarziyeh Sadat Safe, who is affiliated with Seyed-al-Shohada Hospital, Jahrom University of Medical Sciences, Jahrom, Iran. She is also the corresponding author for this paper, and can be contacted via email at marziyehsafe@gmail.com.",
  "publication/journal": "Iran J Public Health",
  "publication/year": "2020",
  "publication/pmid": "34268211",
  "publication/pmcid": "PMC8266002",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- COVID-19\n- Forecast\n- Artificial neural network\n- Iran\n- ARIMA\n- Time series analysis\n- Epidemiology\n- Infectious diseases\n- Public health\n- Predictive modeling",
  "dataset/provenance": "The dataset used in this study was sourced from daily reports provided by the Ministry of Health and Medical Education of Iran, as well as open datasets made available by Johns Hopkins University. These sources were utilized to gather the daily confirmed cases of COVID-19 in Iran from February 19, 2020, to March 30, 2020. The dataset consisted of 42 data points, covering the observed number of new infected cases over this period.\n\nThis dataset was split into two parts for model comparison: a training set that included data from February 19, 2020, to March 24, 2020, and a test set that covered data from March 25, 2020, to March 30, 2020. The training set comprised 35 days of data, while the test set included 6 days of data. This division allowed for the evaluation of the models' predictive accuracy on unseen data, ensuring a robust assessment of their performance.\n\nThe use of publicly available datasets from reputable sources ensured the reliability and accuracy of the data used in our study. This approach is consistent with community practices in epidemiological research, where transparency and reproducibility are paramount. By leveraging these datasets, we aimed to provide a comprehensive and accurate forecast of the COVID-19 trend in Iran, which could inform public health planning and decision-making.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The training set included data from February 19th to March 24th, 2020, which consisted of 35 days of observations. The test set covered the period from March 25th to March 30th, 2020, encompassing 6 days of data. This division was used to train and evaluate the forecasting models, specifically the ARIMA and Artificial Neural Network (ANN) models. The training set was used to fit the models, while the test set was used to assess their predictive performance.",
  "dataset/redundancy": "The dataset used in this study was split into two parts: a training set and a test set. The training set included data from February 19th to March 24th, 2020, covering a period of 35 days. The test set encompassed data from March 25th to March 30th, 2020, spanning 6 days. This split was designed to ensure that the training and test sets were independent, allowing for an unbiased evaluation of the models' predictive performance.\n\nTo enforce the independence of the training and test sets, the data was divided chronologically. This means that the models were trained on historical data and then tested on future data that the models had not seen during training. This approach helps to simulate real-world forecasting scenarios where models predict future outcomes based on past observations.\n\nThe distribution of the dataset in this study is comparable to other machine learning datasets used for time series forecasting. The focus on ensuring independence between the training and test sets is a common practice in time series analysis to avoid data leakage and to provide a more reliable assessment of model performance. By splitting the data in this manner, the study aims to provide robust and generalizable results that can be applied to future forecasting tasks.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is Artificial Neural Networks (ANN). This class of algorithms is well-established and widely recognized for its powerful nonlinear regression capabilities. ANN is a member of machine learning algorithms and has been recently known for its ability in time series forecasting.\n\nThis algorithm is not new, as it has been applied extensively in various fields, including medical research. The choice to use ANN in this study was driven by its proven effectiveness in modeling and predicting time-series data, which is crucial for forecasting the spread of infectious diseases like COVID-19.\n\nThe decision to publish this work in a public health journal rather than a machine-learning journal is due to the focus of the study. The primary objective was to forecast the number of new COVID-19 cases in Iran and compare the performance of ANN with another popular time-series forecasting model, ARIMA. The results and implications of this study are more directly relevant to public health policy makers and researchers in the field of epidemiology, rather than to the machine-learning community. Therefore, it was appropriate to publish the findings in a journal that caters to this audience.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data used for the machine-learning algorithm was the daily-confirmed cases of COVID-19 in Iran from February 19 to March 30, 2020. This data was extracted from daily reports of the Ministry of Health and Medical Education of Iran, and open datasets provided by Johns Hopkins University.\n\nTo prepare the data for modeling, several preprocessing steps were undertaken. For the ARIMA model, differencing was applied if necessary to transform the time series data into stationary ones. Additionally, the Box-Cox transformation was used to improve the model's fitting by providing normal observations.\n\nFor the Artificial Neural Network (ANN), the data was split into training and testing sets. The training set included data from February 19 to March 24, while the testing set covered data from March 25 to March 30. The ANN was trained with three hidden layers, each containing 10 neurons, and the number of repetitions for this algorithm was set to 300.\n\nThe goodness of fit for both models was assessed through various residual plots, including residuals versus observation order, Normal Probability Plot (NPP), histogram, Autocorrelation Function (ACF), and Partial Autocorrelation Function (PACF). Residuals were also tested for stationarity using the Box-Ljung test. The significance level for these tests was set at 0.05.",
  "optimization/parameters": "In our study, we employed two distinct models for forecasting the number of daily new COVID-19 cases: Artificial Neural Networks (ANN) and Auto-Regressive Integrated Moving Average (ARIMA). For the ANN model, we utilized three hidden layers, each containing 10 neurons. The number of repetitions for this algorithm was set to 300. The selection of these parameters was based on standard practices in neural network modeling and was aimed at achieving a balance between model complexity and computational efficiency.\n\nFor the ARIMA model, the specific parameters (p, d, q) were determined through a process of model identification and diagnostic checking. The ARIMA model used in our study was identified as ARIMA(0,1,0), which indicates that the model includes no autoregressive terms (p=0), one differencing (d=1) to make the time series stationary, and no moving average terms (q=0). This configuration was chosen based on the autocorrelation and partial autocorrelation functions of the time series data, as well as the goodness-of-fit criteria.\n\nThe dataset was split into training and testing sets to evaluate the performance of both models. The training set included data from February 19 to March 24, 2020, while the testing set covered March 25 to March 30, 2020. This split allowed us to assess the models' predictive accuracy on unseen data. The goodness of fit for the models was evaluated using residual analysis, including plots of residuals versus observation order, Normal Q-Q plots, histograms, Autocorrelation Function (ACF), and Partial Autocorrelation Function (PACF). Additionally, the residuals were tested for stationarity using the Box-Ljung test.\n\nIn summary, the ANN model was configured with three hidden layers of 10 neurons each and 300 repetitions, while the ARIMA model was specified as ARIMA(0,1,0). These parameters were selected to optimize the models' performance in forecasting the number of new COVID-19 cases in Iran.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "In our study, we employed two distinct models, ARIMA and Artificial Neural Network (ANN), to forecast the number of new COVID-19 cases. Both models were carefully implemented to ensure robust predictions.\n\nFor the ARIMA model, we utilized differencing and Box-Cox transformation to achieve stationarity and improve model fitting. The goodness of fit was rigorously assessed through various residual diagnostics, including plots of residuals versus observation order, Normal Probability Plot (NPP), histogram, Autocorrelation Function (ACF), and Partial Autocorrelation Function (PACF). The residuals were tested for stationarity using the Box-Ljung test. These steps ensured that the model was neither overfitting nor underfitting the data.\n\nThe ANN model consisted of three hidden layers, each containing 10 neurons, and was trained over 300 repetitions. The input layer neurons were derived from previous observations, and the output layer provided forecasts for future values. To mitigate overfitting, we split the dataset into training and test sets, with the training set covering observations from February 19 to March 24, and the test set from March 25 to March 30. This split allowed us to evaluate the model's performance on unseen data, ensuring that it generalized well beyond the training set.\n\nBoth models were compared using Mean Squared Error (MSE) and Mean Absolute Error (MAE) criteria. The residuals from both models were checked for randomness and normality, confirming that neither model was overfitting or underfitting the data. The Shapiro-Wilk test approved the normality of residuals, and the Box-Ljung test affirmed their stationarity. Additionally, the absence of spikes in the ACF and PACF plots indicated no remaining autocorrelation among the residuals.\n\nIn summary, our approach involved thorough residual diagnostics and dataset splitting to ensure that both the ARIMA and ANN models were well-fitted without overfitting or underfitting issues. This meticulous process allowed us to confidently compare the models and draw reliable conclusions about their forecasting capabilities.",
  "optimization/regularization": "In our study, we employed regularization methods to prevent overfitting, particularly when using the Artificial Neural Network (ANN) for forecasting. Overfitting is a common issue in machine learning where a model learns the noise in the training data rather than the underlying pattern, leading to poor generalization on new data.\n\nTo mitigate this, we utilized techniques such as setting an appropriate number of hidden layers and neurons. Specifically, our ANN was trained with three hidden layers, each containing 10 neurons. This architecture was chosen to balance the model's capacity to learn complex patterns while avoiding excessive complexity that could lead to overfitting.\n\nAdditionally, we set the number of repetitions for the ANN algorithm to 300. This ensured that the model was trained sufficiently without becoming overly sensitive to the training data. By controlling the number of repetitions, we aimed to achieve a stable and generalizable model.\n\nFurthermore, we assessed the goodness of fit for our models through various residual analyses. These included plots of residuals versus observation order, Normal Probability Plot (NPP), histogram, Autocorrelation Function (ACF), and Partial Autocorrelation Function (PACF). The residuals were also tested for stationarity using the Box-Ljung test. These assessments helped us ensure that our models were not overfitting by verifying that the residuals were randomly scattered around zero and did not exhibit any patterns.\n\nIn summary, our regularization methods included controlling the architecture of the ANN, setting an appropriate number of training repetitions, and conducting thorough residual analyses to ensure the robustness and generalizability of our forecasting models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the Artificial Neural Network (ANN) was trained with three hidden layers, each containing 10 neurons, and the number of repetitions for this algorithm was set to 300. For the ARIMA model, the specific configuration used was ARIMA(0,1,0). The dataset was split into training and testing sets, with the training set covering the period from February 19 to March 24, 2020, and the testing set from March 25 to March 30, 2020. The goodness of fit for the models was assessed using various plots, including residuals versus observation order, Normal Q-Q plot, histogram, Autocorrelation Function (ACF), and Partial Autocorrelation Function (PACF). Residuals were also tested for stationarity using the Box-Ljung test.\n\nThe model files and optimization parameters are not explicitly provided in the publication, as the focus was on presenting the methodology and results rather than sharing the raw model files. However, the detailed steps and configurations provided should allow for replication of the models by other researchers.\n\nThe publication is licensed under a Creative Commons Attribution-NonCommercial 4.0 International license, which permits non-commercial use of the work, provided the original work is properly cited. This license ensures that the methodology and findings can be accessed and utilized by the research community for further studies and applications.",
  "model/interpretability": "The models used in this study, namely the Artificial Neural Network (ANN) and the Auto-Regressive Integrated Moving Average (ARIMA), exhibit different levels of interpretability.\n\nThe ANN model is generally considered a black-box model. This means that while it can provide accurate predictions, the internal workings and the specific reasons behind its predictions are not easily interpretable. The ANN consists of multiple layers of neurons, and the relationships between the input data and the output predictions are encoded in the weights and biases of these neurons. These relationships are not straightforward to decipher, making it difficult to understand the exact factors contributing to the model's forecasts.\n\nOn the other hand, the ARIMA model is more transparent. ARIMA models are based on statistical methods that are well-understood and can be interpreted more easily. The model parameters (p, d, q) represent the order of the autoregressive part, the degree of differencing, and the order of the moving average part, respectively. These parameters provide insights into the temporal dependencies and patterns in the data. For instance, the autoregressive part captures the relationship between an observation and a number of lagged observations, while the moving average part captures the relationship between an observation and a residual error from a moving average model applied to lagged observations. The differencing part helps in making the time series stationary, which is crucial for accurate forecasting.\n\nIn summary, while the ANN model excels in capturing complex nonlinear relationships, it lacks interpretability. The ARIMA model, although potentially less flexible in capturing highly nonlinear patterns, offers more transparency and interpretability, making it easier to understand the underlying mechanisms driving the forecasts.",
  "model/output": "The models used in this study are both regression models. Specifically, the Auto-Regressive Integrated Moving Average (ARIMA) and Artificial Neural Networks (ANN) were employed to forecast the number of newly infected patients with COVID-19. These models are designed to predict continuous values over time, making them suitable for time-series data analysis. The ANN, in particular, is known for its ability to model nonlinear associations, which is crucial for capturing the complex patterns in the spread of infectious diseases. The output of these models provides point estimates and confidence intervals for the predicted number of daily new cases, helping to understand the trend and make informed decisions. The performance of these models was evaluated using criteria such as Mean Squared Error (MSE) and Mean Absolute Error (MAE), which are common metrics for assessing the accuracy of regression models.",
  "model/duration": "The execution time for the models used in this study is not explicitly detailed. However, the Artificial Neural Network (ANN) was trained with three hidden layers, each containing 10 neurons, and the number of repetitions for this algorithm was set to 300. This setup indicates a computationally intensive process, but the exact duration is not specified. The ARIMA model, on the other hand, involves steps like differencing and Box-Cox transformation, which also require significant computational effort. The data analysis was conducted using the 'forecast' and 'nnfor' packages from R software, but the specific execution times for these processes are not provided.",
  "model/availability": "The source code for the models used in this study is not publicly released. However, the data analysis was conducted using the 'forecast' and 'nnfor' packages from R software. These packages are publicly available and can be accessed through the Comprehensive R Archive Network (CRAN). The 'forecast' package is used for time series forecasting, while the 'nnfor' package is specifically designed for neural network forecasting. Both packages are open-source and can be installed and used by anyone with access to R.\n\nThe models themselves, specifically the Artificial Neural Network (ANN) and Auto-Regressive Integrated Moving Average (ARIMA), are implemented using these R packages. The ANN was trained with three hidden layers, each containing 10 neurons, and the number of repetitions for this algorithm was set to 300. The ARIMA model used was ARIMA(0,1,0).\n\nFor those interested in replicating the analysis or using similar models, the R packages mentioned can be utilized. The 'forecast' package can be installed using the command `install.packages(\"forecast\")`, and the 'nnfor' package can be installed using `install.packages(\"nnfor\")`. Detailed documentation and examples are available on the CRAN website for both packages.",
  "evaluation/method": "The evaluation of the forecasting models involved a comprehensive assessment of their performance using several statistical methods and visual inspections. The dataset was divided into two parts: a training set spanning from February 19th to March 24th, 2020, and a test set from March 25th to March 30th, 2020. This split allowed for the models to be trained on historical data and then evaluated on a separate, more recent dataset to assess their predictive accuracy.\n\nTwo primary models were used for forecasting: the Auto-Regressive Integrated Moving Average (ARIMA) and the Artificial Neural Network (ANN). The goodness of fit for these models was evaluated through various residual assessments. Residuals versus observation order plots were examined to ensure that no patterns or trends were present, indicating that the residuals were randomly scattered around zero. This randomness is a key indicator of a good model fit.\n\nNormal Probability Plots (NPP) and histograms of the residuals were also inspected to check for normality. The Shapiro-Wilk test was used to analytically confirm the normality of the residuals, with p-values of 0.59 for ARIMA and 0.23 for ANN, both indicating that the residuals were normally distributed. Additionally, Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots were analyzed to ensure that there was no remaining autocorrelation in the residuals, further validating the models' performance.\n\nThe Box-Ljung test was employed to confirm the stationarity of the residuals, with p-values of 0.32 for ARIMA and 0.10 for ANN, both above the significance level of 0.05, thus affirming the stationarity of the residuals. The models were compared using Mean Squared Error (MSE) and Mean Absolute Error (MAE) criteria. These metrics provided a quantitative measure of the models' accuracy, with lower values indicating better performance.\n\nOverall, the evaluation method involved a rigorous combination of visual inspections and statistical tests to ensure the robustness and accuracy of the forecasting models. The results demonstrated that both ARIMA and ANN models were effective in predicting the number of new COVID-19 cases, with ARIMA showing slightly better performance in terms of accuracy.",
  "evaluation/measure": "In our study, we employed two primary performance metrics to evaluate and compare the forecasting models: Mean Squared Error (MSE) and Mean Absolute Error (MAE). These metrics are widely used in the literature for assessing the accuracy of time series forecasting models.\n\nMSE measures the average of the squares of the errors\u2014that is, the average squared difference between the estimated values and the actual value. It gives more weight to larger errors, making it sensitive to outliers. The formula used for MSE is:\n\n$$MSE = \\frac{1}{6} \\sum_{t=1}^{6} (y_t - \\hat{y}_t)^2$$\n\nMAE, on the other hand, measures the average of the absolute errors between the predicted and actual values. It provides a linear score that represents average magnitude of the errors in a set of predictions, without considering their direction. The formula used for MAE is:\n\n$$MAE(\\%) = \\frac{1}{6} \\sum_{t=1}^{6} \\frac{|y_t - \\hat{y}_t|}{y_t} \\times 100$$\n\nThese metrics were calculated for both the ARIMA and Artificial Neural Network (ANN) models using a test set that included data from March 25th to March 30th. The choice of these metrics ensures a comprehensive evaluation of the models' performance, as they capture different aspects of the prediction errors. MSE is particularly useful for penalizing larger errors, while MAE provides a straightforward measure of the average error magnitude. Together, they offer a robust assessment of the models' forecasting accuracy.",
  "evaluation/comparison": "In our study, we compared two popular time series forecasting models, ARIMA and ANN, to predict the number of new COVID-19 cases in Iran. We split the observed dataset into a training set, from February 19th to March 24th, 2020, and a test set, from March 25th to March 31st, 2020. This split allowed us to train our models on historical data and evaluate their performance on unseen data.\n\nFor the comparison, we used two common error metrics: Mean Squared Error (MSE) and Mean Absolute Error (MAE). These metrics provided a quantitative measure of the models' predictive accuracy. The MSE and MAE for both models were calculated based on the test set, allowing us to assess how well each model generalized to new data.\n\nThe ARIMA model, specifically the ARIMA(0,1,0) configuration, and the ANN model, with three hidden layers each containing 10 neurons, were both trained and evaluated. The ANN model was trained with 300 repetitions to ensure stability and convergence. We also applied Box-Cox transformation when necessary to achieve normally distributed observations.\n\nTo further validate the models, we assessed the goodness of fit through various residual plots, including residuals versus observation order, Normal Q-Q plot, histogram, Autocorrelation Function (ACF), and Partial Autocorrelation Function (PACF). The residuals were tested for stationarity using the Box-Ljung test. These analyses helped us ensure that the models' residuals were randomly distributed and did not exhibit any patterns, indicating a good fit.\n\nIn terms of simpler baselines, we did not explicitly compare our models to simpler forecasting methods, such as naive forecasts or moving averages. However, the comparison between ARIMA and ANN provided insights into the performance of more complex models. The ARIMA model was found to have lower MSE and MAE, indicating more precise and realistic predictions compared to the ANN model. This finding is consistent with other studies that have highlighted the effectiveness of ARIMA in predicting the incidence of infectious diseases.\n\nIn summary, our methods comparison focused on evaluating the performance of ARIMA and ANN models using standard error metrics and residual analyses. The ARIMA model demonstrated superior predictive accuracy, making it a more reliable tool for forecasting the number of new COVID-19 cases in Iran.",
  "evaluation/confidence": "The evaluation of our models, specifically the Artificial Neural Network (ANN) and Auto Regressive Integrated Moving Average (ARIMA), was conducted using several performance metrics, including Mean Squared Error (MSE) and Mean Absolute Error (MAE). These metrics were calculated over a test set that spanned from March 25th to March 30th, 2020.\n\nThe MSE and MAE values provide a quantitative measure of the models' predictive accuracy. For the ANN, the MSE was 557,422 and the MAE was 24.85%. For the ARIMA model, the MSE was significantly higher at 2,369,871, and the MAE was 52.51%. These values indicate that the ANN model had better predictive performance compared to the ARIMA model.\n\nTo assess the statistical significance of our results, we performed several diagnostic checks on the residuals of both models. The residuals versus observation order plots showed no discernible patterns, suggesting that the models captured the underlying data structure well. Additionally, the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots did not reveal any significant spikes, indicating that there was no remaining autocorrelation in the residuals.\n\nThe Shapiro-Wilk test confirmed the normality of the residuals for both models, with p-values of 0.59 for ARIMA and 0.23 for ANN. This suggests that the residuals are normally distributed, which is a key assumption for many statistical tests. Furthermore, the Normal Probability Plot (NPP) and histogram of the residuals did not show any substantial deviations from normality.\n\nThe Box-Ljung test was used to check the stationarity of the residuals. The p-values for this test were 0.32 for ARIMA and 0.10 for ANN, indicating that the residuals are stationary. This is crucial for ensuring that the models' predictions are reliable over time.\n\nOverall, the diagnostic checks and performance metrics provide strong evidence that our models, particularly the ANN, are robust and statistically significant. The ANN model's lower MSE and MAE, along with the satisfactory residual diagnostics, suggest that it is a superior method for forecasting the number of newly infected patients. However, while the ANN model shows better performance, the differences between ANN and ARIMA predictions are minimal and can be considered negligible.",
  "evaluation/availability": "Not enough information is available."
}