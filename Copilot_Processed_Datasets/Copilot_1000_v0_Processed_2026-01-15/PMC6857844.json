{
  "publication/title": "Deep Learning Analysis of Cerebral Blood Flow to Identify Cognitive Impairment and Frailty in Persons Living With HIV",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "J Acquir Immune Defic Syndr.",
  "publication/year": "2019",
  "publication/pmid": "31714429",
  "publication/pmcid": "PMC6857844",
  "publication/doi": "10.1097/QAI.0000000000002181",
  "publication/tags": "- Deep Learning\n- Cerebral Blood Flow\n- Cognitive Impairment\n- Frailty\n- HIV\n- Neuroimaging\n- Machine Learning\n- Predictive Modeling\n- Brain Regions\n- Neurocognitive Disorders\n- Antiretroviral Therapy\n- Neural Networks\n- Feature Extraction\n- Subcortical Regions\n- Cortical Regions",
  "dataset/provenance": "The dataset used in this study was sourced from ongoing studies conducted by the Infectious Disease clinic at Washington University in Saint Louis. The participants were individuals living with HIV who were virologically suppressed, meaning they had an undetectable viral load (<50 copies/ml) and were on stable combination antiretroviral therapy (cART) for at least 6 months. The cohort consisted of 125 participants, with an average age of 51.4 years and an average of 13.7 years of education. Participants underwent neuropsychological testing and structural neuroimaging. The neuropsychological tests targeted three neurocognitive domains frequently affected by HIV: learning, memory, and executive function. The data used in this study has not been previously published or used by the community in the same context. The dataset is unique to this study, focusing on the application of deep learning algorithms to classify cognitive impairment and frailty in people living with HIV using cerebral blood flow (CBF) measurements.",
  "dataset/splits": "The dataset was split using a 5-fold Monte Carlo cross-validation approach. This means that the data was randomly partitioned into five different splits. In each iteration, 80% of the data was reserved for training the model, while the remaining 20% was used for testing. The results reported are the average accuracy across these five validations. This method ensures that the model's performance is evaluated on data independent of the training set, helping to prevent overfitting due to the small sample size. The distribution of data points in each split was not explicitly detailed, but the cross-validation process ensures that each fold contains a representative sample of the entire dataset.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is deep learning, specifically feed-forward deep neural networks (DNNs). These networks map inputs to outputs through multiple layers of functions, with each layer providing another level of abstraction for feature identification and learning.\n\nThe algorithm is not entirely new, as deep learning has been extensively used in various fields, including neuroimaging. However, our application of deep learning in conjunction with cerebral blood flow (CBF) to classify cognitive impairment and frailty in people living with HIV (PLWH) is novel. This specific use case has not been widely explored in previous studies, making our approach unique in this context.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of our study is on its application in neuroimaging and its potential to inform clinical decisions for PLWH. The primary contributions of our work lie in the domain of medical research and clinical applications, rather than the development of new machine-learning techniques. Our study aims to demonstrate the feasibility and effectiveness of using deep learning with CBF data to classify cognitive impairment and frailty, thereby contributing to the field of medical diagnostics and personalized treatment.",
  "optimization/meta": "The models utilized in this study are not meta-predictors. They do not use data from other machine-learning algorithms as input. Instead, they are deep neural networks (DNNs) that directly process neuroimaging data to make predictions.\n\nThe DNNs were trained and validated using a 5-fold Monte Carlo cross-validation approach. This method ensures that the training data is independent of the testing data. In each iteration, the data was randomly partitioned into training and testing sets, with 80% reserved for training and 20% used for testing. This process was repeated five times, and the results reported are the average accuracy across these five validations.\n\nThe DNNs contained three hidden layers with ten neurons each, and they used a sigmoid transfer function for activation. The models were trained using scaled conjugate gradient backpropagation, and training was terminated at either 200 iterations or 10 successive validations. This approach ensures that the models are robust and not overfitting due to small sample size.",
  "optimization/encoding": "A total of 82 brain regions were generated using FreeSurfer based on each participant's T1 image. These regions were chosen because they have been previously shown to be affected by HIV. Visual inspection of the automated segmentation results was performed for quality assurance purposes, and corrections were made when necessary. Cerebral blood flow (CBF) measurements were obtained from each of these 82 FreeSurfer-defined regions. CBF values from these 82 regions were then grouped into 12 cortical and subcortical regions, including the cerebellum, thalamus, caudate, putamen, pallidum, hippocampus, amygdala, frontal, parietal, temporal, cingulate, and occipital lobes. Within each group, CBF values were averaged to derive a mean CBF value for each region of interest. Each brain region was normalized to mean 0 and standard deviation 1 and rescaled to a [1, \u22121] interval.\n\nThe data was pre-processed by registering each participant\u2019s mean CBF to a common atlas through a series of three linear registrations. First, the mean control volumes were registered to the corresponding T2 images. Second, T2 images were registered to the T1 image. Third, T1 images were registered to a common atlas. T1 and T2 images were used only for registration and segmentation purposes. The feasibility of the deep neural network (DNN) models used is based on the Universal Approximation Theorem, which states that a neural network with a single hidden layer contains a finite set of neurons that can approximate continuous functions on compact subsets of Rn. The DNN contained three hidden layers with 10 neurons each. Every neuron utilized a sigmoid transfer function for activation, which is a smooth differentiable function and mathematically equivalent to a hyperbolic tangent. The models were trained using scaled conjugate gradient backpropagation. Training was terminated at either 200 iterations or 10 successive validations. All analyses were performed in MATLAB R2018a. Models were evaluated using accuracy and the area under the curve. Each DNN was validated using 5-fold Monte Carlo cross-validation. Cross-validation was used to estimate how well a model fit data independent of the information used to train the model, as well as to ensure the model was not overfitting due to small sample size. On each iteration, data were randomly partitioned into training and testing data, with 80% reserved for training and 20% used for testing. The results reported were the average accuracy across the five validations.",
  "optimization/parameters": "In our study, the deep neural network (DNN) model utilized ten input parameters. These parameters were derived from cerebral blood flow (CBF) measurements obtained from specific brain regions. The selection of these parameters was informed by previous research indicating that these regions are affected by HIV. The brain regions included in the analysis were grouped into 12 cortical and subcortical regions: cerebellum, thalamus, caudate, putamen, pallidum, hippocampus, amygdala, frontal, parietal, temporal, cingulate, and occipital lobes. Within each group, CBF values were averaged to derive a mean CBF value for each region of interest. This approach ensured that the input parameters were relevant and significant for the classification tasks undertaken in the study.",
  "optimization/features": "In our study, we utilized cerebral blood flow (CBF) measurements from 82 brain regions as input features. These regions were initially defined using FreeSurfer and then grouped into 12 cortical and subcortical regions, including the cerebellum, thalamus, caudate, putamen, pallidum, hippocampus, amygdala, frontal, parietal, temporal, cingulate, and occipital lobes. Within each group, CBF values were averaged to derive a mean CBF value for each region of interest.\n\nFeature selection was performed using the Relief algorithm, which ranks features based on their ability to distinguish between proximal comparisons. This algorithm was applied to identify the strongest predictors of the given outcomes, such as cognitive impairment and frailty. The feature selection process was conducted using the training set only, ensuring that the model's performance on the test set was not influenced by information from the test data. This approach helped in identifying the most relevant brain regions that contributed significantly to the classification tasks.",
  "optimization/fitting": "The deep learning analysis employed feed-forward deep neural network models (DNNs) with three hidden layers, each containing 10 neurons. The number of input features, derived from cerebral blood flow (CBF) measurements across 82 brain regions, was significantly larger than the number of training points. To mitigate overfitting, several strategies were implemented.\n\nFirstly, the models were trained using scaled conjugate gradient backpropagation, which is an efficient optimization algorithm for neural networks. Training was terminated either after 200 iterations or upon achieving 10 successive validations without improvement, ensuring that the model did not overfit to the training data.\n\nSecondly, 5-fold Monte Carlo cross-validation was used to evaluate the models. This technique involved randomly partitioning the data into training and testing sets, with 80% of the data reserved for training and 20% for testing. This process was repeated five times, and the reported accuracy was the average across these validations. Cross-validation helped to ensure that the model generalized well to independent data and was not overfitting due to the small sample size.\n\nAdditionally, the Relief algorithm was used to rank features according to their importance, identifying the strongest predictors of the outcomes. This feature selection method helped to reduce the dimensionality of the input data, focusing on the most relevant features and further mitigating the risk of overfitting.\n\nTo address underfitting, the architecture of the DNNs was designed with three hidden layers, providing sufficient complexity to capture the underlying patterns in the data. The use of a sigmoid transfer function for activation in each neuron allowed the model to learn non-linear relationships. The high accuracy achieved in classifying cognitive impairment and frailty status, as well as the comparison with other machine learning algorithms, indicated that the models were not underfitting the data.",
  "optimization/regularization": "To prevent overfitting in our deep learning models, we employed several techniques. Firstly, we utilized 5-fold Monte Carlo cross-validation. This method involves randomly partitioning the data into training and testing sets multiple times, with 80% of the data reserved for training and 20% for testing. By averaging the accuracy across these five validations, we ensured that our model's performance was robust and not merely a result of overfitting to a specific subset of the data.\n\nAdditionally, we terminated the training process either after a maximum of 200 iterations or when there were 10 successive validations without improvement. This early stopping criterion helped to prevent the model from becoming too complex and overfitting the training data.\n\nThe architecture of our deep neural network (DNN) also played a role in regularization. Our DNN contained three hidden layers, each with 10 neurons, which is a relatively simple architecture. This simplicity helps to reduce the risk of overfitting by limiting the model's capacity to learn noise in the training data.\n\nFurthermore, the use of a sigmoid transfer function for activation in each neuron provided a smooth, differentiable function, which can help in stabilizing the training process and preventing overfitting.\n\nLastly, the Relief algorithm was used for feature selection, which helps in identifying the most relevant features and discarding the irrelevant ones. This not only improves the model's performance but also acts as a form of regularization by reducing the dimensionality of the input data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported within the publication. Specifically, our deep neural network (DNN) models contained 3 hidden layers with 10 neurons each, and every neuron utilized a sigmoid transfer function for activation. The models were trained using scaled conjugate gradient backpropagation, with training terminated at either 200 iterations or 10 successive validations. All analyses were performed in MATLAB R2018a.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the methods and configurations described are detailed enough for replication. The study does not mention the availability of model files or optimization parameters in a public repository or under a specific license. Therefore, while the configurations and schedule are reported, the actual model files and parameters are not directly accessible.",
  "model/interpretability": "The models employed in our study are not entirely black-box systems. To enhance interpretability, we utilized the Relief algorithm to rank features according to their importance. This algorithm detects conditional dependencies between attributes using a nearest neighbor approach, ranking features by estimating how well their values distinguish between proximal comparisons. This process helps in identifying the strongest predictors of a given outcome, making the model more transparent.\n\nIn our analysis, separate deep neural network (DNN) models were trained to discriminate between cognitively impaired and unimpaired individuals, both overall and by specific domains such as learning, memory, and executive function. Additionally, a single DNN was trained to classify participants as frail, pre-frail, or not frail. The Relief algorithm was instrumental in identifying the key brain regions whose cerebral blood flow (CBF) values were the strongest predictors for these classifications.\n\nFor instance, in classifying cognitive impairment in the learning domain, the algorithm achieved 85% accuracy, with the best predictors being CBF in regions such as the amygdala, cingulate, hippocampus, frontal lobe, and parietal lobe. Similarly, in the memory domain, the algorithm achieved 86% accuracy, with predictive regions including the amygdala, temporal lobe, parietal lobe, caudate, and hippocampus. These specific brain regions and their ranked importance provide clear insights into which areas are most critical for the model's predictions.\n\nIn the context of frailty, the DNN distinguished between frail, pre-frail, and non-frail individuals with 75% accuracy. The strongest predictors of frailty were identified as CBF in subcortical regions, including the thalamus, pallidum, cerebellum, caudate, amygdala, and hippocampus. This information not only aids in understanding the model's decision-making process but also highlights the biological significance of these brain regions in the context of frailty and cognitive impairment.\n\nBy using the Relief algorithm, we were able to extract meaningful patterns and relationships from the data, making the model's predictions more interpretable and clinically relevant. This approach ensures that the model is not a black-box but rather a tool that provides actionable insights into the underlying mechanisms of cognitive impairment and frailty in individuals with HIV.",
  "model/output": "The model employed in our study is a classification model. Specifically, we utilized deep neural networks (DNNs) to classify individuals based on their cognitive impairment status and frailty levels. The DNNs were trained to distinguish between cognitively impaired and unimpaired individuals across various cognitive domains, including learning, memory, and executive function. Additionally, a separate DNN was trained to classify participants as frail, pre-frail, or not frail. The output of these models provides categorical predictions rather than continuous values, which aligns with the nature of classification tasks.\n\nThe performance of these classification models was evaluated using metrics such as accuracy, area under the curve (AUC), true positive rate (TPR), and true negative rate (TNR). For instance, the DNN achieved an average accuracy of 82% in identifying individuals with neurocognitive impairment, with an AUC of 0.81. Similarly, the model demonstrated high accuracy in classifying cognitive impairment within specific domains, such as 85% accuracy for the learning domain and 86% accuracy for both the memory and executive domains. In the context of frailty, the DNN distinguished between frail, pre-frail, and non-frail individuals with 75% accuracy.\n\nThe use of classification models in this study allowed us to effectively categorize participants based on their cognitive and frailty statuses, providing valuable insights into the predictive power of cerebral blood flow (CBF) measurements in these areas. The models' high accuracy and reliability underscore their potential for clinical applications in managing and caring for individuals with HIV.",
  "model/duration": "The execution time for the model was not explicitly detailed in the publication. However, it is mentioned that training was terminated at either 200 iterations or 10 successive validations. This suggests that the model's training process could take a variable amount of time depending on these conditions. Additionally, the models were evaluated using 5-fold Monte Carlo cross-validation, which involves multiple iterations of training and testing. Each iteration reserved 80% of the data for training and 20% for testing. The average accuracy across these five validations was reported, indicating a robust evaluation process. The specific hardware and software environment used for running the models, such as the computational resources and software versions, were also not detailed, which could further influence the execution time.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the deep neural network (DNN) models involved a rigorous process to ensure their accuracy and generalizability. The models were assessed using 5-fold Monte Carlo cross-validation. This method involved randomly partitioning the data into training and testing sets, with 80% of the data reserved for training and 20% used for testing. This process was repeated five times, and the results reported were the average accuracy across these five validations. Cross-validation was crucial for estimating how well the models fit data independent of the information used to train them, as well as for ensuring that the models were not overfitting due to the small sample size. The models were evaluated based on accuracy and the area under the curve (AUC), providing a comprehensive assessment of their performance.",
  "evaluation/measure": "In our evaluation of the deep neural network (DNN) models, we focused on several key performance metrics to ensure a comprehensive assessment of their effectiveness. The primary metrics reported include accuracy and the area under the curve (AUC). Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It provides a straightforward indication of how often the model's predictions are correct.\n\nThe AUC, on the other hand, evaluates the model's ability to distinguish between classes by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. A higher AUC indicates better model performance, with a value of 1 representing a perfect model and 0.5 indicating a model with no discriminative ability.\n\nIn addition to these metrics, we also report the true positive rate (TPR) and true negative rate (TNR). The TPR, also known as sensitivity or recall, measures the proportion of actual positives that are correctly identified by the model. The TNR, or specificity, measures the proportion of actual negatives that are correctly identified. These metrics provide a more detailed view of the model's performance, especially in imbalanced datasets.\n\nThe reported metrics are representative of common practices in the literature, ensuring that our evaluation is both rigorous and comparable to other studies in the field. By focusing on accuracy, AUC, TPR, and TNR, we provide a well-rounded assessment of our models' performance in classifying cognitive impairment and frailty in individuals.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of our deep neural network (DNN) models with several commonly used machine learning algorithms. This comparison was not performed on publicly available benchmark datasets but rather on our own dataset, which included participants categorized by cognitive impairment and frailty status.\n\nThe algorithms we compared against included decision trees, linear discriminant analysis (LDA), logistic regression, na\u00efve Bayes, support vector machines (SVM), and K-nearest neighbors (KNN). These methods were chosen because they represent a range of traditional machine learning techniques that are widely used in similar classification tasks.\n\nFor each cognitive domain\u2014learning, memory, executive function, and overall cognitive impairment\u2014our DNN models consistently outperformed the other algorithms. Specifically, the DNN achieved the highest accuracy in classifying cognitive impairment across all domains. For example, in the learning domain, the DNN reached 85% accuracy, while the next best method, SVM and KNN, achieved 82%. Similarly, in the memory domain, the DNN achieved 86% accuracy, compared to 82% for SVM and KNN. This trend held true for the executive domain as well, where the DNN achieved 86% accuracy, surpassing all other methods.\n\nIn addition to cognitive impairment, we also evaluated the performance of our DNN in classifying frailty status. The DNN distinguished between frail, pre-frail, and non-frail individuals with 75% accuracy, which was higher than any of the other algorithms tested. This comparison underscores the superior performance of our DNN models in both cognitive impairment and frailty classification tasks.\n\nThe results of these comparisons are summarized in a table, which provides a clear overview of the accuracy achieved by each method across different cognitive domains and frailty status. This detailed evaluation demonstrates the robustness and effectiveness of our DNN models in handling complex classification tasks related to cognitive impairment and frailty in individuals with HIV.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not enough information is available."
}