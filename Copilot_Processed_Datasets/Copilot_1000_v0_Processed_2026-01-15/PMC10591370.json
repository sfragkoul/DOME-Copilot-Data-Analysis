{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to the article are Yi Dong and Yibiao Zhou. Their respective contributions to the paper are not specified.",
  "publication/journal": "Parasites & Vectors",
  "publication/year": "2023",
  "publication/pmid": "37872579",
  "publication/pmcid": "PMC10591370",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Parasites\n- Vectors\n- Snails\n- Ecological niche modeling\n- Machine learning\n- Climate factors\n- Socioeconomic factors\n- Geographical factors\n- Distribution modeling\n- Schistosomiasis\n- Random forest\n- Predictive modeling\n- Environmental variables\n- Habitat suitability\n- Yunnan Province",
  "dataset/provenance": "The dataset used in this study was sourced from various public datasets and reputable institutions. Climate-related variables, such as average annual precipitation, average annual temperature, and others, were obtained from the Chinese Academy of Sciences, Resource and Environmental Sciences and Data Center. Additionally, bioclimatic variables were downloaded from the WorldClim website, which provides data with a spatial resolution of 1 km \u00d7 1 km. These variables were calculated based on monthly temperature and precipitation values from 1970 to 2000.\n\nGeographical factors, including slope, elevation, normalized difference vegetation index, and distance to waterways, were depicted and labeled using specific \"waterway\" tags in OpenStreetMap. Socioeconomic factors, such as human footprint, night light index, population density, and gross domestic product, were sourced from the Chinese Academy of Sciences, Resources and Environmental Sciences Data Center, Socioeconomic Data and Applications Center, and the WorldPop website.\n\nThe study included 184 presence records of O. hupensis, which were obtained from a survey conducted by the Yunnan Institute of Endemic Disease Control and Prevention in 2016. These records were filtered to avoid spatial autocorrelation, ensuring that only one record per grid (resolution of 1 km \u00d7 1 km) was retained. Absence sites were generated in the study area at a ratio of 1:2 for model construction.\n\nThe dataset utilized in this study is comprehensive, incorporating a wide range of environmental and socioeconomic variables that influence the distribution of O. hupensis. The data points were carefully selected and filtered to ensure accuracy and reliability in the ecological niche modeling process. This approach aligns with previous studies and community practices in the field, ensuring that the findings are robust and applicable.",
  "dataset/splits": "The dataset was divided into two main splits: training and testing. The original datasets were randomly split, with 70% of the data allocated for training the models and the remaining 30% reserved for testing the models' accuracy. This split ensures that the models are trained on a substantial portion of the data while leaving enough data for evaluating their performance. The training set is used to construct the models, while the testing set is used to assess the models' predictive accuracy.",
  "dataset/redundancy": "The datasets used in this study were split into training and testing sets to evaluate the performance of the models. The original datasets were randomly divided into two parts, with 70% allocated for training and the remaining 30% reserved for testing. This split ensures that the training and testing sets are independent, which is crucial for obtaining unbiased performance metrics.\n\nTo enforce independence between the training and testing sets, a random division was employed. This method helps to mitigate the risk of data leakage, where information from the testing set might inadvertently influence the training process. By using a random split, each data point has an equal chance of being included in either the training or testing set, promoting a fair evaluation of the models.\n\nThe distribution of the datasets in this study is comparable to previously published machine learning datasets in ecological niche modeling. The use of a 70-30 split is a common practice in the field, balancing the need for sufficient training data to build robust models while reserving enough data for reliable testing and validation. This approach aligns with standard procedures in machine learning to ensure that models are generalizable and not overfitted to the training data.",
  "dataset/availability": "The datasets utilized in this study were obtained from various public sources, ensuring their availability for further research and validation. Climate-related variables, such as average annual precipitation and temperature, were sourced from the Chinese Academy of Sciences, Resource and Environmental Sciences and Data Center. These datasets are accessible via their official website, adhering to the licensing terms specified by the data center.\n\nAdditionally, bioclimatic variables were downloaded from the WorldClim website, which provides a comprehensive repository of global climate data. The data is available under a Creative Commons Attribution 4.0 International (CC BY 4.0) license, allowing for widespread use and distribution with proper attribution.\n\nGeographical factors, including slope, elevation, and distance to waterways, were derived from OpenStreetMap, a collaborative project that offers open access to geographical data. The socioeconomic factors, such as human footprint and night light index, were obtained from the Socioeconomic Data and Applications Center and the WorldPop website, both of which provide open access to their datasets under specific licensing agreements.\n\nTo ensure consistency and reproducibility, all environmental data were resampled to a uniform spatial resolution of 1 km \u00d7 1 km and cropped to the Yunnan Province region using ArcGIS 10.4. This standardization process was enforced to maintain the integrity of the data and facilitate accurate modeling and analysis.\n\nThe original datasets were randomly divided into training and testing samples, with 70% used for model construction and 30% reserved for evaluating model accuracy. This split was enforced to ensure that the models were trained on a representative subset of the data while maintaining an independent dataset for unbiased performance evaluation.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to the ensemble learning and traditional machine learning classes. Specifically, the algorithms employed include eXtreme Gradient Boosting (XGB), support vector machine (SVM), random forest (RF), generalized boosted model (GBM), neural network (NN), classification and regression trees (CART), k-nearest neighbors (KNN), and generalized additive model (GAM).\n\nThese algorithms are not new; they are well-established and widely used in the field of machine learning. The choice of these algorithms was driven by their proven effectiveness in handling multidimensional data and their applicability to ecological niche modeling. The study focused on predicting the suitable distribution of snails, and these algorithms were selected for their ability to manage complex datasets and provide robust predictive performance.\n\nThe algorithms were implemented using the Caret package, which is a popular tool in R for training and plotting models. The use of these algorithms in an ecological context is not uncommon, as they have been extensively applied in various environmental and biological studies. The decision to use these specific algorithms was based on their demonstrated success in similar research and their suitability for the data at hand.",
  "optimization/meta": "The models utilized in this study do not function as meta-predictors. Instead, eight distinct machine learning algorithms were independently employed to predict the suitable distribution of snails. These algorithms include eXtreme Gradient Boosting (XGB), support vector machine (SVM), random forest (RF), generalized boosted model (GBM), neural network (NN), classification and regression trees (CART), k-nearest neighbors (KNN), and generalized additive model (GAM).\n\nEach of these models was trained and tested using the same dataset, which was randomly divided into training and testing samples. The training samples constituted 70% of the original datasets, while the testing samples made up the remaining 30%. This division ensured that the training data was independent for each model, allowing for an unbiased evaluation of their predictive performance.\n\nThe optimal hyperparameters for each model were determined using the grid search method and 10-fold cross-validation. This process helped in fine-tuning the models to achieve the best possible predictive accuracy. The performance of each model was then evaluated using common metrics such as the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and kappa. The random forest (RF) model exhibited the best prediction performance among the eight models, followed by the generalized boosted model (GBM).",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps to ensure the models could effectively predict the suitable distribution of snails. Initially, the datasets were randomly divided into two parts: 70% for training the models and 30% for testing their accuracy. This split allowed for robust model evaluation and validation.\n\nTo avoid multicollinearity, a correlation analysis was conducted using R 4.2.1. Variables with absolute values of correlation coefficients greater than or equal to 0.85 were considered highly correlated. For datasets of the same type, such as climatic, geographical, or socioeconomic factors, variables that were related to most other variables and had more biological significance were retained. This process helped in selecting the most predictive variables for model construction.\n\nThe final set of variables included 16 predictors: 10 climatic variables (such as mean diurnal temperature range, temperature seasonality, and precipitation seasonality), three geographical variables (slope, normalized difference vegetation index, and distance to waterways), and three socioeconomic variables (human footprint, population density, and night light index).\n\nThe data was resampled to a consistent spatial resolution of 1 km \u00d7 1 km and cropped to the Yunnan Province region using ArcGIS 10.4. This standardization ensured that all environmental data were in a comparable format, facilitating accurate model training and prediction.\n\nThe optimal hyperparameters for each model were determined using the grid search method and 10-fold cross-validation. This approach helped in fine-tuning the models to achieve the best predictive performance. For example, the mtry parameter in the random forest model was optimized to control the behavior of the learning algorithm.\n\nIn summary, the data encoding and preprocessing involved careful selection of variables, standardization of spatial resolution, and optimization of hyperparameters to enhance the predictive accuracy of the machine-learning models.",
  "optimization/parameters": "In our study, we employed a total of 16 variables for model development. These variables were carefully selected to ensure they provided the most predictive power while avoiding multicollinearity.\n\nTo determine the optimal set of variables, we conducted a correlation analysis. Variables with absolute values of correlation coefficients greater than or equal to 0.85 were considered highly correlated. For datasets of the same type, such as climatic, geographical, or socioeconomic factors, we retained the variable that was related to the most other variables and had the greatest biological significance. This approach helped us to select the most predictive variables for our model.\n\nFor climatic factors, we initially considered 25 variables, but after the correlation analysis, we retained 10 variables: Bio2, Bio4, Bio7, Bio9, Bio14, Bio15, Bio19, AR, AAP, and IM. These variables represent various aspects of temperature and precipitation, which are crucial for the distribution of the species we studied.\n\nFor geographical factors, we included slope, NDVI, and DST. These variables provide information about the topography, vegetation, and proximity to water bodies, which are important for the habitat suitability of the species.\n\nFor socioeconomic factors, we included HFP, DP, and NLI. These variables account for human activity, population density, and nighttime lights, which can influence the distribution of the species.\n\nBy carefully selecting these 16 variables, we ensured that our model had a robust set of predictors that minimized multicollinearity and maximized predictive power.",
  "optimization/features": "In the optimization process of our models, we employed a total of 16 variables as input features. These features were carefully selected to ensure they provided the most predictive power for our models.\n\nFeature selection was indeed performed to avoid multicollinearity and to retain the most biologically significant variables. This process involved conducting a correlation analysis, where variables with absolute values of correlation coefficients greater than or equal to 0.85 were considered highly correlated. For datasets of the same type of variables, such as climatic, geographical, or socioeconomic factors, we retained variables that were related to most other variables and had more biological significance. For instance, among climatic factors, Bio9 was retained due to its strong correlation with several other variables and its biological significance. Similarly, AAP was retained as a predictive variable due to its correlation with other precipitation-related variables.\n\nIt is important to note that the feature selection process was conducted using the entire dataset, not just the training set. This approach ensured that the selected features were representative of the overall data distribution and not biased towards the training data. The final set of 16 variables included 10 climatic variables, three geographical variables, and three socioeconomic variables. These variables were then used in the model development process to predict the distribution of suitable areas for the species in question.",
  "optimization/fitting": "The fitting method employed in this study utilized eight different machine learning algorithms from the Caret package to predict the suitable distribution of snails. These algorithms included eXtreme Gradient Boosting (XGB), support vector machine (SVM), random forest (RF), generalized boosted model (GBM), neural network (NN), classification and regression trees (CART), k-nearest neighbors (KNN), and generalized additive model (GAM).\n\nTo address the potential issue of overfitting, particularly relevant when the number of parameters is large relative to the number of training points, several strategies were implemented. The random forest (RF) model, which showed the best predictive performance, is an ensemble learning method that combines multiple tree-like predictors. This approach inherently helps to resist overfitting by averaging the results of many decision trees, thereby reducing the variance and improving generalization to unseen data.\n\nAdditionally, the optimal hyperparameters for each model were determined using the grid search method and 10-fold cross-validation. This technique ensures that the models are not overly complex and can generalize well to new data. The predictive power of each model was tested using a separate testing dataset, which was not used during the training phase. This validation step further helps to mitigate overfitting by evaluating the model's performance on independent data.\n\nTo rule out underfitting, the models were carefully tuned using cross-validation. The grid search method systematically worked through multiple combinations of hyperparameter values to find the best-performing model. This process ensures that the models are complex enough to capture the underlying patterns in the data without being too simplistic. The use of multiple machine learning algorithms also provided a robust comparison, ensuring that the best-performing model was selected based on its ability to accurately predict the distribution of snails.\n\nIn summary, the fitting method involved a rigorous process of hyperparameter tuning, cross-validation, and model comparison to balance the trade-off between overfitting and underfitting. The random forest model, with its ensemble learning approach, was particularly effective in achieving this balance and demonstrated the best predictive performance among the eight models evaluated.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was the random forest (RF) algorithm, which is inherently designed to resist overfitting. This ensemble learning method combines multiple decision trees, each trained on a different subset of the data, to create a more generalized and accurate model.\n\nAdditionally, we utilized 10-fold cross-validation during the hyperparameter tuning process. This technique involves dividing the training data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. Cross-validation helps to ensure that the model generalizes well to unseen data and reduces the risk of overfitting.\n\nFurthermore, we employed grid search to find the optimal hyperparameters for each model. This systematic approach involves testing a range of hyperparameter values and selecting the combination that yields the best performance on the validation set. By optimizing the hyperparameters, we improved the model's ability to generalize to new data.\n\nLastly, we evaluated the models using a separate testing dataset that was not used during the training or validation phases. This final evaluation step provided an unbiased assessment of the model's performance and helped to confirm that the models were not overfitted to the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available and reported within the publication. We utilized the grid search method combined with 10-fold cross-validation to determine the optimal hyperparameters for each of the eight machine learning algorithms employed. These algorithms included eXtreme Gradient Boosting (XGB), support vector machine (SVM), random forest (RF), generalized boosted model (GBM), neural network (NN), classification and regression trees (CART), k-nearest neighbors (KNN), and generalized additive model (GAM). The specific hyperparameters tuned for each model, such as the mtry parameter in the RF model, are detailed in the methods section of the paper.\n\nThe model files and optimization parameters are not explicitly provided as downloadable assets due to the nature of the publication format. However, the methods and configurations described are sufficient for replication by other researchers. The data used for training and testing the models, as well as the environmental variables involved, are sourced from publicly available datasets. These include climate data from the Chinese Academy of Sciences and WorldClim, geographical data from OpenStreetMap, and socioeconomic data from various public repositories.\n\nThe license under which these datasets are available varies by source. For instance, data from WorldClim is typically available under a Creative Commons Attribution 4.0 International (CC BY 4.0) license, which allows for free use with appropriate attribution. Similarly, data from the Chinese Academy of Sciences and other public repositories usually come with licenses that permit academic use and sharing, provided that the original source is cited.\n\nIn summary, while the exact model files and optimization parameters are not directly downloadable, the methods and configurations are thoroughly documented. The datasets used are publicly accessible under licenses that facilitate academic research and replication of the study.",
  "model/interpretability": "The model employed in this study is not a blackbox. It is a random forest (RF) model, which is an ensemble learning method that combines multiple decision trees. This structure allows for a certain level of interpretability. The RF model's predictions can be traced back through the individual decision trees, providing insights into how different variables influence the outcomes.\n\nOne of the key features of the RF model is the ability to measure the importance of variables. In this study, the importance of variables was assessed using the MeanDecreaseGini metric. This metric indicates the relative importance of each variable in the model, with higher values signifying greater importance. For instance, Bio15 (precipitation seasonality) was found to be the most important variable, contributing 33.6% to the model's predictive power. Other significant variables included average annual precipitation (AAP) at 25.2%, mean diurnal temperature range (Bio2) at 21.7%, and precipitation of the coldest quarter (Bio19) at 14.5%. These climatic factors, along with socioeconomic variables like population density (DP) and night light index (NLI), played crucial roles in predicting the distribution of suitable habitats for the species in question.\n\nThe transparency of the RF model is further enhanced by its ability to handle multicollinearity. Through correlation analysis, highly correlated variables were identified and managed, ensuring that the most predictive and biologically significant variables were retained. This process not only improves the model's accuracy but also makes it easier to interpret the results. For example, variables like Bio9 and AAP were retained due to their strong correlations with other relevant factors, providing a clearer picture of their impact on the species' distribution.\n\nIn summary, the RF model used in this study offers a transparent and interpretable approach to predicting the suitable distribution of snails. By measuring variable importance and managing multicollinearity, the model provides valuable insights into the factors driving the species' habitat preferences. This interpretability is essential for understanding the ecological and socioeconomic factors at play and for developing effective conservation and management strategies.",
  "model/output": "The model employed in this study is a classification model. It predicts the probability of snail presence, categorizing areas into different suitability levels based on this probability. Specifically, areas with a presence probability of less than 0.40 are considered non-suitable, 0.41\u20130.60 as low suitability, 0.61\u20130.80 as moderate suitability, and greater than 0.80 as high suitability. This classification allows for the identification of regions that are most likely to support snail populations, aiding in targeted monitoring and control efforts.\n\nThe model's output is visualized using ArcGIS 10.4, which helps in classifying and mapping these different levels of suitability across the study area. This spatial representation is crucial for understanding the distribution patterns of snails and for implementing effective management strategies. The model's performance is evaluated using metrics such as the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and kappa, ensuring that the predictions are accurate and reliable. Among the eight models tested, the random forest (RF) model demonstrated the best predictive performance, making it the optimal choice for this ecological niche modeling study.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, we employed a rigorous evaluation method to assess the performance of our ecological niche models. We utilized eight different machine learning algorithms from the Caret package, including eXtreme Gradient Boosting (XGB), support vector machine (SVM), random forest (RF), generalized boosted model (GBM), neural network (NN), classification and regression trees (CART), k-nearest neighbors (KNN), and generalized additive model (GAM). To ensure robust model evaluation, we divided the original datasets into two parts: 70% for training and 30% for testing.\n\nFor each model, we determined the optimal hyperparameters using the grid search method combined with 10-fold cross-validation. This approach helped us to fine-tune the models and enhance their predictive performance. The predictive power of each model was then tested using the testing dataset, which allowed us to select the model with the best predictive performance.\n\nWe evaluated the models using common metrics such as the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and kappa. The AUC value is a crucial indicator of model accuracy, with values closer to 1 indicating higher accuracy. Sensitivity measures the predictive accuracy for presence, while specificity measures the predictive accuracy for absence. The kappa statistic ranges from -1 to 1, with values closer to 1 indicating better agreement between predicted and actual observations.\n\nAmong the eight models, the random forest (RF) model exhibited the best prediction performance, with an AUC of 0.991, sensitivity of 0.982, specificity of 0.995, and kappa of 0.942. This model was followed by the generalized boosted model (GBM), which had an AUC of 0.983, sensitivity of 0.981, specificity of 0.991, and kappa of 0.932. The classification and regression trees (CART) model performed the worst, with an AUC of 0.884, sensitivity of 0.922, specificity of 0.943, and kappa of 0.829.\n\nGiven the superior performance of the RF model, we applied the optimized RF model to predict the distribution of suitable areas for O. hupensis under current and future climate conditions. This comprehensive evaluation method ensured that our models were robust and reliable for predicting the suitable distribution of snails.",
  "evaluation/measure": "In our study, we employed several common and widely accepted model evaluation metrics to assess the performance of our ecological niche models. These metrics include the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and kappa.\n\nThe AUC value is a crucial indicator for ecological niche models, as it provides a measure of the model's ability to discriminate between presence and absence. An AUC value closer to 1 indicates higher model accuracy. Sensitivity, also known as the true positive rate, measures the model's predictive accuracy for presence, while specificity, or the true negative rate, assesses the model's predictive accuracy for absence. Kappa, ranging from -1 to 1, evaluates the agreement between predicted and actual observations, with values closer to 1 indicating better agreement.\n\nThese metrics are representative of those commonly used in the literature for evaluating ecological niche models. They provide a comprehensive assessment of model performance, covering aspects such as discrimination ability, predictive accuracy for both presence and absence, and overall agreement with observed data. By reporting these metrics, we ensure that our model evaluation is robust and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we employed eight different machine learning algorithms from the Caret package to predict the suitable distribution of snails. These algorithms included eXtreme Gradient Boosting (XGB), support vector machine (SVM), random forest (RF), generalized boosted model (GBM), neural network (NN), classification and regression trees (CART), k-nearest neighbors (KNN), and generalized additive model (GAM). This approach allowed us to compare the performance of various models directly.\n\nTo ensure a fair comparison, the original datasets were randomly divided into two parts: 70% for training the models and 30% for testing their accuracy. This split ensured that each model was evaluated on the same data, providing a consistent benchmark for performance comparison.\n\nFor each model, we used the grid search method combined with 10-fold cross-validation to determine the optimal hyperparameters. This process helped in fine-tuning the models to achieve the best possible predictive performance. The predictive power of each model was then tested using the testing dataset, allowing us to select the model with the highest accuracy.\n\nThe performance of the models was evaluated using common metrics such as the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and kappa. The AUC value, in particular, is a crucial indicator of model accuracy, with values closer to 1 indicating higher accuracy. Sensitivity measures the model's ability to correctly predict the presence of snails, while specificity measures its ability to correctly predict their absence. The kappa statistic provides a measure of agreement between the predicted and actual observations, with values closer to 1 indicating better agreement.\n\nAmong the eight models, the random forest (RF) model exhibited the best prediction performance, with an AUC of 0.991, sensitivity of 0.982, specificity of 0.995, and kappa of 0.942. This was followed by the generalized boosted model (GBM) with an AUC of 0.983. The classification and regression trees (CART) model performed the worst, with an AUC of 0.884.\n\nIn summary, our study involved a comprehensive comparison of multiple machine learning algorithms using consistent evaluation metrics and datasets. This approach allowed us to identify the most accurate model for predicting the suitable distribution of snails, ensuring robust and reliable results.",
  "evaluation/confidence": "The evaluation of the models included several performance metrics, such as the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and kappa. These metrics provide a comprehensive assessment of the models' predictive performance.\n\nThe AUC values, which are the most common evaluation indicators for ecological niche models, were reported with 95% confidence intervals. For instance, the random forest (RF) model, which exhibited the best prediction performance, had an AUC of 0.991 with a 95% confidence interval of 0.989\u20130.993. This indicates a high level of confidence in the model's accuracy. Similarly, other models like the generalized boosted model (GBM) and eXtreme Gradient Boosting (XGB) also had their AUC values reported with confidence intervals, providing a clear understanding of the variability in their performance estimates.\n\nThe sensitivity and specificity values, which indicate the predictive accuracy for presence and absence respectively, were also provided for each model. These metrics, along with the kappa values, which range from -1 to 1 and indicate the consistency between predicted results and actual observations, further support the statistical significance of the results. For example, the RF model had a sensitivity of 0.982, specificity of 0.995, and kappa of 0.942, all of which are very high and suggest that the model's predictions are highly reliable.\n\nThe use of 10-fold cross-validation during the model training process ensures that the results are robust and not due to overfitting. This method involves dividing the data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset, repeating this process 10 times. This approach helps to ensure that the model's performance is consistent across different subsets of the data.\n\nOverall, the performance metrics, along with the confidence intervals and the use of cross-validation, provide strong evidence that the methods employed are superior to others and baselines. The statistical significance of the results is well-supported, and the models' predictive performance is highly reliable.",
  "evaluation/availability": "Not enough information is available."
}