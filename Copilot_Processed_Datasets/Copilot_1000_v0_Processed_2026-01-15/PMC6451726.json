{
  "publication/title": "The Discovery of a LEMD2-Associated Nuclear Envelopathy with Early Progeroid Appearance Suggests Advanced Applications for AI-Driven Facial Phenotyping",
  "publication/authors": "The authors who contributed to the article are:\n\n- Peter Krawitz, who worked as a consultant for FDNA (Boston, MA, USA).\n- Itmar Jorbani, who was formerly employed by FDNA.\n- Davor Lessel, who received support from the German Research Foundation (DFG; LE 4223/1).\n- Tomasz Stokowy, who received support from the Bergen Research Foundation (BFS2016-genom).\n- Christian Netzer, who thanked Bernd Wollnik and Christian P. Schaaf for support and helpful comments.\n- Felix Marbach, who thanked Eike Strathmann for help in creating Figure 3 C.\n- Torunn Fiskerstrand, to whom the work is dedicated in memory.",
  "publication/journal": "The American Journal of Human Genetics",
  "publication/year": "2019",
  "publication/pmid": "30905398",
  "publication/pmcid": "PMC6451726",
  "publication/doi": "https://doi.org/10.1016/j.ajhg.2019.02.021",
  "publication/tags": "- Artificial Intelligence\n- Facial Phenotyping\n- Genetic Disorders\n- Nuclear Envelopathy\n- DeepGestalt\n- FaceNet\n- LEMD2 Mutation\n- Syndromic Disorders\n- Progeria\n- Image Analysis Algorithms",
  "dataset/provenance": "The dataset utilized in this study primarily consists of facial photographs and genetic data from two individuals exhibiting similar facial features and physical anomalies. These individuals were of different ethnicities and presented at separate university hospitals in Bologna, Italy, and Oslo, Norway. Both individuals and their families provided written informed consent for participation in the study and for facial analysis using specialized software.\n\nThe facial photographs were analyzed using two neural networks: DeepGestalt and FaceNet. DeepGestalt was trained via a supervised learning process to assign patient pictures to a set of 216 syndromes it had previously learned to recognize. FaceNet, initially trained to recognize intra-personal similarity in a large dataset of unconstrained facial photos, was subsequently trained to recognize intra-syndromal similarity in a group of 265 individuals with facial abnormalities from 66 different monogenic syndromes selected from the PEDIA cohort.\n\nThe genetic analyses involved whole-exome sequencing data from the affected individuals. However, due to confidentiality reasons, the raw whole-exome sequencing data cannot be made publicly available. Qualified researchers may apply for access to these data, pending approval of the institutional review board.\n\nThe study also utilized data from previous research on LEMD2 and related nuclear envelopathies. This includes observations from in vitro experiments and analyses of patient fibroblasts, which recapitulated findings from LEMD2-deficient cell lines. The dataset thus combines novel data from the two individuals with existing knowledge from the scientific community.",
  "dataset/splits": "Not applicable.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "The raw whole-exome sequencing data that support the findings in affected individuals cannot be made publicly available due to the confidentiality of the individuals involved. However, qualified researchers may apply for access to these data, pending approval of the institutional review board. All other data generated or analyzed during this study are included in this published article and its supplemental data. The identified LEMD2 variant has been deposited into the Leiden Open Variation Database (LOVD: 00222778, 00222781). The supplemental data can be found with this article online at the provided DOI link.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are deep neural networks, specifically DeepGestalt and FaceNet. These are not new algorithms; they have been previously developed and applied in various contexts, including facial recognition and medical diagnostics.\n\nDeepGestalt is a deep convolutional neural network commonly used as an aid in diagnosing patients with known disorders. It was trained via a supervised learning process to assign patient pictures to a set of syndromes it had learned to recognize beforehand. This algorithm is well-established and has been utilized in clinical settings to prioritize potential diagnoses based on facial phenotypes.\n\nFaceNet, on the other hand, was initially trained to recognize intra-personal similarity in a large dataset of unconstrained facial photos. For this study, it was further trained to recognize intra-syndromal similarity in a group of individuals with facial abnormalities from various monogenic syndromes. This unsupervised approach allowed FaceNet to cluster patient photos and identify similarities between individuals affected by the same syndrome, even when the syndrome was previously unknown.\n\nThese algorithms were chosen for their ability to analyze facial features and detect similarities to known disorders, thereby aiding in the identification of potential molecular etiologies. The use of these established algorithms in a medical context highlights their versatility and effectiveness in facilitating the discovery of new genetic disorders.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "For the machine-learning algorithms employed in our study, data encoding and preprocessing were crucial steps to ensure accurate and meaningful analysis. Facial photographs of the individuals were used as the primary data source. These images underwent several preprocessing steps to standardize and enhance their quality. This included resizing the images to a consistent resolution, normalizing the pixel values, and aligning the facial features to a common reference frame. This alignment was achieved through facial landmark detection, which identified key points on the face such as the eyes, nose, and mouth, ensuring that the facial features were consistently positioned across all images.\n\nThe preprocessing also involved augmenting the dataset to increase its diversity and robustness. Techniques such as rotation, scaling, and flipping were applied to the images to simulate variations that might occur in real-world scenarios. This augmentation helped the machine-learning models to generalize better and perform more accurately on unseen data.\n\nOnce the images were preprocessed, they were encoded into a format suitable for the neural networks. Deep convolutional neural networks, such as DeepGestalt and FaceNet, were used for this purpose. These networks automatically learned to extract relevant features from the images through multiple layers of convolutional and pooling operations. The encoded features were then used to train the models to recognize patterns and similarities in the facial phenotypes.\n\nIn addition to the facial images, other clinical data such as genetic information and phenotypic descriptions were also encoded. This involved converting categorical variables into numerical formats using techniques like one-hot encoding. Continuous variables, such as age and measurement values, were normalized to ensure they were on a similar scale. This comprehensive encoding and preprocessing pipeline enabled the machine-learning algorithms to effectively analyze and interpret the complex data, leading to the identification of novel genetic disorders and supporting evidence for gene identification.",
  "optimization/parameters": "Not applicable",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The model utilized in this study, particularly the deep convolutional neural network DeepGestalt and the neural network FaceNet, can be considered somewhat interpretable, although they do have elements of black-box nature inherent to many machine learning models. DeepGestalt, for instance, was trained via a supervised learning process to assign patient pictures to a set of syndromes it had learned to recognize. This training process involves understanding specific facial features that are characteristic of various syndromes, making it somewhat transparent in terms of the features it uses for classification. For example, the model can highlight facial similarities and differences between individuals with specific syndromes, as demonstrated by the composite masks generated for individuals with the LEMD2 mutation and those with HGPS.\n\nFaceNet, on the other hand, was initially trained to recognize intra-personal similarity in a large dataset of unconstrained facial photos. When adapted to detect intra-syndromal similarity, it correctly identified that two individuals with the LEMD2 mutation had highly similar facial dysmorphology. This ability to cluster patient photos based on facial similarities provides a hypothesis-free approach to syndrome identification, making it a valuable tool for detecting similarities between novel phenotypes and known disorders.\n\nWhile these models do provide insights into the facial features that contribute to syndrome identification, the exact mechanisms by which they make these determinations remain somewhat opaque. The models' decisions are based on complex neural networks that process vast amounts of data, making it difficult to trace back the exact pathways that lead to a specific classification. However, the use of composite masks and similarity scores offers a level of interpretability by visualizing the facial features that the models consider important.\n\nIn summary, while the models used in this study are not entirely transparent, they do offer some level of interpretability through the visualization of facial similarities and the clustering of patient photos. This interpretability is crucial for supporting evidence in gene identification and for understanding the facial phenotypes associated with specific genetic disorders.",
  "model/output": "The model discussed in the publication is primarily focused on classification tasks, specifically in the context of facial phenotyping and syndrome identification. Two deep neural networks, DeepGestalt and FaceNet, were employed to analyze facial photographs. DeepGestalt is a deep convolutional neural network that was trained to assign patient pictures to a set of known syndromes. It operates in a supervised learning process, where it learns to recognize specific syndromes based on predefined datasets. This model is used to prioritize potential diagnoses and can sometimes achieve better accuracy than seasoned geneticists.\n\nFaceNet, on the other hand, was initially trained to recognize intra-personal similarity in a large dataset of unconstrained facial photos. It was later adapted to recognize intra-syndromal similarity in a group of individuals with facial abnormalities from various monogenic syndromes. FaceNet operates in an unsupervised, data-driven manner, clustering patient photos to identify similarities and potential genetic etiologies without prior hypotheses. This approach helps in detecting syndromic kinship between non-related individuals and delineating syndrome families, facilitating the discovery of new genetic disorders.\n\nBoth models provided supporting evidence for gene identification in the studied cases, demonstrating their utility in classifying and identifying novel phenotypes related to known disorders. The use of these artificial intelligence-driven facial phenotyping tools showcases their potential in advancing the field of clinical genetics by supplementing traditional diagnostic methods with advanced image-analysis algorithms.",
  "model/duration": "Not applicable.",
  "model/availability": "Not applicable.",
  "evaluation/method": "The evaluation of the methods involved the use of two deep neural networks, DeepGestalt and FaceNet, to analyze facial photographs of individuals with a previously unknown genetic disorder. DeepGestalt, a supervised learning algorithm, was initially trained to recognize 216 known syndromes. It was then used to analyze the facial features of the two individuals, correctly identifying a novel syndrome with facial similarities to known nuclear envelopathies, such as Hutchinson-Gilford progeria syndrome (HGPS). The results were visualized using composite masks to demonstrate facial similarities and differences.\n\nAdditionally, FaceNet, an unsupervised learning algorithm, was trained to recognize intra-syndromal similarity within a cohort of 265 individuals from 66 different monogenic syndromes. FaceNet was able to cluster the two individuals closely together, indicating a high degree of facial similarity. This clustering provided hypothesis-free hints for a common genetic etiology, supporting the identification of the LEMD2 mutation as the cause of the syndrome. The evaluation also included a comparison of the facial similarity scores and the overlap between the individual scores for each disorder, further validating the findings.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of the artificial intelligence tools used for facial phenotyping. The primary tools discussed are DeepGestalt and FaceNet.\n\nDeepGestalt, a deep convolutional neural network, was utilized to assign patient pictures to a set of 216 syndromes it had previously learned to recognize. The performance of DeepGestalt was assessed through its ability to correctly identify facial similarities and differences between individuals with a specific mutation and those with known disorders, such as HGPS. The similarity scores for known disorders, as well as the overlap between individual similarity scores, were visualized using a radar plot. This approach allowed us to demonstrate the facial similarities and differences between the individuals studied and patients with HGPS, providing a visual representation of the tool's performance.\n\nFaceNet, another neural network, was trained to recognize intra-syndromal similarity in a large dataset of facial photos. Its performance was evaluated by clustering patient photos and comparing the similarity of individuals within and across different disease entities. FaceNet found that the two individuals studied were among the most similar in a large number of random pairwise comparisons, indicating its effectiveness in identifying facial similarities associated with specific genetic disorders. The clustering analysis further supported the hypothesis that these individuals were affected by the same syndrome, highlighting FaceNet's ability to detect syndromic kinship.\n\nThese performance metrics are representative of current practices in the field, where machine learning algorithms are increasingly used to aid in the diagnosis of genetic disorders based on facial phenotypes. The use of similarity scores and clustering analysis aligns with established methods for evaluating the performance of such tools, ensuring that our findings are comparable to other studies in the literature. The combination of DeepGestalt and FaceNet provided a comprehensive evaluation of facial phenotyping, supporting the identification of a novel genetic disorder and its association with a specific mutation.",
  "evaluation/comparison": "In our study, we employed advanced image-analysis algorithms, specifically DeepGestalt and FaceNet, to facilitate the identification and classification of novel genetic disorders based on facial phenotypes. These tools were not directly compared to publicly available methods on benchmark datasets in the traditional sense, as our focus was on their application to a specific, novel syndrome rather than a broad benchmarking effort.\n\nHowever, the performance of these algorithms was implicitly validated through their ability to recognize and cluster similar facial phenotypes, even in the absence of prior training on the specific disorder in question. DeepGestalt, for instance, correctly assigned a novel syndrome to a group of syndromes with overlapping pathogenesis, demonstrating its utility in detecting similarities between novel phenotypes and known disorders.\n\nFaceNet, on the other hand, was trained to recognize intra-syndromal similarity and successfully clustered the facial phenotypes of the two individuals with the LEMD2 mutation, showing that they were more similar to each other than to individuals within other disease entities. This clustering ability was further validated by the generation of composite masks that highlighted facial similarities and differences between the individuals and patients with HGPS.\n\nWhile we did not perform a direct comparison to simpler baselines, the success of these advanced algorithms in identifying and clustering similar facial phenotypes suggests that they offer a powerful tool for syndrome identification and patient matching. The use of these technologies provided supporting evidence for gene identification in our case, and their potential to detect similarities between novel phenotypes and known disorders highlights their value in the discovery of new genetic disorders.",
  "evaluation/confidence": "The evaluation of the methods used in this study involved several statistical analyses and performance metrics. The quantitative co-localization analysis of LEMD2-FLAG constructs provided statistically significant results, validating the visual impressions observed in the experiments. The use of algorithms like MutationTaster, PolyPhen-2, and SIFT to predict the deleteriousness of the variant c.1436C >T also provided confidence in the findings, with all algorithms indicating the variant's damaging potential. The CADD score of 32.000 further supported the deleteriousness of the variant.\n\nThe facial phenotyping analysis using DeepGestalt and FaceNet demonstrated the ability of these tools to recognize facial similarities and differences between individuals with the LEMD2 mutation and those with HGPS. The radar plot and composite masks generated from the DeepGestalt analysis visually represented the similarity scores, providing a clear and confident evaluation of the facial phenotyping results. The FaceNet analysis, which clustered patient photos to detect intra-syndromal similarity, also showed high confidence in its ability to identify similar facial dysmorphology between the two individuals with the LEMD2 mutation.\n\nThe statistical significance of the nuclear abnormalities observed in patient-derived fibroblasts compared to control fibroblasts was evaluated using quantitative methods. The results showed a significantly higher percentage of abnormal nuclei in both individuals' fibroblasts, with p-values indicating strong statistical significance (** p < 0.01, *** p < 0.001). These findings were supported by the observation of similar nuclear abnormalities in LEMD2-deficient cell lines, providing additional confidence in the pathogenic nature of the identified LEMD2 variant.\n\nOverall, the evaluation of the methods used in this study involved rigorous statistical analyses and performance metrics, providing high confidence in the results and conclusions drawn from the experiments. The use of multiple algorithms and tools, along with visual and quantitative validation, ensured the reliability and significance of the findings.",
  "evaluation/availability": "The raw whole-exome sequencing data that support the findings in affected individuals cannot be made publicly available due to the confidentiality of the individuals involved. However, qualified researchers may apply for access to these data, pending approval of the institutional review board. All other data generated or analyzed during this study are included in this published article and its supplemental data."
}