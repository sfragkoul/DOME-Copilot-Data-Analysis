{
  "publication/title": "Machine Learning to Predict Transplant Outcomes: Helpful or Hype?",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Transplantation International",
  "publication/year": "2020",
  "publication/pmid": "32996170",
  "publication/pmcid": "PMC8269970",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Machine Learning\n- Kidney Transplantation\n- Predictive Modeling\n- Regression Analysis\n- Gradient Boosting\n- Random Forests\n- Transplant Outcomes\n- Statistical Analysis\n- Medical Data\n- Comparative Study",
  "dataset/provenance": "The dataset used in this study was sourced from the Scientific Registry of Transplant Recipients (SRTR). This registry is managed by the Hennepin Healthcare Research Institute as the contractor for the SRTR. The data reported here have been supplied by the SRTR, and the interpretation and reporting of these data are the responsibility of the authors.\n\nThe study included a total of 133,431 adult deceased-donor kidney transplant (KT) recipients from 272 KT centers. The data spans from January 1, 2005, to December 31, 2017. The dataset was randomly divided at the center level into a 70% training set, consisting of 190 centers and 97,787 recipients, and a 30% validation set, consisting of 82 centers and 35,644 recipients.\n\nThe dataset used in this study has been utilized in previous research. A detailed description of the data has been provided elsewhere, indicating its use in prior studies. The data is de-identified and was exempted by the Johns Hopkins Medicine Institutional Review Boards, ensuring compliance with ethical standards.",
  "dataset/splits": "The dataset was divided into two splits: a training set and a validation set. The training set consisted of 97,787 recipients from 190 centers, which accounted for approximately 70% of the total data. The validation set included 35,644 recipients from 82 centers, making up the remaining 30%. The distribution of data points in each split was designed to ensure that the characteristics of the training and validation sets were similar. For instance, the median recipient age was 54 years in both sets, and the median donor age was 41 years in the training set and 39 years in the validation set. Additionally, the proportion of female recipients and African American recipients was nearly identical in both sets. This careful splitting helped to maintain the representativeness of the data across both the training and validation phases.",
  "dataset/redundancy": "The dataset used in this study was sourced from the Scientific Registry of Transplant Recipients (SRTR), which includes comprehensive data on all donors, waitlisted candidates, and transplant recipients in the United States. The dataset comprised 133,431 adult deceased-donor kidney transplant recipients between 2005 and 2017.\n\nTo ensure a robust evaluation of the predictive models, the dataset was randomly divided into two independent sets: a training set and a validation set. The training set consisted of 70% of the data, encompassing 190 transplant centers and 97,787 recipients. The validation set made up the remaining 30%, including 82 centers and 35,644 recipients. This split was designed to mimic a common study setup relevant to a wide range of transplantation research, ensuring that the models were tested on data they had not seen during training.\n\nThe independence of the training and validation sets was enforced by randomly assigning transplant centers to either the training or validation set. This approach helped to prevent data leakage and ensured that the models were evaluated on truly unseen data, providing a more accurate assessment of their generalizability.\n\nRegarding the distribution of the dataset, it is noteworthy that the training and validation sets showed similar characteristics. For instance, the median recipient age was 54 years in both sets, and the median donor age was 41 years in the training set and 39 years in the validation set. The proportions of female recipients and African American recipients were also comparable between the two sets. This similarity in distribution helps to ensure that the results are not biased by differences in the underlying data.\n\nIn summary, the dataset was carefully split into independent training and validation sets, with a focus on maintaining similar distributions to previously published machine learning datasets in the field of transplantation. This approach enhances the reliability and validity of the comparative analysis between machine learning algorithms and conventional regression models.",
  "dataset/availability": "Not applicable",
  "optimization/algorithm": "The study employed two machine-learning algorithm classes: gradient boosting (GB) and random forests (RF). These are well-established algorithms in the field of machine learning and are not new. They were chosen for their ability to handle complex interactions and non-linear relationships in the data, which are common in medical research.\n\nThe decision to use these specific algorithms was driven by their proven track record in predictive modeling and their ability to handle high-dimensional data, which is typical in transplantation research. The algorithms were not published in a machine-learning journal because the focus of the study was on their application in transplantation outcomes prediction rather than the development of new machine-learning techniques. The study aimed to compare the performance of these machine-learning algorithms with conventional regression methods in a controlled setting using the same dataset and variables. This approach allowed for a fair comparison and provided insights into the practical advantages and limitations of machine learning in this specific context.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "For the machine-learning algorithms, data encoding and preprocessing were handled to ensure optimal performance. Missing values in the covariates were managed through imputation techniques. For the gradient boosting (GB) models, missing values were imputed during the training process in a manner analogous to multiple imputation. Similarly, for the random forests (RF) models, missing values were also imputed during training. This approach helped to maintain the integrity of the data and prevent any biases that might arise from excluding or improperly handling missing values.\n\nContinuous variables were addressed to account for potential non-linear associations with the clinical outcomes. Linear spline terms were included in the models to capture these non-linear relationships. The knots for these splines were determined based on previous literature and exploratory data analyses, which involved comparing the fit of univariable models using different sets of knots. This careful selection of knots ensured that the models could accurately represent the underlying data patterns.\n\nThe data was divided into a 70% training set and a 30% validation set at the center level. This division helped to ensure that the models were trained and validated on independent datasets, reducing the risk of overfitting and providing a more reliable assessment of their performance. The training set consisted of 97,787 recipients from 190 centers, while the validation set included 35,644 recipients from 82 centers. This split allowed for a robust evaluation of the models' predictive performance across different outcomes, including delayed graft function, one-year acute rejection, death-censored graft failure, death, and all-cause graft failure.",
  "optimization/parameters": "The study utilized a comprehensive set of covariables for the prediction models. These covariables included donor variables such as age, race, sex, ABO blood type, height, weight, cause of donor death, terminal serum creatinine, cytomegalovirus (CMV) status, hepatitis C status, diabetes, hypertension, and donation after cardiac death. Recipient variables encompassed age, sex, race, primary cause of end-stage renal disease, ABO blood type, primary insurer, body mass index (BMI), human immunodeficiency virus (HIV) status, CMV status, hepatitis B status, hepatitis C status, Epstein-Barr virus status, previous transplant history, preemptive transplant status, time on dialysis, panel reactive antibody (PRA) levels, diabetes, hypertension, previous malignancy, symptomatic peripheral vascular disease, total serum albumin, and education level. Additionally, transplant variables such as HLA-A/B/DR mismatches and cold ischemic time were included.\n\nThe selection of these parameters was based on their relevance to kidney transplant outcomes, as established in previous literature and exploratory data analyses. The models were developed using generalized linear regression, gradient boosting, and random forests, with missing values handled through multiple imputation. The tuning parameters for the machine learning algorithms were chosen via cross-validation on the training dataset. This approach ensured that the models were robust and that the selected parameters were optimal for predicting the outcomes of interest.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting, particularly in the context of our machine learning models. For the gradient boosting (GB) models, we utilized cross-validation to select the optimal tuning parameters. This process helps to ensure that the model generalizes well to unseen data by tuning hyperparameters based on performance on validation folds. Additionally, the gradient boosting algorithm inherently includes regularization techniques such as shrinkage (learning rate) and subsampling, which help to control the complexity of the model and prevent overfitting.\n\nFor the random forests (RF) models, we also relied on cross-validation to choose the best tuning parameters. Random forests are inherently robust to overfitting due to their ensemble nature, where multiple decision trees are averaged to make predictions. However, we further controlled for overfitting by setting appropriate values for parameters like the number of trees and the maximum depth of the trees, which were determined through cross-validation.\n\nIn summary, cross-validation was a key technique used across both GB and RF models to prevent overfitting by ensuring that the models were tuned to perform well on validation data, thereby enhancing their generalization to new, unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "When discussing the interpretability of our models, it's crucial to highlight the differences between machine learning (ML) algorithms and conventional regression models. ML algorithms, such as gradient boosting (GB) and random forests (RF), often operate as \"black-box\" predictors. This means that while they can provide highly accurate predictions, the internal workings of these models are not easily interpretable. For instance, it can be challenging to understand exactly how these models arrive at their predictions, which variables are most influential, or how interactions between variables are handled.\n\nIn contrast, regression models offer a more transparent approach. They provide interpretable coefficients that indicate the direction and magnitude of the relationship between each predictor variable and the outcome. This transparency allows for face validity checking, where researchers can assess whether the model's predictions align with established biological or clinical knowledge. Additionally, regression models facilitate hypothesis testing, enabling researchers to draw conclusions about the underlying mechanisms driving the observed outcomes.\n\nFor example, in a regression model predicting kidney transplant outcomes, the coefficient for a variable like \"recipient age\" would clearly indicate whether older age is associated with better or worse outcomes, and by how much. This level of interpretability is not readily available in ML models, where the relationships between variables and outcomes are often obscured by complex, non-linear interactions and decision trees.\n\nMoreover, the black-box nature of ML models can sometimes lead to spurious associations. For instance, a ML algorithm might inadvertently learn to associate irrelevant features, such as the presence of a ruler in an image, with a particular outcome, simply because these features were consistently present in the training data. Such issues are less likely to occur with regression models, which provide a clearer, more straightforward path from input variables to predictions.\n\nIn summary, while ML algorithms can offer powerful predictive capabilities, their lack of interpretability is a significant drawback. Regression models, on the other hand, provide a transparent and interpretable framework that is essential for validating predictions, testing hypotheses, and gaining insights into the underlying biological processes.",
  "model/output": "The model encompasses both classification and regression tasks. Specifically, it addresses binary outcomes such as delayed graft function (DGF) and one-year acute rejection (AR) using classification techniques. For time-to-event outcomes like death-censored graft failure (DCGF), all-cause graft failure (ACGF), and death, the model employs regression methods, particularly Cox regression, which is standard for evaluating survival. The study compares the performance of machine learning algorithms\u2014gradient boosting (GB) and random forests (RF)\u2014against traditional regression models across these various outcomes. The predictive performance is evaluated using metrics like C-statistics for discrimination and Brier scores for calibration, providing a comprehensive assessment of the model's effectiveness in both classification and regression contexts.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the predictive performance of the models was conducted using a 30% validation set, which was independent of the training set. The primary measure used for evaluation was the C-statistic, which assesses the model's ability to discriminate between those who develop the outcome and those who do not. For binary outcomes like delayed graft function (DGF) and one-year acute rejection (AR), the C-statistic was derived using the area under the receiver operating characteristic curve (AUROC). For time-to-event outcomes such as death-censored graft failure (DCGF), death, and all-cause graft failure (ACGF), Harrell\u2019s concordance was used.\n\nAdditionally, a sensitivity analysis was performed using Uno\u2019s C-statistic method for time-to-event outcomes. This method is independent of the censoring distribution of the study population, providing a more robust evaluation. The C-statistic was first estimated over the entire validation set and then within 16 subgroups stratified by quartiles of Kidney Donor Profile Index (KDPI) and Estimated Post-Transplant Survival (EPTS) to assess how predictive performance varied by donor and recipient risk levels.\n\nThe secondary measure of predictive performance was the Brier score, which evaluates the calibration of the models. A lower Brier score indicates better calibration, meaning the predicted risk is closer to the actual risk. For time-to-event outcomes, the integrated Brier score was used. Calibration plots were also created to visualize the calibration of the prediction methods across the spectrum of predicted risk. The validation set was stratified into 20 equally distanced bins by the predicted risk of the outcome, and the observed risk within each bin was estimated. This comprehensive evaluation approach ensured a thorough assessment of both discrimination and calibration of the models.",
  "evaluation/measure": "In our evaluation of predictive performance, we primarily focused on two key metrics: the C-statistic and the Brier score. The C-statistic is a measure of discrimination, indicating how well the model distinguishes between those who develop the outcome and those who do not. For binary outcomes such as delayed graft function (DGF) and acute rejection (AR), we used the area under the receiver operating characteristic curve (AUROC). For time-to-event outcomes like death-censored graft failure (DCGF), death, and all-cause graft failure (ACGF), we employed Harrell\u2019s concordance statistic. Additionally, we conducted a sensitivity analysis using Uno\u2019s C-statistic, which is independent of the censoring distribution of the study population.\n\nOur secondary measure of predictive performance was the Brier score, which assesses calibration by evaluating how close the predicted risk is to the actual risk. A lower Brier score indicates better calibration. For time-to-event outcomes, we used the integrated Brier score, an extension of the Brier score tailored for such outcomes. We also created calibration plots to visualize the calibration of our prediction methods across the spectrum of predicted risk.\n\nThese metrics are widely recognized and used in the literature for evaluating predictive models, particularly in the context of medical outcomes. The C-statistic is a standard measure for assessing the discriminative ability of models, while the Brier score is crucial for evaluating calibration. By including both metrics, we ensure a comprehensive evaluation of our models' performance, covering both discrimination and calibration aspects. This approach aligns with best practices in the field and provides a robust assessment of our models' predictive capabilities.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of machine learning (ML) algorithms against traditional regression methods for predicting kidney transplant (KT) outcomes. We did not use benchmark datasets, but instead utilized a large national registry dataset, which is more relevant to our specific research question. This dataset included a comprehensive set of covariables related to donors, recipients, and transplant procedures.\n\nWe compared the predictive performance of two popular ML algorithms, Gradient Boosting (GB) and Random Forest (RF), against regression models. This comparison was not just a cursory check but a detailed evaluation using two primary measures: the C-statistic and the Brier score. The C-statistic assessed the discrimination ability of the models, indicating how well they could distinguish between patients who would experience the outcome and those who would not. The Brier score evaluated the calibration, showing how closely the predicted risks matched the actual outcomes.\n\nFor the C-statistic, we found that regression models often performed as well as or better than the ML algorithms, particularly in predicting one-year acute rejection (AR). For other outcomes like delayed graft function (DGF), death-censored graft failure (DCGF), death, and all-cause graft failure (ACGF), the performance of regression, GB, and RF was nearly identical. This consistency was observed across the entire validation set and within subgroups stratified by Kidney Donor Profile Index (KDPI) and Estimated Post-Transplant Survival (EPTS).\n\nIn terms of calibration, as measured by the Brier score, regression models generally showed superior performance, especially for time-to-event outcomes. This means that regression models had smaller prediction errors compared to the ML algorithms for DCGF, death, and ACGF. For binary outcomes like DGF and AR, the Brier scores were very similar across all methods.\n\nOur findings suggest that, for straightforward outcome prediction using routinely collected tabular data, regression models are at least as effective as ML algorithms and often more so. This is significant because regression models are more interpretable and allow for hypothesis testing, which is crucial in medical research. While ML algorithms have shown promise in other areas of medicine, our study indicates that for KT outcome prediction, the advantages of ML are not evident. This does not diminish the potential of ML in other contexts, such as handling complex interactions or integrating non-tabular data, but it underscores the importance of choosing the right tool for the specific task at hand.",
  "evaluation/confidence": "The performance metrics in our study include confidence intervals for the C-statistics, which are presented in the Louis and Zeger style. These intervals provide a range within which the true C-statistic is expected to lie with 95% confidence. This approach allows for a more nuanced understanding of the predictive performance of our models, as it accounts for the variability and uncertainty in the estimates.\n\nFor instance, in predicting one-year acute rejection, the C-statistic for regression is reported as 0.601 to 0.621, while for gradient boosting (GB) it is 0.581 to 0.601, and for random forests (RF) it is 0.569 to 0.589. These intervals indicate that regression not only has a higher point estimate but also a higher lower bound compared to the machine learning algorithms, suggesting a more consistent superiority.\n\nStatistical significance is crucial for claiming that one method is superior to others. In our comparison, regression showed a higher C-statistic for one-year acute rejection, and the non-overlapping confidence intervals suggest that this difference is statistically significant. For other outcomes like delayed graft function, death-censored graft failure, all-cause graft failure, and death, the C-statistics across regression, GB, and RF are nearly identical, with overlapping confidence intervals. This indicates that while regression is not inferior, it does not show a clear statistical advantage for these outcomes.\n\nAdditionally, the Brier scores, which measure calibration, also include implicit confidence through the integrated Brier score for time-to-event outcomes. Regression demonstrated lower Brier scores for death-censored graft failure, death, and all-cause graft failure, indicating better calibration and thus smaller prediction errors. The calibration plots further support that all methods have comparable calibration across the spectrum of predicted risk, reinforcing the reliability of our findings.\n\nIn summary, the inclusion of confidence intervals in our performance metrics allows for a robust evaluation of model performance. The results indicate that while regression is statistically superior in predicting one-year acute rejection, it performs similarly to machine learning algorithms for other outcomes. This comprehensive evaluation ensures that our claims about model performance are supported by statistically significant evidence.",
  "evaluation/availability": "Not enough information is available."
}