{
  "publication/title": "Chest pain stratification using machine learning",
  "publication/authors": "The authors who contributed to this article are Muhammad Shafiq, Diego Robles Mazzotti, and Cheryl Gibson.\n\nMuhammad Shafiq was involved in all aspects of this study, including but not limited to study design, data collection, data analyses, and writing of the abstract and manuscript. Diego Robles Mazzotti was involved in study design, data collection, and data analyses. Cheryl Gibson assisted in writing the abstract and manuscript.",
  "publication/journal": "World Journal of Cardiology",
  "publication/year": "2022",
  "publication/pmid": "36483764",
  "publication/pmcid": "PMC9723999",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Chest pain\n- Machine learning\n- Risk stratification\n- Cardiac stress test\n- Coronary artery disease\n- Predictive modeling\n- Statistical analysis\n- Medical diagnosis\n- Patient outcomes\n- Healthcare data analysis",
  "dataset/provenance": "The dataset used in this study was sourced from the i2b2 common data model repository of the University of Kansas Medical Center. This repository contains de-identified data, which allowed for the conduct of database queries for patients observed in the health system between January 2016 and November 2021. The data was accessed using the Healthcare Enterprise Repository for Ontological Narration, a search discovery tool that facilitates cohort building for observational research.\n\nThe specific number of data points or patients included in the final analysis is not explicitly stated. However, the study included patients aged 21 years or older who presented to the emergency room with chest pain, had their first troponin test within the first 6 hours of arrival, had at least one troponin test completed after 6 hours, were subsequently admitted to the hospital, and had a nuclear cardiac stress test (CST) carried out within 4 days of presentation. Patients with elevated troponin levels and those with missing body mass index values were excluded.\n\nThe data used in this study has not been previously published or used by the community in the same context. The identification and definitions of computable phenotypes used in this study are provided in the supplementary material. The de-identified nature of the data meant that Institutional Review Board approval was not required, and no informed consent was necessary.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "The dataset used in this study was split into training and testing sets to ensure independent evaluation of the machine learning models. Specifically, bootstrapping with replacement was employed for internal validation. During each iteration of bootstrapping, the data were randomly divided into a training set comprising 75% of the data and a testing set comprising the remaining 25%. This process was repeated 500 times to produce more precise estimates and to create 95% confidence intervals.\n\nTo enforce the independence of the training and test sets, the models were first fitted using the training data. Subsequently, the testing data were applied to assess the internal validation during each iteration. This method helps to minimize overfitting and ensures that the models generalize well to unseen data.\n\nComparing the distribution of this dataset to previously published machine learning datasets for chest pain stratification, it is notable that our study focused on patients with normal troponin values, which is a more challenging subset for risk stratification. This focus differentiates our dataset from others that include both normal and abnormal troponin levels. The use of a retrospective cohort design with de-identified data from the i2b2 common data model repository at the University of Kansas Medical Center ensures a robust and representative sample for analysis.",
  "dataset/availability": "The data used in this study is not publicly released. All relevant data have been provided within the article. No additional data are available. The study utilized de-identified data from the i2b2 common data model repository of the University of Kansas Medical Center. This data was accessed using the Healthcare Enterprise Repository for Ontological Narration, a tool that facilitates cohort building for observational research. The data was collected from patients observed in the health system between January 2016 and November 2021. Institutional Review Board approval was not required because the data was de-identified. The identification and definitions of computable phenotypes used in this study are provided in the Supplementary material.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to the class of ensemble learning methods. Specifically, three different algorithms were employed: binomial regression, random forest, and XGBoost. These algorithms are well-established in the field of machine learning and have been widely used for various predictive modeling tasks.\n\nThe algorithms used are not new; they have been extensively studied and applied in numerous research and practical applications. Binomial regression is a type of logistic regression used for binary outcome variables. Random forest is an ensemble method that constructs multiple decision trees during training and outputs the mode of the classes (classification) or mean prediction (regression) of the individual trees. XGBoost, short for Extreme Gradient Boosting, is an optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable.\n\nThe choice of these algorithms was driven by their proven effectiveness in handling complex datasets and their ability to provide robust predictive performance. While these algorithms are not novel, their application in the specific context of chest pain stratification using patient characteristics with normal troponin values is a significant contribution. The focus of this study was on clinical application and improving patient outcomes, rather than developing new machine-learning algorithms. Therefore, publishing in a machine-learning journal was not the primary objective. The study aimed to demonstrate the potential of existing machine-learning techniques in a clinical setting, highlighting their utility in enhancing risk stratification for patients presenting with chest pain.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data used in this study was derived from a retrospective cohort design involving de-identified patient information from the i2b2 common data model repository of the University of Kansas Medical Center. The data spanned observations from January 2016 to November 2021. Database queries were conducted using the Healthcare Enterprise Repository for Ontological Narration, a tool that facilitates cohort building for observational research with de-identified data.\n\nFor the machine-learning models, various statistical methods were employed to pre-process and encode the data. Bivariate analysis was performed to assess the association between the incidence of abnormal cardiac stress test (CST) and different variables such as sex, race, and risk factors. The \u03c72 test or Fisher\u2019s exact test was used for categorical variables, while the t-test was applied for age. High-risk and low-risk groups were compared using the \u03c72 test, and risk ratios were calculated.\n\nBinomial regression (BR) was utilized to adjust for confounding factors and infer the degree of association between risk factors and the outcome. All assumptions for BR, including no multi-collinearity and no outliers, were assessed. The Hosmer-Lemeshow goodness-of-fit test was performed to ensure model adequacy.\n\nIn addition to BR, random forest and XGBoost machine-learning models were employed. For the random forest model, proximity and importance were set as true, and the number of trees was set at 25 to minimize overfitting. The XGBoost model used specific hyperparameters, including booster type, objective function, evaluation metric, learning rate, maximum depth, and other regularization parameters, to optimize performance and reduce overfitting. Bootstrapping with replacement was used for internal validation, with data randomly split into training (75%) and testing (25%) sets during each iteration. The models were fitted with training data and then tested with validation data to assess performance. This process was repeated 500 times to produce precise estimates and 95% confidence intervals. Prediction cutoff values were calibrated manually to achieve the best metrics for sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). All statistical analyses were conducted using R software (version 4.1.2).",
  "optimization/parameters": "In our study, we initially considered ten explanatory variables, or input parameters, for our models. These parameters included demographics such as sex and race, as well as medical history factors like coronary artery disease history, hypertension, hyperlipidemia, diabetes mellitus, chronic kidney disease, obesity, and smoking history.\n\nHowever, during the binomial regression model development, age, race, and obesity were removed from the final model. This decision was based on statistical significance and their contribution to the prediction. Specifically, these three covariates together resulted in only a marginal increase in the area under the receiver operating characteristic curve (AUC) by 1.35%. Therefore, the final binomial regression model used seven input parameters: sex, coronary artery disease history, hypertension, hyperlipidemia, diabetes mellitus, chronic kidney disease, and smoking history.\n\nFor the random forest and XGBoost models, all ten initial covariates were included to leverage the ability of these machine learning models to handle a larger number of parameters effectively. This approach allowed us to explore the potential of these models in capturing complex relationships within the data.\n\nThe selection of these parameters was guided by their clinical relevance and availability in the dataset. The final set of parameters for the binomial regression model was determined through a process of statistical analysis and model validation, ensuring that the most significant and relevant factors were included.",
  "optimization/features": "The study utilized ten explanatory variables as input features for the machine learning models. These features were selected based on their relevance to the outcome of interest, which was the incidence of abnormal cardiac stress tests. Feature selection was performed to ensure that the most significant variables were included in the models. This process was conducted using the training set only, adhering to best practices to prevent data leakage and maintain the integrity of the validation process. The selected features included demographic information and various risk factors, all of which were deemed crucial for accurate prediction and stratification of chest pain patients with normal troponin values.",
  "optimization/fitting": "In our study, we employed several machine learning models, including binomial regression, random forest, and XGBoost, to predict abnormal cardiac stress tests. The number of parameters in these models was indeed larger than the number of training points, which could potentially lead to overfitting.\n\nTo mitigate overfitting, we implemented several strategies. For the random forest model, we limited the number of trees to 25 during both training and testing. This constraint helps in preventing the model from becoming too complex and overfitting the training data. Additionally, we set the proximity and importance parameters to \"True\" to better understand the model's behavior and ensure it generalizes well to unseen data.\n\nIn the XGBoost model, we carefully tuned the hyperparameters to balance model complexity and performance. Key hyperparameters included booster type set to \"gbtree,\" objective function set to \"binary:logistic,\" and evaluation metric set to \"auc.\" We also set parameters like eta (learning rate) to 0.1, max depth to 10, and gamma to 0 to control the model's complexity. Furthermore, we used 25 rounds in the XGBoost model to minimize overfitting.\n\nTo ensure the models did not underfit, we performed internal validation using bootstrapping with replacement. Data were randomly split into training (75%) and testing (25%) sets during each iteration of bootstrapping. This process was repeated 500 times to produce precise estimates and 95% confidence intervals. By evaluating the models on both training and testing data, we could assess their performance and ensure they were neither overfitting nor underfitting.\n\nAdditionally, we calibrated the prediction cutoff values manually to optimize metrics such as sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). This step ensured that the models were well-tuned and provided reliable predictions.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. For the random forest model, we set the number of trees to 25 during both training and testing phases. This parameter was chosen to balance model complexity and generalization, helping to minimize overfitting.\n\nIn the XGBoost model, we used a specific set of hyperparameters designed to control overfitting. Key parameters included `eta` set to 0.1, which regulates the learning rate, and `max_depth` set to 10, which limits the maximum depth of the trees. Additionally, `gamma` was set to 0, `min_child_weight` to 1, and `colsample_bytree` to 1. These settings help in pruning the trees and reducing the model's complexity, thereby preventing overfitting.\n\nFurthermore, we utilized bootstrapping with replacement for internal validation of all models. This involved randomly splitting the data into training (75%) and testing (25%) sets during each iteration of bootstrapping. We performed 500 iterations to produce more precise estimates and created 95% confidence intervals. This rigorous validation process ensured that our models were not overfitting to the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules for the machine learning models used in this study are reported. Specifically, for the random forest model, the number of trees was set to 25, and both proximity and importance were enabled. For the XGBoost model, several hyperparameters were specified, including booster type, objective function, evaluation metric, learning rate, maximum tree depth, minimum child weight, and column subsampling by tree. These details are provided to ensure reproducibility and transparency.\n\nThe model files and optimization parameters are not explicitly shared in the publication. However, the statistical analyses were performed using R software (version 4.1.2), and the methods section outlines the steps taken to ensure model adequacy and internal validation. This includes the use of bootstrapping with replacement, splitting data into training and testing sets, and performing 500 iterations to produce precise estimates.\n\nRegarding the availability and licensing of the reported configurations, the publication does not specify a particular license for the use of these details. However, the information is intended to be transparent and reproducible, aligning with the broader goals of the study to promote trust and reproducibility in machine learning models for medical applications.",
  "model/interpretability": "The models employed in this study, specifically the random forest and XGBoost, are generally considered to be black-box models. These models are known for their complexity and the difficulty in interpreting the internal decision-making processes. However, certain aspects of these models can provide some level of interpretability.\n\nFor instance, in the random forest model, the importance of each variable can be assessed, which indicates the contribution of each feature to the prediction. This can help in understanding which factors are most influential in determining the outcome. Similarly, the XGBoost model allows for the examination of feature importance and can provide insights into how different variables interact within the model.\n\nWhile these models do not offer a fully transparent view of their decision-making processes, the ability to evaluate feature importance and interactions provides a degree of interpretability. This can be useful for identifying key risk factors and understanding their impact on the predictions made by the models. However, for a more detailed and transparent interpretation, additional techniques such as SHAP (SHapley Additive exPlanations) values or LIME (Local Interpretable Model-agnostic Explanations) could be employed to further elucidate the model's predictions.",
  "model/output": "The model is a classification model. It is designed to predict the incidence of an abnormal cardiac stress test (CST), which is a binary outcome. The models used in this study\u2014binomial regression, random forest, and XGBoost\u2014are all classification algorithms tailored to handle binary classification tasks. The performance metrics reported, such as sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV), further confirm that the model's output is categorical, indicating whether a patient is likely to have an abnormal CST or not.\n\nThe prediction cutoff values for each model were calibrated manually to optimize these metrics, ensuring that the model's predictions are as accurate as possible for clinical decision-making. The area under the receiver operating characteristic curve (AUC) was also evaluated, which is a common metric for assessing the performance of classification models. The internal validation process involved bootstrapping with replacement, where data were split into training and testing sets to assess the model's generalizability and robustness.\n\nThe final output of the model provides a probability score for each patient, which is then compared to a predetermined cutoff value to classify the patient as either having a high or low risk of an abnormal CST. This classification helps in stratifying patients presenting with chest pain, enabling clinicians to make informed decisions about further diagnostic testing and interventions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study involved a rigorous internal validation process using bootstrapping with replacement. This technique was applied to all models, including binomial regression, random forest, and XGBoost. The data was randomly split into training (75%) and testing (25%) sets during each iteration of bootstrapping. The models were first fitted using the training data, and then the testing data was used to assess internal validation. This process was repeated for 500 iterations to produce more precise estimates and create 95% confidence intervals.\n\nThe performance of the models was evaluated using several key metrics: sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). For the random forest model, a prediction cutoff value of 0.18 was used, resulting in a sensitivity of 13.92%, specificity of 93.66%, PPV of 20.55%, and NPV of 90.24%. The XGBoost model, with a cutoff value of 0.27, yielded a sensitivity of 30.54%, specificity of 88.51%, PPV of 24.33%, and NPV of 91.34%.\n\nThe area under the receiver operating characteristic curve (AUC) was also used to evaluate the models. Both the random forest and XGBoost models showed a significant drop in AUC during internal validation, indicating the need for further refinement and external validation. The binomial regression model served as a baseline for comparison, and its performance was assessed similarly.\n\nIn summary, the evaluation method involved a comprehensive internal validation process using bootstrapping, with performance metrics calculated for each model. The results highlight the strengths and limitations of the models, providing a foundation for future improvements and external validation.",
  "evaluation/measure": "In the evaluation of our machine learning models for chest pain stratification, several key performance metrics were reported to assess the effectiveness and reliability of the models. The primary metrics used were sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics are widely recognized and used in the literature for evaluating the performance of predictive models in medical contexts.\n\nFor the random forest model, a prediction cutoff value of 0.18 was used, resulting in a sensitivity of 13.92%, specificity of 93.66%, PPV of 20.55%, and NPV of 90.24%. The XGBoost model, which utilized all covariates, provided a better area under the curve (AUC) for all data combined compared to binomial regression. With a prediction cutoff value of 0.27, the XGBoost model achieved a sensitivity of 30.54%, specificity of 88.51%, PPV of 24.33%, and NPV of 91.34%. These metrics indicate that the XGBoost model performed better in terms of PPV compared to the random forest model and binomial regression.\n\nThe reported metrics are representative of those commonly used in the literature for evaluating machine learning models in medical risk stratification. Sensitivity and specificity provide insights into the model's ability to correctly identify positive and negative cases, respectively. PPV and NPV are crucial for understanding the likelihood of true positives and true negatives among the predicted outcomes. The inclusion of these metrics ensures a comprehensive evaluation of the models' performance, aligning with standard practices in the field.\n\nThe comparison of these models highlights the strengths and weaknesses of each approach, providing a clear picture of their potential applications in clinical decision-making. The XGBoost model, in particular, showed promise with its higher PPV, suggesting it could be a valuable tool for improving the positive predictive value in chest pain stratification while maintaining a high NPV. This set of metrics is essential for assessing the models' practical utility and their potential to enhance patient outcomes and reduce unnecessary healthcare costs.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, we focused on developing and validating our own machine learning models (MLMs) for risk stratification of abnormal cardiac stress tests (CST). We employed three different models: binomial regression (BR), random forest, and XGBoost.\n\nFor the random forest model, we used 25 trees in both training and testing phases to minimize overfitting. The XGBoost model was configured with specific hyperparameters, including a learning rate (eta) of 0.1, a maximum tree depth of 10, and 25 rounds to minimize overfitting. We did not compare these models against simpler baselines like logistic regression or decision trees, as our primary goal was to evaluate the performance of more complex MLMs.\n\nWe conducted internal validation using bootstrapping with replacement, splitting the data into training (75%) and testing (25%) sets during each iteration. This process was repeated 500 times to produce precise estimates and 95% confidence intervals. The prediction cutoff values were manually calibrated to optimize metrics such as sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) for each model.\n\nThe performance of our models was assessed using these metrics. For instance, the random forest model achieved a sensitivity of 13.92%, specificity of 93.66%, PPV of 20.55%, and NPV of 90.24% with a prediction cutoff value of 0.18. The XGBoost model, using a cutoff value of 0.27, yielded a sensitivity of 30.54%, specificity of 88.51%, PPV of 24.33%, and NPV of 91.34%. These results were compared internally among the models we developed, rather than against external benchmarks or simpler baselines.",
  "evaluation/confidence": "The evaluation of our models included bootstrapping with replacement for internal validation, which involved 500 iterations. This process helped to produce more precise estimates and allowed for the creation of 95% confidence intervals for the performance metrics. These confidence intervals provide a range within which the true performance metrics are likely to fall, giving an indication of the reliability and precision of our results.\n\nStatistical significance was assessed using an alpha criterion set at 0.05 for various tests, including the Hosmer-Lemeshow goodness-of-fit test for the binomial regression model. This ensures that the results are statistically significant and that the models are adequately fitting the data.\n\nThe performance metrics, such as sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV), were calculated for each model. The random forest and XGBoost models, in particular, showed significant improvements in certain metrics compared to the binomial regression model. For instance, the XGBoost model provided a better area under the receiver operating characteristic curve (AUC) for all data combined and yielded a higher sensitivity and PPV compared to the random forest model.\n\nThe internal validation process, which involved splitting the data into training and testing sets during each iteration of bootstrapping, helped to assess the generalizability of the models. The results were averaged across the iterations, providing a robust estimate of the models' performance.\n\nOverall, the confidence intervals and statistical significance tests provide a strong basis for claiming that the machine learning models, particularly the XGBoost model, are superior to the binomial regression model and other baselines in stratifying chest pain patients.",
  "evaluation/availability": "Not enough information is available."
}