{
  "publication/title": "Artificial-intelligence-driven discovery of prognostic biomarker for sarcopenia",
  "publication/authors": "The authors who contributed to the article are:\n\n- Heewon Chung\n- Yunju Jo\n- Dongryeol Ryu\n- Changwon Jeong\n- Seong-Kyu Choe\n- Jinseok Lee\n\nHeewon Chung and Yunju Jo contributed equally to this work.",
  "publication/journal": "Journal of Cachexia, Sarcopenia and Muscle",
  "publication/year": "2021",
  "publication/pmid": "34704369",
  "publication/pmcid": "PMC8718042",
  "publication/doi": "10.1002/jcsm.12840",
  "publication/tags": "- Sarcopenia\n- Muscle wasting\n- Artificial intelligence\n- Transcriptome\n- Diagnosis\n- Deep neural network\n- Gene expression\n- Biomarker discovery\n- Machine learning\n- Healthcare application",
  "dataset/provenance": "The dataset used in this study was sourced from the Gene Expression Omnibus of the National Center for Biotechnology Information. It is accessible under the accession number GSE111017. This dataset comprises a total of 118 subjects, with a mean age of 73.34 \u00b1 5.43 years. Among these subjects, 86 were classified as healthy, while 32 were diagnosed with sarcopenia. The subjects represent three different racial groups from distinct studies: 40 subjects from the Hertfordshire Sarcopenia Study (HSS), 39 from the Jamaica Sarcopenia Study (JSS), and 39 from the Singapore Sarcopenia Study (SSS). The transcriptome analysis within this dataset includes information on 17,339 genes, which are potential biomarkers for diagnosing sarcopenia. For the purposes of this study, the data was segmented into training and testing datasets in a stratified manner, ensuring representation from each racial group and outcome category. The training dataset consisted of 94 subjects (69 normal and 25 sarcopenic), while the testing dataset included 24 subjects (17 normal and 7 sarcopenic). The testing dataset was isolated and used solely to evaluate the performance of the proposed AI model.",
  "dataset/splits": "The dataset was divided into two main splits: a training dataset and a testing dataset. The training dataset consisted of 94 subjects, with 69 being normal and 25 being sarcopenic. The testing dataset was isolated and comprised 24 data points, with 17 normal and 7 sarcopenic subjects. This testing dataset was used solely to evaluate the performance of the proposed AI model. The training dataset underwent a 5-fold stratified cross-validation process to ensure robust model training and evaluation.",
  "dataset/redundancy": "The dataset used in this study was split into a training set and a testing set. The training dataset consisted of 94 subjects, with 69 normal and 25 sarcopenic cases. The testing dataset was smaller, comprising 24 subjects, with 17 normal and 7 sarcopenic cases. The testing dataset was isolated and used solely to evaluate the performance of the proposed AI model, ensuring that it was independent of the training dataset.\n\nTo manage missing features in the dataset, the mean value from the training dataset for each feature was calculated and used to replace any missing values in both the training and testing datasets. This approach helped to maintain consistency and completeness in the data. Additionally, the dataset was standardized, which is a common requirement for machine learning algorithms. Standardization involved adjusting the data distribution of each feature to have a mean of zero and a standard deviation of one. This process was applied to both the training and testing datasets to ensure uniformity.\n\nThe distribution of the dataset, with a focus on gene information, was visualized in supplementary figures. For instance, Figure S1 shows histograms for the number of available gene information across different subjects, indicating variability in the completeness of gene data. This visualization helps in understanding the data's structure and the handling of missing values.\n\nThe study also included a comparison of the performance of different AI models, such as random forest (RF), extreme gradient boosting (XGBoost), and adaptive boosting (AdaBoost), using cross-validation techniques. The models were evaluated based on metrics like sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristics (AUROC). The results demonstrated the effectiveness of the proposed AI model in diagnosing sarcopenia accurately.\n\nIn summary, the dataset was carefully split and preprocessed to ensure independence between the training and testing sets. The handling of missing data and standardization processes were crucial in preparing the dataset for machine learning algorithms. The study's findings highlight the importance of these steps in achieving reliable and accurate model performance.",
  "dataset/availability": "The data used in this study is publicly available. The transcriptomic dataset was obtained from the Gene Expression Omnibus of the National Center for Biotechnology Information under the accession number GSE111017. This dataset includes information from 118 subjects, comprising both healthy individuals and those diagnosed with sarcopenia across three different ethnic groups.\n\nThe dataset was segmented into training and testing datasets in a stratified manner based on race and outcome. Specifically, 94 subjects were used for the training dataset (69 normal and 25 sarcopenic), and 24 subjects were used for the testing dataset (17 normal and 7 sarcopenic). The testing dataset was isolated and used solely to evaluate the performance of the proposed AI model.\n\nThe data preprocessing steps, including handling missing features and standardization, were applied to both the training and testing datasets. The standardization process involved calculating the mean and standard deviation for each feature from the training dataset and then applying these values to both datasets. This ensures that the data distribution for each feature has a mean of zero and a standard deviation of one, which is a typical requirement for machine learning algorithms.\n\nThe study was approved by the Institutional Review Board of Wonkwang University (WKIRB-202108-SB-060), ensuring that all ethical guidelines were followed. The data is available for public access, allowing other researchers to validate and build upon the findings presented in this study.",
  "optimization/algorithm": "The optimization algorithm used in our study is the ADAM optimizer, which is a popular choice for training deep learning models. ADAM is not a new algorithm; it is a well-established optimization technique known for its efficiency and effectiveness in updating model weights during training. It combines the advantages of two other extensions of stochastic gradient descent, namely AdaGrad and RMSProp.\n\nThe ADAM optimizer was chosen for its ability to handle sparse gradients on noisy problems, which is beneficial for our dataset. It adapts the learning rate for each parameter, providing a balance between the speed of convergence and the stability of the training process.\n\nThe reason the ADAM optimizer is not published in a machine-learning journal is that it is a widely recognized and extensively used algorithm in the field of machine learning and deep learning. It was introduced in a seminal paper by Diederik P. Kingma and Jimmy Ba in 2014, and since then, it has become a standard tool in the machine learning community. Given its widespread use and acceptance, there is no need for further publication in machine-learning journals specifically for the ADAM optimizer itself. Instead, it is commonly referenced and utilized in various research studies across different domains.",
  "optimization/meta": "The model employs a meta-predictor approach, utilizing data from other machine-learning algorithms as input. Specifically, the feature importance values from three different algorithms\u2014Random Forest (RF), Extreme Gradient Boosting (XGBoost), and Adaptive Boosting (AdaBoost)\u2014were averaged and normalized to determine the most significant features. This process involved setting specific hyperparameters for each algorithm to ensure optimal performance. For instance, the RF algorithm was configured with 100 tree estimators, a maximum depth of four, and a maximum of five features. Similarly, XGBoost was set with a maximum depth of four, a learning rate of 0.1, and 100 tree estimators, among other parameters. AdaBoost was configured with 200 tree estimators and a learning rate of 0.2.\n\nThe training data for these algorithms was independent, as indicated by the use of 5-fold stratified cross-validation repeated 10 times. This method ensures that the data is split into training and validation sets in a way that maintains the proportion of different classes, thereby providing a robust evaluation of the model's performance. The final ranked feature importance values were derived by averaging the importance values from the three classifiers, which were then used to select the top features for the deep neural network (DNN) model. This DNN model, named DSnet-v1, was developed using the top 27 features identified through this meta-predictor approach. The independence of the training data is crucial for the reliability and generalizability of the model's predictions.",
  "optimization/encoding": "The data used for the machine-learning algorithm consisted of gene expression information from 17,339 genes. Initially, missing gene information was handled by calculating the mean value for each feature from the training dataset and replacing any missing values in both the training and testing datasets with these mean values. This step ensured that the dataset was complete and ready for further processing.\n\nFollowing this, the dataset was standardized. Standardization is a common preprocessing step in machine learning that transforms the data distribution of each feature to have a mean of zero and a standard deviation of one. This process is crucial for algorithms that are sensitive to the scale of the input data, as it helps to improve the convergence and performance of the model. The standardization formula used was:\n\nData standard = (Data - mean(train)) / SD(train)\n\nwhere mean(train) and SD(train) represent the mean and standard deviation values, respectively, for each feature from the training dataset. This standardization was applied uniformly to both the training and testing datasets.\n\nThe standardized data was then used as input for the machine-learning models, including the deep neural network (DNN) and other algorithms like random forest (RF), extreme gradient boosting (XGBoost), and adaptive boosting (AdaBoost). The preprocessing steps ensured that the data was in a suitable format for these algorithms to learn effectively from the gene expression patterns and make accurate predictions regarding sarcopenia diagnosis.",
  "optimization/parameters": "The model utilizes 27 input parameters, which were selected through a feature importance analysis. This analysis involved three different algorithms: random forest (RF), extreme gradient boosting (XGBoost), and adaptive boosting (AdaBoost). Each algorithm was used to rank the importance of 17,339 features. The top 27 features were then identified by averaging and normalizing the importance values obtained from the three models. This process ensured that the most relevant genes were included in the final model, enhancing its diagnostic accuracy for sarcopenia. The selection of these 27 features was further validated through cross-validation, which confirmed their significance in improving the model's performance metrics such as sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristics curve.",
  "optimization/features": "In the optimization process of our AI model, we utilized a total of 27 features as input. These features were selected through a rigorous feature selection process. We employed three different algorithms\u2014random forest, extreme gradient boosting, and adaptive boosting\u2014to determine the importance of each of the 17,339 genes in the dataset. The feature importance values from these algorithms were averaged and normalized to rank the features. This ranking helped us identify the top 27 features that significantly contributed to the diagnosis of sarcopenia.\n\nThe feature selection was performed using only the training dataset. This approach ensured that the testing dataset remained isolated and was used solely for evaluating the performance of the proposed AI model. By focusing on the training dataset for feature selection, we maintained the integrity of the testing process and avoided any potential bias that could arise from using the testing data in the model development phase.",
  "optimization/fitting": "The fitting method employed for the deep neural network (DNN) model, named DSnet-v1, involved a careful balance to avoid both overfitting and underfitting. The model was trained using a dataset comprising 94 subjects for training and 24 for testing, with 17,339 initial features. To manage the high dimensionality, feature selection was performed using random forest (RF), extreme gradient boosting (XGBoost), and adaptive boosting (AdaBoost) algorithms. The top 27 features were selected based on their importance values, averaged across the three models.\n\nTo prevent overfitting, several techniques were utilized. Dropout layers with a rate of 0.5 were incorporated into the fully connected (FC) layers of the DNN. This technique randomly sets a fraction of input units to zero during training, which helps to prevent the model from becoming too reliant on specific features. Additionally, the model was evaluated using 5-fold stratified cross-validation, ensuring that the performance metrics were robust and not dependent on a particular split of the data. The use of a binary cross-entropy cost function and the ADAM optimizer with a learning rate of 0.0001 further aided in stabilizing the training process.\n\nUnderfitting was addressed by carefully tuning the hyperparameters and the architecture of the DNN. The model was designed with up to five hidden layers, and the depth of each layer was optimized. The input layer consisted of the top 27 features, and the hidden layers were configured with 27 and 8 nodes, respectively. The learning rate was adjusted to 0.0005 and 0.0001, and a batch size of 64 was used during training. These adjustments ensured that the model had sufficient capacity to learn the underlying patterns in the data without being too simplistic.\n\nThe performance of the model was evaluated using metrics such as sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristics (AUROC). The results showed that the model achieved high accuracy metrics, indicating that it was neither overfitting nor underfitting the data. The final model, DSnet-v1, demonstrated superior performance compared to other external AI models, including RF, XGBoost, and AdaBoost.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our deep neural network (DNN) model, DSnet-v1. One of the key methods used was dropout regularization. Dropout is a technique where, during training, a random subset of neurons is temporarily removed from the network. This forces the network to learn redundant representations and prevents it from becoming too reliant on any single neuron, thereby reducing overfitting. We applied dropout to the fully connected (FC) layers with a dropout rate of 0.5, meaning that 50% of the neurons were randomly dropped during each training iteration.\n\nAdditionally, we utilized cross-validation to evaluate the model's performance. Specifically, we performed 5-fold stratified cross-validation, which helps in assessing the model's generalization ability by training and validating it on different subsets of the data. This process ensures that the model is not overly fitted to a particular subset of the data and can perform well on unseen data.\n\nFurthermore, we standardized the dataset, which is a common preprocessing step in machine learning. Standardization involves scaling the features to have a mean of zero and a standard deviation of one. This helps in stabilizing the training process and can improve the convergence of the optimization algorithm, thereby reducing the risk of overfitting.\n\nBy combining these techniques\u2014dropout regularization, cross-validation, and data standardization\u2014we aimed to build a robust and generalizable model for the diagnosis of sarcopenia.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed the ADAM optimizer with a binary cross-entropy cost function. The learning rates were adjusted to 0.0005 and 0.0001, and a batch size of 64 was used. For the deep neural network (DNN), we investigated up to five hidden layers, with each layer's depth (nodes) up to the previous layer's depth. Dropout rates ranging from 0 to 0.5 were applied to the fully connected (FC) layers. The final model, DSnet-v1, is a four-layer DNN comprising an input layer, two FC layers as hidden layers, and an output layer. The input layer uses the top 27 features, and the FC layers have 27 and 8 nodes, respectively, with a dropout rate of 0.5.\n\nThe implementation details, including the versions of software used, are also provided. We used TensorFlow (version: tensorflow-gpu 2.0), NumPy (version: 1.16.4), Pandas (version: 0.25.3), and Matplotlib. The code and models are not explicitly made available in the publication, but the methods and configurations are thoroughly described, allowing for replication. The publication itself is open access, and the methods section provides all necessary details for reproducing the experiments. However, specific model files and optimization parameters are not directly downloadable from the publication. For access to the code or further details, readers may need to contact the authors directly.",
  "model/interpretability": "The model developed, DSnet-v1, is not entirely a black-box model. While it utilizes a deep neural network (DNN) for its core functionality, several steps were taken to ensure interpretability.\n\nFirstly, feature importance was determined using multiple machine learning models, including Random Forest (RF), XGBoost, and AdaBoost. By averaging the importance values from these models, the top 27 features were identified. This process provides insight into which genes are most influential in diagnosing sarcopenia.\n\nAdditionally, the model's performance was evaluated using various metrics such as sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristics (AUROC). These metrics help in understanding how well the model generalizes to new data and its reliability.\n\nThe use of a DNN with a limited number of layers (four layers) and nodes also contributes to interpretability. The input layer consists of the top 27 features, and the hidden layers have 27 and 8 nodes, respectively. This structure allows for a clearer understanding of how the input features contribute to the final output.\n\nFurthermore, the model's performance was compared with other external AI models like RF, XGBoost, and AdaBoost. This comparison provides context and helps in understanding the strengths and weaknesses of DSnet-v1.\n\nIn summary, while DSnet-v1 is a complex model, efforts were made to ensure it is not a black-box. The use of feature importance, performance metrics, and a relatively simple DNN structure all contribute to its interpretability.",
  "model/output": "The model developed is a classification model. It is designed to diagnose sarcopenia, a condition characterized by loss of muscle mass and strength. The model outputs the probability of a patient being sarcopenic, which is a binary classification problem where the output is either 1 (sarcopenia) or 0 (normal).\n\nThe model uses a deep neural network (DNN) architecture, specifically a four-layer DNN named DSnet-v1. This DNN takes as input the top 27 features, which are genes ranked by their importance in diagnosing sarcopenia. The output layer of the DNN uses a sigmoid activation function to provide the probability of a patient being sarcopenic.\n\nThe performance of the model is evaluated using metrics such as sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristics (AUROC). These metrics indicate how well the model can classify patients as either having sarcopenia or not.\n\nThe model was trained using the ADAM optimizer and the binary cross-entropy cost function, which are suitable for binary classification tasks. The training process involved adjusting the learning rate and using a batch size of 64. The model's performance was validated through 5-fold stratified cross-validation and tested on an isolated testing dataset, demonstrating high accuracy and reliability in diagnosing sarcopenia.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the AI model DSnet-v1 is not publicly released. However, the model is accessible through a web application deployed on a public server. Users can input gene information to obtain a diagnosis result for sarcopenia. The web application is available at http://sarcopeniaAI.ml/. The application does not store any private information entered by users, ensuring data privacy and security. The entered information is immediately deleted once the diagnosis result is derived. The web application provides a user-friendly interface where individuals can input their quantized gene information and receive the probability of sarcopenia. This deployment allows unrestricted access to the model for diagnosing sarcopenia, facilitating its use by healthcare providers and researchers.",
  "evaluation/method": "The evaluation of the AI models, specifically DSnet-v1, involved several rigorous methods to ensure robustness and accuracy. Initially, the models were trained using the ADAM optimizer and binary cross-entropy cost function, with learning rates adjusted to 0.0005 and 0.0001, and a batch size of 64 on an NVIDIA GeForce GTX 1080 Ti GPU.\n\nFor performance evaluation, we utilized accuracy metrics such as sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristics (AUROC). The training dataset underwent 5-fold stratified cross-validation to assess the model's performance. Subsequently, an isolated testing dataset was used to independently evaluate the diagnostic performance.\n\nTo compare DSnet-v1 with other AI models, we separately trained and evaluated models using Random Forest (RF), XGBoost, and AdaBoost. Each of these models underwent hyperparameter searches to optimize their performance.\n\nAdditionally, we conducted feature selection and cross-validation to identify the top 27 features from a pool of 17,339 features. The importance of these features was ranked using the combined results from RF, XGBoost, and AdaBoost. The cross-validation performance was analyzed using the aforementioned metrics, and the results indicated that the accuracy metrics improved as the number of selected features increased up to 27. Beyond this point, the accuracy metrics began to decline.\n\nThe final evaluation on the isolated testing dataset (n = 4) showed that DSnet-v1 achieved a sensitivity of 1.00, specificity of 0.94, accuracy of 0.96, balanced accuracy of 0.97, and an AUROC of 0.99. These results demonstrated that DSnet-v1 outperformed the other AI models in terms of accuracy, balanced accuracy, and AUROC.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our AI models in diagnosing sarcopenia. The primary metrics we reported include sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristics curve (AUROC). These metrics provide a holistic view of the model's performance, ensuring that we capture both the true positive and true negative rates, as well as the overall correctness and balance of the predictions.\n\nSensitivity, also known as recall, measures the proportion of actual positives that are correctly identified by the model. Specificity, on the other hand, measures the proportion of actual negatives that are correctly identified. Accuracy provides an overall measure of the model's correctness by calculating the proportion of true results (both true positives and true negatives) among the total number of cases examined. Balanced accuracy is particularly useful when dealing with imbalanced datasets, as it takes into account both sensitivity and specificity, providing a more balanced view of the model's performance.\n\nThe AUROC is a widely used metric that summarizes the model's ability to distinguish between positive and negative classes across all possible classification thresholds. It provides a single scalar value that represents the model's performance, making it easy to compare different models.\n\nThese metrics are representative of the standards used in the literature for evaluating machine learning models, particularly in the context of medical diagnostics. They allow for a thorough assessment of the model's performance, ensuring that it is robust and reliable for clinical use. By reporting these metrics, we aim to provide transparency and reproducibility in our evaluation process, enabling other researchers to compare and build upon our work.",
  "evaluation/comparison": "To evaluate the performance of our proposed AI model, DSnet-v1, we conducted a comprehensive comparison with other established machine learning models. We trained and evaluated models using random forest (RF), extreme gradient boosting (XGBoost), and adaptive boosting (AdaBoost) algorithms. These models were chosen for their robustness and widespread use in similar diagnostic tasks.\n\nFor the comparison, we utilized a 5-fold stratified cross-validation approach on the training dataset. This method ensures that each fold is representative of the overall dataset, providing a reliable estimate of model performance. The evaluation metrics included sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristic curve (AUROC). These metrics offer a holistic view of the models' diagnostic capabilities.\n\nIn addition to cross-validation, we independently evaluated the models using an isolated testing dataset. This step is crucial for assessing the generalizability of the models to new, unseen data. The results from the testing dataset further validated the superior performance of DSnet-v1 compared to the other models.\n\nThe comparison revealed that DSnet-v1 consistently outperformed the RF, XGBoost, and AdaBoost models across all evaluation metrics. For instance, in the testing dataset, DSnet-v1 achieved a sensitivity of 1.00, specificity of 0.94, accuracy of 0.96, balanced accuracy of 0.97, and an AUROC of 0.99. These results highlight the effectiveness of our deep neural network (DNN) architecture in diagnosing sarcopenia.\n\nFurthermore, we deployed DSnet-v1 on a public web server, making it accessible for practical use. The web application allows users to input gene information and receive immediate diagnosis results, ensuring privacy and security by not storing any personal information.\n\nIn summary, the comparison with publicly available methods and simpler baselines demonstrated the superior diagnostic performance of DSnet-v1. This validation underscores the potential of our model to aid healthcare providers in the early diagnosis and treatment of sarcopenia.",
  "evaluation/confidence": "The evaluation of our AI model, DSnet-v1, includes several performance metrics with associated confidence intervals, providing a clear understanding of the model's reliability. We utilized 5-fold stratified cross-validation to assess the model's performance, which helps in understanding the variability and stability of the results.\n\nThe metrics evaluated include sensitivity, specificity, accuracy, balanced accuracy, and the area under the receiver operating characteristics (AUROC). Each of these metrics is presented with mean values and standard deviations, indicating the confidence intervals. For instance, the cross-validation results for DSnet-v1 show a sensitivity of 0.8772 \u00b1 0.1072, specificity of 0.9825 \u00b1 0.0317, accuracy of 0.9583 \u00b1 0.0439, and balanced accuracy of 0.9286 \u00b1 0.0596. These intervals provide a measure of the model's performance variability.\n\nIn the test dataset, DSnet-v1 demonstrated a sensitivity of 1.0000, specificity of 0.9412, accuracy of 0.9583, balanced accuracy of 0.9706, and an AUROC of 0.9916. These results are compared against other models like Random Forest (RF), XGBoost, and AdaBoost, where DSnet-v1 consistently outperforms them across all metrics. The statistical significance of these results is evident from the performance gaps, particularly in the AUROC, where DSnet-v1 achieves a value of 0.9916, significantly higher than the other models.\n\nThe use of cross-validation and the presentation of performance metrics with confidence intervals ensure that the results are statistically significant and reliable. This rigorous evaluation process confirms that DSnet-v1 is superior to other models and baselines, providing a robust solution for the diagnosis of sarcopenia.",
  "evaluation/availability": "Not applicable."
}