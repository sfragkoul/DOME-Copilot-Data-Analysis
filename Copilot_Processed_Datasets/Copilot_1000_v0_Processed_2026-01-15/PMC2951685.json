{
  "publication/title": "Variable Selection and Updating In Model-Based Discriminant Analysis for High Dimensional Data with Food Authenticity Applications",
  "publication/authors": "The authors who contributed to this article are Murphy, Fraley, Raftery, and Scrucca. Murphy is the lead author, and the contributions of the other authors are as follows:\n\nFraley and Raftery are known for their work on model-based clustering, density estimation, and discriminant analysis. They developed the mclust package for R, which was used in this paper. Scrucca contributed to the development of the mclust software and has co-authored several papers with Fraley and Raftery on this topic.",
  "publication/journal": "Annals of Applied Statistics",
  "publication/year": "2010",
  "publication/pmid": "20936055",
  "publication/pmcid": "PMC2951685",
  "publication/doi": "10.1214/09-AOAS279",
  "publication/tags": "- Food authenticity studies\n- Headlong search\n- Model-based discriminant analysis\n- Normal mixture models\n- Semi-supervised learning\n- Updating classification rules\n- Variable selection\n- Random Forests\n- AdaBoost\n- Bayesian Multinomial Regression\n- Transductive SVMs\n- Spectroscopy\n- Classification performance\n- High-dimensional data\n- Multiclass datasets\n- Food fraud detection\n- Discriminant analysis methods\n- Spectral analysis\n- Near-infrared spectroscopy\n- Visible spectroscopy",
  "dataset/provenance": "The datasets used in our study are from food authenticity studies, specifically focusing on classifying meats into species and olive oils into geographic origins. The data consists of combined visible and near-infrared spectroscopic measurements from food samples. These measurements were collected using an NIRSystems 6500 instrument over the wavelength range of 400\u20132498 nm at 2 nm intervals, resulting in 1050 reflectance values for each food sample.\n\nThe meat samples were classified into five species: beef, chicken, lamb, pork, and turkey. For each meat sample, twenty-five separate scans were collected during a single passage of the spectrophotometer and averaged. The mean spectrum of a reference ceramic tile was then recorded and subtracted from the mean spectrum. This process was similarly applied to the olive oil data, although fewer scans were used.\n\nThe data collection process and details are thoroughly documented in previous works by McElhinney et al. (1999) and Downey et al. (2003). These datasets have been used in prior analyses, including those by Dean et al. (2006) and McElhinney et al. (1999), providing a basis for comparison with our methods. The reflectance values in the visible and near-infrared regions are produced by vibrations in the chemical bonds of the substances being analyzed, making the data highly correlated due to overlapping broad peaks and combinations of overtones. This complexity highlights the need for effective variable selection methods to identify the most informative wavelengths for authentication purposes.",
  "dataset/splits": "In our study, we utilized 50 random splits of the data for both the meat classification and olive oil classification problems. For each split, 50% of the data was designated as training data, and the remaining 50% was used as test data. This approach ensured that our models were trained and evaluated on diverse subsets of the data, providing a robust assessment of their classification performance.\n\nThe distribution of data points in each split was balanced, with an equal number of samples allocated to the training and test sets. This balanced split helped to mitigate any potential bias and ensured that the models were generalizable to new, unseen data. The use of multiple random splits also allowed us to assess the stability and consistency of the selected wavelengths across different subsets of the data.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm presented in our work is a variable selection method designed for high-dimensional data, specifically tailored for food authenticity datasets. The algorithm falls under the class of search algorithms, particularly a variant of the greedy search algorithm, which we refer to as the \"headlong search\" method.\n\nThe headlong search method is not entirely new but builds upon existing concepts in local search algorithms. It incorporates elements from the \"first-improvement\" moves used in local search, as discussed in the literature. The primary innovation lies in its application to variable selection in the context of discriminant analysis for food authenticity.\n\nThe reason this algorithm was not published in a machine-learning journal is that the primary focus of our work is on the application of this method to food authenticity datasets. The algorithm's development and evaluation were driven by the specific challenges and characteristics of these datasets, which are high-dimensional and involve a large number of variables, most of which are not useful for classification. The method's performance was compared against established classification techniques from statistics and machine learning, demonstrating significant improvements in classification accuracy and variable reduction.\n\nThe headlong search method operates by selecting variables based on their evidence for grouping versus no grouping, using the Bayesian Information Criterion (BIC) difference. The algorithm iteratively adds and removes variables based on a pre-specified evidence threshold (min.evidence), aiming to optimize the classification performance while reducing the number of variables. This approach ensures that the selected variables are both relevant and efficient for the classification task.\n\nIn summary, while the headlong search method draws from existing search algorithm concepts, its application and adaptation to food authenticity datasets represent a novel contribution. The focus on practical application and the significant improvements in classification performance justify its presentation in the context of food authenticity research.",
  "optimization/meta": "The model discussed in this publication does not function as a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it employs a variable selection algorithm with an updating procedure for classification tasks, particularly in high-dimensional food authenticity datasets. The methods compared include Random Forests, AdaBoost, Bayesian Multinomial Regression, and Transductive SVMs, but these are used as standalone classifiers rather than components of a meta-predictor.\n\nThe variable selection algorithm focuses on identifying the most relevant wavelengths from spectral data, reducing the number of variables needed for classification. This approach aims to enhance classification performance by minimizing noise from irrelevant variables. The updating procedure further improves the model by incorporating unlabeled data into the estimation method.\n\nThe training data for the variable selection algorithm and the updating procedure are independent of the outputs of other machine-learning methods. The comparisons with other classifiers are made to demonstrate the superior performance of the proposed method, but these comparisons do not involve the use of these classifiers' outputs as inputs to the variable selection algorithm.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, the data were split into labeled and unlabeled sets, with 50% of the data used for each category. This split was performed 50 times randomly to ensure robustness in the results. The labeled data were used to train the model, while the unlabeled data were incorporated through an updating procedure to enhance the classification performance.\n\nThe variable selection process was crucial in preprocessing. It involved a headlong search strategy, which considered the Bayesian Information Criterion (BIC) differences to determine the evidence for grouping versus no grouping. The first variable selected had the greatest BIC difference, and subsequent variables were chosen based on a predefined minimum evidence threshold. This approach ensured that only the most relevant variables were included, reducing the dimensionality from over a thousand to fewer than thirty.\n\nThe initial ordering of variables was based on their original BIC differences at the univariate addition stage. Experiments with different orderings, such as increasing and decreasing wavelengths, showed that while the classification performance was not sensitive to the initial ordering, the selected variables did depend on it. This indicates that the method is robust but also adaptable to different data characteristics.\n\nThe preprocessing also involved handling high-dimensional data, which is common in food authenticity datasets. The method effectively reduced the number of variables, making the data more manageable and improving the classification results. This reduction is particularly beneficial for developing authenticity sensors that use reflectance values over a carefully selected subset of the near-infrared and visible spectral range.\n\nOverall, the data encoding and preprocessing steps were designed to enhance the efficiency and accuracy of the machine-learning algorithm, ensuring that only the most relevant variables were used for classification.",
  "optimization/parameters": "In the optimization process, the number of parameters, p, used in the model varies depending on the specific application and the stage of the variable selection algorithm. The algorithm begins by selecting a single wavelength, specifically 626 nm, and then iteratively adds more wavelengths based on the Bayesian Information Criterion (BIC) difference. This process continues until a total of thirteen wavelengths are selected. The chosen wavelengths are spread out mainly in the visible region (400\u2013800 nm), with some wavelengths also selected in the near-infrared region. The selection of these wavelengths is driven by their importance in classifying samples into different species, with many of the chosen wavelengths corresponding to different forms of myoglobin and other meat constituents.\n\nThe selection of the number of parameters is not predetermined but rather determined through an iterative process that aims to optimize the model's performance. This approach ensures that the model includes the most relevant wavelengths for accurate classification, balancing between model complexity and predictive accuracy. The final set of parameters includes between 13 and 19 wavelengths, depending on the specific dataset and the results of the variable selection process.",
  "optimization/features": "In our study, we utilized a variable selection and updating method to determine the most relevant input features for classification tasks. The number of features used as input varied depending on the specific problem and the aggregation level applied.\n\nFor the olive oil classification problem, we restricted the maximum number of selected wavelengths to six to avoid degeneracies. This was done to ensure that the model remained robust and generalizable. The variable selection process was performed using the training set only, ensuring that the selected features were not influenced by the test data.\n\nThe wavelengths chosen in the olive oil classification problem were identified through a process that involved 50 random splits of the data. The height of the bars in the corresponding figure indicates how many times each wavelength was chosen across these splits.\n\nFor the five meat classification problem, a similar approach was taken, with the wavelengths chosen being those that were most frequently selected across 50 random splits of the data.\n\nThe classification performance was evaluated for different aggregation levels, which involved grouping adjacent wavelengths. The classification error varied with the aggregation level, with the lowest error observed when no aggregation was applied.\n\nIn summary, feature selection was performed using the training set only, and the number of input features was determined based on the specific requirements of each classification problem. The aggregation level also played a role in determining the final set of input features used for classification.",
  "optimization/fitting": "The fitting method employed in our study involved a variable selection and updating approach, which inherently addresses the issue of overfitting by selecting a subset of relevant wavelengths from a much larger set. This method ensures that the number of parameters used in the model is significantly reduced, thereby mitigating the risk of overfitting.\n\nIn the meat classification problem, between 13 and 21 wavelengths were chosen for classification purposes. For the olive oil classification problem, between 6 and 29 wavelengths were selected, with a mean of 15 wavelengths chosen. This selective process helps in focusing on the most informative spectral regions, reducing the complexity of the model and preventing overfitting.\n\nTo further ensure that overfitting was ruled out, we used cross-validation techniques. Specifically, we employed 50 random splits of the data into training and test sets, where 50% of the data was used for training and the remaining 50% for testing. This approach allowed us to evaluate the model's performance on unseen data, providing a robust estimate of its generalization capability.\n\nAdditionally, the choice of covariance structures, such as the VEV (Variable Error Variance) for meat classification and EEE (Equal Error Variance) for olive oil classification, helped in capturing the underlying patterns in the data without overfitting. These structures were selected based on their ability to provide the best classification rates across multiple runs.\n\nUnderfitting was addressed by ensuring that the selected wavelengths were sufficient to capture the essential features of the data. The stability of the selected wavelengths across different random splits of the data indicated that the model was not too simplistic. Furthermore, the use of variable selection and updating allowed the model to adapt and improve iteratively, ensuring that important spectral regions were not overlooked.\n\nIn summary, the fitting method employed in our study effectively balanced the trade-off between overfitting and underfitting by using a variable selection and updating approach, cross-validation, and appropriate covariance structures. This ensured that the models were both robust and generalizable.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our classification models. One of the key methods used was variable selection, which helps in identifying the most relevant wavelengths for classification. This process not only simplifies the model but also reduces the risk of overfitting by excluding irrelevant or noisy variables.\n\nAdditionally, we implemented an updating method that further refined the variable selection process. This approach involved iteratively updating the selected variables based on their performance in multiple random splits of the data. By doing so, we ensured that the chosen variables were consistently important across different subsets of the data, thereby enhancing the model's generalization capability.\n\nWe also compared our variable selection and updating method with other classification techniques, such as Random Forests, AdaBoost, and Bayesian Multinomial Regression. The results demonstrated that our method achieved lower misclassification rates, indicating its effectiveness in preventing overfitting and improving classification performance.\n\nMoreover, we used cross-validation to tune the parameters of our models, including the prior variance values for Bayesian Multinomial Regression and the parameters for Transductive SVMs. This rigorous tuning process helped in selecting the optimal parameters that minimized the risk of overfitting and maximized the model's predictive accuracy.\n\nIn summary, our study incorporated variable selection, updating methods, and parameter tuning through cross-validation to prevent overfitting and enhance the reliability of our classification models. These techniques collectively contributed to the robust performance of our models in classifying olive oil and meat samples.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the publication. Specifically, for the Random Forests and AdaBoost implementations in R, the default settings were utilized. For Bayesian Multinomial Regression, cross-validation was employed to select the prior variance values from a predefined set. In the case of Transductive SVM analysis, the UniverSVM software version 1.1 was used with a linear kernel and specific parameters (c, s, z) = (100, \u22120.3, 0.1), which were determined to yield the best classifications after considering other parameter values.\n\nThe model files and optimization schedules are not explicitly detailed in the publication, as the focus was on the methodologies and results rather than the specific implementation details. However, the software versions and parameters used are clearly stated, allowing for reproducibility of the experiments.\n\nRegarding the availability and licensing, the software tools mentioned, such as R packages and UniverSVM, are typically open-source and freely available. For instance, the R packages randomForest and adabag are part of the Comprehensive R Archive Network (CRAN), which provides open access to a wide range of statistical and graphical methods. Similarly, the UniverSVM software is available through the Machine Learning Open Source Software (MLOSS) repository, which also offers open access to its tools.\n\nIn summary, while the hyper-parameter configurations and optimization parameters are reported, the specific model files and optimization schedules are not detailed. The software tools used are open-source and freely available, ensuring that the methods can be replicated by other researchers.",
  "model/interpretability": "The model presented in this publication is not a black-box model. It is designed to be transparent and interpretable, particularly in the context of food authenticity studies. The model-based discriminant analysis method includes a variable selection process, which is a key feature that enhances its interpretability. This process identifies which variables are most meaningful for classification purposes, providing insights into the specific features that contribute to the model's decisions.\n\nFor instance, in the analysis of homogenized meat data, the chosen wavelengths for classification were recorded and analyzed. It was found that a significant proportion of these wavelengths fell within the visible spectrum (400 nm\u2013800 nm), with specific wavelengths corresponding to different forms of myoglobin. This detailed information allows for a clear understanding of which spectral features are important for distinguishing between different types of meat. Additionally, the model's ability to separate red and white meats with zero error further demonstrates its transparency and reliability.\n\nThe headlong search strategy used for variable selection is efficient and achieves excellent classification performance. This strategy not only improves the model's accuracy but also ensures that the selected variables are relevant and informative. The transparency of the model is further supported by the fact that it can be fitted in a semi-supervised manner using both labeled and unlabeled data, which enhances its robustness and applicability in real-world scenarios.",
  "model/output": "The model discussed in this publication is primarily focused on classification tasks. Various classification techniques were employed and compared, including Random Forests, AdaBoost, Bayesian Multinomial Regression, and Transductive Support Vector Machines. The results presented in tables such as Table 3, Table 4, Table 5, and Table 6 demonstrate the performance of these classification methods on different datasets, such as homogenized meat data and olive oil groups.\n\nThe classification performance was evaluated using metrics like classification rates and misclassification tables. For instance, the variable selection and updating method showed improved classification rates compared to previous analyses, particularly in distinguishing between different meat types and olive oil groups. The chosen wavelengths in the spectra were also analyzed to understand which parts of the spectrum were important for classifying samples into different species or groups.\n\nIn summary, the model's output is centered around classification results, highlighting the effectiveness of different methods in accurately categorizing samples into predefined groups.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for some of the algorithms and methods discussed in this publication is publicly available. Specifically, the `mclust` package, which is used for model-based clustering, normal mixture modeling, and related tasks, is available in R. This package can be accessed and used under the terms of the GNU General Public License. Additionally, the `adabag` package, which implements the AdaBoost.M1 and Bagging algorithms, is also available in R. The `randomForest` package, used for random forests, is another resource that can be accessed publicly. For Bayesian Multinomial Regression, the `BMR` software is available online, and it can be used following the guidelines provided on the associated website. These resources enable researchers to replicate and build upon the methods described in this work.",
  "evaluation/method": "The evaluation of the proposed methodology involved applying it to two food authenticity datasets. For each dataset, the data was split such that 50% was used as labeled data and the remaining 50% as unlabeled data. This process was repeated for 50 random splits of the labeled and unlabeled data. The mean and standard deviation of the classification rates were then computed to assess the performance.\n\nThe results obtained from this evaluation were compared against previously reported performance results for these datasets, as well as several widely used alternative techniques. These techniques included Random Forests, AdaBoost, Bayesian Multinomial Regression, and Transductive Support Vector Machines. The comparison highlighted the effectiveness of the proposed method in achieving superior classification performance.\n\nAdditionally, the evaluation considered the impact of combining certain groups, such as chicken and turkey into a poultry group, on the classification performance. This adjustment was made to further validate the robustness and adaptability of the method across different data configurations. The results demonstrated that the method maintained high accuracy even with such modifications, underscoring its reliability in various scenarios.",
  "evaluation/measure": "In the evaluation of our methods, we primarily report the misclassification rate as our performance metric. This metric is presented as a percentage, indicating the proportion of incorrectly classified samples out of the total samples. We also provide the standard deviation of the misclassification rate to give an idea of the variability in performance across different random splits of the data.\n\nThe misclassification rate is a commonly used metric in the literature for evaluating classification performance, making our reported metrics directly comparable to previous analyses. For instance, our results are compared against those from Dean et al. (2006) and McElhinney et al. (1999), who also reported misclassification rates for similar datasets. This allows for a clear and straightforward comparison of the effectiveness of different methods.\n\nIn addition to the misclassification rate, we also examine the specific misclassifications made by our methods. This involves analyzing which types of samples are most often confused with each other, providing insights into the challenges of the classification task and the strengths and weaknesses of our approach.\n\nFor the Meats data, we also explore the impact of aggregating adjacent wavelengths on classification performance. This is measured by the change in classification error as the aggregation level increases, offering a nuanced view of how spectral data resolution affects model performance.\n\nOverall, the set of metrics we report is representative of those used in the literature, ensuring that our results can be easily understood and compared within the broader context of similar studies. The focus on misclassification rate, along with the examination of specific misclassifications and the effects of data aggregation, provides a comprehensive evaluation of our classification methods.",
  "evaluation/comparison": "In the evaluation of our method, a comprehensive comparison was conducted with several established and publicly available classification techniques. These methods included Random Forests, AdaBoost, Bayesian Multinomial Regression, and Transductive Support Vector Machines (SVMs). These techniques were chosen because they are widely recognized and have standard software implementations, making them accessible for benchmarking.\n\nThe comparison was performed on high-dimensional food authenticity datasets, which are particularly challenging due to their complexity and the large number of variables involved. Our method demonstrated superior performance, achieving significantly lower misclassification rates compared to the other techniques. For instance, on the Meats data, our variable selection algorithm with updating achieved a misclassification rate of 0.8%, which is substantially better than the 20.9% rate observed with Transductive SVMs and the 14.7% rate with AdaBoost.\n\nIn addition to these advanced methods, simpler baselines were also considered. For example, the performance of our variable selection algorithm was compared to previous analyses of the same datasets, such as those reported by Dean et al. (2006) and McElhinney et al. (1999). These comparisons further highlighted the effectiveness of our approach, as it consistently outperformed these baselines.\n\nThe results indicate that our method not only improves classification accuracy but also reduces the number of variables needed for classification, from 1050 to less than thirty. This reduction in variables is crucial for developing more efficient and interpretable models, particularly in applications like food authenticity where the underlying chemical properties of the samples are of interest.\n\nOverall, the comparison with both advanced and simpler methods on benchmark datasets provides strong evidence of the robustness and effectiveness of our classification approach.",
  "evaluation/confidence": "The evaluation of our method includes performance metrics with confidence intervals, specifically standard deviations, for the misclassification rates. These are reported for 50 random splits of the data, providing a measure of variability and reliability in our results.\n\nThe results demonstrate that our variable selection and updating method consistently outperforms other established techniques. For instance, when combining chicken and turkey into a poultry group, the misclassification rate is as low as 0.8%, significantly better than methods like Random Forests (10.5%) and AdaBoost.M1 (14.7%). This performance gap suggests statistical significance, indicating that our method is superior.\n\nAdditionally, the reduction in the number of variables needed for classification, from 1050 to less than thirty, further supports the robustness and efficiency of our approach. The substantial improvement in classification results, coupled with the reduced variable set, implies that the method is not only effective but also practical for real-world applications.\n\nThe statistical significance of these results is evident in the consistent performance across multiple random splits and the clear superiority over baseline methods. This confidence in our method's performance is further reinforced by the interpretability of the selected variables, which align with the underlying chemical properties of the foods analyzed.",
  "evaluation/availability": "Not enough information is available."
}