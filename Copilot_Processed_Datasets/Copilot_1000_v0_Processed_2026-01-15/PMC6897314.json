{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "J Occup Environ Med.",
  "publication/year": "2020",
  "publication/pmid": "31800451",
  "publication/pmcid": "PMC6897314",
  "publication/doi": "10.1055/s-0031-1298595",
  "publication/tags": "- Biomarkers\n- Machine Learning\n- Smoking\n- miRNA\n- Support Vector Machine\n- Feature Selection\n- Tobacco Exposure\n- Molecular Profiles\n- Cigarette Smoke\n- Predictive Modeling\n- Cytokines\n- Metabolites\n- Cardiovascular Markers\n- Recursive Feature Elimination\n- Animal Models\n- Serum Samples\n- Data Analysis\n- Statistical Methods\n- Cross Validation\n- Biomarker Validation",
  "dataset/provenance": "The dataset used in this study was sourced from the Department of Defense Serum Repository. The initial dataset consisted of 800 de-identified human serum samples collected from active duty service personnel between 2006 and 2012. Two serum samples were obtained for each of the 400 donors, drawn approximately one year apart. However, 25 samples were excluded due to missing values, resulting in a final dataset of 775 samples.\n\nThe samples were analyzed for a diverse range of molecular profiles, including 21 cytokines, nine cardiovascular markers, 144 miRNAs, 59 metabolites, IgE levels, BPDE-protein adducts, and 25 dioxins. These biomarkers were chosen based on their potential relevance to environmental exposures and health outcomes.\n\nThe dataset has been used in previous studies, with some of the methods and initial results for miRNA and metabolomics analysis reported elsewhere. The serum samples were processed to measure various biomarkers, and the data was used to develop a machine-learning pipeline for classifying smokers and non-smokers based on their molecular profiles. The study design and some of the biomarkers have been discussed in depth in other publications.",
  "dataset/splits": "The dataset was split into two main parts: a training set and a test set. The training set comprised 80% of the data, while the test set contained the remaining 20%. Within the training set, a repeated 10-fold cross-validation process was employed. This involved partitioning the training data into 10 equal-sized subsamples. In each iteration of the cross-validation, one subsample was used as the validation set, and the remaining nine subsamples were used for training. This process was repeated 10 times, ensuring that each subsample was used exactly once as the validation dataset. The results from these 10-fold validations were then averaged to produce a single estimation of the model's overall validation-set accuracy. The test set, comprising 20% of the data, was used for independent evaluation of the model's performance. This approach ensured a robust assessment of the model's generalizability and performance.",
  "dataset/redundancy": "The dataset used in our study consisted of 775 samples, each with 236 molecular profiles. To ensure robust model evaluation, the data was split into training and testing sets. Specifically, 80% of the data was used for training and validation, while the remaining 20% was reserved for independent testing. This split was designed to evaluate the models' performance on unseen data, ensuring that the training and test sets were independent.\n\nTo further validate the models, we employed repeated 10-fold cross-validation on the training set. This process involved randomly partitioning the training samples into 10 equal-sized subsamples. In each iteration of the cross-validation, one subsample was held out as the validation set, while the remaining nine subsamples were used to train the models. This procedure was repeated 10 times, with each subsample serving as the validation set exactly once. The results from these 10 iterations were then averaged to produce a single estimation of the overall validation-set accuracy.\n\nThe distribution of our dataset, with a focus on molecular profiles and cotinine levels, is unique compared to previously published machine learning datasets. Our dataset specifically addresses the classification of smokers and non-smokers based on molecular profiles, which is a specialized application in the field of environmental and occupational health. The use of molecular profiles, including miRNAs, cytokines, cardiovascular disease markers, and metabolites, provides a comprehensive set of features for model training and evaluation. This approach allows for a detailed analysis of the biological impacts of environmental exposures, such as tobacco smoking, and sets our dataset apart from more general machine learning datasets.",
  "dataset/availability": "The data used in this study are not publicly available. However, the code developed for the manuscript is accessible on GitHub at https://github.com/Thakar-Lab/ML_Exposure_Prediction. This repository contains all primary data analysis and results, which can be found in the supplementary tables S1\u2013S8. The data itself consists of 236 molecular profiles from 800 de-identified human serum samples from the Department of Defense Serum Repository. Due to the sensitive nature of the data, it was de-identified at various levels and approved by Institutional Review Boards at the Uniformed Services University and the University of Rochester. This ensures that the data cannot be traced back to individual subjects, maintaining confidentiality and compliance with ethical standards. The supplementary tables provide detailed information on the data analysis and results, allowing for reproducibility of the study's findings.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Support Vector Machines (SVM), specifically the linear SVM with class weights. This algorithm is well-established and widely used in the field of machine learning for classification tasks.\n\nThe algorithm is not new; it has been extensively used and validated in various applications, including biomarker selection and classification problems. The choice of SVM was driven by its ability to handle high-dimensional data and its effectiveness in feature selection, which is crucial for identifying the most informative biomarkers from a large set of molecular profiles.\n\nThe reason this algorithm was not published in a machine-learning journal is that our primary focus was on applying machine learning techniques to solve a specific biological problem\u2014predicting past environmental exposures from molecular profiling of post-exposure human serum samples. The innovation lies in the application of these techniques to a novel biological context rather than the development of a new algorithm. Our study demonstrates the practical utility of SVM in a real-world biomedical application, showcasing its potential to uncover complex relationships in molecular data.",
  "optimization/meta": "The model described in the publication does not function as a meta-predictor. Instead, it employs a single machine learning method, specifically a support vector machine (SVM) with recursive feature elimination (RFE), to classify smokers and non-smokers based on molecular profiles. The SVM-RFE approach was used to identify the most informative features by removing redundant and less informative ones, thereby improving the model's predictive accuracy and generalizability.\n\nThe SVM model was trained and validated using a dataset of 775 samples, with 80% of the data used for training and validation through repeated 10-fold cross-validation. The remaining 20% of the data was reserved for independent testing. This process ensured that the training data was independent from the test data, maintaining the integrity of the model's performance evaluation.\n\nThe SVM model's performance was compared against 11 other statistical and machine learning methods, including random forest, k-nearest neighbors, artificial neural networks, and logistic regression. However, the final model selected for classification was the linear SVM with class weights, which demonstrated superior performance in terms of accuracy, area under the curve, and other performance indicators.\n\nIn summary, the model does not use data from other machine-learning algorithms as input. It relies solely on the SVM-RFE method for feature selection and classification, with a clear separation of training and test data to ensure independent evaluation.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the molecular profiles were suitable for classification tasks. Initially, 236 molecular profiles from 775 samples were used as inputs. These profiles included a variety of biomarkers such as cytokines, cardiovascular markers, miRNAs, metabolites, IgE, BPDE-protein adducts, and dioxins. To standardize the data, all features were normalized to have zero mean and unit variance. This standardization is crucial for machine learning algorithms to perform effectively, as it ensures that each feature contributes equally to the model.\n\nClass labels were assigned to each subject based on their cotinine levels, with cotinine \u226510 ng/mL indicating a smoker and cotinine <10 ng/mL indicating a non-smoker. This binary classification allowed for the development of models to distinguish between smokers and non-smokers.\n\nPrincipal component analysis (PCA) was performed on the dioxins and furans measurements to reduce dimensionality. The first principal component (PC1) was retained, as it explained over 90% of the total variance, making it a robust representation of the variation in dioxin and furan concentrations.\n\nAdditionally, regression models were developed to correct for age and sex, which are known confounding variables. These models helped quantify the effects of age and sex on the molecular profiles, ensuring that the association between molecular profiles and cotinine levels was not distorted. The residuals from these regression models were then used as inputs for the support vector machine (SVM) classification.\n\nFor the machine learning models, 80% of the data was used for training and validation, while the remaining 20% was reserved for independent testing. Repeated 10-fold cross-validation was employed on the training set to evaluate model performance. This involved partitioning the training samples into 10 equal-sized subsamples, using nine subsamples for training and one for validation in each iteration. This process was repeated 10 times, with each subsample used exactly once as the validation dataset. The results from these iterations were averaged to produce an overall validation-set accuracy estimate.",
  "optimization/parameters": "In our study, we initially utilized 236 molecular profiles as input parameters for our machine learning models. These profiles included a diverse range of biomarkers such as cytokines, cardiovascular markers, miRNAs, metabolites, IgE, BPDE-protein adducts, and dioxins.\n\nTo enhance the model's predictive accuracy and identify a more robust set of biomarkers, we employed recursive feature elimination (RFE) with a support vector machine (SVM) classifier. This process involved iteratively removing the least important features based on their weights assigned by the SVM. Through this method, we determined that a subset of 45 features achieved the highest performance, with a training accuracy of 78% and a 10-fold cross-validation accuracy of 75%. This subset of 45 features was selected because it provided a good balance between model complexity and performance, ensuring that the model generalized well to unseen data.\n\nThe selection of these 45 features was driven by the need to minimize overfitting and maximize the model's ability to generalize. The recursive feature elimination process helped in identifying the most informative features, thereby improving the model's predictive power and robustness.",
  "optimization/features": "In our study, we initially utilized 236 diverse molecular profiles as input features. These features encompassed a wide range of biomarkers, including cytokines, cardiovascular markers, miRNAs, metabolites, IgE, BPDE-protein adducts, and dioxins. To enhance the model's predictive accuracy and identify a more robust set of biomarkers, we employed recursive feature elimination (RFE). This process involved training a support vector machine (SVM) using all 236 features and then iteratively removing the least significant features based on their weights. The efficiency of the classifier was evaluated through 10-fold cross-validation at each iteration. This feature selection was performed exclusively using the training set to ensure that the model's generalizability and robustness were not compromised. Ultimately, we identified a subset of 45 features that achieved high training and cross-validation accuracy, demonstrating superior performance compared to using all 236 features.",
  "optimization/fitting": "In our study, we utilized a comprehensive set of molecular profiles, totaling 236 features, from 775 samples. Initially, the number of features was indeed much larger than the number of training points, which could potentially lead to overfitting. To address this, we employed several strategies.\n\nFirstly, we standardized all features to have zero mean and unit variance before inputting them into the models. This preprocessing step helps in ensuring that each feature contributes equally to the model, preventing any single feature from dominating the learning process.\n\nSecondly, we used recursive feature elimination (RFE) with support vector machines (SVM) to identify and retain the most informative features. This technique systematically removes the least important features based on their weights in the SVM model, thereby reducing the dimensionality of the feature space. Through this process, we were able to narrow down the features to a more manageable and relevant subset, which improved the model's generalizability and reduced the risk of overfitting.\n\nAdditionally, we implemented 10-fold cross-validation during the training phase. This involved partitioning the training data into 10 subsamples, using 9 for training and 1 for validation, and repeating this process 10 times. This method ensures that the model is evaluated on different subsets of the data, providing a more robust estimate of its performance and helping to identify any signs of overfitting.\n\nTo rule out underfitting, we compared the performance of our models using various metrics such as accuracy, area under the curve (AUC), sensitivity, and specificity. The models were evaluated not only on the training set but also on an independent held-out set, which consisted of 20% of the data that was not used during training. This independent evaluation helped us assess the models' ability to generalize to unseen data, ensuring that they were not too simplistic to capture the underlying patterns.\n\nFurthermore, we conducted a comparative analysis of 12 different statistical and machine learning models. This allowed us to select the most effective model for our classification task, ensuring that we were not underfitting the data by using an overly simplistic model.\n\nIn summary, by employing feature standardization, recursive feature elimination, cross-validation, and comparative model analysis, we effectively managed to mitigate both overfitting and underfitting, resulting in a robust and generalizable model for classifying smokers and non-smokers based on molecular profiles.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and improve the generalization of our models. One of the key methods used was recursive feature elimination (RFE) in conjunction with support vector machines (SVM). This approach helped in identifying and selecting the most informative features by iteratively removing the least significant ones. By doing so, we were able to reduce the dimensionality of our data and focus on the features that contributed most to the predictive power of our models.\n\nAdditionally, we used 10-fold cross-validation to evaluate the performance of our models. This technique involves splitting the data into 10 subsets, training the model on 9 of these subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. The results from these 10 iterations are then averaged to provide a more robust estimate of the model's performance. This method helps in ensuring that the model generalizes well to unseen data and is not overly fitted to the training data.\n\nFurthermore, we standardized all features before inputting them into the models. This process involves scaling the features to have zero mean and unit variance, which helps in improving the convergence and stability of the models, especially for algorithms that are sensitive to the scale of the input features.\n\nIn summary, we utilized recursive feature elimination, 10-fold cross-validation, and feature standardization as regularization techniques to prevent overfitting and enhance the generalization ability of our models.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not explicitly detailed in the provided information. However, the computational analyses were conducted in RStudio version 1.0.143 and Matlab 2016a environment, which suggests that the specific configurations and parameters used for the models could potentially be reconstructed or inferred from the methods described.\n\nThe optimization parameters, such as the use of 10-fold cross-validation and the recursive feature elimination (RFE) technique with support vector machines (SVM), are well-documented within the text. These methods were employed to improve the model's predictive accuracy and to identify a smaller set of robust biomarkers.\n\nRegarding the availability and licensing of the configurations and parameters, there is no specific mention of where these details can be accessed or under what license they are provided. Typically, such information would be included in supplementary materials or an accompanying data repository, but this is not confirmed in the given context.\n\nNot sure if the optimization parameters and configurations are available in a public repository or under a specific license.",
  "model/interpretability": "The model employed in our study is not a black box but rather a transparent one, primarily due to the use of a linear Support Vector Machine (SVM) classifier. This type of model is inherently interpretable because it provides clear insights into the decision-making process. The linear SVM optimizes a hyperplane that separates the classes of smokers and non-smokers, and the coordinates of this hyperplane are represented by feature weights. These weights indicate the importance of each feature in the classification task. Features with higher absolute weights are more influential in determining the class of a sample.\n\nFor instance, in our study, the top five biomarkers with the highest absolute weights assigned by the model were indoleacrylic acid, tryptophan, oxoproline, IL-1\u03b2, and creatinine. These weights provide a relative indication of their importance in the decision-making process of the classifier. Additionally, the model's ability to handle class imbalances through weighted SVM further enhances its interpretability, as it penalizes misclassification costs for the minority class (smokers), ensuring that the model is not skewed towards the majority class.\n\nMoreover, the use of recursive feature elimination (SVM-RFE) helped in identifying a smaller set of robust biomarkers that are not only predictive but also biologically relevant. This process involved recursively removing the least important features based on their weights and measuring the classifier's efficiency through 10-fold cross-validation. The resulting subset of features, such as the 45 features that achieved high accuracy, represents a biological signature of tobacco use. This subset includes members of the tryptophan biosynthesis pathway, metabolites, inflammatory cytokines, cardiovascular markers, and miRNAs, all of which are consistent with known disruptions in inflammation and energy metabolism associated with smoking.\n\nThe biological validation of these features, including miRNAs like miR-29a and let-7a, in both human and mouse models further supports the interpretability of the model. The direction of change in these miRNAs upon cigarette smoke exposure in mice aligns with their contribution to classifying smokers in our study population, providing a mechanistic understanding of their role in tobacco use.\n\nIn summary, the linear SVM model used in our study is transparent and interpretable, offering clear insights into the features that drive the classification of smokers and non-smokers. The model's ability to provide feature weights, handle class imbalances, and identify biologically relevant biomarkers makes it a valuable tool for understanding the complex relationships in the feature space.",
  "model/output": "The model developed is primarily for classification. It is designed to distinguish between smokers and non-smokers based on molecular profiles. Specifically, the model uses various machine learning techniques, including support vector machines (SVM), random forest, k-nearest neighbors, artificial neural networks, and others, to classify individuals into these two categories. The classification is based on serum cotinine levels, with individuals having cotinine levels \u226510 ng/mL classified as smokers and those with levels <10 ng/mL classified as non-smokers.\n\nThe SVM model, in particular, was chosen for its ability to handle complex relationships in the data and for its feasibility in feature selection. The model's performance was evaluated using metrics such as accuracy, area under the curve (AUC), sensitivity, and specificity. The final model, after recursive feature elimination, achieved an accuracy of 78.6% on the independent held-out set, with a sensitivity of 72.9% and a specificity of 82.1%. This indicates that the model is effective in classifying smokers and non-smokers based on the molecular profiles provided.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a comprehensive approach to ensure the robustness and generalizability of the model. Initially, the support vector machine (SVM) classifier was trained using all available features, and its performance was assessed through 10-fold cross-validation. This process involved partitioning the data into 10 subsamples, using 9 for training and 1 for validation, and repeating this 10 times to obtain an average accuracy.\n\nTo address overfitting and improve the model's ability to generalize, recursive feature elimination (RFE) was employed. This technique iteratively removed the least important features based on their weights, with the classifier's efficiency measured by 10-fold cross-validation at each step. The highest cross-validation accuracy achieved was 78% with 87 features, and a subset of 45 features was identified that maintained high accuracy (75% cross-validation accuracy and 78.6% on an independent held-out set).\n\nThe performance of the SVM model with the selected 45 features was compared against 11 other statistical and machine learning models, including random forest, k-nearest neighbors, and logistic regression. The SVM model outperformed all others, demonstrating superior accuracy and sensitivity. Additionally, the model's ability to handle class imbalance was addressed by using weighted SVM, which penalized misclassification of the minority class (smokers).\n\nTo validate the biological relevance of the selected features, further experiments were conducted. An animal model of cigarette smoke exposure was used to quantify specific miRNAs in lung tissue, providing a mechanistic understanding of the model's findings. This multi-step evaluation process ensured that the method was not only statistically robust but also biologically meaningful.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our machine learning models, particularly focusing on the support vector machine (SVM) classifier with recursive feature elimination (RFE). The primary metrics reported include accuracy, area under the curve (AUC), sensitivity, and specificity. These metrics are widely recognized and used in the literature for evaluating classification models, ensuring that our results are comparable with other studies in the field.\n\nAccuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It provides a general indication of how well the model performs across all classes. The AUC, derived from the receiver operating characteristic (ROC) curve, assesses the model's ability to distinguish between the positive and negative classes. A higher AUC indicates better model performance. Sensitivity, also known as the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, measures the proportion of actual negatives that are correctly identified. These metrics are crucial for understanding the model's performance in identifying smokers and non-smokers accurately.\n\nAdditionally, we reported the performance of our models on both the training set using 10-fold cross-validation and an independent held-out test set. This approach ensures that our models are not overfitted to the training data and can generalize well to unseen data. The use of cross-validation helps in providing a robust estimate of model performance by averaging the results across multiple splits of the data.\n\nWe also compared the performance of our SVM model with other statistical and machine learning methods, including random forest, k-nearest neighbors, and logistic regression. This comparative analysis allowed us to demonstrate that the SVM model with RFE outperformed other models in terms of accuracy and sensitivity. The SVM model achieved a high accuracy of 78.6% on the independent held-out set, with a sensitivity of 72.9% and a specificity of 82.1%. These results highlight the effectiveness of the SVM-RFE approach in selecting a subset of informative features that improve model performance.\n\nIn summary, the performance metrics reported in our study are representative of standard practices in the literature. They provide a comprehensive evaluation of our models' ability to classify smokers and non-smokers accurately and generalize to new data. The use of multiple performance metrics ensures that our findings are robust and comparable with other studies in the field.",
  "evaluation/comparison": "In our study, we did not perform a comparison to publicly available methods on benchmark datasets. Instead, we focused on evaluating and comparing the performance of various statistical and machine learning models specifically tailored to our dataset.\n\nWe did, however, compare our models to simpler baselines. Given the complex nature of the associations between the biomarkers in our study, we preferred more advanced models over conventional statistical methods. Many statistical tests assume independence among observations, which can lead to biased estimates when multicollinearity is present, as it was in our case with most of the 144 miRNAs being correlated. Therefore, we evaluated 12 different statistical and machine learning methods, including random forest, k-nearest neighbors, artificial neural networks, linear discriminant analysis, multilayer perceptron, decision trees, logistic regression, na\u00efve Bayes, and both linear and non-linear support vector machines.\n\nThe comparison revealed that methods such as SVM with class weights, logistic regression, neural networks, na\u00efve Bayes, and multilayer perceptron provided a balanced trade-off between sensitivity and specificity. Among these, we selected the linear SVM with class weights for further studies due to its feasibility in feature selection. This model optimizes a hyperplane to best separate the smoker and non-smoker classes, using feature weights that indicate the importance of each feature in the classification process.",
  "evaluation/confidence": "The evaluation of our models included a comprehensive analysis of performance metrics, which were assessed using confidence intervals to provide a range of likely values for the true performance. This approach allowed us to understand the variability and reliability of our results.\n\nFor the linear SVM model with recursive feature elimination, we observed a significant improvement in performance metrics. The model achieved a mean 10-fold cross-validation accuracy of 71.2% with an area under the curve (AUC) of 0.75 on the training set. On the independent held-out set, the model demonstrated an accuracy of 78.6%, with a sensitivity of 72.9% and a specificity of 82.1%. These results were statistically significant, indicating that the model's performance was not due to chance.\n\nThe comparison with other models, such as random forest, further supported the superiority of our approach. The random forest model, which was the second-best performer, had an accuracy of 73.38% with a confidence interval ranging from 65.7% to 80.2%. This comparison highlighted the robustness and generalizability of our linear SVM model with the selected feature set.\n\nAdditionally, the use of recursive feature elimination helped in identifying a subset of 45 features that significantly improved the model's performance. This subset not only enhanced the accuracy but also ensured that the model was not overfitted to the training data. The statistical significance of these improvements was confirmed through rigorous validation processes, including repeated 10-fold cross-validation and independent testing.\n\nOverall, the performance metrics, along with their confidence intervals, provided a strong basis for claiming that our method is superior to other evaluated models and baselines. The statistical significance of the results further reinforced the reliability and validity of our findings.",
  "evaluation/availability": "The raw evaluation files are not directly available for public download. However, the primary data analysis and results can be accessed through supplementary tables S1\u2013S8. These tables provide detailed insights into the evaluations conducted during the study. The code developed for this manuscript is available on GitHub at https://github.com/Thakar-Lab/ML_Exposure_Prediction. This repository includes the computational pipeline and methods used for the evaluations, allowing for reproducibility and further exploration. The data and code are made available to support transparency and to facilitate future research in this area."
}