{
  "publication/title": "Covid-19 detection in chest X-ray through random forest classifier using a hybridization of deep CNN and DWT optimized features",
  "publication/authors": "The authors who contributed to the article are:\n\n- Ra\ufb01d Mosta\ufb01z\n- Mohammad Shorif Uddin\n- Nur-A- Alam\n- Md. Mahfuz Reza\n- Mohammad Motiur Rahman\n\nThe contributions of each author to the paper are not specified.",
  "publication/journal": "Journal of King Saud University \u2013 Computer and Information Sciences",
  "publication/year": "2021",
  "publication/pmid": "38620614",
  "publication/pmcid": "PMC7834658",
  "publication/doi": "10.1016/j.jksuci.2021.100212",
  "publication/tags": "- Covid-19\n- Convolutional neural network (CNN)\n- Discrete wavelet transform (DWT)\n- Minimum redundancy maximum relevance (mRMR)\n- Recursive feature elimination (RFE)\n- Random forest classifier\n- Chest X-ray\n- Medical image analysis\n- Feature extraction\n- Disease diagnosis",
  "dataset/provenance": "The dataset used in this study was compiled from several publicly available sources of chest X-ray data. These sources include the Academic torrent repository of confirmed COVID-19 cases, the Kaggle COVID-19 X-ray data, and the Chest X-ray data of pneumonia (both viral and bacterial) and normal cases. The dataset preparation involved augmenting the data to increase the number of samples, as obtaining a large labeled dataset is challenging. Techniques such as zooming, flipping, rotating, and changing brightness and color were employed to augment the dataset.\n\nThe final dataset consists of a total of 4809 chest X-ray images. This includes 790 confirmed COVID-19 cases, 1215 viral pneumonia cases, 1304 bacterial pneumonia cases, and 1500 normal cases. The prepared datasets are available on GitHub for public access and further research. This comprehensive dataset allows for robust training and testing of the neural network-based computer-aided diagnosis (CAD) system for COVID-19 detection.",
  "dataset/splits": "The dataset was divided into two different scenarios for classification. In the first scenario, a binary classification was performed, where Covid-19 X-rays were classified from non-COVID classes. The non-COVID class included chest X-rays of viral pneumonia, bacterial pneumonia, and normal chests.\n\nIn the second scenario, a multi-class classification was performed based on four classes: Covid-19, viral pneumonia, bacterial pneumonia, and normal chest.\n\nFor both scenarios, the total dataset was randomly divided into training and testing sets at a ratio of 7:3. This means that 70% of the data was used for training the model, while the remaining 30% was used for testing its performance.\n\nThe dataset consisted of a total of 4809 chest X-ray images, including 790 confirmed Covid-19 cases, 1215 viral pneumonia cases, 1304 bacterial pneumonia cases, and 1500 normal cases. The distribution of data points in each split was proportional to the overall distribution in the dataset.",
  "dataset/redundancy": "The dataset used in this study consisted of 4809 chest X-ray images, which were augmented using techniques such as zooming, flipping, rotating, and changing brightness and color. The dataset included 790 confirmed Covid-19 cases, 1215 viral pneumonia cases, 1304 bacterial pneumonia cases, and 1500 normal cases.\n\nThe dataset was divided randomly into training and testing sets at a ratio of 7:3. This means that 70% of the data was used for training the model, while the remaining 30% was used for testing. The random split ensures that the training and test sets are independent, which is crucial for evaluating the model's performance on unseen data.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets for Covid-19 detection. The inclusion of a significant number of non-Covid cases, such as viral pneumonia, bacterial pneumonia, and normal chest X-rays, helps in creating a robust model that can differentiate between various conditions. This is particularly important in a clinical setting where the model needs to accurately identify Covid-19 cases among a diverse range of chest X-ray images.",
  "dataset/availability": "The datasets used in this study are publicly available. The prepared datasets, which include a total of 4809 chest X-ray images, are accessible on GitHub. This repository contains images categorized into confirmed Covid-19 cases, viral pneumonia cases, bacterial pneumonia cases, and normal cases. The data augmentation techniques applied, such as zooming, flipping, rotating, and changing brightness, ensure a robust and diverse dataset for training and testing purposes.\n\nThe data is made freely available to support further research and development in the field of medical image analysis, particularly in the context of Covid-19 detection. This open access aligns with the broader initiative to share COVID-19-related research freely, as granted by Elsevier for their COVID-19 resource center. The datasets can be utilized for unrestricted research re-use and analyses, provided that the original source is acknowledged. This approach fosters collaboration and innovation within the scientific community, enabling researchers to build upon existing work and contribute to the ongoing efforts to combat the pandemic.",
  "optimization/algorithm": "The optimization algorithm used in this study is a feature selection technique, not a new machine-learning algorithm class. Two pragmatic feature optimization algorithms were investigated: Minimal-redundancy-maximal-relevance (mRMR) and Double Input Symmetrical Relevance (DISR). These algorithms are well-established in the field of machine learning and feature selection.\n\nThe mRMR algorithm optimizes the mutual dependencies among the selected features. It aims to maximize the relevance of the features to the target class while minimizing the redundancy among the features. This is achieved by calculating the mutual dependencies of variables using their probabilistic density functions.\n\nThe DISR algorithm, on the other hand, is a mutual information-based feature selection technique. It selects the most relevant features by utilizing feature-selection criteria that involve mutual information and information entropy.\n\nThese algorithms were applied to a fused feature vector consisting of wavelet-based features and deep CNN features. The goal was to achieve more interpretable features and improve classification accuracy and computational cost.\n\nThe reason these algorithms were not published in a machine-learning journal is that they are not new contributions to the field of machine learning. Instead, they are established methods that were applied to a specific problem in medical image analysis. The focus of this study is on the application of these algorithms to the detection and classification of Covid-19 from chest X-ray images, rather than the development of new machine-learning algorithms.",
  "optimization/meta": "The model employs a meta-predictor approach, specifically utilizing a Random Forest (RF) classifier as the ensemble of multiple decision trees. This RF classifier serves as the meta-predictor, integrating features derived from other machine-learning algorithms.\n\nThe RF classifier aggregates outputs from various sources, including wavelet features and CNN features extracted using ResNet50. These features are fused to create a hybridized feature vector, which undergoes further optimization through techniques like minimal-redundancy-maximal-relevance (mRMR) and recursive feature elimination (RFE). This optimization process ensures that the most relevant features are selected, enhancing both computational efficiency and classification performance.\n\nThe RF classifier is trained using a bagging technique of bootstrap aggregation, which involves randomly selecting subsets of features and splitting nodes to find the best thresholds. This process is repeated multiple times to create an ensemble of decision trees, each contributing to the final classification decision.\n\nRegarding the independence of training data, the model employs 5-fold cross-validation. This method divides the dataset into five folds, training the model on four folds and validating it on the remaining fold. This process is repeated five times, with each fold serving as the validation set once. This approach helps to ensure that the model's performance is evaluated on independent data, minimizing the risk of overfitting and providing a more robust assessment of its generalization capabilities.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure effective feature extraction and enhancement of the input images. Initially, data augmentation techniques such as zooming, flipping, rotating, and adjusting brightness, color, and shape were applied to increase the diversity of the training dataset, which consisted of 4809 chest X-ray images across different categories.\n\nFor preprocessing, anisotropic diffusion was employed to remove noise and artifacts from the X-ray images while preserving important details. This iterative process used a space-variant diffusion filter to smooth the inner regions of the images and stop diffusion across boundaries, thereby maintaining edge information. Following this, histogram equalization was applied to enhance the contrast and brightness uniformity of the images, making them more perceptible for clinicians and more effective for feature extraction.\n\nThe images were then resized to 224x224 pixels to standardize the input dimensions for the machine-learning models. Additionally, the watershed technique was used to segment the effective regions within the X-ray images, focusing on the areas of interest for further analysis. These preprocessing steps collectively aimed to improve the quality and consistency of the input data, facilitating better performance of the subsequent feature extraction and classification processes.",
  "optimization/parameters": "In our model, we utilized a hybrid feature vector consisting of 120 wavelet-based feature vectors and 1024 deep CNN feature vectors, resulting in an initial feature vector size of 1144. However, to improve classification accuracy and reduce computational cost, we employed feature optimization techniques. After optimization, the feature vector size was reduced to 100.\n\nThe selection of the number of features, p, was determined through the use of feature optimization algorithms. Specifically, we investigated two pragmatic feature optimization algorithms: Minimal-redundancy-maximal-relevance (mRMR) and Double Input Symmetrical Relevance (DISR). These algorithms helped in selecting the most relevant features and eliminating the irrelevant and redundant ones. The mRMR algorithm optimizes the mutual dependencies among the selected features, while DISR selects the most relevant features by utilizing feature-selection criteria based on mutual information and information entropy.\n\nThe final feature vector size of 100 was chosen because it provided a good balance between classification accuracy and computational efficiency. This optimization process ensured that the most relevant features were retained, leading to improved performance metrics such as accuracy, precision, recall, and F-score.",
  "optimization/features": "In our study, we utilized a combination of wavelet-based features and deep convolutional neural network (CNN) features to form a hybridized feature vector. Initially, we extracted 120 wavelet-based feature vectors and 1024 deep CNN feature vectors from the input images. These features were fused to create a hybridized feature vector of size 1144.\n\nTo enhance the interpretability and performance of our model, we performed feature optimization. This process involved selecting the most relevant features and eliminating the irrelevant and redundant ones. Two feature optimization algorithms were investigated: Minimal-redundancy-maximal-relevance (mRMR) and Double Input Symmetrical Relevance (DISR). The mRMR algorithm optimizes the mutual dependencies among the selected features, ensuring that the features chosen are both relevant to the target variable and minimally redundant with each other.\n\nAfter optimization, the feature vector size was reduced to 100. This reduction improved both the classification accuracy and computational efficiency. The feature selection process was conducted using the training set only, ensuring that the model's performance on the test set was not biased by the feature selection process.\n\nThe final feature vector, consisting of 100 optimized features, was then used as input for the classification task. This approach allowed us to achieve better classification performance and computational efficiency.",
  "optimization/fitting": "The fitting method employed in this study involved a convolutional neural network (CNN) architecture designed to extract features from chest X-ray images. The CNN utilized ReLU activation functions in each convolutional layer and included a dropout layer to mitigate overfitting. The feature extraction process involved fusing wavelet-based features with deep CNN features, resulting in a hybridized feature vector of size 1144. This vector was then optimized using feature selection techniques to reduce its size to 100, enhancing both classification accuracy and computational efficiency.\n\nTo address the potential issue of overfitting, given the large number of parameters relative to the training points, several strategies were implemented. Firstly, a dropout layer was incorporated into the CNN architecture. This layer randomly sets a fraction of input units to zero during training, which helps prevent the model from becoming too reliant on specific features and thus reduces overfitting. Additionally, the use of feature optimization techniques, such as minimal-redundancy-maximal-relevance (mRMR) and double input symmetrical relevance (DISR), further refined the feature set, ensuring that only the most relevant features were retained. This process not only improved the model's interpretability but also helped in mitigating overfitting by reducing the dimensionality of the feature vector.\n\nTo rule out underfitting, the model's performance was evaluated using a 5-fold cross-validation approach. This method ensures that the model is tested on multiple subsets of the data, providing a more robust estimate of its generalization performance. The use of a Random Forest classifier, which is an ensemble of multiple decision trees, also helped in improving the model's ability to capture complex patterns in the data, thereby reducing the risk of underfitting. The classifier's performance was assessed using various metrics, including accuracy, precision, recall, and F1-score, which provided a comprehensive evaluation of its effectiveness in classifying chest X-ray images.",
  "optimization/regularization": "In our study, we implemented a dropout layer to mitigate the overfitting problem. This regularization technique helps to prevent the model from becoming too reliant on specific features in the training data, thereby improving its generalization to unseen data. By randomly setting a fraction of the input units to zero at each update during training time, dropout encourages the network to learn more robust features that are useful in conjunction with many different random subsets of the other neurons. This approach has been shown to be effective in reducing overfitting and improving the model's performance on validation and test datasets.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not explicitly detailed in the publication. However, the feature optimization algorithms used, such as Minimal-Redundancy-Maximal-Relevance (mRMR) and Double Input Symmetrical Relevance (DISR), along with Recurrent Feature Elimination (RFE), are described. The performance metrics for these optimizations are provided in comparative tables, showing their effectiveness in improving classification accuracy and computational efficiency.\n\nThe publication mentions the use of a Random Forest classifier, which outperformed other models like SVM and CNN in terms of performance metrics and computational complexities. The feature selection process involving mRMR and RFE is crucial for enhancing the classification performance.\n\nRegarding the availability of model files and optimization parameters, the publication does not provide direct links or repositories. However, it is implied that the methods and optimizations described can be replicated using the detailed algorithms and performance metrics provided. For specific model files or detailed hyper-parameter configurations, further inquiry or access to supplementary materials might be necessary.",
  "model/interpretability": "The model developed in this research is designed to be transparent, allowing for clear interpretation of its decisions. This transparency is crucial, especially in medical applications like detecting Covid-19 from chest X-rays, where understanding the model's reasoning is as important as the prediction itself.\n\nOne of the key aspects of the model's transparency is its ability to handle tricky cases where even human experts might struggle. For instance, in some chest X-ray images, radiologists may find it challenging to detect Covid-19, but the proposed model can correctly identify the infection. This is achieved through a combination of feature selection techniques and a robust classification algorithm.\n\nThe model uses a fusion of wavelet features and CNN features extracted using ResNet50, along with recurrent feature elimination (RFE) to select the most relevant features. This process ensures that the model focuses on the most informative parts of the X-ray images, making its decisions more interpretable.\n\nIn visual performance evaluations, the model's predictions are compared with those of radiologists. For example, in one case, the model correctly identified a Covid-19 infection that a radiologist missed. This demonstrates the model's ability to provide insights that might be difficult for human experts to discern, especially in cases with poor-quality X-rays.\n\nHowever, there are instances where both the model and human experts make errors. For example, in some cases, the model and radiologists might incorrectly predict pneumonia instead of Covid-19 due to the poor quality of the X-ray. These examples highlight the challenges in medical image analysis and the need for continuous improvement in both human and machine-based diagnostic tools.\n\nOverall, the model's transparency is achieved through a combination of advanced feature selection techniques and a clear visualization of its decision-making process. This makes it a valuable tool for medical professionals, providing them with insights that can aid in the diagnosis of Covid-19 and other conditions.",
  "model/output": "The model is a classification model designed to detect and classify Covid-19 from chest X-ray images. It operates in two main scenarios: binary classification, where it distinguishes Covid-19 cases from non-COVID classes (such as viral pneumonia, bacterial pneumonia, and normal chest X-rays), and multi-class classification, where it categorizes X-ray images into four classes: Covid-19, viral pneumonia, bacterial pneumonia, and normal chest.\n\nThe model utilizes a Random Forest (RF) classifier, which is an ensemble of multiple decision trees. This classifier has shown superior performance compared to other models like Support Vector Machine (SVM) and Convolutional Neural Network (CNN) in terms of performance metrics and computational complexities. The RF classifier is particularly effective for handling overlapping and categorical data.\n\nThe feature selection process involves using the minimum Redundancy Maximum Relevance (mRMR) technique along with Recursive Feature Elimination (RFE). This combination helps in selecting the most relevant features and eliminating redundant ones, thereby increasing computation speed and classification performance. The feature dimension becomes more concise with relevant features, leading to better efficiency with less computation required.\n\nThe model's performance is evaluated using 5-fold cross-validation, which helps in obtaining a more robust experimental result and minimizing overfitting. The peak accuracy achieved is 99.85% for binary classification and 98.91% for multi-class classification. The performance metrics used for evaluation include accuracy, precision, recall, and F-score, ensuring a comprehensive assessment of the model's effectiveness.\n\nIn visual performance evaluations, the model correctly identifies Covid-19 cases in tricky scenarios where radiologists might be confused. However, there are instances where poor-quality X-rays lead to misdetections. The model's transparent design allows for gaining and interpreting insights into Covid-19 infections, which can be challenging for human experts.\n\nOverall, the model demonstrates high accuracy and reliability in detecting Covid-19 from chest X-ray images, making it a valuable tool in medical diagnostics.",
  "model/duration": "The execution time of the model was optimized through the use of feature selection techniques. Specifically, the combination of minimum Redundancy - Maximum Relevance (mRMR) and Recursive Feature Elimination (RFE) was employed to select the most relevant features and eliminate redundant ones. This process significantly increased computation speed and classification performance. By reducing the feature dimension to a more concise set of relevant features, the model required less computation, thereby enhancing efficiency. The use of a Random Forest classifier, which is known for its speed and ability to handle large datasets, further contributed to the model's efficient execution. The 5-fold cross-validation process was also instrumental in ensuring that the model's behavior was accurately estimated towards independent data, minimizing overfitting problems in supervised learning. The performance metrics, including accuracy, precision, recall, and F-score, were averaged across the folds to provide a robust evaluation of the model's execution time and overall performance.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The method was evaluated using a 5-fold cross-validation approach to ensure robust and reliable results. This technique involves dividing the dataset into five equal parts, or folds, and then training the model on four of these folds while testing it on the remaining fold. This process is repeated five times, with each fold serving as the test set once. The performance metrics, such as accuracy, precision, recall, and F-score, are then averaged across all five folds to provide a comprehensive evaluation of the model's performance.\n\nThe evaluation was conducted in two different scenarios: a binary classification scenario, where the model distinguishes between Covid-19 and non-Covid-19 cases, and a multi-class classification scenario, where the model classifies images into four categories: Covid-19, viral pneumonia, bacterial pneumonia, and normal chest. This dual evaluation approach ensures that the model's performance is assessed in both simplified and more complex settings.\n\nAdditionally, the performance of the proposed method was compared with other classification techniques, such as K-Nearest Neighbor (KNN), Convolutional Neural Network (CNN), and Support Vector Machine (SVM). The Random Forest (RF) classifier, which was used in the proposed method, demonstrated superior performance in terms of accuracy, precision, recall, and F-score for both the binary and multi-class classification scenarios.\n\nThe evaluation also included a comparison of different feature optimization approaches, such as mRMR (minimum Redundancy Maximum Relevance) combined with RFE (Recursive Feature Elimination) and DSIR (Discriminative Subspace Iterative Refinement) combined with RFE. The mRMR + RFE approach showed better performance, indicating its effectiveness in selecting relevant features and eliminating redundant ones, thereby improving the model's efficiency and accuracy.\n\nFurthermore, the evaluation considered the handling of imbalanced data, which is crucial in medical image analysis. The use of RFE with mRMR helped in minimizing the misdetection rate, ensuring that the model performs well even when the dataset is imbalanced. This is particularly important in the context of Covid-19 detection, where accurate identification of positive cases is critical.",
  "evaluation/measure": "In our study, we evaluated the performance of our proposed methodology using a comprehensive set of metrics to ensure a thorough assessment. The primary metrics reported include accuracy, precision, recall, and F1-score. These metrics are derived from the confusion matrix, which consists of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n\nAccuracy measures the overall correctness of the classification, providing the ratio of correctly predicted instances (both true positives and true negatives) to the total number of instances. Precision focuses on the correctness of positive predictions, indicating the ratio of true positives to the sum of true positives and false positives. Recall, also known as sensitivity, assesses the ability of the model to identify all relevant instances, calculated as the ratio of true positives to the sum of true positives and false negatives. The F1-score is the harmonic mean of precision and recall, offering a balanced measure that is particularly useful when dealing with imbalanced datasets.\n\nThese metrics are widely recognized and used in the literature for evaluating classification models, especially in medical image analysis. They provide a holistic view of the model's performance, ensuring that we capture not only the overall correctness but also the specific strengths and weaknesses in identifying positive and negative cases. By reporting these metrics, we aim to provide a transparent and comprehensive evaluation of our methodology, allowing for comparisons with other studies and ensuring that our results are representative and reliable.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of various methods and models to ensure the robustness and superiority of our proposed approach. We conducted a comprehensive comparison with publicly available methods using benchmark datasets. Specifically, we compared our fused feature approach (combining DWT and CNN features) with individual methods using either DWT or CNN alone. The results, presented in a comparative table, clearly demonstrate the superiority of the fused method in terms of accuracy, precision, recall, and F1-score for both two-class and four-class scenarios.\n\nAdditionally, we performed a comparison with simpler baselines to assess the effectiveness of our approach. We evaluated different pre-trained CNN models, including ResNet50, VGG19, MobileNet v2, DenseNet201, Inception, and Xception, in combination with DWT features. The results indicated that the fine-tuned ResNet50 model, when combined with wavelet features, achieved the best performance metrics. This comparison highlighted the importance of feature fusion and the selection of an appropriate pre-trained model for enhancing classification accuracy.\n\nFurthermore, we compared the performance of different feature optimization approaches, such as mRMR + RFE and DSIR + RFE. The results confirmed that mRMR + RFE showed better performance, emphasizing the significance of effective feature selection in improving classification outcomes. We also evaluated various classifiers, including KNN, CNN, SVM, and Random Forest, and found that the Random Forest classifier outperformed the others in terms of performance metrics and computational efficiency.\n\nIn summary, our evaluation involved a thorough comparison with publicly available methods and simpler baselines, ensuring that our proposed approach stands out in terms of accuracy and reliability for classifying Covid-19 chest X-rays.",
  "evaluation/confidence": "The evaluation of our proposed methodology involved a rigorous assessment using multiple performance metrics, including accuracy, precision, recall, and F1-score. These metrics were calculated based on confusion matrices derived from our classification experiments. The experiments were conducted in two scenarios: a binary class scenario (Covid-19 vs. non-COVID) and a multi-class scenario (Covid-19, viral pneumonia, bacterial pneumonia, and normal chest).\n\nTo ensure the robustness of our results, we employed a 5-fold cross-validation technique. This approach helps in estimating the model's behavior on independent data and minimizes the risk of overfitting. The performance metrics were averaged across the five folds, providing a more reliable estimate of the model's performance.\n\nThe peak accuracy achieved was 99.85% for the binary classification scenario and 98.91% for the multi-class classification scenario. These high accuracy values indicate that our model performs exceptionally well in distinguishing between the different classes of chest X-ray images.\n\nIn addition to accuracy, we also reported precision, recall, and F1-score, which provide a more comprehensive evaluation of the model's performance. The high values of these metrics further confirm the effectiveness of our approach.\n\nStatistical significance was assessed by comparing our method with other classifiers, such as KNN, CNN, and SVM. The results, as shown in the comparison tables, demonstrate that our method outperforms these baselines in terms of accuracy, precision, recall, and F1-score. This suggests that our approach is not only accurate but also statistically superior to other methods.\n\nConfidence intervals for the performance metrics were not explicitly provided in the results. However, the use of 5-fold cross-validation and the consistent performance across different folds provide a strong indication of the reliability and statistical significance of our findings. The high accuracy and other performance metrics achieved across multiple folds suggest that the results are not due to chance but reflect the true superiority of our method.",
  "evaluation/availability": "Not applicable."
}