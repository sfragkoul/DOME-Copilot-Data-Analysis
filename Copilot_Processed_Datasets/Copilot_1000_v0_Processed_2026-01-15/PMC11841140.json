{
  "publication/title": "Predictive Model for Compassion Fatigue Among Nursing Students Using Machine Learning and SHAP Analysis",
  "publication/authors": "The authors who contributed to this article are Huiling Zhang and Wireeen Leila. Huiling Zhang was responsible for data analysis and manuscript writing. Wireeen Leila polished the article.",
  "publication/journal": "BMC Nursing",
  "publication/year": "2025",
  "publication/pmid": "39972360",
  "publication/pmcid": "PMC11841140",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Nursing students\n- Compassion fatigue\n- Predictive modeling\n- Machine learning\n- Logistic regression\n- LASSO regression\n- Psychological resilience\n- Social support\n- Secondary trauma\n- Ethical guidelines\n- Data analysis\n- Statistical methods\n- Multivariate analysis\n- Nursing education\n- Mental health\n- Job satisfaction\n- Clinical practice\n- Nursing management\n- Data visualization\n- Feature importance",
  "dataset/provenance": "The dataset used in this study was sourced from nursing students undergoing clinical internships. The inclusion criteria specified that participants had to be nursing students in their clinical internship phase, while the exclusion criteria removed those with severe physical or psychological illnesses and those unwilling to participate. A total of 512 valid questionnaires were collected from these students.\n\nThe data collection process involved self-administered questionnaires that covered a range of variables. These included demographic information such as age, gender, and family background. Work-related variables were also gathered, including details about the internship hospital level, the number of weekly working days, and the number of patients cared for per week. Additionally, psychological variables were assessed using several validated scales. These scales measured perceived social support, psychological resilience, compassion fatigue, and role overload. The scales used had high reliability and validity, ensuring the quality of the data collected.\n\nThis dataset has not been used in previous papers or by the community, as it was specifically collected for this study. The focus was on understanding the factors influencing compassion fatigue among nursing students, and the data was divided into training and test sets in a 7:3 ratio to facilitate analysis and model validation.",
  "dataset/splits": "The dataset used in this study was divided into two primary splits: a training set and a test set. The dataset consisted of 512 valid questionnaires collected from nursing students. The split ratio was 7:3, resulting in 246 participants in the training set and 245 participants in the test set. This division ensured a balanced distribution of demographic and work-related variables between the two sets, with no significant differences observed (p > 0.05). This balance is crucial for maintaining the integrity and reliability of the subsequent analyses and model evaluations.",
  "dataset/redundancy": "The dataset used in this study consisted of 512 valid questionnaires collected from nursing students. To ensure robust model training and evaluation, the dataset was randomly divided into a training set and a test set in a 7:3 ratio. This resulted in 246 participants in the training set and 245 participants in the test set.\n\nThe independence of the training and test sets was enforced through a random split, ensuring that there was no overlap between the two sets. This random division helped to mitigate any potential bias and ensured that the models were evaluated on unseen data, which is crucial for assessing their generalization capability.\n\nBaseline comparisons were conducted to verify that the training and test sets were well-balanced. These comparisons showed no significant differences between the two sets regarding various demographic and work-related variables, such as hospital level, grade, age, gender, time entering clinical practice, religious beliefs, only child status, number of night shifts, physical condition, number of patients cared for per week, and number of critically ill patients. Additionally, psychological variables like social support score, empathy satisfaction, job burnout, secondary trauma, role overload, and psychological resilience also showed no significant differences.\n\nThis careful splitting and balancing of the dataset ensured that the models developed were reliable and that the results were not influenced by any inherent biases in the data distribution. The approach taken is consistent with best practices in machine learning, where the goal is to create independent and representative training and test sets to validate the model's performance accurately.",
  "dataset/availability": "Not applicable.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is logistic regression. This algorithm is well-established and widely used in various fields for binary classification tasks. It was chosen for its interpretability and ability to provide clear insights into the relationships between the predictors and the outcome variable.\n\nThe logistic regression model employed is not a new algorithm. It has been extensively studied and applied in numerous research studies and practical applications. The decision to use logistic regression in this context was driven by its effectiveness in predicting compassion fatigue among nursing students, as demonstrated by its superior performance metrics such as AUC, precision-recall curves, and decision curve analysis.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of this study is on the application of machine learning in the field of nursing, specifically to predict compassion fatigue. The primary contribution of this work lies in the domain of nursing research rather than the development of new machine-learning algorithms. The study aims to provide practical tools for nursing management and education, leveraging established machine-learning techniques to address a specific healthcare challenge.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on a set of independent variables identified through LASSO regression to predict compassion fatigue among nursing students. The logistic regression model was chosen for its superior performance in terms of accuracy and generalization ability. The training data was carefully divided into training and test sets in a 7:3 ratio, ensuring that the datasets were independent and balanced, with no significant differences in demographic and work-related variables. This approach helps to validate the model's predictive power and reliability.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of the machine-learning algorithms. Initially, we collected a total of 512 valid questionnaires from nursing students, which were then randomly divided into training and test sets in a 7:3 ratio. This division ensured a balanced dataset, with no significant differences in demographic and work-related variables between the two sets.\n\nThe independent variables analyzed included a wide range of factors such as hospital level, age, gender, grade, religious belief, only-child status, number of night shifts, physical exercise habits, dietary habits, sleep habits, physical condition, number of patients cared for per week, number of critically ill patients cared for per week, number of new admissions per week, actual working days per week, whether coping techniques for compassion fatigue have been learned, teaching effectiveness at the hospital, social support score, empathy satisfaction, job burnout, secondary trauma, role overload, and psychological resilience.\n\nTo handle the multicollinearity and prevent overfitting, we employed LASSO (Least Absolute Shrinkage and Selection Operator) regression. This method effectively selected and shrunk variables, reducing the number of independent variables from 23 to 16. The optimal penalty coefficient (lambda) was determined through tenfold cross-validation, ensuring that only the most predictive variables were retained.\n\nFollowing the variable selection, we conducted multivariate logistic regression analysis to assess the independent impact of each variable on compassion fatigue. The results were expressed as odds ratios (OR) and 95% confidence intervals (CI), with statistical significance set at p < 0.05.\n\nFor the machine learning models, we utilized several open-source libraries in Python. Sci-kit-learn was used for statistical analyses such as LASSO regression and logistic regression. XGBoost and LightGBM were employed for building tree-based models. Matplotlib and seaborn were used for data visualization and result presentation. SHAP (Shapley Additive exPlanations) values were utilized to interpret the feature importance in the machine learning models, providing a clear understanding of each variable's contribution to the prediction outcomes.\n\nThe dataset was divided into training and testing sets in a 7:3 ratio, and ten repetitions of sampling were conducted to reduce model error. Model evaluation metrics included AUC (Area Under the Curve), PR curve (Precision-Recall curve), DCA (Decision Curve Analysis), and calibration curves to assess model performance and prediction accuracy. These steps ensured that our data was properly encoded and preprocessed, leading to robust and reliable machine-learning models.",
  "optimization/parameters": "In our study, we initially considered 23 independent variables. To select the most predictive variables, we employed LASSO (Least Absolute Shrinkage and Selection Operator) regression analysis. This method is effective in addressing multicollinearity and preventing model overfitting by selecting and shrinking variables.\n\nThrough tenfold cross-validation, we determined the optimal penalty coefficient (lambda), which resulted in 16 non-zero coefficients. These 16 variables were then used in our multivariate logistic regression analysis. This approach ensured that we focused on the most relevant features, enhancing the model's predictive accuracy and generalization capability.",
  "optimization/features": "In the optimization process of our study, we initially considered 23 independent variables as potential input features. To enhance the model's performance and prevent overfitting, we employed LASSO regression for feature selection. This technique effectively addressed multicollinearity among the variables.\n\nThe feature selection was conducted using the training set only, ensuring that the test set remained unseen during this process. Through LASSO regression, we identified 16 key features that significantly influenced the prediction of compassion fatigue. These selected features were then used as input for our logistic regression model, which demonstrated exceptional performance across multiple metrics.\n\nThe final model utilized these 16 features, which included variables such as hospital level, age, gender, psychological resilience, social support, and empathy satisfaction, among others. This approach ensured that our model was both efficient and effective in predicting compassion fatigue among nursing students.",
  "optimization/fitting": "In our study, we employed several strategies to ensure that our model was neither overfitting nor underfitting the data. Initially, we used LASSO regression to select the most predictive variables from a set of 23 independent variables, reducing them to 16 key variables. This step was crucial in addressing multicollinearity and preventing overfitting by compressing variable coefficients.\n\nTo further validate our model, we utilized tenfold cross-validation during the logistic regression analysis. This technique helps in assessing the model's performance and generalization capability by dividing the data into ten subsets, training on nine, and validating on the remaining one, repeating this process ten times. The average AUC of the training set was 0.81, while the validation set's AUC was slightly lower, and the test set's AUC was 0.77. This indicates that our model generalizes well to unseen data.\n\nAdditionally, we compared the AUC values of the training, validation, and test sets. A well-fitted model is considered when the AUC of the validation set is lower than that of the test set or the difference does not exceed 10%. Our results met this criterion, suggesting that the model is appropriately fitted and not overfitting the training data.\n\nWe also ensured that the model was not underfitting by evaluating its performance on multiple metrics, including AUC, PR curves, and DCA. The logistic regression model showed high AUC values on both the training and test sets, indicating strong fitting ability and high stability. The learning curve further supported this, as the AUC values for both the training and validation sets gradually stabilized as the number of training samples increased.\n\nIn summary, through the use of LASSO regression for variable selection, tenfold cross-validation, and thorough evaluation metrics, we have demonstrated that our logistic regression model is well-fitted, neither overfitting nor underfitting the data.",
  "optimization/regularization": "In our study, we employed LASSO (Least Absolute Shrinkage and Selection Operator) regression as a regularization method to prevent overfitting and address multicollinearity among the variables. This technique is particularly useful in scenarios where the number of predictors is large compared to the number of observations, which was the case in our analysis of compassion fatigue among nursing students.\n\nLASSO regression works by adding a penalty equal to the absolute value of the magnitude of coefficients to the loss function. This penalty shrinks some of the coefficients to zero, effectively performing both variable selection and regularization. We determined the optimal penalty coefficient (lambda) through tenfold cross-validation, ensuring that the model was both parsimonious and accurate.\n\nBy using LASSO regression, we were able to reduce the 24 independent variables to 16, which were then used in the multivariate logistic regression analysis. This step was crucial in identifying the key predictors of compassion fatigue and in building a robust predictive model. The use of LASSO regression helped in enhancing the model's generalization capability and preventing overfitting, thereby improving the reliability of our findings.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a black box. To ensure transparency and interpretability, we employed the SHAP (Shapley Additive explanations) method. This approach allows us to visually explain the impact of selected variables on the model\u2019s predictions. By using SHAP values, we can identify which features are critical in the model, providing a better understanding of how these variables affect the prediction outcomes.\n\nFor instance, the SHAP value analysis revealed that social support, psychological resilience, and empathy satisfaction have the most significant impact on the model's predictions. These factors play a crucial role in shaping the prediction model. Other variables like secondary trauma and age also significantly influence the model, while features such as hospital level have almost no effect, indicating their unimportance in forming the predictive model.\n\nThrough SHAP value plots, we can see the importance of each feature and its simulated impact on the target variable. Features are ranked from top to bottom by importance, with the horizontal axis representing the degree of influence each feature has on the target variable. Positive values indicate a positive effect, while negative values indicate a negative effect. The color of the dots ranges from purple to yellow, indicating the feature values from low to high, with the size of the dots proportional to their impact on the model. This visual representation helps in understanding the contribution of different variables to the prediction outcomes, making the model more transparent and interpretable.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the presence of compassion fatigue among nursing students. The logistic regression model was chosen for its superior generalization ability and high accuracy in predicting compassion fatigue. The model's performance was evaluated using various metrics, including the Area Under the Curve (AUC) and Average Precision (AP), which demonstrated its effectiveness in classifying nursing students at risk of compassion fatigue.\n\nThe logistic regression model was trained, validated, and tested on different datasets, with the AUC values stabilizing across these sets. This indicates that the model has good prediction accuracy and generalization capability. The learning curve further supports this, showing that as the number of training samples increases, the AUC values for both the training and validation sets gradually stabilize, indicating strong fitting ability and high stability.\n\nThe model's interpretability was enhanced using SHAP (Shapley Additive explanations) values, which visually explained the impact of selected variables on the model\u2019s predictions. This approach identified key predictors such as social support, psychological resilience, and empathy satisfaction, which play crucial roles in shaping the prediction model. Other significant factors include secondary trauma and age, while variables like role overload and hospital level have relatively minor impacts.\n\nIn summary, the logistic regression model is well-suited for classification tasks in the current dataset, providing accurate prediction results. It offers an effective tool for early identification of high-risk nursing students, laying the foundation for targeted interventions to mitigate compassion fatigue.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the models used in this study is not publicly released. However, the data analysis and model construction utilized several open-source libraries in Python, including sci-kit-learn for statistical analyses such as LASSO regression and logistic regression, XGBoost and LightGBM for building tree-based models, and matplotlib and seaborn for data visualization and result presentation. SHAP was used for interpreting feature importance in machine learning models.\n\nThe study does not provide a specific method to run the algorithm, such as an executable, web server, virtual machine, or container instance. The focus was on the development and evaluation of the models rather than on providing a publicly accessible implementation.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive approach to ensure the robustness and generalizability of the predictive models. Initially, the dataset was divided into training and testing sets in a 7:3 ratio, with ten repetitions of sampling conducted to reduce model error. This division ensured that the models were trained on a substantial portion of the data while being tested on a separate, unseen dataset.\n\nTo evaluate the models, several metrics were utilized, including the Area Under the Curve (AUC), Precision-Recall (PR) curve, Decision Curve Analysis (DCA), and calibration curves. These metrics provided a thorough assessment of model performance and prediction accuracy. The AUC values were particularly focus on, as they indicated the models' ability to distinguish between nursing students with and without compassion fatigue.\n\nTenfold cross-validation was applied to the logistic regression model to determine the optimal penalty coefficient (lambda) and to select non-zero coefficient variables. This technique helped in addressing multicollinearity and preventing model overfitting. The logistic regression model was found to have the highest AUC value on the test set, demonstrating its superior generalization ability.\n\nAdditionally, the study employed SHAP (Shapley Additive exPlanations) values to interpret the features within the models. SHAP value plots were generated to illustrate the importance of different variables and their positive or negative impacts on compassion fatigue. This approach provided insights into the contribution of each variable to the prediction outcomes, enhancing the interpretability of the models.\n\nMultiple machine learning models, including logistic regression, random forest, XGBoost, and LightGBM, were constructed and evaluated. The logistic regression model outperformed the other models in terms of AUC, PR curve, DCA, and calibration curve metrics, making it the optimal model for predicting compassion fatigue in nursing students. The results were expressed as odds ratios (OR) and 95% confidence intervals (CI), with statistical significance set at p < 0.05.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the effectiveness of our models. The primary metric used was the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, which provided a clear indication of each model's ability to distinguish between classes. This metric is widely recognized and used in the literature for its robustness in evaluating classification models.\n\nAdditionally, we utilized the Precision-Recall (PR) curve to assess model performance, particularly in handling imbalanced data. The Average Precision (AP) value derived from the PR curve was crucial in evaluating the models' precision and recall trade-offs, especially on the test set.\n\nTo further gauge the clinical applicability of our models, we conducted Decision Curve Analysis (DCA). This method allowed us to evaluate the net benefits of our models at different threshold probabilities, providing insights into their practical utility in real-world scenarios.\n\nCalibration curves were also employed to assess the models' prediction accuracy and reliability. These curves helped us understand how well the predicted probabilities aligned with the actual outcomes, ensuring that our models were well-calibrated and reliable.\n\nOverall, the combination of AUC, PR curves, DCA, and calibration curves provided a thorough evaluation of our models' performance. These metrics are representative of the standards used in the literature, ensuring that our evaluation is both rigorous and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we evaluated multiple machine learning models to predict compassion fatigue among nursing students. We constructed and validated models using logistic regression, random forest, XGBoost, and LightGBM. The dataset was divided into training and testing sets in a 7:3 ratio, with ten repetitions of sampling to reduce model error.\n\nTo assess the performance of these models, we used several evaluation metrics, including AUC (Area Under the Curve), PR curve (Precision-Recall curve), DCA (Decision Curve Analysis), and calibration curves. These metrics provided a comprehensive evaluation of model performance and prediction accuracy.\n\nThe logistic regression model demonstrated superior generalization ability on the test set, with the highest AUC value. Additionally, the DCA results indicated that logistic regression and random forest models had higher net benefits at different thresholds, showcasing their good clinical application potential. Calibration curve analysis further revealed that the logistic regression model had higher prediction accuracy on the test set, with lower calibration error and greater reliability.\n\nIn the PR curve analysis, the logistic regression model performed best when handling imbalanced data, achieving the highest AP (Average Precision) value on the test set. This consistent performance across multiple metrics underscores the logistic regression model's effectiveness in predicting compassion fatigue.\n\nWhile we did not compare our methods to publicly available benchmark datasets, the rigorous evaluation using various metrics and the superior performance of the logistic regression model provide strong evidence of its reliability and applicability in predicting compassion fatigue among nursing students.",
  "evaluation/confidence": "The evaluation of the models involved several performance metrics, including AUC, PR curves, DCA, and calibration curves. The logistic regression model demonstrated superior performance on the test set, with the highest AUC and AP values, indicating strong generalization ability. The results showed that the logistic regression model had higher net benefits at different thresholds in the DCA, demonstrating good clinical application potential. Additionally, the calibration curve analysis revealed that the logistic regression model had higher prediction accuracy on the test set, with lower calibration error and greater reliability.\n\nThe statistical significance of the results was assessed using p-values. For instance, in the multivariate logistic regression analysis, variables such as hospital level, age, psychological resilience, social support, empathy satisfaction, and secondary trauma showed statistically significant p-values (p < 0.05), indicating that these factors have a significant impact on compassion fatigue. The odds ratios (OR) and 95% confidence intervals (CI) were provided for each variable, further supporting the statistical significance of the findings.\n\nThe use of tenfold cross-validation in the logistic regression analysis ensured that the model's performance was robust and not dependent on a specific split of the data. The average AUC of the training set was 0.81, with the validation set's AUC slightly lower, and the test set's AUC at 0.77. This consistency across different datasets suggests that the model's performance is reliable and generalizable.\n\nOverall, the evaluation metrics and statistical analyses provide strong evidence that the logistic regression model is superior to other models and baselines in predicting compassion fatigue among nursing students. The results are statistically significant, and the model demonstrates high accuracy and generalization ability.",
  "evaluation/availability": "The raw evaluation files used in this study are not publicly available. However, the data and materials can be obtained from the corresponding author upon reasonable request. This approach ensures that the data is shared responsibly while maintaining the privacy and security of the participants, in line with the ethical guidelines followed throughout the study."
}