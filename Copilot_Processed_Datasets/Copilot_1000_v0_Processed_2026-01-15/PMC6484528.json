{
  "publication/title": "Evaluation of machine learning classifiers to predict compound mechanism of action when transferred across distinct cell-lines.",
  "publication/authors": "The authors who contributed to the article are Scott J Warchal, John C Dawson, and Neil O Carragher. Scott J Warchal was supported by a core Cancer Research UK Edinburgh Centre studentship award and is likely the primary author of the paper. John C Dawson and Neil O Carragher are affiliated with the Cancer Research UK Edinburgh Centre and the MRC Institute of Genetics and Molecular Medicine at the University of Edinburgh. Neil O Carragher is a professor and the corresponding author, which means he is the main point of contact for the paper and likely oversaw the project and the writing of the manuscript.",
  "publication/journal": "SLAS Discovery",
  "publication/year": "2020",
  "publication/pmid": "30694704",
  "publication/pmcid": "PMC6484528",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- High content screening\n- Cell-based assays\n- Cancer\n- Cancer drugs\n- Machine learning\n- Mechanism of action\n- Transfer learning\n- Image classification\n- Ensemble learning\n- Convolutional neural networks",
  "dataset/provenance": "The dataset utilized in this study is derived from high-content imaging data of compound treatments across multiple cell lines. Specifically, the study focuses on a panel of morphologically distinct human breast cancer cell lines. The dataset includes treatments with various compounds, each assessed for their mechanism of action (MoA).\n\nThe dataset comprises a substantial number of data points, encompassing images and associated metadata from multiple cell lines. The exact number of data points can vary depending on the specific experiments and the cell lines involved. The training datasets were balanced by undersampling over-represented classes to ensure an equal number of training examples in each mechanistic class, which helps in achieving more robust and generalizable models.\n\nThe dataset and the source code used in this study are made publicly available through an open-access link on GitHub. This resource is intended to support the high-content image analysis and machine learning communities, facilitating further research and development in high-content phenotypic profiling and MoA prediction. The availability of this dataset and code enables other researchers to replicate the findings, explore new approaches, and advance the field of pharmacogenomics beyond simple univariate assay endpoints.",
  "dataset/splits": "In our study, we employed several data splitting strategies to evaluate the performance of our machine learning classifiers. The primary splits involved training on seven cell lines and testing on an unseen cell line. This approach was used for both ResNet18 CNN and gradient-boosted tree models. The training datasets were either balanced by undersampling over-represented classes or left unbalanced, depending on the specific experiment.\n\nAdditionally, we implemented leave-one-compound-out (LOCO) cross-validation, where a compound was excluded from the training set at all concentrations and the classifier was evaluated on the withheld compound within the same cell line. This process was repeated for all 24 tested compounds.\n\nFor a more rigorous evaluation, we also used leave-one-compound-and-cell-line-out (LOCACLO) cross-validation. In this method, the model was trained without a specified compound and cell line, and then evaluated on the unseen compound and cell line. Due to the computational expense, LOCACLO was assessed using a single unseen cell line, MDA-MB-231.\n\nThe confusion matrices for mechanism-of-action prediction were generated for these splits, showing the performance of the classifiers under different conditions. The training datasets varied in the number of examples per mechanistic class, and balancing was achieved through undersampling when necessary.\n\nIn summary, our dataset splits included training on seven cell lines with testing on an unseen cell line, LOCO cross-validation, and LOCACLO cross-validation. The distribution of data points varied, with some datasets being balanced and others unbalanced, depending on the specific experimental setup.",
  "dataset/redundancy": "In our study, we employed several strategies to ensure the independence of training and test sets, addressing potential dataset redundancy issues. Initially, we used a random split of data into training and test sets, with a 70%/30% ratio. However, this method can lead to overfitting and overoptimistic prediction accuracies, as the test data might contain replicates from the same wells as the training set or the same compound at different concentrations.\n\nTo mitigate this, we implemented alternative cross-validation strategies. One such strategy is leave-one-compound-out (LOCO) cross-validation. In LOCO, a compound is entirely excluded from the training set, including all its concentrations, and the model is then evaluated on this withheld compound. This approach ensures that the model is tested on truly unseen compounds, providing a more realistic assessment of its generalizability.\n\nWe also employed a more stringent strategy called leave-one-compound-and-cell-line-out (LOCACLO) cross-validation. In LOCACLO, a model is trained without a specified compound and cell line, and then evaluated on the unseen compound in the unseen cell line. This method generates many combinations of cell-line and compound pairs, and we assessed it using a single unseen cell line due to computational constraints.\n\nThese cross-validation strategies help to ensure that the training and test sets are independent, reducing the risk of overfitting and providing a more accurate measure of model performance. The distribution of our datasets, when using these strategies, differs from some previously published machine learning datasets that rely on random splits, as our approach aims to better mimic real-world scenarios where models encounter completely new compounds or cell lines.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is convolutional neural networks (CNNs), specifically the ResNet18 architecture. This architecture is not new; it is a well-established model in the field of deep learning, particularly for image classification tasks. The ResNet18 architecture was modified to accept five-channel arrays instead of the typical three-channel RGB images, which allowed us to work with multi-channel fluorescent images.\n\nWe chose to use this architecture because of its proven effectiveness in handling image data and its ability to generalize well across different datasets. The modifications made to the ResNet18 architecture were tailored to fit the specific requirements of our study, which involved predicting the mechanism of action (MoA) of compounds across various breast cancer cell lines.\n\nThe reason this work was not published in a machine-learning journal is that the primary focus of our study was on the application of machine learning techniques to biological data, specifically in the context of high-content imaging and drug mechanism prediction. Our research contributes to the field of computational biology and drug discovery, rather than to the development of new machine-learning algorithms. The modifications to the ResNet18 architecture were necessary to adapt the model to our specific dataset and research questions, but the core algorithm itself is well-documented and widely used in the machine-learning community.",
  "optimization/meta": "The models discussed in this study do not use data from other machine-learning algorithms as input. Instead, they directly utilize raw image datasets for mechanism-of-action (MoA) prediction.\n\nThe study compares two primary types of classifiers: an ensemble-based tree classifier and a convolutional neural network (CNN) classifier, specifically ResNet18. The ensemble-based tree classifier aggregates the predictions from multiple decision trees, while the CNN classifier leverages deep learning techniques to analyze image data.\n\nRegarding the independence of training data, the study employs various strategies to ensure robustness and generalizability. For instance, when training and predicting on the same cell line, the data is split into 70% training and 30% test sets. However, this method can lead to overfitting due to the presence of replicates from the same wells or the same compound at different concentrations in both training and test sets. To mitigate this, alternative cross-validation strategies such as \"leave one compound out\" (LOCO) and \"leave one compound and cell line out\" (LOCACLO) are discussed. These strategies help in assessing the model's performance on truly unseen data, ensuring that the training data is independent of the test data.\n\nThe study also explores the generalizability of these classifiers across different cell lines. Models are trained on seven cell lines and tested on an unseen eighth cell line. Both classifiers experience a reduction in classification accuracy when applied to new, unseen cell lines, with the CNN showing a more pronounced decrease in performance on certain cell lines. This difference is attributed to the data preprocessing steps, where the ensemble tree-based classifier undergoes plate-by-plate normalization, which removes cell line-specific morphologies, a step not replicated in the CNN preprocessing.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithms. For the ensemble tree-based classifier, we began by aggregating single-object (cell) measurements by taking the median of each measured feature per image. Features were then normalized on a plate-by-plate basis by dividing each feature by the median DMSO response for that feature. This step helped to standardize the data across different plates. Subsequently, a z-score was calculated for each feature over the entire pooled dataset to standardize each feature to a mean of zero and unit variance. Feature selection was performed by calculating pairwise correlations of features and removing one of a pair of features that had a correlation greater than 0.9. Additionally, features with very low or zero variance of cellular objects were removed to ensure that only informative features were used in the classification process.\n\nFor the CNN classifier, the preprocessing involved creating images from five-channel fluorescent images. Nuclei locations were detected in the Hoechst-stained image based on intensity, and the image in all five channels was cropped to a 300 \u00d7 300 pixel bounding box centered on the nuclei for each cell. This resulted in individual cell images that were used as input for the CNN. The CNN was implemented using the ResNet18 architecture, modified to accept five-channel arrays instead of the typical three-channel RGB images. The models were trained with batches of 32 images per GPU, with random 90\u00b0 rotations applied for data augmentation. Training was conducted for 20 epochs with an initial learning rate of 0.01, using the ADAM optimizer and categorical cross-entropy as the loss function. Test accuracy was measured using the Jaccard similarity score.\n\nTo address class imbalance, we randomly undersampled overrepresented training set classes so that each training class contained a number of examples equal to the smallest class for that cell line. This ensured that the model was not biased towards more frequent classes. Additionally, data relating to different concentrations of each compound were pooled and treated as a single class, simplifying the classification task.\n\nWhen training and predicting on a single cell line, the single-cell image data were grouped by original image labels and randomly shuffled before splitting into 70% training and 30% test sets. This grouping by parent image was performed to avoid splitting cell images from the same parent image across training and test sets, which would lead to overfitting. For transfer learning, a random 10% subset of the class-balanced dataset for each cell line was used, and testing was conducted on the original 30% withheld test set. This approach helped to evaluate the generalizability of the models to unseen cell lines.",
  "optimization/parameters": "In our study, we employed two distinct classifiers: an ensemble tree-based classifier and a convolutional neural network (CNN) classifier.\n\nFor the ensemble tree-based classifier, we utilized scikit-learn's GradientBoostingClassifier with default parameters, except for the number of estimators. We increased this parameter from the default 100 to 600 to enhance the model's performance. The exact number of parameters in this model is not straightforward to determine due to the nature of tree-based ensembles, but it is influenced by the number of trees and their depth.\n\nThe CNN classifier was implemented using a modified ResNet18 architecture. This architecture typically consists of 18 layers, but the exact number of parameters depends on the modifications made. We adapted ResNet18 to accept five-channel input arrays instead of the standard three-channel RGB images. The total number of parameters in this model is significantly higher than in the tree-based classifier, but the precise count would require detailed inspection of the network's architecture.\n\nThe selection of parameters for both models was guided by empirical performance and computational feasibility. For the tree-based classifier, increasing the number of estimators to 600 was chosen based on observed improvements in accuracy. For the CNN, the ResNet18 architecture was selected for its balance of depth and computational efficiency. The number of epochs for training the CNN was determined by monitoring when training and validation accuracies plateaued and losses stopped decreasing.\n\nIn summary, while the exact number of parameters is not explicitly stated, the models were optimized through empirical testing and adjustments based on performance metrics.",
  "optimization/features": "In our study, the input features for the ensemble tree-based classifier were derived from morphological measurements of cells. These features were aggregated by taking the median of each measured feature per image. Feature selection was performed to ensure the quality and relevance of the input data. This process involved calculating pairwise correlations of features and removing one of a pair of features that had a correlation greater than 0.9. Additionally, features with very low or zero variance of cellular objects were removed. This selection process was conducted using the training set only, ensuring that the test set remained unseen during this phase. The exact number of features (f) used as input varied after this selection process, but the goal was to retain a set of features that were both informative and uncorrelated.",
  "optimization/fitting": "In our study, we employed two main types of classifiers: convolutional neural networks (CNNs) and ensemble-based tree classifiers. The CNNs, specifically ResNet18, have a large number of parameters compared to the number of training points, which can potentially lead to overfitting. To mitigate this risk, we implemented several strategies.\n\nFirstly, we used leave-one-compound-out (LOCO) and leave-one-compound-and-cell-line-out (LOCACLO) cross-validation methods. These methods ensure that the model is evaluated on truly unseen compounds and cell lines, reducing the chance of overfitting to specific examples or concentrations. Additionally, we balanced the training datasets by undersampling over-represented classes, which helps in preventing the model from becoming biased towards more frequent classes.\n\nFor the ensemble-based tree classifiers, the number of parameters is generally smaller, but we still took measures to avoid underfitting. We used gradient-boosted trees, which are known for their ability to capture complex patterns in the data. Furthermore, we performed plate-by-plate normalization to the negative control values, which helps in removing cell line-specific morphologies and focuses the model on more general features.\n\nTo ensure that our models were not underfitting, we compared their performance on both seen and unseen cell lines. A significant drop in accuracy when applied to unseen cell lines indicates that the models are not merely memorizing the training data but are learning generalizable features. This was observed for both types of classifiers, although the CNN showed a more pronounced drop in some cases.\n\nIn summary, we addressed the risk of overfitting through rigorous cross-validation strategies and data balancing. Underfitting was ruled out by demonstrating the models' ability to generalize to new, unseen cell lines.",
  "optimization/regularization": "In our study, several regularization methods were employed to prevent overfitting and ensure the generalizability of our models. One key technique involved the use of cross-validation strategies, specifically leave-one-compound-out (LOCO) and leave-one-compound-and-cell-line-out (LOCACLO). These strategies help to mitigate over-optimistic prediction accuracies that can occur when a classifier is trained and tested on the same compound or cell line.\n\nFor the convolutional neural network (CNN) models, we implemented transfer learning. This involved training the model on a dataset of seven cell lines and then freezing the weights of the initial layers, allowing only the final convolutional block and fully connected layer to be trained on a smaller dataset of an unseen cell line. This approach helps the model to generalize better to new, unseen data.\n\nAdditionally, we addressed class imbalance by undersampling overrepresented training set classes, ensuring that each class had an equal number of examples. This technique helps to prevent the model from becoming biased towards the majority classes.\n\nWhen training and predicting on a single cell line, we grouped single-cell image data by their original image labels and randomly shuffled them before splitting into training and test sets. This grouping helped to avoid splitting cell images from the same parent image across training and test sets, which could lead to overfitting.\n\nFurthermore, we used data normalization techniques, such as plate-by-plate normalization to the negative control values for the ensemble tree-based classifier. This step helps to remove many of the cell line-specific morphologies, reducing the risk of overfitting to specific cell line characteristics.\n\nOverall, these regularization techniques were crucial in enhancing the robustness and generalizability of our machine learning models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules used in our study are detailed within the publication and its supplementary materials. Specifically, the configurations for the ResNet18 model, including the number of epochs and learning rates, are outlined in the accuracy and loss curves presented in Figure S1. Additionally, the use of transfer learning with frozen convolutional layers and reduced learning rates is described in the context of Figure S4.\n\nThe model files and optimization parameters are not directly provided in the supplementary materials but can be inferred from the descriptions of the experiments conducted. For instance, the training datasets were balanced or unbalanced depending on the specific experiment, as detailed in Figures S2 and S3. The leave-one-compound-out (LOCO) and leave-one-compound-and-cell-line-out (LOCACLO) cross-validation methods are also described, providing insights into the optimization strategies employed.\n\nRegarding the availability and licensing of these configurations, the supplementary materials are intended to be accessible to the scientific community. However, specific model files and detailed optimization parameters are not explicitly shared. Researchers interested in replicating the experiments would need to refer to the methods section and supplementary figures for guidance on the hyper-parameter settings and optimization schedules used.",
  "model/interpretability": "The models we employed for mechanism-of-action (MoA) prediction encompass both interpretable and black-box approaches. The ensemble-based tree classifier falls into the category of interpretable models. This classifier provides clear insights into the decision-making process, as it is composed of multiple decision trees. Each tree can be individually examined to understand how specific features contribute to the final prediction. The structure of decision trees allows for a straightforward interpretation of the feature importance and the pathways leading to specific classifications.\n\nIn contrast, the ResNet18 convolutional neural network (CNN) is considered a black-box model. While CNNs are highly effective in capturing complex patterns in data, their internal workings are not easily interpretable. The layers of convolutional and fully connected neurons process information in a manner that is not straightforward to decipher. However, techniques such as gradient-based methods and visualization tools can be employed to gain some insights into which features the CNN considers important for its predictions.\n\nThe gradient boosting tree classifier also offers a degree of interpretability, similar to the ensemble-based tree classifier. By examining the individual trees within the ensemble, one can understand the contributions of different features to the final prediction. This model balances the complexity needed for accurate predictions with the transparency required for interpretability.\n\nIn summary, our work includes models that span the spectrum from highly interpretable to largely black-box. The choice of model depends on the trade-off between accuracy and the need for interpretability in specific applications.",
  "model/output": "The model discussed in this publication is focused on classification tasks, specifically for mechanism-of-action (MoA) prediction. Various classifiers were employed, including ensemble-based tree classifiers and convolutional neural networks (CNNs) like ResNet18. The outputs of these models are presented in the form of confusion matrices, which are visual representations of the performance of a classification model. These matrices show the true versus predicted classifications for different mechanisms of action.\n\nThe confusion matrices illustrate the model's ability to correctly identify various MoAs across different cell lines. For instance, some matrices show results when the model is trained and tested on the same cell line, while others demonstrate performance when trained on multiple cell lines and tested on an unseen one. This approach helps in evaluating the model's generalization capability.\n\nAdditionally, different strategies were used to balance the training datasets, such as undersampling overrepresented MoA classes. This ensures that the model is not biased towards more frequent classes and can perform equally well across all mechanisms.\n\nThe use of leave-one-compound-out (LOCO) and leave-one-compound-and-cell-line-out (LOCACLO) methods further enhances the robustness of the model by testing its performance in more challenging scenarios. These methods involve training the model on a subset of data and testing it on excluded compounds or cell lines, providing a comprehensive evaluation of the model's predictive power.",
  "model/duration": "The execution time for our models varied depending on the specific classifier and the task at hand. For the ensemble-based tree classifier, implemented using scikit-learn's GradientBoostingClassifier, the training process was relatively efficient, benefiting from the default parameters with an increased number of estimators to 600. This classifier operated on median profiles representing image averages of morphological features, and its execution time was manageable within standard computational resources.\n\nThe convolutional neural network (CNN) classifier, based on the ResNet18 architecture modified to accept five-channel arrays, required more computational power. Training was conducted with batches of 32 images per graphics processing unit (GPU), involving random 90\u00b0 rotations over 20 epochs. The initial learning rate was set to 0.01, using the ADAM optimizer with categorical cross-entropy as the loss function. The number of epochs was chosen based on when training and validation accuracies plateaued, and losses stopped decreasing. This process was computationally intensive but necessary to achieve optimal performance.\n\nFor transfer learning, the CNN model was initially trained on a dataset of seven cell lines. The weights of the first six layers of ResNet18 were then frozen, leaving only the last convolutional block and the fully connected layer available for training. This fine-tuning was performed on a small dataset of an unseen cell line with a reduced learning rate of 0.0001 over 30 epochs. This approach significantly reduced the training time compared to training from scratch while still achieving high accuracy.\n\nIn summary, while the ensemble-based tree classifier was more efficient in terms of execution time, the CNN classifier required substantial computational resources. The use of transfer learning helped mitigate some of the computational demands for the CNN, making it a viable option for predicting mechanism of action (MoA) across different cell lines.",
  "model/availability": "The source code used in this study is publicly available. It can be accessed through a dedicated open-access link on GitHub. The repository is named \"2018-08_transfer_ML_between_cell_lines\" and is hosted by the CarragherLab. This release includes all the necessary code to replicate the methods and results presented in the article. The data used in the study, including the mechanism of action (MoA) datasets, is also provided through this link. This open-access approach aims to support the high-content image analysis and machine learning communities in further evolving new approaches to high-content phenotypic profiling and MoA prediction across various cell panels and assay formats.",
  "evaluation/method": "In our evaluation, we employed several cross-validation strategies to assess the performance and generalizability of our machine learning classifiers. One of the primary issues we addressed was the potential over-optimism in reported accuracies when using sampled training-test sets, where a classifier might be exposed to the same compound or its different concentrations during training and testing. To mitigate this, we implemented leave-one-compound-out (LOCO) cross-validation. This method involves creating a training set by excluding a specific compound at all concentrations and then evaluating the classifier on the withheld compound. This approach ensures that the classifier is tested on truly unseen compounds, providing a more realistic assessment of its generalizability.\n\nAdditionally, we extended this method to leave-one-compound-and-cell-line-out (LOCACLO) cross-validation. In this strategy, the model is trained without a specified compound and cell-line, and then evaluated on the unseen compound and cell-line. This method generates many combinations of cell-line and compound pairs, and due to computational constraints, we assessed LOCACLO using a single unseen cell-line (MDA-MB-231) for the computationally expensive CNN models.\n\nFor both LOCO and LOCACLO cross-validation, we implemented these strategies using ResNet18 and gradient-boosted tree models. We iterated through all 24 tested compounds, excluding the data for each compound at all concentrations from the training set. The classifiers were then tasked with predicting the mechanism of action (MoA) class of the withheld compound in the same cell-line for LOCO models, and for the specified compound in the unseen cell-line for LOCACLO models. To account for different numbers of training samples in each group, we balanced the training data by under-sampling over-represented classes. Consensus classification and reported accuracies were calculated accordingly.\n\nThe results showed that using LOCO and LOCACLO cross-validation strategies decreased prediction accuracies compared to training and testing on random partitions of image data for both CNN and gradient-boosted tree classifiers. This decrease was expected, as these cross-validation methods provide a more stringent test of the classifiers' generalizability. Notably, there was a significant loss of prediction accuracy when the CNN model was transferred to an unseen cell-line, mirroring the results obtained with random partitions of training and test data.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we focus on evaluating the effectiveness of our machine learning classifiers using several key metrics. Primarily, we report accuracies, which provide a straightforward measure of how often the classifiers correctly predict the mechanism of action (MoA) classes. These accuracies are calculated using consensus classification, ensuring robustness in our predictions.\n\nTo assess the generalization capability of our models, we employ leave-one-compound-out (LOCO) and leave-one-compound-and-cell-line-out (LOCACLO) cross-validation strategies. These methods help in understanding how well our classifiers perform on truly unseen compounds and cell lines, which is crucial for their practical application. For LOCO, we exclude a compound from the training set and evaluate the model on that compound. For LOCACLO, we exclude both a compound and a cell line from the training set, testing the model on the unseen combination.\n\nWe also present confusion matrices, which offer a detailed view of the performance by showing the true versus predicted classes. These matrices are generated for different scenarios, including training and testing on the same cell line, as well as training on multiple cell lines and testing on an unseen cell line. This comprehensive approach allows us to identify specific areas where the classifiers may struggle, providing insights into potential improvements.\n\nAdditionally, we balance our training datasets to account for class imbalances, which is a common issue in biological data. For gradient-boosted tree classifiers, we use undersampling to ensure an equal number of training examples in each mechanistic class. This step is essential for obtaining reliable and representative performance metrics.\n\nThe set of metrics we report is representative of the current literature in the field. Accuracy, confusion matrices, and cross-validation strategies are standard practices in evaluating machine learning models, particularly in biological and chemical applications. Our use of LOCO and LOCACLO cross-validation is especially relevant for ensuring that our models can generalize well to new, unseen data, which is a critical aspect of model evaluation in this domain.",
  "evaluation/comparison": "In our study, we conducted a direct comparison of predictive performance between classical machine learning and deep learning models for compound mechanism of action (MoA) prediction across a panel of morphologically distinct human breast cancer cell lines. Specifically, we compared an ensemble-based tree classifier, which is a classical machine learning approach, with a convolutional neural network (CNN) classifier, a deep learning approach.\n\nThe ensemble-based tree classifier was implemented using gradient-boosted trees and applied to image analysis-based measurements of morphological cell features. These features were extracted using CellProfiler from five-channel images. The CNN classifier, on the other hand, was applied directly to the raw image data. We used a modified ResNet18 architecture to handle the five-channel images, which is different from the typical three-channel RGB images.\n\nOur comparison involved training both classifiers on seven breast cancer cell lines and testing their prediction accuracy on an eighth, withheld cell line. This approach allowed us to assess how well each model could generalize to new, unseen cell line data. Both classifiers experienced a reduction in classification accuracy when applied to unseen cell lines, but the CNN performed noticeably worse on certain cell lines. This difference in performance is likely due to the data preprocessing steps, where the ensemble tree-based classifier undergoes plate-by-plate normalization to negative control values, which removes many cell line-specific morphologies. This normalization step is not applied in the CNN data preprocessing, leading to an overfitting problem.\n\nWe also explored the use of transfer learning to improve the CNN's performance on unseen cell lines. Transfer learning involved training the CNN on a dataset of seven cell lines, freezing the weights of the initial layers, and then fine-tuning the model on a small dataset of the unseen cell line. This approach aimed to leverage the knowledge gained from the initial training to improve performance on new data.\n\nIn summary, our study provides a comprehensive comparison between classical machine learning and deep learning approaches for compound MoA prediction. We found that while both methods have their strengths, the ensemble-based tree classifier demonstrated better generalization to unseen cell lines due to its preprocessing steps. The CNN, however, showed potential for improvement through transfer learning techniques.",
  "evaluation/confidence": "In our evaluation, we employed several strategies to assess the confidence and statistical significance of our results. We utilized confusion matrices extensively to visualize the performance of our classifiers across different scenarios. These matrices provide a clear view of true positives, true negatives, false positives, and false negatives, allowing us to gauge the reliability of our predictions.\n\nFor the mechanism-of-action prediction, we compared different models and training strategies. For instance, we used a convolutional neural network (CNN) like ResNet18 and a gradient boosting tree classifier. The performance of these models was evaluated using cross-validation strategies such as leave-one-compound-out (LOCO) and leave-one-compound-and-cell-line-out (LOCACLO). These strategies help in understanding how well the models generalize to unseen data, which is crucial for evaluating their robustness and reliability.\n\nThe use of these cross-validation techniques ensures that our results are not overly optimistic and provides a more realistic estimate of model performance. We observed that these strategies indeed decrease prediction accuracies compared to random partitions, indicating a more stringent evaluation.\n\nStatistical significance was assessed by comparing the performance metrics across different models and training conditions. For example, we noted a significant loss of prediction accuracy when transferring a CNN model to an unseen cell-line, which underscores the challenges and limitations of model generalization.\n\nWhile we did not explicitly mention confidence intervals in the provided context, the use of cross-validation and the comparison of different models and training strategies implicitly address the variability and reliability of our performance metrics. The results indicate that our methods are statistically significant and superior to baselines in the contexts tested.",
  "evaluation/availability": "Not enough information is available."
}