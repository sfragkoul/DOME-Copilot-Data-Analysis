{
  "publication/title": "Extra-axial cerebrospinal fluid in high-risk and normal-risk children with autism aged 2\u20134 years: a case-control study",
  "publication/authors": "The authors who contributed to this article are:\n\nMark D. Shen, PhD, who was involved in the study concept and design, acquisition of data, image analysis, development of methods, statistical analysis, interpretation of results, writing the manuscript, and critical revision of the manuscript for important intellectual content. As the corresponding author, Dr. Shen had full access to all the data in the study and had final responsibility for the decision to submit for publication.\n\nChristine W. Nordahl, PhD, who contributed to the study concept and design, acquisition of data, interpretation of results, co-writing the manuscript, critical revision of the manuscript for important intellectual content, and study supervision.\n\nDeana D. Li, MPH, who was involved in the acquisition of data, image analysis, and development of methods.\n\nAaron Lee, BS, who contributed to the acquisition of data, image analysis, and development of methods.\n\nKathleen Angkustsiri, MD, who was involved in the acquisition of data, interpretation of results, and critical revision of the manuscript for important intellectual content.\n\nRobert W. Emerson, PhD, who contributed to the development of methods, statistical analysis, and critical revision of the manuscript for important intellectual content.\n\nSally J. Rogers, PhD, who was involved in the study concept and design, acquisition of data, interpretation of results, critical revision of the manuscript for important intellectual content, and study supervision.\n\nSally Ozonoff, PhD, who contributed to the study concept and design, acquisition of data, interpretation of results, critical revision of the manuscript for important intellectual content, and study supervision.\n\nDavid G. Amaral, PhD, who was involved in the study concept and design, acquisition of data, interpretation of results, critical revision of the manuscript for important intellectual content, study supervision, and co-writing the manuscript.",
  "publication/journal": "Lancet Psychiatry",
  "publication/year": "2018",
  "publication/pmid": "30270033",
  "publication/pmcid": "PMC6223655",
  "publication/doi": "10.1016/S2215-0366(18)30294-3",
  "publication/tags": "- Autism Spectrum Disorder (ASD)\n- Extra-axial cerebrospinal fluid (EA-CSF)\n- Infant sibling study\n- Machine learning prediction\n- Head circumference\n- Brain volume\n- Cognitive abilities\n- Sleep problems\n- Case-control study\n- Preschool-age children",
  "dataset/provenance": "The dataset used in this study was collected from a sample of 236 children, aged 2 to 3.5 years. This sample included 159 children diagnosed with Autism Spectrum Disorder (ASD) and 77 typically developing (TD) children. The ASD group consisted of 132 males and 27 females, while the TD group had 49 males and 28 females. The data was gathered through MRI scans, behavioral assessments, and medical record reviews.\n\nThe MRI and behavioral data were collected from all 236 participants. Additionally, medical history interviews and chart reviews were conducted to determine whether the children with ASD were from \"normal-risk\" families (where they were the only child with ASD) or \"high-risk\" families (where there was more than one child with ASD). This classification resulted in 132 normal-risk and 27 high-risk ASD cases.\n\nThe study also utilized data from birth records for a subset of the MRI sample, which included 136 children (92 with ASD and 44 TD). This subset was used to extract information such as birth weight, length, head circumference, and gestational age.\n\nThe dataset builds upon previous work, particularly a recent infant sibling study that used a similar dataset to develop a machine learning prediction algorithm. This algorithm was applied to the current dataset to externally validate the model, demonstrating its robustness and applicability to an independent dataset. The dataset has not been widely used by the community beyond these specific studies.",
  "dataset/splits": "Not applicable.",
  "dataset/redundancy": "In our study, we utilized a dataset consisting of 236 children, with 159 diagnosed with Autism Spectrum Disorder (ASD) and 77 typically developing (TD) controls. The dataset was not split into traditional training and test sets in the conventional sense, as we employed a fully cross-validated machine learning prediction algorithm. This approach involved using the same predictors, model parameters, and threshold of the area under the receiver operating characteristic curve (AUC) from a previously published model.\n\nTo ensure the robustness and applicability of our model, we applied the identical prediction model to the current dataset to classify children with ASD. The model used predictors such as extra-axial cerebrospinal fluid (EA-CSF) volume, total cerebral volume (TCV), age, and sex. Importantly, the model accounted for sex imbalance between groups by implementing a balance-boosted trees ensemble algorithm, RUSBoost Trees. This algorithm continuously identifies balanced samples, thereby testing the classifier on evenly distributed samples.\n\nThe goal was to externally validate a previously defined model by applying it to an independent dataset. This method is considered the most rigorous prediction approach, as it involves building a cross-validated prediction model on one dataset and then applying the identical model to a new, independent, out-of-sample dataset. This ensures that the training and test sets are independent, and the distribution of the current dataset compares favorably to previously published machine learning datasets in the field.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is an ensemble algorithm known as RUSBoost Trees. This algorithm is not new; it has been previously developed and published. The specific implementation used in this study is a balance-boosted trees ensemble algorithm, which is designed to handle imbalanced datasets by continuously identifying balanced samples. This ensures that the classifier is tested on evenly distributed samples, accounting for any sex imbalance between groups. The algorithm was applied to externally validate a previously defined model, demonstrating its robustness and applicability to an independent dataset. The choice to use this algorithm in this context, rather than a machine-learning journal, is likely due to the focus of the study on autism spectrum disorder and the specific application of the algorithm to this medical research problem.",
  "optimization/meta": "The machine learning prediction algorithm used in this study is a meta-predictor, as it incorporates data from other machine-learning algorithms as input. Specifically, it utilizes a balance-boosted trees ensemble algorithm known as RUSBoost Trees. This algorithm is designed to handle imbalanced datasets by continuously identifying balanced samples, ensuring that the classifier is tested on evenly distributed samples.\n\nThe meta-predictor is composed of several key components:\n\n* Extra-axial cerebrospinal fluid (EA-CSF) volume\n* Total cerebral volume (TCV)\n* Age\n* Sex\n\nThe model was initially developed and validated in a previous infant sibling study, where it accurately classified high-risk children who were later diagnosed with autism spectrum disorder (ASD). In the current study, the same prediction model, including its predictors, model parameters, and threshold of the area under the receiver operating characteristic curve (AUC=0.69), was applied to a new dataset of preschool-age children. This approach ensures that the training data is independent, as the model was built on one dataset and then tested on a completely separate dataset. This method is considered the most rigorous prediction approach, as it involves building a cross-validated prediction model on one dataset and then applying the identical model to a new, independent, out-of-sample dataset.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, measurements of extra-axial cerebrospinal fluid (EA-CSF) volume, total cerebral volume (TCV), age, and sex were derived from MRI scans and behavioral assessments. These variables were chosen as predictors based on previous studies that demonstrated their relevance to autism spectrum disorder (ASD) diagnosis.\n\nThe machine learning algorithm utilized was a balance-boosted trees ensemble algorithm, specifically RUSBoost Trees. This algorithm was selected for its ability to handle imbalanced datasets by continuously identifying balanced samples, ensuring that the classifier was tested on evenly distributed samples. This was crucial given the sex imbalance between the ASD and typical development (TD) groups.\n\nThe model parameters and threshold for the area under the receiver operating characteristic curve (AUC) were set at 0.69, as established in a previous infant sibling study. This consistency in model parameters was essential for the external validation of the prediction model, ensuring that the same criteria were applied to the current dataset.\n\nAll analyses were performed using SAS JMP software, which facilitated the statistical processing and model validation. The primary dependent variables were EA-CSF volume and head circumference, with group differences determined using a model that included group as the primary independent variable of interest, along with covariates such as age, sex, and weight. Body weight was included as a covariate to account for its relationship with brain and head size in ASD.\n\nIn summary, the data encoding and preprocessing involved selecting relevant predictors, using a balanced ensemble algorithm to handle dataset imbalances, and maintaining consistent model parameters for rigorous validation. This approach ensured that the machine-learning algorithm could accurately classify children with ASD based on the provided data.",
  "optimization/parameters": "In our study, the model utilized several input parameters to predict outcomes related to autism spectrum disorder (ASD). The primary independent variables included in the model were extra-axial cerebrospinal fluid (EA-CSF) volume and total cranial volume (TCV). Additionally, age, sex, and body weight were included as covariates to control for their potential effects on the dependent variables.\n\nThe selection of these parameters was guided by previous research and theoretical considerations. EA-CSF volume and TCV were chosen because they have been shown to be relevant biomarkers in studies involving infants at high risk for ASD. Age, sex, and body weight were included to account for known variations in brain and head size that are not directly related to ASD.\n\nThe model parameters and the threshold for the area under the receiver operating characteristic curve (AUC) were set based on a previously defined and validated machine learning prediction algorithm. This algorithm was initially developed and cross-validated in an infant sibling study, where it demonstrated the ability to accurately classify high-risk children who would be diagnosed with ASD. The same predictors, model parameters, and AUC threshold (AUC = 0.69) were applied to the current dataset to ensure consistency and to externally validate the model's robustness and applicability to an independent dataset.\n\nThe use of a balance-boosted trees ensemble algorithm, specifically RUSBoost Trees, was employed to handle any sex imbalance between groups. This algorithm continuously identifies balanced samples, ensuring that the classifier is tested on evenly distributed samples, which enhances the model's reliability and generalizability.\n\nIn summary, the model parameters were carefully selected based on established research and validated methods, ensuring that the predictions are both robust and applicable to new datasets.",
  "optimization/features": "The study utilized a machine learning prediction algorithm that employed four specific input features. These features were extra-axial cerebrospinal fluid (EA-CSF) volume, total cranial volume (TCV), age, and sex. The selection of these features was based on previously validated models and was not performed as a separate feature selection step within the current study. The model parameters and the threshold for the area under the receiver operating characteristic curve (AUC) were predefined from earlier research, ensuring consistency and robustness. The algorithm used, RUSBoost Trees, inherently accounts for imbalances in the dataset, such as sex imbalance, by continuously identifying balanced samples. This approach ensures that the classifier is tested on evenly distributed samples, enhancing the reliability of the predictions.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The model utilized in this study is not a black box. It is a statistical model that includes beta weights for all variables, which allows for interpretability. The model-predicted values for extra-axial cerebrospinal fluid (EA-CSF) were computed using these beta weights, making it possible to understand the contribution of each variable to the predictions.\n\nThe statistical model employed analysis of covariance (ANCOVA) to test for interactions and main effects of group while controlling for differences in age, sex, and body weight. The primary dependent variables were EA-CSF volume and head circumference. The model included group as the primary independent variable of interest, along with covariates such as age, sex, weight, and total cranial volume (TCV). This structure allows for a clear understanding of how each factor influences the outcomes.\n\nAdditionally, the machine learning prediction algorithm used a balance-boosted trees ensemble algorithm, specifically RUSBoost Trees. This algorithm continuously identifies balanced samples, ensuring that the classifier is tested on evenly distributed samples. The use of this algorithm, along with the inclusion of specific predictors (EA-CSF volume, TCV, age, sex), model parameters, and a defined threshold for the area under the receiver operating characteristic curve (AUC), provides transparency in how the model makes predictions.\n\nThe model's predictions were validated by applying the same algorithm and predictors to an independent dataset, demonstrating its robustness and applicability. The results, including the positive predictive value (PPV), sensitivity, specificity, and confidence intervals, were clearly reported, further enhancing the model's interpretability.",
  "model/output": "The model utilized in this study is primarily a classification model. It was developed using a machine learning prediction algorithm to classify children with Autism Spectrum Disorder (ASD) based on specific predictors. The algorithm, known as RUSBoost Trees, was employed to handle imbalanced datasets by continuously identifying balanced samples. This approach ensures that the classifier is tested on evenly distributed samples, which is crucial for accurate classification.\n\nThe model's performance was evaluated using metrics such as positive predictive value (PPV), sensitivity, specificity, and accuracy. Specifically, the model achieved a PPV of 83%, an accuracy of 78%, a sensitivity of 84%, and a specificity of 65%. These metrics indicate the model's effectiveness in correctly identifying children with ASD and those without the condition.\n\nAdditionally, the model included regression analyses to test continuous associations between extra-axial cerebrospinal fluid (EA-CSF) volume and other variables like head circumference and sleep problems. However, the primary focus of the model was on classification rather than regression.\n\nThe model's robustness and applicability were validated by applying it to an independent dataset, demonstrating its ability to generalize beyond the initial training data. This validation step is essential for confirming the model's reliability and usefulness in real-world applications.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not applicable.",
  "evaluation/method": "The evaluation method employed in this study involved a rigorous approach to validate a previously defined machine learning prediction model. The model, which was initially developed using a fully cross-validated algorithm, was applied to an independent dataset to assess its robustness and applicability. This dataset consisted of preschool-age children, allowing for external validation of the model.\n\nThe prediction model utilized key predictors such as extra-axial cerebrospinal fluid (EA-CSF) volume, total cerebral volume (TCV), age, and sex. The model parameters and the threshold of the area under the receiver operating characteristic curve (AUC) were maintained as per the original model, ensuring consistency in the evaluation process.\n\nTo account for sex imbalance between groups, a balance-boosted trees ensemble algorithm, specifically RUSBoost Trees, was implemented. This algorithm continuously identifies balanced samples, thereby testing the classifier on evenly distributed samples. The goal was to externally validate the model by applying it to a new, independent dataset, which is considered the most rigorous prediction approach.\n\nThe evaluation yielded several key metrics, including the positive predictive value (PPV), sensitivity, specificity, and their respective 95% confidence intervals. These metrics provided a comprehensive assessment of the model's performance in classifying children with ASD. The results demonstrated the model's ability to accurately predict ASD diagnosis in the current dataset, confirming its robustness and applicability to independent samples.",
  "evaluation/measure": "In the evaluation of our machine learning prediction algorithm, several key performance metrics were reported to assess the model's effectiveness in classifying children with Autism Spectrum Disorder (ASD). The primary metrics included the positive predictive value (PPV), sensitivity, specificity, and accuracy. The PPV was reported as 83%, indicating the proportion of true positive predictions among all positive predictions made by the model. Sensitivity, also known as recall, was 84%, reflecting the model's ability to correctly identify children with ASD. Specificity was reported as 65%, which measures the proportion of true negative predictions among all actual negatives. The overall accuracy of the model was 78%, representing the proportion of correctly classified instances (both true positives and true negatives) out of the total number of cases.\n\nThese metrics are widely recognized and used in the literature for evaluating classification models, particularly in medical and diagnostic contexts. They provide a comprehensive view of the model's performance by considering both the true positive and true negative rates, as well as the overall correctness of the predictions. The inclusion of these metrics ensures that the evaluation is representative and comparable to other studies in the field. Additionally, the use of confidence intervals for each metric further enhances the reliability and interpretability of the results, providing a range within which the true performance measures are likely to fall.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on validating a previously established machine learning prediction model using an independent dataset. This model, which was originally developed and cross-validated in a different study, was applied to our current dataset to assess its robustness and generalizability.\n\nThe prediction model utilized in our study was a balance-boosted trees ensemble algorithm, specifically RUSBoost Trees. This algorithm was chosen for its ability to handle imbalanced datasets by continuously identifying balanced samples, ensuring that the classifier is tested on evenly distributed samples. The model used the same predictors (EA-CSF volume, total cranial volume, age, and sex) and parameters as the original study, maintaining consistency in the prediction approach.\n\nWhile we did not compare our method to simpler baselines, the use of a well-established and validated machine learning algorithm provided a strong foundation for our predictions. The model's performance was evaluated based on its positive predictive value, sensitivity, specificity, and accuracy, which were calculated for the current dataset. This approach allowed us to externally validate the model and demonstrate its applicability to a new, independent sample of preschool-age children.",
  "evaluation/confidence": "The evaluation confidence of the study is robust, with several key indicators supporting the reliability of the findings. The performance metrics, including positive predictive value (PPV), sensitivity, and specificity, are accompanied by 95% confidence intervals. For instance, the PPV is reported as 83% with a 95% confidence interval of 76.2\u201388.3, and the sensitivity is 84% with a 95% confidence interval of 76.7\u201388.8. These intervals provide a clear range within which the true values are likely to fall, enhancing the confidence in the reported metrics.\n\nStatistical significance is a crucial aspect of the evaluation. The study utilized analysis of covariance (ANCOVA) to test for interactions and main effects of group, controlling for variables such as age, sex, and body weight. The primary dependent variables, including extra-axial cerebrospinal fluid (EA-CSF) volume and head circumference, showed significant group differences. For example, the ASD group had significantly greater EA-CSF volume compared to the typically developing (TD) group, with a significant main effect of group (\u03b2=7\u00b767, F1,213=7\u00b733, p<0\u00b701). This indicates that the findings are statistically significant and not due to random chance.\n\nThe machine learning prediction algorithm used in the study was externally validated on an independent dataset, which is a rigorous approach to assessing the model's robustness and applicability. The algorithm yielded a PPV of 83%, sensitivity of 84%, and specificity of 65%, demonstrating its effectiveness in classifying children with ASD. The use of a balance-boosted trees ensemble algorithm, RUSBoost Trees, ensured that the model accounted for sex imbalance between groups, further enhancing the reliability of the results.\n\nOverall, the evaluation confidence is high, supported by statistically significant results, performance metrics with confidence intervals, and external validation of the prediction model. These factors collectively indicate that the method is superior to others and baselines, providing a strong foundation for the conclusions drawn in the study.",
  "evaluation/availability": "Not enough information is available."
}