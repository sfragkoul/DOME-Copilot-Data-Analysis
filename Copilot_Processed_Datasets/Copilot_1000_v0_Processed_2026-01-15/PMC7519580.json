{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to the article are:\n\n- Li X\n- Dvornek NC\n- Zhuang J\n- Ventola P\n- Duncan JS\n\nThe specific contributions of each author are not detailed in the provided information.",
  "publication/journal": "Information Processing in Medical Imaging",
  "publication/year": "2020",
  "publication/pmid": "32982121",
  "publication/pmcid": "PMC7519580",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Deep Learning\n- Biomarker Discovery\n- Autism Spectrum Disorder\n- Functional Magnetic Resonance Imaging\n- Shapley Value Explanation\n- Cooperative Game Theory\n- Feature Importance\n- Model Interpretation\n- Brain Connectivity\n- Machine Learning\n- Graph Structure\n- Monte Carlo Approximation\n- Random Forest\n- Neural Networks\n- Medical Imaging\n- Data Interpretation",
  "dataset/provenance": "The dataset used in our study consists of fMRI scans from a group of 82 children with Autism Spectrum Disorder (ASD) and 48 age and IQ-matched healthy controls. These scans were acquired using a Siemens MAGNETOM Trio TIM 3T scanner during a biological motion perception task. The fMRI data has a voxel size of 3.44 \u00d7 3.44 \u00d7 4mm\u00b3, with a repetition time (TR) of 2000ms and an echo time (TE) of 25ms, and a flip angle of 60\u00b0.\n\nThe data was split into training, validation, and testing sets, with 80% used for training, 10% for validation, and 10% for testing. The Automated Anatomical Labeling (AAL) atlas was employed to parcellate the brain into 116 regions. For each subject, a 116\u00d7116 adjacency matrix was computed using Pearson correlation, and the matrix was averaged over the patient subjects in the training data. The edges were then binarized based on whether their weight was larger than the average weight.\n\nThe dataset has been used previously in the community, as evidenced by its use in the development of the 2CC3D deep neural network classifier described in a prior study. This classifier utilizes each voxel's mean and standard deviation as two-channel inputs, starting with preprocessed 3D fMRI volumes downsampled to 32 \u00d7 32 \u00d7 32. The original fMRI sequence is denoted as X(x, y, z, t), with the mean-channel sequence and standard deviation-channel sequence derived from this data.",
  "dataset/splits": "The dataset was split into three parts: training, validation, and testing. The training set comprised 80% of the data, the validation set 10%, and the testing set also 10%. This split was done randomly.\n\nThe dataset consisted of 82 children with ASD and 48 age and IQ-matched healthy controls. Therefore, approximately 114 subjects were used for training, 15 for validation, and 15 for testing. The testing dataset specifically included 7 ASD subjects.",
  "dataset/redundancy": "The datasets were split based on subjects, ensuring that the training, validation, and testing sets were independent. This approach was taken to prevent data leakage and to ensure that the model's performance could be accurately evaluated on unseen data. By splitting the data in this manner, it was enforced that no subject appeared in more than one of the splits, maintaining the independence of the datasets.\n\nThe distribution of the datasets is not explicitly compared to previously published machine learning datasets. However, the method of splitting the data based on subjects is a common practice in medical imaging and other fields where subject-specific data is used. This approach helps to ensure that the results are generalizable and that the model is not overfitting to the training data. The specific details of the dataset distribution would depend on the characteristics of the subjects and the task at hand, but the focus was on ensuring the independence of the training and testing sets.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm discussed in the publication leverages concepts from cooperative game theory, specifically the Shapley value, to analyze the contributions of individual features (or players) in a network. The Shapley value is a well-established method in game theory used to fairly distribute the collective profit attained by a coalition of players based on their relative contributions.\n\nThe machine-learning algorithm class used is not a traditional supervised or unsupervised learning algorithm but rather a method for interpreting the importance of features in a model. It falls under the category of explainable AI (XAI) techniques, which aim to make the decisions of complex models more understandable.\n\nThe algorithm is not entirely new; it builds upon the foundational work of Shapley values in cooperative game theory. However, the application of Shapley values to high-dimensional data, such as that found in deep learning models, presents unique challenges. To address these challenges, two novel approaches are proposed to approximate the Shapley value efficiently. These approaches are designed to handle the high dimensionality of inputs in deep neural networks (DNNs) by reducing the dimension of the Shapley value testing features once the underlying graph structure of the features is defined.\n\nThe reason this work was not published in a machine-learning journal is that the primary focus is on the application of game theory to interpret the decisions of machine-learning models, particularly in the context of medical imaging and brain region analysis. The publication aims to demonstrate the feasibility and advantages of using Shapley value explanations (SVE) for feature importance analysis in complex models, rather than introducing a new machine-learning algorithm per se. The methods are validated through experiments on datasets such as MNIST and ASD task-fMRI, showing their practical utility in real-world applications.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it focuses on interpreting deep learning models using graph structure and cooperative game theory. The primary goal is to identify important features, or biomarkers, in functional magnetic resonance imaging (fMRI) data for autism spectrum disorder (ASD) diagnosis.\n\nThe methods employed involve using Shapley value explanation (SVE) from cooperative game theory to determine the importance of features. This approach considers the interaction between features, providing a more accurate way of identifying biomarkers compared to traditional methods that look at individual features in isolation.\n\nThe model does not use data from other machine-learning algorithms as input. Instead, it applies SVE to deep learning classifiers and other machine learning methods to understand the features they use for predictions. The validation process includes comparing SVE results to standard feature importance methods in a Random Forest (RF) classifier trained on ASD/control subjects from fMRI data.\n\nThe training data for the deep learning classifier and the RF classifier are independent, ensuring that the feature importance analysis is robust and not biased by overlapping data. The methods are designed to be generalizable to other feature importance analysis problems where the underlying graph structure of features is available.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithms employed. For the MNIST dataset, images were parcellated into regions of interest (ROIs) using the SLIC superpixel method. This approach mimics the setting of detecting saliency brain ROIs for identifying conditions like autism spectrum disorder (ASD). The distance between the centers of ROI i and ROI j was denoted as dij, and the connection between ROI i and j was defined as aij = exp(-dij/2). This encoding helped in defining the underlying graph structure of the data, which was essential for simplifying the calculation of Shapley values.\n\nFor the ASD task-fMRI dataset, the data was augmented to 18,720 samples using a temporal sliding window size of 3. This augmentation helped in capturing the temporal dynamics of the brain activity. The data was then split into training, validation, and testing sets based on subjects to ensure that the model's performance was evaluated on unseen data. The training process achieved an 85.7% classification accuracy through majority voting.\n\nAdditionally, to avoid domination by large ROIs, the importance scores were divided by the number of voxels in each ROI. This normalization step ensured that the contribution of each ROI was evaluated fairly, regardless of its size. The preprocessing steps, including data augmentation and normalization, played a significant role in enhancing the model's performance and interpretability.",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "The fitting method employed in this study involves a deep learning model, specifically a deep convolutional neural network (2CC3D), which inherently has a large number of parameters compared to the number of training points. To address potential overfitting, several strategies were implemented.\n\nFirstly, the dataset was split into training, validation, and testing sets based on subjects, ensuring that the model's performance was evaluated on unseen data. This approach helps in assessing the model's generalization capability.\n\nSecondly, techniques such as data augmentation were used to increase the effective size of the training dataset. This involved augmenting the data to 18,720 samples, which helps in making the model more robust and less likely to overfit.\n\nAdditionally, the use of a validation set during training allowed for early stopping and hyperparameter tuning, further mitigating overfitting. The model's performance was monitored on the validation set, and training was stopped when performance on this set ceased to improve.\n\nTo rule out underfitting, the model's architecture was designed to be sufficiently complex to capture the underlying patterns in the data. The convolutional layers and dense layers were chosen to ensure that the model could learn relevant features from the input data. The achieved classification accuracy of 85.7% on the testing dataset indicates that the model was able to learn from the data effectively without underfitting.\n\nFurthermore, the use of Monte Carlo (MC) approximation for large neighborhoods in the Shapley Value Estimation (SVE) methods ensured that the computation was manageable, allowing for a more accurate estimation of feature importance. This approach helped in interpreting the model's decisions and understanding the contribution of different regions of interest (ROIs).\n\nIn summary, the fitting method involved careful splitting of the dataset, data augmentation, and the use of a validation set to prevent overfitting. The model's architecture and training process were designed to ensure that it could learn from the data without underfitting, resulting in a robust and generalizable model.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model we propose is not a black box. We employ Shapley value explanation (SVE) from cooperative game theory to interpret deep learning models, which allows us to understand the interactions between features and determine instance-wise biomarker importance. This approach is advantageous because it considers the interaction between features, providing a more accurate interpretation of the model's predictions.\n\nOur methods explicitly reduce the computational complexity of SVE by leveraging the underlying graph structure of the input data. We use two main approaches: first, by considering only the centralized coalition of each feature, and second, by implementing a hierarchical pipeline that clusters features into small communities and then applies SVE within each community. This hierarchical approach, combined with Monte Carlo approximation for large permutation sets, makes our model interpretable even for complex datasets.\n\nFor example, when applied to a deep learning model for identifying autism spectrum disorder (ASD) from functional magnetic resonance imaging (fMRI), our methods discovered brain biomarkers that matched findings in the literature and had meaningful neurological interpretations. This demonstrates the transparency and interpretability of our model, as it provides clear insights into the features that contribute to the model's predictions.\n\nAdditionally, we validated our methods on the MNIST dataset and compared the results to human perception, further illustrating the model's ability to provide interpretable results. The use of SVE ensures that the model's decisions are not opaque but are instead grounded in a theoretical framework that considers feature interactions, making the model more transparent and trustworthy.",
  "model/output": "The model discussed in this publication is primarily used for classification tasks. In these tasks, the model assigns a relevance value to each input feature with respect to a class label. The probability of a class given an input is determined by the predictive score of the deep neural network (DNN) model. This model outputs conditional probabilities for assigning class labels, indicating that it is designed for classification rather than regression.\n\nThe model's output involves calculating the importance score of features, which is interpreted as the negative of the expected number of bits required to encode the model's output based on the input. This is done by marginalizing out the corrupted feature set and considering the interaction of different features.\n\nThe model's feasibility was tested on a deep learning model, where it identified similar possible brain biomarkers that matched findings in the literature and had meaningful neurological interpretations. The pipeline can be generalized to other feature importance analysis problems where the underlying graph structure of features is available.\n\nFuture work includes testing the methods on different atlases, graph building methods, and community clustering methods. Additionally, the interaction score embedded in the proposed algorithms can be disentangled to understand the interaction between features.",
  "model/duration": "The model was tested on a workstation equipped with a Nvidia 1080 Ti GPU. For the task of testing all 7 ASD subjects in the testing dataset, the execution times were approximately 21,000 seconds for C-SVE and 26,000 seconds for H-SVE. These times were recorded using 1,000 samples for Monte Carlo approximation, which ensured convergence to stable ranks. The model achieved an 85.7% classification accuracy through majority voting.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed methods involved several steps and datasets to ensure their feasibility and accuracy. Initially, the methods were validated using the MNIST dataset, where the explanation results were compared to human judgment about feature importance. A convolutional neural network was trained on this dataset, achieving 97.32% accuracy. The images were parcellated into regions of interest (ROIs) using the slic method to mimic the setting of detecting saliency brain ROIs for identifying autism spectrum disorder (ASD). The results showed that the interpretation matched human perception, highlighting the importance of the \"x cross\" shape in recognizing the digit 8. Compared to single ROI testing, the proposed methods assigned smoother and more widely distributed importance scores to more pixels.\n\nAdditionally, the methods were tested on an ASD task-fMRI dataset consisting of 82 children with ASD and 48 age and IQ-matched healthy controls. The data was split into training, validation, and testing sets. The Automated Anatomical Labeling (AAL) atlas was used to parcellate the brain into 116 regions, and an adjacency matrix was computed for each subject using Pearson correlation. The methods were compared with a Random Forest (RF) strategy, which achieved 71.4% accuracy on the testing set. The interpretation results showed that seven of the top 10 important ROIs discovered by the proposed methods overlapped with those found by the RF interpretation.\n\nFurthermore, the methods were applied to a deep neural network classifier, specifically the 2CC3D model, which used each voxel's mean and standard deviation as two-channel input. The results showed that the proposed methods discovered similar possible brain biomarkers, which matched findings in the literature and had meaningful neurological interpretations. The pipeline can be generalized to other feature importance analysis problems where the underlying graph structure of features is available.\n\nThe evaluation also included experiments to examine the effect of important ROIs on prediction. Pixels whose importance power added up to 90% of the positive importance scores were corrupted, and the difference between the original prediction probability and the new prediction probability was compared. The proposed methods, C-SVE and H-SVE, were able to better fool the classifier, decreasing the prediction probability more significantly than the single ROI method.\n\nIn summary, the evaluation involved multiple datasets and comparison methods to validate the feasibility and accuracy of the proposed approaches. The results demonstrated that the methods can capture more interpretable features and provide meaningful neurological interpretations.",
  "evaluation/measure": "In the evaluation of our methods, we primarily focused on classification accuracy as our key performance metric. Specifically, we achieved an 85.7% classification accuracy through majority voting. This metric is widely used in the literature and provides a clear indication of the model's ability to correctly classify subjects.\n\nAdditionally, we reported the time taken for testing all subjects in the testing dataset. For the ASD subjects, testing took approximately 21,000 seconds using the C-SVE method and 26,000 seconds using the H-SVE method. These times were recorded on a workstation equipped with an Nvidia 1080 Ti GPU, using 1000 samples for Monte Carlo (MC) approximation, which converged to stable ranks.\n\nWe also examined the contribution and prediction power of different regions, averaged over testing subjects. This analysis helped us identify the most important regions and their relative contributions to the classification task. The Spearman rank-order correlation coefficient between the importance scores of all regions explained by both C-SVE and H-SVE methods was 0.58, indicating a moderate level of agreement between the two methods.\n\nFurthermore, we evaluated the impact of corrupting important regions of interest (ROIs) on the prediction probability and accuracy. We corrupted the top ROIs, summing up to 50% of the positive importance scores, and calculated the average decrease in probability (\u0394prob) and accuracy (\u0394acc) for the subjects in the testing set. These results were listed in a table, providing insights into the robustness of our model and the significance of the identified ROIs.\n\nIn summary, our performance measures included classification accuracy, testing time, region contribution analysis, and the impact of ROI corruption on prediction performance. These metrics collectively provide a comprehensive evaluation of our methods and their effectiveness in analyzing feature importance in classification tasks.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we conducted a thorough evaluation of our proposed methods by comparing them with publicly available and simpler baseline methods. To ensure a fair and comprehensive assessment, we applied our approaches to well-established benchmark datasets, including the MNIST dataset and an ASD task-fMRI dataset.\n\nFor the MNIST dataset, we demonstrated that our methods could capture more interpretable features compared to simpler baselines. This was evident in the ability of our methods to better fool the classifier by significantly decreasing the prediction probability when important regions were corrupted.\n\nAdditionally, we compared our methods with a Random Forest (RF) strategy on the ASD task-fMRI dataset. The RF method, which used mean Gini impurity decrease as a measure of feature importance, served as a standard baseline for comparison. We inputted node-weighted modularity into the RF model, treating each subject as a game and each region of interest (ROI) as a player. This allowed us to perform group-based analysis and investigate the importance of each ROI. The results showed that seven of the top 10 important ROIs discovered by our methods overlapped with those identified by the RF interpretation, validating the accuracy and reliability of our approaches.\n\nFurthermore, we tested our methods on a deep neural network classifier, specifically the 2CC3D model, which used voxel mean and standard deviation as inputs. The comparison revealed that the top 10 biomarkers discovered using our Shapley Value Estimation (SVE) methods in the RF model differed from those found in the 2CC3D model. This discrepancy can be attributed to differences in inputs, prediction accuracy, and the sensitivity of our methods as model interpreters rather than data interpreters.\n\nOverall, the comparisons with publicly available methods and simpler baselines on benchmark datasets provided strong evidence of the effectiveness and interpretability of our proposed approaches.",
  "evaluation/confidence": "In our evaluation, we employed several metrics to assess the performance and confidence of our methods. For the ASD task-fMRI dataset, we achieved an 85.7% classification accuracy using majority voting. This metric provides a clear indication of our model's performance, but it does not inherently include confidence intervals.\n\nTo address statistical significance, we compared our methods with a Random Forest (RF) strategy, which served as a baseline. The RF model achieved a 71.4% accuracy on the testing set. While this comparison highlights the superior performance of our methods, it does not directly provide statistical significance. However, the overlap of important regions of interest (ROIs) between our methods and the RF interpretation suggests consistency and reliability.\n\nAdditionally, we used Monte Carlo (MC) approximation for large neighborhoods, which involved running 1000 samples to ensure stable ranks. This approach helps in approximating the Shapley values more accurately, contributing to the confidence in our results.\n\nThe Spearman rank-order correlation coefficient between the importance scores of all the ROIs explained by our methods was 0.58, indicating a moderate to strong correlation. This further supports the reliability of our findings.\n\nIn summary, while our performance metrics are robust, explicit confidence intervals and detailed statistical significance tests are not provided. The overlap of important ROIs and the use of MC approximation contribute to the overall confidence in our methods' superiority over the baseline.",
  "evaluation/availability": "Not enough information is available."
}