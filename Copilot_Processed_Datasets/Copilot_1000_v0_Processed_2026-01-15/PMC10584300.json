{
  "publication/title": "Artificial Intelligence to Predict Cirrhosis",
  "publication/authors": "The authors who contributed to the article are:\n\n- Grace L. Su, MD, who is the guarantor of the article.\n- B.E., who contributed to the conception of the project, contributed materials/methods, data analysis, interpretation of results, and write-up and revision of the manuscript.\n- P.Z., who contributed to the conception of the project, contributed materials/methods, data analysis, and interpretation of results.\n- N.R.M., who contributed to the literature review, interpretation of results, and write-up and revision of the manuscript.",
  "publication/journal": "Clinical and Translational Gastroenterology",
  "publication/year": "2023",
  "publication/pmid": "37436183",
  "publication/pmcid": "PMC10584300",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Artificial Intelligence\n- Cirrhosis Detection\n- Computed Tomography\n- Machine Learning\n- Liver Disease\n- Morphomics\n- Predictive Modeling\n- Gradient Boosting\n- Medical Imaging\n- Noninvasive Diagnosis",
  "dataset/provenance": "The dataset used in this study consisted of patients with and without cirrhosis. Initially, the cohort included 100 patients with cirrhosis and 257 patients without cirrhosis. After excluding some patients due to the quality of CT images, a total of 351 patients were included for analysis. Among these, 96 patients had cirrhosis and 255 did not. The data used in this study were derived from CT scans performed for various clinical indications, not solely dedicated liver CT examinations. Notably, 23 of these scans were noncontrast scans. The dataset included a mix of patients with different causes of chronic liver disease, with a significant portion having a history of liver transplant. The study leveraged both imaging data and laboratory measures to develop and validate the predictive models. The dataset was selected based on the presence of cross-sectional imaging and liver biopsy, ensuring a robust gold standard for training and validating the algorithm. This approach allowed for the incorporation of a wide range of patient characteristics and imaging features, enhancing the model's ability to predict cirrhosis accurately.",
  "dataset/splits": "The dataset was initially composed of 357 patients, including 100 patients with cirrhosis and 257 patients without cirrhosis. After excluding some patients due to the quality of CT images, the final cohort consisted of 351 patients, with 96 patients having cirrhosis and 255 patients without cirrhosis.\n\nThe dataset was not explicitly split into multiple subsets for training, validation, or testing. Instead, the entire cohort was used for analysis, with some sensitivity analyses performed on a subset of patients who had not undergone liver transplantation.\n\nThe distribution of data points in the final cohort was as follows:\n\n* Patients with cirrhosis: 96\n* Patients without cirrhosis: 255\n\nThe dataset included a variety of patient characteristics, such as age, sex, cause of chronic liver disease, history of liver transplant, and laboratory measures. The median age of patients with cirrhosis was 52 years, while the median age of noncirrhotic patients was 51 years. The majority of patients in both groups were male, with 54.2% of cirrhotic patients and 54.9% of noncirrhotic patients being male. The most common cause of chronic liver disease in both groups was hepatitis C virus (HCV) infection, followed by non-alcoholic fatty liver disease (NAFLD) and other causes.\n\nThe dataset also included laboratory measures, such as platelet count, aspartate aminotransferase (AST), alanine aminotransferase (ALT), international normalized ratio (INR), model for end-stage liver disease (MELD) score, AST to platelet ratio index (APRI), and fibrosis-4 (FIB-4) index. The median MELD score was significantly higher in the cirrhotic group compared to the noncirrhotic group (10.9 vs 7.6, P < 0.001). Similarly, the median APRI and FIB-4 index were also significantly higher in the cirrhotic group compared to the noncirrhotic group (P < 0.0001 for both).",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is gradient boosting decision trees. This approach leverages an ensemble of decision trees, which typically outperforms random forest models by combining multiple weak learners to form a more accurate final model. The specific implementation used was XGBoost, a popular and efficient library for gradient boosting.\n\nThis algorithm is not new; it has been widely used and validated in various fields, including medical research. The choice to use gradient boosting decision trees was driven by their proven effectiveness in handling complex datasets and their ability to manage missing data directly within the algorithm. This is particularly important in medical imaging, where data can often be incomplete or noisy.\n\nThe decision to use this well-established algorithm in a medical context, rather than publishing it in a machine-learning journal, is rooted in the practical application and validation of the method. The focus of our study was to demonstrate the utility of gradient boosting decision trees in automating the detection of cirrhosis from CT images, integrating both imaging and laboratory data. The innovation lies in the application of this algorithm to a specific medical problem, rather than the development of a new algorithm. By showcasing the effectiveness of gradient boosting decision trees in this context, we aim to contribute to the broader goal of improving diagnostic tools in healthcare.",
  "optimization/meta": "The model developed in this study is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on gradient boosting decision trees to create a multivariate prediction model. This approach leverages an ensemble of decision trees, which typically outperforms random forest models by combining multiple weak learners to form a more accurate final model.\n\nThe model incorporates various features, including laboratory scores like FIB-4, Lok score, total bilirubin, platelet count, AST:ALT ratio, and transplant status. Additionally, it utilizes several image parameters generated by the computer, such as the median CT attenuation of the liver, the eccentricity of the liver shape, and a measure of nodularity. These features are directly derived from the data rather than from other machine-learning algorithms.\n\nThe training data for the model is independent, as it involves a cohort of patients with and without cirrhosis. The cohort characteristics were carefully selected and analyzed to ensure robustness. The model's performance was evaluated using the area under the receiver operating curve (AUC), and the DeLong test was used to compare multiple correlated receiver operating characteristic curves resulting from different models. This ensures that the training data is independent and that the model's performance is accurately assessed.",
  "optimization/encoding": "For the machine-learning algorithm, the data encoding and preprocessing involved several key steps. Initially, the cohort consisted of patients aged 16 years and older who had undergone a liver biopsy within six months of a CT scan between January 2004 and 2012. Clinical data, including laboratory values within six months of the CT scan, were retrospectively abstracted. Both contrast and noncontrast CT studies were utilized, with the phase containing the most slices of the entire liver selected for analysis.\n\nTo ensure data quality, all scans were reviewed by a research assistant for quality assurance, blinded to the clinical data. Scans were excluded if the superior or inferior sections of the liver were cut off or if there were significant image quality issues, such as pixel spacing problems or artifacts.\n\nAutomated liver segmentation was achieved using two convolutional neural network (CNN) models: 3D U-net followed by Google\u2019s DeepLab v3. These models were trained on 1,590 scans within the Analytic Morphomics database, where ground truth masks of fully segmented liver volumes were produced through an iterative process of manual segmentation and quality checks by trained research assistants and a hepatologist.\n\nThe preprocessing pipeline also included the normalization of measures through automatic segmentation, which allowed for the extraction of clinically relevant features. These features included the median CT attenuation of the liver in Hounsfield units, the eccentricity of the liver shape, and a measure of nodularity defined by the total smoothed perimeter divided by the total original perimeter.\n\nAdditionally, laboratory scores such as FIB-4, Lok score, total bilirubin, platelet count, AST:ALT ratio, and transplant status were included as important features in the model. The combination of these laboratory measures with morphometric characteristics derived from the CT images enhanced the model's predictive performance.\n\nThe data was further optimized through 5-fold cross-validation to ensure robust internal validation and to prevent overfitting. This process involved splitting the data into five subsets, training the model on four subsets, and validating it on the remaining subset, repeating this process five times to ensure comprehensive evaluation.",
  "optimization/parameters": "In our study, we utilized gradient boosting decision trees to develop multivariate prediction models. The hyperparameters optimized through 5-fold cross-validation included maximum tree depth, subsample percentage, and minimum child weight. These parameters were crucial in enhancing the model's performance and accuracy. The decision tree framework allowed us to handle missing data directly, which is a significant advantage in real-world datasets. The model's performance was evaluated using the area under the receiver operating curve (AUC), and the DeLong test was used to compare multiple correlated receiver operating characteristic curves resulting from different models. The analysis was conducted using R 4.0.0 with packages including rpart, Hmisc, pROC, and xgboost. The specific number of parameters used in the model is not explicitly stated, but the optimization process ensured that the selected parameters were the most effective for our dataset.",
  "optimization/features": "The study utilized a combination of laboratory scores and morphometric features derived from CT images as input features for the prediction models. The top-ranked laboratory features included FIB-4, Lok score, total bilirubin, platelet count, AST: ALT ratio, and transplant status. Additionally, several image parameters generated by the computer were significant, such as the median CT attenuation of the liver in Hounsfield units, the eccentricity of the liver shape, and a measure of nodularity.\n\nFeature selection was implicitly performed through the model training process, as the gradient boosting decision trees algorithm inherently selects the most important features during training. This process ensures that the final model includes only the most relevant features for prediction. The feature importance was assessed across all models, and the top features were identified based on their contribution to the model's performance.\n\nThe feature selection process was conducted using the training set only, adhering to best practices in machine learning to prevent data leakage and ensure the model's generalizability. This approach allows the model to learn the most relevant features from the data without being influenced by the test set, thereby maintaining the integrity of the validation process.",
  "optimization/fitting": "The model building process involved the use of gradient boosting decision trees, which are known for their ability to handle a large number of parameters relative to the number of training points. To mitigate the risk of overfitting, several strategies were employed. Hyperparameters such as maximum tree depth, subsample percentage, and minimum child weight were optimized through 5-fold cross-validation. This technique helps in ensuring that the model generalizes well to unseen data by validating it on different subsets of the data. Additionally, the decision tree framework used allows for handling missing data directly, which further aids in preventing overfitting by not requiring imputation methods that could introduce bias.\n\nTo address underfitting, the ensemble nature of gradient boosting was leveraged. By combining multiple weak learners, the model achieves a more accurate final prediction. The use of feature importance analysis also helped in identifying the most relevant features, ensuring that the model focuses on the most predictive variables. The evaluation of model performance using the area under the receiver operating curve (AUC) provided a robust metric to assess the model's discriminative ability. Furthermore, the DeLong test was used to compare multiple correlated receiver operating characteristic curves, ensuring that the improvements in model performance were statistically significant.\n\nIn summary, the combination of cross-validation, feature importance analysis, and the ensemble nature of gradient boosting decision trees helped in balancing the trade-off between overfitting and underfitting, resulting in a model that performs well on both training and validation datasets.",
  "optimization/regularization": "To prevent overfitting, we employed robust internal validation techniques. Specifically, we used 5-fold cross-validation to optimize hyperparameters such as maximum tree depth, subsample percentage, and minimum child weight. This method helps ensure that our model generalizes well to unseen data by training and validating on different subsets of the data. Additionally, our algorithm inherently handles missing data, which further aids in preventing overfitting by not relying on imputed values that could introduce bias.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available. We utilized gradient boosting decision trees for our multivariate prediction models, and the hyperparameters, such as maximum tree depth, subsample percentage, and minimum child weight, were optimized through 5-fold cross-validation. These details are included in the methodology section of our publication.\n\nThe specific model files and optimization parameters are not explicitly provided in the publication. However, the analysis was conducted using R 4.0.0 with packages including rpart, Hmisc, and pROC, xgboost. These packages are widely available and can be accessed under their respective licenses. The use of these packages ensures that the methods and tools used for optimization are reproducible.\n\nFor those interested in replicating our study or using similar methods, the packages mentioned are open-source and can be installed via standard repositories. The optimization process, including the cross-validation technique, is described in sufficient detail to allow for replication.",
  "model/interpretability": "The model developed in this study is not a typical black-box convolutional neural network (CNN) architecture. Instead, it combines multiple imaging findings of cirrhosis simultaneously, making it more interpretable. The algorithm identifies and utilizes clinically relevant features that have known correlations with liver disease pathophysiology.\n\nOne of the key features highlighted by the model is the median CT attenuation of the liver in Hounsfield units. This feature reflects the known paradoxical loss of fat in advanced liver disease, which alters the organ's attenuation on CT scans. Another important feature is the \"eccentricity\" of the liver shape, quantified by the ratio of the horizontal to vertical dimensions. This measure is related to prior studies that have shown the predictive value of liver shape characteristics, such as caudate lobe hypertrophy, in detecting cirrhosis.\n\nAdditionally, the model emphasizes a measure of \"nodularity,\" which is obtained by comparing the actual versus smoothed perimeter of the liver. This feature is frequently noted in visual inspections during laparotomy or autopsy and has been shown to predict advanced fibrosis in patients with hepatitis C. By incorporating these well-established radiologic indicators, the model provides a more transparent and clinically meaningful prediction of cirrhosis.\n\nThe top-ranked features in the model include both conventional expected markers, such as FIB-4, transplant status, platelet count, AST:ALT ratio, bilirubin, and AST, as well as liver morphomics features. These features are not only statistically significant but also have clear clinical interpretations, making the model's predictions more understandable and trustworthy. The algorithm's ability to normalize measures through automatic segmentation and its focus on clinically important binary classification tasks further enhance its interpretability and performance.",
  "model/output": "The model developed is designed for classification, specifically to predict the presence of cirrhosis in patients. It uses gradient boosting decision trees, which are well-suited for binary classification tasks. The model's performance is evaluated using the area under the receiver operating curve (AUC), a metric commonly used for classification problems. The output of the model is a binary classification indicating whether a patient has cirrhosis or not. This is achieved by leveraging various features, including laboratory scores, demographic information, and morphometric characteristics derived from CT images. The model's ability to handle missing data and its use of multiple weak learners to form a more accurate final model further enhance its classification capabilities. The top-ranked features for the model include FIB-4, Lok score, total bilirubin, platelet count, AST: ALT ratio, and transplant status, along with several image parameters generated by the computer. These features collectively contribute to the model's classification performance.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our method involved several key steps to ensure its robustness and accuracy. We utilized gradient boosting decision trees to develop multivariate prediction models, which were evaluated using the area under the receiver operating curve (AUC). This metric provided a comprehensive measure of the model's performance in distinguishing between patients with and without cirrhosis.\n\nTo optimize the hyperparameters, such as maximum tree depth, subsample percentage, and minimum child weight, we employed 5-fold cross-validation. This technique helped in tuning the model parameters effectively and ensured that the model generalized well to unseen data.\n\nThe DeLong test was used to compare multiple correlated receiver operating characteristic curves resulting from different models. This statistical test allowed us to assess the significance of differences in performance between various models.\n\nOur analysis was conducted using R 4.0.0, with packages including rpart, Hmisc, pROC, and xgboost. These tools facilitated the implementation and evaluation of our models, ensuring that our findings were reliable and reproducible.\n\nIn summary, our evaluation method combined cross-validation for hyperparameter tuning, the AUC for performance measurement, and the DeLong test for comparative analysis, all supported by robust statistical software and packages.",
  "evaluation/measure": "The primary performance metric reported in our study is the area under the receiver operating characteristic curve (AUROC), also known as the area under the curve (AUC). This metric was used to evaluate the predictive ability of various models, including those based on Fibrosis-4 (FIB-4) index, morphomics alone, and combined models incorporating morphomics, laboratory data, and demographics.\n\nThe AUROC values provide a comprehensive measure of model performance, indicating the ability of each model to distinguish between patients with and without cirrhosis. For instance, the FIB-4 index alone achieved an AUROC of 0.76, while morphomics alone had an AUROC of 0.71. The combined Morphomics + laboratory model significantly improved performance, reaching an AUROC of 0.84. Adding demographics to this model further enhanced the AUROC to 0.85, although this improvement was not statistically significant compared to the Morphomics + laboratory model.\n\nTo compare the performance of different models, we employed the DeLong test, which is specifically designed to compare correlated receiver operating characteristic curves. This statistical method allowed us to assess the significance of differences in AUROC values between models, ensuring robust and reliable comparisons.\n\nAdditionally, we conducted a sensitivity analysis by excluding patients with a history of liver transplant. This analysis revealed that model performance generally increased, with the AUROC of the FIB-4 index rising to 0.82. However, the relative performance of the combined models remained consistent, with the Morphomics + laboratory model still outperforming individual components, albeit with a smaller margin.\n\nThe reported metrics are representative of standard practices in the literature, providing a clear and comparable measure of model performance. The use of AUROC and the DeLong test ensures that our findings are both rigorous and aligned with established methodologies in the field.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, we focused on evaluating our model's performance using internal metrics and comparisons with established clinical scores.\n\nWe compared our model's performance with simpler baselines, such as the FIB-4 score and other laboratory-based fibrosis scores like APRI and the Lok index. These scores are commonly used in clinical practice to predict advanced fibrosis and cirrhosis. Our results showed that our model, which combines morphomics and laboratory data, outperformed these simpler baselines. For instance, the area under the receiver operating characteristic curve (AUROC) for the FIB-4 score was 0.76, while our combined model achieved an AUROC of 0.84. This indicates that our approach provides a more accurate prediction of cirrhosis compared to these simpler, laboratory-based methods.\n\nAdditionally, we compared our model's performance with morphomics alone. The AUROC for morphomics alone was 0.71, which was similar to the FIB-4 score but lower than our combined model. This suggests that while morphomics alone can provide useful information, combining it with laboratory data enhances the model's predictive power.\n\nWe also conducted a sensitivity analysis by excluding patients with a history of liver transplant. This analysis showed that the performance of all models increased, but the comparative jump in sensitivity was not uniform. Notably, the AUROC of the FIB-4 score increased to 0.82, making the margin between our combined model and the FIB-4 score smaller. However, our combined model still outperformed the FIB-4 score and morphomics alone, demonstrating its robustness and generalizability.\n\nIn summary, while we did not compare our model with publicly available methods on benchmark datasets, we did evaluate its performance against simpler baselines and showed that our approach provides a more accurate prediction of cirrhosis. This comparison highlights the potential of our model to improve the triage of patients to specialty care in health systems that are increasingly digitally integrated.",
  "evaluation/confidence": "The evaluation of our models involved calculating the area under the receiver operating characteristic curve (AUROC) to assess performance. The DeLong test was employed to compare multiple correlated receiver operating characteristic curves resulting from different models, ensuring statistical significance in our comparisons. This method allowed us to determine whether the differences in AUROC values between models were statistically significant.\n\nThe models were evaluated using 5-fold cross-validation, which helps in assessing the generalizability of the models and provides a measure of their performance variability. This technique involves dividing the data into five subsets, training the model on four subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. The results from these five iterations are then averaged to provide a more robust estimate of model performance.\n\nThe statistical significance of the results was crucial in claiming that our method outperformed others and established baselines. For instance, the Morphomics + laboratory model showed a significant improvement in AUROC compared to Morphomics or FIB-4 alone, with a P-value less than 0.001. This indicates a high level of confidence that the observed differences are not due to random chance.\n\nAdditionally, the inclusion of demographics in the model did not significantly improve performance compared to the Morphomics + laboratory model, as indicated by a P-value of 0.54. This suggests that while demographics may contribute to the model, their impact is not statistically significant in this context.\n\nOverall, the use of the DeLong test and 5-fold cross-validation provides a strong foundation for evaluating the confidence in our model's performance metrics. The statistically significant results support the claim that our method is superior to others and baselines, offering a reliable approach for predicting cirrhosis.",
  "evaluation/availability": "Not enough information is available."
}