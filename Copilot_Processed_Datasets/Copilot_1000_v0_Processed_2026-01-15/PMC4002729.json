{
  "publication/title": "A genetic algorithm optimized support vector machine model for the identification of agonists and antagonists of the 5-HT1A receptor",
  "publication/authors": "The authors who contributed to the article are:\n\n- Wei-liang Zhu, who designed and supervised the research and revised the manuscript.\n- Xue-lian Zhu, who performed the research, analyzed data, and wrote the manuscript.\n- Heyao Wang, who helped with parts of the research design.\n- Zhi-jian Xu, who helped with parts of the research design.\n- Hai-yan Cai, who helped to perform the research and revise the manuscript.\n- Yong Wang, who helped to perform the research and revise the manuscript.\n- Ao Zhang, who helped to perform the research and revise the manuscript.",
  "publication/journal": "Acta Pharmacologica Sinica",
  "publication/year": "2011",
  "publication/pmid": "21963891",
  "publication/pmcid": "PMC4002729",
  "publication/doi": "10.1038/aps.2011.112",
  "publication/tags": "- 5-HT1A receptor\n- Support vector machine\n- Genetic algorithm\n- Agonists\n- Antagonists\n- Drug development\n- Computational model\n- Ligand identification\n- Machine learning\n- Molecular descriptors",
  "dataset/provenance": "The dataset used in this study comprised 284 ligands of the 5-HT1A receptor. These ligands were collected from various literature sources and exhibited diverse structures. The overall dataset was divided into training and test sets to evaluate the performance of the developed model. Specifically, there were 195 compounds in the training set and 41 compounds in the test set that remained in the refined datasets after applying a probability estimate threshold of 0.7. This threshold was chosen because the majority of the compounds had a probability estimate higher than 0.7, indicating more reliable predictions. The dataset included both agonists and antagonists of the 5-HT1A receptor, and the model's performance was validated using this refined dataset. Additionally, the model was applied to an external dataset consisting of 25 ligands collected from recently published literature to further validate its reliability.",
  "dataset/splits": "The dataset was split into subsets, with each subset being used for prediction five times. This implies that there were multiple data splits, but the exact number of splits is not specified. Each subset contained a certain number of data points, but the specific number of data points in each split is not detailed. The distribution of data points across these splits is also not provided. The primary focus was on ensuring that each subset could be used for prediction multiple times to validate the model's performance.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is Support Vector Machine (SVM). This is a well-established method in the field of machine learning, known for its effectiveness in classification tasks. The SVM model was employed to build a prediction model for distinguishing agonists and antagonists of the 5-HT1A receptor.\n\nThe specific implementation of SVM used here is not new; it is a widely recognized and utilized technique in various scientific and engineering domains. The SVM algorithm was originally developed by Vladimir Vapnik and is based on the structural risk minimization principle from statistical learning theory. It is a supervised learning method that can be applied to both classification and regression problems.\n\nThe reason this study was published in a pharmacology journal rather than a machine-learning journal is likely due to the focus and application of the research. The primary objective of the study was to develop a computational model for identifying the physiological function of ligands for the 5-HT1A receptor, which falls within the scope of pharmacology and drug development. The use of SVM was a means to achieve this goal, but the main contribution lies in the application and validation of the model in the context of pharmacology.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it is a Support Vector Machine (SVM) model that was developed using a set of 13 molecular descriptors derived from known agonists and antagonists. These descriptors were selected using an in-house feature selection program and were used to train and validate the SVM model.\n\nThe SVM model's performance was evaluated using various metrics, including the Receiver-Operating-Characteristics (ROC) curve, the Matthews correlation coefficient (MCC), and overall accuracy. The model was further refined by using a probability estimate factor to remove ambiguous compounds, which improved its predictive accuracy for both the training and test sets.\n\nThe training and test sets were created by dividing the data into subsets and using each subset for prediction once. This process was repeated five times to ensure that each subset was used for prediction once. The model's performance was also validated using an external dataset, which confirmed its effectiveness in classifying agonists and antagonists of the 5-HT1A receptor.",
  "optimization/encoding": "For the data encoding and preprocessing, we began by collecting a total of 259 ligands of the 5-HT1A receptor, which included 137 agonists and 122 antagonists. These ligands were sourced from various previous studies and encompassed diverse structural classes such as aminotetralins, indolylalkylamines, ergolines, aporphines, arylpiperazines, and aryloxyalkylamines.\n\nThe structures of these compounds were created and optimized using Sybyl 6.8. To quantitatively represent the structural and physicochemical features of these compounds, we calculated 292 molecular descriptors. These descriptors included topological, graph-theoretical, quantum-chemical, and electro-topological state (E-state) descriptors. Each descriptor's value was then scaled to the range of [-1, 1] to ensure consistency and comparability.\n\nGiven the large number of descriptors, we employed a genetic algorithm (GA) to select the most relevant features. The GA randomly initialized a population of solutions, which were then improved through repetitive operations of mutation, crossover, and selection. Each solution, or chromosome, consisted of two parts: the feature mask and the SVM parameters (C and r). The feature mask indicated whether a descriptor was kept (value of 1) or abandoned (value of 0). The values of C and r were represented as 2^m and 2^n, respectively, where m and n are integers.\n\nTo build the classification model, we used a support vector machine (SVM) with a radial basis function (RBF) kernel. The SVM model was trained using a 5-fold cross-validation approach, where the training set of 207 ligands was randomly split into five subsets of approximately equal size. In each validation, one subset was used for testing while the remaining four were used for training. This process was repeated five times so that each subset was used for prediction once.\n\nThe final model selected 13 optimized molecular descriptors, which were categorized into five classes: semi-empirical quantum mechanical properties, E-state keys, molecular property counts, molecular properties, and shadow indices. These descriptors, along with the optimized parameters C and r (both set to 1), were used to develop a robust SVM model with a cross-validation r\u00b2 of 0.826.",
  "optimization/parameters": "In our study, two parameters were used in the model: C and r. These parameters are crucial for developing a robust SVM model. C is a global parameter that regulates the trade-off between maximizing the margin and minimizing the training error. Small values of C tend to emphasize the margin and ignore outliers in the training set, while large values of C can lead to overfitting. The parameter r indicates the radial basis function (RBF), which serves as the kernel function in our model.\n\nTo optimize the values of C and r, we employed an in-house method. This method involved using a genetic algorithm (GA) to simultaneously select the most important molecular descriptors and optimize the model parameters. The GA randomly initializes a population of solutions and improves them through repetitive operations of mutation, crossover, and selection. Each possible solution, referred to as a chromosome, consists of two parts: the feature mask and the SVM parameters (C and r). The feature mask values are either 0 or 1, where 0 indicates that the corresponding descriptor is abandoned, and 1 indicates that the descriptor is kept. Although C and r are real numbers, we considered specific discrete values in our study, where C and r were represented as 2^m and 2^n, respectively, with m and n being integers. The optimized values of C and r were both found to be 1 in our final SVM model.",
  "optimization/features": "In our study, we initially calculated 292 molecular descriptors for each compound, which included topological, graph-theoretical, quantum-chemical, and electro-topological state (E-state) descriptors. These descriptors were used to quantitatively represent the structural and physicochemical features of the compounds.\n\nTo ensure that only the most relevant features were used in our model, we performed feature selection. This process was carried out using a genetic algorithm (GA), which is a method that optimizes solutions through iterative operations of mutation, crossover, and selection. The GA was used to simultaneously select the most important descriptors and optimize the model parameters.\n\nThe feature selection process involved creating a feature mask, where each descriptor was either included (value of 1) or excluded (value of 0) from the model. This mask was part of a chromosome, which also included the SVM parameters C and r. The GA was applied to the training set only, ensuring that the feature selection process did not use any information from the test set.\n\nAs a result of this feature selection process, 13 descriptors were ultimately chosen for use in the SVM model. These descriptors were categorized into five classes, including semi-empirical quantum mechanical properties, E-state keys, molecular property counts, molecular properties, and shadow indices. This selection process helped to improve the model's performance and reliability.",
  "optimization/fitting": "In our study, we employed a Support Vector Machine (SVM) model to classify ligands as agonists or antagonists of the 5-HT1A receptor. The SVM model involved two key parameters, C and r, which needed careful adjustment to ensure a robust model.\n\nThe parameter C is a global parameter that balances the trade-off between maximizing the margin and minimizing training error. Small values of C can lead to a model that focuses too much on the margin, potentially ignoring important outliers in the training set. Conversely, large values of C can result in overfitting, where the model performs well on the training data but poorly on new, unseen data.\n\nTo address the risk of overfitting, we used a genetic algorithm (GA) to optimize the values of C and r. The GA randomly initializes a population of solutions and improves them through iterative processes of mutation, crossover, and selection. This method helps in finding the optimal values of C and r that generalize well to new data.\n\nAdditionally, we used 5-fold cross-validation to assess the reliability of our statistical models. The training set of 207 ligands was randomly split into five subsets, with each subset used once for testing and four times for training. This process ensures that the model's performance is evaluated on different portions of the data, reducing the likelihood of overfitting.\n\nFurthermore, we calculated the Area Under the ROC Curve (AUC) for both the training and test sets, which were 0.883 and 0.906, respectively. These values indicate that our model has a good balance between sensitivity and specificity, suggesting that it is not underfitting the data.\n\nIn summary, by carefully tuning the parameters C and r using a genetic algorithm and employing 5-fold cross-validation, we were able to develop a reliable SVM model that effectively distinguishes between agonists and antagonists of the 5-HT1A receptor without overfitting or underfitting the data.",
  "optimization/regularization": "In our study, we employed a regularization method to prevent overfitting when developing our support vector machine (SVM) model. The parameter C plays a crucial role in this regard. C is a global parameter that regulates the trade-off between maximizing the margin and minimizing the training error. By carefully adjusting the value of C, we can control the model's complexity and prevent it from overfitting the training data. Small values of C emphasize the margin, potentially overlooking outliers in the training set, while large values of C can lead to overfitting. To find the optimal value of C, we used an in-house method that involved a genetic algorithm for parameter optimization. This approach helped us to build a robust classification model that generalizes well to unseen data. Additionally, we used 5-fold cross-validation to further ensure the reliability of our statistical models. This process involved splitting the training set into five subsets, using four for training and one for testing in each iteration, thereby providing a more accurate estimate of the model's performance.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we discussed the parameters C and r, which are crucial for developing a robust Support Vector Machine (SVM) model. The values of C and r were optimized using an in-house method, and the optimized values were both determined to be 1. These details are provided to ensure reproducibility and transparency in our methodology.\n\nRegarding the optimization schedule, we employed a genetic algorithm (GA) to simultaneously select the most important molecular descriptors and optimize the model parameters. The GA process involves random initialization of a population of solutions, followed by repetitive operations of mutation, crossover, and selection. This approach ensures a thorough exploration of the parameter space to find the best configuration.\n\nModel files and specific optimization parameters, such as the 13 selected molecular descriptors, are not directly provided in the main text but are referenced in supplementary materials. These descriptors were calculated using Discovery Studio 2.1 and scaled to the range [-1, 1]. The list of optimized descriptors and their classes is available in Table 2 of the supplementary information.\n\nThe license under which these details are made available is not explicitly stated in the provided context. However, it is standard practice in scientific publications to make such information available for reproducibility purposes, typically under terms that allow for academic use and further research. For specific licensing details, one would need to refer to the journal's policies or the supplementary materials directly.",
  "model/interpretability": "The model developed in this study is not entirely a black box, as it incorporates interpretable features and provides insights into the decision-making process. The use of molecular descriptors, such as VAMP/AM1 semi-empirical quantum-chemical, electro-topological state (E-state), molecular property, and shadow index descriptors, allows for a degree of transparency. These descriptors reflect specific structural information related to the function of the ligands, making it possible to understand how certain molecular features contribute to the classification of agonists and antagonists.\n\nFor instance, the E-state indices are known to be efficient descriptors for the affinity of 5-HT1A receptor antagonists. Additionally, the descriptor \"number of surface points with positive electrostatic potential\" aligns with the observation that most agonists or antagonists of the 5-HT1A receptor are positively charged. This indicates that the model can provide clear examples of how specific molecular properties influence the classification outcomes.\n\nMoreover, the probability estimate factor adds another layer of interpretability. This factor allows for the assessment of the reliability of the predicted results. For example, a compound predicted to be an agonist with a high probability estimate (e.g., 0.9) is more likely to be an agonist than one with a lower probability estimate (e.g., 0.6). This probabilistic approach helps in understanding the confidence level of the model's predictions, making it more transparent and interpretable.\n\nThe model's performance metrics, such as accuracy, sensitivity, and specificity, before and after refinement, further illustrate its reliability and the impact of the probability estimate factor. The significant improvement in these metrics after considering the probability estimate factor demonstrates the model's ability to provide more accurate and interpretable results.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict whether a given ligand acts as an agonist or an antagonist of the 5-HT1A receptor. The model uses a support vector machine (SVM) algorithm, which is a well-known machine learning method for classification tasks. The output of the model provides a probability estimate for each ligand, indicating the likelihood of it being an agonist or an antagonist. This probability estimate is crucial for assessing the reliability of the predictions. For instance, ligands with a probability estimate higher than 0.7 are considered more reliable predictions. The model's performance was evaluated using metrics such as sensitivity, specificity, and the Matthews correlation coefficient (MCC), which are all relevant to classification tasks. Additionally, the receiver-operating-characteristics (ROC) curve and the Area-Under-the-ROC-Curve (AUC) were used to assess the model's classification power. The overall predictive accuracy for the training and test sets was also calculated, further confirming the model's effectiveness in classifying ligands as agonists or antagonists.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the developed model involved several rigorous steps to ensure its reliability and robustness. Initially, the dataset was divided into training and test sets with a 4:1 ratio, allowing for repeated evaluations. The model's performance was assessed using various metrics, including the receiver-operating-characteristics (ROC) curve, which plots the true positive rate (TPR) against the false positive rate (FPR). This curve provides a visual representation of the model's classification power.\n\nKey metrics calculated included sensitivity (TPR), specificity, and the Matthews correlation coefficient (MCC), which ranges from -1 to 1, with 1 indicating a perfect model and 0 representing a random model. The overall accuracy of the model was also computed. Additionally, the Area-Under-the-ROC-Curve (AUC) was determined for both the training and test sets, with values of 0.883 and 0.906, respectively, indicating strong predictive performance.\n\nTo further validate the model, an external dataset comprising 25 recently reported ligands was used. The predicted results from this dataset were found to be in good agreement with the biological functions of the reported ligands, confirming the model's reliability. The model's predictive accuracy was notably higher for compounds with a probability estimate greater than 0.7, demonstrating its effectiveness in distinguishing between agonists and antagonists of the 5-HT1A receptor. This approach can potentially be extended to other members of the GPCR family.",
  "evaluation/measure": "In our study, we employed several performance metrics to comprehensively evaluate the effectiveness of our Support Vector Machine (SVM) model in distinguishing between agonists and antagonists of the 5-HT1A receptor. The primary metrics reported include the Receiver-Operating-Characteristics (ROC) curve, the Area Under the ROC Curve (AUC), sensitivity, specificity, overall accuracy, and the Matthews correlation coefficient (MCC).\n\nThe ROC curve is a graphical representation that illustrates the diagnostic ability of the model by plotting the true positive rate (sensitivity) against the false positive rate (1-specificity) at various threshold settings. This curve provides a visual assessment of the model's performance, with a curve closer to the top left corner indicating better performance. The AUC quantifies the overall ability of the model to discriminate between the positive and negative classes, with values ranging from 0 to 1. Higher AUC values signify better model performance. For our model, the AUC values for the training and test sets were 0.883 and 0.906, respectively, indicating strong discriminative power.\n\nSensitivity, also known as the true positive rate, measures the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, assesses the proportion of actual negatives that are correctly identified. Both metrics are crucial for understanding the model's performance in correctly classifying agonists and antagonists. Our model demonstrated high sensitivity and specificity, both exceeding 0.8 for the training and test sets before refinement.\n\nOverall accuracy provides a single metric that summarizes the proportion of correctly classified instances (both agonists and antagonists) out of the total instances. The accuracy values for the training and test sets were also above 0.8, indicating reliable performance.\n\nThe Matthews correlation coefficient (MCC) is a balanced measure that takes into account true and false positives and negatives, providing a value between -1 and 1, where 1 indicates a perfect model, 0 represents a random model, and -1 signifies a completely wrong model. Our model achieved an MCC of 0.783, further confirming its robustness and reliability.\n\nThese performance metrics are widely recognized and used in the literature for evaluating classification models, particularly in the field of computational biology and pharmacology. The combination of these metrics provides a thorough evaluation of our model's performance, ensuring that it is both reliable and robust in predicting the classification of agonists and antagonists of the 5-HT1A receptor.",
  "evaluation/comparison": "In our study, we focused on developing and validating a Support Vector Machine (SVM) model for classifying agonists and antagonists of the 5-HT1A receptor. While we did not explicitly compare our method to publicly available methods on benchmark datasets, our approach was rigorously validated through several means.\n\nWe employed a robust cross-validation strategy, where each subset of our data was used for prediction multiple times. This ensured that our model's performance was thoroughly evaluated. Additionally, we used the Receiver Operating Characteristic (ROC) curve to assess the classification power of our model. The Area Under the Curve (AUC) values for the training and test sets were 0.883 and 0.906, respectively, indicating strong predictive capability.\n\nTo further validate our model, we applied it to an external dataset consisting of 25 ligands collected from recent literature. This external validation confirmed the reliability and effectiveness of our SVM model in classifying agonists and antagonists of the 5-HT1A receptor.\n\nRegarding simpler baselines, our model's performance was compared against a random model, represented by a diagonal line in the ROC space. The significant difference between our model's ROC curve and the diagonal line demonstrated that our SVM model outperformed a random classifier.\n\nIn summary, while we did not perform a direct comparison with other publicly available methods, our model underwent extensive validation through cross-validation, ROC analysis, and external dataset testing. These steps ensured that our SVM model is reliable and effective for its intended purpose.",
  "evaluation/confidence": "The evaluation of our model's performance involved several key metrics, but confidence intervals for these metrics were not explicitly provided. The primary metrics used were the Area Under the Curve (AUC) for the Receiver Operating Characteristic (ROC) curves, sensitivity, specificity, and the Matthews correlation coefficient (MCC). The AUC values for the training and test sets were 0.883 and 0.906, respectively, indicating strong discriminative power. The overall predictive accuracy, sensitivity, and specificity for both the training and test sets were all above 0.8, suggesting a reliable and robust model.\n\nThe statistical significance of these results was not explicitly discussed in terms of p-values or confidence intervals. However, the high AUC values and the consistent performance across both training and test sets imply that the model's performance is likely statistically significant. The model's ability to correctly classify compounds with high probability estimates further supports its reliability. For instance, compounds like HT01 to HT10 were predicted as antagonists with high probability, aligning with their structural similarity to known antagonists like WAY-100635.\n\nThe refinement process, which involved setting a probability estimate threshold of 0.7, significantly improved the model's performance, particularly for the test set. This refinement reduced the discrepancy between the training and test sets, indicating a more balanced and reliable model. The model's performance on an external dataset also validated its effectiveness in classifying agonists and antagonists of the 5-HT1A receptor.\n\nIn summary, while explicit confidence intervals and statistical significance tests were not provided, the high performance metrics and consistent results across different datasets suggest that the model is superior to random classification and likely statistically significant. Further statistical analysis could provide more definitive evidence of the model's superiority.",
  "evaluation/availability": "Not enough information is available."
}