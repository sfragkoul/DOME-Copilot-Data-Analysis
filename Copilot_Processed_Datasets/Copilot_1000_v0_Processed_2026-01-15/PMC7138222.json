{
  "publication/title": "DeepPhagy: a deep learning framework for quantitatively measuring autophagy activity in Saccharomyces cerevisiae",
  "publication/authors": "The authors who contributed to the article are:\n\n- Y. Zhang\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n- Not sure\n-",
  "publication/journal": "Autophagy",
  "publication/year": "2020",
  "publication/pmid": "31204567",
  "publication/pmcid": "PMC7138222",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Deep Learning\n- Autophagy\n- Saccharomyces cerevisiae\n- Fluorescence Microscopy\n- GFP-Atg8\n- Convolutional Neural Networks\n- Image Analysis\n- Machine Learning\n- Bioinformatics\n- Computational Biology",
  "dataset/provenance": "The dataset used in this study consists of fluorescent microscopy images of yeast cells, specifically focusing on the autophagic process. The images were obtained from wild-type and knockout (KO) mutants of the haploid S. cerevisiae yeast strain BY4741. The KO mutants were purchased from Thermo Fisher Scientific.\n\nA total of 26,571 yeast cells were manually labeled from 216 images, with 8,078 cells identified as autophagic and 18,493 as non-autophagic. These labeled cells were used to create a benchmark dataset for training and testing the DeepPhagy model. The dataset was split into a training set containing 24,156 cells and a testing set containing 2,415 cells, maintaining a ratio of approximately 10:1.\n\nThe images were pre-processed to enhance contrast, sharpen details, detect and repair cell edges, and segment individual cells. This pre-processing pipeline was fine-tuned using the labeled cells to ensure accurate feature extraction and classification.\n\nThe dataset includes images of GFP-Atg8 fluorescence, which is used to monitor autophagic phenotypes. Additionally, other autophagic phenotypes such as Atg1-GFP vacuolar delivery, GFP-Atg19 vacuolar targeting, and the disintegration of autophagic bodies were analyzed. For these phenotypes, specific models were re-trained using newly labeled datasets to ensure accurate recognition.\n\nAll original and DeepPhagy-labeled images of wild-type and atg KO S. cerevisiae mutants are freely available for download at http://deepphagy.biocuckoo.org/dataset.php/. The benchmark datasets, including the original and manually labeled images for training and testing, are also available for download. This dataset has been used in previous studies and is intended for use by the community to further advance research in this area.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "The dataset used in this study consisted of 26,571 manually labeled yeast cells, which were randomly selected from 216 images. These cells were split into a training dataset and a testing dataset with a ratio of approximately 10:1. The training set contained 24,156 cells, including 7,322 autophagic and 16,834 non-autophagic cells. The testing set consisted of 2,415 cells, with 756 autophagic and 1,659 non-autophagic cells.\n\nThe training and testing sets were independent, ensuring that the model's performance could be evaluated on unseen data. This independence was enforced by the random selection process, which ensured that cells from the training set were not included in the testing set.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the field. The dataset is balanced, with a significant number of both autophagic and non-autophagic cells in both the training and testing sets. This balance is crucial for training robust models that can accurately classify both types of cells. The dataset's size and diversity, encompassing various yeast strains and conditions, further enhance its value for training and evaluating machine learning models in autophagy research.",
  "dataset/availability": "All original and DeepPhagy-labelled images of wild-type and atg knockout S. cerevisiae mutants are freely available for download. The benchmark datasets, including the original and manually labelled images for training and testing, are also available for download. The datasets can be accessed at http://deepphagy.biocuckoo.org/dataset.php/. The availability of these datasets ensures that other researchers can reproduce the results and build upon the work presented. The datasets are provided to support the reproducibility and transparency of the research, allowing for further advancements in the field of autophagy analysis using deep learning techniques.",
  "optimization/algorithm": "The machine-learning algorithm class used is convolutional neural networks (CNNs). Specifically, a 5-layer CNN was implemented for the DeepPhagy method. This CNN contains 3 convolutional blocks, each with a convolution layer and a pooling layer, followed by 2 fully connected layers for classification. The use of CNNs is well-established in the field of image processing and has been successfully applied to various tasks, including the recognition of autophagic phenotypes from fluorescent images.\n\nThe CNN architecture used in DeepPhagy is not entirely new but has been adapted and optimized for the specific task of identifying autophagic cells. The choice of CNN was driven by its effectiveness in handling image data and its ability to learn hierarchical feature representations. The architecture includes several key components:\n\n* Rectified Linear Unit (ReLU) activation functions to avoid gradient diffusion during training.\n* Local Response Normalization (LRN) to improve generalization capacity.\n* Max pooling layers to downsample feature representations and reduce dimensionality.\n* Fully connected layers for classifying the inputted fluorescent images.\n* A SoftMax function for calculating the probability of the output.\n\nThe reason this specific CNN architecture was not published in a machine-learning journal is that the focus of the publication is on its application to biological image analysis rather than the development of new machine-learning algorithms. The primary contribution of the work is the application of deep learning techniques to the specific problem of recognizing autophagic phenotypes in yeast cells, rather than the innovation of the CNN architecture itself. The method has been validated through extensive testing and comparison with other existing tools, demonstrating its effectiveness in the biological context.",
  "optimization/meta": "The model described does not function as a meta-predictor. It is a standalone convolutional neural network (CNN) designed specifically for classifying autophagic phenotypes in yeast cells from fluorescent images. The CNN architecture includes convolutional layers with ReLU activation and local response normalization, followed by max pooling layers. After the convolutional blocks, there are two fully connected layers for classification, with a dropout method applied to prevent overfitting. The output uses a SoftMax loss function to calculate probabilities.\n\nThe training process involves stochastic gradient descent (SGD) with a momentum of 0.9 and a learning rate that follows a sigmoid decay policy. The model was trained for 50,000 iterations using a mini-batch size of 10. Performance evaluation was conducted using standard measurements such as accuracy (Ac), sensitivity (Sn), specificity (Sp), precision (Pr), and the Mathew Correlation Coefficient (MCC).\n\nFor comparison, other machine-learning methods were used, including a random forest (RF) classifier trained on features extracted using a CellProfiler pipeline and two other CNN-based tools, DeepYeast and DeepLoc. However, these methods were used separately for comparison purposes and not as part of a meta-predictor ensemble. The training data for these comparisons was the same, ensuring independence and fairness in the evaluation process.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure efficient and accurate analysis. Initially, the original confocal microscopy images, which had a resolution of 1024 \u00d7 1024 pixels, were downsampled to 650 \u00d7 650 pixels using a Java smooth function. This reduction in resolution significantly decreased computational time without compromising image fidelity.\n\nColor inversion was applied to enhance the contrast of the images. The RGB images were then converted to grayscale, and the Sobel operator was used to sharpen the cell edges. For segmenting candidate cell regions, a multi-level Otsu thresholding algorithm was employed to convert grayscale images to binary images. Morphological operations, including erosion, dilation, and filling holes, were performed to remove isolated pixel noise, smooth irregular borders, and fill holes, respectively.\n\nTo separate clustered cells, a distance transformation was applied to calculate the distance of each pixel from the nearest candidate region, and peripheral contours were removed. A seeded region growing (SRG) algorithm was then used to label the maximum gradient regions, and the weighted centroid of each region was calculated as the cell center. Individual candidate cells were cropped to a size of 61 \u00d7 61 pixels, centered on their weighted centroids. Regions of interest (ROIs) were defined using a circle around the weighted centroid with a fixed radius of 20 pixels, and pixels outside the ROI were normalized to RGB (0, 0, 0) as the black background.\n\nThe parameters for the image preprocessing procedure were fine-tuned using a benchmark dataset of 26,571 manually labeled yeast cells. The Quantum-behaved Particle Swarm Optimization (QPSO) algorithm was adopted to minimize the error value to 5.49%, obtaining the optimal parameters for the preprocessing steps. This comprehensive preprocessing pipeline ensured that the input data for the machine-learning algorithm was of high quality and well-suited for accurate analysis.",
  "optimization/parameters": "In our study, we utilized a total of 26 parameters (p) in the image pre-processing procedure. These parameters were determined using the Quantum-behaved Particle Swarm Optimization (QPSO) algorithm. The goal was to minimize the error value (\u03b5) to obtain the optimal parameters. Through this optimization process, we achieved an \u03b5 value of 5.49%, which ensured the best possible performance of our model. This approach allowed us to fine-tune the various steps in our image pre-processing pipeline, including scaling, color inversion, grayscale conversion, edge sharpening, and segmentation, to accurately label yeast cells in fluorescent images.",
  "optimization/features": "In our study, we utilized a convolutional neural network (CNN) approach, which inherently performs feature extraction directly from the input images. Therefore, the number of input features is not explicitly defined as in traditional machine learning methods. Instead, the CNN automatically learns and extracts relevant features from the raw image data.\n\nFor comparison purposes, we also trained a random forest (RF) classifier using features extracted via a CellProfiler pipeline. In this case, a total of 102 different features were used, consisting of intensity, geometric, and texture measurements of images on different scales. These features were selected based on their relevance to the task of identifying autophagic phenotypes in yeast cells.\n\nFeature selection was not explicitly performed for the CNN model, as the network itself determines the most relevant features during training. However, for the RF classifier, the features were carefully chosen based on domain knowledge and their potential to discriminate between autophagic and non-autophagic cells. The selection of these features was done using the entire dataset, including both training and testing sets, to ensure a comprehensive feature set.\n\nNot applicable",
  "optimization/fitting": "The fitting method employed in our study involved training a convolutional neural network (CNN) to recognize autophagic phenotypes from fluorescent images of yeast cells. The CNN architecture consisted of 5 layers, which included convolutional and pooling layers, followed by fully connected layers. This architecture was chosen to balance complexity and performance, ensuring that the model could generalize well to new data.\n\nTo address the potential issue of overfitting, given the relatively small training dataset, several strategies were implemented. First, a dropout method with a threshold value of 0.5 was applied before the fully connected layers. This technique randomly sets a fraction of the input units to zero during training, which helps to prevent the network from becoming too reliant on specific features and improves generalization. Additionally, a local response normalization (LRN) function was introduced after the ReLU activation function in the convolutional layers. This function helps to improve the generalization capacity of the network by normalizing the responses across different feature maps.\n\nFurthermore, the learning rate followed a sigmoid decay policy, which gradually reduces the learning rate over time. This approach allows the model to make larger updates initially, when the loss is high, and smaller updates as it converges, helping to avoid overfitting. A weight decay of 0.0005 was also applied to penalize large weights, encouraging the model to find a simpler solution that generalizes better.\n\nTo ensure that the model was not underfitting, the network was trained for 50,000 iterations using stochastic gradient descent (SGD) with a momentum of 0.9. This extensive training allowed the model to learn the underlying patterns in the data effectively. Additionally, the performance of the model was evaluated using five standard measurements: accuracy (Ac), sensitivity (Sn), specificity (Sp), precision (Pr), and the Matthews correlation coefficient (MCC). These metrics provided a comprehensive assessment of the model's performance, ensuring that it was not only accurate but also robust and reliable.\n\nIn summary, the fitting method involved a carefully designed CNN architecture, regularization techniques such as dropout and weight decay, and extensive training. These measures collectively helped to mitigate both overfitting and underfitting, resulting in a model that generalizes well to new data.",
  "optimization/regularization": "In our study, we implemented a dropout method to prevent overfitting in our neural network model. This technique was applied before the two fully connected layers used for classifying the inputted fluorescent images. The dropout method involved setting a threshold value of 0.5, which means that during training, 50% of the neurons in these layers were randomly deactivated. This process helps to ensure that the model does not become too reliant on any single neuron or path, thereby improving its generalization capacity and reducing the risk of overfitting. Additionally, we used a local response normalization (LRN) function with specific parameters to further enhance the model's ability to generalize from the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the convolutional layers employed a ReLU activation function and a Local Response Normalization (LRN) function with specified parameters to enhance generalization. The convolutional layers utilized Gaussian filters with varying counts across layers, and a max pooling strategy was applied to downsample feature representations. The fully connected layers for classification were preceded by a dropout method to prevent overfitting. The learning rate followed a sigmoid decay policy, and the models were trained for 50,000 iterations using stochastic gradient descent (SGD) with a specified momentum and weight decay.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the software package DeepPhagy 1.0, which integrates the image pre-processing pipeline and the convolutional neural networks (CNNs), is available for download. This package supports major x64 operating systems, including Windows, Unix/Linux, and Mac. Users can directly input fluorescent images for automatic recognition of autophagic phenotypes. The software is written in Java 1.8 and packaged with Install4j 6.0, ensuring compatibility and ease of use across different platforms.\n\nFor detailed usage instructions and to access the software, users can refer to the manual available at http://deepphagy.biocuckoo.org/down.php. The software is designed to be user-friendly, allowing for both individual and batch processing of images, and includes options for manual labeling and exporting results in multiple formats.",
  "model/interpretability": "The model DeepPhagy, which we developed, is primarily a deep learning-based framework that utilizes convolutional neural networks (CNNs) for the classification of autophagic phenotypes in yeast cells. As such, it is largely considered a black-box model, meaning that the internal workings and decision-making processes are not easily interpretable by humans.\n\nHowever, we have taken steps to enhance the interpretability of our model. For instance, we visualized the activations of the last fully connected layer of DeepPhagy using t-distributed stochastic neighbor embedding (t-SNE). This visualization technique allows us to project high-dimensional data into a two-dimensional space, making it easier to distinguish between different types of cells. In our study, we demonstrated that DeepPhagy clearly distinguished autophagic cells from non-autophagic cells, whereas other tools like CellProfiler, DeepYeast, and DeepLoc showed substantial overlap in their classifications.\n\nAdditionally, we evaluated the performance of DeepPhagy using standard measurements such as accuracy, sensitivity, specificity, precision, and the Mathew Correlation Coefficient. These metrics provide a quantitative assessment of the model's performance and help in understanding its strengths and weaknesses.\n\nWhile DeepPhagy itself is not fully transparent, the use of visualizations and performance metrics helps in gaining insights into how the model makes its predictions. This approach allows researchers to trust the model's outputs and understand its limitations better.",
  "model/output": "The model is a classification model. It is designed to label autophagic and non-autophagic cells from fluorescent images. The output of the model is implemented with a SoftMax loss function to calculate the probability of each class. The model provides a probability score for each cell image, indicating the likelihood of it being autophagic or non-autophagic. This probability score can be used as a threshold to generate predictions. The model's output is used to automatically recognize autophagic phenotypes in a quantitative manner. The final output is a classification of each cell as either autophagic or non-autophagic, marked with different colored rings for visualization.",
  "model/duration": "The model was trained for 50,000 iterations. The specific execution time for each iteration or the total training time is not provided. However, the training process utilized stochastic gradient descent with a mini-batch size of 10, which can influence the overall training duration. Additionally, the model employed convolutional layers with Gaussian filters, max pooling, and fully connected layers, followed by a SoftMax loss function for classification. These architectural choices, along with the training parameters such as learning rate decay and momentum, would have contributed to the computational demands and execution time. For more detailed information on execution time, further specifics on the hardware used and the implementation environment would be necessary.",
  "model/availability": "The DeepPhagy software package, version 1.0, is freely available for academic research. It is written in Java 1.8 and packaged with Install4j 6.0, ensuring compatibility across major operating systems, including Windows, Unix/Linux, and Mac. The software integrates both the image pre-processing pipeline and the 5-layer convolutional neural networks (CNNs), allowing users to input fluorescent images directly for automatic recognition of autophagic phenotypes.\n\nThree stand-alone packages have been developed to support the major x64 operating systems. The software has been rigorously tested under Windows 7/10, Ubuntu, and Apple Mac OS 10.12 (Sierra), ensuring its reliability and performance across different platforms. For convenience, DeepPhagy 1.0 has been designed as an easy-to-use program. Users can load images in various formats, including BMP, JPG, PNG, GIF, or TIF, and the software will process these images to recognize autophagic phenotypes quantitatively.\n\nThe software also includes a 'Batch' module, which allows for the input of multiple images at once, making it efficient for large-scale analyses. Additionally, users have the option to manually label images before or after computational recognition, providing flexibility in data analysis. The labeled images can be exported in multiple formats for further use.\n\nFor more detailed instructions on usage, a manual is available for download from the official website. The software's availability and user-friendly design make it a valuable tool for researchers studying autophagy in yeast cells.",
  "evaluation/method": "The evaluation of DeepPhagy involved several rigorous methods to ensure its accuracy and robustness. Cross-validation was employed, specifically 4-, 6-, 8-, and 10-fold cross-validations, which yielded area under the curve (AUC) values of 0.9749, 0.9708, 0.9726, and 0.9710, respectively. These results demonstrated the tool's consistent performance across different validation schemes.\n\nIn addition to cross-validation, DeepPhagy was compared with other existing tools, including CellProfiler, DeepYeast, and DeepLoc. These tools were retrained using the same dataset as DeepPhagy, and their AUC values for 10-fold cross-validations were 0.8489, 0.9483, and 0.9574, respectively. This comparison highlighted DeepPhagy's superior performance.\n\nFurthermore, the tools were evaluated on a testing dataset, where DeepPhagy achieved an AUC of 0.9813, outperforming CellProfiler (0.8697), DeepYeast (0.9761), and DeepLoc (0.9675). This testing dataset evaluation provided an independent assessment of DeepPhagy's generalization capabilities.\n\nThe performance of DeepPhagy was also analyzed at the single-cell level, where it showed considerably higher accuracy compared to DeepYeast and DeepLoc. This evaluation underscored DeepPhagy's effectiveness in distinguishing autophagic cells from non-autophagic cells.\n\nAdditionally, the mistakes made by DeepPhagy were carefully analyzed using 216 yeast images. The errors were primarily attributed to technical issues and yeast population heterogeneity, such as regions with contamination, ambiguous signals, and dead or immature cells. This analysis helped in understanding the limitations and areas for improvement in DeepPhagy.\n\nOverall, the evaluation of DeepPhagy involved a combination of cross-validation, comparison with other tools, testing on independent datasets, and detailed error analysis. These methods collectively demonstrated DeepPhagy's superior accuracy and reliability in recognizing autophagic cells.",
  "evaluation/measure": "To evaluate the prediction accuracy and robustness of DeepPhagy, several standard measurements were adopted. These include accuracy (Ac), sensitivity (Sn), specificity (Sp), precision (Pr), and the Mathew Correlation Coefficient (MCC). These metrics provide a comprehensive view of the model's performance.\n\nAccuracy (Ac) is calculated as the ratio of true positives (TP) and true negatives (TN) to the total number of predictions. Sensitivity (Sn) measures the proportion of actual positives that are correctly identified, while specificity (Sp) measures the proportion of actual negatives that are correctly identified. Precision (Pr) indicates the proportion of positive identifications that are actually correct. The Mathew Correlation Coefficient (MCC) provides a balanced measure that considers all four outcomes (TP, TN, FP, FN) and is particularly useful for imbalanced datasets.\n\nThese metrics are widely used in the literature for evaluating classification models, ensuring that the performance of DeepPhagy can be compared with other methods. The use of these metrics allows for a thorough assessment of the model's ability to correctly identify autophagic cells, making the evaluation robust and representative of standard practices in the field.",
  "evaluation/comparison": "A comparison to publicly available methods was performed using benchmark datasets. Specifically, DeepPhagy was compared with CellProfiler, DeepYeast, and DeepLoc. These tools were retrained using the same training set as DeepPhagy, and their performance was evaluated using 10-fold cross-validation. The Area Under the Curve (AUC) values for CellProfiler, DeepYeast, and DeepLoc were 0.8489, 0.9483, and 0.9574, respectively. Additionally, the performance of these tools was compared to DeepPhagy using a testing dataset, where the AUC values were 0.8697 for CellProfiler, 0.9761 for DeepYeast, and 0.9675 for DeepLoc, while DeepPhagy achieved an AUC of 0.9813.\n\nA comparison to simpler baselines was also conducted. A random forest (RF) classifier was trained on 102 features extracted using a CellProfiler pipeline. The RF classifier's performance was evaluated and compared to DeepPhagy, demonstrating that deep learning algorithms, including DeepPhagy, outperformed conventional machine learning classifiers. The accuracy of DeepPhagy was found to be considerably higher than that of DeepYeast and DeepLoc, especially on the single cell level. This comparison highlights the superior performance of deep learning-based methods in classifying protein subcellular localizations from high-throughput microscopy data.",
  "evaluation/confidence": "The evaluation of DeepPhagy's performance involved several standard measurements, including accuracy (Ac), sensitivity (Sn), specificity (Sp), precision (Pr), and the Mathew Correlation Coefficient (MCC). These metrics were calculated to assess the prediction accuracy and robustness of the model. The area under the curve (AUC) values from 10-fold cross-validations were reported as 0.9710, indicating high performance. Additionally, the AUC values for other tools like CellProfiler, DeepYeast, and DeepLoc were 0.8489, 0.9483, and 0.9574, respectively, showing that DeepPhagy outperformed these methods.\n\nStatistical significance was ensured through pairwise comparisons using two-tailed t-tests with a Benjamini-Hochberg adjusted p-value of less than 0.01. This rigorous statistical approach helps to confirm that the observed differences in performance are not due to random chance. The results were also visually represented using ROC curves and t-SNE visualizations, providing a clear depiction of the model's ability to distinguish between autophagic and non-autophagic cells.\n\nThe evaluation included a comparison of DeepPhagy with other existing tools using the same training dataset. The performance metrics were consistently higher for DeepPhagy across different folds of cross-validation, reinforcing the model's reliability. Furthermore, the testing dataset results showed that DeepPhagy achieved an AUC of 0.9813, which was superior to CellProfiler (0.8697), DeepYeast (0.9761), and DeepLoc (0.9675). This comprehensive evaluation demonstrates the superior accuracy and robustness of DeepPhagy in recognizing autophagic cells.",
  "evaluation/availability": "All original and DeepPhagy-labelled images of wild-type and atg knockout S. cerevisiae mutants are freely available for download. The benchmark datasets, including the original and manually labelled images for training and testing, are also available for download. The datasets can be accessed at the provided URL."
}