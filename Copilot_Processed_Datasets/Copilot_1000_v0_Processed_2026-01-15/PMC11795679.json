{
  "publication/title": "Development and validation of machine learning-derived frailty index in predicting outcomes of patients undergoing percutaneous coronary intervention",
  "publication/authors": "The authors who contributed to the article are:\n\nJohn T.Y. Soong, who contributed to the writing of the original draft, data curation, and conceptualization.\n\nL.F. Tan, who contributed to the writing of the original draft, data curation, and conceptualization.\n\nRodney Y.H. Soh, who contributed to the writing of the original draft, visualization, data curation, and review & editing.\n\nW.B. He, who contributed to the formal analysis and data curation.\n\nAndie H. Djohan, who contributed to the validation and supervision.\n\nH.W. Sim, who contributed to the writing of the original draft, validation, and supervision.\n\nT.C. Yeo, who contributed to the writing of the original draft, visualization, and supervision.\n\nH.C. Tan, who contributed to the writing of the original draft, data curation, and conceptualization.\n\nMark Y.Y. Chan, who contributed to the writing of the original draft and supervision.\n\nC.H. Sia, who contributed to the writing of the original draft and supervision.\n\nM.L. Feng, who contributed to the validation, supervision, and software.",
  "publication/journal": "IJC Heart & Vasculature",
  "publication/year": "2024",
  "publication/pmid": "39911618",
  "publication/pmcid": "PMC11795679",
  "publication/doi": "https://doi.org/10.1016/j.ijcha.2024.101511",
  "publication/tags": "- Novel machine learning\n- Frailty index\n- Percutaneous coronary intervention\n- Asian\n- Predictive power\n- Clinical outcomes\n- Cardiovascular disease\n- Machine learning models\n- Logistic regression\n- Extreme Gradient Boosting\n- Frailty status\n- Patient stratification\n- Hospital information systems\n- Cardiovascular medicine\n- Aging population\n- Predictive analytics\n- Healthcare structures\n- Acute coronary syndromes\n- Patient care\n- Data-driven decision making",
  "dataset/provenance": "The dataset utilized in this study was derived from data routinely collected as part of patient care in a cohort of patients who received percutaneous coronary intervention (PCI). This dataset is comprehensive, encompassing a wide range of variables that contribute to the frailty index. The dataset includes 30 variables, which are used to calculate a patient episode level index. This index is then divided into ascending quartiles to categorize patients into different frailty statuses: robust, mild frailty, moderate frailty, and severe frailty.\n\nThe dataset underwent a missing data analysis, revealing a range of percentage missing data across the variables, from 0% to 35.3%. To address this, multiple imputation via classification and regression tree (CART) was utilized to create a complete dataset, ensuring that all variables within the frailty index were included. This method has been shown to improve frailty index estimation and predictive power, particularly in aging studies.\n\nThe dataset was randomly split into training (80%) and validation (20%) sets to develop and validate the predictive models. The models constructed include a conventional logistic regression model and an Extreme Gradient Boosting (XGBoost) machine learning model. The XGBoost model, known for its efficiency and scalability, was used to analyze the contribution of each variable to different outcomes.\n\nThe dataset includes primary outcomes such as cardiac and in-hospital death, as well as secondary outcomes like subsequent coronary angiogram required, subsequent congestive cardiac failure, subsequent myocardial infarction, and subsequent stroke or transient ischemic attack. These secondary outcomes were combined into a composite adverse outcome using Boolean OR logic.\n\nThe mean population age in the dataset is 61.12 years, with 19.4% of the participants being female. The dataset reflects an increase in the prevalence of comorbidities and deranged physiology as frailty status worsens. The full patient characteristics by frailty status are displayed in supplementary tables.\n\nThe dataset has been used to develop a frailty index with good predictive power for significant clinical outcomes post-PCI. The models developed have the potential to be automated within hospital information systems, further reducing clinician burden. The dataset and the analytics source code of the project can be accessed for further validation and use by the community.",
  "dataset/splits": "The dataset was split into two main parts: a training set and a validation set. The training set comprised 80% of the data, while the validation set contained the remaining 20%. This split was done randomly to ensure that the model could be trained effectively and then validated on unseen data. The specific number of data points in each split was not explicitly stated, but the proportions are clear: 80% for training and 20% for validation. This approach helps in assessing the model's performance and generalizability.",
  "dataset/redundancy": "The dataset was randomly split into training and validation sets, with 80% of the data allocated for training and 20% for validation. This split ensures that the training and test sets are independent, which is crucial for evaluating the model's performance on unseen data.\n\nTo enforce independence and maintain the integrity of the dataset, a stratified sampling method was employed for cases with a heterogeneous distribution. This method ensures that the proportion of the minority class in the test data is similar to that in the training data. This approach is particularly important when dealing with imbalanced datasets, where certain outcomes, such as in-hospital death or cardiac death, are underrepresented.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of frailty and cardiovascular outcomes. The use of stratified sampling helps mitigate the issues arising from class imbalance, which is a common challenge in medical datasets. By ensuring that the test data represents the minority class similarly to the training data, the model's predictive power is enhanced, and the results are more reliable.\n\nIn summary, the dataset was carefully split to maintain independence between training and test sets, with stratified sampling used to handle class imbalance. This approach aligns with best practices in machine learning, ensuring robust and generalizable model performance.",
  "dataset/availability": "The data used in this study is not publicly available. The dataset consists of patient information collected as part of routine care for individuals who underwent percutaneous coronary intervention (PCI). Due to the sensitive nature of this medical data, it is not released in a public forum to protect patient privacy and comply with ethical guidelines.\n\nThe dataset was split into training and validation sets, with 80% of the data used for training and 20% for validation. This split was done randomly to ensure that the model's performance could be evaluated on unseen data. The specifics of the data splits are not publicly disclosed to maintain the integrity of the validation process and to prevent overfitting.\n\nThe study adheres to strict ethical standards and regulatory requirements, ensuring that all patient data is handled securely and confidentially. Access to the dataset is restricted to authorized researchers involved in the study, and all analyses were conducted in compliance with institutional review board approvals and relevant data protection laws.\n\nThe analytics source code of the project can be accessed at https://github.com/nus-mornin-lab/frailty_cardiac. This repository provides transparency into the methods and algorithms used in the development of the frailty index and the predictive models. However, the actual patient data remains proprietary and is not included in the public repository.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is an ensemble learning method based on decision trees, specifically Extreme Gradient Boosting (XGBoost). This algorithm is not new; it is well-established and known for its efficiency and scalability, particularly in handling sparse data.\n\nXGBoost was chosen for its robustness and ability to provide high predictive power, which is crucial for our study focusing on predicting adverse clinical outcomes post percutaneous coronary intervention (PCI). The decision to use XGBoost was driven by its proven track record in similar predictive modeling tasks and its suitability for the complex and high-dimensional data involved in our research.\n\nThe reason this algorithm was not published in a machine-learning journal is that our primary focus is on the application of machine learning in the medical field, specifically in developing a frailty index to predict clinical outcomes. The innovation lies in the application of XGBoost to this particular medical problem rather than the development of a new machine-learning algorithm. Our study contributes to the medical literature by demonstrating the effectiveness of XGBoost in improving predictive power for significant clinical outcomes post PCI, which has direct implications for patient care and healthcare management.",
  "optimization/meta": "The model developed in this study does not use data from other machine-learning algorithms as input. Instead, it utilizes a combination of logistic regression and Extreme Gradient Boosting (XGBoost) machine learning methodologies to identify predictors of adverse clinical outcomes post percutaneous coronary intervention (PCI).\n\nThe XGBoost model is an ensemble learning method based on decision trees, which is known for its efficiency and scalability. This model was used to analyze the contribution of each variable to different outcomes, helping to construct the final machine learning algorithm.\n\nThe logistic regression model was used to ascertain odds ratios with 95% confidence intervals and to test the significance of these odds ratios. Two separate risk models were created: one utilizing the frailty index only, and another combining age, gender, and the frailty index.\n\nThe dataset was randomly split into training (80%) and validation (20%) sets to ensure that the training data was independent. This split helps in evaluating the model's performance on unseen data, thereby ensuring the robustness and generalizability of the predictions.\n\nThe models' predicted probabilities were used to plot the area under the receiver operating characteristic curve (AUC) as a measure of predictive power. Additionally, the Net Reclassification Index (NRI) and Decision Curve Analysis (DCA) were applied to assess the incremental improvement in prediction over baseline models.\n\nIn summary, the model leverages both logistic regression and XGBoost methodologies, with a clear separation of training and validation data to ensure independence and reliability of the results.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, a frailty index was created using 30 variables, each contributing to a total of 40 points. This index was calculated at the patient episode level, with the patient's actual symptom points serving as the numerator. The resultant index was then divided into ascending quartiles to categorize patients into robust, mild frailty, moderate frailty, and severe frailty statuses.\n\nTo handle missing data, which ranged from 0% to 35.3% across variables, a multiple imputation technique using classification and regression tree (CART) was employed. This method improved the frailty index estimation and predictive power, ensuring a complete dataset for analysis.\n\nMulticollinearity was assessed through a correlation matrix of all variables. The ethnicity variable, although weakly correlated with outcome variables, was removed from further analysis to avoid potential biases. The dataset was then randomly split into training (80%) and validation (20%) sets.\n\nTwo predictive models were constructed: a conventional logistic regression model and an Extreme Gradient Boosting (XGBoost) machine learning model. The XGBoost model, known for its efficiency and scalability, was particularly useful for handling sparse data. Logistic regression was used to ascertain odds ratios and the significance of these ratios was tested using the t-test and Wald Chi-Squared Test method. Two separate risk models were created: one utilizing the frailty index alone and another combining age, gender, and the frailty index.\n\nThe models' predicted probabilities were used to plot the area under the receiver operating characteristic curve (AUC) as a measure of predictive power. Additionally, the Net Reclassification Index (NRI) and Decision Curve Analysis (DCA) were applied to evaluate the incremental improvement in prediction over baseline models. These analyses were conducted using R software version R44.1.22, with a p-value of less than 0.05 defined as statistically significant.",
  "optimization/parameters": "In our study, we utilized a frailty index consisting of 30 variables, which contributed to a total of 40 points. This index was used to calculate a patient episode level index, serving as a crucial input parameter for our predictive models. The selection of these variables was meticulously defined to ensure comprehensive coverage of relevant health metrics.\n\nThe frailty index was categorized into ascending quartiles to form cut-points for different frailty statuses: robust, mild frailty, moderate frailty, and severe frailty. This categorization helped in stratifying patients based on their frailty levels, which was essential for our predictive modeling.\n\nAdditionally, age and gender were included as important input parameters. These demographic factors were chosen due to their well-documented influence on cardiovascular outcomes. The inclusion of age and gender, along with the frailty index, allowed us to develop more robust and accurate predictive models.\n\nThe dataset underwent a rigorous process of handling missing data, utilizing multiple imputation via classification and regression tree (CART) to create a complete dataset. This step was crucial in ensuring that all variables within the frailty index were fully utilized, thereby enhancing the predictive power of our models.\n\nIn summary, the input parameters for our models included the frailty index (comprising 30 variables), age, and gender. These parameters were selected based on their established relevance to cardiovascular outcomes and their ability to improve the predictive accuracy of our models.",
  "optimization/features": "The input features for our model consist of 30 variables, which are used to create a frailty index. This index is calculated at the patient episode level and is used to assess the severity of frailty, categorizing patients into robust, mild frailty, moderate frailty, and severe frailty status.\n\nFeature selection was performed using the XGBoost model, which is an ensemble learning method based on decision trees. This model helped identify the contribution and importance of each variable to different outcomes. The variables selected through this process were then used to construct the final machine learning algorithm.\n\nThe dataset was split into training (80%) and validation (20%) sets. The feature selection process was conducted using the training set only, ensuring that the validation set remained unbiased and could be used to assess the model's performance accurately. This approach helps in maintaining the integrity of the validation process and prevents data leakage, which could otherwise lead to overoptimistic performance estimates.",
  "optimization/fitting": "The fitting method employed in this study involved constructing two predictive models: a conventional logistic regression model and an Extreme Gradient Boosting (XGBoost) machine learning model. The dataset was randomly split into training (80%) and validation (20%) sets to ensure robust model evaluation.\n\nThe logistic regression model was used to ascertain odds ratios with 95% confidence intervals, and the significance of these odds ratios was tested using the t-test and Wald Chi-Squared Test method. This approach helped in identifying the contribution of each variable to the outcomes, ensuring that the model was not overfitting by validating the statistical significance of the parameters.\n\nThe XGBoost model, an ensemble learning method based on decision trees, was utilized to analyze the contribution (importance) of each variable to different outcomes. XGBoost is designed to handle sparse data efficiently and is highly scalable, which helped in managing the complexity of the dataset. The model's predictive probabilities were used to plot the area under the receiver operating characteristic curve (AUC) as a measure of predictive power. This metric provided a clear indication of the model's performance and helped in ruling out underfitting by ensuring that the model could generalize well to unseen data.\n\nTo further assess the model's performance, the Net Reclassification Index (NRI) and Decision Curve Analysis (DCA) were applied. These methods evaluated the incremental improvement in prediction over baseline models and the degree of benefit provided by the 'Frailty Index + Age + Gender' model compared to the baseline 'Age + Gender' model. This comprehensive evaluation ensured that the model was neither overfitting nor underfitting, providing a reliable predictive tool for significant clinical outcomes.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters used in our study are available. All the analytics source code of the project can be accessed on GitHub at the following URL: https://github.com/nus-mornin-lab/frailty_cardiac. This repository contains detailed information on the configurations and parameters utilized in our machine learning models, including the XGBoost and logistic regression models. The code and associated documentation provide transparency and reproducibility for our methods. The repository is open access, allowing researchers and practitioners to review, use, and build upon our work. This ensures that the community can benefit from our findings and apply similar methodologies in their own research or clinical settings.",
  "model/interpretability": "The models developed in this study include both a conventional logistic regression model and an Extreme Gradient Boosting (XGBoost) machine learning model. The logistic regression model is inherently more interpretable, as it provides odds ratios and confidence intervals for each variable, making it clear how each factor contributes to the outcomes. This transparency allows for straightforward interpretation of the impact of variables such as the frailty index, age, and gender on the predicted outcomes.\n\nOn the other hand, the XGBoost model, while highly efficient and scalable, is considered more of a black-box model. However, it offers insights into the importance of each variable in predicting the outcomes. For instance, the frailty index consistently shows high importance across different outcomes, indicating its significant role in prediction. Age and gender also contribute, but to a lesser extent compared to the frailty index. This variable importance ranking helps in understanding which factors are most influential in the model's predictions, even though the exact relationships are not as explicitly defined as in logistic regression.\n\nIn summary, while the logistic regression model provides clear, interpretable results through odds ratios, the XGBoost model offers a more complex but powerful predictive capability, with variable importance scores aiding in interpretability.",
  "model/output": "The model developed in this study is primarily a classification model. It was designed to predict significant clinical outcomes post-percutaneous coronary intervention (PCI), including cardiac death, in-hospital death, and composite adverse events. These outcomes are categorical in nature, making classification the appropriate approach.\n\nThe model utilized two main methodologies: logistic regression and Extreme Gradient Boosting (XGBoost). Logistic regression was used to ascertain odds ratios and the significance of these ratios for various outcomes. XGBoost, an ensemble learning method based on decision trees, was employed to analyze the contribution of each variable to different outcomes. The predicted probabilities from these models were used to plot the area under the receiver operating characteristic curve (AUC), which measures the predictive power of the models.\n\nThe study also evaluated the incremental improvement in prediction over baseline models using the Net Reclassification Index (NRI) and Decision Curve Analysis (DCA). These evaluations further support the classification nature of the model, as they assess how well the model reclassifies patients into different risk categories compared to baseline models.\n\nIn summary, the model is a classification model aimed at predicting categorical clinical outcomes with high predictive power.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code of the project is publicly available. It can be accessed through a GitHub repository. The repository contains all the analytics source code used in the project. The specific URL for the repository is https://github.com/nus-mornin-lab/frailty_cardiac. The code is released under the CC BY-NC license, which allows for non-commercial use and distribution with proper attribution. This makes it accessible for researchers and developers who wish to replicate or build upon the work.",
  "evaluation/method": "The evaluation of the developed model involved several rigorous steps to ensure its predictive power and reliability. Initially, the dataset was randomly split into training (80%) and validation (20%) sets. This split allowed for the model to be trained on a substantial portion of the data while reserving a separate set for unbiased evaluation.\n\nTwo predictive models were constructed: a conventional logistic regression model and an Extreme Gradient Boosting (XGBoost) machine learning model. The logistic regression model was used to ascertain odds ratios with 95% confidence intervals and to test the significance of these odds ratios using statistical methods such as the t-test and Wald Chi-Squared Test. This model was created in two versions: one utilizing the frailty index alone and another combining age, gender, and the frailty index.\n\nThe XGBoost model, known for its efficiency and scalability, was employed to analyze the contribution of each variable to different outcomes. After identifying the key variables through XGBoost, these variables were used to construct the final machine learning algorithm. The models' predicted probabilities were then used to plot the area under the receiver operating characteristic curve (AUC), which served as a measure of predictive power.\n\nTo assess the incremental improvement in prediction over baseline models, the Net Reclassification Index (NRI) and Decision Curve Analysis (DCA) were applied. These methods compared the 'Frailty Index + Age + Gender' model to the baseline 'Age + Gender' model in both the training and test groups. This comparison helped evaluate the degree of benefit provided by the inclusion of the frailty index.\n\nAdditionally, a subgroup analysis was conducted by dividing the cohort into those receiving elective PCI and those presenting with non-ST segment elevation myocardial infarction. All analyses were performed using R software version R44.1.22, with a p-value of less than 0.05 defined as statistically significant. The source code for all analytics is accessible via a provided GitHub link, ensuring transparency and reproducibility of the methods used.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the predictive power of our models. For the machine learning models, we reported the Area Under the Curve (AUC) for the Receiver Operating Characteristic (ROC) curve. Specifically, the XGBoost model demonstrated an AUC of 0.83 for both cardiac death and in-hospital death, indicating strong predictive performance. However, for composite adverse events, the AUC was 0.66, suggesting a more modest predictive capability.\n\nIn addition to AUC, we utilized the Net Reclassification Index (NRI) to assess the improvement in risk prediction when the frailty index was added to a baseline model that included only age and gender. The NRI showed statistically significant improvements in predicting cardiac death (8.5%), in-hospital death (12%), and composite adverse events (17.9%).\n\nWe also conducted a Decision Curve Analysis (DCA) to evaluate the clinical benefit of our models. The DCA compared the 'Age + Gender' model, the 'Frailty Index alone' model, and the combined 'Frailty Index + Age + Gender' model. The results indicated that the frailty index alone provided additional benefits compared to the 'Age + Gender' model.\n\nThese metrics are representative of those commonly used in the literature for evaluating predictive models in similar contexts. The AUC is a standard measure for assessing the discriminative ability of models, while the NRI and DCA provide insights into the clinical utility and incremental value of the models. Our choice of metrics ensures a comprehensive evaluation of model performance, aligning with established practices in the field.",
  "evaluation/comparison": "In our study, we employed a comprehensive approach to evaluate the performance of our machine learning models. We constructed two predictive models: a conventional logistic regression model and an Extreme Gradient Boosting (XGBoost) machine learning model. The XGBoost model, known for its efficiency and scalability, was chosen for its ability to handle sparse data and provide robust predictions.\n\nTo assess the predictive power of these models, we used the area under the receiver operating characteristic curve (AUC). The XGBoost model demonstrated superior performance in predicting cardiac death and in-hospital death, with an AUC of 0.83 for both outcomes. However, it did not significantly outperform the logistic regression model in predicting composite adverse events, achieving an AUC of 0.66.\n\nIn addition to comparing the models' AUCs, we evaluated the incremental improvement in prediction using the Net Reclassification Index (NRI) and Decision Curve Analysis (DCA). The NRI showed statistically significant improvements in predicting cardiac death, in-hospital death, and composite adverse events when the frailty index was added to a baseline model that included only age and gender. The DCA further illustrated the additional benefit of including the frailty index in the prediction models.\n\nWhile we did not compare our methods to publicly available benchmark datasets, our approach involved a rigorous comparison to simpler baselines, such as the logistic regression model. This comparison allowed us to highlight the strengths of the XGBoost model in handling complex datasets and providing more accurate predictions for significant clinical outcomes post-PCI.",
  "evaluation/confidence": "The evaluation of our machine learning models, specifically the XGBoost models, included comprehensive performance metrics with confidence intervals. For instance, the Area Under the Curve (AUC) for predicting cardiac death and in-hospital death was reported with 95% confidence intervals, providing a clear range of expected performance. The AUC for cardiac death was 0.83 (95% CI 0.80 \u2013 0.86), and for in-hospital death, it was also 0.83 (95% CI 0.80 \u2013 0.86). These intervals indicate the reliability of our model's predictive power.\n\nStatistical significance was thoroughly assessed using various methods. The odds ratios for different predictors, such as age, gender, and the frailty index, were tested using t-tests and Wald Chi-Squared tests. The p-values for these tests were consistently below 0.05, indicating strong statistical significance. For example, the frailty index showed a highly significant p-value of less than 0.001 for predicting cardiac death and in-hospital death, reinforcing its importance as a predictor.\n\nAdditionally, the Net Reclassification Index (NRI) was used to evaluate the improvement in risk prediction when the frailty index was added to a baseline model of age and gender. The NRI results were statistically significant, showing improvements of 8.5% for cardiac death, 12% for in-hospital death, and 17.9% for composite adverse events. These improvements were all statistically significant with p-values less than 0.05.\n\nDecision Curve Analysis (DCA) further supported the superiority of our models by demonstrating the net benefit of using the frailty index alone or in combination with age and gender, compared to using age and gender alone. This analysis provided a visual and quantitative measure of the models' clinical utility.\n\nOverall, the performance metrics, confidence intervals, and statistical significance tests collectively demonstrate that our machine learning models, particularly the XGBoost models, are robust and superior to baseline models in predicting significant clinical outcomes post-PCI.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study utilized retrospective single-centre patient registry data, which is not released publicly due to privacy and ethical considerations. However, the analytics source code of the project can be accessed on GitHub at https://github.com/nus-mornin-lab/frailty_cardiac. This code includes the methodologies used for data analysis and model development, allowing for reproducibility of the results. The study was conducted using R software version R44.1.22, and the specific details of the data processing and analysis steps are outlined in the supplementary materials and the GitHub repository. For further information or access to the data, interested parties may contact the corresponding authors."
}