{
  "publication/title": "Collaborative analysis on fruit disorder with AI and transcriptome",
  "publication/authors": "The authors who contributed to this article are:\n\nK. Masuda, M. Suzuki, H. Asakuma, K. Takeshita, K. Baba, Y. Kubo, T. Akagi, and M. Sugiura.\n\nK. Masuda, M. Suzuki, H. Asakuma, K. Takeshita, K. Baba, and Y. Kubo were involved in the conceptualization and methodology of the study, focusing on the deep learning models and transcriptome analysis. They also contributed to the data curation and analysis, particularly in the visualization of relevant regions for rapid-softening prediction using Grad-CAM and guided Grad-CAM.\n\nT. Akagi and M. Sugiura provided supervision and resources for the research, ensuring the integration of AI and transcriptome analysis. They also played a crucial role in the validation and interpretation of the results, contributing to the overall scientific rigor of the study.\n\nThe collaborative efforts of these authors resulted in a comprehensive analysis of fruit disorder using AI and transcriptome data, advancing the understanding of rapid-softening in persimmon fruits.",
  "publication/journal": "Plant Cell Physiol.",
  "publication/year": "2023",
  "publication/pmid": "37225398",
  "publication/pmcid": "PMC10700010",
  "publication/doi": "10.1093/pcp/pcad050",
  "publication/tags": "- Fruit disorder\n- AI\n- Transcriptome\n- Rapid-softening prediction\n- Grad-CAM\n- Guided Grad-CAM\n- Persimmon fruits\n- Deep learning\n- Image analysis\n- Plant omics",
  "dataset/provenance": "The dataset used in this study consists of photographic images of persimmon fruits, specifically from the cultivar 'Soshu'. A total of 2,690 fruits were harvested at the fully mature stage in October 2018 in Gifu city, Japan. These fruits were divided into two groups: one consisting of 1,446 fruits and the other of 1,244 fruits. RGB photographic images of the apex side of each fruit were taken using two different digital cameras on a uniform black background, forming 'dataset A' and 'dataset B'.\n\nThe use of two different cameras was intended to capture environmental differences and to test the robustness of the convolutional neural network (CNN) models trained with these images. The fruits were assessed for rapid softening by storing them at ambient temperature for one week and checking their flesh texture. Fruits that substantially softened within this period were classified as 'rapid softening'.\n\nThe dataset was utilized to train a VGG16 model for binary classification, distinguishing between rapid softening (positive) and control (negative) fruits. This model was implemented in Keras 2.2.4 and pre-trained with the ImageNet dataset. The images captured were analyzed to predict the fate of the fruits, which were then subjected to further transcriptomic analysis to understand the physiological mechanisms underlying rapid softening.",
  "dataset/splits": "There were two datasets, A and B, each consisting of images of persimmon fruits. The images in each dataset were randomly split into training and validation sets in a ratio of 3:1. Dataset A consisted of 1,446 fruits, while dataset B consisted of 1,244 fruits. Therefore, in dataset A, approximately 1,084 images were used for training and 362 for validation. In dataset B, approximately 933 images were used for training and 311 for validation. The validation sets were used to evaluate the performance of the trained models. The training sets were used to train two independent classification models, referred to as model A and model B.",
  "dataset/redundancy": "The datasets used in this study were split into training and validation sets with a ratio of 3:1. This means that for every dataset, 75% of the images were used for training the models, while the remaining 25% were used for validation purposes. The images in each dataset were randomly split to ensure that the training and validation sets were independent. This random splitting helped to enforce independence by preventing any systematic bias that could arise from a non-random split.\n\nThe distribution of the datasets used in this study is comparable to previously published machine learning datasets in the context of plant science. The datasets were designed to capture the variability in the features relevant to the prediction of rapid softening in persimmon fruits. The models were trained on these datasets to achieve adequate classification performance, with ROC-AUC values greater than 0.77 and accuracy greater than 75%. This performance is consistent with the standards set by other studies in the field, ensuring that the datasets are robust and reliable for the intended analysis.\n\nThe independence of the training and validation sets was crucial for evaluating the models' generalization capabilities. By ensuring that the sets were independent, the study could accurately assess how well the models performed on unseen data, which is a critical aspect of validating the models' predictive power. The random splitting process helped to mitigate the risk of overfitting, where a model might perform well on the training data but poorly on new, unseen data. This approach aligns with best practices in machine learning, where the goal is to develop models that can generalize well to new, unseen examples.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is convolutional neural networks (CNNs). Specifically, the VGG16 architecture was employed to train two independent classification models for predicting rapid softening in persimmon fruits. This architecture is well-established and has been widely used in various image analysis tasks, particularly in the context of the ImageNet Large Scale Visual Recognition Challenge.\n\nThe VGG16 model is not a new algorithm; it has been extensively used and validated in the field of computer vision. The choice to use VGG16 in this study was likely driven by its proven effectiveness in image classification tasks. Given that the focus of this research is on plant physiology and the application of machine learning to predict fruit disorders, the publication in a plant science journal is appropriate. The integration of CNNs with transcriptomic analysis provides a novel approach to understanding physiological mechanisms in persimmon fruits, rather than introducing a new machine-learning algorithm.",
  "optimization/meta": "In our study, we employed a meta-predictor approach to enhance the classification performance for predicting rapid-softening persimmon fruits. This meta-predictor leverages the outputs of two independently trained convolutional neural network (CNN) models, referred to as model A and model B. These models were trained using different datasets, each consisting of images captured with distinct digital cameras. This setup not only ensured efficient image capturing but also tested the robustness of the CNN models by incorporating environmental differences.\n\nThe meta-predictor combines the predictions from models A and B, utilizing a higher confidence threshold than the default classification threshold of 0.5. This combination maximized accuracy and positive precision, achieving over 93% accuracy and a positive precision greater than 0.8 for the validation samples in dataset A. The independence of the training data for models A and B is clearly established, as the images in each dataset were randomly split into training and validation sets in a 3:1 ratio. This independence is crucial for the meta-predictor's effectiveness, as it ensures that the models learn different feature characteristics, leading to a more robust and accurate prediction system.\n\nThe meta-predictor's approach involves filtering the predictions based on higher confidence values, which helps in selecting the most reliable positive samples for further transcriptomic analyses. This method not only improves the prediction accuracy but also provides a clearer understanding of the physiological mechanisms underlying rapid softening in persimmon fruits. The use of a meta-predictor in this context demonstrates the potential of combining multiple machine-learning models to achieve higher prediction performance and gain deeper insights into complex biological processes.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the images were suitable for training the convolutional neural network (CNN) models. A total of 2,690 persimmon fruits from the cv. Soshu variety were harvested at the same full maturing stage, and RGB photographic images of the apex side were taken with different digital cameras on a uniform black background. This process formed two datasets, A and B, each consisting of images captured with different cameras. The use of two cameras aimed to enhance efficiency in image capturing and to test the robustness of the CNN models when trained with images that included environmental differences.\n\nThe images were then divided into training and validation sets in a 3:1 ratio. This division was crucial for evaluating the models' performance accurately. The VGG16 model, a typical CNN architecture, was implemented in Keras 2.2.4 and pre-trained with the ImageNet dataset. This pre-training helped the model to recognize general features in the images, which were then fine-tuned for the specific task of classifying persimmon fruits as either rapid softening (positive) or control (negative).\n\nFor the assessment of rapid softening, the packaged mature fruits were stored at ambient temperature for one week. Fruits that substantially softened within this period were defined as 'rapid softening'. This criterion was used to label the images for training the models. The images were then processed to extract relevant features, which were visualized using techniques such as t-distributed stochastic neighbor embedding (tSNE) and receiver operating characteristic (ROC) curves. These visualizations helped in understanding the feature distribution and the classification performance of the models.\n\nThe models achieved adequate classification performance, with ROC-area under curve (AUC) values greater than 0.77 and accuracy greater than 75%. The confidence distributions of the two models were not strongly correlated, suggesting that they utilized slightly different feature characteristics for classification. This difference indicated that combining the models could potentially enhance prediction performance, especially for positive samples (rapid-softening fruits).",
  "optimization/parameters": "In our study, we utilized the VGG16 model for the prediction of rapid-softening persimmon fruits. The VGG16 architecture is a deep convolutional neural network known for its simplicity and uniformity, consisting of 16 weight layers. This model has a fixed number of parameters due to its predefined architecture. The VGG16 model comprises 13 convolutional layers followed by three fully connected layers. The total number of parameters in the VGG16 model is approximately 138 million.\n\nThe selection of the VGG16 model was based on its proven effectiveness in image classification tasks and its robustness in handling large-scale image datasets. The model was pre-trained on the ImageNet dataset, which contains millions of annotated images across thousands of categories. This pre-training allows the model to generalize well to new tasks, including the classification of persimmon fruits into rapid-softening and control categories.\n\nThe fully connected layers of the VGG16 model were customized for binary classification, which is suitable for our specific task of distinguishing between rapid-softening and control persimmon fruits. The model's parameters were fine-tuned using stochastic gradient descent as the solver, with a learning rate of 0.001 and categorical cross-entropy as the loss function. The training process involved 20 to 100 epochs, with the class weight option enabled to handle class imbalances in the dataset.\n\nThe input images for the model were resized to 224 \u00d7 224 pixels and augmented using the ImageDataGenerator in Keras. This augmentation process helps to improve the model's robustness by introducing variations in the training data. The images were randomly split into training and validation sets in a ratio of 3:1, ensuring that the model's performance could be evaluated on unseen data.\n\nIn summary, the VGG16 model with its approximately 138 million parameters was chosen for its proven performance in image classification tasks. The model's parameters were fine-tuned using standard settings and techniques to optimize its performance for the specific task of predicting rapid-softening persimmon fruits.",
  "optimization/features": "The input features for the models used in this study were derived from photographic images of persimmon fruits. Specifically, RGB images of the apex side of the fruits were captured using digital cameras. These images were then used to train two independent classification models, referred to as model A and model B. The images in each dataset were randomly split into training and validation sets in a ratio of 3:1.\n\nFeature selection in the traditional sense was not explicitly mentioned. However, the use of convolutional neural networks (CNNs), specifically the VGG16 architecture, inherently involves a form of feature extraction and selection. The CNN models were pre-trained on the ImageNet dataset, which means they were initially trained to recognize a wide range of features from large-scale image data. This pre-training allows the models to extract relevant features from the input images of persimmon fruits without the need for manual feature selection.\n\nThe feature distribution in the fully connected layer of the trained models was visualized using t-distributed stochastic neighbor embedding (tSNE), a dimensionality reduction technique. This visualization helped in understanding the feature characteristics used by the models for classification. The models achieved adequate classification performance, with ROC-area under curve (AUC) values greater than 0.77 and accuracy greater than 75%.\n\nIn summary, the input features were the RGB image data of persimmon fruits, and feature selection was performed implicitly through the training of the CNN models on the ImageNet dataset. The models were trained and validated using separate datasets to ensure robust performance.",
  "optimization/fitting": "The fitting method employed in this study involved training two independent classification models using datasets A and B. The images in each dataset were randomly split for training and validation sets in a ratio of 3:1. This split ensures that the models are trained on a sufficient number of samples, reducing the risk of overfitting. The VGG16 model, pretrained on the ImageNet dataset, was used as the base architecture. This pretraining helps in mitigating overfitting by providing a good initialization for the weights, leveraging knowledge from a large and diverse dataset.\n\nTo further address overfitting, techniques such as data augmentation were employed using the ImageDataGenerator in Keras. This process involves randomly altering the training images to create new, synthetic training examples, effectively increasing the size and diversity of the training dataset. Additionally, the models were trained with a class weight option, which helps in handling imbalanced datasets by giving more importance to the underrepresented class during training.\n\nThe classification performance was evaluated using multiple metrics, including the distribution of features in the fully connected layer using t-distributed stochastic neighbor embedding (tSNE), receiver operating characteristic (ROC) curves, and classification accuracies. Both models achieved adequate classification performance with ROC-area under curve (AUC) values greater than 0.77 and accuracies greater than 75%. These metrics provide a comprehensive evaluation of the models' performance, ensuring that they generalize well to unseen data and are not merely memorizing the training samples.\n\nRegarding underfitting, the models were trained for a sufficient number of epochs (20\u2013100) with stochastic gradient descent as the solver and a learning rate of 0.001. The use of a pretrained model and data augmentation helps in capturing complex patterns in the data, reducing the risk of underfitting. The models' performance on the validation set further confirms that they are not too simplistic to capture the underlying patterns in the data.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models employed in this study are not entirely black-box systems. To enhance interpretability, we utilized explainable AI (X-AI) techniques, specifically Gradient-weighted Class Activation Mapping (Grad-CAM) and guided Grad-CAM. These methods allowed us to visualize the regions in the fruit images that were most relevant to the prediction of rapid softening. By applying these techniques, we could identify specific areas on the fruit surface that contributed significantly to the model's predictions. For instance, the relevance was often located in regions with color unevenness or around the apex and peripheral regions of the fruit. This visualization not only helps in understanding which parts of the fruit the model focuses on but also provides insights into potential premonitory symptoms of rapid softening. The integration of these X-AI techniques with transcriptomic analyses further aids in interpreting the physiological mechanisms underlying the predicted outcomes, making the model more transparent and interpretable.",
  "model/output": "The model employed in this study is a classification model. Specifically, it is a convolutional neural network (CNN) based on the VGG16 architecture, which was trained to classify persimmon fruits into two categories: rapid softening (positive) and control (negative). The model's performance was evaluated using metrics such as the area under the receiver operating characteristic curve (ROC-AUC) and classification accuracy. Two independent models, referred to as model A and model B, were trained using different datasets to ensure robustness and to capture a variety of features relevant to the prediction of rapid softening in persimmon fruits. The models achieved adequate classification performance, with ROC-AUC values greater than 0.77 and accuracies exceeding 75%. The confidence distributions of the two models were not strongly correlated, suggesting that they utilize different feature characteristics for classification. This diversity in feature utilization was leveraged to improve prediction performance, particularly for positive samples, by combining the outputs of both models and applying a higher confidence threshold. The final selected samples for transcriptomic analysis were chosen based on the highest confidence predictions from both models, ensuring a high likelihood of accurate classification.",
  "model/duration": "The execution time for the models was not explicitly detailed in the publication. However, the models were trained using a VGG16 architecture, which is a deep convolutional neural network known for its computational intensity. The training process involved datasets split into training and validation sets in a 3:1 ratio, with images resized to 224 \u00d7 224 pixels. The models were trained for 20 to 100 epochs using stochastic gradient descent as the solver. Given the complexity of the VGG16 model and the number of epochs, it is reasonable to infer that the training process required a significant amount of time, likely spanning several hours to days, depending on the computational resources available. The exact duration would depend on factors such as the hardware specifications, batch size, and any optimizations applied during training.",
  "model/availability": "The source code for the Python scripts used in preprocessing and demultiplexing of sequencing data is publicly available on GitHub. The specific script can be found at the following URL: https://github.com/Comai-Lab/allprep/blob/master/allprep-13.py. This script is part of the allprep toolset developed by the Comai Lab.\n\nRegarding the models and algorithms used for the deep learning predictions, specific details about the release of the trained models or the code to run them are not provided. However, the methods and techniques used, such as the VGG16 architecture and the Grad-CAM and guided Grad-CAM visualization methods, are well-documented in the literature and can be implemented using publicly available frameworks and libraries.\n\nThe data generated from the Illumina transcriptome sequencing have been deposited in the DDBJ database under the BioProject accession number PRJDB15165, with the SRA submission ID number DRA015556 and Run ID numbers DRR438138\u2013DRR438161. This ensures that the raw data used in the study is accessible for further analysis and verification by other researchers.\n\nNot applicable",
  "evaluation/method": "The evaluation of the method involved several steps to ensure the robustness and accuracy of the models. Two independent classification models, referred to as model A and model B, were trained using datasets A and B, respectively. The images in each dataset were randomly split into training and validation sets in a 3:1 ratio. The classification performance was assessed using various metrics, including feature distribution in the fully connected layer visualized through t-distributed stochastic neighbor embedding (tSNE), receiver operating characteristic (ROC) curves, and classification accuracies.\n\nBoth models demonstrated adequate classification performance, with ROC-area under curve (AUC) values exceeding 0.77 and accuracies above 75%. The confidence distributions of the two models were not strongly correlated, suggesting that they utilized different feature characteristics for classification. This divergence indicated that combining the models could potentially enhance prediction performance, particularly for identifying positive samples (rapid-softening fruits).\n\nFor the validation samples in dataset A, which consisted of 361 samples, the combination of models A and B, with a higher confidence threshold than the default (0.5), achieved a maximized accuracy of over 93% and a positive precision exceeding 0.8. This approach highlighted the potential benefits of integrating multiple models to improve prediction accuracy.\n\nAdditionally, the method was evaluated through transcriptomic analyses. A total of 311 persimmon fruits were harvested and analyzed using the trained classification models to predict their likelihood of rapid softening. Ten positive samples with the highest confidence from both models and ten negative samples with sufficiently low confidence were selected for further analysis. These samples were subjected to transcriptomic studies to understand the underlying biological mechanisms associated with rapid softening.\n\nThe relevance of specific regions in the fruits for the prediction of rapid softening was visualized using Grad-CAM and guided Grad-CAM. These techniques helped identify the areas with the highest relevance, which were then sampled for transcriptomic analysis. The distribution of relevance weights was also analyzed, revealing that higher relevance weights were concentrated around the apex or in the peripheral regions of the fruit. This information was crucial for selecting the appropriate regions for sampling and subsequent transcriptomic interpretation.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our deep learning models in predicting rapid softening in persimmon fruits. The primary metrics reported include the area under the receiver operating characteristic curve (ROC-AUC) and classification accuracy. Both models achieved ROC-AUC values greater than 0.77, indicating a strong ability to distinguish between positive and negative samples. Additionally, both models demonstrated classification accuracies exceeding 75%, which is a robust indicator of their predictive performance.\n\nWe also examined the precision values for positive and negative classifications. Precision is particularly important in this context because it measures the proportion of true positive predictions among all positive predictions made by the model. Model A exhibited a positive precision of 0.47, while model B had a lower positive precision of 0.25. However, both models showed high negative precision values, with model A at 0.89 and model B at 0.97. This suggests that while the models are highly reliable in identifying non-rapid-softening fruits, they are less precise in identifying rapid-softening fruits.\n\nFurthermore, we analyzed the confidence distributions of the models' predictions. The confidence values for predicting rapid softening (positive) and control (negative) were evaluated, with values close to 1 strongly supporting rapid softening and values close to 0 supporting control. The combination of models A and B, with a higher confidence threshold than the default (0.5), maximized accuracy to over 93% and positive precision to over 0.8. This approach highlights the potential for improved prediction performance by integrating multiple models and adjusting confidence thresholds.\n\nThe set of metrics used in this study is representative of standard practices in the literature for evaluating classification models, particularly in the context of agricultural and biological research. The use of ROC-AUC, accuracy, and precision provides a comprehensive assessment of model performance, covering both the overall discriminative ability and the reliability of positive predictions. This approach ensures that our findings are comparable to other studies in the field and provides a clear understanding of the models' strengths and limitations.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, our focus was on developing and evaluating two independent classification models, referred to as model A and model B, using datasets A and B respectively. These models were trained using a VGG16 architecture, a well-established convolutional neural network (CNN) model, which was pre-trained with the ImageNet dataset. The primary goal was to assess the performance of these models in predicting rapid softening in persimmon fruits.\n\nThe evaluation of our models involved several key steps. First, we examined the feature distribution in the fully connected layer using t-distributed stochastic neighbor embedding (tSNE). This technique helped us visualize how well the models could distinguish between positive (rapid softening) and negative (control) samples. Additionally, we used receiver operating characteristic (ROC) curves to evaluate the classification performance, achieving ROC-area under curve (AUC) values greater than 0.77 and accuracies greater than 75% for both models. These metrics indicated that our models performed adequately in classifying the samples.\n\nFurthermore, we compared the confidence distributions of the two models, finding that they were not appreciably correlated. This suggested that the models utilized slightly different feature characteristics for classification, which could potentially be combined to achieve higher prediction performance for positive samples. We also evaluated the precision values for positive and negative classifications, noting that model B exhibited substantially lower precision for positive classification compared to model A.\n\nIn summary, while we did not compare our methods directly with other publicly available techniques on benchmark datasets, our evaluation involved a comprehensive assessment of model performance using various metrics and visualization techniques. This approach allowed us to understand the strengths and limitations of our models in predicting rapid softening in persimmon fruits.",
  "evaluation/confidence": "The evaluation of the models' performance included several metrics, but confidence intervals for these metrics were not explicitly provided. The models were assessed using ROC-AUC values and classification accuracies, with both models achieving ROC-AUC values greater than 0.77 and accuracies above 75%. These metrics suggest adequate classification performance.\n\nStatistical significance was not directly discussed in the context of comparing the models to baselines or other methods. However, the combination of models A and B, with a higher confidence threshold, maximized accuracy to over 93% and positive precision to over 0.8. This indicates that the combined approach might be superior in certain aspects, but without explicit statistical tests, it is challenging to claim definitive superiority.\n\nThe confidence distributions of the two models were not appreciably correlated, suggesting that they utilize different feature characteristics for classification. This diversity could contribute to the improved performance when the models are combined. The selection of test samples for transcriptomic analysis was based on the highest confidence predictions from both models, which might imply a level of confidence in the models' predictions, although this is not explicitly quantified with statistical significance.",
  "evaluation/availability": "All Illumina transcriptome sequencing data have been deposited in the DDBJ database: Short Read Archives (SRA) database. The BioProject accession number is PRJDB15165, and the SRA submission ID number is DRA015556. The Run ID numbers range from DRR438138 to DRR438161. These datasets are publicly available, allowing researchers to access and utilize the raw evaluation files for further analysis or validation of the findings presented in the study. The data can be accessed through the provided accession numbers and IDs, ensuring transparency and reproducibility in the research process."
}