{
  "publication/title": "Nuclear grooves and artificial intelligence",
  "publication/authors": "The authors who contributed to this article are:\n\nPedro R. F. Rende, who contributed to conceptualization, data curation, formal analysis, investigation, and methodology.\n\nJoel Machado Pires, who contributed to data curation, formal analysis, investigation, and methodology.\n\nK\u00e1tia Sakimi Nakadaira, who contributed to data curation and investigation.\n\nSara Lopes, who contributed to data curation and investigation.\n\nJo\u00e3o Vale, who contributed to methodology.\n\nFabio Hecht, who contributed to methodology.\n\nFabyan E. L. Beltr\u00e3o, who contributed to methodology.\n\nGabriel J. R. Machado, who contributed to methodology.\n\nEdna T. Kimura, who contributed to methodology.\n\nCatarina Eloy, who contributed to methodology.\n\nHelton E. Ramos, who contributed to conceptualization, formal analysis, investigation, and methodology.",
  "publication/journal": "Journal of Pathology and Translational Medicine",
  "publication/year": "2024",
  "publication/pmid": "38684222",
  "publication/pmcid": "PMC11106606",
  "publication/doi": "https://doi.org/10.4132/jptm.2024.03.07",
  "publication/tags": "- Thyroid gland\n- Cytology\n- Fine-needle aspiration\n- Artificial intelligence\n- Machine learning\n- Nuclear grooves\n- Object detection\n- Deep learning\n- Computational pathology\n- Digital pathology\n- Transfer learning\n- YOLOv5\n- Cytological research\n- Pathology\n- Medical imaging",
  "dataset/provenance": "The dataset utilized in this study was derived from whole slide images (WSIs) of thyroid cytopathology samples. A total of 7,255 images were obtained from 22 WSIs. These images were meticulously annotated by an experienced pathologist, resulting in 7,242 annotated nuclear grooves. The annotations were performed using the LabelImg tool, with nuclear grooves defined as elongated structures that cross the largest part of the cell and exhibit distinct coloration compared to the rest of the nucleus.\n\nThe dataset was augmented using techniques such as zooming, rotations, and random mirroring to artificially increase the amount of data. This augmentation was crucial for improving the performance of the neural network and avoiding overfitting. The augmented dataset was then divided into training and validation groups in a 7:3 ratio, ensuring that the validation group did not contain any images previously encountered during training. This division was essential for fine-tuning the pretrained model and assessing its performance accurately.\n\nThe images were annotated and exported in YOLO format, with a script written to remove any invalid annotations, such as repeated or incorrectly labeled boxes. This process ensured the quality and consistency of the dataset, which is vital for the successful training and validation of the model. The dataset was not publicly available due to proprietary and privacy considerations, but it can be made available from the corresponding author upon reasonable request.",
  "dataset/splits": "The dataset was divided into two main splits: the training group and the validation group. The distribution of data points between these groups followed a 7:3 ratio. This means that 70% of the images were allocated to the training group, while the remaining 30% were designated for the validation group. This split was implemented to ensure that the model could be effectively trained and subsequently evaluated for its performance. The training group was used for fine-tuning the pretrained model, while the validation group was employed to assess the model's performance and select the version that achieved the best results. No other splits were created beyond these two primary groups.",
  "dataset/redundancy": "The dataset used in this study consisted of 7,242 annotated nuclear grooves. To enhance the database provided to the model, data augmentation techniques such as zooming, rotations, and random mirroring were applied. This process was crucial for improving the model's performance and generalization capacity, as it helped avoid overfitting by artificially increasing the amount of data.\n\nThe augmented dataset was then randomly divided into training and validation groups in a 7:3 ratio. This means that 70% of the images were allocated to the training group, while the remaining 30% were used for validation. It is important to note that images of grooves encountered during training were not present in the validation data, ensuring the independence of the training and test sets. This separation was enforced to prevent the model from memorizing specific instances and to evaluate its performance on unseen data accurately.\n\nThe distribution of the dataset in this study differs from some previously published machine learning datasets, which often rely on larger and more diverse datasets. The relatively small size of our database may have influenced the obtained results, potentially diminishing the model's generalization capacity. However, the use of data augmentation techniques helped mitigate this limitation to some extent.\n\nIn summary, the dataset was split into independent training and validation sets, with measures taken to ensure that the validation data did not contain any images seen during training. This approach aligns with best practices in machine learning to evaluate the model's performance on unseen data accurately.",
  "dataset/availability": "The datasets generated or analyzed during the study are not publicly available. This decision is due to the proprietary nature of the data and the privacy considerations inherent in cytological research. However, the datasets are available from the corresponding author upon reasonable request. This approach ensures that the data remains secure and confidential while still allowing for potential collaboration and verification of the study's findings.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Convolutional Neural Networks (CNNs), specifically the YOLOv5 architecture. This is a well-established class of algorithms known for their effectiveness in object detection tasks.\n\nThe algorithm employed is not new; it is a state-of-the-art real-time object detection model. YOLOv5 is widely recognized for its performance in object detection datasets such as Pascal VOC and MS COCO. The choice to use YOLOv5 was driven by its proven efficiency and accuracy in detecting objects in images, which aligns with our objective of identifying nuclear grooves in digitized slides.\n\nGiven that YOLOv5 is a pre-existing and widely used model, it was not necessary to publish it in a machine-learning journal. Instead, we focused on applying and fine-tuning this model for our specific use case in thyroidology. The model was fine-tuned using transfer learning, where a pre-trained model was repurposed and adjusted with our dataset of nuclear grooves. This approach allowed us to leverage the existing strengths of YOLOv5 while tailoring it to our particular research needs.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. It relies on a single machine learning approach, specifically transfer learning using the YOLOv5s architecture. This model is fine-tuned with a dataset of annotated nuclear groove images, rather than integrating outputs from multiple machine-learning algorithms.\n\nThe YOLOv5s model is a state-of-the-art real-time object detection system that operates as a single-stage object detector. It was initially trained on datasets unrelated to the current objective, such as Pascal VOC and MS COCO, and is repurposed for detecting nuclear grooves in thyroid images. The training process involves using data augmentation techniques like zooming, rotations, and random mirroring to enhance the model's performance and generalization capacity.\n\nThe dataset used for training and validation was meticulously annotated by an experienced pathologist, ensuring high-quality ground truth data. The images were divided into training and validation groups in a 7:3 proportion, with no overlap between the groups to maintain independence. This division helps in fine-tuning the pretrained model and assessing its performance accurately.\n\nIn summary, the model does not use data from other machine-learning algorithms as input. It is a standalone object detection model based on the YOLOv5s architecture, trained and validated on a dedicated dataset of nuclear groove images. The training data is independent, with clear separation between the training and validation groups.",
  "optimization/encoding": "The data encoding process involved annotating nuclear grooves using the LabelImg tool with a standard mouse input method. An experienced pathologist with over two decades of expertise defined a nuclear groove as an elongated, non-linear structure that crosses the largest part of the cell and differs in color from the rest of the nucleus. These annotations were grouped into a single class labeled \"GROOVE.\" A total of 7,242 nuclear grooves were annotated and exported as text files in YOLO format.\n\nTo ensure data quality, a script was employed to remove invalid annotations, such as repeated or empty bounding boxes and incorrect labels. Data augmentation techniques, including zooming, rotations, and random mirroring, were applied to artificially increase the dataset size. These techniques were chosen to help the model identify grooves regardless of their orientation or position, thereby improving the neural network's performance and generalization capacity.\n\nThe augmented dataset was then divided into training and validation groups in a 7:3 ratio. The training group, comprising 70% of the images, was used for fine-tuning a pretrained YOLOv5s model. The validation group, with the remaining 30%, was used to assess the model's performance and select the best-performing version. No additional image preprocessing methods were applied to avoid introducing bias into the model. The YOLOv5s model, known for its real-time object detection capabilities, was chosen for its proven performance on datasets like Pascal VOC and MS COCO. During training, YOLOv5s utilizes the mosaic data augmentation technique, which combines four training images to enhance the network's accuracy. The model's architecture includes a backbone for feature extraction, a neck for combining features from different network levels, and a head for predicting bounding boxes and object classes.",
  "optimization/parameters": "The model utilized in this study is based on the YOLOv5 architecture, which is a convolutional neural network (CNN) designed for object detection tasks. The specific number of parameters (p) in the model can vary depending on the configuration and the specific version of YOLOv5 used. However, YOLOv5 models typically have a large number of parameters due to their deep architecture, which includes multiple convolutional layers, batch normalization layers, and fully connected layers.\n\nThe selection of the model architecture and its parameters was guided by the need to balance computational efficiency and detection accuracy. YOLOv5 is known for its real-time processing capabilities, making it suitable for applications that require quick and accurate object detection. The choice of YOLOv5 was also influenced by its proven performance in similar tasks and its flexibility in handling various object detection challenges.\n\nIn this particular study, the model was trained using a dataset of annotated images of nuclear grooves. The dataset was augmented to increase its size and diversity, which helped in improving the model's generalization capabilities. The training process involved 50 epochs, during which the model's weights were adjusted iteratively to minimize the loss functions. The model's performance was evaluated using metrics such as mean average precision (mAP), recall, and precision, which provided insights into its detection accuracy and reliability.\n\nThe best model was identified at the 14th epoch, achieving a true positive rate of 67%, a mAP of 45.5%, a recall of 49.8%, and a precision of 43.1%. These results indicate that the model was able to effectively learn the defining characteristics of nuclear grooves, demonstrating its potential for use in cytopathological diagnosis. However, it is important to note that the model's performance may be influenced by factors such as the quality and representativeness of the training data, as well as the specific staining methods used in the cytology slides.",
  "optimization/features": "The input features for our model are derived from digitalized images of thyroid nodules, specifically focusing on the detection of nuclear grooves. The primary feature used is the image data itself, which is processed to identify and annotate nuclear grooves. These grooves are defined as elongated structures within the nucleus, characterized by their unique appearance and orientation.\n\nThe model utilizes a single class for these features, labeled as \"GROOVE.\" This class encompasses all the annotated nuclear grooves, which were meticulously identified by an experienced pathologist. The annotations were performed using the LabelImg tool, ensuring precision and consistency in the labeling process.\n\nFeature selection, in the traditional sense, was not performed as the model relies on the entire image data for training. Instead, data augmentation techniques were employed to enhance the diversity and robustness of the input features. These techniques included zooming, rotations, and random mirroring, which helped the model to recognize nuclear grooves regardless of their orientation or position within the image.\n\nThe images were divided into training and validation sets in a 7:3 ratio, ensuring that the model was trained on a comprehensive dataset while also being validated on unseen data. This approach helped in fine-tuning the model and assessing its performance accurately. The training set was used exclusively for adjusting the model weights, while the validation set was used to evaluate the model's generalization capability.\n\nIn summary, the model uses image data as the primary input feature, focusing on the detection of nuclear grooves. Data augmentation techniques were used to enhance the input features, and the dataset was split into training and validation sets to ensure robust model training and evaluation.",
  "optimization/fitting": "The fitting method employed in this study utilized a deep learning model based on the YOLOv5 architecture, which is known for its extensive parameter set. The number of parameters in such models is indeed much larger than the number of training points, a common scenario in deep learning applications.\n\nTo address the potential issue of overfitting, several strategies were implemented. Firstly, the dataset was augmented to increase the diversity of training examples, which helps the model generalize better to unseen data. Secondly, the training process was monitored closely using a validation set, which was not used during training. The performance metrics on the validation set, such as loss functions, recall, and precision, were tracked over 50 epochs. Notably, after the 14th epoch, an increase in loss functions and fluctuations in recall and accuracy values indicated the onset of overfitting. This observation was crucial in identifying the optimal epoch (14th) where the model's performance was best balanced between training and validation data.\n\nTo mitigate underfitting, the model was trained for a sufficient number of epochs (50 in total), allowing it to learn the underlying patterns in the data. The gradual decrease in loss functions during the training phase indicated that the model was effectively learning from the training data. Additionally, the use of data augmentation techniques ensured that the model was exposed to a variety of examples, reducing the risk of underfitting.\n\nIn summary, the fitting method involved careful monitoring of the model's performance on both training and validation sets, along with the use of data augmentation to enhance generalization. These measures helped in balancing the trade-off between overfitting and underfitting, ensuring that the model achieved a commendable true positive rate and other performance metrics.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and enhance the model's generalization capabilities. One of the primary methods used was data augmentation. This technique involved creating new versions of the existing images through processes such as zooming, rotations, and random mirroring. By artificially increasing the diversity of the training dataset, data augmentation helped the model to learn more robust features and reduced the risk of overfitting to specific patterns in the training data.\n\nAdditionally, we utilized a validation group that was separate from the training group. The images in the validation group were not seen by the model during the training phase, allowing us to assess the model's performance on unseen data. This approach helped in monitoring the model's ability to generalize and in identifying the onset of overfitting.\n\nWe also observed the model's performance metrics over 50 epochs. While the training group showed consistent improvement in metrics such as box loss and object loss, the validation group exhibited an increase in loss functions after the 14th epoch. This indicated the beginning of overfitting, where the model started to perform better on the training data but worse on the validation data. By closely monitoring these metrics, we could make informed decisions about when to stop training to prevent overfitting.\n\nFurthermore, the use of transfer learning with a pretrained YOLOv5s model provided a strong foundation for our detector. This approach leveraged the features learned from a large, unrelated dataset, which helped in improving the model's performance and reducing the likelihood of overfitting to our specific dataset.\n\nIn summary, data augmentation, the use of a separate validation group, and transfer learning were key techniques employed to prevent overfitting and ensure the model's robustness and generalization capabilities.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we utilized 50 epochs for training and validation, with a 7:3 ratio split between the training and validation groups. The initial box loss started at 10.2% and decreased to 2.3% by the 49th epoch, while the object loss declined from 3% to 1.3% over the same period. For the validation group, improvements were observed until the 14th epoch, after which there was a gradual increase in loss values, indicating overfitting.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the methodology and results are thoroughly described, allowing for replication of the experimental setup. The study focuses on the detection of nuclear grooves using a CNN based on the YOLOv5 architecture, and the metrics such as mean average precision (mAP), recall, and precision are reported in detail.\n\nRegarding the availability and licensing of the data and models, specific details on where to access the model files or the exact licensing terms are not provided. The emphasis is on the methodology and the outcomes, which are intended to contribute to the broader field of digital pathology and AI-driven diagnostic tools. For further details on accessing the model or data, readers are encouraged to contact the authors directly.",
  "model/interpretability": "The model developed in this study is not a black box but rather a transparent system, particularly in the context of object detection applied to nuclear structures in thyroid cytopathology. The transparency of the model is evident through several key aspects.\n\nFirstly, the model's architecture and training process are well-documented. The use of convolutional neural networks (CNNs) and deep learning techniques allows for a clear understanding of how the model processes input images to detect nuclear grooves. The training involved 50 epochs, during which the model's weights were adjusted based on the input images. This iterative process is crucial for understanding how the model learns to identify the relevant features in the images.\n\nSecondly, the model's performance metrics provide insights into its decision-making process. Metrics such as recall, precision, and mean average precision (mAP) at different thresholds (0.5 and 0.5:0.95) offer a quantitative measure of the model's accuracy and reliability. For instance, the recall indicates how well the model correctly predicts the true bounding boxes of nuclear grooves, while precision measures the accuracy of the positive predictions. These metrics help in interpreting the model's performance and understanding its strengths and weaknesses.\n\nAdditionally, the use of data augmentation techniques enhances the model's transparency by ensuring that it is trained on a diverse set of images. This process helps in generalizing the model's performance across different types of nuclear structures, making it more robust and interpretable.\n\nFurthermore, the model's ability to identify nuclear grooves is visually demonstrated through annotated images. The comparison between the true bounding boxes (manually annotated) and the predicted bounding boxes (generated by the model) provides a clear visual representation of the model's performance. This visual evidence is crucial for interpreting the model's outputs and understanding its decision-making process.\n\nIn summary, the model's transparency is achieved through a combination of well-documented training processes, quantitative performance metrics, data augmentation techniques, and visual evidence. These elements collectively ensure that the model is not a black box but a transparent system that can be interpreted and understood by researchers and clinicians.",
  "model/output": "The model developed is an object detection model, specifically designed for identifying nuclear grooves in digitized slides stained with Diff-Quik. It is based on the YOLOv5 architecture, which is a convolutional neural network (CNN) tailored for real-time object detection. This type of model is primarily used for classification tasks, where it predicts the presence and location of objects within an image.\n\nThe model's output includes bounding boxes around detected objects, along with the confidence scores indicating the likelihood of the detected object being a nuclear groove. Given that the model focuses on detecting and classifying a specific feature (nuclear grooves) within images, it falls under the classification category rather than regression. The evaluation metrics used, such as mean average precision (mAP), precision, and recall, further support that the model's primary goal is to classify and locate objects accurately.\n\nDuring training, the model was evaluated using loss functions that measure the error in detecting objects and the accuracy of the predicted bounding boxes. The object loss indicates the error in detecting if an object exists in a suggested region, while the box loss measures the error between the predicted and true bounding boxes. These metrics are crucial for assessing the model's performance in classifying and locating nuclear grooves.\n\nThe model's performance was assessed over 50 epochs, with improvements observed in both training and validation groups initially. However, signs of overfitting were noted after the 14th epoch, as indicated by the increasing loss functions in the validation group and fluctuating recall and precision values. Despite these challenges, the model demonstrated a commendable true positive rate and mean average precision, suggesting its potential for detecting nuclear structures in digitized slides.\n\nIn summary, the model is a classification-based object detection system designed to identify and locate nuclear grooves in images. It utilizes YOLOv5 architecture and is evaluated using metrics that assess its ability to classify and accurately bound detected objects.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the model is not publicly available. The datasets generated or analyzed during the study are not publicly available due to the proprietary nature of the data and privacy considerations inherent in cytological research. However, the datasets are available from the corresponding author on reasonable request.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive assessment of the model's performance using several key metrics and techniques. The dataset, which consisted of annotated nuclear grooves, was divided into training and validation groups in a 7:3 ratio. This division ensured that the model was trained on a substantial portion of the data while reserving a separate set for validation purposes.\n\nDuring the training process, the model underwent 50 epochs, allowing it to iteratively improve its performance. The training group demonstrated consistent improvement in both box loss and object loss, indicating that the model became more accurate in predicting the location and existence of nuclear grooves over time. Specifically, the box loss decreased from 10.2% to 2.3%, and the object loss declined from 3% to 1.3% by the 49th epoch.\n\nHowever, the validation group showed a different trend. Initially, there was an improvement in the loss functions until the 14th epoch, after which the values began to increase, particularly the object loss. This increase suggested the onset of overfitting, where the model became too specialized in the training data and struggled to generalize to new, unseen data. The validation box loss and object loss fluctuated, with the box loss settling at 3.5% and the object loss at 2.7% by the 49th epoch.\n\nIn addition to loss functions, other metrics such as recall (sensitivity), precision (positive predictive value), and mean average precision (mAP) were evaluated. Recall values exhibited an initial decrease, followed by an increase between epochs 13 and 21, peaking at around 50.8%. Precision showed a slight increase up to epoch 18, with values ranging from 40.6% to 45.9%, before declining. The mAP at the 0.5 threshold increased from 7.5% to 39.3% by epoch 7 and reached its highest values between epochs 8 and 18, with a peak of 45.6% at epoch 14.\n\nThe model's performance was further substantiated by its ability to develop a rule governing true bounding boxes, achieving a true positive rate of 67%. Despite some limitations, the model demonstrated a partial ability to locate and scale the object under study, with a mAP of 45.5%, sensitivity of 49.8%, and positive predictive value of 43.1%.\n\nOverall, the evaluation method involved a rigorous assessment of the model's performance using a combination of loss functions and key metrics, providing a comprehensive understanding of its strengths and areas for improvement.",
  "evaluation/measure": "In the evaluation of our model, several key performance metrics were reported to provide a comprehensive assessment of its effectiveness. These metrics include:\n\n* **Box Loss**: This metric measures the error between the location and size of the predicted bounding box and the true bounding box. It was tracked for both the training and validation groups, providing insights into the model's ability to accurately localize objects.\n\n* **Object Loss**: This metric evaluates the error in detecting if an object exists in the suggested region. Similar to box loss, it was monitored for both training and validation to assess the model's object detection capabilities.\n\n* **Recall (Sensitivity)**: Recall is the ratio of true positives to the sum of true positives and false negatives. It indicates how well the model identifies actual positive instances, which is crucial for ensuring that true bounding boxes are correctly predicted.\n\n* **Precision (Positive Predictive Value)**: Precision is the ratio of true positives to the total number of positives (true positives and false positives). It measures the accuracy of the predicted bounding boxes, showing the proportion of positive identifications among positive predictions.\n\n* **Mean Average Precision (mAP)**: This metric is calculated as the weighted mean of precisions at each threshold and represents the area under the precision-recall curve. We reported mAP at two thresholds: mAP_0.5, which considers a 50% overlap (Intersection over Union, IoU), and mAP_0.5:0.95, which averages the mAP across thresholds from 0.5 to 0.95. These metrics provide a comprehensive evaluation of the model's performance across different levels of overlap.\n\nThe set of metrics reported is representative of standard practices in the literature for evaluating object detection models. These metrics collectively offer a thorough assessment of the model's performance, covering aspects such as localization accuracy, object detection reliability, and overall detection quality. By tracking these metrics throughout the training and validation processes, we ensured a robust evaluation of the model's effectiveness in detecting nuclear grooves, which is a critical task in the context of thyroid cytopathology.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. The focus of our research was on evaluating the potential of an object detection model based on the YOLOv5 architecture for identifying nuclear grooves in digitalized slides stained with Diff-Quik. This approach is unique in its specific objective and the type of staining used, which sets it apart from other studies that might use different staining methods or have different primary goals.\n\nInstead of comparing with other publicly available methods, we concentrated on demonstrating the feasibility and limitations of our model. We highlighted the model's ability to develop a rule for true bounding boxes, indicating its capacity to extract defining characteristics of nuclear grooves. This resulted in a true positive rate of 67%, a mean average precision (mAP) of 45.5%, sensitivity of 49.8%, and a positive predictive value of 43.1%.\n\nRegarding simpler baselines, our approach involved using data augmentation techniques to increase the database provided to the model. The database was randomly divided into training and validation groups in a 7:3 ratio. The model was trained for 50 epochs, and we observed improvements in both box loss and object loss throughout the training period. However, we noted signs of overfitting after the 14th epoch, as indicated by the increase in loss functions and fluctuating recall and precision values in the validation group.\n\nWhile we did not compare our method directly with simpler baselines or publicly available methods, our results suggest that the AI-based approach has potential. The model's performance metrics, despite the limitations, indicate that it can partially locate and scale the object under study. This paves the way for further refinement and exploration in future research endeavors.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The datasets generated or analyzed during the study are not publicly available due to the proprietary nature of the data and privacy considerations inherent in cytological research. However, they are available from the corresponding author upon reasonable request. This approach ensures that the sensitive nature of the data is protected while still allowing for potential collaboration and verification of the results."
}