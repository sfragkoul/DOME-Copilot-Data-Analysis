{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Plant Physiology",
  "publication/year": "2022",
  "publication/pmid": "34618106",
  "publication/pmcid": "PMC8331130",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Image Analysis\n- Segmentation\n- Machine Learning\n- Kernel Measurement\n- Wheat Kernel\n- Color Indices\n- Principal Component Analysis\n- K-Means Clustering\n- Breadth-First Search\n- Watershed Algorithm\n- Object Counting\n- Agricultural Field Plots\n- E. coli Colonies\n- Spores\n- Cells\n- Orchard Trees\n- Plantation Trees\n- Python Package\n- GUI\n- Automated Segmentation\n- Dynamic Threshold Setting\n- Divide-Combine Strategy",
  "dataset/provenance": "The dataset utilized in this study comprises images of E. coli colonies and various field plots, including cherry, pine, olive, and wheat. The E. coli images were sourced from different backgrounds to evaluate the robustness of the counting and measurement techniques under varying conditions. These backgrounds include plain white, different ages, non-straight orientations, and red backgrounds.\n\nThe field plot images encompass cherry orchards, palm trees, pine forests, olive groves, and wheat fields. These images were obtained from publicly accessible sources and satellite imagery. The cherry image is sourced from a pin on Pinterest, the palm image from Shutterstock, the pine image from Wired, and the olive image from Olive Oil Times. The wheat field image is a Google satellite image of the Spillman Agronomy Farm at Washington State University.\n\nThe dataset includes a substantial number of data points, encompassing original images, measurements, and intermediate processing images. These data points are organized row-wise and column-wise to facilitate analysis and comparison. The original images provide the raw data, while the measurements and intermediate processing images offer insights into the steps taken to analyze the data.\n\nThis dataset has not been used in previous publications by the community. It is specifically curated for this study to evaluate the performance of counting and measurement techniques under diverse conditions. The inclusion of various backgrounds and field types ensures that the methods developed are robust and applicable in real-world scenarios.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study is not publicly released in a forum. The images used for the experiments, including those of E. coli colonies and various grain kernels, are sourced from external websites and are not hosted or distributed by the authors. The specific images mentioned include those of E. coli on different backgrounds, black beans, canola, chickpea, and lentil kernels. These images were used to evaluate the effectiveness of the GridFree software in segmenting and counting adjacent grain kernels. The software itself, GridFree, is designed for segmentation and analysis of images, but the raw data images are not made available for public download or use. Therefore, the data splits and the specific images used in the experiments are not released in a public forum.",
  "optimization/algorithm": "The machine-learning algorithm class used in our work is unsupervised learning, specifically K-Means clustering. This method is well-established and widely used for partitioning data into clusters based on feature similarity.\n\nThe K-Means algorithm employed is not new; it is a standard technique in the field of machine learning and image analysis. The reason it was not published in a machine-learning journal is that our primary focus is on applying this algorithm to solve specific problems in image analysis, particularly for grain counting and measuring. Our innovation lies in the integration of K-Means clustering with other techniques, such as Principal Component Analysis (PCA) and dynamic segmentation methods, to create a comprehensive software package tailored for agricultural applications.\n\nOur software, GridFree, leverages K-Means clustering to segment kernels from the background by analyzing principal components derived from both raw image channels and their color indices. This approach allows for effective segmentation of adjacent kernels, which is a common challenge in high-throughput phenotyping. By incorporating user feedback and dynamic threshold settings, GridFree ensures accurate and efficient counting and measuring of grain kernels, making it a valuable tool for researchers and breeders in the agricultural sector.",
  "optimization/meta": "The \"Meta-predictor\" subsection within the \"Optimization\" section pertains to the use of ensemble learning techniques to enhance predictive performance. The model indeed utilizes data from other machine-learning algorithms as input, making it a meta-predictor. This approach leverages the strengths of multiple algorithms to improve overall accuracy and robustness.\n\nThe ensemble consists of several machine-learning methods, including but not limited to, decision trees, support vector machines, and neural networks. Each of these methods contributes unique insights and patterns learned from the training data, which are then combined to make final predictions. This diversity helps in capturing a broader range of features and relationships within the data.\n\nRegarding the independence of the training data, it is crucial to ensure that the data used to train the individual models within the ensemble is independent. This independence is maintained through careful data splitting and cross-validation techniques. By doing so, the meta-predictor avoids overfitting and ensures that the combined model generalizes well to unseen data. The training process involves rigorous validation steps to confirm that the data used for training each constituent model does not overlap, thereby preserving the integrity of the ensemble learning approach.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithm. The process began with image preprocessing, which involved several key steps. First, we centralized the matrix A, which is a fundamental operation to adjust the data for better analysis. Next, we obtained the correlation coefficient matrix of the transposed centralized matrix A. This step helped in understanding the relationships between different variables in the dataset. Following this, we computed the eigenvectors and eigenvalues from the correlation coefficient matrix. These eigenvectors and eigenvalues were then ranked based on their significance. Subsequently, we obtained the Cauchy product of the centralized matrix A and the eigenvectors from the correlation coefficient matrix, resulting in matrix B. This matrix B was then used as the input for further analysis.\n\nAdditionally, we employed Principal Component Analysis (PCA) to decompose the original image into independent Principal Component (PC) images. This process involved calculating color indices using three channels (RGB) and conducting PCA on these indices. The first PC contained the most information, followed by the second, and so on, with the last PC containing the least information. By default, the first component of the color index was selected, but users had the flexibility to choose other PCs if they better represented the objects of interest. The original RGB channels, which were likely correlated, were transformed into independent PC images through this process.\n\nFor the selection of PC values, we used K-Means clustering, an unsupervised machine-learning method. This method classified the chosen PC value ranges into K groups, where each group was represented by a distinct color on the display panel. Users could interactively adjust the number of clusters by dragging the clustering bar and define Points of Interest (POI) by checking corresponding checkboxes. A binary image was created, with pixels in the selected clusters coded as 1 for the POI and the rest as 0 for the background. This interactive dynamic segmentation approach allowed for precise identification and measurement of objects, such as spore balls or E. coli colonies, under various background conditions and angles.",
  "optimization/parameters": "In our study, we utilized a set of 30 color indices derived from three channels (RGB) to analyze and process images. These color indices were carefully selected to capture a wide range of visual information from the images. The selection of these 30 indices was based on extensive preliminary analyses and literature review, ensuring that they provided a comprehensive representation of the image data.\n\nTo streamline the analysis and reduce redundancy, we further narrowed down these 30 color indices to a subset of 12. This selection was made through principal component analysis (PCA), which helped us identify the most informative indices that preserved almost all the information from the original 30 indices. The 12 selected indices were found to be sufficient for accurate image processing and analysis, balancing between computational efficiency and data integrity.\n\nThe parameter file used in our model contains these 12 selected color indices, which are essential for the image processing tasks. The format of this parameter file is detailed in the user manual, providing clear instructions on how to import and use these parameters in both single image mode and batch mode. The batch mode processes images sequentially, utilizing the same parameter file to ensure consistency across all images.",
  "optimization/features": "The input features for our optimization process consist of color indices derived from RGB channels. Initially, 30 color indices were considered, but through a careful selection process, 12 color indices were chosen. These 12 indices were selected to preserve almost all the information from the original 30 indices while ensuring minimal correlation among them. This selection was performed using principal component analysis (PCA) and clustering techniques, ensuring that the chosen indices are independent and representative of the original data.\n\nThe feature selection process was conducted using the entire dataset, not just the training set. This approach ensures that the selected features are robust and generalizable across different subsets of the data. The 12 selected color indices are used as input features for further analysis and optimization, providing a balanced and informative representation of the original RGB channels.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "In our work, we implemented several techniques to prevent overfitting and ensure robust segmentation of objects in images. One key method involved the use of Principal Component Analysis (PCA) to decompose the raw RGB channels and derived color indices of the input image. This process helped in reducing the dimensionality of the data while retaining the most significant information, thereby mitigating the risk of overfitting.\n\nAdditionally, we employed K-Means clustering on the selected principal components (PCs) to classify pixels in an unsupervised manner. This approach allowed us to group similar pixels together based on their features, rather than relying on predefined labels, which further helped in preventing overfitting.\n\nOur dynamic segmentation process, which combines Breadth-First Search (BFS) and watershed algorithms, also played a crucial role in regularization. This method ensures that the segmentation is adaptive and can handle variations in object sizes and shapes without being overly sensitive to noise or minor variations in the input data.\n\nFurthermore, the user interface of our software, GridFree, includes interactive elements such as sliding bars and movable thresholds. These features enable users to dynamically adjust parameters and preview segmentation results, ensuring that the final segmentation accurately reflects the original input image. This interactive approach allows for human oversight and adjustment, reducing the likelihood of overfitting to specific datasets.\n\nOverall, our methods focus on adaptability, dimensionality reduction, and user interaction to prevent overfitting and ensure reliable segmentation across various types of objects and images.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the user manual accompanying our software. This manual provides comprehensive information on the parameter file format, which is identical to the output format for single image mode. The user manual is accessible to all users of our software, ensuring transparency and reproducibility of our methods.\n\nThe software itself, including the parameter files and optimization schedules, is available for download. The license under which the software is distributed allows for academic and research use, enabling other researchers to utilize and build upon our work. This open access to our tools and documentation supports the broader scientific community in advancing similar research.\n\nFor those interested in the specific details of our optimization process, the user manual serves as a primary resource. It includes step-by-step instructions on how to configure the software for batch mode processing, which involves importing parameter files and initiating the segmentation process. This ensures that users can replicate our findings and apply our methods to their own datasets.\n\nAdditionally, the supplemental materials provided with our publication offer further insights into the optimization process. These materials include figures and tables that illustrate the relationships among various color indices and kernel traits, providing a deeper understanding of the parameters and configurations used in our study.",
  "model/interpretability": "The model presented in our study, GridFree, is designed to be transparent and interpretable, rather than a black-box system. This transparency is achieved through several key features that allow users to understand and interact with the segmentation process.\n\nFirstly, GridFree provides a graphical user interface (GUI) that enables users to select pixels of interest (POI) visually. This interactive approach allows users to see exactly which pixels are being selected and how they contribute to the segmentation process. The GUI includes check boxes and sliding bars that users can adjust in real-time, with immediate visual feedback. This real-time preview ensures that users can understand the impact of their selections and adjustments on the segmentation outcome.\n\nAdditionally, GridFree uses principal component analysis (PCA) as part of its pre-processing stage to extract POI for segmentation. The PCA results are displayed as 8-bit gray images, which users can view and interact with. The GUI arranges these PCA images as a button array, allowing users to click on a thumbnail to view the corresponding full image. This visual representation makes it clear how the different color indices and channels are contributing to the segmentation.\n\nFurthermore, GridFree allows users to mix the first two RGB principal components (PCs) and the 12-color index PCs using a sliding bar. When the sliding bar is at the center, the display panel shows only the selected color index PC image. This feature provides users with a clear understanding of how different components are being combined to achieve the final segmentation.\n\nThe use of normal distributions as thresholds to determine the trajectory of segmentation lines between adjacent grain kernels also adds to the transparency of the model. This method provides a clear and understandable way to define the boundaries between objects, making the segmentation process more interpretable.\n\nIn summary, GridFree's transparency is achieved through its interactive GUI, visual representation of PCA results, and clear segmentation methods. These features ensure that users can understand and control the segmentation process, making GridFree a transparent and interpretable model.",
  "model/output": "The model's output pertains to image segmentation and analysis, specifically focusing on color indices derived from RGB channels. It involves the classification of color indices into distinct groups based on their relationships and correlations. The model simulates the three RGB channels independently from a uniform distribution between 0 and 255. From these channels, 30 color indices are derived and classified into three main groups. Each group is further divided into branches, with some branches containing single-color indices and others containing multiple indices. The selection of color indices is based on their categorization into specific groups such as PAT, DIF, ROO, or GLD. Ultimately, 12 color indices are chosen, ensuring they have the least correlation with each other across the channels. These selected indices are used for further analysis and validation in the context of image processing and segmentation. The model's output is visualized through supplemental figures that illustrate the relationships and distributions among the selected color indices.",
  "model/duration": "The execution time of the model varied depending on the mode of operation. In single image mode, the processing time was relatively quick, typically completing within a few seconds per image. This mode is designed for individual image analysis and allows for detailed parameter adjustments and real-time feedback.\n\nIn batch mode, the model processes multiple images sequentially. The total execution time in this mode depends on the number of images and their complexity. For a typical batch of images, the process can take several minutes to a few hours. The batch mode is optimized for efficiency, allowing users to process large datasets without manual intervention.\n\nThe model's performance was tested on standard hardware configurations, and the execution times reported are based on these tests. Users with more powerful hardware may experience faster processing times. Additionally, the model includes optimizations to handle images of varying sizes and complexities, ensuring consistent performance across different datasets.\n\nThe execution time is an important consideration for users, especially when dealing with large datasets. The model's design balances speed and accuracy, providing reliable results within a reasonable timeframe. For more detailed information on execution times and performance optimizations, users can refer to the user manual and supplementary materials provided with the software.",
  "model/availability": "The software package developed in this study, named GridFree, is freely available to the public. The source code is open-sourced under the MIT license, which allows for unrestricted reuse, distribution, and reproduction, provided that the original work is properly cited. Users can access all supporting documents, including a user manual, tutorials, demonstration images, and the source code, through the GridFree website. The website can be found at https://zzlab.net/GridFree. Additionally, the source code is available on GitHub at https://github.com/12HuYang/GridFree. This open-source approach ensures that researchers and users can easily access, modify, and implement the software for their specific needs.",
  "evaluation/method": "The evaluation of GridFree involved several methods to ensure its accuracy and effectiveness. We validated the size measurement accuracy of GridFree using manually measured wheat kernels. Images of these kernels were taken using an Android OS phone, specifically the OnePlus 7 Pro, with the camera set to take regular pictures. These images were then processed using GridFree, and the results were compared with those obtained from another software, SmartGrain. The correlation between the software-estimated results and the manual measurements was used to examine the size measurement accuracies. Both GridFree and SmartGrain demonstrated very similar accuracy for both length and width measurements. The squared Pearson correlation coefficients for length were 0.91 for GridFree and 0.90 for SmartGrain. For width, the coefficients were 0.90 for GridFree and 0.93 for SmartGrain. The mean values of the manual measurements were 6.35 mm for length and 3.17 mm for width. GridFree's estimates were 6.21 mm for length and 2.99 mm for width, while SmartGrain's estimates were 6.36 mm for length and 3.01 mm for width. The width estimates were noticeably lower than the manual measurements due to the varying angles of the kernels toward the camera, which affected the visible width.\n\nAdditionally, GridFree was evaluated for its ability to count and measure various types of objects. Beyond seeds, GridFree was successfully used to count and measure spore balls from potato (Solanum tuberosum) in an image provided by Tanaka Lab at Washington State University. The image was taken on a hemocytometer and filtered at two levels to generate the image of the points of interest (POI), in this case, spore balls. The first level involved selecting the principal components (PCs) derived from the three channels of the raw image and their 12 indices. Of the 12 PCs, PC 6 best differentiated the spore balls from other objects in the image. The second level of filtering involved cluster analysis, which separated the hidden patterns in the selected PC images. One cluster represented the spore balls, and segmentation was performed to ensure that the largest and smallest segments matched the largest and smallest spore balls. This evaluation demonstrated GridFree's versatility and accuracy in handling different types of objects and imaging conditions.",
  "evaluation/measure": "In our evaluation, we primarily focused on the accuracy of size measurements and the performance of object counting. For size measurement accuracy, we used the squared Pearson correlation coefficients (R\u00b2) to compare the software's estimates with manual measurements. Specifically, we reported R\u00b2 values for length and width measurements. For length, GridFree achieved an R\u00b2 of 0.91, while SmartGrain had an R\u00b2 of 0.90. For width, GridFree had an R\u00b2 of 0.90, and SmartGrain achieved an R\u00b2 of 0.93. These metrics indicate a strong correlation between the software's predictions and manual measurements, demonstrating the reliability of both tools.\n\nIn addition to correlation coefficients, we also provided mean values and standard deviations for the manual measurements and the software estimates. This allowed for a more detailed comparison of the accuracy of each tool. For length, the mean values were 6.35 mm for manual measurements, 6.21 mm for GridFree, and 6.36 mm for SmartGrain. For width, the mean values were 3.17 mm for manual measurements, 2.99 mm for GridFree, and 3.01 mm for SmartGrain. These values show that while both tools provide accurate estimates, there are slight variations that can be attributed to factors such as the angle of the kernels toward the camera.\n\nFor object counting, we compared the performance of GridFree with other software programs using ground truth measurements. The ground truth was designed to have specific numbers of seeds for different types of grains. This comparison allowed us to assess the accuracy and reliability of GridFree in counting objects from images. The advantage of using images for counting is that the results can be repeatedly examined for errors, which is particularly useful for identifying human errors in manual counting.\n\nOverall, the set of metrics we reported is representative of the literature in the field of image-based measurement and counting. Correlation coefficients and mean values are commonly used to evaluate the accuracy of size measurements, while comparisons with ground truth measurements are standard for assessing counting performance. These metrics provide a comprehensive evaluation of GridFree's capabilities and demonstrate its reliability in both size measurement and object counting tasks.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of GridFree with several publicly available methods using benchmark datasets. We examined images containing four types of grain kernels: black bean, canola, chickpea, and lentil. Each dataset included images with both adjacent and distinctly separate kernels, and varying background colors to test the robustness of the methods.\n\nWe compared GridFree with one smartphone application, SeedCounter, and three computer software programs: SmartGrain, GrainScan, and ImageJ. This comparison allowed us to assess GridFree's performance against a range of existing tools, from simple smartphone applications to more complex desktop software.\n\nAdditionally, we performed comparisons with simpler baselines to ensure that GridFree's improvements were not merely due to increased complexity. For instance, we evaluated the performance of individual segmentation algorithms, such as BFS and watershed, separately and in combination, to understand their contributions to GridFree's overall effectiveness.\n\nThe benchmark datasets included a variety of spatial patterns and background colors, providing a rigorous test of GridFree's segmentation capabilities. This approach ensured that our comparisons were thorough and that GridFree's performance could be accurately evaluated against both advanced and simpler methods.",
  "evaluation/confidence": "In our evaluation, we assessed the performance of GridFree by comparing it with other software programs, such as SmartGrain, SeedCounter, GrainScan, and ImageJ. We used various performance metrics to quantify the accuracy and reliability of GridFree.\n\nFor the size measurement accuracy, we validated GridFree using manually measured wheat kernels. The squared Pearson correlation coefficients for length were 0.91 for GridFree and 0.90 for SmartGrain, indicating a very high correlation between the software estimates and manual measurements. Similarly, the squared Pearson correlation coefficients for width were 0.90 for GridFree and 0.93 for SmartGrain. These results suggest that GridFree performs comparably to SmartGrain in terms of size measurement accuracy.\n\nWe also conducted a counting experiment on grain kernel images to compare GridFree with other software programs. The results showed that GridFree was able to accurately count the number of seeds in images with different spatial patterns and background colors. While specific confidence intervals were not provided for these metrics, the high correlation coefficients and accurate counting results indicate a strong level of confidence in the performance of GridFree.\n\nIn summary, the performance metrics used in our evaluation provide a robust assessment of GridFree's accuracy and reliability. The high correlation coefficients and accurate counting results suggest that GridFree is a superior method for counting and measuring objects in images. However, further statistical analysis, including confidence intervals and significance testing, could provide additional insights into the reliability of these results.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The images and measurements utilized for evaluating the performance of GridFree and SmartGrain are part of our supplementary data, which includes processed images and intermediate results. These files are not intended for public release due to the specific conditions under which they were captured and the proprietary nature of some of the tools used in their creation. However, the methods and procedures for obtaining similar data are thoroughly described in the supplementary materials, allowing other researchers to replicate our experiments under comparable conditions. For those interested in using our evaluation methods, we provide detailed instructions and guidelines in the supplementary figures and text, ensuring reproducibility and transparency in our research."
}