{
  "publication/title": "The Dynamics of the COVID-19 Pandemic\u2013Nonlinear Approaches on the Modelling, Prediction and Control.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Eur. Phys. J. Spec. Top.",
  "publication/year": "2022",
  "publication/pmid": "35966369",
  "publication/pmcid": "PMC9363874",
  "publication/doi": "10.1140/epjs/s11734-022-00661-9",
  "publication/tags": "- COVID-19\n- Respiratory Sounds\n- Machine Learning\n- Deep Learning\n- Disease Classification\n- Model Accuracy\n- Data Analysis\n- Medical Diagnosis\n- AI Techniques\n- SARS-CoV-2 Variants",
  "dataset/provenance": "The datasets used in our study were collected from various sources, primarily from the University of Cambridge, with mutual agreements for research purposes. The ethical committee at Cambridge University approved these datasets for our research.\n\nThe first dataset, released in May 2020, is known as KDD-data. It contains around 12,000 samples collected from different countries, with approximately 302 users testing positive for COVID-19.\n\nThe second dataset, ComParE2021-CCS-CSS-Data, was released in June 2021. This dataset includes two metadata files in CSV format, used to classify two tasks: COVID symptoms and no COVID symptoms.\n\nThe third dataset, NeurlPs2021-data, was released in November 2021. It is a large dataset consisting of 53,500 respiratory sound samples collected from 36,117 unique users. This dataset includes voice, breath, and cough sounds and is used to predict two tasks: other respiratory disease symptoms and COVID-19 symptoms. It contains data from users with varying smoking statuses and age groups, primarily between 20 and 50 years old.\n\nAdditionally, we collected various other COVID-19 respiratory sounds datasets, including Virufy, COVID-19-Cough, Coswara, Tos COVID-19, and COUGHVID, with sample sizes ranging from 121 to 27,550. We also prepared a comprehensive dataset with 90,341 samples, including data from local hospitals and trusted repositories. This dataset is classified into ten different classes, covering various respiratory diseases and COVID-19 variants.\n\nThe data collection process involved a web-based application and iOS/Android applications developed to gather respiratory sounds and associated metadata, such as past medical history, smoking status, age, gender, and COVID-19 status. The data were secured on the University of Cambridge databases and transferred when the device was connected to Wi-Fi. Users' personal information was deleted based on their requests.\n\nThe datasets have been used in previous examinations and by the community to develop AI-based screening models for identifying COVID-19 disease symptoms from lung sounds data. However, there is no accurate and sensitive framework available to diagnose human respiratory diseases on large datasets to detect COVID-19 symptoms with various variants and other respiratory disease symptoms.",
  "dataset/splits": "In our study, we utilized three primary datasets for our research: KDD-data, ComParE2021-CCS-CSS-Data, and NeurlPs2021-data. These datasets were collected from the University of Cambridge with the necessary agreements and ethical approvals.\n\nThe KDD-data, released in May 2020, consists of around 12,000 samples from various countries, with approximately 302 users testing positive for COVID-19. This dataset is divided into ten different data folders, each representing different conditions such as asthma, COVID-19 with and without cough, and healthy individuals with and without symptoms.\n\nThe ComParE2021-CCS-CSS-Data, released in June 2021, includes two metadata files used to classify two tasks: COVID symptoms and no COVID symptoms. This dataset does not specify the exact number of samples but focuses on metadata classification.\n\nThe NeurlPs2021-data, released in November 2021, is the largest dataset among the three, containing 53,500 respiratory sound samples collected from 36,117 unique users. This dataset is divided into two main tasks: predicting other respiratory disease symptoms and COVID-19 symptoms. It includes a diverse range of participants, with 62% males, 36% females, and 2% unidentified. The dataset also provides self-reported COVID-19 status, with 2105 individuals testing positive.\n\nAdditionally, we prepared a combined dataset that includes samples from the NeurlPs2021-data, additional samples collected from local hospitals, and other publicly available sources. This combined dataset consists of 90,341 samples, categorized into ten classes: COPD, Asthma, Pertussis, Bronchitis, COVID-19 variants (Alpha, Beta, Gamma, Delta, Omicron), and Healthy Symptoms. The distribution of samples in this combined dataset is as follows: 111 samples for COPD, 224 for Asthma, 131 for Pertussis, 129 for Bronchitis, 1820 for COVID-19 Variant Alpha, 1985 for Variant Beta, 1232 for Variant Gamma, 2198 for Variant Delta, 26 for Variant Omicron, and 82,485 for Healthy Symptoms. This combined dataset was used to train and validate our proposed model, achieving state-of-the-art results in respiratory sound-based AI frameworks for human health.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets used in our study are available through various means, ensuring accessibility for research purposes. The first COVID-19 crowdsourced dataset, known as KDD-data, was released in May 2020. This dataset, along with the second dataset, ComParE2021-CCS-CSS-Data (released in June 2021) and the third dataset, NeurlPs2021-data (released in November 2021), were collected from the University of Cambridge with a mutual agreement for research purposes. These datasets have been approved by Cambridge University\u2019s ethical committee for research use.\n\nThe NeurlPs2021-data, in particular, is a large-scale dataset containing 53,500 respiratory sound samples collected from 36,117 unique users. This dataset includes modalities such as voice, breath, and cough sounds, and it is available for public use. The data collection process involved a web-based application and iOS/Android applications developed to gather respiratory sounds and associated metadata from participants. The data includes self-reported COVID-19 status, past medical history, smoking status, age, gender, and other relevant health information.\n\nIn addition to these datasets, we have also collected various other COVID-19 respiratory sounds datasets, such as Virufy, COVID-19-Cough, Coswara, Tos COVID-19, and COUGHVID. These datasets are publicly available and have been cited in our references. The central part of our data was collected from Cambridge University with an agreement for research purposes, while the remaining data were gathered from publicly available sources and local hospitals.\n\nThe newly prepared dataset, which consists of 90,341 samples, is also available for research. This dataset includes 7,261 COVID-19-positive samples and covers a broad spectrum of respiratory diseases and health issues. The data is secured on University of Cambridge databases, and participants' personal information is deleted based on user requests.\n\nTo ensure the ethical use of the data, all participants provided informed consent, and the data collection process was overseen by the ethical committee at Cambridge University. The datasets are released under licenses that permit their use for research purposes, with appropriate citations and acknowledgments. This ensures that the data is used responsibly and ethically, contributing to the advancement of research in respiratory sound-based AI frameworks for human health.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the Adam Optimizer, which is a widely-used class of machine-learning algorithms known for its efficiency in training deep learning models. The Adam Optimizer is not a new algorithm; it was introduced by Diederik P. Kingma and Jimmy Ba in their 2014 paper \"Adam: A Method for Stochastic Optimization.\" It combines the advantages of two other extensions of stochastic gradient descent, namely AdaGrad and RMSProp.\n\nThe reason the Adam Optimizer is discussed in a physics journal rather than a machine-learning journal is that our primary focus is on the application of this optimization technique to respiratory disease classification using deep learning models. The novelty of our work lies in the specific application and the architectural design of our models, rather than the optimization algorithm itself. We utilize the Adam Optimizer to fine-tune the parameters of our Regularized Deep Convolutional Neural Networks (RDCNNs), which are designed to classify respiratory sounds into various disease categories, including different variants of COVID-19.\n\nThe Adam Optimizer is chosen for its adaptability and efficiency in handling sparse gradients on noisy problems, making it well-suited for the complex and high-dimensional data involved in respiratory sound analysis. By using this optimizer, we aim to achieve robust and accurate model performance, which is crucial for reliable disease diagnosis.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, we employed various feature extraction techniques to encode the input data for our machine-learning algorithms. Specifically, we utilized three different spectrums: Modified Mel-Frequency Cepstral Coefficients (MMFCC), Soft-Mel frequency spectrum, and Log-Mel frequency spectrum. The input vector size for the MMFCC spectrogram was set to (20,128), while the other two spectrums had an input vector size of (128,128).\n\nThe data preprocessing involved applying convolutional filters to the input spectrums. This process included edge detection and pattern recognition to identify convolved features within the sound spectrograms. The convolutional operation involved sliding a filter across the input spectrogram, with the stride determining the movement of the filter. This operation was crucial for extracting relevant features from the input data.\n\nFor the convolutional layers, we used ReLU (Rectified Linear Unit) as the activation function for the first four layers. This non-linear operation helped in mapping the input data to the output estimated values. The dense layers and convolutional layers were represented using specific equations that detailed the operations performed on the input vectors.\n\nWe also implemented L2 norm regularization with a value of 0.001 to prevent overfitting. This regularization technique was applied to fine-tune the model parameters, including the number of hidden layers, dropout rate, learning rates, and activation functions. Additionally, we tested different epochs to minimize model loss, finding that the network saturated at the 69th epoch with a batch size of 32.\n\nThe data was further processed using k-fold validation methods to evaluate the performance of our deep learning and machine learning techniques. This approach ensured that the model was robust and could generalize well to unseen data. The datasets used included KDD-data, ComParE2021-CCS-CSS-Data, and a newly prepared Respiratory COVID-19 dataset, which was compiled from various sources, including local hospitals and internet data.",
  "optimization/parameters": "In our study, we utilized several key parameters to optimize the performance of our models. The primary optimization parameter employed was the Adam Optimizer, which is known for its efficiency in handling sparse gradients on noisy problems. We set a uniform batch size of 32, which was determined through extensive testing to balance computational efficiency and model performance.\n\nThe number of epochs was another critical parameter. We tested various epoch ranges and found that the network saturated at the 69th epoch with the specified batch size. This saturation point indicated that further training did not significantly improve the model's performance, thus 69 epochs were selected as optimal.\n\nFor the activation functions, we used the rectified linear unit (ReLU) for the first four layers, which helps in mitigating the vanishing gradient problem and accelerates the convergence during training. The final layer utilized the softmax function to output probability distributions over the different classes.\n\nAdditionally, we implemented L2 norm regularization with a value of 0.001 to prevent overfitting. This regularization technique helps in fine-tuning the model parameters by penalizing large weights, thereby improving generalization to unseen data.\n\nThe selection of these parameters was based on a combination of empirical testing and theoretical considerations. The Adam Optimizer and ReLU activation function are widely recognized for their effectiveness in deep learning models. The batch size and number of epochs were chosen after evaluating the model's performance on validation datasets, ensuring that the model neither underfits nor overfits the training data. The L2 norm regularization was included to enhance the model's robustness and prevent overfitting, which is crucial for achieving reliable performance on diverse datasets.",
  "optimization/features": "In our study, we utilized three distinct types of spectral features as inputs for our models. These features are the Modified Mel-Frequency Cepstral Coefficients (MMFCC) spectrogram, the Soft-Mel frequency spectrum, and the Log-Mel frequency spectrum. The input vector size for the MMFCC spectrogram is (20,128), while for the Soft-Mel and Log-Mel frequency spectra, the input vector size is (128,128).\n\nFeature selection was not explicitly performed in the traditional sense. Instead, we focused on extracting and utilizing these specific spectral features based on their known effectiveness in representing audio data. The choice of these features was informed by their widespread use and proven performance in similar audio classification tasks.\n\nThe extraction of these spectral features was done independently of the training process. This means that the features were generated from the raw audio data without using any information from the training set to guide the feature selection process. This approach ensures that the features are general and not overfitted to the specific training data, thereby enhancing the model's ability to generalize to new, unseen data.",
  "optimization/fitting": "In our study, we employed two models, Model-1 and Model-2, both of which are regularized deep convolutional neural networks (RDCNNs). The number of parameters in these models is indeed larger than the number of training points, which is a common scenario in deep learning. To address the potential issue of overfitting, we implemented several strategies.\n\nFirstly, we used L2 norm regularization with a value of 0.001 across all layers of both models. This technique helps to penalize large weights, thereby preventing the model from becoming too complex and overfitting the training data.\n\nSecondly, we incorporated dropout layers with a rate of 0.5 in both models. Dropout randomly sets a fraction of input units to 0 at each update during training time, which helps to prevent overfitting by ensuring that the model does not rely too heavily on any single feature.\n\nAdditionally, we fine-tuned various hyperparameters, including the number of hidden layers, dropout rate, learning rates, and activation functions. We also experimented with different kernel sizes (3 \u00d7 3 and 5 \u00d7 5) and found that the 3 \u00d7 3 kernel size provided better accuracy.\n\nTo further mitigate overfitting, we used k-fold validation methods to evaluate the performance of our models. This technique helps to ensure that the model generalizes well to unseen data.\n\nRegarding underfitting, we observed that our models achieved high accuracy on multiple datasets, indicating that they are capable of capturing the underlying patterns in the data. The use of deep convolutional layers allows the models to learn complex features from the input spectrograms, reducing the risk of underfitting.\n\nIn summary, through the use of regularization techniques, dropout layers, hyperparameter tuning, and k-fold validation, we effectively addressed the issues of overfitting and underfitting in our models.",
  "optimization/regularization": "In our study, we employed the L2 norm regularization method to prevent overfitting in both Model-1 and Model-2. This technique was applied to fine-tune the convolutional model parameters, including regulating the number of hidden layers, adjusting the dropout rate, applying different learning rates, and implementing various activation functions across different layers. Additionally, we examined the number of epochs, ranging from 1 to 69, to decrease the model loss. This approach helped in avoiding the overfitting problem and ensured that the models generalized well to unseen data. The use of L2 norm regularization, along with other techniques such as dropout and careful tuning of hyperparameters, contributed to the robustness and accuracy of our models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules used in our study are detailed within the publication. Specifically, we have discussed the use of different kernel sizes (3 \u00d7 3 and 5 \u00d7 5) and their impact on model accuracy. The 3 \u00d7 3 kernel size filter was found to provide 2\u20133% better accuracy compared to the 5 \u00d7 5 filter size. Additionally, we have evaluated the performance of our models using various datasets, including KDD-data, ComParE2021-CCS-CSS-Data, and a newly prepared Respiratory COVID-19 dataset.\n\nRegarding the model files and optimization parameters, these details are implicitly covered in the description of our experimental setup. For instance, we mentioned the use of L2 norm regularization to prevent overfitting and the fine-tuning of convolutional model parameters such as the number of hidden layers, dropout rate, learning rates, and activation functions. The number of epochs was also examined to decrease model loss, with observations made up to the 69th epoch.\n\nThe specific model files and exact optimization parameters are not explicitly provided in the text, but the methods and configurations used are thoroughly described. This information allows for reproducibility of the experiments and further research. The datasets used, including the newly prepared Respiratory COVID-19 data, are based on publicly available sources such as NeurlPs2021-data, local hospital data, and internet sources. The licensing details for these datasets would need to be referred to from their original sources.",
  "model/interpretability": "The models discussed in this publication, specifically Model-1 and Model-2, are deep convolutional neural networks (CNNs) designed for respiratory disease classification. These models can be considered somewhat transparent due to the use of spectrograms and specific feature channels that aid in interpretability.\n\nModel-1 incorporates max-pooling, while Model-2 does not. Both models utilize three Mel-spectrogram feature channels: Modified Mel-Frequency Cepstral Coefficients (MMFCC), Log-Mel Spectrum, and Soft-Mel Spectrum. These spectrograms provide visual representations of the respiratory sounds, making it possible to analyze and interpret the features that the models use for classification.\n\nFor instance, the MMFCC spectrogram has been observed to perform better in extracting deep respiratory sound features compared to the other two feature channels. This indicates that the MMFCC spectrogram provides more interpretable and relevant information for the models to make accurate classifications.\n\nThe models' performance on various datasets, including KDD-data, ComParE2021-CCS-CSS-data, and Respiratory COVID-19 Data, demonstrates their ability to handle different respiratory diseases and variants of COVID-19. The use of data augmentation techniques to balance the datasets further enhances the models' interpretability and robustness.\n\nIn summary, while the models are complex deep learning architectures, the use of spectrograms and specific feature channels allows for a degree of interpretability. The models are not entirely black-box; they provide insights into the features that contribute to their classification decisions.",
  "model/output": "The model is a classification model designed to identify various respiratory diseases. It categorizes input data into one of ten different disease classes, including COPD, Asthma, Pertussis, Bronchitis, and several variants of COVID-19, as well as healthy symptoms. The model uses a softmax classifier in its final layer to output probabilities for each class, enabling the classification of respiratory conditions based on input features.\n\nThe performance of the model is evaluated using metrics such as accuracy, precision, recall, and F1 score for each disease class. These metrics provide a comprehensive understanding of the model's effectiveness in correctly identifying and distinguishing between different respiratory diseases. The model has been tested on multiple datasets, including KDD-data, ComParE2021-CCS-CSS-Data, and a newly prepared Respiratory COVID-19 dataset, demonstrating its robustness and generalizability across different data sources.\n\nTwo versions of the model have been developed: Model-1, which includes max-pooling layers, and Model-2, which does not. Model-2 generally shows better performance, achieving higher accuracy for most disease classes. The use of L2 norm regularization and dropout layers helps to prevent overfitting, ensuring that the model generalizes well to new, unseen data. The model's architecture includes multiple convolutional layers with ReLU activation functions, followed by dense layers that lead to the final classification output.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed models involved several key methods to ensure robust and reliable performance assessment. We employed k-fold validation, which is particularly well-suited for evaluating deep learning (DL) and machine learning (ML) techniques. This method helps in measuring the model's performance across different subsets of the data, providing a comprehensive view of its generalization capabilities.\n\nTo avoid overfitting, we utilized L2 norm regularization. This technique was applied to fine-tune various parameters of the convolutional models, including the number of hidden layers, dropout rates, learning rates, and activation functions. Additionally, we examined the number of epochs, ranging from 1 to 69, to optimize the model's performance by minimizing loss.\n\nThe models were tested on three different datasets: KDD-data, ComParE2021-CCS-CSS-Data, and a newly prepared Respiratory COVID-19 dataset. The Respiratory COVID-19 dataset was compiled from various sources, including the NeurlPs2021-data raw dataset, local hospital data, and internet sources. This diverse dataset allowed us to evaluate the models' performance on a wide range of respiratory conditions.\n\nWe calculated several performance metrics, including accuracy, precision, recall, and F1-score. Accuracy was determined by the ratio of true positive and true negative values to the total number of predictions. Precision and recall were specifically calculated for the COVID-19 class, providing insights into the model's ability to correctly identify positive cases and avoid false negatives. The F1-score, which is the harmonic mean of precision and recall, offered a balanced measure of the model's performance.\n\nThe evaluation also included a comparison with existing models and approaches, such as SVM, VGG-Net, LSTM, 1D CNN, and Light-Weight CNNs. This comparison highlighted the strengths and weaknesses of our models in detecting various respiratory diseases, including different variants of COVID-19.\n\nOverall, the evaluation process was designed to be thorough and comprehensive, ensuring that the proposed models were rigorously tested and validated against a variety of benchmarks and datasets.",
  "evaluation/measure": "In our evaluation, we reported several key performance metrics to comprehensively assess the effectiveness of our models. These metrics include accuracy, precision, recall, and the F1 score. Accuracy is defined as the ratio of true positive and true negative values to the total number of predictions. Precision, specifically for the COVID-19 class, is the ratio of true positive values to the sum of true positive and false positive values. Recall, also for the COVID-19 class, is the ratio of true positive values to the sum of true positive and false negative values. The F1 score is the harmonic mean of precision and recall, providing a balanced measure of a model's performance.\n\nThese metrics are widely used in the literature and are representative of the standard evaluation criteria for machine learning and deep learning models, particularly in the context of respiratory disease classification. By including these metrics, we ensure that our evaluation is thorough and comparable to existing studies. The use of k-fold validation methods further enhances the reliability of our performance measurements, making our results robust and generalizable.",
  "evaluation/comparison": "In the evaluation of our models, a comprehensive comparison was conducted with publicly available methods using benchmark datasets. Specifically, we evaluated our deep CNN models against established approaches such as Support Vector Machines (SVM), VGG-Net, Long Short-Term Memory (LSTM) networks, 1D Convolutional Neural Networks (CNN), and Light-Weight CNNs. These comparisons were performed on various datasets, including KDD-Data, ComParE2021-CCS-CSS-Data, and a newly prepared Respiratory COVID-19 dataset.\n\nThe KDD-Data and ComParE2021-CCS-CSS-Data were balanced according to disease class to ensure fair evaluation. Our models demonstrated superior performance across multiple respiratory diseases, including COPD, asthma, pertussis, bronchitis, and various COVID-19 variants. For instance, on the KDD-Data, our models achieved accuracies of 92.43% for asthma, 92.18% for pertussis, 93.10% for bronchitis, 94.17% for COVID-19, and 93.26% for healthy symptoms. Similarly, on the ComParE2021-CCS-CSS-Data, the accuracies were 90.14% for asthma, 92.42% for pertussis, 92.69% for bronchitis, 93.73% for COVID-19, and 95.30% for healthy symptoms.\n\nIn addition to comparing with advanced models, we also evaluated simpler baselines to provide a broader context for our models' performance. For example, the SVM model achieved accuracies of 80% for COVID-19 detection with cough and breath, 82% for COVID-19 detection with cough, and 80% for distinguishing COVID-19 from asthma using breath sounds. The VGG-Net model showed higher accuracies of 87% for COVID-19 detection with cough and 88% for distinguishing COVID-19 from asthma using breath sounds.\n\nOur deep CNN models, particularly Model-2 without max-pooling, consistently outperformed these baselines and other advanced models. This indicates that our approach not only matches but often exceeds the performance of existing methods, providing a robust solution for respiratory disease detection using audio data.",
  "evaluation/confidence": "The evaluation of the models presented in this study focuses on several key performance metrics, including precision, recall, accuracy, and F1 score. These metrics were calculated for various respiratory diseases and COVID-19 variants using two different models: one with max-pooling and one without. The performance was assessed across multiple datasets, including KDD-data, ComParE2021-CCS-CSS-Data, and a newly prepared Respiratory COVID-19 dataset.\n\nThe models were evaluated using k-fold validation methods, which are well-suited for assessing the performance of deep learning and machine learning techniques. This approach helps in ensuring that the results are robust and generalizable. The use of k-fold validation indicates that the models were tested multiple times on different subsets of the data, providing a more reliable estimate of their performance.\n\nThe study also employed L2 norm regularization to prevent overfitting. This technique involves fine-tuning various parameters of the convolutional models, such as the number of hidden layers, dropout rates, learning rates, and activation functions. Additionally, the number of epochs was examined to minimize model loss, further enhancing the reliability of the results.\n\nThe performance metrics for the models are presented in tables, showing the accuracy and F1 scores for different disease classes and datasets. For instance, the accuracy for detecting COVID-19 Variant_1 (Alpha) using the model with max-pooling is 94%, while the model without max-pooling achieves 96% accuracy. These values suggest that the models perform well in distinguishing between different respiratory conditions and COVID-19 variants.\n\nHowever, specific confidence intervals for the performance metrics are not explicitly mentioned in the provided information. While the use of k-fold validation and regularization techniques suggests a rigorous evaluation process, the absence of confidence intervals means that the precise variability and statistical significance of the results are not detailed. This makes it challenging to definitively claim that one method is superior to others or baselines without further statistical analysis.\n\nIn summary, while the evaluation methods used in this study are robust and the performance metrics are promising, the lack of reported confidence intervals limits the ability to make strong statistical claims about the superiority of the proposed models over existing ones. Further statistical analysis would be beneficial to provide a more comprehensive evaluation of the models' performance.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The data used in our study was collected from various sources, including trusted repositories, local hospitals, and publicly available datasets. However, the specific raw evaluation files are not released to the public. The data collection process involved obtaining agreements for research purposes, particularly with institutions like Cambridge University. While some datasets used in our study are publicly available, the raw evaluation files generated during our specific research are not part of these public releases. Therefore, access to these files is restricted and not openly accessible."
}