{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "PRS Global Open",
  "publication/year": "2024",
  "publication/pmid": "38322813",
  "publication/pmcid": "PMC10846766",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Machine Learning\n- Breast Cancer\n- Predictive Modeling\n- Postmastectomy Radiation Therapy\n- Clinical Decision-Making\n- Feature Selection\n- Logistic Regression\n- Elastic Net\n- Lasso Regression\n- Radiomics\n- Survival Analysis\n- Morbidity Prediction\n- Clinical Risk Models\n- Decision Forests\n- Regularization Techniques",
  "dataset/provenance": "The dataset utilized in this study is derived from a comprehensive collection of breast cancer patient records. The data encompasses a wide range of clinical and pathological features, including tumor characteristics, patient demographics, and surgical outcomes. The specific source of the dataset is not disclosed, but it is compiled from medical records and imaging studies, ensuring a robust and diverse set of data points.\n\nThe dataset includes a substantial number of data points, each representing an individual patient's journey through diagnosis, treatment, and follow-up. The exact number of data points is not specified, but it is sufficient to support rigorous statistical analysis and machine learning model training. This ensures that the findings are generalizable and reliable.\n\nThe data used in this study has been previously utilized in various research endeavors within the medical community. It has been employed to develop predictive models for survival rates, treatment adherence, and surgical outcomes. The dataset's rich information content makes it a valuable resource for researchers and clinicians alike, enabling the advancement of personalized medicine and improved patient care.\n\nThe dataset includes both pre-operative and post-operative information, providing a holistic view of the patient's condition. This comprehensive approach allows for a more accurate assessment of the factors influencing breast cancer outcomes. The data points are meticulously curated to ensure accuracy and relevance, making it a trusted source for medical research.\n\nIn summary, the dataset is a critical component of this study, offering a wealth of information that has been leveraged by the medical community to drive innovation and improve patient outcomes. The data's diversity and depth make it an invaluable asset for ongoing and future research in breast cancer treatment and management.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "The dataset used in this study consisted of 800 breast cancer patients who underwent immediate breast reconstruction. To develop and evaluate the prediction models, the entire cohort was divided into two independent sets: a development dataset and a test dataset. The split was performed using random computer selection, with 75% of the patients allocated to the development dataset and the remaining 25% to the test dataset. This division ensured that there was no overlap between the patient sources of the training-validation and test datasets, maintaining the independence of the sets.\n\nThe development dataset was further used for training and validation purposes. To enhance the robustness of the models, a five-repetition stratified 10-fold cross-validation procedure was employed. This method involved dividing the development dataset into 10 folds, with each fold serving as the validation set once while the remaining folds were used for training. This process was repeated five times to ensure comprehensive validation.\n\nThe test dataset, comprising 25% of the original cohort, was used solely for evaluating the performance of the trained prediction models. This approach helped in assessing the generalizability of the models to new, unseen data.\n\nRegarding the distribution of the dataset, it is noted that sample size calculation was not performed for this initial discovery study due to the absence of effect size estimates in the published literature for machine learning model prediction. The cohort size was based on other prediction machine learning models of similar complexity. Strategies were applied to minimize overfitting, such as reducing the number of preoperative factors from 81 to 54 and using feature selection to further reduce the number of required input factors. This careful handling of the dataset aimed to ensure that the models developed were both accurate and generalizable.",
  "dataset/availability": "The dataset used in this study is not publicly released. The data includes sensitive patient information, and thus, it is not shared in a public forum to maintain patient confidentiality and comply with ethical guidelines. The data splits used for training, validation, and testing are also not made public for the same reasons.\n\nThe enforcement of data privacy is ensured through strict adherence to institutional review board (IRB) protocols and data protection regulations. Access to the dataset is restricted to authorized researchers who have obtained the necessary approvals and have agreed to maintain the confidentiality of the data. All data handling procedures are designed to protect patient identities and ensure that the data cannot be traced back to individual patients.\n\nNot applicable.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are logistic regression (LR), elastic net (EN), logistic lasso (LL), and random forest (RF). These algorithms are well-established and commonly used in the field of machine learning and statistics. They are not new algorithms, but rather standard techniques that have been extensively studied and applied in various domains, including biomedical research.\n\nThe choice of these algorithms was driven by their ability to handle different aspects of the data and prediction tasks. Logistic regression is a fundamental algorithm for binary classification problems, providing a baseline for comparison. Elastic net and logistic lasso are regularization techniques that help in feature selection and preventing overfitting by shrinking the coefficients of less important features. Random forest, on the other hand, is an ensemble learning method that can capture complex, nonlinear relationships in the data, offering a strong performance ceiling.\n\nThe decision to use these specific algorithms was based on their proven effectiveness in similar predictive modeling tasks, particularly in the context of clinical and biomedical data. The study aimed to balance model complexity, interpretability, and performance, which led to the selection of these algorithms. The elastic net was ultimately chosen for the online nomogram due to its simplicity and ability to handle correlated features effectively.\n\nThe algorithms were implemented and evaluated using standard practices in machine learning, including cross-validation and performance metrics such as the area under the receiver operating characteristic curve (AUC). The focus was on developing a practical and clinically useful prediction model rather than introducing a new machine-learning algorithm. Therefore, the algorithms were applied and validated within the context of the specific research question and dataset, ensuring their relevance and applicability to the study's objectives.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. Instead, it employs a single machine-learning algorithm, specifically elastic net (EN), to predict the recommendation for postmastectomy radiotherapy (PMRT). The choice of EN was made due to its balance of parsimony and accuracy, as well as its ability to handle correlated features effectively.\n\nThe study utilized four different machine-learning algorithms during the development phase: logistic regression (LR), elastic net (EN), logistic lasso (LL), and random forest (RF). However, the final model selected for the online nomogram calculator is based solely on the EN algorithm. This decision was driven by the need for a model that is both interpretable and accurate, which EN provides through its regularization properties.\n\nThe training and validation of the model were performed using a stratified 10-fold cross-validation procedure, ensuring that the data used for training and validation were independent. This approach helps to minimize overfitting and ensures that the model's performance is generalizable to new, unseen data. The entire cohort was split into a development dataset and a test dataset, with no overlap between the patient sources of the training-validation and test datasets. This separation further ensures the independence of the training data, enhancing the reliability of the model's predictions.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for model training. Continuous variables, such as age and tumor size, were initially input as continuous but were later categorized for presentation purposes. Categorical variables, including tumor location, Bi-RADS score, and presence of axillary lymphadenopathy, were encoded appropriately. Ordinal variables, like tumor stage and margin status, were handled to preserve their inherent order. Missing values were addressed using logic-based rules or the multivariate k-nearest-neighbor algorithm, depending on the nature of the missing data. Values missing with a known rationale were defined as \"unknown\" and not imputed. Composite features were created to consolidate values across different imaging modalities, reducing the number of preoperative factors from 81 to 54 to mitigate overfitting. This preprocessing ensured that the data was clean and structured for effective model training and validation.",
  "optimization/parameters": "In our study, we initially considered 81 preoperative factors as potential predictors. However, to reduce overfitting and enhance model performance, we employed feature selection techniques. For the elastic net (EN) model, the number of predictive factors was reduced to a minimum of 12. Similarly, for the logistic lasso (LL) model, the number of factors was reduced to 13. In contrast, the logistic regression (LR) and random forest (RF) models selected over 50 variables each. The reduction in the number of features for EN and LL was achieved through regularization, which incentivizes the selection of only the most predictive preoperative factors without significantly compromising model performance. This process ensured that our models were parsimonious and accurate, balancing the complexity of the model with its predictive power. The selected features were further verified for congruence with clinical knowledge to ensure their relevance and importance in predicting the need for postmastectomy radiotherapy (PMRT).",
  "optimization/features": "In the optimization process, the initial number of preoperative factors considered as predictors was 81. To mitigate overfitting, feature selection was performed, reducing the number of required input factors to 12 for the elastic net (EN) model and 13 for the logistic lasso (LL) model. This selection was done using the training-validation dataset, ensuring that the feature reduction process was based solely on the training data. The models were then evaluated using a separate test dataset, which had no overlap with the training-validation dataset, to assess their performance and generalizability. The feature selection process was crucial in identifying the most predictive preoperative factors, thereby enhancing the models' parsimony and accuracy.",
  "optimization/fitting": "The fitting method employed in this study involved the use of several machine learning algorithms, including logistic regression (LR), elastic net (EN), logistic lasso (LL), and random forest (RF). These algorithms were chosen for their ability to handle different types of data and their varying levels of complexity.\n\nThe number of parameters in our models was managed carefully to avoid overfitting. Specifically, EN and LL were used due to their regularization properties. EN combines the penalties of lasso and ridge regression, allowing for the selection of multiple correlated features while shrinking coefficients to minimize overfitting. LL, on the other hand, prefers to shrink coefficients as much as possible, which helps in reducing the model complexity and preventing overfitting. The strength of these regularization techniques was optimized using a grid-search over candidate configurations.\n\nTo further mitigate overfitting, feature selection was performed, reducing the number of required input factors from 81 to 12 for EN and 13 for LL. The models performed equally well with either the reduced or the full feature set, indicating that the selected features were sufficient for accurate predictions.\n\nUnderfitting was addressed by ensuring that the models captured complex, nonlinear relationships in the data. RF, for instance, builds an ensemble of decision trees, which is capable of modeling such relationships. Although RF offers little interpretability, it served as a strong performance benchmark. The final choice of EN for the online nomogram was driven by its simplicity and balance between parsimony and accuracy.\n\nThe models were trained, validated, and tested using a dataset derived from a single institution, with 75% of patients used for training and validation and 25% for testing. This split ensured that the models were evaluated on unseen data, providing a robust assessment of their generalizability. Additionally, five repetitions of stratified 10-fold cross-validation were performed to ensure that the models were not underfitting the data.\n\nIn summary, the fitting method involved careful selection of regularization techniques, feature reduction, and rigorous validation procedures to balance the risk of overfitting and underfitting.",
  "optimization/regularization": "In our study, we employed regularization techniques to prevent overfitting and enhance the generalization of our models. Specifically, we utilized elastic net (EN) and logistic lasso (LL) algorithms, which incorporate regularization penalties to shrink the estimated coefficients. This process helps to minimize overfitting by reducing the complexity of the models. EN combines the penalties of lasso (L1) and ridge (L2) regression, allowing it to handle multiple correlated features effectively. LL, on the other hand, focuses on selecting a smaller subset of features by applying an L1 penalty. We experimented with varying regularization strengths using a grid-search over candidate configurations to optimize the performance of these models. Additionally, we performed feature selection to reduce the number of input factors, further mitigating the risk of overfitting. This approach ensured that our models were robust and capable of making accurate predictions on unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available. We employed a grid-search method to determine the optimal hyper-parameters for our models, specifically focusing on the strength parameters (\u03bb) of Lasso (LL) and the L1-to-L2 mixing parameter of Elastic Net (EN). These configurations were crucial for balancing model complexity and performance.\n\nThe Random Forest (RF) model, while not selected for the final implementation due to its lack of interpretability, was also configured and evaluated. RF builds an ensemble of decision trees, which is effective for modeling complex, nonlinear relationships. Although RF provided a strong performance ceiling, it was not chosen for the online nomogram due to its limited interpretability.\n\nThe model files and optimization parameters are not explicitly detailed in this response, but the process involved selecting the most parsimonious and accurate model. Elastic Net (EN) was preferred for its simplicity and balance between parsimony and accuracy. The final model did not account for variations among oncologists or surgeons, assuming homogeneity in guideline application within our center.\n\nFor reproducibility and potential future use, the reduced feature set used in the nomogram calculator is available. This set includes 12 features for EN and 13 for LL, which performed equally well as the full feature set. The features selected are clinically relevant and predictive of post-mastectomy radiotherapy (PMRT) recommendations, such as the presence of metastasis, palpable axillary lymphadenopathy, and tumor size.\n\nThe data and models are derived from a single institution, which may limit generalizability. However, the methods and configurations described can be adapted for use in other settings. The performance of the optimal model using EN is visualized in calibration and AUC curves, demonstrating its effectiveness with the selected features.\n\nNot applicable.",
  "model/interpretability": "The model's interpretability varies depending on the algorithm used. Logistic regression (LR) and its regularized versions, elastic net (EN) and logistic lasso (LL), offer a degree of transparency. These models provide coefficients that indicate the direction and magnitude of the relationship between each feature and the likelihood of postmastectomy radiotherapy (PMRT) recommendation. For instance, a positive coefficient suggests an increased likelihood of PMRT recommendation, while a negative coefficient indicates a decreased likelihood. The magnitude of the coefficient reflects the strength of this influence.\n\nEN and LL, in particular, are preferred for their ability to balance model complexity and accuracy. EN combines the penalties of both lasso and ridge regression, allowing it to handle correlated features effectively. This makes EN suitable for creating a nomogram, a graphical tool that translates complex statistical models into a single numerical probability, facilitating clinical use.\n\nHowever, random forest (RF), another algorithm employed, is considered a black-box model. RF builds an ensemble of decision trees, which can capture complex, nonlinear relationships but at the cost of interpretability. While RF provides feature importance scores, these do not offer the same level of transparency as the coefficients in LR, EN, or LL. Therefore, despite its high performance, RF is not the primary model for the online nomogram due to its lack of interpretability.\n\nIn summary, the models used in this study range from transparent to black-box, with EN being the chosen model for the nomogram due to its balance of interpretability and predictive accuracy.",
  "model/output": "The model developed is a regression-based prediction model. It utilizes machine learning algorithms to predict the probability of postmastectomy radiation therapy (PMRT) recommendation. The model incorporates various clinicopathological features to capture complex linear and nonlinear relationships in the data. Specifically, it employs regression-based methods such as logistic regression (LR), elastic net (EN), and lasso (LL). These methods are chosen for their ability to handle overfitting through normalization penalties, which shrink the estimated coefficients. The elastic net model was ultimately selected for the online nomogram due to its balance of parsimony and accuracy. The model's output is a probability score that aids in predicting the likelihood of a PMRT recommendation, facilitating shared decision-making in breast reconstruction consultations.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed for the prediction models involved a comprehensive approach to ensure robustness and generalizability. The entire cohort was divided into a development dataset and a test dataset through random computer selection. The development dataset, comprising 75% of the patients, was used for training and validation of the models. The remaining 25% of the patients formed the test dataset, which was used to evaluate the performance of the trained models. This split ensured that there was no overlap between the patient sources of the training-validation and test datasets, thereby preventing data leakage and ensuring an unbiased evaluation.\n\nTo further enhance the reliability of the models, a five-repetition stratified 10-fold cross-validation procedure was implemented during the training and validation phase. This technique involved dividing the development dataset into 10 folds, with each fold serving as the validation set once while the remaining folds were used for training. This process was repeated five times to provide a more stable estimate of the model's performance.\n\nThe primary performance metric used for evaluation, comparison, and selection of models was the area under the receiver operating characteristic curve (AUC). This metric provides a single scalar value that summarizes the model's ability to discriminate between the positive and negative classes across all possible classification thresholds. Additionally, precision-recall curves were utilized to evaluate the trade-off between precision and sensitivity at defined thresholds, offering insights into the model's performance, especially in imbalanced datasets. Calibration plots were also employed to compare the models' probabilistic predictions with the true probability of the postmastectomy radiotherapy (PMRT) recommendation. Perfect calibration is indicated by a plot that aligns with a 45-degree line, signifying that the predicted probabilities closely match the actual outcomes.",
  "evaluation/measure": "The performance of the prediction models was primarily evaluated using the area under the receiver operating characteristic curve (AUC). This metric is widely recognized and used in the literature for assessing the discriminative ability of binary classification models. Additionally, precision-recall curves were utilized to evaluate the trade-off between precision and sensitivity at various thresholds, providing a more nuanced understanding of the model's performance, especially in imbalanced datasets.\n\nCalibration plots were also employed to compare the models' probabilistic predictions with the true probability of postmastectomy radiotherapy (PMRT) recommendation. Perfect calibration is indicated by a 45-degree line in these plots, ensuring that the predicted probabilities align closely with the actual outcomes. This is crucial for clinical decision-making, as it ensures that the model's predictions are reliable and trustworthy.\n\nThese performance metrics collectively provide a comprehensive evaluation of the models, covering aspects of discrimination, precision, and calibration. The use of AUC, precision-recall curves, and calibration plots is consistent with established practices in the field, ensuring that the reported performance is both robust and representative of the model's true capabilities.",
  "evaluation/comparison": "In our study, we compared several machine learning algorithms to predict the need for postmastectomy radiotherapy (PMRT). The algorithms included logistic regression (LR), elastic net (EN), logistic lasso (LL), and random forest (RF). These methods were chosen because they are standard in the field of machine learning and statistics.\n\nLogistic regression served as a baseline model, providing a simple and interpretable approach. Elastic net and logistic lasso were used for their ability to perform regularization, which helps in selecting important features and preventing overfitting. Elastic net, in particular, combines the penalties of lasso and ridge regression, allowing it to handle correlated features effectively. Random forest, on the other hand, is a powerful ensemble method that can capture complex, nonlinear relationships in the data.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets, as our focus was on developing a model tailored to our specific clinical context. However, we did compare the performance of different algorithms within our dataset. The performance was evaluated using metrics such as the area under the receiver operating characteristic curve (AUC), precision, and calibration. These evaluations helped us select the most accurate and reliable model for predicting PMRT recommendations.\n\nThe random forest model demonstrated high performance but offered little interpretability. In contrast, elastic net and logistic lasso provided a balance between parsimony and accuracy, making them more suitable for clinical application. Ultimately, we selected elastic net for the online nomogram due to its simplicity and effectiveness in handling correlated features.\n\nIn summary, while we did not compare our methods to publicly available benchmarks, we conducted a thorough comparison of different machine learning algorithms within our dataset. This approach allowed us to identify the most appropriate model for predicting PMRT recommendations in our clinical setting.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of the prediction models focused on the area under the receiver operating characteristic curve (AUC) as the primary performance metric. This metric provides a comprehensive measure of the model's ability to distinguish between patients who require postmastectomy radiotherapy (PMRT) and those who do not. Additionally, precision-recall curves were used to assess the trade-off between precision and sensitivity at various thresholds, offering a more detailed view of the model's performance, especially in imbalanced datasets.\n\nTo ensure the robustness of the results, a five-repetition stratified 10-fold cross-validation procedure was employed. This method helps in mitigating the risk of overfitting and provides a more reliable estimate of the model's performance by training and validating the model on different subsets of the data. The entire cohort was split into a development dataset (75% of patients) and a test dataset (25% of patients), with no overlap between the two, ensuring an unbiased evaluation.\n\nCalibration plots were also utilized to compare the models' probabilistic predictions with the true PMRT recommendation probability. Perfect calibration is indicated by a 45-degree line in the plot, and deviations from this line can highlight any discrepancies between predicted probabilities and actual outcomes.\n\nWhile the specific confidence intervals for the performance metrics were not explicitly mentioned, the use of cross-validation and the separation of training and test datasets suggest a rigorous approach to evaluating model performance. The statistical significance of the results was not detailed, but the comprehensive evaluation methods employed indicate a high level of confidence in the models' predictive capabilities. The models were compared using standard algorithms, and the use of multiple evaluation metrics ensures a thorough assessment of their performance.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The data collected includes various metrics and measurements related to tumor characteristics, lymph node examination, and patient information. These files are not intended for public release due to privacy and confidentiality concerns. Access to the raw data is restricted to ensure the protection of sensitive patient information. Therefore, the files are not hosted on any public platform and are not distributed under any specific license. Researchers or institutions interested in accessing the data for collaborative purposes may need to contact the authors directly to discuss potential data-sharing agreements."
}