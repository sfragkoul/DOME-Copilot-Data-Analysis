{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- Cooper, who led the research and development of the machine-learning models to predict high-risk recipients for developing GVHD after liver transplantation.\n- Other authors who contributed to the study include those involved in data collection, statistical analysis, and validation of the models. However, their specific contributions and full names are not provided in the available information.",
  "publication/journal": "Liver Transplantation",
  "publication/year": "2022",
  "publication/pmid": "34587357",
  "publication/pmcid": "PMC9297869",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Liver Transplant\n- Graft-versus-host disease (GVHD)\n- Machine Learning\n- Predictive Modeling\n- Transplant Outcomes\n- Donor-Recipient Matching\n- Statistical Analysis\n- Fraud Detection Techniques\n- Survival Analysis\n- Immunosuppression",
  "dataset/provenance": "The dataset used in this study originates from a single center, the University of Washington Medical Center. The data comprises 1938 consecutive orthotopic liver transplant (OLT) recipients who underwent transplantation between January 17, 1996, and April 13, 2019. This dataset was used to construct machine-learning algorithms aimed at predicting the risk of graft-versus-host disease (GVHD) in liver transplant recipients.\n\nThe dataset includes recipient-specific, donor-specific, and transplant-specific characteristics available at the time of OLT. Variables were selected based on prior published studies on the development of GVHD and survival after OLT. These variables include blood type ABO matching, cytomegalovirus (CMV) and Epstein-Barr virus (EBV) serostatus matching, age differences, and donor race/ethnicity to recipient race/ethnicity matching. Human leukocyte antigen (HLA) combinations for each HLA loci were also evaluated for both recipient and donor mismatches.\n\nThe dataset was split into a training set and a test set using a 70/30 random split to preserve the proportion of GVHD in both sets. The training set consisted of 1358 recipient observations, with 14 (1.0%) having GVHD. The test set had 580 observations, with 5 (0.7%) recipients with GVHD. To balance the training set for the final training of the algorithms, the set consisted of 1362 (50.1%) observations without GVHD and 1354 (49.9%) observations with GVHD.\n\nAdditionally, a validation dataset was collected from 75 consecutive recipients who underwent OLT from May 1, 2019, to May 1, 2020. This validation dataset was used to evaluate the performance of the developed models on data that was not seen during the training and test phases.",
  "dataset/splits": "The dataset was split into three parts: a training set, a test set, and a validation set. The initial split was a 70/30 division of the study dataset, resulting in 1358 recipient observations in the training set and 580 in the test set. The training set had 14 recipients with GVHD (1.0%) and the test set had 5 recipients with GVHD (0.7%). To balance the training set for the final training of the algorithms, it was adjusted to consist of 1362 observations without GVHD (50.1%) and 1354 observations with GVHD (49.9%). The validation set, collected after the algorithms were developed, consisted of 75 donor-recipient pairs. This set was used to evaluate the models on data that the algorithms had not previously seen.",
  "dataset/redundancy": "The dataset used in this study consisted of 1938 liver transplant recipients, with only 19 (1.0%) developing graft-versus-host disease (GVHD). To address the imbalance, the dataset was split into a training set and a test set using a 70/30 random split, preserving the proportion of GVHD cases in both sets. The training set contained 1358 recipient observations, with 14 (1.0%) having GVHD, while the test set had 580 observations, with 5 (0.7%) recipients with GVHD.\n\nTo enhance the learning process of the classification algorithms, the training set was balanced by oversampling recipients with GVHD and undersampling those without. This resulted in a balanced training set of 1362 (50.1%) observations without GVHD and 1354 (49.9%) observations with GVHD. The test set remained unbalanced to simulate real-world conditions.\n\nThe independence of the training and test sets was enforced through the random split, ensuring that no data from the test set was used during the training phase. This approach helps in evaluating the generalizability of the models.\n\nThe distribution of the dataset, with a rare occurrence of GVHD, is comparable to other medical datasets where the event of interest is infrequent. This rarity necessitates the use of techniques like oversampling and anomaly detection to build effective predictive models. The use of a validation dataset collected from a different time period further ensures that the models are evaluated on data that was not seen during training, providing a robust assessment of their performance.",
  "dataset/availability": "The data used in this study is not publicly available. The study involved a retrospective analysis of clinical features of 1938 recipients who underwent orthotopic liver transplantation (OLT) at the University of Washington Medical Center (UWMC) from January 17, 1996, to April 13, 2019. Additionally, a validation dataset of 75 consecutive recipients who underwent OLT from May 1, 2019, to May 1, 2020, was collected. The data included recipient-specific, donor-specific, and transplant-specific characteristics available at the time of OLT.\n\nThe study data set was split into a training set and a test set using a 70/30 random split to preserve the proportion of GVHD in both sets. The training set was balanced by oversampling recipients with GVHD and undersampling those without GVHD. The test set remained unbalanced. The validation data set was collected after the algorithms were developed and scored on the test set to determine how the models would perform on data never seen by the algorithms.\n\nThe data was analyzed using various machine-learning algorithms, including logistic regression, neural networks, generalized gradient boosting machines, extreme gradient boosting trees, adaptive boosting, and C5.0. The caret package in R was used to build these classification algorithms, and hyperparameter tuning was performed using a grid search and 10-fold cross-validation.\n\nThe study was approved by the Institutional Review Board of the Human Subjects Division at the University of Washington. The data was collected and analyzed in accordance with the ethical guidelines and regulations set by the institution. The results of the study were published in a scientific journal, and the content is solely the responsibility of the authors. The data itself is not released in a public forum due to privacy and ethical considerations.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. They include logistic regression, neural networks, gradient boosting machines (GGBM), regularized gradient boosting trees, adaptive boosting, and C5.0. These algorithms are part of the caret package, which is a popular tool in R for building and evaluating predictive models.\n\nThe algorithms employed are not new; they have been extensively used and validated in various domains, including medical research. The choice of these algorithms was driven by their proven effectiveness in handling complex datasets and their ability to provide robust predictions. The study focused on applying these algorithms to predict the risk of graft-versus-host disease (GVHD) in liver transplant recipients, rather than developing new algorithms.\n\nThe decision to use these established algorithms was strategic. The primary goal was to develop a reliable predictive model for GVHD, leveraging the strengths of well-known machine-learning techniques. The algorithms were selected based on their performance in initial tests and their suitability for the specific dataset and research objectives. The study aimed to demonstrate the practical application of these algorithms in a clinical setting, rather than introducing novel machine-learning methods.\n\nThe algorithms were evaluated using a comprehensive approach, including hyperparameter tuning through grid search and 10-fold cross-validation. This process ensured that the models were optimized for the dataset and could generalize well to new data. The performance of the algorithms was assessed using metrics such as the area under the receiver operating characteristic curve (AUROC), sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). The best-performing algorithms were then validated on a separate dataset to confirm their predictive accuracy.\n\nIn summary, the machine-learning algorithms used in this study are established and widely recognized. They were chosen for their proven effectiveness and suitability for the research objectives. The focus was on applying these algorithms to develop a reliable predictive model for GVHD in liver transplant recipients, rather than introducing new machine-learning methods.",
  "optimization/meta": "In our study, we employed a meta-predictor approach, specifically a heterogenous ensemble model, which combines the predictions of multiple machine-learning algorithms to enhance overall performance. This meta-predictor leverages the strengths of various individual models to improve the accuracy and robustness of our predictions.\n\nThe heterogenous ensemble model integrates several machine-learning methods, including generalized logistic regression, neural networks, gradient boosting machines (GGBM), regularized gradient boosting trees, adaptive boosting, and C5.0 algorithms. Each of these algorithms contributes unique insights and patterns recognized from the data, which are then aggregated to form a more comprehensive and reliable prediction.\n\nTo ensure the independence of the training data, we utilized a validation data set that was collected after the development and initial testing of our models. This validation set included 75 consecutive donor-recipient pairs who underwent orthotopic liver transplantation (OLT) at our center. The data from this validation set were collected at a later time than the training and test sets, ensuring that the models were evaluated on data they had never seen before. This approach helps to mitigate the risk of overfitting and ensures that our models generalize well to new, unseen data.\n\nThe performance of the heterogenous ensemble model was particularly notable on the validation data set, where it demonstrated high accuracy and a low detection prevalence. This indicates that the model effectively captures the relevant patterns in the data without being overly influenced by any single algorithm's biases or limitations. The use of a meta-predictor in this manner allows us to leverage the collective wisdom of multiple algorithms, leading to more reliable and clinically useful predictions for identifying recipients at high risk for developing graft-versus-host disease (GVHD) after OLT.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to prepare the dataset for the machine-learning algorithms. We began by selecting variables based on prior research and our own analyses, including donor-recipient combinations, HLA mismatches, and other relevant clinical factors. These variables were encoded to ensure compatibility with the machine-learning models.\n\nFor categorical variables, such as blood type matching and HLA combinations, we used one-hot encoding to convert them into a format that the algorithms could interpret. This involved creating binary columns for each category, allowing the models to understand the relationships between different categories.\n\nNumerical variables, like age differences and body mass index (BMI), were standardized to have a mean of zero and a standard deviation of one. This process, known as z-score normalization, helped to ensure that all numerical features contributed equally to the model's predictions, regardless of their original scales.\n\nTo address the imbalance in our dataset, where only a small percentage of recipients developed GVHD, we employed techniques such as oversampling and undersampling. Specifically, we balanced the training set by oversampling recipients with GVHD and undersampling those without, resulting in an equal number of cases and controls. This step was essential for improving the performance of our classification algorithms.\n\nAdditionally, we performed a 70/30 split of the dataset into training and test sets, preserving the proportion of GVHD cases in both subsets. The training set was further balanced, while the test set remained unbalanced to reflect real-world conditions.\n\nWe also utilized the Boruta algorithm to identify the most important variables for predicting GVHD. Variables selected by Boruta, along with those from our chi-square analysis with a P value \u22640.20, were included in the final models. This dimension-reduction strategy helped to enhance the performance and interpretability of our machine-learning algorithms.\n\nIn summary, our data encoding and preprocessing involved one-hot encoding for categorical variables, z-score normalization for numerical variables, and techniques to address data imbalance. These steps were essential for preparing the dataset and improving the performance of our machine-learning models in predicting GVHD risk.",
  "optimization/parameters": "The model utilized a subset of variables determined through a dimension-reduction strategy. This strategy involved selecting important variables confirmed by the Boruta algorithm and variables from a chi-square analysis with a P value of 0.20 or less. The final set of variables used in the machine-learning algorithms is detailed in a specific table. The study dataset was unbalanced due to the rare occurrence of GVHD, with only 19 out of 1938 recipients developing the condition. After splitting the dataset into training and test sets, and subsequently balancing the training set, each classification algorithm was trained on this balanced dataset. The exact number of parameters used in the model is not explicitly stated, but the process involved a thorough selection method to ensure the most relevant variables were included.",
  "optimization/features": "In our study, we employed a dimension-reduction strategy to select important variables for our machine-learning algorithms. This process involved using the Boruta algorithm and variables from our chi-square analysis with a P value \u22640.20. The specific variables used in the machine-learning algorithms are detailed in Table 4. Feature selection was indeed performed, and it was conducted using the training set only. This approach ensured that the selected features were relevant and contributed to the predictive power of our models. The total number of features used as input is not explicitly stated, but the selection process aimed to include only the most significant variables to enhance model performance.",
  "optimization/fitting": "In our study, we employed several machine-learning algorithms to predict the risk of developing GVHD after liver transplantation. The number of parameters in our models was indeed larger than the number of training points, particularly due to the rarity of GVHD cases. To address potential overfitting, we implemented several strategies.\n\nFirstly, we used a grid search with 10-fold cross-validation to tune the hyperparameters of each algorithm. This process helped in selecting the best hyperparameters that generalized well to unseen data, rather than just fitting the training data.\n\nSecondly, we balanced the training set by oversampling recipients with GVHD and undersampling those without GVHD. This balancing act ensured that our models were not biased towards the majority class and could effectively learn from the minority class.\n\nAdditionally, we used the Boruta algorithm to select the most important variables for predicting GVHD. This dimension-reduction strategy helped in reducing the complexity of our models and focusing on the most relevant features.\n\nTo further mitigate overfitting, we evaluated the performance of our models on a separate test set that was not used during training. This allowed us to assess the generalization capability of our models on unseen data.\n\nMoreover, we collected a validation data set from a different time period to evaluate the performance of our models on data that was not seen during the training and test phases. This validation step provided an additional layer of confidence in the robustness of our models.\n\nRegarding underfitting, we chose a diverse set of algorithms, including logistic regression, neural networks, gradient boosting machines, and ensemble methods. This diversity ensured that we covered a wide range of model complexities, reducing the risk of underfitting.\n\nFurthermore, we monitored the performance metrics such as AUROC, sensitivity, specificity, positive predictive value, and negative predictive value. These metrics provided a comprehensive evaluation of our models' performance and helped in identifying any signs of underfitting.\n\nIn summary, our approach to fitting the models involved careful hyperparameter tuning, data balancing, feature selection, and rigorous validation on separate data sets. These steps collectively helped in addressing both overfitting and underfitting concerns.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was hyperparameter tuning through grid search and 10-fold cross-validation. This process helped in selecting the optimal hyperparameters for each algorithm, thereby reducing the risk of overfitting to the training data.\n\nAdditionally, we utilized a validation dataset collected after the algorithms were developed and tested. This dataset included 75 donor-recipient pairs and was used to evaluate the models' performance on data that the algorithms had never seen before. This approach helped in assessing the generalizability of our models and mitigating the risk of overfitting.\n\nWe also addressed the issue of variable importance inflation by using multiple algorithms. By having seven different algorithms, we reduced the concern that an insignificant predicting variable might dominate model performance. This ensemble approach ensured that the models were not overly reliant on any single variable, further enhancing their robustness.\n\nMoreover, we balanced the training dataset to handle the rare occurrence of GVHD. The training set was balanced to have an equal number of observations with and without GVHD, which helped in training more reliable models that could generalize better to new data.\n\nIn summary, our study incorporated grid search with cross-validation, a separate validation dataset, an ensemble of multiple algorithms, and data balancing to prevent overfitting and improve the overall performance and generalizability of our predictive models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are available and can be accessed through our Clinical and Bio-analytic Transplant Laboratory Web site. The specific details of the hyper-parameter tuning process, including the grid search and 10-fold cross-validation methods, are described in the publication. The models developed, such as logistic regression, neural network, GGBM, regularized gradient boosting tree, adaptive boosting, and C5.0, each have their respective methods and hyper-parameters that were optimized for the best performance on the training dataset.\n\nThe model files and optimization parameters are not directly provided in the publication but can be inferred from the methods described. The algorithms were trained on a balanced training set after determining the best hyper-parameters for each algorithm. The performance metrics, including AUROC, specificity, positive predictive value (PPV), and negative predictive value (NPV), were recorded for each model. The best-performing algorithms, such as logistic regression, heterogenous ensemble, and GGBM, were identified based on their performance on the validation dataset.\n\nThe data and models are intended for use in a healthcare setting and are designed to be integrated into electronic health records (EHRs) for continuous improvement. The algorithms are available for use by other institutions, and the important variables for predicting GVHD are listed in the publication and on the web site. The use of these models and data is subject to the terms and conditions specified on the web site, which include appropriate licensing and ethical considerations for medical research and practice.",
  "model/interpretability": "The models developed in our study are not entirely black-box, as we have employed several algorithms that offer varying degrees of interpretability. For instance, logistic regression is a transparent model, providing clear insights into the relationship between the input variables and the output. The coefficients in logistic regression indicate the direction and strength of the association between each predictor and the likelihood of developing GVHD.\n\nThe C5.0 algorithm, another model used, builds decision trees or rule sets, which are inherently interpretable. These trees split the data based on the most significant predictors, making it easy to trace the decision-making process. Each split in the tree represents a condition based on a variable, and the path from the root to a leaf node provides a clear set of rules that lead to a prediction.\n\nHowever, some of the models, such as neural networks and gradient boosting machines (GGBM), are more complex and can be considered less interpretable. These models often involve multiple layers and interactions between variables, making it challenging to trace the exact path that leads to a prediction. Nevertheless, techniques like feature importance scores can be used to understand which variables contribute most to the model's predictions.\n\nIn summary, while some of our models offer clear interpretability, others are more complex and less transparent. The choice of model depends on the trade-off between predictive performance and the need for interpretability in clinical decision-making.",
  "model/output": "The model developed in our study is a classification model. We utilized the caret package to build various classification algorithms aimed at predicting the risk of graft-versus-host disease (GVHD) in liver transplant recipients. The algorithms included logistic regression, neural networks, gradient boosting machines (GGBM), extreme gradient boosting trees (EGBT), adaptive boosting, and C5.0. Each algorithm was trained using specific methods within the caret package, such as glm for logistic regression and nnet for neural networks.\n\nHyperparameter tuning was performed using grid search and 10-fold cross-validation to optimize the performance of each algorithm on the training dataset. The goal was to label the fewest recipients at high risk while capturing at least 80% of those who develop GVHD. This was achieved by tuning the models to have a sensitivity of 0.80 and the lowest detection prevalence.\n\nThe performance of each algorithm was evaluated on the test dataset using metrics such as the area under the receiver operating characteristic curve (AUROC), specificity, positive predictive value (PPV), and negative predictive value (NPV). The best-performing algorithms were then applied to a validation dataset to assess their generalizability to new, unseen data.\n\nIn the validation dataset, the logistic regression algorithm performed best with an AUROC of 0.96 and a detection prevalence of 0.09. Other top-performing models included the heterogenous ensemble and GGBM, both with AUROCs of 0.93 and detection prevalences of 0.11. These models successfully identified the two recipients who developed GVHD in the validation dataset, demonstrating their effectiveness in predicting high-risk cases.\n\nThe output of our classification models provides valuable insights into the risk factors associated with GVHD development. Key variables identified as important for prediction include recipient age, body mass index (BMI), presence of hepatocellular carcinoma (HCC), and type of induction immunosuppression. These variables were found to have significant relative weights in predicting the risk of developing GVHD.\n\nThe models are designed to be integrated into electronic health records (EHRs) or used through our Clinical and Bio-analytic Transplant Laboratory Web site. This integration allows for real-time risk assessment and potential modification of transplant variables to reduce the risk of GVHD. The models will continue to be updated and improved as more data becomes available, ensuring their relevance and accuracy in clinical practice.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the machine-learning algorithms used in this study is not publicly released. However, the algorithms are accessible through a web server. The machine-learning algorithms are available for use at the Clinical and Bio-analytic Transplant Laboratory Web site. The web address is https://cbatl.shinyapps.io/GVHD. The web site allows users to input relevant data and obtain predictions regarding the risk of developing GVHD. The specific licensing terms for using these algorithms through the web site are not detailed, but it is implied that the algorithms can be used for predictive purposes in a healthcare setting.",
  "evaluation/method": "The evaluation method involved several steps to ensure the robustness and generalizability of the models. Initially, the study data set was split into a training set and a test set using a 70/30 random split, preserving the proportion of recipients who developed GVHD. The training set was then balanced by oversampling recipients with GVHD and undersampling those without, to address the unbalanced nature of the data. This balancing was crucial for the classifier algorithms to learn effectively.\n\nHyperparameter tuning was performed using a grid search and 10-fold cross-validation on the training set. This process helped determine the optimal hyperparameters for each of the seven classification algorithms: logistic regression, neural network, generalized gradient boosting machine (GGBM), extreme gradient boosting tree (EGBT), adaptive boosting, and C5.0. Additionally, a heterogeneous ensemble model was developed by averaging the predictions of the other six algorithms.\n\nEach trained algorithm was then evaluated on the unbalanced test data set. The performance metrics recorded included the area under the receiver operating characteristic curve (AUROC), sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). The goal was to label the fewest recipients at high risk while capturing at least 80% of those who developed GVHD, thus tuning the models to have a sensitivity of 0.80 and the lowest detection prevalence.\n\nTo further validate the models, a separate validation data set was collected from a more recent cohort of 75 recipients, including 2 who developed GVHD. This validation set was used to assess how the models performed on data never seen during the training and test phases. The models were evaluated based on their AUROC and detection prevalence on this validation set, ensuring their applicability to new, unseen data.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to assess the effectiveness of our machine learning models in predicting the risk of GVHD in liver transplant recipients. The primary metric we reported was the Area Under the Receiver Operating Characteristic Curve (AUROC), which provides a comprehensive measure of the model's ability to distinguish between high-risk and low-risk recipients. This metric is widely used in the literature and offers a robust evaluation of model performance, especially in imbalanced datasets like ours.\n\nIn addition to AUROC, we also reported sensitivity, which was set to 0.80 to ensure that at least 80% of recipients who develop GVHD are correctly identified. This is crucial for clinical applications where missing high-risk cases can have severe consequences. Detection prevalence, which measures the proportion of recipients labeled as high risk, was also reported. This metric is important for understanding the practical implications of deploying the model in a clinical setting, as it indicates how many recipients would be flagged for closer monitoring.\n\nWe also included specificity, positive predictive value (PPV), and negative predictive value (NPV) in our evaluation. Specificity measures the proportion of true negatives correctly identified, while PPV and NPV provide insights into the accuracy of the model's predictions for high-risk and low-risk recipients, respectively. These metrics collectively offer a detailed view of the model's performance and help in understanding its strengths and limitations.\n\nThe set of metrics we reported is representative of standard practices in the literature, ensuring that our evaluation is comprehensive and comparable to other studies in the field. By focusing on these key performance indicators, we aimed to provide a clear and thorough assessment of our models' ability to predict GVHD risk accurately and reliably.",
  "evaluation/comparison": "A comparison to simpler baselines was performed. Several machine learning algorithms were developed and compared to predict recipients at high risk for developing GVHD after orthotopic liver transplantation (O LT). These algorithms included logistic regression, neural network, generalized gradient boosting machine (GGBM), extreme gradient boosting tree (EGBT), adaptive boosting, and C5.0. Additionally, a heterogeneous ensemble model was created by combining the predictions of these algorithms.\n\nThe performance of each algorithm was evaluated using the area under the receiver operating characteristic curve (AUROC), sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). The models were ranked by their AUROC values. The C5.0 algorithm had the best AUROC of 0.86 with a sensitivity of 0.80 and a detection prevalence of 0.21 on the test data set. The heterogeneous ensemble model had the second-best AUROC of 0.84, followed by the GGBM with an AUROC of 0.83. The adaptive boosting algorithm could not be tuned to achieve a sensitivity of 0.80 and had an AUROC of 0.72.\n\nOn the validation data set, the logistic regression algorithm performed best with an AUROC of 0.96 and a detection prevalence of 0.09. The heterogeneous ensemble and GGBM models both had AUROCs of 0.93 and detection prevalences of 0.11. These results indicate that the logistic regression, heterogeneous ensemble, and GGBM models were the better predictors on the validation data set.\n\nThe comparison of these algorithms allowed for the identification of the most effective models for predicting high-risk recipients. The best-performing models were then considered for deployment in a healthcare database and on the Clinical and Bio-analytic Transplant Laboratory website. This approach ensures that the most accurate and reliable models are used for clinical decision-making.",
  "evaluation/confidence": "The evaluation of our machine-learning models focused on several key performance metrics, including the area under the receiver operating characteristic curve (AUROC), sensitivity, detection prevalence, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics were calculated for each algorithm on both the test and validation datasets.\n\nThe AUROC values, which indicate the models' ability to distinguish between high-risk and low-risk recipients, were reported for each algorithm. For instance, the C5.0 algorithm achieved the highest AUROC of 0.86 on the test dataset, while logistic regression performed best on the validation dataset with an AUROC of 0.96. These values suggest strong discriminative power, but confidence intervals for these metrics were not explicitly provided in the results. This omission means that while the point estimates of AUROC are high, the precision of these estimates is not quantified.\n\nStatistical significance was assessed using the chi-square test for differences between recipients with and without GVHD. A P-value threshold of less than 0.05 was used to determine significance. This approach ensures that the observed differences in performance metrics are unlikely to have occurred by chance. However, the specific P-values for the performance metrics of individual algorithms were not detailed, making it challenging to assert the statistical superiority of one method over another with absolute certainty.\n\nThe models were tuned to achieve a sensitivity of 0.80, ensuring that at least 80% of recipients who develop GVHD are correctly identified. This high sensitivity is crucial for clinical applications where missing high-risk cases is particularly costly. The detection prevalence, which measures the proportion of recipients labeled as high risk, varied across algorithms but was generally low, indicating that the models are conservative in their predictions.\n\nIn summary, while the performance metrics indicate that the models are effective in predicting GVHD risk, the lack of confidence intervals and detailed P-values for the performance metrics limits the ability to make definitive claims about the statistical significance and superiority of one algorithm over another. Future work could benefit from reporting confidence intervals and conducting more rigorous statistical comparisons to bolster the confidence in these findings.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The evaluation process involved using a test set and a validation set to assess the performance of our machine-learning algorithms. The test set was derived from the original study data, while the validation set consisted of data collected from a later period, specifically from May 1, 2019, to May 1, 2020. This validation set included 75 consecutive recipients who underwent orthotopic liver transplantation (O LT) at the University of Washington Medical Center.\n\nThe evaluation metrics recorded for each model included the area under the receiver operating characteristic curve (AUROC), specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics were crucial in determining the effectiveness of our algorithms in predicting recipients at high risk for developing graft-versus-host disease (GVHD).\n\nWhile the raw evaluation files are not publicly released, the results and the methodologies used are detailed in the publication. The algorithms and their performance are also available for use at the Clinical and Bio-analytic Transplant Laboratory Web site. This web site provides access to the machine-learning algorithms, allowing other researchers and healthcare professionals to utilize them for similar predictive purposes. The variables included in the analysis and on the web site are essential for predicting GVHD and must be used in all analyses."
}