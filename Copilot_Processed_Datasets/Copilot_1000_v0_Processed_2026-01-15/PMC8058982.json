{
  "publication/title": "Prognostic models for 1-year mortality in traumatic brain injury patients undergoing decompressive craniectomy: a machine learning-based approach.",
  "publication/authors": "The authors who contributed to the article are:\n\n- Cui\n- Wu\n- Liu\n- Zhou\n- Hilton\n- Zhao\n- Tian\n- Salsbery\n- Wang\n- Yuan\n- Yang\n- Kolias\n- Adams\n- Timofeev\n- Corteen\n- Pickard\n- Nourallah\n- Menon\n- Zeiler\n- Rughani\n- Dumont\n- Lu\n- Bongard\n- Horgan\n- Penar\n- Folweiler\n- Sandsmark\n- Diaz-Arrastia\n- Cohen\n- Masino\n- Hernandes Rocha\n- Elahi\n- Cristina da Silva\n\nAll authors approved the final manuscript.",
  "publication/journal": "Chinese Neurosurgical Journal",
  "publication/year": "2021",
  "publication/pmid": "33879254",
  "publication/pmcid": "PMC8058982",
  "publication/doi": "10.3171/2019.2.Jns182098",
  "publication/tags": "- Traumatic Brain Injury\n- Decompressive Craniectomy\n- Machine Learning\n- Prognostic Models\n- Mortality Prediction\n- Logistic Regression\n- Random Forest\n- Coagulopathy\n- Glasgow Coma Score\n- Long-term Outcomes",
  "dataset/provenance": "The dataset used in this study was sourced from a registry database maintained at Tangdu Hospital, Fourth Military Medical University. The data were collected from 947 consecutive traumatic brain injury (TBI) patients treated at the hospital between January 1, 2015, and April 25, 2019. However, only 230 patients met the inclusion criteria for the study. These criteria included patients who underwent decompressive craniectomy (DC) with a history of TBI, with specific indications and approaches as described in previous studies. Exclusion criteria included an interval from injury to admission of more than 24 hours, death in the hospital, other severe systemic diseases, and loss to follow-up.\n\nThe dataset included various demographic characteristics, clinical variables, and outcomes. Key variables extracted from the registry database included patient demographic characteristics, Glasgow Coma Score (GCS) upon admission, biochemical tests such as aPTT, INR, platelet counts, D-dimer, fibrinogen, glucose, red blood cell counts, and neutrophil/lymphocyte ratio (NLR). Additionally, initial CT scan characteristics, perioperative bleeding, and worsening neurologic conditions were recorded. These variables were used to define traumatic coagulopathy and to develop prognostic models for predicting 1-year mortality in TBI patients undergoing DC.\n\nThe dataset has not been previously used in other published studies by the community, as this study represents a novel application of machine learning techniques to predict long-term prognosis in TBI patients after DC. The specific focus on patients undergoing DC and the inclusion of detailed clinical and biochemical variables make this dataset unique and valuable for further research in the field of traumatic brain injury.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a testing set. The training set consisted of 172 patients, which accounted for 75% of the total dataset. The testing set comprised the remaining 58 patients, making up 25% of the total dataset. The random seed used for this split was set to 66,511.\n\nThe ratio of non-survivors to survivors in the dataset was 1:2. To balance the training data, the synthetic minority oversampling technique (SMOTE) was employed. This technique was used to address the imbalance in the training set, ensuring that the model could learn effectively from both classes.\n\nThe dataset was further utilized in a 10-fold cross-validation process, repeated three times, to evaluate the performance of the models. This cross-validation was performed using the original 75% of the data that was designated as the training set. The features for the models were selected using the univariate logistic regression method, and hyperparameter optimization was achieved through the grid search method.",
  "dataset/redundancy": "The dataset consisted of 230 patients, which were split into training and testing sets. 172 patients, constituting 75% of the total, were randomly selected for the training set, while the remaining 58 patients, or 25%, were allocated to the testing set. The random seed was set to 66,511 to ensure reproducibility.\n\nThe training and testing sets were designed to be independent. This independence was enforced through the random selection process, ensuring that no patient data was shared between the two sets. The ratio of non-survivors to survivors in the dataset was 1:2. To address this imbalance, the synthetic minority oversampling technique (SMOTE) was applied to the training data, thereby balancing the class distribution.\n\nThe distribution of the dataset is comparable to previously published machine learning datasets in the context of traumatic brain injury (TBI). For instance, a study by Matsuo et al. included 232 patients with TBI, which is very similar to our sample size of 230 patients. This comparison highlights the consistency in sample sizes used in similar research, reinforcing the reliability and generalizability of our findings.",
  "dataset/availability": "The data used in this study is not publicly available. Interested parties should contact the authors directly for data requests. This approach ensures that the data is shared responsibly and in accordance with ethical guidelines. The study was approved by the ethical committee of Tangdu Hospital, Fourth Military Medical University, and consent was waived for this specific research. The authors declare that they have no competing interests, and all authors approved the final manuscript. The data sharing process is managed through direct communication with the research team to maintain data integrity and confidentiality.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is ensemble learning, specifically the random forest model. This model is not new; it is a well-established algorithm in the field of machine learning. The random forest model is a type of ensemble learning method that operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe choice of using the random forest model was driven by its robustness and ability to handle complex datasets, which is crucial for predicting outcomes in traumatic brain injury (TBI) patients. The random forest model is known for its effectiveness in reducing overfitting, handling high-dimensional data, and providing feature importance, which are all beneficial for our prognostic model.\n\nThe reason the random forest model was not published in a machine-learning journal is that our primary focus is on its application in the medical field, specifically for predicting 1-year mortality in TBI patients undergoing decompressive craniectomy. The novelty of our work lies in the application of this established machine-learning technique to a specific medical problem, rather than the development of a new algorithm. Our study aims to demonstrate the practical utility of the random forest model in improving patient outcomes and providing better precision medicine and care directions.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "For the machine-learning algorithm, the data was pre-processed and encoded as follows:\n\nThe dataset consisted of 230 patients, with 172 patients randomly selected for training and 58 patients for testing. The random seed was set to 66,511 to ensure reproducibility. Given the imbalance in the ratio of non-survivors to survivors (1:2), the synthetic minority oversampling technique (SMOTE) was employed to balance the training data.\n\nFeature selection was performed using the univariate logistic regression method. This process helped in identifying the most relevant predictors for the models. For the random tree model, three key parameters were determined: the \"Gini\" impurity criterion, mtry set to 4, and the number of trees set to 100. The mtry value was optimized using a grid search algorithm.\n\nHyperparameter optimization was achieved through the grid search method, ensuring that the models were fine-tuned for optimal performance. The programming language R 3.6.1 and the machine learning tool GraphLab Create were utilized for coding the machine learning models.\n\nCategorical variables were expressed as frequencies and percentages, while continuous variables with skewed distributions were presented as medians and interquartile ranges. This approach ensured that the data was appropriately encoded and pre-processed for the machine-learning algorithms.",
  "optimization/parameters": "In our study, we utilized three parameters for the random tree model. These parameters were determined through a grid optimization algorithm. The specific parameters identified were the \"Gini\" impurity criterion, mtry set to 4, and tree set to 100. The value of mtry was particularly determined using the grid optimization algorithm to ensure optimal performance.",
  "optimization/features": "In our study, we utilized several input features to predict 1-year mortality in patients with traumatic brain injury (TBI) after decompressive craniectomy (DC). The specific features included age, Glasgow Coma Scale (GCS) score, D-dimer levels, coagulopathy status, use of noradrenaline to treat hypotension, and the presence of completely effaced basal cisterns.\n\nFeature selection was performed using the univariate logistic regression method. This process was conducted exclusively on the training dataset to ensure that the model's performance on the test data remained unbiased. By focusing on the training data, we aimed to identify the most relevant predictors for 1-year mortality, thereby enhancing the model's predictive accuracy and generalizability.",
  "optimization/fitting": "The study involved 230 patients, with 172 used for training and 58 for testing. The number of parameters in the models was not excessively large compared to the number of training points. To prevent overfitting, several techniques were employed. First, a 10-fold cross-validation repeated three times was performed on the training data. This method helps to ensure that the model generalizes well to unseen data by training and validating on different subsets of the data. Additionally, feature selection was conducted using univariate logistic regression, which helps to identify the most relevant predictors and reduces the risk of overfitting by excluding irrelevant features. Hyperparameter optimization was achieved through grid search, which systematically works through multiple combinations of parameter tunes to determine the optimal settings for the model. For the random tree model, specific parameters were determined, including the \"Gini\" impurity criterion, mtry = 4, and tree = 100, which were optimized using a grid optimization algorithm. These steps collectively helped to mitigate overfitting.\n\nTo address underfitting, the synthetic minority oversampling technique (SMOTE) was used to balance the training data, ensuring that the model had sufficient examples of both non-survivors and survivors. This technique helps to prevent the model from being too simplistic and missing important patterns in the data. Furthermore, the comparison of logistic regression and random tree models provided a robust evaluation of model performance, ensuring that the chosen models were not underfitting the data. The performance metrics, including accuracy, sensitivity, specificity, and AUC, were thoroughly evaluated on both training and testing data, providing a comprehensive assessment of the models' predictive capabilities.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method used was the synthetic minority oversampling technique (SMOTE), which helped balance the training data by addressing the class imbalance between survivors and non-survivors. This technique is crucial for preventing the model from becoming biased towards the majority class.\n\nAdditionally, we utilized 10-fold cross-validation, repeated three times, to evaluate the performance of our models. This approach helps in assessing the model's generalization ability by ensuring that each data point is used for both training and validation across multiple iterations.\n\nFeature selection was another important step in our process. We applied the univariate logistic regression method to select relevant features, which helped in reducing the complexity of the model and preventing overfitting by excluding irrelevant or redundant variables.\n\nFor hyperparameter optimization, we employed the grid search method. This systematic approach allowed us to find the optimal set of hyperparameters for our random tree model, which included parameters such as the \"Gini\" impurity criterion, mtry, and the number of trees. By tuning these parameters, we aimed to improve the model's performance and reduce the risk of overfitting.\n\nOverall, these techniques collectively contributed to building more reliable and generalizable models for predicting 1-year mortality in patients with traumatic brain injury.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the publication. Specifically, for the random tree model, three key parameters were determined: the \"Gini\" impurity criterion, mtry set to 4, and the number of trees set to 100. The mtry value was optimized using a grid optimization algorithm.\n\nThe optimization schedule involved 10-fold cross-validation, repeated three times, to ensure robust performance evaluation. Feature selection was conducted using the univariate logistic regression method. Hyperparameter optimization was achieved through the grid search method.\n\nThe model files and specific details about the implementation are not directly provided in the publication. However, the methods and tools used, such as the programming language R (version 3.6.1) and the machine learning tool GraphLab Create, are mentioned. These tools are open-source and widely available, allowing for reproducibility of the methods described.\n\nThe data used in this study is not publicly available, but interested parties can contact the authors for data requests. The study was conducted in accordance with ethical guidelines, and the necessary approvals were obtained. The consent for publication was waived as per the ethical committee's guidelines.\n\nThe code and specific model files are not shared publicly, but the methods and parameters are detailed enough for replication by other researchers familiar with the tools and techniques used.",
  "model/interpretability": "The model employed in our study is not entirely a black box, as we have taken steps to ensure interpretability. We utilized a random forest model, which, while complex, offers insights into feature importance. Through the random forest algorithm, we identified the most significant predictors for 1-year mortality: age, Glasgow Coma Score (GCS), and D-dimer levels. These predictors were ranked based on their importance, providing a clear understanding of which factors most influence the model's predictions.\n\nAdditionally, we constructed a nomogram that incorporates all independent predictors identified in the multivariate regression analysis. This nomogram assigns a score to each parameter, ranging from 0 to 100, and sums these scores to yield a total score. This total score is then converted into an individual probability of 1-year mortality, ranging from 1% to 99%. The nomogram serves as a transparent tool, allowing clinicians to intuitively predict 1-year mortality based on the condition of the patients.\n\nBy using these methods, we aimed to balance the complexity of the random forest model with the need for interpretability, ensuring that the model's predictions are not only accurate but also understandable and actionable for clinical use.",
  "model/output": "The model developed in our study is primarily a classification model. It is designed to predict the probability of 1-year mortality in patients with traumatic brain injury (TBI) who have undergone decompressive craniectomy (DC). The model uses various predictors, such as age, Glasgow Coma Scale (GCS) score, D-dimer levels, coagulopathy, hypotension, and completely effaced basal cisterns, to classify patients into survivors and non-survivors.\n\nWe employed both logistic regression and random forest models to achieve this classification. The logistic regression model provides a straightforward approach to binary classification, while the random forest model offers a more complex, ensemble-based method that can capture intricate relationships within the data. The performance of these models was evaluated using metrics such as accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC).\n\nThe random forest model demonstrated superior performance, particularly in terms of accuracy, sensitivity, and specificity, both on the training and testing datasets. This suggests that the random forest model is more effective in predicting 1-year mortality in TBI patients undergoing DC. The AUC values for the random forest model were notably high, indicating strong discriminative ability.\n\nIn summary, the model is a classification model aimed at predicting 1-year mortality in TBI patients post-DC, with the random forest model showing the best predictive performance.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method involved a comprehensive approach to assess the performance of the prognostic models. The dataset consisted of 230 patients, which was split into training and testing sets with a 75% to 25% ratio, respectively. A random seed of 66,511 was used to ensure reproducibility. Given the imbalance in the ratio of non-survivors to survivors (1:2), the synthetic minority oversampling technique (SMOTE) was employed to balance the training data.\n\nTo evaluate the models, a 10-fold cross-validation was performed three times using the original 75% of the data designated as the training set. Feature selection was conducted using the univariate logistic regression method, and hyperparameter optimization was achieved through the grid search method. For the random tree model, specific parameters were determined, including the \"Gini\" impurity criterion, mtry = 4, and tree = 100. The number of mtry was optimized using a grid optimization algorithm.\n\nThe predictive performance of the logistic regression and random tree models was compared based on accuracy, sensitivity, specificity, and the area under the curve (AUC). The AUCs of the two models on the testing data were derived from back-substituting the training set into the models. The definitions of accuracy, sensitivity, and specificity were referenced from a previous study.\n\nStatistical analysis involved expressing categorical variables as frequencies and percentages, and continuous variables with skewed distributions as medians and interquartile ranges. The importance of each predictor for 1-year mortality was identified using the random forest algorithm, highlighting age, GCS, and D-dimer as the most significant predictors. The receiver operating characteristic (ROC) curves and AUC were calculated to evaluate the discriminative ability of the models. The prediction performance was further assessed using 10-fold cross-validation on the training data.",
  "evaluation/measure": "In our evaluation, we reported several key performance metrics to assess the effectiveness of our models. These metrics include accuracy, sensitivity, specificity, and the area under the curve (AUC). Accuracy measures the overall correctness of the model's predictions, sensitivity (or recall) indicates the model's ability to identify true positive cases, and specificity measures the model's ability to identify true negative cases. The AUC provides a single scalar value that summarizes the performance of the model across all classification thresholds.\n\nWe evaluated these metrics on both training and testing datasets. For the logistic regression model, we initially reported metrics before applying the Synthetic Minority Over-sampling Technique (SMOTE) to balance the training data. After applying SMOTE, we again reported the metrics to show the impact of data balancing on model performance.\n\nAdditionally, we used 10-fold cross-validation to ensure the robustness of our results. This technique helps in assessing how the model will generalize to an independent dataset. We also compared our results with those from similar studies in the literature, noting that our findings are consistent with other research that highlights the importance of certain predictors like age and GCS score.\n\nThe reported metrics are representative of standard practices in the field, providing a comprehensive view of model performance. The inclusion of AUC, in particular, is crucial as it offers a more nuanced understanding of the model's discriminative ability compared to accuracy alone. Overall, these metrics collectively provide a thorough evaluation of our models' predictive capabilities.",
  "evaluation/comparison": "In our study, we conducted a performance comparison between logistic regression and random tree models to predict 1-year mortality in patients with traumatic brain injury (TBI) after decompressive craniectomy (DC). We did not use publicly available benchmark datasets for this comparison. Instead, we utilized our own dataset consisting of 230 patients, which was split into training and testing sets.\n\nFor the training data, we used 172 patients (75% of the total), and for testing, we used the remaining 58 patients (25%). To address the imbalance in the ratio of non-survivors to survivors (1:2), we employed the synthetic minority oversampling technique (SMOTE) to balance the training data.\n\nWe performed 10-fold cross-validation, repeated three times, on the training data to evaluate the models' performance. Feature selection was carried out using the univariate logistic regression method. Hyperparameter optimization was achieved through the grid search method. For the random tree model, we determined three key parameters: \"Gini\" impurity criterion, mtry = 4, and tree = 100. The number of mtry was determined by a grid optimization algorithm.\n\nWe evaluated the models based on accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). The performance metrics for both models on the training and testing data are detailed in our results. This comparison allowed us to assess the effectiveness of the random tree model against the logistic regression model in predicting 1-year mortality in TBI patients undergoing DC.",
  "evaluation/confidence": "The evaluation of our models included several performance metrics such as accuracy, sensitivity, specificity, and the area under the curve (AUC). These metrics were calculated for both the training and testing datasets, providing a comprehensive view of the models' performance.\n\nThe logistic regression model, before applying SMOTE, achieved an overall accuracy of 0.750 on the training data and 0.672 on the testing data. The sensitivity and specificity were also reported, with the model showing a sensitivity of 1.000 on the testing data at the optimal cutoff point. The AUC for the logistic regression model was 0.770 on the training data and 0.765 on the testing data.\n\nAfter balancing the training data using SMOTE, the logistic regression model's performance improved slightly. On the training data, the model achieved an overall accuracy of 0.756, with a sensitivity of 0.615 and a specificity of 0.817. On the testing data, the model's accuracy was 0.741, with a sensitivity of 0.889 and a specificity of 0.675. The AUC for the SMOTE-balanced logistic regression model was 0.760 on the training data and 0.843 on the testing data.\n\nThe random forest model demonstrated superior performance compared to the logistic regression model. On the training data, the random forest model achieved an overall accuracy of 0.983, with a sensitivity of 1.000 and a specificity of 0.975. The AUC for the random forest model was 0.998 on the training data. On the testing data, the model's accuracy was 0.810, with a sensitivity of 0.833 and a specificity of 0.800. The AUC for the random forest model on the testing data was 0.830.\n\nThe performance metrics for the random forest model indicate that it is a valuable and accurate model for predicting 1-year mortality in patients with traumatic brain injury (TBI) after decompressive craniectomy (DC). The random forest model's higher accuracy, sensitivity, and specificity on both the training and testing data suggest that it is superior to the logistic regression model. The AUC values further support the random forest model's superior performance, particularly on the testing data.\n\nThe statistical significance of the results was assessed using p-values. For example, the odds ratios for age, GCS score, and D-dimer were found to be statistically significant, with p-values less than 0.001. This indicates that these variables are important predictors of 1-year mortality in TBI patients after DC. The use of noradrenaline to treat hypotension and the presence of completely effaced basal cisterns were also found to be statistically significant predictors.\n\nIn summary, the performance metrics and statistical significance of the results provide strong evidence that the random forest model is superior to the logistic regression model for predicting 1-year mortality in TBI patients after DC. The high accuracy, sensitivity, specificity, and AUC values, along with the statistically significant p-values, support the reliability and validity of the random forest model's predictions.",
  "evaluation/availability": "Not enough information is available."
}