{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- Su ZP\n- Mao WJ\n- Li B\n- Zheng ZZ\n- Yang B\n- Ren MY\n- Feng HM\n- Song TN\n- Meng YQ\n\nThe specific contributions of the authors are as follows:\n\nSu ZP, Mao WJ, and Li B conceived and designed the study. Su ZP and Mao WJ performed the experiments. Su ZP, Mao WJ, Zheng ZZ, Yang B, and Ren MY analyzed the data. Feng HM, Song TN, and Meng YQ contributed analysis tools. Su ZP, Mao WJ, and Li B provided critical inputs on design, analysis, and interpretation of the study. All the authors had access to the data. All authors read and approved the final manuscript as submitted.",
  "publication/journal": "Chin J Lung Cancer",
  "publication/year": "2022",
  "publication/pmid": "35477188",
  "publication/pmcid": "PMC9051300",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Lung cancer\n- Early-stage lung adenocarcinoma\n- Invasive adenocarcinoma\n- Minimally invasive adenocarcinoma\n- Adenocarcinoma in situ\n- Artificial intelligence\n- Deep learning\n- 3D convolutional neural networks\n- Medical imaging\n- Diagnostic accuracy\n- Confusion matrix\n- ROC curve\n- AUC\n- Patient characteristics\n- CT imaging\n- Pulmonary nodules\n- Diagnostic tools\n- Machine learning\n- Radiology\n- Oncology",
  "dataset/provenance": "The dataset utilized in this study is sourced from a collection of over 10,000 lung nodule cases. These cases originate from renowned lung specialty hospitals and tertiary hospitals within the country. The primary focus of the dataset is on ground-glass nodules and sub-centimeter nodules. The dataset includes both imaging data and corresponding pathological results. This extensive dataset has been used to train and validate an artificial intelligence-assisted diagnostic system for lung nodules. The system leverages various algorithms, including three-dimensional convolutional neural networks, to process and analyze the imaging data. The goal is to enhance the diagnostic efficiency and accuracy of early-stage lung adenocarcinoma by predicting the subtype of lung nodules. The dataset's richness and diversity are crucial for the system's ability to provide valuable references for clinical diagnostic and treatment planning.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is deep learning, specifically convolutional neural networks (CNNs). We employed a three-dimensional convolutional neural network (3D CNN) as part of our artificial intelligence system for assisting in the diagnosis of lung nodules. This system was trained on a large dataset of lung nodule images and pathological results from renowned pulmonary specialty hospitals and tertiary hospitals.\n\nThe algorithm is not entirely new, as CNNs are widely used in various image processing tasks. However, our implementation incorporates attention mechanisms, which are relatively novel in this context. Attention mechanisms help the model focus on the most relevant parts of the input data, thereby improving the efficiency and accuracy of the task at hand.\n\nThe reason this algorithm was not published in a machine-learning journal is that our primary focus is on the application of this technology in the medical field, specifically in the diagnosis of early-stage lung adenocarcinoma. Our study aims to demonstrate the clinical value of this artificial intelligence-assisted diagnostic system in predicting the invasive subtypes of early lung adenocarcinoma. This application is more aligned with medical and clinical research journals, which is where we chose to publish our findings.",
  "optimization/meta": "The model employed in this study is not a meta-predictor. It primarily relies on a deep learning approach, specifically a 3D Convolutional Neural Network (3D CNN) enhanced with attention mechanisms. This model directly processes medical imaging data, such as CT scans, to predict the infiltration subtypes of early lung adenocarcinoma.\n\nThe 3D CNN model is trained on a dataset consisting of over 10,000 cases of lung nodules, primarily ground-glass nodules and sub-centimeter nodules, sourced from renowned pulmonary specialty hospitals and tertiary hospitals. The training data includes both imaging data and pathological results, which the model uses to learn and make predictions.\n\nThe attention mechanisms within the 3D CNN allow the model to assign different weights to various parts of the input data, thereby extracting more critical and relevant information. This enhances the model's efficiency and accuracy in processing tasks.\n\nThe performance of the model is evaluated using metrics such as accuracy, recall, F1 score, and AUC. The reported results indicate that the model achieves an accuracy of 83.86%, a recall of 85.03%, an F1 score of 76.46%, and an AUC of 0.879 for the three-class classification task.\n\nWhile the model shows promising results, it is important to note that the study has certain limitations. These include the single-center retrospective nature of the study, the relatively small sample size, and the imbalance in the number of cases across different infiltration subtypes. Future work aims to address these limitations through prospective studies with larger and more balanced datasets.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, a large dataset of over 10,000 lung nodule images, primarily consisting of ground-glass nodules and sub-centimeter nodules, was collected from renowned lung specialty hospitals and tertiary hospitals. These images were accompanied by corresponding pathological results, which were crucial for training and validating the model.\n\nThe images underwent various preprocessing steps to enhance their quality and consistency. This included normalization to standardize the pixel intensity values, resizing to ensure uniform dimensions, and augmentation techniques such as rotation, flipping, and scaling to increase the diversity of the training data. These steps helped in reducing overfitting and improving the model's generalization capabilities.\n\nFor the machine-learning algorithm, three-dimensional convolutional neural networks (3D CNNs) were employed. The data was encoded in a manner that preserved the spatial information across the three dimensions, which is essential for accurately capturing the intricate structures of lung nodules. The 3D CNNs were trained to learn hierarchical features from the input images, starting from low-level features like edges and textures to high-level features that represent complex patterns indicative of different invasive subtypes of early-stage lung adenocarcinoma.\n\nThe preprocessing also involved the extraction of relevant imaging characteristics, such as nodule diameter, density, volume, average CT values, and malignancy probability. These features were used to enhance the model's ability to differentiate between benign and malignant nodules and to predict the invasive subtypes accurately.\n\nIn summary, the data encoding and preprocessing involved normalization, resizing, augmentation, and feature extraction, all aimed at improving the performance and robustness of the 3D CNN-based machine-learning algorithm. This meticulous preparation of the data was instrumental in achieving high accuracy and reliability in the diagnosis of early-stage lung adenocarcinoma.",
  "optimization/parameters": "In our study, the model utilized a three-dimensional convolutional neural network (3D CNN) as part of an artificial intelligence system designed for assisting in the diagnosis of lung nodules. The specific number of parameters (p) in the model is not explicitly stated, as the focus was on the overall architecture and performance rather than the detailed parameter count.\n\nThe selection of the model architecture, including the choice of a 3D CNN, was driven by the need to handle the complexity of lung nodule images effectively. This type of network is particularly well-suited for tasks involving volumetric data, such as medical imaging, due to its ability to capture spatial hierarchies and patterns in three dimensions. The decision to use a 3D CNN was informed by its proven effectiveness in similar applications and its capacity to automatically extract relevant features from the data, thereby enhancing the model's performance in diagnosing early-stage lung adenocarcinoma subtypes.\n\nAdditionally, the model was trained on a large dataset comprising over 10,000 lung nodule images sourced from renowned pulmonary specialty hospitals and tertiary care centers. This extensive training dataset ensured that the model could learn from a diverse range of cases, improving its generalization and accuracy. The training process involved iterative learning and validation, which helped in fine-tuning the model parameters to achieve optimal performance.\n\nThe evaluation metrics, such as precision, recall, and the F1 score, were used to assess the model's diagnostic accuracy. The receiver operating characteristic (ROC) curve and the area under the curve (AUC) were also calculated to provide a comprehensive evaluation of the model's performance. These metrics indicated that the model could effectively differentiate between various subtypes of early-stage lung adenocarcinoma, thereby aiding in clinical decision-making.\n\nIn summary, while the exact number of parameters in the model is not specified, the choice of a 3D CNN and the extensive training dataset were crucial in developing a robust diagnostic tool for lung nodules. The model's performance was validated through rigorous testing and evaluation, demonstrating its potential to improve diagnostic accuracy and efficiency in clinical settings.",
  "optimization/features": "The study utilized a variety of input features for the artificial intelligence-assisted diagnosis system. These features included both clinical data and imaging characteristics of lung nodules. Specifically, the system considered factors such as the diameter, density, volume, average CT value, and malignant probability of the nodules. Additionally, imaging features like the presence of pure ground-glass nodules, part-solid nodules, and solid nodules were taken into account.\n\nFeature selection was implicitly performed through the training process of the deep learning models, particularly the three-dimensional convolutional neural network (3D CNN). This model is designed to automatically extract relevant features from the input data, reducing the need for manual feature selection. The training set, which consisted of over 10,000 cases from renowned lung specialty hospitals and tertiary hospitals, was used to train the model. This ensured that the feature extraction process was based solely on the training data, avoiding any bias from the test set.\n\nThe system's performance was evaluated using metrics such as sensitivity, specificity, and the area under the curve (AUC) for both binary and multi-class classification problems. The results demonstrated the system's effectiveness in predicting the invasive subtypes of early-stage lung adenocarcinoma, highlighting its potential to assist in clinical decision-making.",
  "optimization/fitting": "The fitting method employed in this study leverages deep learning techniques, specifically three-dimensional convolutional neural networks (3D CNNs), to analyze medical imaging data. The model was trained on a substantial dataset comprising over 10,000 cases of lung nodules, primarily consisting of ground-glass nodules and sub-centimeter nodules, sourced from renowned pulmonary specialty hospitals and tertiary care centers.\n\nGiven the complexity and high dimensionality of the input data, the number of parameters in the 3D CNN is indeed much larger than the number of training points. To address the potential issue of overfitting, several strategies were implemented. Firstly, the model underwent extensive training and validation using cross-validation techniques to ensure that it generalizes well to unseen data. Additionally, regularization methods such as dropout layers were incorporated to prevent the model from becoming too reliant on specific features in the training data. These layers randomly deactivate a fraction of neurons during training, which helps in reducing overfitting by ensuring that the model does not memorize the training data.\n\nTo rule out underfitting, the model's architecture and hyperparameters were carefully tuned. This involved experimenting with different network depths, filter sizes, and learning rates to find the optimal configuration that captures the underlying patterns in the data without being too simplistic. Furthermore, the use of attention mechanisms within the 3D CNN allowed the model to focus on the most relevant parts of the input images, thereby enhancing its ability to learn meaningful features.\n\nThe performance of the model was evaluated using metrics such as accuracy, recall, F1 score, and the area under the receiver operating characteristic curve (AUC). The model achieved an accuracy of 83.86%, a recall of 85.03%, an F1 score of 76.46%, and an AUC of 0.879, indicating that it effectively balances between overfitting and underfitting. These results demonstrate the model's capability to generalize well to new data while capturing the essential features necessary for accurate classification of lung nodule infiltration subtypes.",
  "optimization/regularization": "In our study, we employed several regularization methods to prevent overfitting and enhance the generalization of our deep learning models. One of the key techniques used was dropout, which randomly sets a fraction of input units to zero at each update during training time. This helps to prevent units from co-adapting too much, thereby improving the model's ability to generalize to unseen data.\n\nAdditionally, we utilized data augmentation techniques to artificially increase the diversity of our training dataset. This involved applying random transformations such as rotations, translations, and flips to the input images, which helped the model to learn more robust features and reduce overfitting.\n\nWe also incorporated weight decay (L2 regularization) in our optimization process. Weight decay adds a penalty term to the loss function that is proportional to the square of the magnitudes of the weights, encouraging the model to keep the weights small and preventing it from fitting the noise in the training data.\n\nFurthermore, we employed early stopping as a regularization technique. During training, we monitored the model's performance on a validation set, and stopped the training process when the performance stopped improving. This helped to prevent the model from overfitting to the training data by avoiding excessive training epochs.\n\nThese regularization methods collectively contributed to the robustness and reliability of our deep learning models in predicting the infiltration subtypes of early lung adenocarcinoma.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The model employed in this study leverages deep learning techniques, specifically three-dimensional convolutional neural networks (3D CNNs), which are inherently complex and often considered black-box models. These models are designed to automatically learn and extract features from input data, making them highly effective for tasks like image classification and pattern recognition. However, their internal workings are not easily interpretable, as they involve multiple layers of nonlinear transformations.\n\nTo enhance the interpretability of the model, attention mechanisms were integrated. These mechanisms assign different weights to various parts of the input data, highlighting the most relevant features for the task at hand. By doing so, the model can provide insights into which regions of the input images are crucial for making predictions. This approach helps in understanding the decision-making process of the model to some extent, although it does not fully elucidate the intricate details of the neural network's operations.\n\nThe use of attention mechanisms allows for a more transparent evaluation of the model's performance. For instance, in the context of lung nodule classification, the model can indicate which areas of the CT scans are most informative for diagnosing different types of lung cancer. This not only aids in improving the model's accuracy but also provides valuable information for clinicians, enabling them to better understand the underlying patterns that the model has learned.\n\nIn summary, while the deep learning model used in this study is primarily a black-box system, the incorporation of attention mechanisms adds a layer of interpretability. This allows for a clearer understanding of how the model processes and interprets the input data, making it a more reliable tool for medical diagnosis and decision-making.",
  "model/output": "The model employed in this study is designed for classification tasks. Specifically, it focuses on the classification of early-stage lung adenocarcinoma subtypes that appear as pulmonary nodules. The system utilizes a three-dimensional convolutional neural network (3D CNN) among other algorithms to process and analyze medical imaging data. This approach allows the model to predict the invasiveness of lung nodules, categorizing them into different subtypes. The output of the model provides valuable insights into the diagnosis and management of lung cancer, aiding in the determination of appropriate treatment strategies and improving diagnostic accuracy.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several key metrics and techniques to assess its performance in predicting the infiltration subtypes of early lung adenocarcinoma. The primary metrics used included accuracy, recall, F1 score, and the area under the curve (AUC). The F1 score was calculated using the formula 2 * (precision * recall) / (precision + recall). Additionally, the receiver operating characteristic (ROC) curve was plotted, with the pathological results serving as the gold standard. The area under the ROC curve (AUC) was computed to evaluate the model's performance. A P-value of less than 0.05 was considered statistically significant.\n\nThe study compared different infiltration subtypes, focusing on characteristics such as age, diameter, volume, mean CT value, and malignant probability. Statistical analyses, including single-factor variance analysis, were conducted to determine the significance of differences among these characteristics. The results indicated that age, diameter, volume, mean CT value, and malignant probability showed statistically significant differences among the different infiltration subtypes.\n\nThe confusion matrix was used to evaluate the three-class classification results, providing a visual representation of the model's performance in distinguishing between the different subtypes. The method was also compared with other deep learning models, such as those based on 3D VGG and attention mechanisms, to highlight its advantages in terms of accuracy, recall, F1 score, and AUC. The evaluation demonstrated that the proposed method achieved high performance metrics, indicating its potential as a non-invasive tool for preoperative analysis of early lung adenocarcinoma infiltration subtypes. This can aid in guiding surgical decisions and managing the disease during early and follow-up periods.",
  "evaluation/measure": "In the evaluation of our study, several performance metrics were reported to assess the effectiveness of the deep learning models used for predicting early lung adenocarcinoma infiltration subtypes. The primary metrics included accuracy, F1 score, Matthews correlation coefficient (MCC), and the area under the receiver operating characteristic curve (AUC).\n\nAccuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. It provides a general indication of how often the model's predictions are correct. The F1 score, which is the harmonic mean of precision and recall, offers a balance between these two metrics and is particularly useful when dealing with imbalanced datasets. The MCC is a correlation coefficient that takes into account all four quadrants of the confusion matrix, providing a more comprehensive evaluation of the model's performance, especially in multi-class classification problems.\n\nThe AUC is a widely used metric that evaluates the model's ability to distinguish between different classes. It provides a single scalar value that summarizes the performance across all classification thresholds. A higher AUC indicates better model performance.\n\nIn our study, the reported accuracy was 83.86%, the F1 score (F1AVG) was 76.46%, and the MCC was 0.407. The AUC for our model was 0.879, which is comparable to other advanced models reported in the literature. For instance, a study using a 3D visual geometry group (3D VGG) based multi-task deep learning network reported an accuracy of 64.9%, an F1AVG of 65.1%, and an MCC of 0.472. Another study using a 3D convolutional neural network (3D CNN) with attention mechanisms achieved an AUC of 0.926.\n\nThese metrics collectively provide a robust evaluation of our model's performance, demonstrating its effectiveness in predicting early lung adenocarcinoma infiltration subtypes. The use of these metrics aligns with common practices in the field, ensuring that our results are comparable to other studies and representative of the state-of-the-art in deep learning for medical imaging.",
  "evaluation/comparison": "In our evaluation, we compared our proposed method with several publicly available and established techniques to assess its performance. We utilized benchmark datasets to ensure a fair and comprehensive comparison. One of the methods we compared against was a three-dimensional visual geometry group (3D VGG) based multi-task deep learning network. This method achieved an accuracy of 64.9%, an F1AVG of 65.1%, and a Matthews correlation coefficient (MCC) of 0.472. This comparison highlighted the competitive performance of our approach.\n\nAdditionally, we evaluated our method against simpler baselines to understand its effectiveness relative to more straightforward techniques. For instance, we compared our results with those obtained using residual neural networks and random forest models. These comparisons demonstrated that our method, which incorporates an attention mechanism into a 3D convolutional neural network (3D CNN), outperformed these baselines. Specifically, our model achieved an area under the curve (AUC) of 0.926, which was superior to the performance of residual neural networks and random forest models.\n\nFurthermore, we conducted a comparison with a baseline system called SSNet, which is based on three-dimensional deep learning. This comparison involved evaluating the performance of SSNet against six doctors with varying levels of experience in thoracic surgery and radiology. The results showed that SSNet performed better than the doctors in classifying the infiltration subtypes of ground-glass nodules (GGN). Moreover, the use of SSNet significantly improved the doctors' AUC in three-class subtype differentiation, from 0.844 to 0.852. This indicates that our attention-based 3D CNN model can potentially enhance the diagnostic capabilities of clinicians in identifying GGN infiltration subtypes.\n\nOverall, our method demonstrated superior performance compared to both publicly available methods and simpler baselines, underscoring its potential as a non-invasive tool for pre-operative analysis of early lung adenocarcinoma infiltration subtypes. This comparison provides strong evidence of the effectiveness and reliability of our proposed approach in clinical settings.",
  "evaluation/confidence": "The evaluation of the deep learning methods used in this study includes several performance metrics, such as accuracy, F1 score, and the Matthews correlation coefficient (MCC). These metrics provide a comprehensive assessment of the model's performance in classifying different subtypes of early lung adenocarcinoma.\n\nThe accuracy of the deep learning method is reported as 64.1%, with an F1AVG of 63.3% and an MCC of 0.407. These metrics indicate the model's ability to correctly classify the subtypes and balance precision and recall. Additionally, the area under the curve (AUC) is used to evaluate the model's performance, with values such as 0.889 and 0.724 reported for different analyses. An AUC of 0.889 suggests that the measurement method has good diagnostic capability.\n\nStatistical significance is also considered in the evaluation. For instance, differences in age, diameter, volume, mean CT value, and malignant probability among different subtypes are found to be statistically significant (P < 0.001). This indicates that the observed differences are unlikely to be due to chance and provides confidence in the model's ability to distinguish between subtypes.\n\nThe study also compares the performance of different deep learning models. For example, a model based on the 3D visual geometry group (3D VGG) achieves an accuracy of 64.9%, an F1AVG of 65.1%, and an MCC of 0.472. Another model, SSNet, shows superior performance compared to six experienced doctors in classifying ground-glass nodules (GGN). The AUC for doctors improves from 0.844 to 0.852 with the help of SSNet, demonstrating the potential of deep learning systems to enhance diagnostic accuracy.\n\nFurthermore, the use of attention mechanisms in 3D CNN models is explored. These models assign different weights to different parts of the input, extracting more critical information and improving task efficiency and accuracy. The reported metrics for a 3D CNN model with attention mechanisms include an accuracy of 83.86%, a recall rate of 85.03%, an F1 score of 76.46%, and an AUC of 0.879. These results suggest that attention-based models can further enhance classification performance.\n\nIn summary, the performance metrics are accompanied by statistical significance tests, providing confidence in the superiority of the deep learning methods over baselines and other models. The use of AUC and other metrics, along with comparisons to existing models and human experts, supports the claim that these deep learning approaches are effective in classifying early lung adenocarcinoma subtypes.",
  "evaluation/availability": "Not enough information is available."
}