{
  "publication/title": "Clinical and inflammatory features based machine learning model for fatal risk prediction of hospitalized COVID-19 patients: results from a retrospective cohort study",
  "publication/authors": "The authors who contributed to the article are:\n\n- **Xin Guan**: Contributed to the Department of Laboratory Medicine, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China.\n- **Bo Zhang**: Contributed to the Department of Laboratory Medicine, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China.\n- **Ming Fu**: Contributed to the Department of Laboratory Medicine, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China.\n- **Mengying Li**: Contributed to the Department of Laboratory Medicine, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China.\n- **Xu Yuan**: Contributed to the Department of Laboratory Medicine, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China.\n- **Yaowu Zhu**: Contributed to the Department of Laboratory Medicine, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China.\n- **Jing Peng**: Contributed to the Department of Laboratory Medicine, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China.\n- **Huan Guo**: Contributed to the Department of Occupational and Environmental Health, State Key Laboratory of Environmental Health (Incubating), School of Public Health, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China.\n- **Yanjun Lu**: Contributed to the Department of Laboratory Medicine, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, China.",
  "publication/journal": "Annals of Medicine",
  "publication/year": "2021",
  "publication/pmid": "33410720",
  "publication/pmcid": "PMC7799376",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- COVID-19\n- Machine Learning\n- Fatal Risk\n- Extreme Gradient Boosting\n- Predictive Modeling\n- Clinical Features\n- Mortality Prediction\n- Retrospective Cohort Study\n- Disease Severity\n- Biomarkers",
  "dataset/provenance": "The dataset used in this study was derived from the electronic medical records of 1270 COVID-19 patients admitted to two hospitals in Wuhan, China, between January 27 and April 5, 2020. These patients were confirmed to have COVID-19 through positive RT-PCR detection of nasal or throat-swab specimens, following the diagnostic criteria established by the World Health Organization.\n\nThe patients were recruited from two branches of Tongji Hospital: the Sino French New City Branch and the Optical Valley Branch. A total of 984 patients were admitted to the Sino French New City Branch, while 286 patients were admitted to the Optical Valley Branch.\n\nThe dataset includes a variety of clinical features collected from the patients' medical records. These features encompass demographic information, clinical characteristics such as onset symptoms, disease severity, and comorbidities, laboratory examinations including blood routine tests, cytokines, infection-related factors, blood coagulation factors, and serum biochemical indices, as well as chest CT scan findings upon admission.\n\nThe dataset was processed to handle missing values and ensure data quality. For laboratory markers that were below the limits of detection for more than 15% of subjects, these biomarkers were categorized as binary variables using the normal reference range as the cutoff value. The primary outcomes recorded were discharge or death.\n\nThe study utilized a subset of this dataset to develop and validate a machine learning model for predicting death risk in COVID-19 patients. The training set consisted of 554 cases from the Sino French New City Branch, while the internal validation set included 233 cases from the same branch. Additionally, an external validation set of 286 cases from the Optical Valley Branch was used to further evaluate the model's performance.\n\nThe dataset used in this study is unique and specifically curated for the purpose of identifying key clinical features that can predict the death risk in COVID-19 patients. Previous studies have used different datasets and methodologies, but this study aims to provide a more comprehensive and representative analysis by including a larger and more diverse patient population.",
  "dataset/splits": "The dataset was split into three distinct sets: a training set, an internal validation set, and an external validation set. The training set consisted of 554 cases from the Sino French New City Branch of Tongji Hospital. The internal validation set comprised 233 cases from the same hospital branch. The external validation set included 286 cases from the Optical Valley Branch of Tongji Hospital. The training set was used to develop the model, the internal validation set was used to tune the model's hyperparameters and avoid overfitting, and the external validation set was used to evaluate the model's performance on an independent dataset. The distribution of data points in each split was designed to ensure robust model training and validation.",
  "dataset/redundancy": "The datasets used in this study were split into training, internal validation, and external validation sets. The training set consisted of 554 cases from the Sino French New City Branch of Tongji Hospital, while the internal validation set included 233 cases from the same hospital. The external validation set comprised 286 cases from the Optical Valley Branch of Tongji Hospital.\n\nThe training and validation sets were designed to be independent. This independence was enforced by randomly splitting the 984 cases from the Sino French New City Branch into training and internal validation sets in a 7:3 ratio. The external validation set, sourced from a different branch of the same hospital, ensured an additional layer of independence and generalizability.\n\nThe distribution of the datasets aimed to represent a broader population of COVID-19 patients. The training set had a case-fatality rate of 5.67%, which is close to the mortality rate reported in Wuhan (7.68%). This rate is significantly lower than that of a prior study conducted in Wuhan, which had a higher proportion of critical clinical symptoms (40.3%) and a mortality rate of 46.4%. The datasets used in this study, therefore, provide a better representation of the general patient population compared to previous studies that focused primarily on critically ill patients.\n\nThe datasets were processed to handle missing values and ensure that the most significant clinical characteristics were selected for mortality risk prediction. The least absolute shrinkage and selection operator (LASSO) regression analysis was used to optimize latent collinearity and avoid overfitting. This process involved 48 clinical features with missing values less than 20%, ensuring a robust and reliable model. The XGBoost machine learning algorithm was then applied to further refine the model and identify key features related to mortality risk. The final model, termed \"simple-tree XGBoost,\" was evaluated for its precision, recall, and F1 scores across the training, internal validation, and external validation sets, demonstrating high performance in predicting death risk among hospitalized COVID-19 patients.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is gradient boosting, specifically the XGBoost algorithm. XGBoost, which stands for Extreme Gradient Boosting, is an optimized distributed gradient boosting library designed to be highly efficient, flexible, and portable. It is not a new algorithm; it has been widely used and recognized in the machine learning community for its performance and efficiency in handling structured/tabular data.\n\nThe reason XGBoost was not published in a machine-learning journal is that it is an established algorithm that has already been extensively documented and validated in the literature. XGBoost was developed by Tianqi Chen and his team, and it has been open-sourced, allowing researchers and practitioners to use, modify, and build upon it. The algorithm's effectiveness has been demonstrated in numerous applications and competitions, making it a standard choice for many machine learning tasks.\n\nIn our study, we utilized XGBoost due to its proven ability to handle large datasets and its robustness in predicting outcomes. We employed a simple-tree XGBoost model, which was constructed based on six key clinical features identified through LASSO regression. This model demonstrated high precision and recall in predicting the death risk of COVID-19 patients, showcasing its effectiveness in a medical context. The use of XGBoost in our research aligns with its established reputation for delivering accurate and reliable results in various domains, including healthcare.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "For the machine-learning algorithm, the data was pre-processed and encoded as follows:\n\nElectronic medical records were reviewed to collect demographic information, clinical characteristics, laboratory examinations, and chest CT scan findings. For some laboratory markers that were below the limits of detection among more than 15% of subjects, these biomarkers were categorized as binary variables using the normal reference range as the cut-off value in the subsequent analysis.\n\nDescriptive data were expressed as frequencies for categorical variables and as medians with interquartile ranges for continuous variables. Mann\u2013Whitney U and Chi-square tests were conducted to estimate the differences between continuous and categorical data for surviving and not surviving groups, respectively.\n\nTo optimize latent collinearity and avert over-fitting of variables, the least absolute shrinkage and selection operator (LASSO) regression analysis was carried out in the training set to select the most significant clinical characteristics for mortality risk. Forty-eight clinical features with missing values less than 20% were enrolled into the variable shrinkage process.\n\nThe LASSO regression was established using a Cox proportional hazard model, with the optimal value of k with the minimum partial-likelihood deviance selected by 10-fold cross-validation. Subsequently, variables selected by LASSO regression were entered into a high-performance machine learning prediction model, namely XGBoost. The importance of candidate features in XGBoost is identified by its cumulative use in each decision step in trees.\n\nTo avoid model overfitting, the 984 cases were split randomly into training and internal validation sets in the ratio 7:3. A grid search method based on the \"caret\" package in R software was conducted in the training set to tune XGBoost hyperparameters, including the number of trees, the learning rate, and the minimum loss to expend on a leaf node.",
  "optimization/parameters": "In the optimization process, a total of 48 clinical features with missing values less than 20% were initially considered for the variable shrinkage process using LASSO regression. This method was employed to select the most significant clinical characteristics for predicting mortality risk in COVID-19 patients. Through this process, six key features were ultimately identified as significant predictors. These features include disease severity, age, levels of high-sensitivity C-reactive protein (hs-CRP), lactate dehydrogenase (LDH), ferritin, and interleukin-10 (IL-10). These six features were then used to construct a simplified and portable decision model defined as the \"simple-tree XGBoost\" model. The selection of these parameters was optimized using a Cox proportional hazard model with 10-fold cross-validation to determine the optimal value of the regularization parameter (k) that minimized the partial-likelihood deviance.",
  "optimization/features": "In the optimization process, feature selection was performed using the training set only. Initially, 48 clinical features were considered. To optimize latent collinearity and prevent overfitting, the least absolute shrinkage and selection operator (LASSO) regression analysis was conducted on the training set of 984 patients. This process selected 19 significant clinical characteristics associated with COVID-19 mortality risk. Subsequently, these 19 features were entered into a multi-tree XGBoost model to rank their importance. Features were added one by one to the model until the improvement in the area under the curve (AUC) score was less than 0.5%. This resulted in the selection of six key features: disease severity, age, levels of high-sensitivity C-reactive protein (hs-CRP), lactate dehydrogenase (LDH), ferritin, and interleukin-10 (IL-10). These six features were used as input for the final simple-tree XGBoost model.",
  "optimization/fitting": "In our study, we employed a robust methodology to address potential over-fitting and under-fitting issues. Initially, we had a large number of clinical features, but we used the least absolute shrinkage and selection operator (LASSO) regression to select the most significant variables, reducing the risk of over-fitting by minimizing latent collinearity among the features. This process was crucial as it helped in identifying the most relevant predictors for mortality risk in COVID-19 patients.\n\nTo further mitigate over-fitting, we split our dataset into training and internal validation sets in a 7:3 ratio. This division allowed us to train our model on a substantial portion of the data while reserving a separate set for validation, ensuring that the model's performance was evaluated on unseen data. Additionally, we utilized 10-fold cross-validation during the LASSO regression and grid search for hyperparameter tuning in the XGBoost model. This technique helps in providing a more reliable estimate of model performance and reduces the risk of over-fitting by ensuring that the model generalizes well to new data.\n\nThe XGBoost model was trained with carefully selected hyperparameters, including maximum tree depth, learning rate, minimum loss to expend on a leaf node, minimum sum of instance weight needed in a child node, subsampling proportion, and the number of trees. These hyperparameters were optimized using a grid search method based on the \"caret\" package in R, with the goal of minimizing the root mean square error (RMSE) through 10 repeats of 10-fold cross-validation. This rigorous tuning process helped in finding the best combination of hyperparameters that balanced model complexity and performance, thereby avoiding both over-fitting and under-fitting.\n\nMoreover, we conducted a 100-round 5-fold cross-validation to further select the most significant features related to mortality risk. This extensive validation process ensured that the selected features were robust and that the model's performance was consistent across different subsets of the data. The final model, termed \"simple-tree XGBoost,\" was trained with the selected features and evaluated on both the training and internal validation sets, as well as an external validation set from a different branch of the hospital. This multi-step validation approach provided confidence in the model's generalizability and its ability to accurately predict mortality risk in COVID-19 patients.",
  "optimization/regularization": "In our study, several techniques were employed to prevent over-fitting and optimize the model's performance. Initially, the least absolute shrinkage and selection operator (LASSO) regression analysis was utilized to select the most significant clinical characteristics for mortality risk. This method helps to optimize latent collinearity and avert over-fitting by shrinking less important features.\n\nAdditionally, the dataset was split into training and internal validation sets in a 7:3 ratio. This division allowed for the tuning of hyperparameters using a grid search method based on the \"caret\" package in R software. The hyperparameters optimized included the number of trees, learning rate, minimum loss to expend on a leaf node, maximum tree depths, minimum sum of instance weight needed in a child node, and subsampling proportion. The optimal hyperparameters were selected according to the minimum root mean square error (RMSE) in the grid search process using 10 repeats of 10-fold cross-validation.\n\nFurthermore, the XGBoost model was trained with specific hyperparameter settings, including max_depth, eta, gamma, min_child_weight, subsample, and nrounds. These settings were chosen to ensure the model's robustness and generalizability. The performance of the model was evaluated using various metrics, including identification accuracy, precision, recall, and F1 scores, across training, internal validation, and external validation sets. This comprehensive approach helped to ensure that the model was not over-fitted and could accurately predict mortality risk in COVID-19 patients.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in detail within the publication. Specifically, the optimal hyperparameters for the XGBoost model were selected based on the minimum root mean square error (RMSE) using a grid search process with 10 repeats of 10-fold cross-validation. The final hyperparameter settings for the multi-tree XGBoost model included max_depth of 3, eta of 0.1, gamma of 0.2, min_child_weight of 4, subsample of 1, and nrounds of 145. For the simple-tree XGBoost model, the same hyperparameters were used, except for min_child_weight, which was set to 1.\n\nThe model files and optimization parameters are not explicitly provided in the publication, as the focus was on reporting the methodology and results rather than distributing the actual model files. However, the detailed steps and parameters used for training and validating the models are thoroughly described, allowing for reproducibility by other researchers.\n\nRegarding the availability and licensing of the reported configurations and schedules, they are included in the public domain through the publication itself. Researchers can refer to the methods section of the paper to replicate the hyper-parameter settings and optimization processes. No specific license is mentioned for the use of these configurations, implying that they can be freely used for research purposes as per standard academic practices.",
  "model/interpretability": "The model employed in this study is a simple-tree XGBoost model, which is generally considered a black-box model due to its complexity and the intricate decision-making process within the ensemble of trees. However, efforts were made to enhance interpretability by focusing on a limited set of key features.\n\nThe model was constructed using six significant features: disease severity, age, and serum levels of hs-CRP, LDH, ferritin, and IL-10. These features were selected through a rigorous process involving LASSO regression and XGBoost feature importance ranking, ensuring that only the most relevant predictors were included. This simplification helps in making the model more interpretable, as clinicians can easily understand and monitor these six key biomarkers at hospital admission.\n\nMoreover, the decision tree structure illustrated with these six features provides a visual representation of how the model makes predictions. This visualization aids in understanding the decision-making process, making the model more transparent compared to more complex, multi-tree XGBoost models.\n\nWhile the model retains some level of interpretability through feature selection and visualization, it is important to note that the underlying XGBoost algorithm still operates as a black-box. The trade-off between model interpretability and prediction accuracy was considered, with a preference for maintaining high predictive performance. Future work could focus on further balancing these aspects to develop models that are both accurate and easily interpretable by clinicians.",
  "model/output": "The model developed is a classification model. It is designed to predict the outcome of COVID-19 patients, specifically whether they will survive or die. The model uses a simple-tree XGBoost algorithm, which is a type of machine learning model known for its effectiveness in classification tasks. The performance metrics provided, such as precision, recall, and F1 scores for survival and death predictions, further confirm that the model is intended for classification rather than regression. The model was evaluated using various datasets, including training, internal validation, and external validation sets, and it demonstrated high accuracy in predicting patient outcomes. The key features used in the model, such as disease severity, age, and serum levels of hs-CRP, LDH, ferritin, and IL-10, were selected to optimize the classification performance. The decision tree structure illustrated with these features also supports the classification nature of the model.",
  "model/duration": "The execution time for the model was not explicitly mentioned. However, the model was trained using a grid search process with 10 repeats of 10-fold cross-validation to select the optimal hyperparameters. This process is computationally intensive and can take a significant amount of time, depending on the hardware used. Additionally, the model was trained in the training set with specific hyperparameter settings, which would also contribute to the overall execution time. The exact duration of these processes is not specified.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed simple-tree XGBoost model involved several rigorous steps to ensure its robustness and generalizability. Initially, the model was trained on a dataset consisting of 554 cases from the Sino French New City Branch of Tongji Hospital. The performance was assessed using precision, recall, F1-score, and accuracy metrics. The model demonstrated high precision and recall for both survival and death predictions, with an overall accuracy of 99.3%.\n\nTo validate the model's performance, it was further evaluated on an internal validation set comprising 233 cases from the same hospital branch. The results showed consistent high precision and recall, with an accuracy of 99.1%. Additionally, an external validation set of 286 cases from the Optical Valley Branch of Tongji Hospital was used to test the model's generalizability. The model maintained high performance metrics, achieving an accuracy of 99.7%.\n\nThe evaluation also included a comparison with a conventional multivariable logistic regression model. The simple-tree XGBoost model outperformed the logistic regression model in terms of the area under the curve (AUC) scores across all datasets. Specifically, in the training set, the XGBoost model had an AUC of 0.999 compared to 0.970 for the logistic regression model using all 19 features and 0.931 using six features. Similar superior performance was observed in the internal and external validation sets.\n\nMoreover, the model's performance was evaluated using 100-round fivefold cross-validation to optimize feature selection and avoid overfitting. The key features were identified based on their contribution to the model's AUC score, ensuring that only the most significant predictors were included. This thorough evaluation process underscores the model's reliability and effectiveness in predicting death risk among COVID-19 patients.",
  "evaluation/measure": "In our study, we evaluated the performance of the proposed simple-tree XGBoost model using several key metrics to ensure a comprehensive assessment. The primary metrics reported include precision, recall, F1-score, and accuracy. These metrics were calculated for both survival and death predictions across three datasets: the training set, the internal validation set, and the external validation set.\n\nPrecision and recall are crucial for understanding the model's performance in predicting both survival and death outcomes. Precision measures the accuracy of positive predictions (i.e., the proportion of true positives among all positive predictions), while recall measures the model's ability to identify all relevant instances (i.e., the proportion of true positives among all actual positives). The F1-score, which is the harmonic mean of precision and recall, provides a single metric that balances both concerns.\n\nAccuracy, which represents the proportion of correct predictions among all predictions, was also reported. Additionally, we provided macro and weighted averages for precision, recall, and F1-score. Macro averages treat all classes equally, providing an unweighted mean of the metrics, while weighted averages account for the support (number of instances) of each class, giving a more representative measure when dealing with imbalanced datasets.\n\nThe reported metrics are representative of standard practices in the literature, ensuring that our evaluation is both rigorous and comparable to other studies in the field. The high values of these metrics across all datasets indicate that the simple-tree XGBoost model is robust and reliable in predicting death risk among COVID-19 patients.",
  "evaluation/comparison": "For the evaluation of our model, we conducted a comparison with a conventional multivariable logistic regression model to benchmark our simple-tree XGBoost model. This comparison was performed across three datasets: the training set, the internal validation set, and the external validation set.\n\nIn the training set, the simple-tree XGBoost model demonstrated superior performance compared to the logistic regression model, whether it used all 19 features or just the six selected features. The area under the curve (AUC) for the XGBoost model was significantly higher (0.999 vs. 0.970 and 0.999 vs. 0.931, respectively), indicating better discriminative ability.\n\nSimilarly, in the internal validation set, the simple-tree XGBoost model outperformed the logistic regression model with all 19 features and the six selected features, showing higher AUC scores (1.000 vs. 0.941 and 1.000 vs. 0.883, respectively). This suggests that the XGBoost model is more effective in predicting outcomes in this dataset as well.\n\nIn the external validation set, the simple-tree XGBoost model again showed superior performance compared to the logistic regression model using 19 features. However, the comparison with the logistic regression model using six features was not explicitly mentioned for this dataset.\n\nAdditionally, we compared the performance of the simple-tree XGBoost model with a multi-tree XGBoost model. The results indicated that there was no significant difference in AUC scores between the simple-tree and multi-tree models in the training set. However, in the internal validation set, the simple-tree model showed a marginally higher AUC compared to the multi-tree model.\n\nOverall, these comparisons highlight the robustness and effectiveness of the simple-tree XGBoost model in predicting death outcomes among COVID-19 patients, demonstrating its superiority over traditional logistic regression models and comparable performance to more complex multi-tree XGBoost models.",
  "evaluation/confidence": "The evaluation of the proposed simple-XGBoost algorithm was conducted using several performance metrics, including precision, recall, F1-score, and accuracy. These metrics were calculated for both survival and death predictions across three datasets: the training set, the internal validation set, and the external validation set.\n\nThe performance metrics demonstrated high values, indicating strong predictive capabilities. For instance, the precision and recall for survival predictions were consistently above 99% across all datasets. Similarly, the precision for death predictions was 100% in most cases, with recall values slightly lower but still above 85%. The overall accuracy for each dataset was also very high, exceeding 99%.\n\nStatistical significance was assessed through comparisons with a conventional multivariable logistic regression model. The simple-tree XGBoost model showed superior performance in terms of the area under the curve (AUC) scores. In the training set, the AUC for the simple-tree XGBoost model was 0.999, significantly higher than the logistic regression models using either all 19 features (AUC: 0.970, p = 0.008) or the six selected features (AUC: 0.931, p = 0.003). Similar trends were observed in the internal and external validation sets, where the simple-tree XGBoost model also outperformed the logistic regression models.\n\nThe p-values from these comparisons indicate that the differences in performance are statistically significant, providing strong evidence that the simple-tree XGBoost model is superior to the logistic regression models. Additionally, the model's performance was consistent across different datasets, further reinforcing its reliability and generalizability.\n\nIn summary, the evaluation metrics and statistical analyses support the conclusion that the simple-XGBoost algorithm is highly effective and statistically superior to baseline models in predicting the death risk of COVID-19 patients. The high precision, recall, and accuracy, along with significant p-values, underscore the model's robustness and potential for clinical application.",
  "evaluation/availability": "The datasets generated for this study are not publicly available due to confidentiality requirements. The data used to train and validate the models included sensitive patient information from COVID-19 cases admitted to two branches of Tongji Hospital in Wuhan. Therefore, sharing these datasets is not applicable. The study focused on identifying key clinical features and developing a simple-tree XGBoost model to predict mortality risk in COVID-19 patients. The performance of the model was evaluated using precision, recall, F1-score, and AUC metrics across training, internal validation, and external validation sets. While the specific datasets are not shared, the methods and results are thoroughly described to allow for reproducibility and further research."
}