{
  "publication/title": "Machine learning algorithms for identifying travel modes using accelerometer and GPS data",
  "publication/authors": "The authors who contributed to the article are:\n\n- DP, who processed objective data, created the predictive model, wrote the R package, and drafted the initial manuscript.\n- BR, AR, and CO, who collected study data and enrolled participants.\n- CM, who processed demographic data.\n- CC and DL, who provided technical advice on spatial data.\n- AP, AC, AE, AR, PW, SC, BG-C, DC, and CO, who designed the ENABLE London study and secured funding.\n- All authors contributed to the final manuscript and approved it.\n\nThe specific contributions of each author are detailed in the authors' contributions section.",
  "publication/journal": "International Journal of Behavioral Nutrition and Physical Activity",
  "publication/year": "2018",
  "publication/pmid": "30241483",
  "publication/pmcid": "PMC6150970",
  "publication/doi": "10.1186/s12966-018-0724-y",
  "publication/tags": "- Active travel\n- Physical activity\n- Accelerometer data\n- GPS data\n- GIS data\n- Machine learning\n- Travel mode identification\n- Gradient boosted trees\n- Cross-validation\n- Predictive accuracy\n- Built environment\n- Health behaviors\n- Data analysis\n- Open-source tools\n- Public health\n- Sedentary behavior\n- Type-2 diabetes\n- Data processing\n- Algorithm development\n- Health outcomes",
  "dataset/provenance": "The dataset used in this study originates from the Examining Neighbourhood Activities in Built Living Environments in London (ENABLE London) study, which evaluates the impact of the built environment on health behaviors, including physical activity. Participants in this study wore accelerometers and GPS receivers on their hips for seven days. The data was time-matched and extracted from the commutes of 326 adult participants. These participants reported their commute times and modes, which were manually verified to confirm the stated travel mode. This process yielded examples of five travel modes: walking, cycling, motorized vehicle, train, and stationary.\n\nThe training dataset contained 131,573 data points, which were split into two parts. Approximately a quarter of the training data (33,529 points) was used to test different moving window sizes. The remaining 98,387 points were used to build the cross-validated model. The dataset includes data from 66 participants who walked to work, 34 cyclists, 94 vehicle users, and 132 train users. The data points were manually identified and classified to ensure reliability.\n\nIn addition to the ENABLE London study, data from the Sedentary Time and Metabolic Health in People with type-2 Diabetes (STAMP-2) study was also used to test the generalizability of the model. The STAMP-2 study involved 10 participants, contributing 210,936 data points. These participants were independent of the ENABLE London study and were recruited from a different geographical area with varying travel options.\n\nThe dataset has not been used in previous papers by the community, as this is the first publication presenting this open-source tool. The full cross-validation output and all model parameters used are available in Additional file 2, providing transparency and reproducibility for further research.",
  "dataset/splits": "The dataset was split into multiple parts for different purposes. Initially, the training data, consisting of 131,573 data-points, was divided into two main subsets. Approximately a quarter of the training data, totaling 33,529 points, was used to test various moving window sizes. The remaining 98,387 points were utilized to build the cross-validated model.\n\nFor cross-validation, the training data was further divided into five separate subsets. Each subset was iteratively removed from the pool of training data, and a model was trained on the remaining 80% of the data. The excluded subset was then used as test data. This process was repeated five times, resulting in five separate fitted models and test datasets.\n\nAdditionally, the model's generalizability was tested using data from participants who were not included in the training dataset. This included 21 participants from the ENABLE London study, contributing 402,749 data points, and 10 participants from the STAMP-2 study, contributing 210,936 data points. These datasets were used to compare predicted travel modes with manually identified travel patterns, further validating the model's accuracy and generalizability.",
  "dataset/redundancy": "The datasets were split into training and test sets to ensure independence and to validate the model's performance. The training data was derived from the ENABLE London study, focusing on participants who commuted using the same mode of transport to and from work. This data was manually curated to include reliable examples of different travel modes, such as walking, cycling, vehicle use, and train use, as well as stationary periods. The training data was further divided into two parts: one subset was used to test different moving window sizes, and the remaining data was used to build the cross-validated model.\n\nTo enforce independence between the training and test sets, participants from the ENABLE London study who were not included in the training dataset were randomly selected for the test set. This resulted in 21 participants contributing 402,749 data points, which were manually classified for travel modes. Additionally, to test the generalizability of the model, data from a separate study, the STAMP-2 study, was used. This study included 10 participants with 210,936 data points, providing an independent dataset from a different geographical context and demographic profile.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the context of travel mode identification. The training data included a diverse range of travel modes, ensuring that the model could learn to distinguish between them accurately. The test datasets, both from the ENABLE London study and the STAMP-2 study, provided a robust evaluation of the model's performance in real-world scenarios, including different travel behaviors and geographical contexts. This approach ensures that the model is not overfitted to the training data and can generalize well to new, unseen data.",
  "dataset/availability": "The data used in this study is not publicly available. The training data was derived from the ENABLE London study, which included participants who commuted to and from work using the same mode of transport. The data consisted of combined GPS and accelerometry measurements during commutes, manually identified and classified using a Geographical Information System (ArcGIS 10.4). Additionally, data from the STAMP-2 study, which focused on sedentary behavior in adults with type-2 diabetes, was used to test the generalizability of the model. This data was collected using ActiGraph accelerometers and GPS receivers.\n\nThe specific data points and splits used for training and testing the model are not released in a public forum due to strict data privacy and ethical conditions. The analyses were conducted on researchers' own machines to avoid problems related to data privacy. The methodology and code used for the analyses are open source and freely available online, allowing other researchers to replicate the study under similar conditions. The ethical approval for the STAMP-2 study was obtained from the South West-Central Bristol NHS Research Ethics Committee, ensuring that all participants provided written informed consent.",
  "optimization/algorithm": "The optimization algorithm employed in this study is based on gradient boosted trees, specifically using the XGBoost implementation. This algorithm belongs to the ensemble learning class, where multiple decision trees are combined to improve predictive accuracy. Gradient boosting is a well-established technique in machine learning, known for its effectiveness in various data science tasks.\n\nThe algorithm used is not new; it has been widely adopted and refined over the years. The XGBoost implementation, in particular, has gained prominence due to its efficiency and performance in handling large datasets. It has been successfully applied in numerous machine learning challenges and competitions, demonstrating its robustness and versatility.\n\nThe choice to use XGBoost in this context is driven by its proven track record in achieving high predictive accuracy. While it is a powerful tool, it is important to note that the focus of this study is on applying machine learning to identify travel modes from accelerometer and GPS data, rather than developing a new algorithm. The algorithm's effectiveness in this specific application is what is being highlighted, rather than its novelty in the field of machine learning.\n\nThe decision to present this work in a behavioral nutrition and physical activity journal, rather than a machine learning journal, is due to the study's primary focus. The research aims to contribute to the understanding of travel behavior and physical activity, leveraging advanced machine learning techniques to achieve this goal. The algorithm is a means to an end, enabling more accurate identification of travel modes, which is crucial for studies in this domain.",
  "optimization/meta": "The model employed in this study is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on a single machine-learning method: gradient boosted trees, specifically implemented using the XGBoost package in R. This approach involves fitting a large number of decision trees to the data, where each tree is a weak learner. The final prediction is made by assessing the likelihood of each point belonging to different travel modes, with the highest probability determining the outcome.\n\nThe training data used for this model is carefully curated to ensure reliability. It includes participants' self-reported travel modes, which are then manually verified by researchers using GIS. This twofold assessment helps to confirm that the training data contains accurate examples of each travel mode. The data is split into two parts: one for testing different moving window sizes and another for fitting the gradient boosted tree model. This splitting process ensures that the training data is independent and that the model's performance can be robustly evaluated through cross-validation.\n\nThe model's performance is assessed using several measures, including overall accuracy, positive predictive value, sensitivity, and F1 score for each travel mode. These metrics provide a comprehensive understanding of the model's predictive accuracy. Additionally, the model's generalizability is tested on separate datasets, such as the STAMP-2 study, which includes participants with different demographics and geographical contexts. This further validates the model's ability to accurately predict travel modes across various populations.",
  "optimization/encoding": "The data used for the machine-learning algorithm consisted of GPS and accelerometer data collected from daily commuters. The GPS data points were recorded every 10 seconds, and the accelerometer data was combined with the GPS data to create a comprehensive dataset. The data was not segmented into journeys prior to analysis; instead, the travel mode of each GPS data point was identified individually.\n\nThe training dataset was created using survey data from the ENABLE London study. This dataset included combined GPS and accelerometer data from participants who commuted using various modes of transportation, such as walking, cycling, motorized vehicles, and trains. Additionally, data points that showed no directionality and were clustered around a single location were classified as \"stationary.\"\n\nTo ensure the reliability of the training dataset, a twofold assessment was conducted. Participants stated their mode of commute, and a researcher manually double-checked this information using GIS. This process confirmed that the training dataset contained reliable examples of each travel mode.\n\nThe data was pre-processed by splitting the training dataset into two parts. The first part was used to test different moving window sizes, with a four-minute window ultimately selected for its high predictive accuracy for active travel modes. The remaining data points were used to build the cross-validated model.\n\nThe machine-learning algorithm employed was XGBoost, a gradient boosted tree implementation. This algorithm fits a large number of decision trees to the data, with each tree being a weak learner. The data points are re-weighted after each tree is created to emphasize points that were misclassified in the previous round. This process continues until a consensus across all trees leads to high predictive accuracy.\n\nTo avoid overfitting, the learning rate was set lower than the default, and a subsampling value of 0.2 was used, meaning each tree was fit to only 20% of the available data. Five-fold cross-validation was employed to assess model accuracy, with participants randomly assigned to one of five subsets. Each subset was iteratively removed from the pool of training data, and a model was trained on the remaining 80% of the data. The excluded subset was then used as test data, resulting in five separate fitted models and test datasets. The overall accuracy scores from these models were reported.",
  "optimization/parameters": "In our study, we utilized a gradient boosted tree model implemented using the XGBoost package in R. This model type is known for its flexibility and ability to handle a large number of parameters. The specific number of parameters (p) used in our model can vary, as gradient boosting involves fitting multiple decision trees sequentially, each contributing to the final prediction.\n\nThe selection of parameters in our model was carefully considered to avoid overfitting to the training data. We adjusted several key parameters from their default settings. For instance, we set a lower learning rate (0.1 instead of the default 0.3) to ensure that the model learns more gradually and generalizes better to unseen data. Additionally, we employed a subsampling value of 0.2, meaning that each tree was fit to only 20% of the available data. This technique helps in reducing the variance and preventing the model from becoming too complex.\n\nFurthermore, we used five-fold cross-validation to assess the model's accuracy. This process involved randomly assigning participants within the training data to one of five subsets, iteratively removing each subset from the pool of training data, and training the model on the remaining 80% of the data. The excluded subset was then used as test data. This method ensures that our model's performance is robust and not dependent on a particular split of the data.\n\nIn summary, while the exact number of parameters can be extensive due to the nature of gradient boosting, our approach focused on tuning critical parameters to enhance the model's generalizability and performance.",
  "optimization/features": "The input features used in our model were carefully selected based on their potential to differentiate between various travel modes. We calculated several features for each 10-second epoch from accelerometer and GPS data. These features include the mean, standard deviation, 10th, and 90th percentiles of each accelerometer axis and speed. Additionally, we computed the mean sum of signal-to-noise ratio (sumSNR) and the mean distance from train lines. The distance from train lines was determined using a combination of Meridian 2 rail network data for the UK, OS OpenMAP data for central London, and the spatstat package in R. We also calculated the distance traveled over the previous and next minute. These features were chosen because they are likely to vary between different travel modes. For instance, vehicles and trains typically have higher speeds than walking and cycling, while walking generally shows greater accelerometer activity than other modes. Cycling may exhibit higher accelerometer activity compared to vehicles and trains. Both vehicles and trains have metal structures that can obstruct GPS signals, resulting in lower sumSNR than other travel modes. Either the distance over the next minute or the distance over the previous minute should be very low while a subject is stationary.\n\nFeature selection was not explicitly performed as a separate step. Instead, the features were chosen based on domain knowledge and their relevance to distinguishing between travel modes. The selection process was guided by the understanding that certain variables are more likely to differ between travel modes, ensuring that the chosen features are informative for the model. The training data was used to develop and test the algorithm, ensuring that the features selected are reliable representations of different travel modes. The context around the training data is less relevant, focusing on ensuring that a data point is a true representation of the assigned travel mode. This approach helps in training the model using data from commutes and predicting travel modes for all data points.",
  "optimization/fitting": "The fitting method employed in this study utilized a gradient boosted tree model, specifically using the XGBoost package in R. This approach is an ensemble learning method that fits multiple shallow decision trees to the data. Each tree is trained to correct the errors of the previous ones, which helps in improving the overall predictive accuracy.\n\nTo address the potential issue of overfitting, several measures were taken. Firstly, the learning rate was set lower than the default value (0.1 instead of 0.3). This slower learning rate ensures that the model makes smaller adjustments with each tree, reducing the risk of overfitting to the training data. Additionally, a subsampling value of 0.2 was used, meaning that each tree was fit to only 20% of the available data. This technique further helps in preventing overfitting by ensuring that the model does not become too specialized to the training data.\n\nTo rule out underfitting, the model's performance was evaluated using five-fold cross-validation. This process involved randomly assigning participants to one of five subsets, iteratively removing each subset from the training data, and training the model on the remaining 80% of the data. The excluded subset was then used as test data. This method ensures that the model is tested on different portions of the data, providing a robust assessment of its generalizability and performance.\n\nThe training data was split into two parts: one for testing different moving window sizes and the other for fitting the gradient boosted tree. The moving window size was selected based on the highest predictive accuracy for active travel modes, ensuring that the model captures the relevant temporal dynamics of the data.\n\nOverall, the combination of a lower learning rate, subsampling, and cross-validation helped in balancing the model to avoid both overfitting and underfitting, ensuring reliable and generalizable predictions.",
  "optimization/regularization": "In our study, we implemented several regularization techniques to prevent overfitting and ensure the robustness of our predictive model. One key approach was adjusting the learning rate, which we set lower than the default value. This modification helps to make the model more conservative in updating the weights during the training process, thereby reducing the risk of overfitting.\n\nAdditionally, we employed subsampling, using a value of 0.2. This means that each decision tree in our gradient boosted model was trained on only 20% of the available data. Subsampling introduces randomness and helps to decorrelate the trees, further mitigating overfitting.\n\nWe also utilized a learning weight, which controls the degree of re-weighting of data points. By carefully tuning this parameter, we ensured that the model did not become too sensitive to individual data points, thus enhancing its generalization capability.\n\nThese regularization methods collectively contributed to building a model that performs well on unseen data, demonstrating its reliability and generalizability across different datasets and participant groups.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in detail. Specifically, we utilized a gradient boosted tree model implemented with the XGBoost package in R. Key parameters such as the learning rate and subsampling value were adjusted to prevent overfitting. The learning rate was set to 0.1, which is lower than the default value of 0.3, and a subsampling value of 0.2 was used, meaning each tree was fit to only 20% of the available data.\n\nThe full cross-validation output, including all model parameters, is available in Additional file 2. This file provides comprehensive details on the configurations and settings used during the optimization process, ensuring reproducibility.\n\nAdditionally, our method is open source, and all code is freely available online. This transparency allows other researchers to access and utilize our configurations and parameters for their own studies. The open-source nature of our work also facilitates further development and improvement of the model.",
  "model/interpretability": "The model employed in this study is based on gradient boosted trees, specifically using the XGBoost package. This type of model is considered an ensemble learner, which means it combines the predictions of multiple decision trees to improve overall accuracy. While individual decision trees can be interpreted relatively easily, the ensemble nature of gradient boosted trees makes the model somewhat less transparent compared to simpler models like linear regression.\n\nHowever, the model does offer some level of interpretability. Each decision tree in the ensemble is a series of if-then statements based on the input features, such as accelerometer and GPS data. By examining these trees, one can understand which features are most important for predicting different travel modes. For instance, speed and directionality from GPS data, along with activity patterns from accelerometer data, are crucial for distinguishing between walking, cycling, and vehicle use.\n\nThe model's predictions are probabilistic, meaning it outputs the likelihood of each travel mode for a given data point. The mode with the highest probability is selected as the predicted outcome. This probabilistic nature allows for a degree of interpretability, as researchers can see how confident the model is in its predictions.\n\nAdditionally, the use of a confusion matrix provides further insight into the model's performance. This matrix compares the observed travel modes with the predicted ones, allowing researchers to see where the model succeeds and where it might be misclassifying certain modes. For example, the model might struggle to differentiate between buses and other vehicles due to similar speed and activity patterns.\n\nIn summary, while the gradient boosted trees model is not entirely transparent, it does offer ways to interpret its decisions. The importance of various features, probabilistic predictions, and the confusion matrix all contribute to a better understanding of how the model makes its travel mode predictions.",
  "model/output": "The model developed is a classification model. It is designed to predict the travel mode for each GPS data point, distinguishing between five different modes: walking, cycling, motorized vehicle, train, and stationary. The model uses a gradient boosted tree approach, specifically implemented with the XGBoost package in R. This type of model is well-suited for classification tasks where the goal is to assign categorical labels to data points based on input features.\n\nThe model's performance is evaluated using several metrics, including overall accuracy, positive predictive value, sensitivity, and F1 score for each travel mode. These metrics provide a comprehensive understanding of how well the model predicts each travel mode. The model was trained and validated using a dataset from the ENABLE London study, which included GPS and accelerometer data from daily commuters. The training data was split into subsets for testing different moving window sizes and for fitting the gradient boosted tree model.\n\nThe model's predictions were compared against manually identified travel patterns from other participants, demonstrating high accuracy overall. However, there were some discrepancies, particularly at the start and end of journeys, which highlights the challenge of identifying modal shifts. Despite these limitations, the model shows strong predictive performance and can be applied to other datasets to identify travel modes from GPS and accelerometer data.",
  "model/duration": "The execution time of the model was not explicitly detailed in the publication. However, some insights can be inferred from the methodology described.\n\nThe model was built using a gradient boosted tree with the XGBoost package in R. The training data was split into two parts: one for testing moving window sizes and the other for building the cross-validated model. The subset used for testing moving windows contained approximately a quarter of the training data, which amounted to 33,529 points. The remaining 98,387 points were used to build the model.\n\nThe model fitting process involved five-fold cross-validation, where participants were randomly assigned to one of five subsets. Each subset was iteratively removed from the pool of training data, and a model was trained on the remaining 80% of the data. This process was repeated five times, resulting in five separate fitted models and test datasets.\n\nGiven the computational intensity of gradient boosted trees and the size of the dataset, the execution time would likely be significant. However, the exact duration was not specified. It is also worth noting that the model was run on a researcher's own machine, which could vary in computational power and thus affect the execution time.\n\nFor a more precise execution time, one would need to refer to the supplementary materials or contact the authors directly, as the main text does not provide this specific detail.",
  "model/availability": "The source code for the algorithm is publicly available and open source. It is released as a package for the statistical software environment R. This allows researchers to run the algorithm on their own machines, which is particularly advantageous for maintaining data privacy and adhering to strict ethical conditions. The code is freely accessible online, enabling other researchers to replicate the findings and apply the predictive model to their own datasets. Additionally, a full usage example is provided to assist researchers who may be inexperienced with coded input tools like R. This ensures that the method is accessible and can be easily integrated into various research projects.",
  "evaluation/method": "The evaluation of our method involved several steps to ensure its robustness and generalizability. We employed a five-fold cross-validation approach, which involved training and testing the model on different subsets of the data. This process resulted in five separate fitted models and corresponding test datasets, from which we reported overall accuracy scores. The full cross-validation output, including all model parameters used, is available in Additional file 2.\n\nTo further test the predictive accuracy of our method, we compared our predicted travel modes with manually identified travel patterns from participants who were not included in the training dataset. Specifically, we randomly selected 21 participants from the ENABLE London study, who contributed 402,749 data points. Each participant's data was exported as a Shapefile for ArcGIS 10.4, and we manually classified the travel mode of every data point for each day.\n\nAdditionally, we tested the generalizability of our fitted model by comparing predicted values to manually identified data from 10 participants in a separate dataset, the Sedentary Time and Metabolic Health in People with type-2 Diabetes study (STAMP-2). This dataset included 210,936 data points and represented a different demographic and geographical context. The STAMP-2 participants were older and less healthy, with a mean age of 58.6 years and a mean BMI of 34.4. This comparison demonstrated the model's ability to generalize to other populations and contexts.\n\nWe reported several measures of predictive accuracy, including overall accuracy, positive predictive value, sensitivity, and F1 score for each travel mode. The F1 score, which is the harmonic mean of positive predictive value and sensitivity, was used as a measure of accuracy for each mode. We also presented the raw confusion matrix, which compares counts for observed and predicted modes and can be used to calculate accuracy scores.\n\nIn summary, our evaluation method included cross-validation, comparison with manually identified data from the same study, and comparison with data from a separate study. These steps ensured that our method is reliable, accurate, and generalizable to different datasets and populations.",
  "evaluation/measure": "In our evaluation, we report several key performance metrics to provide a comprehensive understanding of our model's predictive accuracy. Firstly, we present an overall accuracy score, which is the percentage of correctly predicted data points. This metric is useful for providing a single number that represents the model's overall performance. However, due to the uneven distribution of data points across different travel modes, this metric alone may not be fully representative.\n\nTo address this, we also report the positive predictive value (PPV) for each mode. PPV is the percentage of data points predicted as a specific mode that were actually observed as that mode. This metric helps to understand the precision of our predictions for each travel mode.\n\nAdditionally, we report sensitivity for each mode, which is the percentage of data points observed to be a specific travel mode that were correctly predicted by our model. Sensitivity provides insight into the model's ability to correctly identify true positives for each mode.\n\nWe also calculate the F1 score for each mode, which is the harmonic mean of PPV and sensitivity. The F1 score is particularly useful for providing a single metric that balances both precision and recall. A high F1 score indicates that the model has a high rate of correct identification of both true positives and true negatives for a given mode.\n\nFor those who wish to delve deeper into the model's performance, we provide the raw confusion matrix. This table compares the counts of observed and predicted modes, allowing for the calculation of various accuracy scores and a detailed understanding of how the model performs across different modes.\n\nThese metrics collectively offer a thorough evaluation of our model's performance, ensuring that researchers can interpret the results accurately and apply the model to their specific research questions.",
  "evaluation/comparison": "In our evaluation, we compared our predictive algorithm to the PALMS system, which is a freely available method for processing physical activity data. While both methods aim to identify travel modes, they serve different purposes. PALMS focuses on identifying entire journeys, whereas our method identifies each individual data point. This difference in approach means that the choice between the two methods depends on the specific research question at hand.\n\nOne notable advantage of our method is that it can be run on a researcher's own machine, which is particularly beneficial given the strict data privacy and ethical conditions that govern the use of physical activity data. This local processing capability helps to avoid potential issues related to data privacy, as it eliminates the need to upload sensitive data to a remote server for analysis.\n\nAdditionally, our method is open source, with all code freely available online. This transparency allows other researchers to review, suggest edits, and contribute to the development of our method, thereby enhancing its utility to the broader research community.\n\nIn terms of performance, our method exhibits similar levels of accuracy to the PALMS system. However, our approach provides more granular data by identifying each data point, which can be crucial for detailed analyses of physical activity patterns.\n\nWhile we did not perform a direct comparison to simpler baselines, our method's ability to generalize to different datasets and participant groups, as demonstrated by its performance on the STAMP-2 study, suggests its robustness and reliability. The STAMP-2 study involved participants with type-2 diabetes from a different geographical and demographic background, yet our algorithm maintained high accuracy, indicating its potential for broader applicability.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being publicly available. However, the models developed in this study are made freely available to apply to similar data in the statistical software environment R. This implies that while the raw evaluation files themselves may not be publicly released, the tools necessary to replicate the evaluations are accessible. The method is open source, meaning all code is freely available online. This allows other researchers to use and build upon the work, ensuring transparency and reproducibility. The specific details about the license under which the code is released are not provided, but the emphasis on open source suggests it is intended for broad use and collaboration."
}