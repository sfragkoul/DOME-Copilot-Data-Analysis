{
  "publication/title": "Development and Validation of a Nocturnal Hypoglycaemia Risk Model for Patients With Type 2 Diabetes Mellitus",
  "publication/authors": "The authors who contributed to this article are:\n\nChen Gong, who was responsible for drafting the original manuscript.\n\nHuiqun Huang, who contributed to the conceptualization of the study.\n\nTingting Cai, who reviewed and edited the manuscript.\n\nYing Wang, who performed the formal analysis.\n\nXuelian Xiong, who reviewed and edited the manuscript.\n\nYunfeng Zhou, who conducted the formal analysis.\n\nTingting Zhou, who contributed to the methodology.\n\nQi Sun, who contributed to the conceptualization.\n\nAll authors approved the manuscript and accept accountability for the work.",
  "publication/journal": "Nursing Open",
  "publication/year": "2024",
  "publication/pmid": "39363560",
  "publication/pmcid": "PMC11449968",
  "publication/doi": "https://doi.org/10.1002/nop2.70055",
  "publication/tags": "- Continuous glucose monitoring\n- Machine learning\n- Nocturnal hypoglycaemia\n- Prediction model\n- Type 2 diabetes mellitus\n- Risk assessment\n- Medical data analysis\n- Patient safety\n- Diabetes management\n- Clinical decision support",
  "dataset/provenance": "The dataset utilized in this study was sourced from dynamic blood glucose monitoring of patients with type 2 diabetes mellitus (T2DM) who were admitted to the Department of Endocrinology and Metabolism at a hospital in Shanghai, China. The data collection period spanned from November 2020 to January 2022. The study included patients who underwent continuous glucose monitoring (CGM) for at least 24 hours.\n\nA total of 4015 continuous glucose monitoring data points were collected from 440 patients. This dataset was used to build a risk prediction model for nocturnal hypoglycemia in T2DM patients. The model incorporated 28 variables, which were selected based on a comprehensive review of previous studies. These variables included various CGM parameters such as mean blood glucose, glycated hemoglobin A1c (eHbA1c), standard deviation (SD), coefficient of variation (CV), low amplitude of glycemic excursions (LAGE), blood glucose risk index (BGRI), low blood glucose index (LBGI), high blood glucose index (HBGI), minimum blood glucose (Min), maximum blood glucose (Max), coefficient of glycemic variation (JIndex), average daily risk range (ADRR), a weighted average glucose value (M value), percentage of time below the target glucose range (TBR), percentage of time in the target glucose range (TIR), and percentage of time above the target glucose range (TAR).\n\nThe dataset was analyzed using statistical methods and machine learning algorithms, including logistic regression, random forest, and light gradient boosting machine (LGBM). The predictive performance of these models was evaluated using metrics such as AUC, accuracy, specificity, recall rate, precision, F1 score, and the Kolmogorov\u2013Smirnov test. The LGBM model demonstrated the highest predictive performance, indicating its effectiveness in identifying high-risk groups for nocturnal hypoglycemia.",
  "dataset/splits": "The dataset was divided into three splits: a training set, validation set 1, and validation set 2. The training set and validation set 1 were created in a 7:3 ratio through random sampling. This means that approximately 70% of the data was used for training, while 30% was allocated to validation set 1.\n\nValidation set 2 was formed by extracting one continuous glucose monitoring (CGM) measurement from each patient, resulting in a dataset with 440 data points. This set was used to further validate the models' performance.\n\nThe training set was used to cross-validate the hyperparameters of the optimized model using a 10-fold approach to prevent overfitting. The remaining 30% of the data constituted validation set 1. The models\u2014Logistic Regression (LR), Random Forest (RF), and Light Gradient Boosting Machine (LGBM)\u2014were trained using 70% of the dataset.",
  "dataset/redundancy": "The dataset used in this study comprised continuous glucose monitoring (CGM) data and 28 variables. The data was split into training and validation sets in a 7:3 ratio through random sampling. Additionally, one CGM measurement was randomly extracted from each patient to form a validation set with 440 data points.\n\nThe training set was further divided using a 10-fold cross-validation approach to optimize the model's hyperparameters and prevent overfitting. This method ensures that the training and test sets are independent by rotating the data used for training and validation in each fold.\n\nThe remaining 30% of the data constituted the validation set, which was completely isolated from the training set. This isolation ensures that the validation set provides an unbiased evaluation of the model's performance.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in the context of hypoglycemia prediction. The use of CGM data and a comprehensive set of variables allows for a robust analysis and model development. The random sampling and cross-validation techniques employed ensure that the dataset is representative and that the models are generalizable to new, unseen data.",
  "dataset/availability": "The datasets utilized in this study are not publicly available. However, they can be obtained from the first author upon reasonable request. This approach ensures that the data is shared responsibly and in accordance with ethical guidelines. The data was collected from 440 patients, with a total of 4015 continuous glucose monitoring data points. The dataset includes various CGM parameters and other relevant variables that were used to build and validate the predictive models for nocturnal hypoglycaemia. The data was split into training and validation sets, with specific ratios used for model development and evaluation. The training set constituted 70% of the data, while the remaining 30% was used for validation. Additionally, a separate validation set was created by randomly sampling one CGM measurement from each patient, resulting in a dataset with 440 data points. This careful splitting of the data ensures that the models were trained and validated on independent datasets, enhancing the robustness of the results. The study adhered to the principles of the Helsinki Declaration, and informed consent was obtained from all participants. The data was used anonymously to protect the privacy of the individuals involved.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are Logistic Regression (LR), Random Forest (RF), and Light Gradient Boosting Machine (LGBM). These are well-established algorithms in the field of machine learning and are not new.\n\nLR is a linear classification model widely used in disease prediction due to its simplicity and ease of interpretation. RF and LGBM are decision tree models known for their efficiency in handling large-scale data and enhancing training speed.\n\nThe choice of these algorithms was driven by their suitability for binary classification tasks, which is relevant for predicting nocturnal hypoglycaemia. The study aimed to develop a prediction model for nocturnal hypoglycaemia in patients with Type 2 Diabetes Mellitus (T2DM) using these machine learning algorithms.\n\nThe algorithms were selected based on their ability to handle different aspects of the data, such as missing values and feature correlations. For instance, LGBM automatically learns the data distribution and assigns a default direction for missing values, while RF randomly selects a subset of features to reduce the impact of highly correlated features. These characteristics make them effective for the specific predictive task at hand.\n\nThe study focused on applying these algorithms to a medical context rather than developing new machine-learning algorithms. Therefore, the algorithms were not published in a machine-learning journal but in a nursing and medical research journal, as the primary contribution is in the medical field. The algorithms were used to identify high-risk patients for nocturnal hypoglycaemia and to develop targeted intervention programs.",
  "optimization/meta": "The study does not employ a meta-predictor approach. Instead, it utilizes three distinct machine learning algorithms\u2014Logistic Regression (LR), Random Forest (RF), and Light Gradient Boosting Machine (LGBM)\u2014to build predictive models for nocturnal hypoglycaemia in patients with type 2 diabetes mellitus (T2DM). Each of these models was trained and validated independently using the same dataset, which was split into training and validation sets.\n\nThe training set, comprising 70% of the data, was used to develop the models, while the remaining 30% constituted the validation set. Additionally, a separate validation set 2 was created by randomly sampling one continuous glucose monitoring (CGM) measurement from each patient, resulting in 440 data points. This approach ensures that the training data is independent for each model, preventing data leakage and maintaining the integrity of the validation process.\n\nThe models were evaluated using various metrics, including the area under the receiver operating characteristic curve (AUC), specificity, accuracy, precision, recall rate, F1 score, and Kolmogorov\u2013Smirnov (KS) test. The LGBM model demonstrated the highest predictive performance, outperforming LR and RF in most metrics. This indicates that LGBM is the most effective model for predicting nocturnal hypoglycaemia in this study.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps to ensure the data was suitable for training and validation. The dataset comprised continuous glucose monitoring (CGM) data and 28 variables, which were split into training and validation sets in a 7:3 ratio through random sampling. One CGM measurement was randomly extracted from each patient to form a validation set with 440 data points.\n\nFor the Logistic Regression (LR) model, missing values were handled using the multiple imputation method via the mice package in R studio. This approach ensures that missing data does not bias the model's predictions. In the Random Forest (RF) model, missing values were managed by selecting the best split that ignores the missing values during the construction of decision trees. This method allows the algorithm to consider complete subsets of features during each split, ensuring robust training.\n\nThe LightGBM model, which uses the gradient boosting method, has built-in support for missing values. It automatically learns the data distribution and assigns a default direction for missing values, making it efficient in handling incomplete datasets. Additionally, LightGBM employs a histogram algorithm to speed up training by binning the features, which reduces the impact of interactions among features on the model.\n\nThe dataset included various CGM parameters such as mean blood glucose, glycated haemoglobin A1c (eHbA1c), standard deviation (SD), coefficient of variation (CV), and others. These parameters were non-normally distributed, and thus, non-parametric methods like the Mann\u2013Whitney U-test were used for comparisons. Discrete data were described using frequency, composition ratio, or percentage, and the chi-square test was employed for group comparisons.\n\nTo prevent overfitting, the training set was used for cross-validation of the hyperparameters using a 10-fold approach. This method ensures that the model generalizes well to unseen data. The remaining 30% of the data constituted the validation set, which was used to estimate the model's performance.\n\nIn summary, the data encoding and preprocessing involved handling missing values appropriately for each model, using non-parametric methods for non-normally distributed data, and employing cross-validation to optimize hyperparameters and prevent overfitting. These steps ensured that the machine-learning algorithms were trained on high-quality data, leading to robust and reliable predictive models.",
  "optimization/parameters": "In our study, we utilized a total of 28 variables as input parameters for our models. These parameters were selected based on a comprehensive review of previous studies and included a mix of general, clinical, laboratory, and continuous glucose monitoring (CGM) data. The CGM parameters encompassed various metrics such as mean blood glucose, glycated haemoglobin A1c, standard deviation, coefficient of variation, and several indices related to blood glucose levels and variability. Additionally, we considered demographic and clinical factors like age, sex, duration of diabetes, use of oral antidiabetic drugs, insulin therapy, and laboratory values such as creatinine and uric acid. The selection of these parameters aimed to provide a robust set of predictors for nocturnal hypoglycaemia, ensuring that our models could capture the complexity and variability of the condition.",
  "optimization/features": "The study utilized a dataset comprising 28 variables to build the prediction model for nocturnal hypoglycaemia in patients with type 2 diabetes mellitus (T2DM). These variables included a mix of continuous glucose monitoring (CGM) data and clinical parameters such as age, sex, duration of diabetes, oral antidiabetic drugs, insulin usage, creatinine, uric acid, glycated albumin, aspartate aminotransferase, and alanine aminotransferase.\n\nFeature selection was performed to identify the most influential characteristics of the predictive model. This process involved examining variables in single-factor analysis for Logistic Regression (LR), Random Forest (RF), and Light Gradient Boosting Machine (LGBM). The top 10 important predictors of nocturnal hypoglycaemia included TBR, M value, LBGI, Min, duration of diabetes, Max, CV, insulin, BGRI, and SD. Notably, eight of these variables were CGM parameters from the previous day, highlighting their significance in predicting nocturnal hypoglycaemia.\n\nThe feature selection process was conducted using the training set only, ensuring that the validation set remained independent and unbiased. This approach helps in preventing overfitting and ensures that the model's performance is generalizable to new, unseen data.",
  "optimization/fitting": "The study utilized three machine learning algorithms\u2014Logistic Regression (LR), Random Forest (RF), and Light Gradient Boosting Machine (LGBM)\u2014to build a prediction model for nocturnal hypoglycaemia in patients with Type 2 Diabetes Mellitus (T2DM). The dataset comprised 4015 continuous glucose monitoring (CGM) data points from 440 patients, with 28 variables considered as predictors.\n\nTo address the potential issue of overfitting, especially given the relatively large number of parameters compared to the number of training points, several strategies were employed. For LR, the collinearity diagnostic coefficient and variance inflation factor (VIF) were tested among highly correlated predictors to ensure that multicollinearity did not inflate the model's complexity. Additionally, the training set was used to cross-validate the hyperparameters of the optimized model using a 10-fold approach, which helps in preventing overfitting by ensuring that the model generalizes well to unseen data.\n\nRF and LGBM also have built-in mechanisms to mitigate overfitting. RF randomly selects a subset of features from all available features when constructing each tree, which reduces the impact of highly correlated features on the model. LGBM, using the gradient boosting method, adds new trees to correct the residuals of all previous trees, allowing it to adapt to some level of collinearity among features. Moreover, LGBM offers various regularization methods, including L1 and L2 regularization, which help in mitigating the effects of feature correlation and preventing overfitting. LGBM also uses a histogram algorithm to speed up training, which bins the features and can reduce the impact of interactions among features on the model.\n\nTo rule out underfitting, the models were evaluated using multiple performance metrics, including the area under the receiver operating characteristic curve (AUC), specificity, accuracy, precision, recall rate, F1 score, and Kolmogorov\u2013Smirnov (KS) test. The AUC indicates the probability that the model precisely evaluates the risk of nocturnal hypoglycaemia, with higher values indicating better performance. The F1 score and KS score were also used to assess the prediction effect of the model, with higher scores indicating higher precision. The calibration of the model was assessed using the Hosmer-Lemeshow goodness-of-fit test and calibration curve, ensuring that the predicted probabilities align well with the observed outcomes.\n\nIn summary, the study employed a combination of cross-validation, regularization techniques, and comprehensive performance evaluation to ensure that the models were neither overfitted nor underfitted, providing robust predictions for nocturnal hypoglycaemia in T2DM patients.",
  "optimization/regularization": "In our study, several regularization methods were employed to prevent overfitting and mitigate the effects of feature correlation. Specifically, we utilized L1 and L2 regularization techniques. These methods help to penalize large coefficients, thereby reducing the model's complexity and preventing it from fitting the noise in the training data. Additionally, we implemented a 10-fold cross-validation approach during the hyperparameter optimization process. This technique ensures that the model generalizes well to unseen data by training and validating it on different subsets of the data. Furthermore, the LightGBM model, which we used, incorporates a histogram-based algorithm that bins the features, reducing the impact of interactions among features on the model. This approach not only speeds up the training process but also contributes to the model's robustness by handling feature interactions more effectively.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters used in this study are not explicitly detailed in the provided information. However, it is mentioned that the training set was used to cross-validate the hyperparameters of the optimized model using a 10-fold approach to prevent overfitting. This indicates a structured approach to hyperparameter tuning, although the specific configurations and schedules are not reported.\n\nThe study utilized three machine learning algorithms: Logistic Regression (LR), Random Forest (RF), and Light Gradient Boosting Machine (LGBM). Each of these models has its own set of hyperparameters that were likely optimized during the training process. For instance, LR involves testing collinearity diagnostic coefficients and variance inflation factors (VIF) among highly correlated predictors. RF randomly selects a subset of features from all available features when constructing each tree, which can reduce the impact of highly correlated features on the model. LGBM, using the gradient boosting method, adds new trees to correct the residuals of all previous trees, allowing it to adapt to some level of collinearity among features.\n\nThe data set comprised continuous glucose monitoring (CGM) data and 28 variables. The training set and validation set 1 were split in a 7:3 ratio by random sampling. One CGM measurement was extracted by randomly sampling from every patient to form a data set with 440 data points for validation set 2. LR, RF, and LGBM were trained using 70% of the data set, with the remaining 30% constituting the validation set.\n\nWhile the specific hyper-parameter configurations and optimization schedules are not reported, the methods used for model training and validation are described. The study emphasizes the importance of comprehensive assessment metrics such as the area under the ROC curve (AUC), specificity, accuracy, precision, recall rate, F1 score, and Kolmogorov\u2013Smirnov (KS) test to verify and compare the predictive performances of the models. The AUC indicates high accuracy above 0.9, low accuracy at 0.5\u20130.7, and moderate accuracy at 0.7\u20130.9. The Normal Approximation Method was used to calculate the 95% confidence interval for the AUC.\n\nIn summary, while the exact hyper-parameter configurations and optimization schedules are not detailed, the study provides a clear methodology for model training and validation. The focus is on ensuring robust and comprehensive evaluation of the predictive models using various metrics.",
  "model/interpretability": "The models employed in this study, namely Logistic Regression (LR), Random Forest (RF), and Light Gradient Boosting Machine (LGBM), vary in their levels of interpretability.\n\nLogistic Regression is inherently transparent and interpretable. It provides a clear and straightforward relationship between the input features and the output probability of nocturnal hypoglycaemia. Each coefficient in the LR model indicates the strength and direction of the relationship between a specific feature and the likelihood of the event. For instance, a positive coefficient for a feature like insulin usage would suggest that higher insulin usage increases the probability of nocturnal hypoglycaemia.\n\nRandom Forest, while more complex than LR, offers some level of interpretability through feature importance scores. These scores indicate which features are most influential in making predictions. For example, the model might reveal that the time below range (TBR) from the previous day is a critical factor in predicting nocturnal hypoglycaemia. However, the individual decision trees within the forest are not easily interpretable on their own, making RF somewhat of a \"gray box\" model.\n\nLight Gradient Boosting Machine (LGBM) is generally considered a black-box model due to its complexity and the way it builds multiple decision trees sequentially. However, LGBM provides feature importance scores and SHAP (SHapley Additive exPlanations) values, which can help in understanding the contribution of each feature to the model's predictions. For example, SHAP values can show that a high TBR from the previous day significantly increases the risk of nocturnal hypoglycaemia. Additionally, LGBM's ability to handle feature interactions and collinearity makes it powerful but less transparent compared to LR.\n\nIn summary, while LR is the most transparent model, RF and LGBM offer varying degrees of interpretability through feature importance and SHAP values. This allows for a balance between model complexity and the ability to understand the underlying factors contributing to nocturnal hypoglycaemia predictions.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict the occurrence of nocturnal hypoglycaemia in patients with type 2 diabetes mellitus (T2DM). The model categorizes patients into two groups: those at high risk of experiencing nocturnal hypoglycaemia (defined as blood glucose levels \u2264 3.9 mmol/L between 0:00 AM and 6:00 AM) and those at low risk. This classification is achieved using machine learning algorithms, specifically Logistic Regression (LR), Random Forest (RF), and Light Gradient Boosting Machines (LGBM). The performance of these models was evaluated using metrics such as the area under the receiver operating characteristic curve (AUC), specificity, accuracy, precision, recall rate, F1 score, and Kolmogorov\u2013Smirnov (KS) test. The LGBM model demonstrated the highest predictive performance among the three algorithms, indicating its effectiveness in classifying patients based on their risk of nocturnal hypoglycaemia.",
  "model/duration": "The execution time for the models varied depending on the algorithm used. Logistic Regression (LR) is known for its simplicity and efficiency, typically requiring less time to train compared to more complex models. Random Forest (RF) and Light Gradient Boosting Machines (LGBM) are decision tree-based models that can handle large-scale data efficiently. However, the exact execution times were not explicitly detailed in the study. The training process involved cross-validation using a 10-fold approach to optimize hyperparameters, which can be time-consuming but ensures robust model performance. The models were trained using 70% of the dataset, with the remaining 30% used for validation. The use of out-of-bag (OOB) samples in RF and the histogram algorithm in LGBM helped speed up the training process and reduce the impact of feature interactions. Overall, the models demonstrated favorable predictive performances, with LGBM showing the highest area under the ROC curve (AUC) among the three algorithms.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the models involved several key metrics and methods to ensure comprehensive assessment. The receiver operating characteristic (ROC) curve was employed to reflect the relationship between predicted risk profiles and actual nocturnal hypoglycaemia events. The area under the ROC curve (AUC) was calculated to indicate the probability of the model accurately evaluating the risk of nocturnal hypoglycaemia. An AUC above 0.9 signifies high accuracy, while values between 0.7 and 0.9 indicate moderate accuracy.\n\nIn addition to the AUC, specificity, accuracy, precision, recall rate, F1 score, and Kolmogorov\u2013Smirnov (KS) test were used to verify and compare the predictive performances of the models. Precision was determined using the ratio of true positives to the sum of true positives and false positives, while recall was calculated as the ratio of true positives to the sum of true positives and false negatives. Specificity was measured using the ratio of true negatives to the sum of false positives and true negatives. The F1 score, which combines precision and recall, was calculated as the harmonic mean of these two metrics. The KS score was derived from the maximum difference between the recall and the false positive rate.\n\nThe calibration of the models was assessed using the Hosmer-Lemeshow goodness-of-fit test and calibration curves. Furthermore, a decision curve analysis (DCA) was applied to estimate the value of the predictive models across all possible thresholds. DCA considers the accuracy of the model, the consequences of decisions, and patient preferences, making it practical for clinical decision support systems. It evaluates the net benefit, which represents the benefit of correctly classifying cases minus the risks and costs associated with incorrect classification.\n\nThe models were trained using 70% of the dataset, with the remaining 30% constituting the validation set. A 10-fold cross-validation approach was used to prevent overfitting during the hyperparameter optimization of the models. Additionally, an independent validation set was used to estimate the model performance, ensuring that the results were not biased by the training data.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the predictive models for nocturnal hypoglycaemia. These metrics include the area under the receiver operating characteristic curve (AUC), specificity, accuracy, precision, recall rate, F1 score, and Kolmogorov\u2013Smirnov (KS) test. The AUC provides an overall measure of the model's ability to discriminate between positive and negative cases, with higher values indicating better performance. We also calculated the 95% confidence interval for the AUC using the Normal Approximation Method to assess the reliability of our estimates.\n\nSpecificity, accuracy, precision, and recall rate offer detailed insights into the model's performance. Specificity measures the true negative rate, accuracy reflects the overall correctness of the model, precision indicates the proportion of true positives among all positive predictions, and recall (or sensitivity) shows the proportion of true positives among all actual positives. The F1 score, which is the harmonic mean of precision and recall, provides a single metric that balances both concerns.\n\nThe KS score, calculated as the maximum difference between the recall and the false positive rate, helps in evaluating the model's ability to distinguish between high-risk and low-risk individuals. Higher F1 and KS scores indicate better model performance.\n\nAdditionally, we used the Hosmer-Lemeshow goodness-of-fit test and calibration curve to assess the calibration of the models. Decision curve analysis (DCA) was applied to estimate the clinical value of the predictive models across all possible thresholds. DCA considers the accuracy of the model, the consequences of decisions, and patient preferences, making it a practical tool for clinical decision support.\n\nThis set of metrics is representative of the literature, as it includes both common and advanced evaluation measures. The AUC, specificity, accuracy, precision, recall, and F1 score are standard in machine learning evaluations. The inclusion of the KS test and DCA adds depth to our analysis, ensuring a thorough assessment of model performance and clinical applicability.",
  "evaluation/comparison": "In our study, we evaluated the performance of three machine learning algorithms\u2014Logistic Regression (LR), Random Forest (RF), and Light Gradient Boosting Machine (LGBM)\u2014for predicting nocturnal hypoglycaemia in patients with type 2 diabetes mellitus (T2DM). These algorithms were chosen for their suitability in handling binary classification tasks, which is essential for predicting the occurrence of nocturnal hypoglycaemia.\n\nTo ensure a comprehensive evaluation, we compared the predictive performances of these models using several metrics, including the area under the receiver operating characteristic curve (AUC), specificity, accuracy, precision, recall rate, F1 score, and Kolmogorov\u2013Smirnov (KS) test. The AUC, in particular, provides a measure of the model's ability to distinguish between patients who will experience nocturnal hypoglycaemia and those who will not. An AUC above 0.9 indicates high accuracy, while values between 0.7 and 0.9 suggest moderate accuracy.\n\nThe dataset used for this study comprised 4015 continuous glucose monitoring (CGM) data points from 440 patients. The data was split into training and validation sets, with the training set used to optimize the models' hyperparameters through 10-fold cross-validation. This approach helps in preventing overfitting and ensures that the models generalize well to unseen data.\n\nIn addition to the standard metrics, we employed the Hosmer-Lemeshow goodness-of-fit test and calibration curves to assess the calibration of the models. Decision Curve Analysis (DCA) was also applied to evaluate the clinical usefulness of the predictive models by considering the net benefit, which accounts for the accuracy of the model, the consequences of decisions, and patient preferences.\n\nThe results showed that all three models\u2014LR, RF, and LGBM\u2014demonstrated favorable predictive performances. However, LGBM outperformed the other two models, achieving the highest AUC of 0.869. This indicates that LGBM is the most effective among the compared models for predicting nocturnal hypoglycaemia in T2DM patients.\n\nIn summary, our evaluation involved a thorough comparison of LR, RF, and LGBM using multiple performance metrics and validation techniques. The results highlight the superior performance of LGBM in predicting nocturnal hypoglycaemia, providing valuable insights for clinical decision-making and patient management.",
  "evaluation/confidence": "The evaluation of our models included several performance metrics, and we ensured that these metrics were robust and reliable. For the area under the receiver operating characteristic curve (AUC), we calculated the 95% confidence interval using the Normal Approximation Method. This provided a range within which we could be 95% confident that the true AUC value lies, giving us a measure of the precision of our AUC estimates.\n\nTo assess the statistical significance of our results, we employed various metrics such as specificity, accuracy, precision, recall rate, F1 score, and the Kolmogorov\u2013Smirnov (KS) test. These metrics were analyzed for each machine learning model to ensure a comprehensive evaluation. The F1 score, for instance, was calculated as the harmonic mean of precision and recall, providing a single metric that balances both concerns. The KS score, which measures the maximum difference between the cumulative distributions of the positive and negative classes, was also used to evaluate the models' ability to distinguish between high-risk and low-risk patients.\n\nThe decision curve analysis (DCA) was particularly useful in evaluating the clinical usefulness of our models. DCA considers not only the accuracy of the model but also the cost of false positives and false negatives, making it a practical tool for clinical decision support. The net benefit, a key measure in DCA, represents the benefit of correctly classifying cases minus the risks and costs associated with incorrect classification. This analysis helped us determine the threshold probabilities at which our models, particularly the LightGBM (LGBM) model, offered more benefits compared to other management strategies.\n\nIn summary, our evaluation process was thorough and included confidence intervals for key metrics, statistical significance tests, and practical clinical evaluations. This ensured that our claims about the superiority of our methods, particularly the LGBM model, were well-supported and reliable.",
  "evaluation/availability": "The datasets utilized during this study are available from the first author upon reasonable request. This approach ensures that the data can be accessed by other researchers for verification or further analysis, promoting transparency and reproducibility in scientific research. However, specific details about the licensing terms under which the data is shared are not provided. This means that interested parties would need to contact the first author to discuss the terms of data access and any potential restrictions that may apply."
}