{
  "publication/title": "A Robust and Accurate Deep-learning-based Method for the Segmentation of Subcortical Brain: Cross-dataset Evaluation of Generalization Performance",
  "publication/authors": "The authors who contributed to this article are Naoya Furuhashi, Shiho Okuhata, and Tetsuo Kobayashi. Naoya Furuhashi is the first author, and Shiho Okuhata is the second author. Tetsuo Kobayashi is the corresponding author and is affiliated with the Graduate School of Engineering at Kyoto University. The specific contributions of each author to the paper are not detailed.",
  "publication/journal": "Magnetic Resonance in Medical Sciences",
  "publication/year": "2021",
  "publication/pmid": "32389928",
  "publication/pmcid": "PMC8203473",
  "publication/doi": "doi:10.2463/mrms.mp.2019-0199",
  "publication/tags": "- Deep learning\n- Segmentation\n- Subcortical brain\n- Cross-dataset evaluation\n- Magnetic resonance imaging (MRI)\n- Generalization performance\n- Accuracy\n- Robustness\n- Neural network\n- Dilated convolution\n- Volumetric analysis\n- Psychiatric diseases\n- Neurological diseases\n- Automatic segmentation\n- 3D bounding boxes\n- FreeSurfer\n- FSL-FIRST\n- Dice coefficient\n- TensorFlow\n- Adam method",
  "dataset/provenance": "The datasets used in our study were sourced from several well-known repositories. The first supervised dataset was the Internet Brain Segmentation Repository (IBSR), which includes images of 18 healthy subjects, comprising 14 males and 4 females, aged between 7 and 71 years. This dataset features expert-labeled segmentations of subcortical brain structures and was obtained using 1.5T MRI scanners.\n\nThe second supervised dataset was from the Medical Image Computing and Computer Assisted Intervention (MICCAI) Multi-Atlas Labeling Challenge 2012. This dataset consists of images from 35 healthy subjects, including 13 males and 22 females, aged between 19 and 90 years. The subjects were divided into two groups of 15 and 20 people each to evaluate generalization performance. The images were acquired using a 1.5T MRI scanner with magnetization-prepared rapid acquisition of gradient echo (MPRAGE) sequences, and the voxel size was 1.0 \u00d7 1.0 \u00d7 1.0 mm\u00b3.\n\nFor unsupervised datasets, we utilized the Open Access Series of Imaging Studies 3 (OASIS-3), which includes images of 609 healthy controls and 489 Alzheimer\u2019s disease patients, totaling 2057 images. The subjects' ages ranged from 42 to 95 years. The images were collected using 1.5T and 3T MRI scanners with various voxel sizes. Additionally, we used the Information eXtraction from Images (IXI) dataset, which consists of images from 619 healthy subjects aged between 20 and 107 years. This dataset was collected at three hospitals in London using different MRI scanners and voxel sizes.\n\nThese datasets have been widely used in the community for evaluating segmentation methods and have been referenced in previous studies. The IBSR and MICCAI datasets, in particular, have been instrumental in validating the performance of various segmentation algorithms, including deep learning methods. The unsupervised datasets, OASIS-3 and IXI, were used to qualitatively evaluate the robustness of our proposed segmentation method across different MRI scanners and imaging conditions.",
  "dataset/splits": "The dataset used in the study was divided into several splits for different purposes. For the MICCAI Multi-Atlas Labeling Challenge 2012 dataset, the 35 healthy subjects were divided into two groups: one consisting of 15 people and the other of 20 people. This split was used to evaluate generalization performance.\n\nAdditionally, a part of the MICCAI dataset, specifically the 15 people used in the MICCAI competition, was used to validate hyperparameters such as the dilation rates. This validation data was not used in the subsequent testing.\n\nFor the unsupervised datasets, the OASIS-3 dataset consisted of 2057 images from 609 healthy controls and 489 Alzheimer\u2019s disease patients, with most subjects undergoing multiple image acquisitions. The IXI dataset included images of 619 healthy subjects.\n\nThe IBSR dataset, which was also used, consisted of images of 18 healthy subjects. The left and right brain structures were treated without distinction by inverting the left brain structures to the right, effectively doubling the number of samples for each structure.\n\nIn summary, the datasets were split into training, validation, and testing sets, with specific subsets used for hyperparameter validation and cross-dataset evaluation. The distribution of data points varied across these splits, with some datasets undergoing multiple image acquisitions, leading to a larger total number of images.",
  "dataset/redundancy": "The datasets used in our study were split to evaluate generalization performance. For the MICCAI Multi-Atlas Labeling Challenge 2012 dataset, the 35 healthy subjects were divided into two groups: one with 15 subjects and another with 20 subjects. This split was used to assess how well the proposed method could generalize to new, unseen data.\n\nTo ensure independence between training and test sets, we used different subsets of the MICCAI dataset for validation and testing. Specifically, the 15-subject group was used to validate hyperparameters such as dilation rates, while the 20-subject group was reserved for testing. This approach prevented any overlap between the validation and test sets, ensuring that the evaluation was conducted on truly independent data.\n\nThe distribution of our datasets compares favorably to previously published machine learning datasets in the field of medical imaging. For instance, the IBSR dataset consists of images from 18 healthy subjects, while the MICCAI dataset includes images from 35 healthy subjects. These sample sizes are typical for studies focusing on subcortical brain segmentation and are sufficient to train and evaluate deep learning models effectively. Additionally, the unsupervised datasets, such as OASIS-3 and IXI, include a large number of subjects, providing a robust basis for qualitative evaluation.\n\nIn summary, the datasets were carefully split to ensure independence between training and test sets, and the distribution of subjects is consistent with other published datasets in the field. This approach helps to validate the generalization performance of the proposed method and ensures that the results are reliable and reproducible.",
  "dataset/availability": "The datasets used in this study are publicly available, ensuring reproducibility and accessibility for further research. The Internet Brain Segmentation Repository (IBSR) dataset can be accessed at https://www.nitrc.org/projects/ibsr/. This dataset includes images of 18 healthy subjects along with expert-labeled segmentations of their subcortical brains. The Medical Image Computing and Computer Assisted Intervention (MICCAI) Multi-Atlas Labeling Challenge 2012 dataset is available at https://my.vanderbilt.edu/masi/workshops/. It consists of images of 35 healthy subjects with expert-labeled segmentations of their subcortical brains. The Open Access Series of Imaging Studies 3 (OASIS-3) dataset, which includes images of 609 healthy controls and 489 Alzheimer\u2019s disease patients, can be found at https://www.oasis-brains.org. The Information eXtraction from Images (IXI) dataset, comprising images of 619 healthy subjects, is accessible at https://brain-development.org/ixi-dataset/.\n\nAll these datasets are released under licenses that permit their use for research purposes, facilitating the validation and comparison of segmentation methods. The availability of these datasets in public forums ensures that other researchers can replicate the experiments and build upon the findings presented in this study. The use of publicly available datasets also promotes transparency and collaboration within the scientific community.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the Adam method. This is a well-established technique for stochastic optimization, widely used in training deep learning models. It is not a new algorithm; it was introduced in a conference paper presented at The International Conference on Learning Representations in 2015. The decision to use Adam was driven by its efficiency and effectiveness in handling sparse gradients on noisy problems, which is particularly suitable for the complex task of subcortical brain segmentation.\n\nThe choice of using Adam in a medical imaging context, rather than a machine-learning journal, is due to the specific application and the focus of our research. Our primary goal was to develop a robust and accurate deep-learning-based method for the segmentation of subcortical brain structures, and the optimization algorithm was selected based on its proven performance in similar tasks. The implementation and results of using Adam in this context are relevant to the medical imaging community, which is why the findings were published in a journal focused on magnetic resonance in medical sciences.",
  "optimization/meta": "Not applicable. The model does not use data from other machine-learning algorithms as input. The proposed method is a deep learning segmentation technique that processes local 3D bounding boxes of subcortical brain structures using dilated convolution layers. It does not rely on predictions from other machine-learning methods to make its own predictions. The training and testing datasets are explicitly different, ensuring independence, but the model itself is not a meta-predictor. It directly segments the subcortical brain structures from MRI images without incorporating outputs from other algorithms.",
  "optimization/encoding": "In our study, we focused on encoding and preprocessing data to optimize the performance of our machine-learning algorithm for brain structure segmentation. We began by extracting local 3D bounding box images containing each target structure from whole brain images. This approach allowed us to handle the memory constraints of processing entire 3D brain images while preserving the 3D structural information.\n\nWe targeted seven subcortical brain structures: the thalamus, putamen, caudate, pallidum, hippocampus, amygdala, and accumbens. The 3D bounding boxes for each structure were determined based on the center coordinates, which were specified using FreeSurfer for automation. The sizes of these bounding boxes were tailored to match the dimensions of each structure, measured in terms of axial, coronal, and sagittal voxels. For instance, the bounding box for the thalamus was set to 40 x 48 x 48 voxels, while the caudate had a bounding box of 32 x 64 x 56 voxels.\n\nThis method of extracting local 3D bounding boxes not only reduced the memory requirements but also enhanced the generalization performance of our model. By focusing on specific structures rather than the entire brain, we minimized the variability in image quality and brain shape across different datasets. This approach made our model less susceptible to differences in MRI acquisition conditions and head positions, leading to more stable and accurate segmentation results.\n\nAdditionally, we employed data augmentation techniques during training to further improve the robustness of our model. This included randomly enlarging, reducing, and translating images, as well as adding Gaussian noise. These augmentations helped the model generalize better to unseen data by exposing it to a wider range of variations.\n\nIn summary, our data encoding and preprocessing involved extracting local 3D bounding boxes for targeted brain structures, automating the process with FreeSurfer, and applying data augmentation to enhance model robustness and generalization performance.",
  "optimization/parameters": "In our study, the model utilized local 3D bounding boxes containing each structure as input, which significantly reduced the required computer memory compared to using whole brain images. This approach also helped in maintaining the 3D structure of the brain, which is crucial for accurate segmentation.\n\nThe sizes of these 3D bounding boxes were determined based on the number of axial, coronal, and sagittal voxels for each specific structure. For instance, the bounding box for the thalamus was set to 40 x 48 x 48 voxels, while for the putamen it was 40 x 56 x 48 voxels. These dimensions were chosen to match the size of the respective structures, ensuring that the bounding boxes were neither too large nor too small.\n\nThe use of local 3D bounding boxes not only reduced the computational load but also improved the generalization performance of the model. By focusing on specific structures, the model became less susceptible to variations in brain shape and image quality across different datasets. This approach allowed the model to process both global and local information effectively, leading to more accurate and robust segmentation results.\n\nThe model was trained using a part of the MICCAI dataset, which consisted of 15 individuals. This dataset was used to validate hyperparameters such as dilation rates. The validation data were not used for testing to ensure an unbiased evaluation of the model's performance.\n\nFor optimization, the Adam method was employed with a learning rate set to 1 x 10^-5. A batch size of 2 was used due to memory constraints. Training was terminated when the dice coefficient decreased after 1000 iterations. The TensorFlow framework on Python was utilized for implementing the model. Training the proposed network for all structures took approximately 2 days on a personal computer equipped with an Intel Core i7-9750H CPU and an NVIDIA RTX 2060 GPU.\n\nIn summary, the input parameters were carefully selected to balance computational efficiency and model performance. The use of local 3D bounding boxes and optimized hyperparameters contributed to the model's ability to generalize well across different datasets and achieve accurate segmentation of subcortical brain structures.",
  "optimization/features": "In our study, the input features consist of local 3D bounding box images containing each specific subcortical brain structure. We targeted seven subcortical brain structures: the thalamus, putamen, caudate, pallidum, hippocampus, amygdala, and accumbens. These bounding boxes were extracted from whole brain images, with their sizes determined to match the structure's dimensions using the number of axial, coronal, and sagittal voxels.\n\nFeature selection was not performed in the traditional sense, as we directly used the 3D bounding box images as inputs. The bounding boxes were extracted based on the center coordinates of the structures, which were specified using FreeSurfer for automation. This approach allowed us to maintain the 3D structure of the target areas while reducing the need for extensive computer memory.\n\nThe use of local 3D bounding boxes as input features helped improve generalization performance and robustness. By focusing on specific structures, the neural network became less susceptible to variations in brain shape and image quality among different datasets. Additionally, this method preserved the 3D information of the structures, making it less sensitive to head position during MRI acquisition.",
  "optimization/fitting": "The fitting method employed in our study utilized a neural network architecture designed to handle the segmentation of subcortical brain structures. The network was trained using a dataset augmented through techniques such as random enlargement, reduction, translation of images, and the addition of Gaussian noise. This augmentation helped in increasing the effective size of the training dataset, thereby mitigating the risk of overfitting.\n\nTo further address the potential for overfitting, we implemented several strategies. Firstly, we used a validation dataset consisting of samples from the MICCAI dataset to tune hyperparameters such as dilation rates. This ensured that the model's performance was evaluated on data it had not seen during training, providing a more reliable estimate of its generalization capability. Additionally, the training process was halted when the dice coefficient, a measure of segmentation accuracy, ceased to improve after 1000 iterations. This early stopping criterion helped in preventing the model from becoming too complex and overfitting to the training data.\n\nThe optimization of the neural network was performed using the Adam method, with a learning rate set to 1 \u00d7 10^-5. A batch size of 2 was used due to memory constraints, and training was conducted on a personal computer equipped with an Intel Core i7-9750H CPU and an NVIDIA RTX 2060 GPU. The use of a relatively small batch size and a low learning rate helped in stabilizing the training process and reducing the risk of overfitting.\n\nTo rule out underfitting, we ensured that the model had sufficient capacity to learn the underlying patterns in the data. The network architecture included dilated convolution blocks that processed both global and local information in parallel, enabling accurate segmentation. Furthermore, the use of local 3D bounding boxes as input reduced the variability in the data, making it easier for the model to learn relevant features. The model's performance was also compared with state-of-the-art methods, and it demonstrated competitive or superior results, indicating that it was not underfitted.\n\nIn summary, the fitting method involved careful augmentation of the training data, use of a validation dataset for hyperparameter tuning, early stopping to prevent overfitting, and an appropriate network architecture to ensure sufficient model capacity. These measures collectively helped in achieving a well-fitted model that generalized well to unseen data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and improve the generalization performance of our neural network.\n\nOne of the key methods used was data augmentation. We augmented our training datasets by randomly enlarging, reducing, and translating images. Additionally, we added Gaussian noise to the images. This process helped to increase the diversity of the training data, making the model more robust and less likely to overfit to the specific characteristics of the training samples.\n\nAnother important technique was the use of local 3D bounding boxes containing each structure as input to the network. By focusing on these specific regions rather than the entire brain image, we reduced the complexity of the input data. This approach not only made the model less susceptible to variations in brain shape and image quality but also helped in maintaining the 3D information of the structures, which is crucial for accurate segmentation.\n\nWe also utilized dilated convolutions in our network architecture. Dilated convolutions allow the network to capture multi-scale contextual information without increasing the number of parameters or the computational cost. This helps in improving the model's ability to generalize to new, unseen data.\n\nFurthermore, we employed the Adam optimization method, which is known for its adaptive learning rate and efficient handling of sparse gradients. This method helped in stabilizing the training process and preventing the model from getting stuck in local minima, thereby reducing the risk of overfitting.\n\nThe training process was terminated when the dice coefficient decreased after 1000 iterations. This early stopping criterion ensured that the model did not continue to train beyond the point where it started to overfit to the training data.\n\nOverall, these techniques collectively contributed to enhancing the model's ability to generalize well to different datasets and improve the robustness of the segmentation results.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in the publication. Specifically, we utilized the Adam method for optimizing the neural network, with a learning rate set to 1 \u00d7 10^-5. The batch size was set to 2 due to memory constraints. Training was terminated when the dice coefficient decreased after 1000 iterations. These details are provided to ensure reproducibility of our experiments.\n\nThe model files and optimization parameters are not explicitly detailed in the publication, as the focus was on the methodology and results rather than the specific implementation details. However, the framework used was TensorFlow, and the experiments were conducted on a personal computer with an Intel Core i7-9750H CPU and an NVIDIA RTX 2060 GPU. Training the proposed network for all structures took approximately 2 days.\n\nRegarding the availability and licensing of the configurations and parameters, the publication does not specify the exact terms under which these details are shared. However, the datasets used, such as the Internet Brain Segmentation Repository (IBSR) and the Medical Image Computing and Computer Assisted Intervention (MICCAI) Multi-Atlas Labeling Challenge 2012, are publicly available and can be accessed through their respective websites. The IBSR dataset is available at https://www.nitrc.org/projects/ibsr/, and the MICCAI dataset can be found at https://my.vanderbilt.edu/masi/workshops/. These datasets are crucial for validating the proposed method and can be used by other researchers for similar studies.",
  "model/interpretability": "The model employed in our study is not entirely a black box, as it incorporates several design choices that enhance its interpretability. One key aspect is the use of local 3D bounding boxes containing each structure instead of whole brain images. This approach reduces the complexity of the input data, making it easier to understand how the model processes and segments specific brain structures.\n\nThe neural network architecture itself includes dilated convolutions, which allow the model to capture both global and local information simultaneously. This parallel processing of different scales of information can be visualized and understood through the receptive fields of the dilated convolutions. By examining these receptive fields, one can see how the model integrates information from various parts of the input data to make segmentation decisions.\n\nAdditionally, the use of shortcut connections in the neural network helps in propagating gradients more effectively during training, which can be interpreted as a way to maintain the flow of information through the network. This design choice aids in understanding how different layers of the network contribute to the final segmentation output.\n\nGroup normalization is another technique used to normalize the input and stabilize the learning process. This method ensures that the outputs do not become too small or too large, which can be interpreted as a way to control the scale of the features being learned by the network.\n\nThe activation function used, the leaky rectified linear unit, introduces non-linearity in a controlled manner, allowing the model to learn complex patterns while remaining interpretable. The use of different dilation rates in the dilated convolution blocks provides a clear example of how the model adapts to different scales of information, making it more transparent in its operation.\n\nOverall, while the model does involve complex neural network architectures, the design choices and techniques used enhance its interpretability. By focusing on local bounding boxes, using dilated convolutions, shortcut connections, group normalization, and specific activation functions, the model provides insights into how it processes and segments brain structures.",
  "model/output": "The model is designed for segmentation, which is a type of classification task at the pixel or voxel level. It specifically focuses on identifying and delineating seven subcortical brain structures within MRI images. These structures include the thalamus, putamen, caudate, pallidum, hippocampus, amygdala, and accumbens.\n\nThe output of the model is a segmented image where each voxel is classified as belonging to one of the targeted brain structures or the background. The segmentation process involves determining the boundaries of these structures within the input MRI data.\n\nThe model's performance is evaluated using the Dice coefficient, a metric that measures the overlap between the predicted segmentation and the ground truth. A Dice coefficient of 1 indicates perfect overlap, while a coefficient of 0 indicates no overlap. The model aims to achieve high Dice coefficients for accurate segmentation.\n\nThe segmentation results are visually represented and compared with other methods, such as 3D U-Net and Kushibar's method, to demonstrate the model's effectiveness and generalization performance. The model's output is also qualitatively evaluated on unsupervised datasets to assess its robustness and applicability to diverse MRI data.\n\nThe model's architecture includes dilated convolutions, which allow it to capture both global and local information, enhancing the accuracy of the segmentation. Group normalization is used to stabilize the training process, and a leaky rectified linear unit (ReLU) activation function is employed to introduce non-linearity into the network.\n\nThe training process involves optimizing the model using the Adam method, with a learning rate of 1e-5 and a batch size of 2. The training is conducted on a personal computer equipped with an Intel Core i7-9750H CPU and an NVIDIA RTX 2060 GPU. The training time for the proposed network is approximately 2 days, while the segmentation of each structure from a bounding box takes less than 1 second.",
  "model/duration": "The proposed method was trained using a personal computer equipped with an Intel Core i7-9750H 2.60 GHz CPU and an NVIDIA RTX 2060 GPU with 6 GB of memory. The training process for the proposed network, which involved all structures, took approximately 2 days to complete.\n\nFor segmentation tasks, the proposed method demonstrated efficient performance. FreeSurfer, used for extracting bounding boxes from whole brain images, took about 5 hours to segment the structures on a single CPU core. In contrast, the proposed network could segment each structure from the bounding box in less than 1 second.\n\nAdditionally, FSL-FIRST took about 5 minutes to segment all structures from a whole brain image on a single CPU core. Kushibar\u2019s method, which is based on a simple convolutional neural network, was reported to take less than 5 minutes for segmentation. These comparisons highlight the efficiency and speed of the proposed method in handling segmentation tasks.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed method focused on assessing its generalization performance, accuracy, and robustness. This was achieved through a series of cross-dataset experiments, where different datasets were used for training and testing. Specifically, two main experiments were conducted.\n\nIn the first experiment, the method was compared with two deep learning approaches: 3D U-Net and Kushibar's method. Training was performed using the IBSR dataset and testing with the MICCAI dataset, and vice versa. This setup allowed for a direct comparison of how well each method generalizes to unseen data. The dice coefficient, a metric ranging from 0 to 1, was used to evaluate the overlap between the ground truth and estimated segmentation areas. The proposed method demonstrated higher dice coefficients for most structures compared to Kushibar's method, indicating better performance.\n\nThe second experiment involved comparing the proposed method with conventional segmentation tools like FreeSurfer and FSL-FIRST. Training was conducted on augmented versions of the IBSR and MICCAI datasets, with testing performed on the respective other dataset. Augmentation techniques included random enlarging, reducing, translating images, and adding Gaussian noise. This experiment aimed to evaluate the method's robustness and accuracy under varied conditions. The proposed method again showed superior performance, with significantly higher dice coefficients for several structures.\n\nAdditionally, the proposed method and FSL-FIRST were applied to unsupervised datasets (OASIS-3 and IXI) to qualitatively assess their segmentation capabilities. The proposed method, utilizing a pre-trained model from the second experiment, demonstrated robust segmentation across different datasets, further highlighting its generalization performance.\n\nThe optimization of the neural network was done using the Adam method with a learning rate of 1e-5 and a batch size of 2, due to memory constraints. Training was halted when the dice coefficient ceased to improve after 1000 iterations. The experiments were conducted using TensorFlow on a personal computer equipped with an Intel Core i7-9750H CPU and an NVIDIA RTX 2060 GPU. Training the proposed network for all structures took approximately 2 days. The proposed method's efficiency was also noted, with segmentation taking less than 1 second per structure, compared to longer times for FreeSurfer and FSL-FIRST.",
  "evaluation/measure": "In our study, we primarily used the Dice coefficient as our performance metric to evaluate the segmentation of subcortical brain structures. The Dice coefficient is a widely accepted measure in the field of medical image segmentation, providing a value between 0 and 1 that indicates the overlap between the estimated segmentation area and the ground truth. A Dice coefficient of 0 means no overlap, while a value of 1 indicates perfect overlap.\n\nWe evaluated the Dice coefficient for seven subcortical brain structures: the thalamus, putamen, caudate, pallidum, hippocampus, amygdala, and accumbens. This set of structures is representative of the subcortical brain regions commonly analyzed in volumetric studies related to psychiatric and neurological diseases.\n\nThe Dice coefficient was calculated for different datasets and under various experimental conditions. For instance, we compared our method with other deep learning approaches, such as 3D U-Net and Kushibar's method, using cross-dataset evaluations. We also compared our method with conventional segmentation tools like FreeSurfer and FSL-FIRST.\n\nIn addition to the Dice coefficient, we conducted statistical analyses using the Wilcoxon signed-rank test to determine the significance of the differences in performance between our method and the comparison methods. This statistical approach is standard in the literature for evaluating the significance of segmentation performance metrics.\n\nOverall, the use of the Dice coefficient, along with statistical validation, ensures that our performance measures are both representative and rigorous, aligning with established practices in the field of medical image segmentation.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of our proposed method with both deep learning and conventional segmentation methods using benchmark datasets. For the deep learning comparison, we evaluated our method against 3D U-Net and Kushibar's method. We performed cross-dataset experiments where we trained on the IBSR dataset and tested on the MICCAI dataset, and vice versa. These experiments allowed us to assess the generalization performance of our method in comparison to established deep learning techniques.\n\nIn the first set of experiments, we compared our method with 3D U-Net and Kushibar's method. 3D U-Net is a popular network for 3D segmentation, and we input the bounding box to the network. Kushibar's method, which uses a simple convolutional neural network with 2D whole brain images as input, is a state-of-the-art method for subcortical brain segmentation when training and testing are done on the same dataset. We cited the dice coefficient scores from Kushibar's cross-dataset evaluation to ensure a fair comparison.\n\nIn the second set of experiments, we compared our method with conventional segmentation methods using FreeSurfer and FSL-FIRST. We trained on the augmented IBSR dataset and tested on the MICCAI dataset, and vice versa. The training datasets were augmented by randomly enlarging, reducing, and translating images, and adding Gaussian noise. This augmentation helped us evaluate the robustness of our method against variations in image quality and brain shape.\n\nAdditionally, we applied our proposed method and FSL-FIRST to unsupervised OASIS-3 and IXI datasets to qualitatively evaluate the segmentation performance on more data without depending on MRI scanners. For the proposed method, we utilized the preceding model trained with the augmented datasets from the second experiment.\n\nOverall, our comparisons with publicly available methods and simpler baselines demonstrated the superior generalization performance, accuracy, and robustness of our proposed method.",
  "evaluation/confidence": "The evaluation of our method included statistical significance testing to ensure the robustness of our claims. We employed the Wilcoxon signed-rank test to compare the performance metrics, specifically the dice coefficients, between our proposed method and other deep learning methods, as well as conventional segmentation methods. This test helped us determine if the differences in dice coefficients were statistically significant.\n\nFor the comparison with deep learning methods, such as 3D U-Net and Kushibar's method, the Wilcoxon signed-rank test revealed that our proposed method had significantly higher dice coefficients for several subcortical brain structures. For instance, when training with the MICCAI dataset and testing with the IBSR dataset, our method showed significantly higher dice coefficients for the caudate, pallidum, and hippocampus compared to 3D U-Net. Similarly, when training with the IBSR dataset and testing with the MICCAI dataset, our method outperformed 3D U-Net in multiple structures, including the thalamus, putamen, caudate, pallidum, hippocampus, and accumbens.\n\nIn the comparison with conventional segmentation methods like FreeSurfer and FSL-FIRST, the Wilcoxon signed-rank test also indicated significant improvements. For the IBSR dataset, our method had significantly higher dice coefficients for several structures compared to FreeSurfer and for the caudate and accumbens compared to FSL-FIRST. For the MICCAI dataset, our method showed significant advantages over FreeSurfer and FSL-FIRST in multiple structures, demonstrating its robustness and generalization performance.\n\nThese statistical analyses provide confidence in the superiority of our method over existing techniques, both in terms of accuracy and reliability across different datasets. The use of the Wilcoxon signed-rank test ensures that the observed differences are not due to random chance, thereby strengthening our claims of improved performance.",
  "evaluation/availability": "Not applicable"
}