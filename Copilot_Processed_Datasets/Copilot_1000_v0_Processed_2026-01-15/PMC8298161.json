{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Behavioural Neurology",
  "publication/year": "2021",
  "publication/pmid": "34336000",
  "publication/pmcid": "PMC8298161",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Alzheimer's disease\n- Genetic analysis\n- Genome-wide association study (GWAS)\n- Deep learning\n- Classification models\n- ResNet\n- Convolutional neural networks (CNN)\n- Single nucleotide polymorphisms (SNPs)\n- Multitasking classification\n- Neuroimaging\n- Machine learning\n- Genetic susceptibility factors\n- Diagnostic capabilities\n- Statistical analysis\n- Neurodegenerative disorders",
  "dataset/provenance": "The dataset used in this study was obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. ADNI is a public-private partnership launched in 2004, funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, the Food and Drug Administration, private pharmaceutical companies, and non-profit organizations. The dataset includes 1461 individuals, comprising 622 with Alzheimer's disease (AD), 473 with mild cognitive impairment (MCI), and 366 healthy controls (HCs) from the ADNI 1, ADNI 2, and ADNI GO cohorts. The data includes Illumina SNP genotyping data, demographic information, and diagnosis information. The subjects were aged between 55 and 90 years, inclusive. The ADNI eligibility criteria ensured that the participants were appropriately categorized into normal subjects, MCI subjects, and AD subjects based on specific clinical and cognitive assessments. The dataset has been utilized in various studies within the community, focusing on the progression of Alzheimer's disease and related cognitive impairments.",
  "dataset/splits": "In our study, we utilized data from the Alzheimer's Disease Neuroimaging Initiative (ADNI) to investigate the progression of Alzheimer's disease (AD). The dataset was divided into two main groups: a training and validation group, and an independent test group.\n\nThe training and validation group consisted of 1316 subjects, which included 560 individuals with AD, 426 individuals with mild cognitive impairment (MCI), and 330 healthy controls (HC). This group was used to establish and optimize our predictive models. Within this group, 25% of the subjects were randomly selected to form a validation subset, which guided the choice of hyperparameters during model training.\n\nThe independent test group comprised 145 subjects, with 62 individuals diagnosed with AD, 47 with MCI, and 36 healthy controls. This group was used to evaluate the diagnostic performance of the models developed in the training phase.\n\nThe subjects in both groups were randomly divided to ensure a representative distribution of AD, MCI, and HC individuals, facilitating robust model training and evaluation.",
  "dataset/redundancy": "The datasets used in this study were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI). The subjects involved in the multitasking classification were randomly divided into a training group and an independent test group at a ratio of 9:1. This split ensures that the training group is used to optimize the model parameters, while the test group is used to evaluate the diagnostic value of the predictive models.\n\nTo enforce the independence of the training and test sets, the subjects were randomly assigned to either the training or test group without any overlap. This random assignment helps to prevent data leakage and ensures that the model's performance on the test set is a true reflection of its generalizability.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the field of Alzheimer's disease research. The training and validation group contained 560 subjects with Alzheimer's disease (AD), 426 subjects with mild cognitive impairment (MCI), and 330 healthy controls (HC). The test group consisted of 62 AD subjects, 47 MCI subjects, and 36 HC controls. This distribution allows for a comprehensive evaluation of the model's performance across different stages of cognitive impairment.\n\nAdditionally, to guide the choice of hyperparameters, 25% of the training group was randomly selected to form a validation group. This validation group is used to tune the model parameters and prevent overfitting, ensuring that the final model generalizes well to unseen data.",
  "dataset/availability": "The datasets utilized in this study were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI). The ADNI database is publicly accessible at http://adni.loni.usc.edu/. The data includes Illumina SNP genotyping data, demographic information, and diagnosis information for 1461 individuals, comprising 622 AD patients, 473 MCI subjects, and 366 healthy controls (HCs) from the ADNI 1, ADNI 2, and ADNI GO cohorts.\n\nThe ADNI initiative is a public-private partnership funded by the National Institutes of Health, the Department of Defense, and various private organizations. The data is disseminated by the Laboratory for Neuro Imaging at the University of Southern California. The datasets are made available to researchers under specific terms and conditions, ensuring that the data is used responsibly and ethically. The ADNI data is shared with the research community to facilitate the development of methods for solving the problems facing clinical trials in AD research, such as the development of successful treatments and the ability to measure their effectiveness.\n\nThe data used in this study was collected with informed consent from all participants, and the study was conducted with prior institutional review board approval. The ADNI data is available for download by researchers who agree to the data use agreement, which outlines the terms and conditions for using the data. This agreement ensures that the data is used for research purposes only and that the privacy and confidentiality of the participants are protected. The data use agreement also requires researchers to acknowledge the ADNI in any publications resulting from the use of the data.",
  "optimization/algorithm": "The optimization algorithm used in this study is the Adam algorithm, which is a first-order gradient-based optimization algorithm. It is not a new algorithm; it has been widely used and proven to be computationally efficient for training deep neural networks.\n\nThe Adam algorithm was chosen for its effectiveness in updating model parameters during the training stage. It was applied to update the model parameters with a batch size of 8. The learning rate was set to 1e-3 for the ResNet models and 1e-2 for the traditional CNN model. The maximum number of iterations was set to 20 for the ResNet models and 30 for the CNN model.\n\nThe focus of this study is on the application of deep learning in genomics, specifically for classifying Alzheimer's disease progression. The Adam algorithm was selected for its robustness and stability in training deep learning models, which is crucial for the complex task of genomic data analysis. The study compares the performance of different deep learning models, including ResNet18, ResNet34, and a traditional CNN, to identify the most effective model for this specific application.",
  "optimization/meta": "The model employed in this study does not function as a meta-predictor. Instead, it directly utilizes deep learning techniques to analyze SNP genotype data. Specifically, the model uses frameworks such as ResNet18, ResNet34, and a traditional CNN to classify subjects into different groups, such as Alzheimer's Disease (AD) patients, Healthy Controls (HCs), and Mild Cognitive Impairment (MCI) subjects.\n\nThe training process involves dividing the subjects into a training group and an independent test group at a ratio of 9:1. The training group is further split, with 25% of it used as a validation group to guide the choice of hyperparameters. This ensures that the training data is independent from the test data, maintaining the integrity of the model's evaluation.\n\nThe deep learning models are trained using the Adam optimizer, with specific learning rates and batch sizes tailored to each model. The ResNet models, in particular, demonstrate robustness and stability, outperforming the traditional CNN in classification tasks. The final chosen model, ResNet34, shows superior performance in distinguishing between AD, HC, and MCI groups.\n\nIn summary, the model does not rely on data from other machine-learning algorithms as input. It is a standalone deep learning approach that directly processes SNP genotype data to achieve classification. The training and validation processes are designed to ensure independence and robustness in the model's performance.",
  "optimization/encoding": "Before feeding the data into the neural network, several preprocessing steps were undertaken. Each subject's SNP genotype data underwent quality control and was then mapped to a 776 \u00d7 776 pixel grid. The pathology type was encoded using a one-hot encoding scheme, which served as the label for the classification task. This encoding ensures that each pathology type is represented as a binary vector, making it suitable for the neural network's input requirements.\n\nDuring the training stage, the SNP genotype data was input into the network. The model parameters were updated via backward propagation using the Adam optimization algorithm. This algorithm is known for its computational efficiency and is well-suited for training deep neural networks. The outputs of the network were used to classify the data, with the cross-entropy of the outputs serving as the loss function. Specifically, the network's output for each individual SNP could be a binary value, where 1 indicated the highest probability of the subject being an Alzheimer's Disease (AD) patient, and 0 indicated the highest probability of being a Healthy Control (HC) subject.\n\nThe deep-learning models, including ResNet18 and ResNet34, as well as a traditional CNN model, were trained on a GPU (GTX 1080 Ti) using PyCharm 3.5. For the ResNet models, the learning rate was set to 1e-3, with the Adam optimizer updating the model parameters using a batch size of 8. The maximum number of iterations was set to 20, and L2 regularization was applied to prevent overfitting. For the CNN model, the learning rate was set to 1e-2, with the same batch size and optimizer, but the maximum number of iterations was increased to 30. These settings ensured that the models were trained effectively and efficiently.",
  "optimization/parameters": "In our study, we utilized deep learning models, specifically ResNet18 and ResNet34, for classification tasks. These models have a predefined number of parameters due to their architecture. ResNet18 consists of 18 layers, while ResNet34 has 34 layers. The exact number of parameters in these models can vary slightly depending on the specific configuration, but typically, ResNet18 has around 11.7 million parameters, and ResNet34 has around 21.8 million parameters.\n\nThe selection of these models was based on their proven performance in various image classification tasks. We also compared these with a traditional CNN model to evaluate their effectiveness. The learning rate for the ResNet models was set to 1e-3, and for the CNN model, it was set to 1e-2. The Adam optimizer was used for updating model parameters with a batch size of 8. The maximum number of iterations was set to 20 for the ResNet models and 30 for the CNN model. L2 regularization was applied to prevent overfitting.\n\nThe choice of these hyperparameters was guided by empirical evidence and common practices in the field of deep learning. The learning rates and batch sizes were selected to ensure stable and efficient training, while the number of iterations was chosen to allow sufficient time for the models to converge. The use of L2 regularization helped in mitigating overfitting, thereby improving the generalization performance of the models.",
  "optimization/features": "The input features for the deep-learning genomics model were derived from SNP genotype data. Each subject's SNP genotype data was processed and mapped to a 776 \u00d7 776 pixel grid. This mapping resulted in a total of 602,276 features (776 \u00d7 776) used as input for the model.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the model utilized a deep residual network (ResNet) to automatically learn and extract relevant features from the input data. The last convolutional layer of the last residual block was chosen to extract normalized deep learning genomics (DLG) features. These features were then compared using a two-sample t-test with a false discovery rate to identify significant differences between groups.\n\nThe feature extraction process was conducted using the training set only, ensuring that the model's performance on the independent test set was not biased. This approach allowed the model to optimize its parameters based on the training data while maintaining the integrity of the test data for unbiased evaluation.",
  "optimization/fitting": "In our study, we employed deep residual networks, specifically ResNet18 and ResNet34, which inherently have a large number of parameters due to their deep architecture. To address the potential issue of overfitting, given the high number of parameters relative to the training points, we implemented several strategies.\n\nFirstly, we utilized L2 regularization, which helps to penalize large weights and thus prevents the model from becoming too complex and overfitting the training data. This technique is particularly effective in deep learning models where the number of parameters can be very large.\n\nSecondly, we employed a validation set, which was randomly chosen to be 25% of the training group. This validation set was used to guide the choice of hyperparameters and to monitor the model's performance during training. By doing so, we ensured that the model generalized well to unseen data and did not merely memorize the training set.\n\nAdditionally, we conducted 5-fold cross-validation in the training group to evaluate the model's performance more robustly. This technique helps to ensure that the model's performance is consistent across different subsets of the data, further mitigating the risk of overfitting.\n\nTo address underfitting, we used the Adam optimizer, which is known for its efficiency and appropriateness for training deep neural networks. The learning rates were set to 1e-3 for the ResNet models and 1e-2 for the traditional CNN model, ensuring that the models had sufficient capacity to learn from the data. The batch size was set to 8, and the maximum number of iterations was set to 20 for ResNet models and 30 for the CNN model, providing ample opportunity for the models to converge.\n\nOverall, these strategies helped us to balance the model complexity, ensuring that it neither overfitted nor underfitted the data.",
  "optimization/regularization": "In our study, we implemented L2 regularization to prevent overfitting of our models. This technique helps to penalize large weights in the network, thereby encouraging the model to learn more general features and reducing the risk of overfitting to the training data. By incorporating L2 regularization, we aimed to improve the generalization performance of our deep learning models on unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules used in our study are detailed within the publication. Specifically, for the ResNet models, the learning rate was set to 1e-3, with the Adam optimizer used to update model parameters. The batch size was 8, and the maximum number of iterations was 20. L2 regularization was applied to prevent overfitting. For the traditional CNN model, the learning rate was set to 1e-2, also using the Adam optimizer with a batch size of 8 and a maximum of 30 iterations.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the methods and configurations are described in sufficient detail to allow replication of the experiments. The software used for processing the deep-learning models was PyCharm 3.5 with GPU acceleration provided by a GTX 1080 Ti. The statistical analyses were performed using SPSS Version 22.0 and Matlab2016b.\n\nRegarding the availability and licensing of the configurations and parameters, the publication does not specify a particular license for the reported methods and hyper-parameters. However, the detailed descriptions provided should enable other researchers to implement and validate the findings using standard open-source tools and frameworks.",
  "model/interpretability": "The model employed in this study is not entirely a black box. To enhance interpretability, the last convolutional layer of the last residual block was made transparent. This allowed for the extraction of deep learning genomics (DLG) features using Grad-CAM and two-sample t-tests. Specifically, the last convolutional layer of the last residual block was chosen to extract normalized DLG features. These features were then compared using a two-sample t-test with a false discovery rate to identify significant differences between various groups, such as Alzheimer's Disease (AD) patients and healthy controls (HCs), as well as between Mild Cognitive Impairment (MCI) and AD groups, and between HC and MCI groups.\n\nMore than one thousand single nucleotide polymorphism (SNP) loci with significant differences were identified between these groups. Notably, several SNP loci, such as rs11136000 (CLU), rs3851179 (PICALM), rs2070045 (SORL1), and rs1699102 (SORL1), have been previously identified as risk factors for Alzheimer's Disease. These findings highlight the model's ability to uncover biologically relevant genetic markers, providing insights into the underlying mechanisms of the disease.\n\nAdditionally, the model's interpretability was further demonstrated by identifying more than ten thousand SNP loci that showed differences between the groups, with many of these loci being consistent with findings from previous genome-wide association studies (GWAS). This consistency reinforces the reliability and validity of the model's interpretations. Furthermore, sixty-six SNP loci were shared across different stages of Alzheimer's Disease progression, including well-known gene regions like CLU, PICALM, and SORL1. These shared loci provide valuable information for understanding the genetic basis of Alzheimer's Disease and its progression.",
  "model/output": "The model is a classification model. It is designed to classify subjects into different groups based on their SNP genotype data. Specifically, it categorizes individuals into Alzheimer's Disease (AD), Mild Cognitive Impairment (MCI), and Healthy Control (HC) groups. The output of the network for each individual SNP is a binary value, where 1 represents the highest probability of being an AD subject, and 0 represents the highest probability of being an HC subject. The model's performance is evaluated using metrics such as accuracy, sensitivity, specificity, and the area under the curve (AUC), which are standard for classification tasks. The classification results are used to update model parameters via backward propagation with the Adam algorithm, and the cross-entropy of the outputs is calculated as the loss function.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved several key steps to ensure robust and reliable results. Initially, subjects were randomly divided into a training group and an independent test group at a ratio of 9:1. The training group was further split, with 25% of the subjects randomly chosen to form a validation group. This validation group was used to guide the selection of hyperparameters.\n\nSeveral deep-learning models, including ResNet18, ResNet34, and a traditional CNN, were trained and their classification performance was compared. This comparison aimed to identify the optimal deep-learning genomics (DLG) model. Additionally, comparative trials were designed to verify the diagnostic capabilities of the DLG model against traditional GWAS analysis. The gene indicator theta was found to be the most directly related to SNP changes, and APOE \u03b54 status along with the normalized theta-value of significant SNP loci were identified as genetic predictors.\n\nTo evaluate the classification performance, 5-fold cross-validation was repeatedly conducted within the training group. The performance metrics used included accuracy, sensitivity, and specificity. These metrics were calculated using the formulas:\n\nAccuracy = (Tn + Tp) / (Tn + Tp + Fn + Fp)\n\nSensitivity = Tp / (Tp + Fn)\n\nSpecificity = Tn / (Tn + Fp)\n\nwhere Tn, Tp, Fn, and Fp denote true negatives, true positives, false negatives, and false positives, respectively.\n\nA receiver-operating characteristic (ROC) curve was generated to visually compare the results of different approaches, and the area under the curve (AUC) was computed to quantitatively evaluate the classification performance. The statistical analyses were performed using SPSS Version 22.0 software and Matlab2016b, with a significance level set at p values < 0.05.",
  "evaluation/measure": "In our study, we evaluated the classification performance using several key metrics to ensure a comprehensive assessment. The primary metrics reported include accuracy, sensitivity, specificity, and the area under the curve (AUC) of the receiver-operating characteristic (ROC) curve. Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as the true positive rate, indicates the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, represents the proportion of actual negatives that are correctly identified. The AUC provides a single scalar value that summarizes the performance of the classifier across all classification thresholds, offering a more intuitive comparison of different approaches.\n\nThese metrics are widely used in the literature and provide a robust framework for evaluating the performance of classification models. The use of ROC curves and AUC is particularly valuable as it allows for a visual and quantitative assessment of the trade-off between sensitivity and specificity. By reporting these metrics, we aim to provide a clear and representative evaluation of our models' performance, enabling comparisons with other studies in the field. Additionally, the use of 5-fold cross-validation ensures that our results are reliable and generalizable, further enhancing the representativeness of our performance measures.",
  "evaluation/comparison": "In the evaluation of our deep-learning genomics model, we conducted a comprehensive comparison with several other classification methods to assess its performance. We compared the results of our deep-learning models, including ResNet18, ResNet34, and a traditional CNN, to evaluate their classification performance. This comparison was crucial in screening for the optimal deep-learning genomics (DLG) model.\n\nAdditionally, we designed comparative trials to verify the diagnostic capabilities of our DLG model against traditional genome-wide association studies (GWAS) analysis. Among all the gene indicators, theta proved to be the most directly related to single nucleotide polymorphism (SNP) changes. APOE \u03b54 status and the normalized theta-value of the significant SNP loci found in this study were identified as genetic predictors. We used a support vector machine (SVM) with a linear kernel 500 times for the classification of traditional GWAS.\n\nTo evaluate the classification performance, we repeatedly conducted 5-fold cross-validation in the training group. The metrics used for evaluation included accuracy, sensitivity, and specificity. The mathematical expressions for these parameters were provided to ensure clarity and reproducibility. A receiver-operating characteristic (ROC) curve was produced to intuitively compare the results of the different approaches, and the area under the curve (AUC) of the ROC was computed to quantitatively evaluate classification performance.\n\nThe results showed that the deep-learning models, particularly ResNet34, exhibited superior performance compared to traditional GWAS analysis and the simpler CNN model. The ResNet models demonstrated robustness and stability, making them more suitable for genome applications. These findings suggest that deep-learning algorithms are effective in genome applications and that the development of deep-learning genomics is worthy of further exploration.",
  "evaluation/confidence": "The evaluation of the classification performance in this study includes several key metrics: accuracy, sensitivity, specificity, and the area under the curve (AUC) of the receiver-operating characteristic (ROC) curve. These metrics are presented with their respective confidence intervals, providing a measure of the variability and reliability of the results.\n\nThe performance metrics were evaluated using 5-fold cross-validation, which helps to ensure that the results are robust and not dependent on a particular split of the data. This method involves dividing the training data into five subsets, training the model on four of these subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. The final performance metrics are averaged across these five iterations, and the standard deviation is reported as the confidence interval.\n\nStatistical significance was assessed using a two-sample t-test with a false discovery rate correction. This approach helps to control for the increased risk of Type I errors that can occur when performing multiple comparisons. The p-values obtained from these tests indicate whether the differences in performance between the various models and baselines are statistically significant.\n\nThe results demonstrate that the deep-learning models, particularly ResNet18 and ResNet34, exhibit superior performance compared to traditional GWAS analysis and a simple CNN model. The high accuracy, sensitivity, and specificity, along with the AUC values, suggest that these models are effective in classifying the different groups. The statistical significance of these results further supports the claim that the deep-learning models are superior to the baselines.\n\nIn summary, the performance metrics include confidence intervals, and the results are statistically significant, providing strong evidence that the deep-learning models, especially ResNet34, are more effective for classification tasks in this study.",
  "evaluation/availability": "The datasets used in this study were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI). These datasets are publicly available and can be accessed through the ADNI website at http://adni.loni.usc.edu/. The ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of Southern California. The data includes a variety of information, such as clinical data, genetic data, and brain imaging, which were utilized in our research.\n\nThe ADNI data is made available to researchers under specific terms and conditions. These conditions typically include proper citation of the ADNI in any publications resulting from the use of the data, adherence to data usage agreements, and compliance with ethical guidelines for research involving human subjects. The exact licensing details and terms of use can be found on the ADNI website.\n\nIn summary, the raw evaluation files are available to the public through the ADNI initiative. Researchers interested in accessing these datasets should visit the ADNI website for detailed information on how to obtain the data and the associated terms of use."
}