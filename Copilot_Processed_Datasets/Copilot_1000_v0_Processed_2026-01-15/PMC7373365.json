{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "J Urol.",
  "publication/year": "2020",
  "publication/pmid": "30810465",
  "publication/pmcid": "PMC7373365",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Vesico-Ureteral Reflux\n- Urinary Tract Infection\n- Machine Learning\n- Predictive Modeling\n- Pediatric Urology\n- Optimal Classification Trees\n- Recurrent UTI\n- Clinical Decision-Making\n- Data-Driven Medicine\n- Pediatric Health",
  "dataset/provenance": "The dataset used in this study was derived from two comprehensive trials: the Randomized Intervention for Children with Vesico-Ureteral Reflux (RIVUR) and the Careful Urinary Tract Infection Evaluation (CUTIE). These trials provided robust and well-described cohort data, making them ideal for developing a predictive model.\n\nA total of 500 participants were included, all of whom had not been exposed to prophylactic antibiotics. Among these, 305 participants were from the RIVUR trial, and 195 were from the CUTIE trial. The mean age of the participants was 21 months, with a standard deviation of 19 months. The cohort was predominantly female, constituting 90% of the participants.\n\nThe data from these trials have been utilized in previous research and by the community, establishing their reliability and relevance. The trials focused on children between 2 months and 6 years old, with a heavy female predominance, and excluded those with congenital anatomical abnormalities. This selection criteria ensured that the dataset captured the majority of children of interest, making it representative for the development of the predictive model.\n\nThe dataset included a variety of baseline variables such as Bladder and Bowel Dysfunction (BBD), age, gender, race, weight percentile, number of antibiotic resistance in urine culture, urine albumin to creatinine ratio (urine ACR), dysuria, medication use, and systolic blood pressure. These variables were carefully chosen to ensure that the model was both clinically relevant and easy to implement in typical clinical settings.",
  "dataset/splits": "The dataset was split into training and testing sets. The specific number of data points in each split is not provided. However, the process involved oversampling to handle class imbalances, which is typically done on the training set to ensure that the model learns from a balanced representation of all classes. The testing set is usually kept separate to evaluate the model's performance on unseen data. The distribution of data points in each split would reflect this oversampling in the training set, while the testing set would maintain the original distribution.",
  "dataset/redundancy": "The datasets were split into training, validation, and testing sets. This process was crucial for ensuring that the model's performance could be evaluated on independent data, which helps to prevent overfitting and provides a more accurate assessment of the model's generalizability.\n\nThe independence of the training and test sets was enforced through a careful splitting process. Specifically, the data were divided such that no patient's information appeared in more than one set. This was achieved by randomly assigning participants to either the training, validation, or testing set, ensuring that each set was mutually exclusive. The validation set was used for hyperparameter tuning with 5-fold cross-validation, which further helped in selecting the best model parameters without biasing the final performance evaluation on the test set.\n\nRegarding the distribution of the datasets, it is important to note that the study included 500 subjects from two cohorts: RIVUR and CUTIE. The mean age of the participants was 21\u00b119 months, with a heavy female predominance (90%). This demographic distribution is reflective of the populations typically studied in pediatric urology, where urinary tract infections (UTIs) and vesico-ureteral reflux (VUR) are more commonly observed in young children, particularly females. The datasets used in this study are thus representative of the clinical scenarios encountered in pediatric practice, making the findings more applicable to real-world settings.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Optimal Classification Trees (OCTs). This class of algorithms was chosen for its high performance and interpretability. OCTs are particularly useful in medical contexts because they allow clinicians to understand the decision-making process, ensuring that the model is clinically sound and applicable in real-world settings.\n\nThe OCT algorithm used is not entirely new, but it has been applied in a novel way within the context of predicting clinical outcomes in children with urinary tract infections (UTIs). The specific implementation and application of OCTs in this study are unique, focusing on the prediction of recurrent UTI-associated vesicoureteral reflux (VUR). This novel application is what sets our work apart and makes it significant in the field of pediatric urology.\n\nThe reason the OCT algorithm was not published in a machine-learning journal is that the primary focus of our study is on its clinical application rather than the development of the algorithm itself. Our work is centered on demonstrating the practical utility of OCTs in a medical context, showcasing how this algorithm can be used to improve clinical decision-making and patient outcomes. The clinical insights and the potential impact on patient care are the main contributions of our study, which is why it was published in a medical journal rather than a machine-learning journal.",
  "optimization/meta": "Not applicable. The model developed in this study is an Optimal Classification Tree (OCT), which is a single machine learning algorithm. It does not use data from other machine-learning algorithms as input. Therefore, it is not a meta-predictor. The model was trained using data from two cohorts, RIVUR and CUTIE, and the training data is independent. The model's performance was evaluated using a testing set, ensuring that the data used for training and testing were separate.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure robustness and accuracy. Initially, missing data were handled using optimal tree imputation, a novel technique that effectively fills in gaps without introducing significant bias. This step was crucial for maintaining the integrity of the dataset, which included participants from the RIVUR and CUTIE studies.\n\nThe dataset was then split into training, validation, and testing sets to facilitate model development and evaluation. This splitting process was essential for tuning the machine learning algorithm's hyperparameters using 5-fold cross-validation on the validation set. This approach helped in optimizing the model's performance and generalizability.\n\nBaseline variables were carefully selected and encoded for the model. These variables included bladder and bowel dysfunction (BBD), age, gender, race, weight percentile, number of antibiotic resistances in urine culture, urine albumin to creatinine ratio (urine ACR), dysuria, medication use, and systolic blood pressure percentile. Each variable was encoded in a manner that allowed the model to interpret and utilize the data effectively.\n\nThe model development process also involved oversampling techniques to address class imbalances, ensuring that the algorithm could accurately predict outcomes even for underrepresented groups. This step was particularly important given the relatively small sizes of the cohorts, which could otherwise limit the model's power and generalizability.\n\nIn summary, the data encoding and preprocessing involved imputing missing values, splitting the dataset, selecting and encoding baseline variables, and using oversampling techniques. These steps were integral to developing a robust and interpretable machine learning model for predicting rUTI-associated VUR in children.",
  "optimization/parameters": "The model utilized a reduced set of variables to maintain performance while ensuring clinical applicability. Initially, over 50 variables were considered, but through a process of refinement and sensitivity analysis, the number was decreased to fewer than 8 key parameters per patient. These parameters were selected based on their significance in predicting the risk of recurrent urinary tract infection-associated vesicoureteral reflux (rUTI-associated VUR). The final model includes variables such as bladder and bowel dysfunction (BBD), age, gender, race, weight percentile, number of antibiotic resistances in urine culture, urine albumin to creatinine ratio (urine ACR), dysuria, medication use, recent antibiotic exposure, and systolic blood pressure. This selection process ensured that the model remained interpretable and practical for clinical use, focusing on variables that are easily obtainable in a typical clinical setting.",
  "optimization/features": "The model utilized a total of nine input features. These features were carefully selected to ensure they were easily obtainable in a typical clinical setting and to maintain the model's performance. The features included age, gender, race, weight percentile, systolic blood pressure percentile, dysuria, urine albumin/creatinine ratio, prior antibiotics exposure, and current medication use.\n\nFeature selection was indeed performed during the model development process. This involved initially considering a larger set of potential variables, including serum parameters. However, to reduce unnecessary invasive testing, analyses were conducted with and without serum data. Since model performance was minimally affected by the exclusion of serum-related variables, they were removed. This process helped in narrowing down the features to the nine that were ultimately included in the final model.\n\nThe feature selection process was conducted using the training set only, ensuring that the validation and testing sets remained unbiased. This approach helped in maintaining the model's generalizability and performance on unseen data.",
  "optimization/fitting": "The fitting method employed in our study utilized optimal classification trees (OCTs), which are designed to handle datasets with a potentially large number of parameters relative to the number of training points. To address the risk of overfitting, we implemented several strategies. Firstly, we used a technique called optimal tree imputation to handle missing data, ensuring that the model was trained on a complete and robust dataset. Secondly, we employed oversampling techniques to balance the dataset, which helped in mitigating the risk of the model becoming too specialized to the training data. Additionally, we performed sensitivity analyses comparing different algorithms, including logistic regression, random forests, and gradient boosted trees. The OCT model was chosen not only for its high performance but also for its tighter area under the curve (AUC) confidence interval, indicating better generalization to unseen data. This approach helped in ruling out overfitting by ensuring that the model's performance was consistent across different validation sets.\n\nTo rule out underfitting, we carefully selected the baseline variables that were clinically relevant and had a significant impact on the outcome. These variables included factors such as age, gender, race, weight percentile, number of antibiotic resistances in urine culture, urine albumin to creatinine ratio, dysuria, medication use, and systolic blood pressure. The tree structure of the OCT model was intuitive and interpretable, allowing us to ensure that the model captured the essential patterns in the data without being too simplistic. Furthermore, the model's good performance, as indicated by an AUC of 0.761, suggested that it was neither overfitting nor underfitting the data. The model's ability to categorize patients into probabilistic groups for recurrent urinary tract infection (rUTI)-associated vesicoureteral reflux (VUR) demonstrated its effectiveness in capturing the underlying relationships in the dataset.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our predictive model. One key method used was optimal tree imputation for handling missing data, which helped maintain the integrity of our dataset without introducing bias.\n\nAdditionally, we utilized oversampling techniques to balance the dataset, which is crucial for preventing the model from being biased towards the majority class. This step is particularly important in medical datasets where certain outcomes may be rarer than others.\n\nDuring the model development phase, we split our data into training and testing sets. This separation allowed us to train the model on one subset of the data and evaluate its performance on an unseen subset, thereby providing a more accurate assessment of the model's generalizability.\n\nWe also performed sensitivity analysis by comparing different algorithms, including logistic regression, random forests, and gradient boosted trees. This comparative analysis helped us select the optimal classification trees (OCTs) due to their high performance, tighter area under the curve (AUC) confidence intervals, and interpretability.\n\nFurthermore, we reduced the number of variables from over 50 to fewer than 8 needed per patient while maintaining the model's performance. This variable reduction not only simplified the model but also helped in preventing overfitting by focusing on the most relevant predictors.\n\nIn summary, our approach included data imputation, oversampling, train/test splitting, algorithm comparison, and variable reduction, all of which contributed to building a robust and generalizable predictive model.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a black-box model. Instead, it utilizes Optimal Classification Trees (OCTs), which are known for their high performance and interpretability. This approach allows physicians to understand the decision-making process of the model, ensuring that it aligns with clinical intuition and medical knowledge.\n\nOne of the key features of the OCT model is its ability to provide a clear and intuitive tree structure. Each patient is categorized into a terminal \"leaf,\" which groups patients with similar probabilities of recurrent urinary tract infection (rUTI)-associated vesicoureteral reflux (VUR). This structure makes it easy for clinicians to follow the decision path and understand how specific variables influence the risk assessment.\n\nFor example, consider a patient who is a 20-month-old black male without bladder and bowel dysfunction (BBD). The model first evaluates the BBD status and age. Since the patient has no BBD and is 20 months old, the initial calculation leads to a value less than the cutoff of 42. The next node in the tree considers the interaction between race and sex. As a black male, the patient falls into a lower-risk category. This example illustrates how the model uses readily available clinical variables to make transparent and interpretable decisions.\n\nAnother example involves a 5-year-old girl with BBD. The model first assesses her BBD status and age, leading to a value greater than the cutoff. Subsequent nodes evaluate other variables such as race, sex, and urine albumin-to-creatinine ratio (ACR), ultimately placing her in a higher-risk category. This step-by-step process allows clinicians to see exactly how each variable contributes to the final risk prediction.\n\nThe model's interpretability is further enhanced by the inclusion of variables that are easy to obtain in a typical clinical setting. For instance, urine ACR is a common test that does not require sterile urine collection, making it accessible for widespread use. Additionally, the model reduces the number of variables needed per patient from over 50 to fewer than 8, ensuring that the decision-making process remains straightforward and clinically relevant.\n\nIn summary, the OCT model provides a transparent and interpretable framework for predicting the risk of rUTI-associated VUR. Its clear decision paths and use of clinically relevant variables make it a valuable tool for data-driven management in pediatric urology.",
  "model/output": "The model developed is a classification model, specifically an Optimal Classification Tree (OCT). It is designed to predict the probability of recurrent urinary tract infection (rUTI)-associated vesicoureteral reflux (VUR) in children after an initial UTI. The model categorizes patients into probabilistic groups, indicating their risk of developing rUTI-associated VUR. This classification allows for data-driven management decisions, such as determining whether to order a voiding cystourethrogram (VCUG) after the initial UTI. The model's output is a probability that helps clinicians decide on the next steps in patient care, making it a classification model rather than a regression model. The area under the curve (AUC) for the OCT model is 0.761, demonstrating good performance in distinguishing between high and low-risk groups. The model's interpretability and clinical relevance are key features, enabling physicians to understand the underlying factors contributing to the predictions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the machine learning model developed in this study is not publicly released. However, the model's predictions are accessible through a free webpage and an app, which are currently available. The app is pending approval for release on the Appstore. These tools allow users to predict the risk of recurrent urinary tract infection-associated vesicoureteral reflux (rUTI-associated VUR) in children after an initial UTI. The tools are designed to aid clinical decision-making and facilitate data collection for further studies. The webpage and app provide an interface for clinicians to input patient data and receive probabilistic risk assessments, enabling more selective use of voiding cystourethrogram (VCUG) procedures.",
  "evaluation/method": "The evaluation of the predictive model involved several key steps to ensure its robustness and performance. Initially, missing data were handled using a novel technique called optimal tree imputation. This was followed by a process of oversampling, train/test set splitting, model training, and performance evaluation using the area under the curve (AUC).\n\nThe model's performance was assessed using an AUC of 0.761, with a 95% confidence interval ranging from 0.714 to 0.808. This AUC value indicates good performance, as a perfect predictive model would have an AUC of 1.0, while a model no better than random chance would have an AUC of 0.5.\n\nTo validate the choice of the optimal classification tree (OCT) model, a sensitivity analysis was conducted comparing it with other algorithms such as logistic regression, random forests, and gradient boosted trees. The OCT model was selected due to its superior performance, tighter AUC confidence interval, and interpretability.\n\nThe receiver operating characteristics (ROC) curve for the proposed OCT model on the testing set was also examined, providing a visual representation of the model's performance. Additionally, the model's interpretability was highlighted, as it allows physicians to understand the underlying factors contributing to the predictions, ensuring clinical soundness and real-world applicability.\n\nThe evaluation process included comparing the model's performance with and without certain variables, such as serum parameters, to ensure that unnecessary invasive testing was minimized. This resulted in a model that requires fewer than eight variables per patient, all of which are easily obtainable in a typical clinical setting. The only specimen needed to fully utilize the model's predictive power was the urine albumin to creatinine ratio (urine ACR), a common test that does not require sterile urine collection.",
  "evaluation/measure": "The primary performance metric reported for our predictive model is the Area Under the Curve (AUC) of the Receiver Operating Characteristics (ROC) curve. The AUC for our Optimal Classification Tree (OCT) model was 0.761, with a 95% confidence interval ranging from 0.714 to 0.808. This metric indicates the model's ability to distinguish between children with and without recurrent urinary tract infection (rUTI)-associated vesicoureteral reflux (VUR). An AUC of 0.761 suggests good performance, as a perfect model would have an AUC of 1.0, and a model no better than random chance would have an AUC of 0.5.\n\nThe AUC is a widely used and representative metric in the literature for evaluating the performance of predictive models, particularly in medical and clinical settings. It provides a single scalar value that summarizes the model's performance across all classification thresholds. By reporting the AUC, we align with standard practices in the field, ensuring that our model's performance can be easily compared with other studies and models.\n\nAdditionally, we performed sensitivity analyses comparing different algorithms, including logistic regression, random forests, and gradient boosted trees. The OCT model was chosen due to its good performance, tighter AUC confidence interval, and interpretability. This approach ensures that our reported performance metric is robust and that the chosen model is optimal for the task at hand.\n\nIn summary, the AUC is the key performance metric reported for our model, and it is a representative and widely accepted metric in the literature. This metric, along with our sensitivity analyses, provides a comprehensive evaluation of our model's performance.",
  "evaluation/comparison": "A comparison to simpler baselines was performed during the sensitivity analysis phase of the model development. Specifically, algorithms such as logistic regression, random forests, and gradient boosted trees were evaluated alongside the optimal classification trees (OCT) model. The OCT model was ultimately chosen due to its superior performance, tighter area under the curve (AUC) confidence interval, and interpretability. This comparison allowed for a thorough evaluation of the OCT model's effectiveness relative to more straightforward and commonly used machine learning techniques. However, it is not explicitly mentioned whether a comparison to publicly available methods was performed on benchmark datasets.",
  "evaluation/confidence": "The evaluation of our model's performance included the calculation of confidence intervals for the area under the curve (AUC). Specifically, the AUC for our optimal classification tree (OCT) model was reported as 0.761 with a 95% confidence interval ranging from 0.714 to 0.808. This indicates a good level of confidence in the model's performance, as the interval does not include the value of 0.5, which would represent a model with no better than random performance.\n\nStatistical significance was assessed using an alpha of 0.05. This threshold was applied to determine whether the differences observed in the model's performance were likely due to actual effects rather than random chance. The results demonstrated that the OCT model outperformed other algorithms, such as logistic regression, random forests, and gradient boosted trees, with a tighter AUC confidence interval and better interpretability. This suggests that the OCT model's superior performance is statistically significant and not merely due to random variation.",
  "evaluation/availability": "Not enough information is available."
}