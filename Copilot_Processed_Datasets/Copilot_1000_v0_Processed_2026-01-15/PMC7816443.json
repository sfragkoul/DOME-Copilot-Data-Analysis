{
  "publication/title": "An efficient computational method for predicting drug-target interactions using weighted extreme learning machine and speed up robot features",
  "publication/authors": "The authors who contributed to the article are:\n\n- An JY\n- MFR\n- YZJ\n- ZYJ\n\nAn JY and MFR conceived the algorithm, carried out analyses, prepared the data sets, carried out experiments, and wrote the manuscript. YZJ and ZYJ designed, performed and analyzed experiments and wrote the manuscript. All authors read and approved the final manuscript.",
  "publication/journal": "BioData Mining",
  "publication/year": "2021",
  "publication/pmid": "33472664",
  "publication/pmcid": "PMC7816443",
  "publication/doi": "10.1186/s13040-021-00242-1",
  "publication/tags": "- Drug-target interactions\n- Computational methods\n- Weighted Extreme Learning Machine\n- Speeded Up Robust Features\n- Protein evolutionary information\n- Drug fingerprints\n- Machine learning\n- Bioinformatics\n- Drug discovery\n- Predictive modeling\n- Molecular substructure fingerprints\n- Position Specific Scoring Matrix\n- Classification algorithms\n- Data mining\n- Biochemical networks",
  "dataset/provenance": "The datasets used in our study are obtained from well-established biological databases, ensuring their reliability and relevance. Specifically, the datasets for enzymes, ion channels, G-protein-coupled receptors (GPCRs), and nuclear receptors are sourced from the KEGG BRITE, BRENDA, SuperTarget, and DrugBank databases. These datasets are defined as gold standard datasets by Yamanishi, which underscores their quality and widespread acceptance in the scientific community.\n\nThe datasets comprise a significant number of known drugs and target proteins. For enzymes, there are 445 known drugs and 664 known target proteins. In the case of ion channels, the dataset includes 210 known drugs and 204 known target proteins. For GPCRs, there are 233 known drugs and 95 known target proteins. Lastly, the nuclear receptor dataset contains 54 known drugs and 26 known target proteins. These datasets collectively include 5127 drug-target pairs that are known to interact with each other.\n\nThe number of known interactions varies across the datasets. For enzymes, there are 2926 known interactions. Ion channels have 1476 known interactions, while GPCRs have 635 known interactions. The nuclear receptor dataset includes 90 known interactions. These interactions are crucial for understanding the biological functions and potential therapeutic applications of these drug-target pairs.\n\nThe datasets are constructed to include both positive and negative samples. Positive samples represent known drug-target interactions, while negative samples are randomly selected to balance the dataset. This approach helps in addressing the bias problem that arises due to the significantly larger number of possible negative samples compared to positive samples. For instance, in the enzyme dataset, there are 2926 positive samples and an equal number of negative samples. This balanced approach ensures that the model is trained effectively and can generalize well to new, unseen data.",
  "dataset/splits": "The dataset was divided into five parts for evaluation purposes. This division was done to ensure that the model's performance could be assessed using a fivefold cross-validation test. In this setup, four parts of the dataset were used as the training set, while the remaining part served as the testing set. This process was repeated five times, with each part of the dataset serving as the testing set once. This approach helps in providing a more robust evaluation of the model's performance by ensuring that each data point is used for both training and testing.\n\nThe datasets used in the study include enzymes, ion channels, GPCRs, and nuclear receptors. The number of known drugs for these categories are 445, 210, 233, and 54, respectively, and the count of known target proteins are 664, 204, 95, and 26. There are 5127 drug-target pairs that can interact with each other. The known interactions involving enzymes, ion channels, GPCRs, and nuclear receptors are 2926, 1476, 635, and 90, respectively.\n\nTo address the imbalance in the dataset, where the number of negative samples is significantly larger than the number of positive samples, an equal number of negative and positive samples were randomly selected. Therefore, the number of negative samples for the enzyme, ion channel, GPCRs, and nuclear receptor datasets are 2926, 1476, 635, and 90, respectively. This balancing ensures that the model is not biased towards the majority class and can effectively learn from both positive and negative interactions.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets used in our study are publicly available and can be obtained from several well-known biological databases. Specifically, the datasets for enzymes, ion channels, GPCRs, and nuclear receptors can be downloaded from the KEGG BRITE, BRENDA, SuperTarget, and DrugBank databases. These datasets are defined as gold standard datasets by Yamanishi.\n\nThe data splits used in our experiments were created by randomly dividing the entire dataset into five parts, where four parts were used for training and one part for testing. This process was repeated five times using fivefold cross-validation to ensure the robustness and fairness of our results.\n\nThe datasets are freely accessible to the public, and there are no specific licensing restrictions mentioned beyond the standard terms of use for these databases. Researchers can access these datasets by visiting the respective database websites and following their data retrieval procedures. The datasets are widely used in the bioinformatics community, ensuring that other researchers can replicate our experiments and build upon our findings.",
  "optimization/algorithm": "The machine-learning algorithm class used is the Weighted Extreme Learning Machine (WELM). This is a variant of the Extreme Learning Machine (ELM), which is known for its fast training speed and good generalization performance.\n\nThe WELM is not entirely new; it builds upon the existing ELM algorithm by incorporating weighting strategies to handle class imbalances. The primary innovation lies in its ability to assign different weights to minority and majority class samples, thereby improving the classification performance for imbalanced datasets.\n\nThe reason it was not published in a machine-learning journal is that the focus of the current work is on its application in predicting drug-target interactions (DTIs) rather than the development of the algorithm itself. The WELM's advantages, such as short training time and good generalization ability, make it suitable for this specific application. The study demonstrates how the WELM can be effectively used in conjunction with feature extraction methods like SURF to achieve high prediction accuracy for DTIs. This application-driven approach is why the research was published in a bioinformatics journal rather than a machine-learning one.",
  "optimization/meta": "The WELM-SURF model does not function as a meta-predictor. It is a standalone computational method that combines the Weighted Extreme Learning Machine (WELM) with Speeded Up Robust Features (SURF) for predicting Drug-Target Interactions (DTIs). The model leverages drug fingerprints and protein evolutionary information to make its predictions.\n\nThe WELM-SURF model does not use data from other machine-learning algorithms as input. Instead, it relies on its own feature extraction method, SURF, which is designed to capture robust features from the input data. The WELM component of the model is responsible for the classification task, utilizing a weighted approach to handle imbalanced data effectively.\n\nThe training data used for the WELM-SURF model is carefully divided into five parts, with four parts used for training and one part used for testing. This process is repeated five times using fivefold cross-validation to ensure that the model's performance is evaluated fairly and comprehensively. The independence of the training data is maintained through this cross-validation strategy, ensuring that the model's predictions are robust and generalizable.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effective application of the machine-learning algorithm. For drug representation, we utilized molecular substructure fingerprints to encode the chemical structures of drugs. This method translates each molecular structure into a binary vector of 881 dimensions, where each bit indicates the presence or absence of specific substructures.\n\nFor protein sequences, we employed the Position Specific Scoring Matrix (PSSM) to capture evolutionary information. This matrix not only retains the position information of the protein sequence but also reflects the conservative function of the protein through evolutionary data. We used the PSI-BLAST tool to convert each protein sequence into a PSSM, setting the e-value to 0.001 and performing three iterations to obtain widely and highly homologous sequences. The PSSM matrix dimensions are L\u00d720, where L represents the length of the protein sequence, and 20 corresponds to the 20 different amino acids. The matrix elements Pij indicate the probability of the ith amino acid mutating to the jth amino acid during evolution.\n\nTo extract key features from the PSSM, we applied the Speeded Up Robust Features (SURF) algorithm. SURF is an improvement over the Scale-Invariant Feature Transform (SIFT) algorithm, offering faster computation and better feature extraction. It uses a Box Filter to approximate the Laplacian of Gaussian, making it efficient in capturing multi-scale features from the PSSM.\n\nThe encoded drug and protein features were then used as inputs for the Weighted Extreme Learning Machine (WELM) classifier. WELM was chosen for its short training time, good generalization ability, and efficient classification through weight matrix optimization. This approach allows the model to better perceive class distribution information by assigning larger weights to minority class samples, thereby improving prediction accuracy.",
  "optimization/parameters": "In our study, we optimized several parameters of the WELM model using the grid search method. Specifically, we selected the 'Sigmoid' function and the 'Gaussian' kernel as the mapping functions of the hidden nodes. The number of hidden neurons was set to 2500, and the regularization parameter C was set to 160. Other parameters were kept at their default values. These settings were chosen to ensure optimal performance of the WELM-SURF model in predicting drug-target interactions.",
  "optimization/features": "Not enough information is available.",
  "optimization/fitting": "In our study, we employed a weighted extreme learning machine (WELM) with a specific focus on addressing the challenges of overfitting and underfitting. The WELM model utilizes a single-hidden layer feedforward network (SLFN), which is capable of approximating the training set with zero error. This is achieved by finding appropriate input weights, biases, and output weights.\n\nTo mitigate overfitting, we implemented a fivefold cross-validation strategy. This involved randomly dividing the entire dataset into five parts, using four parts for training and the remaining part for testing. This process was repeated five times, ensuring that each part of the dataset was used as the testing set once. Additionally, we optimized several parameters of the WELM model using a grid search method. This approach helped in selecting the optimal parameters, such as the number of hidden neurons and the regularization parameter C, which were set to 2500 and 160, respectively. The use of the 'Sigmoid' function and the 'Gaussian' kernel as mapping functions for the hidden nodes further enhanced the model's ability to generalize well to unseen data.\n\nTo address underfitting, we ensured that the model had sufficient complexity by setting a large number of hidden neurons (2500). This allowed the model to capture the underlying patterns in the data effectively. Furthermore, the use of the WELM's automatic weighting strategy helped in balancing the classification accuracy between majority and minority classes, thereby improving the model's overall performance.\n\nThe results of our experiments, as shown in the tables, demonstrate the effectiveness of our approach in achieving high accuracy and robustness. The WELM-SURF model outperformed other methods, such as ELM and SVM, on various datasets, indicating its competence in predicting drug-target interactions with high accuracy.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the primary methods used was fivefold cross-validation. This technique involves dividing the entire dataset into five parts, using four parts for training and the remaining part for testing. This process is repeated five times, with each part serving as the test set once. This approach helps to ensure that the model generalizes well to unseen data and is not merely memorizing the training set.\n\nAdditionally, we optimized several parameters of the WELM model using a grid search method. This systematic approach helps in finding the best combination of parameters that minimize overfitting and improve the model's performance. For instance, we selected the 'Sigmoid' function and the 'Gaussian' kernel as the mapping functions of the hidden nodes and set the number of hidden neurons to 2500 and C to 160. Other parameters were set to their default values.\n\nThe use of weighted extreme learning machine (WELM) also contributed to preventing overfitting. WELM assigns different weights to different sample classes, which helps in balancing the classification accuracy between majority and minority classes. This weighting strategy ensures that the model does not become biased towards the majority class, thereby improving its generalization ability.\n\nFurthermore, the Receiver Operating Curve (ROC) was employed to assess the prediction performance of the WELM-SURF model. The ROC curve provides a comprehensive view of the model's performance across different threshold settings, helping to identify the optimal trade-off between sensitivity and specificity.\n\nIn summary, the combination of fivefold cross-validation, parameter optimization through grid search, and the use of WELM with its weighting strategy effectively prevented overfitting and enhanced the model's predictive performance.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in detail within the publication. Specifically, we employed a grid search method to optimize several parameters of the WELM model. For instance, the 'Sigmoid' function and the 'Gaussian' kernel were selected as the mapping functions of the hidden nodes. The number of hidden neurons was set to 2500, and the parameter C was set to 160. Other parameters were set to their default values.\n\nThe optimization schedule involved dividing the entire dataset into five parts, using four parts for training and one part for testing. This process was repeated five times using fivefold cross-validation to ensure the fairness and robustness of our results.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly mentioned as being publicly accessible or shared under a specific license. Therefore, while the configurations and parameters are described within the publication, the actual model files and optimization parameters are not reported as available for download or further use.",
  "model/interpretability": "The model employed in our study, WELM-SURF, is a type of weighted extreme learning machine (WELM) combined with Speeded Up Robust Features (SURF). This model can be considered somewhat transparent due to its structure and the interpretability of its components.\n\nThe WELM part of the model uses a feedforward neural network with a single hidden layer, which is a relatively simple architecture. The output of this network can be expressed through a series of mathematical equations that involve input weights, biases, and an activation function. This makes it possible to trace the flow of data through the network and understand how inputs are transformed into outputs. For example, the output of the hidden layer neurons can be described using the equation h = G(a * x + b), where G is the activation function, a and b are the input weights and biases, and x is the input sample. This equation shows how the input data is processed and highlights the role of each component in the network.\n\nAdditionally, the WELM model uses a weighting strategy to handle class imbalances, which can be clearly defined and understood. There are two weighting strategies: automatic weighting, where the weight is inversely proportional to the number of samples in each class, and a strategy that sacrifices the classification accuracy of the majority class to improve the accuracy of the minority class. These strategies are designed to ensure that the model does not become biased towards the majority class and can be easily explained and justified.\n\nThe SURF component of the model is used for feature extraction and is based on the Scale-Invariant Feature Transform (SIFT) algorithm. SURF is designed to detect and describe local features in images, and its operation can be understood through a series of steps that involve detecting interest points, constructing a descriptor for each point, and matching these descriptors between images. This makes it possible to understand how the model extracts relevant information from the input data and how this information is used to make predictions.\n\nOverall, while the WELM-SURF model is more complex than a simple linear model, its components are well-defined and can be understood through a series of mathematical equations and clear steps. This makes it possible to trace the flow of data through the model, understand how inputs are transformed into outputs, and explain the role of each component in the network. However, it is important to note that the interpretability of the model may be limited by the complexity of the data and the specific application. In some cases, it may be necessary to use additional techniques, such as sensitivity analysis or feature importance scores, to fully understand the behavior of the model.",
  "model/output": "The model discussed is a classification model. It is designed to predict drug-target interactions (DTIs), which is a classification task. The model uses a weighted extreme learning machine (WELM) with a specific output function to classify whether a drug interacts with a target or not. The performance of the model is evaluated using metrics such as accuracy, sensitivity, precision, and Matthews' correlation coefficient, which are commonly used in classification problems. The model's output is a binary classification indicating the presence or absence of an interaction.",
  "model/duration": "The execution time of the model was not explicitly mentioned. However, it is worth noting that the WELM classifier, which is a key component of the WELM-SURF model, has the advantage of short training time. This efficiency is attributed to its ability to optimize the loss function of the weight matrix, allowing for quick classification. Additionally, the SURF feature extraction method contributes to the overall computational speed, as it improves upon the SIFT method by using the concept of \"scale space\" to capture features at multiple scale levels. This makes the model highly tolerant to scale changes and capable of extracting high-efficiency features from PSSM.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the WELM-SURF method involved a comprehensive assessment using multiple datasets and comparison with other established methods. The primary evaluation technique employed was fivefold cross-validation. This process involved randomly dividing each dataset into five parts, using four parts for training and the remaining part for testing. This procedure was repeated five times, with each part serving as the test set once, ensuring that every data point was used for both training and testing.\n\nTo ensure fairness and robustness, several parameters of the WELM model were optimized using the grid search method. The 'Sigmoid' function and the 'Gaussian' kernel were selected as the mapping functions for the hidden nodes. The number of hidden neurons was set to 2500, and the parameter C was set to 160, with other parameters kept at their default values.\n\nThe performance of the WELM-SURF model was evaluated on four benchmark datasets: enzymes, ion channels, GPCRs, and nuclear receptors. The results were presented in tables showing the accuracy, sensitivity, precision, and Matthews correlation coefficient for each testing set and the average performance across all sets.\n\nAdditionally, the WELM-SURF method was compared with other classifiers, including the ELM classifier and the SVM classifier, on the enzyme and ion channels datasets. The comparison results, displayed in tables and ROC curves, demonstrated that the WELM classifier achieved significantly higher average accuracy than both the ELM and SVM classifiers.\n\nFurthermore, the WELM-SURF method was compared with four existing DTI predictors: DBSI, Yamanishi, KBMF2K, and NetCMP, across all four datasets. The comparison results indicated that the WELM-SURF method outperformed these existing methods, providing strong evidence of its efficiency and robustness.\n\nIn summary, the evaluation of the WELM-SURF method involved rigorous cross-validation, parameter optimization, and extensive comparisons with other classifiers and existing methods, demonstrating its superior performance in predicting drug-target interactions.",
  "evaluation/measure": "In our evaluation of the WELM-SURF model, we employed several key performance metrics to comprehensively assess its predictive capabilities. These metrics include Accuracy (Acc), Sensitivity (TPR), Precision (PPV), and Matthews' Correlation Coefficient (MCC).\n\nAccuracy measures the overall correctness of the predictions, providing a general sense of how well the model performs. Sensitivity, also known as the True Positive Rate, indicates the model's ability to correctly identify positive instances. Precision, or the Positive Predictive Value, reflects the proportion of true positives among all positive predictions, highlighting the model's reliability in predicting positive outcomes. Matthews' Correlation Coefficient offers a balanced measure that considers true and false positives and negatives, providing a single value that summarizes the quality of binary classifications.\n\nThese metrics are widely recognized and used in the literature for evaluating predictive models, ensuring that our results are comparable with other studies in the field. By reporting these metrics, we aim to provide a thorough and transparent assessment of the WELM-SURF model's performance, demonstrating its effectiveness and robustness in predicting drug-target interactions.",
  "evaluation/comparison": "In the evaluation of our proposed method, a comprehensive comparison was conducted with several publicly available methods and simpler baselines to assess its performance. The comparison involved benchmark datasets, specifically enzyme, ion channels, GPCRs, and nuclear receptor datasets. These datasets were chosen to provide a robust evaluation across different types of drug-target interactions.\n\nFor the comparison with publicly available methods, we evaluated our WELM-SURF model against four existing DTIs predictors: DBSI, Yamanishi, KBMF2K, and NetCMP. The results, displayed in a comparison table, showed that our method achieved significantly higher prediction accuracy than these existing methods. This strong evidence indicates that the WELM-SURF method is not only efficient but also robust compared to current approaches.\n\nIn addition to comparing with other publicly available methods, we also performed a comparison with simpler baselines. Specifically, we compared our WELM-SURF model with the Extreme Learning Machine (ELM) and the Support Vector Machine (SVM) using the SURF feature extraction method on enzyme and ion channel datasets. The ELM and SVM are well-established classifiers in the field of machine learning. The results demonstrated that our WELM-SURF model outperformed both ELM and SVM in terms of average accuracy. For instance, on the enzyme dataset, the WELM classifier achieved an average accuracy of 93.54%, compared to 90.38% for the ELM classifier and 87.07% for the SVM classifier. Similarly, on the ion channels dataset, the WELM classifier achieved an average accuracy of 90.48%, compared to 87.76% for the ELM classifier and 83.30% for the SVM classifier.\n\nThese comparisons highlight the superior performance of the WELM-SURF model in predicting drug-target interactions. The method's ability to efficiently execute classification by optimizing the loss function of the weight matrix, along with its short training time and good generalization ability, contributes to its high prediction accuracy. The results suggest that the WELM-SURF model is a useful computational tool for identifying DTIs with high accuracy and robustness.",
  "evaluation/confidence": "The evaluation of the WELM-SURF model includes detailed performance metrics with confidence intervals, providing a clear indication of the model's reliability. For instance, the fivefold cross-validation results for the enzyme dataset show an average accuracy of 93.54% with a standard deviation of 0.61%, demonstrating consistent performance across different test sets. Similarly, other datasets such as ion channels, GPCRs, and nuclear receptors also present average accuracies with associated standard deviations, ensuring that the reported metrics are robust and not due to random chance.\n\nStatistical significance is further supported by the comparison with other methods. The WELM-SURF model outperforms existing methods like DBSI, Yamanishi, KBMF2K, and NetCMP, as well as baseline classifiers like ELM and SVM. The ROC curves and the average accuracy metrics clearly indicate that the WELM-SURF model has a superior prediction capacity. The use of grid search for parameter optimization and the employment of fivefold cross-validation ensure that the results are not overfitted and are generalizable to new data.\n\nMoreover, the comparison with ELM and SVM classifiers on the enzyme and ion channels datasets shows that the WELM classifier achieves higher average accuracies, reinforcing the statistical significance of the results. The WELM-SURF model's advantages, such as short training time, good generalization ability, and efficient classification, contribute to its superior performance. These factors collectively provide high confidence in the model's evaluation and its claimed superiority over other methods.",
  "evaluation/availability": "The raw evaluation files used in our study are not directly available for download. However, the experimental datasets can be obtained from publicly accessible databases, specifically KEGG BRITE, BRENDA, SuperTarget, and DrugBank. These datasets were defined as gold standard datasets by Yamanishi and are widely used in the field for evaluating drug-target interaction predictions.\n\nThe datasets include information on known drugs and target proteins for enzymes, ion channels, G-protein-coupled receptors (GPCRs), and nuclear receptors. The number of known drug-target pairs and the specific interactions within these datasets are detailed in our publication. Researchers interested in replicating or extending our work can access these datasets through the provided database links.\n\nRegarding the availability of our specific evaluation results, the performance metrics and comparison results are thoroughly documented in the tables and figures within the publication. These include accuracy, sensitivity, precision, and Matthews correlation coefficient for various datasets and models. The methods and parameters used for evaluation, such as fivefold cross-validation and the use of the WELM-SURF model, are also described in detail.\n\nFor those interested in using our methods or datasets, the publication provides comprehensive information on the experimental setup, feature extraction processes, and the evaluation criteria. This should enable other researchers to replicate our findings or adapt our approaches to their own studies."
}