{
  "publication/title": "Prospective Analysis Using a Novel CNN Algorithm to Distinguish Atypical Ductal Hyperplasia From Ductal Carcinoma in Situ in Breast",
  "publication/authors": "The authors who contributed to this article are:\n\n- Simukayi Mutasa\n- Peter Chang\n- John Nemer\n- Eduardo Pascual Van Sant\n- Mary Sun\n- Alison McIlvride\n- Maham Siddique\n- Richard Ha\n\nRichard Ha is the corresponding author and is an Associate Professor of Radiology and the Director of Research and Education at the Breast Imaging Section of Columbia University Medical Center. He also has a fellowship in breast radiology and has been involved in the development and validation of the convolutional neural network (CNN) algorithm used in this study. His contributions include the manual extraction of segmentations for the mammographic images and the interpretation of the results.\n\nThe other authors are affiliated with the Department of Radiology at Columbia University Medical Center and the Center for Artificial Intelligence in Diagnostic Medicine (CAIDM) at UCI Health. Their specific contributions to the paper are not detailed, but they likely include data collection, analysis, and interpretation of the results.",
  "publication/journal": "Clin Breast Cancer",
  "publication/year": "2020",
  "publication/pmid": "32680766",
  "publication/pmcid": "PMC8207833",
  "publication/doi": "10.1016/j.clbc.2020.06.001",
  "publication/tags": "- ADH\n- Artificial intelligence\n- Convolutional neural networks\n- DCIS\n- Deep learning\n- Breast cancer\n- Mammography\n- Diagnostic accuracy\n- Medical imaging\n- Surgical excision",
  "dataset/provenance": "The dataset used in this study consists of 280 unique mammographic images from 140 patients. These images were obtained from patients who underwent consecutive stereotactic-guided biopsies at our institution between January 2016 and February 2018. All patients presented with suspicious calcifications without an associated mass on mammography. Each patient had at least two magnification views: a craniocaudal view and either a mediolateral or lateromedial view. The mammographic images were acquired using dedicated mammography units (Senographe Essential, GE Healthcare).\n\nThe dataset includes images from patients who underwent subsequent surgical excision, with final pathology results available. The patients were divided into two groups based on their pathology results: 61 patients with a diagnosis of atypical ductal hyperplasia (ADH) and 79 patients with a diagnosis of ductal carcinoma in situ (DCIS). The ADH group consisted of 122 images, while the DCIS group consisted of 158 images.\n\nThis dataset was used to test our previously developed convolutional neural network (CNN) algorithm, which was designed to distinguish between ADH and DCIS. The algorithm had been initially developed and tested on a different dataset in a previous study. The current study represents a prospective validation of the algorithm using this new, unseen dataset.",
  "dataset/splits": "The study utilized a single dataset split, which consisted of 280 unique mammographic images. These images were obtained from 140 patients who underwent stereotactic-guided biopsies. The dataset was divided into two groups based on the final pathology diagnosis: 122 images from 61 patients with atypical ductal hyperplasia (ADH) and 158 images from 79 patients with ductal carcinoma in situ (DCIS). Each patient had at least two magnification views, including a craniocaudal view and either a mediolateral or lateromedial view. The images were used to test the convolutional neural network (CNN) algorithm's ability to distinguish between ADH and DCIS.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a convolutional neural network (CNN). This type of algorithm is particularly well-suited for image analysis tasks, such as distinguishing between atypical ductal hyperplasia (ADH) and ductal carcinoma in situ (DCIS) in mammographic images.\n\nThe CNN algorithm employed in this research is not entirely new; it builds upon previously established methodologies. However, the specific implementation and application to this particular medical imaging problem are novel. The algorithm was developed and validated within the context of medical imaging and diagnostic support, rather than as a general-purpose machine-learning tool.\n\nThe decision to publish this work in a clinical journal, rather than a machine-learning journal, is driven by the primary focus of the study. The aim is to demonstrate the clinical utility and diagnostic performance of the CNN algorithm in a real-world medical setting. The study's emphasis is on the prospective validation of the algorithm's ability to distinguish between ADH and DCIS, which is of direct relevance to the medical community. This approach ensures that the findings are immediately applicable to clinical practice, addressing a specific need in breast cancer diagnosis and management.",
  "optimization/meta": "The potential of combining clinical information and the results of our convolutional neural network (CNN) algorithm to further improve the overall prediction model is currently under investigation. This approach suggests that the model may indeed use data from other machine-learning algorithms or clinical inputs as part of a meta-predictor framework.\n\nIn this context, the CNN algorithm is the primary machine-learning method used to distinguish atypical ductal hyperplasia (ADH) from ductal carcinoma in situ (DCIS) based on mammographic images. The integration of clinical information could involve additional machine-learning methods or statistical models that process patient data such as age, span of calcifications, and other relevant clinical parameters.\n\nRegarding the independence of training data, it is crucial to ensure that the data used for training the CNN and any additional machine-learning models are independent to avoid overfitting and to ensure the generalizability of the model. While the current study focuses on testing the CNN algorithm on unseen data to limit overfitting, the specific details of how clinical information will be integrated and whether the training data for the meta-predictor will remain independent are still under investigation. Therefore, it is not yet completely clear that the training data for the meta-predictor will be independent.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the mammographic images were suitable for analysis by the convolutional neural network (CNN). Initially, the mammographic images were loaded into a 3D segmentation program. A fellowship-trained breast radiologist manually extracted segmentations to encompass the regions of the magnification view that contained calcifications. Each image was then scaled in size based on the radius of the segmentations and resized to fit a bounding box of 128 \u00d7 128 pixels. This standardization ensured consistency in the input size for the CNN.\n\nThe entire image batch was centered using histogram-based z-score normalization of the non-air pixel intensity values. This normalization process helped to standardize the pixel values across different images, reducing variability and enhancing the model's ability to learn relevant features.\n\nData augmentation techniques were applied to increase the diversity of the training dataset and improve the robustness of the CNN. These techniques included randomly flipping the images vertically, horizontally, or in both directions, rotating the images by a random angle between 0.52 and \u22120.52 radians, and randomly cropping the images to a box that was 80% of the initial size. Additionally, random affine shear was applied to each input breast image. These augmentations helped the CNN to generalize better by exposing it to a wider range of variations in the input data.\n\nThe CNN architecture used for this study consisted of 15 hidden layers, including 5 residual layers and dropout of 0.25 after each convolution. This design helped to mitigate overfitting and improve the model's performance by introducing regularization. The software code for this study was written using an open-source software library for numerical computation, specifically the Python TensorFlow library, version 1.5. Experiments and network training were performed on a workstation with an Ubuntu operating system (release 16.04) and a graphics card (Titan X Pascal).",
  "optimization/parameters": "Not enough information is available.",
  "optimization/features": "The input features for the convolutional neural network (CNN) algorithm consist of mammographic images. Specifically, the dataset comprises 280 unique mammographic images from 140 patients. Each patient had at least two magnification views: a craniocaudal view and either a mediolateral or lateromedial view. These images were segmented to focus on the regions containing calcifications, which were then resized to fit a bounding box of 128 \u00d7 128 pixels.\n\nFeature selection in the traditional sense was not performed, as the features are the pixel values of the mammographic images themselves. Instead, data augmentation techniques were applied to enhance the diversity of the training data. These techniques included random flipping, rotation, cropping, and affine shear transformations. The images were also normalized using histogram-based z-score normalization of the non-air pixel intensity values.\n\nThe segmentation process was manually performed by a fellowship-trained breast radiologist with extensive experience, ensuring that the regions of interest were accurately identified. This manual segmentation step is crucial for focusing the CNN on the relevant areas of the mammographic images.\n\nThe CNN architecture used for this study has 15 hidden layers, including 5 residual layers and dropout of 0.25 after each convolution. This design helps in capturing complex patterns in the mammographic images and prevents overfitting. The network was trained using an open-source software library for numerical computation, specifically the Python TensorFlow library, version 1.5. The experiments and network training were conducted on a workstation with an Ubuntu operating system and a graphics card (Titan X Pascal, NVIDIA).",
  "optimization/fitting": "The convolutional neural network (CNN) algorithm employed in this study utilized a topology with 15 hidden layers, which indeed has a large number of parameters compared to the number of training points. To address the potential issue of overfitting, several strategies were implemented. Firstly, the dataset used for testing the CNN algorithm consisted of unseen data, which helps in evaluating the model's generalization capability. This approach limits overfitting, where a CNN algorithm becomes overly reliant on the provided training data, thereby artificially boosting model performance. Additionally, dropout layers with a rate of 0.25 were included after each convolution to prevent the network from becoming too dependent on specific neurons, further mitigating overfitting. Data augmentation techniques, such as random flipping, rotation, cropping, and affine shear, were also applied to increase the diversity of the training data and enhance the model's robustness.\n\nTo ensure that the model was not underfitting, the architecture was designed with a sufficient number of layers and parameters to capture the complex patterns in the mammographic images. The use of residual layers helped in maintaining the gradient flow during training, allowing the network to learn more effectively. Furthermore, the model's performance was evaluated using diagnostic metrics such as sensitivity, specificity, accuracy, and the area under the receiver operating characteristic curve (AUC), which provided a comprehensive assessment of the model's effectiveness in distinguishing between atypical ductal hyperplasia (ADH) and ductal carcinoma in situ (DCIS). The high specificity of 93.7% and an AUC of 0.90 indicate that the model was adequately trained to generalize well to new, unseen data without underfitting.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our convolutional neural network (CNN) algorithm. One key method used was data augmentation. This involved randomly flipping images vertically, horizontally, or in both directions, rotating them by random angles, and applying random affine shear. These transformations helped to increase the diversity of the training data, making the model more generalizable to new, unseen data.\n\nAdditionally, dropout was implemented after each convolutional layer with a rate of 0.25. Dropout is a regularization technique where a random subset of neurons is temporarily removed during training, which helps to prevent the model from becoming too reliant on any single neuron or path through the network. This encourages the network to learn more robust features and reduces the risk of overfitting.\n\nThe use of a residual network architecture also contributed to mitigating overfitting. Residual networks allow gradients to flow more easily through the network during backpropagation, which can help in training deeper networks without degrading performance. This architecture helps in maintaining the performance of the network as it scales in depth.\n\nFurthermore, the CNN algorithm was tested on a new, unseen dataset, which is a crucial step in validating the model's performance and ensuring it generalizes well to real-world data. This approach helps to avoid the pitfalls of overfitting to the training data, as the model is evaluated on data it has not seen during training.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are not explicitly detailed in the main text. However, the architecture of the convolutional neural network (CNN) is described, including the use of 15 hidden layers, 5 residual layers, and a dropout rate of 0.25 after each convolution. The software code for this study was written using the Python TensorFlow library, version 1.5, and the experiments were conducted on a workstation with an Ubuntu operating system (release 16.04) and a Titan X Pascal graphics card.\n\nThe model files and specific optimization parameters are not provided in the publication. The focus of the paper is on the diagnostic performance metrics, such as sensitivity, specificity, accuracy, and the area under the receiver operating characteristic curve (AUC), rather than the detailed technical specifications of the model training process. Therefore, while the general approach and some high-level details about the CNN architecture are available, the specific hyper-parameter configurations, optimization schedule, and model files are not reported.\n\nNot applicable",
  "model/interpretability": "The model we developed is a convolutional neural network (CNN), which is inherently a black-box model. This means that the decision-making process within the network is not easily interpretable by humans. The CNN operates through a series of layers that transform input data into outputs, but the intermediate steps and the specific features that influence the final prediction are not explicitly clear. This lack of transparency is a common characteristic of deep learning models, including CNNs.\n\nThe end-to-end training process of the CNN does not provide a deterministic explanation for its predictions. While the model can distinguish between atypical ductal hyperplasia (ADH) and ductal carcinoma in situ (DCIS) with high specificity, the reasoning behind these distinctions is not straightforwardly accessible. This opacity is a recognized challenge in the field of artificial intelligence and machine learning, particularly when applying these technologies to medical imaging.\n\nEfforts are ongoing to improve the interpretability of such models. Researchers are exploring methods to visualize and understand the features that CNNs focus on during their decision-making process. Techniques such as saliency maps and class activation maps can highlight the regions of an image that most influence the model's output, providing some insight into what the CNN is \"seeing.\" However, these methods are still in development and do not fully elucidate the internal workings of the model.\n\nIn summary, while our CNN model demonstrates strong diagnostic performance, it remains a black-box model. The lack of transparency in its decision-making process is a limitation that is being actively addressed through various research initiatives aimed at enhancing the interpretability of deep learning models in medical applications.",
  "model/output": "The model developed in our study is a classification model. Specifically, it is a 2-class convolutional neural network (CNN) designed to distinguish between atypical ductal hyperplasia (ADH) and ductal carcinoma in situ (DCIS) based on mammographic images. The model's output is a classification that categorizes each input image into one of these two classes.\n\nThe performance of the model was evaluated using several metrics, including diagnostic accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). The AUC achieved by the model was 0.90, indicating strong discriminative ability. The diagnostic accuracy was 80.7%, with a sensitivity of 63.9% and a specificity of 93.7%. These metrics demonstrate the model's effectiveness in classifying the images into the correct categories.\n\nThe high specificity of 93.7% is particularly notable, as it ensures that the model minimizes the misclassification of DCIS cases as ADH, which is crucial for clinical decision-making. This high specificity allows for careful selection of patients who may be observed rather than undergoing surgery, potentially reducing unnecessary surgical procedures.\n\nThe model's architecture includes 15 hidden layers, with 5 residual layers and dropout of 0.25 after each convolution. This design helps in preventing overfitting and improves the model's generalization to new, unseen data. The use of data augmentation techniques, such as random flipping, rotation, and cropping, further enhances the model's robustness and performance.\n\nIn summary, the output of our model is a classification that distinguishes between ADH and DCIS with high specificity, making it a valuable tool for supporting clinical decisions in the management of breast cancer.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The software code for this study was written using an open-source software library for numerical computation, specifically the Python TensorFlow library, version 1.5. The code was executed on a workstation with an Ubuntu operating system (release 16.04) and a graphics card (Titan X Pascal, NVIDIA). The source code is not publicly released. There is no executable, web server, virtual machine, or container instance available for running the algorithm.",
  "evaluation/method": "The evaluation method involved a prospective analysis using a novel convolutional neural network (CNN) algorithm to distinguish between atypical ductal hyperplasia (ADH) and ductal carcinoma in situ (DCIS) in breast mammographic images. The study utilized 280 unique mammographic images from 140 patients who underwent stereotactic-guided biopsies and subsequent surgical excision. These images were unseen by the algorithm during its initial development, ensuring an unbiased evaluation.\n\nThe dataset consisted of two standard mammographic magnification views: craniocaudal and mediolateral/lateromedial. The images were segmented using an open-source software platform and resized to fit a 128x128 pixel bounding box. The CNN algorithm, which had previously been developed, was applied to these images. The network architecture included 15 hidden layers, 5 residual layers, and dropout of 0.25 after each convolution.\n\nDiagnostic performance metrics were analyzed, including sensitivity, specificity, accuracy, and the area under the receiver operating characteristic curve (AUC). The \"positive class\" was defined as the pure ADH group, meaning that specificity represented the minimization of falsely labeled pure ADH cases. The results showed an AUC of 0.90, with a diagnostic accuracy of 80.7%, sensitivity of 63.9%, and specificity of 93.7%. This high specificity is crucial for identifying patients with pure ADH who may be safely observed rather than undergo surgery. The use of an unseen dataset in a prospective manner was designed to limit overfitting and provide stronger evidence for clinical efficacy.",
  "evaluation/measure": "In the evaluation of our convolutional neural network (CNN) algorithm, several key performance metrics were reported to assess its diagnostic capabilities. These metrics include sensitivity, specificity, accuracy, and the area under the receiver operating characteristic curve (AUC).\n\nSensitivity, also known as the true positive rate, measures the proportion of actual positive cases (pure atypical ductal hyperplasia (ADH)) that are correctly identified by the algorithm. Specificity, or the true negative rate, indicates the proportion of actual negative cases (ductal carcinoma in situ (DCIS)) that are correctly identified. Accuracy provides an overall measure of the algorithm's performance by calculating the proportion of true results (both true positives and true negatives) among the total number of cases evaluated.\n\nThe AUC is a comprehensive metric that evaluates the model's ability to distinguish between the two classes (ADH and DCIS) across all possible classification thresholds. An AUC of 1.0 represents a perfect model, while an AUC of 0.5 indicates a model with no discriminative power.\n\nIn our study, the CNN algorithm achieved an AUC of 0.90, demonstrating strong discriminative ability. The diagnostic accuracy was reported at 80.7%, indicating a high overall performance. Sensitivity was 63.9%, and specificity was notably high at 93.7%. This high specificity is particularly important as it minimizes the number of false positives, ensuring that DCIS cases are not misclassified as pure ADH, which is crucial for clinical decision-making.\n\nThese performance metrics are representative of the standards in the literature for evaluating diagnostic algorithms, particularly in the context of medical imaging and AI applications. The focus on specificity aligns with the clinical need to ensure that patients with DCIS are not incorrectly categorized as having ADH, which could lead to inappropriate management decisions. The reported metrics provide a robust evaluation of the algorithm's performance and its potential for clinical application.",
  "evaluation/comparison": "Not applicable. The study focuses on the development and validation of a convolutional neural network (CNN) algorithm for distinguishing atypical ductal hyperplasia (ADH) from ductal carcinoma in situ (DCIS) using mammographic images. The evaluation primarily centers on the performance of this specific CNN algorithm rather than comparing it to publicly available methods or simpler baselines on benchmark datasets. The study emphasizes the prospective analysis of an unseen dataset to validate the algorithm's diagnostic performance, including metrics such as sensitivity, specificity, accuracy, and area under the receiver operating characteristic curve (AUC). The comparison to other methods or baselines is not a primary focus of this evaluation.",
  "evaluation/confidence": "The evaluation of our convolutional neural network (CNN) algorithm included the calculation of confidence intervals for the performance metrics. Specifically, the area under the receiver operating characteristic curve (AUC) was reported with a 95% confidence interval of \u00b1 0.04. This provides a measure of the uncertainty around the AUC estimate, indicating the range within which the true AUC is likely to fall.\n\nStatistical significance was assessed using a 2-sample t-test for various clinical, imaging, and pathologic parameters. A 2-sided P-value of \u2264 .05 was considered significant. For instance, the difference in age between patients diagnosed with atypical ductal hyperplasia (ADH) and those with ductal carcinoma in situ (DCIS) was found to be statistically significant with a P-value of .01. This suggests that the observed age difference is unlikely to have occurred by chance, reinforcing the reliability of this finding.\n\nThe diagnostic performance metrics, including sensitivity, specificity, and accuracy, were evaluated to determine the effectiveness of the CNN algorithm. The specificity of 93.7% was particularly emphasized, as it represents the algorithm's ability to minimize false positives, which is crucial for clinical decision-making. The high specificity, along with a reasonable diagnostic accuracy of 80.7%, supports the claim that the method is superior to previous attempts that relied on various clinical, histologic, and radiographic criteria.\n\nOverall, the inclusion of confidence intervals and the assessment of statistical significance strengthen the confidence in the performance and reliability of the CNN algorithm. These evaluations provide a robust foundation for claiming that the method is effective and potentially superior to existing approaches.",
  "evaluation/availability": "Not enough information is available."
}