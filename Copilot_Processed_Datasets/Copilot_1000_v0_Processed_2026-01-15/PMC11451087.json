{
  "publication/title": "Epigenomic biomarkers insights in PBMCs for prognostic assessment of ECMO-treated cardiogenic shock patients",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Clinical Epigenetics",
  "publication/year": "2024",
  "publication/pmid": "39363385",
  "publication/pmcid": "PMC11451087",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- ECMO\n- Prognostic biomarker\n- Epigenome\n- Cardiogenic shock\n- DNA methylation\n- Survival prediction\n- Machine learning\n- Clinical epigenetics\n- Extracorporeal membrane oxygenation\n- Hospital mortality",
  "dataset/provenance": "The dataset utilized in this study was sourced from patients who underwent extracorporeal membrane oxygenation (ECMO) support. Specifically, blood samples were collected from 34 patients at two key time points: immediately upon the initiation of ECMO (t0) and two hours post-initiation (t2). Additionally, samples were collected from 14 patients who successfully concluded ECMO support (tr). These samples were used to profile the epigenomics of peripheral blood mononuclear cells (PBMCs).\n\nThe primary data for this study were generated using the Illumina HumanMethylation450 BeadChip, which includes 485,577 methylation probes. These probes offer single-nucleotide resolution and cover approximately 99% of RefSeq genes, enabling comprehensive epigenetic profiling across the entire human genome. The data were subsequently uploaded to the Gene Expression Omnibus (GEO) database under the accession number GSE182609.\n\nThe dataset was filtered to retain only probes with UCSC RefGene annotations, indicating their association with genes. This filtering process left 365,860 probes for further analysis. To mitigate the influence of environmental changes due to ECMO treatment, the Wilcoxon sign-rank test was employed to evaluate methylation levels between the t0 and tr datasets. Probes yielding a p-value greater than 0.8 were deemed stable and retained for further analysis, resulting in 40,112 stable probes.\n\nThe dataset was divided into training and testing cohorts. The t0 dataset was used as the training dataset to develop a machine learning model capable of distinguishing between survival and non-survival groups among ECMO-supported patients. The t2 dataset was used as the test dataset to evaluate the model\u2019s classification performance. This approach ensures that the model is tested on data representing a different time point, which helps in assessing its predictive accuracy and robustness.\n\nThe study also employed LASSO regression for feature selection, which helped in minimizing overfitting and enhancing model validity. Leave-one-out cross-validation (LOOCV) was used to ensure the robustness of the model despite the limited sample size. This methodology significantly improved the reliability of the findings.",
  "dataset/splits": "In our study, we utilized three distinct datasets, denoted as t0, t2, and tr, to develop and evaluate our predictive models. The t0 dataset comprises samples collected from 34 patients at the initiation of ECMO support. The t2 dataset includes samples from the same 34 patients, collected two hours post-initiation of ECMO. The tr dataset consists of samples from 14 patients who successfully concluded ECMO support.\n\nThe t0 dataset was primarily used for training our machine learning models, while the t2 dataset served as the test dataset to evaluate the models' classification performance. This approach ensured that our models were tested on data representing a different time point, thereby assessing their predictive accuracy and robustness.\n\nThe distribution of data points in each dataset reflects the stages of ECMO treatment. The t0 and t2 datasets each contain 34 data points, corresponding to the 34 patients sampled at the respective time points. The tr dataset includes 14 data points, representing the patients who successfully completed ECMO support. This distribution allowed us to analyze epigenetic changes over time and develop models that could predict outcomes based on initial and short-term post-initiation data.",
  "dataset/redundancy": "The datasets used in this study were collected from patients at three key stages: at the initiation of ECMO (t0), two-hour post-initiation (t2), and upon successful ECMO removal (tr). The t0 dataset was used for training the machine learning model, while the t2 dataset was used for testing. This approach ensures that the training and test sets are independent, as they represent different time points. To enforce this independence, samples were collected from 34 patients at t0 and t2, and from 14 patients who successfully concluded ECMO support at tr.\n\nThe distribution of these datasets is tailored to overcome the constraints of a small sample size. The use of leave-one-out cross-validation (LOOCV) ensures robustness despite limited data. This methodology significantly improves the reliability of the findings, as it allows for a thorough evaluation of the model's performance on different subsets of the data.\n\nThe datasets were filtered to retain only probes with UCSC RefGene annotations, indicating their association with genes. This filtering process resulted in 365,860 probes for further analysis. Additionally, the Wilcoxon sign-rank test was employed to evaluate methylation levels between t0 and tr datasets, retaining 40,112 probes that exhibited no significant changes across these time points. This step mitigates the influence of environmental changes, ensuring that the selected features are stable and representative of the patients' epigenetic characteristics.\n\nThe use of LASSO regression for feature selection further refines the dataset, identifying the most relevant probes for predicting outcomes. The alpha values tested in LASSO regression range from 0 to 0.25, with the number of features retained varying accordingly. This systematic approach to dataset redundancy ensures that the final model is robust, reliable, and capable of accurately predicting hospital mortality for patients receiving ECMO support.",
  "dataset/availability": "The data supporting the findings of this study have been deposited in the Gene Expression Omnibus (GEO) at the National Center for Biotechnology Information (NCBI). The GEO accession number is GSE182609. This ensures that the dataset is publicly available for verification and further research. The deposition in GEO provides a standardized platform for data sharing, adhering to the principles of open science and reproducibility. The data includes the methylation profiles of peripheral blood mononuclear cells (PBMCs) collected at different time points during ECMO treatment, which were used to develop and validate the predictive model for hospital mortality in cardiogenic shock patients receiving ECMO support. The dataset is accessible under the terms and conditions specified by GEO, which typically include proper citation and acknowledgment of the original study. This approach ensures that the data is available for future research while maintaining the integrity and proper use of the information.",
  "optimization/algorithm": "The optimization algorithm employed in our study is based on LASSO (Least Absolute Shrinkage and Selection Operator) regression, a well-established machine-learning technique used for feature selection and regularization. LASSO regression is not a new algorithm; it has been widely used in various fields, including genomics and bioinformatics, for its ability to handle high-dimensional data and perform variable selection.\n\nThe choice of LASSO regression was driven by its effectiveness in mitigating overfitting, which is crucial given the constraints of a small sample size in our dataset. By applying LASSO regression, we were able to identify a subset of stable methylation probes that consistently represent the epigenetic characteristics of patients across different time points, thereby enhancing the robustness of our predictive model.\n\nThe algorithm's implementation involved selecting optimal alpha values to determine the number of features retained for model training. We tested several alpha values, including 0.05, 0.1, 0.2, and 0.25, to evaluate their classification performance. The results indicated that specific alpha values, such as 0.2 and 0.25, demonstrated superior predictive accuracy on the testing dataset, highlighting the algorithm's effectiveness in feature selection.\n\nWhile LASSO regression is a standard technique in machine learning, its application in our study is tailored to the specific context of predicting hospital mortality in cardiac surgery patients receiving ECMO support. The focus of our publication is on the clinical implications and the development of a biomarker for outcome prediction, rather than the novelty of the machine-learning algorithm itself. Therefore, it is published in a clinical epigenetics journal rather than a machine-learning journal.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. Instead, it relies on epigenomic biomarkers and machine learning techniques to predict outcomes for patients undergoing ECMO treatment for cardiogenic shock. The primary machine learning method employed is LASSO regression, which is used for feature selection from methylation data. This selected features are then used to train a random forest classifier.\n\nThe training dataset consists of methylation profiles collected at the initiation of ECMO (t0), while the testing dataset includes profiles from two hours post-initiation (t2). This temporal separation ensures that the training and testing data are independent, enhancing the robustness of the model's predictive performance.\n\nThe model's development involved several steps, including profiling the epigenomics of peripheral blood mononuclear cells (PBMCs) at different time points, filtering stable methylation probes, and using LASSO regression to select significant features. The random forest classifier was then trained on these features to distinguish between survival and non-survival groups among ECMO-supported patients.\n\nThe integration of the SAVE score with selected methylation features further improved the model's performance, as evidenced by enhanced AUC values in the ROC curves. This approach leverages both clinical characteristics and epigenetic data to provide a more accurate prediction of in-hospital mortality for patients receiving ECMO treatment.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several key steps. Initially, we profiled the epigenomics of peripheral blood mononuclear cells (PBMCs) collected at three critical stages: at the initiation of extracorporeal membrane oxygenation (ECMO) support (t0), two hours post-initiation (t2), and upon successful ECMO removal (tr). Samples were collected from 34 patients at t0 and t2, and from 14 patients who successfully concluded ECMO support.\n\nWe started with 485,577 methylation probes from the Human Methylation 450 Beadchip assay. To ensure relevance, we retained only probes with UCSC RefGene annotations, which are associated with genes, resulting in 365,860 probes for further analysis. Our hypothesis was that changes in methylation levels among different time points could be attributed to environmental changes resulting from ECMO treatment. Therefore, we aimed to identify features that consistently represent the epigenetic characteristics of a patient across these transitions.\n\nTo mitigate the influence of environmental changes, we employed the Wilcoxon sign-rank test to evaluate methylation levels between the t0 and tr datasets. Probes yielding a p-value greater than 0.8 were deemed to exhibit no significant changes across these time points, resulting in the retention of 40,112 stable probes.\n\nFor the machine learning model, we utilized the t0 dataset as the training dataset and the t2 dataset as the test dataset. This approach ensured that our model was tested on data representing a different time point, helping to assess its predictive accuracy and robustness. Given the constraints of a small sample size, we employed LASSO (Least Absolute Shrinkage and Selection Operator) regression to minimize overfitting and enhance model validity. We also utilized leave-one-out cross-validation (LOOCV) to ensure robustness despite limited data.\n\nLASSO regression was applied to the 40,112 stable probes in the t0 dataset for feature selection. We tested various alpha values (0, 0.00001, 0.05, 0.1, 0.2, and 0.25) to evaluate classification performance. An alpha of 0 implied that all stable probes were included in the model without feature selection, using a random forest classification approach. The number of features retained for each tested alpha were 40,112, 290, 27, 24, 10, and 4, respectively.\n\nThe LOOCV accuracy for alphas 0.1 and 0.2 reached approximately 0.912, indicating robust training performance. Notably, alpha 0.25 demonstrated the highest testing accuracy at 0.765. We conducted Kaplan\u2013Meier survival analyses using the feature sets from LASSO alphas of 0.20 and 0.25, which showed significant differences in survival between patients predicted to be in the survival or non-survival groups. The ten-feature classifier had a p-value of 0.0459, while the four-feature classifier had a p-value of 0.0328, indicating their superior predictive power as biomarkers for outcomes in cardiogenic shock patients undergoing ECMO treatment.",
  "optimization/parameters": "In the development of our predictive model for hospital mortality in cardiogenic shock (CS) patients with extracorporeal membrane oxygenation (ECMO) installation, we initially considered a comprehensive set of epigenetic features. Specifically, we started with 40,112 stable methylation probes identified from the t0 dataset, which were selected based on their consistency across different time points to mitigate the influence of environmental changes due to ECMO treatment.\n\nTo optimize our model and prevent overfitting, we employed LASSO (Least Absolute Shrinkage and Selection Operator) regression for feature selection. This method allowed us to systematically reduce the number of features by adjusting the alpha parameter. We tested several alpha values: 0, 0.00001, 0.05, 0.1, 0.2, and 0.25. Each alpha value corresponded to a different number of retained features: 40,112, 290, 27, 24, 10, and 4, respectively.\n\nThe selection of the optimal alpha value was guided by the model's performance metrics, particularly the mean squared error and the number of nonzero features. We evaluated the classification performance for each alpha value using leave-one-out cross-validation (LOOCV) on the t0 dataset and tested the models on the t2 dataset. The results indicated that alpha values of 0.1 and 0.2 provided robust training performance with LOOCV accuracy approaching 0.912. Notably, alpha 0.25 demonstrated the highest testing accuracy at 0.765, suggesting that a smaller set of features could still yield strong predictive power.\n\nUltimately, we identified that the models using 10 features (alpha 0.20) and 4 features (alpha 0.25) showed superior predictive accuracy on the t2 testing dataset, with values of 0.735 and 0.765, respectively. These feature sets were further validated through Kaplan-Meier survival analyses, confirming their significance in predicting in-hospital survival for CS patients undergoing ECMO treatment.",
  "optimization/features": "In the optimization process, feature selection was indeed performed using LASSO regression. This method was applied to an initial set of 40,112 stable probes identified from the t0 dataset. The LASSO regression helped in determining the optimal shrinkage parameter, alpha, by evaluating the mean squared error and the number of nonzero features associated with each alpha value.\n\nSeveral alpha values were tested to assess classification performance: 0, 0.00001, 0.05, 0.1, 0.2, and 0.25. An alpha of 0 included all stable probes in the model without feature selection, utilizing a random forest classification approach. The number of features retained for each tested alpha value varied significantly: 40,112 for alpha 0, 290 for alpha 0.00001, 27 for alpha 0.05, 24 for alpha 0.1, 10 for alpha 0.2, and 4 for alpha 0.25.\n\nThe feature selection process was conducted using the training set only, ensuring that the model's performance was evaluated on an independent test set (t2 dataset). This approach helped in mitigating overfitting and enhancing the model's validity, especially given the constraints of a small sample size. The selected features for the tested alpha values of 0.05, 0.1, 0.2, and 0.25 are detailed in Table 2, which lists the corresponding LASSO coefficients and Mann\u2013Whitney U test p-values. Notably, four probes were selected when alpha was set to 0.25, corresponding to the genes PLA2G5, PTK2B, ANKRD11, and COLEC12. These probes showed significant differences between the survival and non-survival groups, underscoring their potential importance in the dataset.",
  "optimization/fitting": "The fitting method employed in this study involved several key strategies to address potential issues of overfitting and underfitting, particularly given the high-dimensional nature of the data.\n\nThe number of parameters initially considered was indeed much larger than the number of training points. Specifically, we started with 485,577 methylation probes, which far exceeds the 34 patients in the training dataset. To mitigate the risk of overfitting, we implemented LASSO (Least Absolute Shrinkage and Selection Operator) regression. LASSO is a regularization technique that performs both variable selection and regularization to enhance the prediction accuracy and interpretability of the statistical model it produces. By applying LASSO, we were able to reduce the number of features to a more manageable size, thereby minimizing the risk of overfitting.\n\nAdditionally, we utilized Leave-One-Out Cross-Validation (LOOCV) to ensure the robustness of our model. LOOCV is a technique where each learning algorithm is run on all the data points except one, and this is repeated such that each data point has been left out once. This method helps in maximizing the data available for model training and provides a more reliable estimate of the model's performance.\n\nTo further enhance the model's validity, we employed a random forest classifier. Random forests build multiple decision trees on random subsets of the data and aggregate their results, which helps in improving accuracy and mitigating the risk of overfitting. This approach was particularly useful given the high-dimensional features and the small sample size.\n\nRegarding underfitting, the use of LASSO regression and random forest classifier ensured that the model was complex enough to capture the underlying patterns in the data without being too simplistic. The selection of optimal alpha values in LASSO and the aggregation of multiple decision trees in the random forest classifier helped in achieving a balance between bias and variance, thereby preventing underfitting.\n\nIn summary, the fitting method involved LASSO regression for feature selection, LOOCV for robust performance estimation, and a random forest classifier for building a robust model. These techniques collectively addressed the challenges posed by the high-dimensional data and small sample size, ensuring that the model was neither overfitted nor underfitted.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and enhance the robustness of our machine learning models. Given the constraints of a small sample size, we utilized LASSO (Least Absolute Shrinkage and Selection Operator) regression. LASSO is a regularization method that performs both variable selection and regularization to enhance the prediction accuracy and interpretability of the statistical model it produces. It does this by adding a penalty equal to the absolute value of the magnitude of coefficients, which can shrink some coefficients to zero, effectively performing feature selection.\n\nWe applied LASSO regression to the 40,112 stable probes in the t0 dataset for feature selection. We tested various alpha values (0, 0.00001, 0.05, 0.1, 0.2, and 0.25) to evaluate the classification performance. An alpha of 0 implies that all stable probes were included in the model without feature selection, using a random forest classification approach. The number of features retained for each tested alpha varied significantly, ranging from 40,112 to just 4.\n\nAdditionally, we used Leave-One-Out Cross-Validation (LOOCV) to ensure the robustness of our models despite the limited data. LOOCV is a technique where each learning set is created by taking all the samples except one, and the test set is the sample that was left out. This process is repeated such that each sample in the dataset is used once as a test set while the remaining samples form the training set. This method helps in assessing the model's performance and generalizability.\n\nThese techniques collectively improved the reliability and predictive accuracy of our models, ensuring that they were not overfitted to the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we employed LASSO regression for feature selection, testing various alpha values to determine the optimal model. The alpha values tested were 0, 0.00001, 0.05, 0.1, 0.2, and 0.25, with corresponding numbers of features retained being 40,112, 290, 27, 24, 10, and 4, respectively. The performance of these models was evaluated using ROC curves and LOOCV accuracy.\n\nThe datasets supporting our findings have been deposited in the Gene Expression Omnibus (GEO) at the National Center for Biotechnology Information (NCBI). The GEO accession number is GSE182609. This repository provides access to the data used for training and testing our models, ensuring reproducibility and transparency.\n\nRegarding model files and optimization parameters, while the specific model files are not explicitly mentioned as being available, the detailed methodology and results provided in the publication allow for the reconstruction of the models. The optimization schedule, including the use of LOOCV and the evaluation of different alpha values, is thoroughly described, enabling other researchers to replicate our approach.\n\nThe data and materials are made available under standard licensing terms typical for GEO submissions, which generally allow for academic use and further research. This ensures that the community can build upon our work, fostering collaboration and advancement in the field.",
  "model/interpretability": "The model developed in our study is not entirely a black box, as we have employed techniques to enhance its interpretability. We utilized LASSO regression for feature selection, which helps in identifying the most relevant probes associated with hospital mortality in cardiac shock (CS) patients with ECMO installation. This process reduces the complexity of the model by selecting a subset of features that contribute most to the prediction, making it more interpretable.\n\nFor instance, at an alpha value of 0.25, four specific probes were selected: cg25974901, cg26330738, cg04937029, and cg07137336. These probes correspond to the genes PLA2G5, PTK2B, ANKRD11, and COLEC12, respectively. The selection of these probes across different alpha values underscores their potential significance in predicting outcomes. Additionally, the consistent selection of probes cg25974901 (PLA2G5) and cg26330738 (PTK2B) across all tested alpha levels further highlights their importance.\n\nMoreover, we conducted Kaplan\u2013Meier survival analyses using the feature sets identified by LASSO regression at alpha values of 0.20 and 0.25. The results showed significant differences in survival between patients predicted to be in the survival or non-survival groups, with p-values of 0.0459 and 0.0328, respectively. This analysis provides a clear interpretation of how the selected features are associated with patient outcomes.\n\nTo further enhance interpretability, we incorporated clinical characteristics, such as the SAVE score, with the selected methylation features to develop the EpiSAVE classifier. This integration allows for a more comprehensive understanding of the factors contributing to patient outcomes, combining both epigenetic and clinical data.\n\nIn summary, while the model leverages advanced machine learning techniques, the use of LASSO regression for feature selection and the integration of clinical scores provide a level of transparency. This approach allows for a clearer understanding of the key factors influencing hospital mortality in CS patients with ECMO installation.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict hospital mortality in patients with cardiogenic shock (CS) who have undergone extracorporeal membrane oxygenation (ECMO) installation. The model utilizes various machine learning techniques, including LASSO regression for feature selection and random forest classification for predicting outcomes.\n\nThe workflow involves training the model on a dataset (t0) and testing it on another dataset (t2). Different alpha values in LASSO regression were tested to determine the optimal number of features for the model. The performance of the model was evaluated using metrics such as accuracy, area under the curve (AUC), and receiver operating characteristic (ROC) curves. The model's predictive capabilities were further validated through Kaplan-Meier survival analyses, which showed significant differences in survival between the predicted survival and non-survival groups.\n\nThe final classifier, named EpiSAVE, incorporates the SAVE score with selected methylation features, enhancing the predictive power of the model. The EpiSAVE classifier demonstrated improved AUC values, indicating its effectiveness in predicting outcomes for CS patients undergoing ECMO treatment.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in our study was designed to ensure the robustness and reliability of our predictive models. We utilized leave-one-out cross-validation (LOOCV) to assess the training performance of our models on the t0 dataset. This method involves training the model on all but one sample and testing it on the left-out sample, repeating this process for each sample in the dataset. This approach maximizes the use of available data and provides a thorough evaluation of the model's performance.\n\nFor the testing phase, we evaluated the models' performance on the t2 dataset, which represents a different time point from the training data. This strategy helps in assessing the models' predictive accuracy and robustness when applied to new, unseen data.\n\nWe also conducted Kaplan\u2013Meier survival analyses using the feature sets identified by LASSO regression at different alpha levels. The results showed significant differences in survival between patients predicted to be in the survival or non-survival groups, as determined by the log-rank test. This analysis further validated the predictive capabilities of our models.\n\nAdditionally, we evaluated the performance of random forest classifiers trained with different feature sets identified by LASSO regression. The results were presented in terms of LOOCV training accuracy and testing accuracy on the t2 dataset. This comprehensive evaluation method ensures that our findings are reliable and generalizable.",
  "evaluation/measure": "In our evaluation, we employed several performance metrics to comprehensively assess the effectiveness of our classifiers. The primary metrics reported include the area under the receiver operating characteristic curve (AUC) and accuracy. The AUC was used to evaluate the predictive power of various risk assessment scores, such as APACHE II, LODS, MODS, SOFA, and SAVE, in distinguishing between success and failure groups within 7 days. Notably, APACHE II and LODS demonstrated significant predictive power with AUC values of 0.76 and 0.73, respectively, both with p-values less than 0.05. In contrast, MODS, SAVE, and SOFA scores showed poor predictive performance for 7-day outcomes and did not significantly predict in-hospital mortality.\n\nFor the classifiers developed using LASSO regression, we reported the leave-one-out cross-validation (LOOCV) accuracy and testing accuracy on the t2 dataset. The LOOCV accuracy for alphas 0.1 and 0.2 reached approximately 0.912, indicating robust training performance. The highest testing accuracy of 0.765 was achieved with an alpha of 0.25. Additionally, we conducted Kaplan\u2013Meier survival analyses using the feature sets from LASSO alphas of 0.20 and 0.25, which showed significant differences in survival between predicted survival and non-survival groups, with p-values of 0.0459 and 0.0328, respectively.\n\nThe set of metrics used in our study is representative of standard practices in the literature for evaluating classifier performance. The AUC is a widely accepted metric for assessing the discriminative ability of predictive models, particularly in medical research. The use of accuracy and LOOCV further ensures the robustness and generalizability of our findings. By incorporating these metrics, we aimed to provide a thorough evaluation of our classifiers' performance, aligning with established methodologies in the field.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on developing and evaluating a machine learning model tailored to our specific dataset, which involved patients undergoing ECMO treatment. We utilized LASSO regression for feature selection and random forest classifiers for prediction, ensuring robustness through leave-one-out cross-validation (LOOCV).\n\nWe did, however, compare the performance of our models with established clinical scoring systems. Specifically, we evaluated the predictive power of APACHE II, LODS, MODS, SAVE, and SOFA scores for outcomes within 7 days and in-hospital mortality. APACHE II and LODS demonstrated significant predictive power for outcomes within 7 days, achieving AUC values of 0.76 and 0.73, respectively. However, MODS, SAVE, and SOFA scores showed poor predictive performance for outcomes within 7 days and none of these scores significantly predicted in-hospital mortality.\n\nOur approach involved incorporating the SAVE score with selected methylation features to enhance the predictive power of our models. This integration resulted in improved AUC values for the ROC curves, indicating better performance compared to using the SAVE score alone. This comparison to simpler baselines, such as clinical scoring systems, provided a context for evaluating the effectiveness of our machine learning models in predicting patient outcomes.",
  "evaluation/confidence": "The evaluation of our models involved several key metrics and statistical tests to ensure the robustness and significance of our findings. We utilized the leave-one-out cross-validation (LOOCV) method to assess the training performance, which provided accuracy metrics for different alpha values in LASSO regression. Specifically, LOOCV accuracy for alphas 0.1 and 0.2 reached approximately 0.912, indicating strong training performance. Notably, alpha 0.25 demonstrated the highest testing accuracy at 0.765, highlighting its predictive capabilities.\n\nTo further validate our results, we conducted Kaplan\u2013Meier survival analyses using feature sets derived from LASSO alphas of 0.20 and 0.25. The ten-feature classifier had a p-value of 0.0459, while the four-feature classifier had a p-value of 0.0328, both indicating significant differences in survival between the predicted groups. These p-values, derived from the log-rank test, confirm the statistical significance of our models in distinguishing between survival and non-survival outcomes.\n\nAdditionally, we evaluated the performance of our models using receiver operating characteristic (ROC) curves and the area under the curve (AUC). The incorporation of the SAVE score with selected methylation features enhanced the AUC values, improving from 0.78 to 0.82 at a specific alpha value. This improvement underscores the added predictive power of integrating clinical characteristics with epigenetic features.\n\nThe Mann\u2013Whitney U test was employed to assess the significance of selected probes. Probes such as cg25974901 (PLA2G5) and cg26330738 (PTK2B) were consistently selected across different alpha levels, with p-values indicating significant differences between survival and non-survival groups. These probes, along with others like cg04937029 (ANKRD11) and cg07137336 (COLEC12), demonstrated robust statistical significance.\n\nIn summary, our evaluation metrics, including LOOCV accuracy, Kaplan\u2013Meier survival analyses, ROC curves, and statistical tests like the Mann\u2013Whitney U test, provide a comprehensive assessment of our models' performance. The significant p-values and improved AUC values support the claim that our method is superior in predicting outcomes for patients undergoing ECMO treatment.",
  "evaluation/availability": "The raw evaluation files supporting the findings of this study have been deposited in the Gene Expression Omnibus (GEO) at the National Center for Biotechnology Information (NCBI). The GEO accession number is GSE182609. This dataset is publicly available, allowing other researchers to access and utilize the data for further analysis or validation of our results. The data is released under the terms and conditions specified by the NCBI, ensuring that it can be used responsibly and ethically by the scientific community."
}