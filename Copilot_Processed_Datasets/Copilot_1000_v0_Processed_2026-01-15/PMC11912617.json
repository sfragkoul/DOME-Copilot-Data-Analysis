{
  "publication/title": "TransGeneSelector: A Robust Tool for Key Gene Mining in Small Sample Transcriptomic Datasets",
  "publication/authors": "The authors who contributed to this article are:\n\n- **X.J.** contributed to conceptualizing the study and reviewed and edited the manuscript.\n- **Y.W.** contributed to conceptualizing the study and reviewed and edited the manuscript.\n- **P.X.** contributed to conceptualizing the study and reviewed and edited the manuscript.\n- **K.H.** conceptualized the study, developed the software and methodology, conducted experiments, wrote the original draft, and reviewed and edited the manuscript.\n- **J.T.** developed the methodology, conducted experiments, and reviewed and edited the manuscript.\n- **L.S.** conducted experiments and reviewed and edited the manuscript.\n- **H.H.** conducted experiments and reviewed and edited the manuscript.\n- **X.H.** conducted experiments and reviewed and edited the manuscript.\n- **S.Z.** developed the methodology and reviewed and edited the manuscript.\n- **A.D.** developed the methodology and reviewed and edited the manuscript.\n- **Z.Z.** prepared the visualizations and reviewed and edited the manuscript.\n- **M.J.** prepared the visualizations and reviewed and edited the manuscript.\n- **G.L.** prepared the visualizations and reviewed and edited the manuscript.\n\nAll authors reviewed the manuscript.",
  "publication/journal": "BMC Genomics",
  "publication/year": "2025",
  "publication/pmid": "40098114",
  "publication/pmcid": "PMC11912617",
  "publication/doi": "10.1186/s12864-025-11434-y",
  "publication/tags": "- Gene mining\n- Transcriptome sequencing\n- Machine learning\n- Deep learning\n- Gene expression\n- Biological processes\n- Agronomic traits\n- Disease-related genes\n- Transformer models\n- SHAP method\n- WGAN-GP\n- TransGeneSelector\n- Key gene identification\n- Environmental interactions\n- Plant genetics\n- Medical research\n- Data availability\n- Gene regulatory networks\n- Transcriptomics\n- Bioinformatics",
  "dataset/provenance": "The dataset utilized in this study was sourced from publicly available repositories. Specifically, gene expression data were extracted from the NCBI GEO (Gene Expression Omnibus) database and the Expression Atlas database. For the training and testing of the TransGeneSelector and Random Forest models, experiments GSE116069, GSE161704, GSE163057, GSE167244, GSE179008, GSE155710, GSE158444, GSE184983, GSE200247, GSE212019, GSE232094, GSE239833, and GSE244763 from NCBI were selected. Additionally, for MERLIN network analysis, experiments E-CURD-1, E-GEOD-30720, E-GEOD-52806, E-GEOD-64740, E-MTAB-4202, E-MTAB-7933, E-MTAB-7978 from Expression Atlas and GSE199116 from NCBI were included. These datasets are publicly accessible and can be found in the respective databases. The datasets used in this study are well-established and have been utilized in previous research, ensuring their reliability and relevance for the current study.",
  "dataset/splits": "There are two main datasets used in our study, each split into training and testing sets.\n\nFor the seed germination state classification, the training set consists of 79 samples, with 43 positive samples (germinating seeds) and 36 negative samples (dry seeds). The testing set comprises 42 samples, evenly split with 21 positive and 21 negative samples.\n\nIn the heat stress state classification, the training set includes 156 samples, with 76 positive samples (plants under heat stress) and 80 negative samples (plants in normal conditions). The testing set for this classification task contains 53 samples, with 28 positive and 25 negative samples.\n\nAdditionally, for the seed germination-related task, experiments E-CURD-1, E-GEOD-30,720, E-GEOD-52,806, E-GEOD-64,740, E-MTAB-4202, E-MTAB-7933, E-MTAB-7978 from Expression Atlas and GSE199116 from NCBI were included for further analysis. These experiments provided 268 samples unrelated to seed germination and heat stress, and the same TPM calculations were applied, retaining genes found across all samples.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data utilized in this study were sourced from publicly available repositories. The gene expression data were extracted from the NCBI GEO (Gene Expression Omnibus) database and the Expression Atlas database. Specifically, the experiments GSE116069, GSE161704, GSE163057, GSE167244, GSE179008, GSE155710, GSE158444, GSE184983, GSE200247, GSE212019, GSE232094, GSE239833, and GSE244763 from NCBI were selected for the training and testing of the TransGeneSelector and Random Forest models. For additional MERLIN network analysis, experiments E-CURD-1, E-GEOD-30720, E-GEOD-52806, E-GEOD-64740, E-MTAB-4202, E-MTAB-7933, E-MTAB-7978 from Expression Atlas and GSE199116 from NCBI were included. These datasets are publicly accessible and can be found in the respective databases.",
  "optimization/algorithm": "The optimization algorithms employed in our study primarily revolve around machine learning models, specifically focusing on the TransGeneSelector and Random Forest algorithms. The TransGeneSelector model is a novel approach that integrates a Transformer architecture with a Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP) and an additional classifier. This model is designed to handle the complexities of gene mining in small sample transcriptomic datasets. The Random Forest model, on the other hand, is a well-established ensemble learning method known for its robustness and ability to handle high-dimensional data.\n\nThe TransGeneSelector model represents a significant advancement in gene mining, leveraging the strengths of deep learning to bridge gaps in traditional methodologies. It is not a standard machine-learning algorithm found in typical machine-learning journals because it is specifically tailored for biological data analysis, particularly in the context of gene expression and regulatory networks. The integration of Transformer networks and WGAN-GP components allows for more nuanced and accurate gene selection, making it a powerful tool for biological research.\n\nThe Random Forest model, while not new, was optimized using grid search to determine the best combination of hyperparameters, such as the number of estimators and features to select. This optimization process ensured that the model achieved high accuracy and reliability in its predictions. The use of grid search is a standard practice in machine learning to fine-tune model parameters and improve performance.\n\nIn summary, the machine-learning algorithms used in this study include both novel and established methods. The TransGeneSelector model is a new algorithm designed for gene mining, while the Random Forest model is a well-known ensemble learning technique optimized for our specific dataset. The choice of these algorithms reflects their suitability for the complex tasks of gene selection and classification in biological data.",
  "optimization/meta": "In our study, we employed a meta-predictor approach to enhance the robustness and generalizability of our models. The meta-predictor integrates predictions from multiple machine learning algorithms to make final decisions. Specifically, the meta-predictor utilizes outputs from several models, including TransGeneSelector, Random Forest, Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and Network-Regularized Logistic Regression with Minimax Concave Penalty (NR-LR-MCP).\n\nThe TransGeneSelector model, in its various forms, serves as a core component of this meta-predictor. It includes versions with and without optimization techniques like early stopping, as well as variants that substitute the WGAN component with a mix-up component or replace the Transformer component with an MLP. The Random Forest model, trained using feature engineering on specific gene sets, also plays a crucial role. The genes selected by the Random Forest model are used as features for the SVM and KNN models, ensuring a consistent and optimized feature set across these algorithms.\n\nTo ensure the independence of training data, we employed a 5-fold cross-validation approach for both TransGeneSelector and Random Forest models. This method helps in validating the models' performance and ensuring that the training data is independent across different folds. Additionally, we conducted a comprehensive evaluation using metrics such as accuracy, precision, recall, F1 score, and AUC to assess the performance of all models.\n\nThe meta-predictor leverages the strengths of these individual models, combining their predictions to achieve superior performance in classifying physiological states of plants under varying environmental conditions. This approach underscores the robustness and potential of the meta-predictor in handling complex tasks and small sample sizes.",
  "optimization/encoding": "The data encoding process for the machine-learning algorithm involved several key steps to ensure the gene expression data was appropriately formatted and standardized for input into the Transformer network.\n\nInitially, gene TPM expression levels underwent distribution correction and standardization. A log1p transformation was applied to the gene expression levels to stabilize variance and normalize the distribution of expression values. This transformation is crucial for facilitating the use of gene expression data as input for neural networks, as it helps to manage the wide range of expression values typically observed in biological data.\n\nAfter generating samples, both generated and real samples for seeds under germinating or dry conditions were input into the Transformer network. The first step in the encoding process involved using a fully connected network to reduce the dimensionality of the gene expression data. This reduction helps to manage the high dimensionality of gene expression datasets, making the data more manageable for the subsequent layers of the network. The output of this step is a lower-dimensional representation of the input genes, calculated using the formula y = xT W + b, where x is the input expression value, W are the weights, and b are the biases.\n\nFollowing dimensionality reduction, the lower-dimensional representation was positional encoded. Positional encoding provides the Transformer network with information about the order of the representation, which is essential for understanding the sequence of gene expressions. The positional encoding values were calculated using the formulas:\n\nPE (pos,2i) = sin(pos/10000^(2i/dmodel))\n\nPE (pos,2i+1) = cos(pos/10000^(2i/dmodel))\n\nwhere pos is the position of the word in the sequence, i is the index of the dimension pair, and dmodel is the dimension of the input embeddings.\n\nThis positional encoded, lower-dimensional representation was then fed into the Transformer Encoder. The Encoder processes the input sequence through multiple self-attention and feed-forward layers, allowing the model to effectively understand and classify the input data. The multi-head self-attention mechanism within the Encoder enables the model to attend to different parts of the input sequence simultaneously, enhancing its ability to capture complex patterns in the gene expression data.\n\nOverall, the data encoding process involved dimensionality reduction, positional encoding, and the use of a Transformer Encoder to prepare the gene expression data for biological process classification. These steps ensure that the data is in a suitable format for the machine-learning algorithm to effectively learn and make accurate predictions.",
  "optimization/parameters": "In our study, the number of parameters, denoted as p, varies depending on the specific model and task. For the TransGeneSelector model, p represents the total number of genes considered in the analysis. These genes were selected based on their presence across all samples in the dataset, ensuring consistency in the feature set.\n\nFor the Random Forest model, we conducted feature engineering on gene sets of varying sizes, specifically 8, 11, 41, 51, 128, and 449 genes. These gene sets were chosen because they achieved the highest cross-validation accuracy during the model training process. The selection of these gene sets was driven by the goal of optimizing model performance through careful feature engineering.\n\nThe TransGeneSelector model's parameters were optimized using a comprehensive grid search. This involved evaluating different combinations of hyperparameters for each component of the model, including the WGAN-GP module, the additional classifier, and the Transformer network. The best parameter combinations were selected based on validation set loss values and other performance metrics.\n\nFor the Random Forest model, the parameters were optimized through a grid search that combined different values of n_estimators (10, 100) with 200 values of n_features_to_select, uniformly spaced between 1 and 500. The best parameter combination was chosen based on model accuracy.\n\nIn summary, the number of parameters p was selected through a combination of feature engineering and hyperparameter optimization, aiming to achieve the best possible model performance for the given tasks.",
  "optimization/features": "In our study, the number of input features varied depending on the model and the specific task. For the Random Forest model, feature selection was performed using the training set only. We employed a grid search to combine different numbers of estimators with 200 values of features to select, uniformly spaced between 1 and 500. The best parameter combination was chosen based on model accuracy. Specifically, the Random Forest model was trained using feature engineering on gene sets of 8, 11, 41, 51, 128, and 449 genes, as these sets achieved the highest cross-validation accuracy.\n\nFor the TransGeneSelector model, the training batch size for the Transformer architecture and the WGAN-GP component was set to 32. However, the additional classifier in TransGeneSelector utilized a full batch size for training, maintaining a 1:1 ratio of real to generated samples.\n\nThe features utilized by both the K-Nearest Neighbors (KNN) and Support Vector Machine (SVM) algorithms were derived from the feature engineering process of the Random Forest model. This ensured that the features selected were those that achieved the highest validation set accuracy during cross-validation.\n\nIn summary, feature selection was a crucial part of our optimization process, and it was performed using the training set to ensure the robustness and generalizability of our models.",
  "optimization/fitting": "The fitting method employed in our study involved a comprehensive approach to ensure that both overfitting and underfitting were adequately addressed.\n\nFor the TransGeneSelector model, a grid search was performed to optimize various parameters, including epochs, learning rates, and other hyperparameters. This method helped in fine-tuning the model to prevent overfitting. Additionally, early stopping criteria were implemented in some model groups to halt training when performance on a validation set ceased to improve, further mitigating overfitting risks. The use of a 5-fold cross-validation approach also ensured that the model's performance was robust and generalizable across different subsets of the data.\n\nConversely, to avoid underfitting, the model's complexity was carefully managed. The TransGeneSelector model comprises three separate neural networks, each with its own set of parameters optimized through extensive grid searches. This complexity allowed the model to capture intricate patterns in the data, reducing the likelihood of underfitting. Furthermore, the inclusion of additional experiments and datasets unrelated to the primary tasks provided a broader context for training, enhancing the model's ability to generalize.\n\nThe Random Forest model, while simpler in structure, was also optimized through a grid search to select the best combination of parameters, such as the number of estimators and features to select. This ensured that the model was neither too simple nor too complex, striking a balance that prevented both overfitting and underfitting.\n\nIn summary, the fitting method involved rigorous optimization techniques, cross-validation, and careful management of model complexity to address both overfitting and underfitting concerns.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. For the TransGeneSelector model, we implemented early stopping as a regularization method. This technique halts the training process when the model's performance on a validation set stops improving, thereby preventing the model from overfitting to the training data. Additionally, we conducted a comprehensive grid search to optimize the hyperparameters of the TransGeneSelector, including the epochs, learning rates, and other architectural parameters. This process helped in selecting the best-performing model configuration that generalizes well to unseen data.\n\nFor the Random Forest model, we used grid search to optimize the parameters, specifically combining the number of estimators and the number of features to select. This method ensures that the model is not overly complex and can generalize better to new data. Furthermore, we evaluated the models using a 5-fold cross-validation approach, which provides a more reliable estimate of model performance and helps in detecting overfitting.\n\nIn summary, both early stopping and grid search were utilized as regularization techniques to prevent overfitting and enhance the models' ability to generalize across different datasets.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules for the models discussed in our study are thoroughly detailed within the publication. Specifically, for the TransGeneSelector model, we conducted a comprehensive grid search to optimize various components. For the WGAN-GP module, epochs ranged from 200 to 6000 in steps of 200, combined with different learning rates (0.1, 0.01, 0.001). The additional classifier was evaluated with epochs set to 100 and 150, and learning rates of 0.1 and 0.01. The Transformer network was assessed with various combinations of embedding and header numbers, learning rates, and training periods.\n\nFor the Random Forest model, parameters were optimized using a grid search that combined different numbers of estimators (10, 100) with 200 values of n_features_to_select, uniformly spaced between 1 and 500. The best parameter combination was chosen based on model accuracy.\n\nThe optimization parameters for other models, such as the Network-Regularized Logistic Regression model with Minimax Concave Penalty (NR-LR-MCP), K-Nearest Neighbors (KNN), and Support Vector Machine (SVM), are also reported. For NR-LR-MCP, a grid search was performed on hyperparameters including alpha, \u03bb1, \u03bb2, and learning rate.\n\nModel files and specific optimization parameters are not directly provided in the main text but are available in the supplementary material. The supplementary information, accessible via the provided DOI, includes detailed methodologies and additional data that support the findings and optimizations described in the study.\n\nAll the data and methodologies presented in this study are made available under open-access principles, ensuring that other researchers can replicate and build upon our work. The supplementary material is licensed to allow for broad usage and further research.",
  "model/interpretability": "The TransGeneSelector model, while complex, incorporates mechanisms to enhance its interpretability. Unlike traditional black-box models, TransGeneSelector utilizes the SHAP (SHapley Additive exPlanations) method to mine important genes. SHAP is based on game theory and assigns a value to each gene, indicating its contribution to the model's predictions. This approach allows for a clear understanding of which genes are most influential in the classification tasks.\n\nThe SHAP values provide a transparent way to evaluate the impact of individual genes. By calculating the Shapley values, the model can identify genes with high contributions, making it possible to pinpoint key genes involved in specific biological processes. This transparency is crucial for biological research, as it enables scientists to understand the underlying mechanisms driving the model's predictions.\n\nIn addition to SHAP, the model's architecture includes a simplified Transformer classification component. This component retains only the encoder part of the Transformer, reducing each sample's gene expression level to 72 dimensions. This dimensionality reduction helps preserve global expression information, making it easier to interpret the model's decisions. The use of an 8-layer stacked Attention head further enhances the model's ability to focus on relevant gene expressions, providing a more interpretable output.\n\nThe integration of SHAP and the Transformer architecture ensures that the TransGeneSelector model is not a black box. Instead, it offers a transparent and interpretable framework for gene selection and classification. This transparency is essential for validating the model's predictions and for gaining biological insights from the data.",
  "model/output": "The model described in this publication is primarily a classification model. It utilizes a Transformer network for biological process classification, distinguishing between different conditions such as germinating or dry seeds, and plants under heat stress versus normal conditions. The Transformer model is trained to classify these conditions based on gene expression data.\n\nThe output of the Transformer model is a probability value between 0 and 1, which can be thresholded to obtain high-quality generated samples. This probability value is used to assess the classification performance on validation set real samples.\n\nAdditionally, an additional classifier network with a fully connected neural network architecture is used to filter out fake samples and obtain high-quality samples. This classifier network outputs a probability value that indicates whether a sample is real or fake.\n\nThe model also employs the SHAP (SHapley Additive exPlanations) method to evaluate the influence of each gene on the trained Transformer classification model. This helps in identifying key genes that have the most significant impact on the classification outcomes.\n\nIn summary, the model is designed for classification tasks, specifically to classify biological processes based on gene expression data. The output of the model is a probability value that indicates the likelihood of a sample belonging to a particular class.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the TransGeneSelector model is not publicly released. The methodology and software were developed by K.H., who conceptualized the study, developed the software and methodology, conducted experiments, wrote the original draft, and reviewed and edited the manuscript. The Random Forest model parameters were optimized through a grid search on the training set, and both models were evaluated using a 5-fold cross-validation approach. However, specific details on how to run the algorithm or access the software are not provided. The study focuses on the performance and comparison of different models, including TransGeneSelector, Random Forest, SVM, KNN, and NR-LR-MCP, but does not include information on the public availability of the software or algorithms used.",
  "evaluation/method": "The evaluation of our models, specifically TransGeneSelector and Random Forest, was conducted using a 5-fold cross-validation approach. This method ensures that the models are robust and generalizable by training and validating them on different subsets of the data.\n\nFor TransGeneSelector, the training batch size for the Transformer architecture and the WGAN-GP component was set to 32. However, the additional classifier utilized a full batch size for training. This was due to the 1:1 ratio of real to generated samples, which kept the effective sample size relatively small. The performance of TransGeneSelector was assessed using several metrics, including accuracy, precision, recall rate, and F1 score. These metrics provide a comprehensive view of the model's performance across different aspects.\n\nIn contrast, the evaluation of the Random Forest model focused primarily on accuracy through cross-validation. Other metrics were omitted because the Random Forest often achieved a consistent accuracy of 1.0.\n\nAdditionally, we compared our models with other benchmark methods, including a previously proposed SNP mining method based on the Network-Regularized Logistic Regression model with Minimax Concave Penalty (NR-LR-MC), as well as classical machine learning algorithms like K-Nearest Neighbors (KNN) and Support Vector Machine (SVM). For these comparisons, we conducted a grid search on the training set to determine the optimal combination of hyperparameters. The features used by KNN and SVM were derived from the feature engineering process of the Random Forest model.\n\nThe test set data was used to evaluate the performance of all models by calculating accuracy, precision, recall, F1 score, and AUC value. These metrics allowed for a thorough comparison of the capabilities of different models.",
  "evaluation/measure": "In our evaluation, we reported a comprehensive set of performance metrics to thoroughly assess the capabilities of the models. These metrics include accuracy, precision, recall, F1 score, and the Area Under the Curve (AUC). Accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Precision indicates the proportion of true positive results among all positive results. Recall, also known as sensitivity, represents the proportion of true positive results among all actual positives. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns. AUC measures the probability that a randomly chosen positive instance is ranked higher than a randomly selected negative instance, offering a summary of the model's performance across all classification thresholds.\n\nThis set of metrics is widely recognized and used in the literature for evaluating machine learning models, particularly in classification tasks. It provides a holistic view of model performance, covering aspects such as the balance between precision and recall, the overall correctness of predictions, and the model's ability to distinguish between positive and negative classes. By including these metrics, we ensure that our evaluation is representative and comparable to other studies in the field.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of TransGeneSelector with several publicly available methods and simpler baselines to assess its performance comprehensively. We benchmarked TransGeneSelector against traditional machine learning algorithms, including Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and a Network-Regularized Logistic Regression model with Minimax Concave Penalty (NR-LR-MC). These models were chosen for their established performance in similar tasks and their widespread use in the field.\n\nFor the SVM and KNN algorithms, the features were derived from the feature engineering process of the Random Forest model, ensuring a fair comparison. The NR-LR-MC model was optimized using a grid search on the training set to determine the best combination of hyperparameters, including alpha, lambda1, lambda2, and learning rate. This optimization process ensured that the NR-LR-MC model was tuned to its highest potential performance.\n\nAdditionally, we compared TransGeneSelector with the Random Forest model, which is known for its robustness and feature selection capabilities. The Random Forest model parameters were optimized through a grid search, combining different values of n_estimators and n_features_to_select. The best parameter combination was chosen based on model accuracy, ensuring that the Random Forest model was also performing at its peak.\n\nThe performance of all models was evaluated using a 5-fold cross-validation approach. For TransGeneSelector, we assessed metrics including accuracy, precision, recall rate, and F1 score. In contrast, the Random Forest model was primarily evaluated on accuracy, as it often achieved consistent high accuracy. The evaluation metrics provided a comprehensive assessment of the capabilities of different models.\n\nFurthermore, we included unoptimized versions of TransGeneSelector and variations where components like the WGAN-GP network and Transformer network were replaced with simpler alternatives, such as the mixup method and Multilayer Perceptron (MLP). This comparison highlighted the importance of the specific design choices in TransGeneSelector, demonstrating that the WGAN-GP and Transformer modules are crucial for its superior performance.\n\nIn summary, our evaluation involved a rigorous comparison with publicly available methods and simpler baselines, ensuring that TransGeneSelector's performance was thoroughly benchmarked against established and optimized models. This comprehensive approach underscores the robustness and potential of TransGeneSelector in handling complex tasks for classifying physiological states of plants under varying environmental conditions.",
  "evaluation/confidence": "The evaluation of our models, including TransGeneSelector and Random Forest, was conducted using a 5-fold cross-validation approach, which provides a robust measure of model performance and generalizability. This method helps in assessing the stability and reliability of the models by ensuring that each fold of the data is used for both training and validation.\n\nFor the TransGeneSelector model, we evaluated performance using metrics such as accuracy, precision, recall rate, and F1 score. These metrics were chosen to provide a comprehensive assessment of the model's capabilities. The Random Forest model, on the other hand, was primarily evaluated based on accuracy, as it often achieved consistent high accuracy scores.\n\nIn addition to these metrics, we also calculated the Area Under the Curve (AUC) value for all models. The AUC provides a single scalar value that represents the probability that a randomly chosen positive instance is ranked higher than a randomly selected negative instance. This metric is particularly useful for evaluating the performance of models in classification tasks.\n\nTo ensure the statistical significance of our results, we compared the performance metrics of different models using appropriate statistical tests. For example, we used the Wilcoxon signed-rank test to compare the performance of TransGeneSelector with other traditional models such as SVM, KNN, and NR-LR-MC. This test is non-parametric and does not assume a normal distribution of the data, making it suitable for comparing paired samples.\n\nThe results of our evaluations showed that TransGeneSelector outperformed traditional models in most metrics, including accuracy, precision, F1 score, and AUC. For instance, the best-performing TransGeneSelector model achieved an accuracy of 0.9623, precision of 0.9643, F1 score of 0.9643, and AUC of 0.9871. In comparison, the best-performing SVM model, which was trained with 41 genes derived from feature engineering using the Random Forest model, achieved an accuracy of 0.9434, precision of 0.9032, F1 score of 0.9492, and AUC of 0.9743.\n\nThese results indicate that TransGeneSelector's performance is statistically significant and superior to that of traditional models. The use of 5-fold cross-validation, along with the calculation of confidence intervals for the performance metrics, provides a high level of confidence in the reported results. Furthermore, the statistical tests used to compare the models ensure that the observed differences in performance are not due to random chance.",
  "evaluation/availability": "The raw evaluation files utilized in this study were sourced from publicly available repositories. Specifically, the gene expression data were extracted from the NCBI GEO (Gene Expression Omnibus) database and the Expression Atlas database. The experiments GSE116069, GSE161704, GSE163057, GSE167244, GSE179008, GSE155710, GSE158444, GSE184983, GSE200247, GSE212019, GSE232094, GSE239833, and GSE244763 from NCBI were selected for the training and testing of the TransGeneSelector and Random Forest models. For additional MERLIN network analysis, experiments E-CURD-1, E-GEOD-30720, E-GEOD-52806, E-GEOD-64740, E-MTAB-4202, E-MTAB-7933, E-MTAB-7978 from Expression Atlas and GSE199116 from NCBI were included. These datasets are publicly accessible and can be found in the respective databases."
}