{
  "publication/title": "Significance of plasma p-tau217 in predicting long-term dementia risk in older community residents: insights from machine learning approaches",
  "publication/authors": "The authors who contributed to the article are Ding Ding and Yang Cao.\n\nDing Ding is one of the authors who contributed to the manuscript titled \"Significance of plasma p-tau217 in predicting long-term dementia risk in older community residents: insights from machine learning approaches\". Ding Ding has received funding from several entities, including the Shanghai Municipal Science and Technology Major Project, ZJ LAB, Shanghai Municipal Health Commission, National Natural Science Foundation of China, and the Key Project of the Ministry of Science and Technology, China. These funds were directed to the institution.\n\nYang Cao is another author who contributed to the same manuscript. Yang Cao has not reported any specific funding or support for the present manuscript, nor any grants, contracts, royalties, or licenses related to the content of the manuscript in the past 36 months.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2024",
  "publication/pmid": "39115912",
  "publication/pmcid": "PMC11485078",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Plasma p-tau217\n- Dementia risk\n- Long-term prediction\n- Older community residents\n- Machine learning\n- Alzheimer's disease\n- Biomarkers\n- Epidemiology\n- Geriatrics\n- Predictive modeling",
  "dataset/provenance": "The dataset used in this study is derived from the Shanghai Aging Study (SAS), a community-based cohort focused on dementia as its primary outcome. The study participants are older adults aged 50 years and above, residing in the central area of Shanghai, China. The SAS cohort includes a wide array of baseline data, meticulously collected to evaluate cognitive function and diagnose dementia according to clinical criteria. This dataset is rich and includes cutting-edge plasma biomarkers, which have been previously demonstrated to be associated with long-term cognitive decline and incident dementia.\n\nThe study considered 90 variables, categorized into nine groups, as candidate predictors to construct prediction models. These variables include demographic information, family background, lifestyle factors, anthropometry, biochemical tests, blood biomarkers, genetic data, medical history, and neuropsychological test results. The dataset includes participants who were successfully followed at least once during the study period, ensuring a robust and comprehensive analysis.\n\nThe SAS dataset has been utilized in previous research, including a study that demonstrated the association of higher concentrations of plasma p-tau217, p-tau181, and NfL with higher risks of long-term cognitive decline and incident dementia. This rich dataset has been leveraged to select key variables through a data-driven approach and to train and validate models for predicting incident dementia using machine learning algorithms. The study aims to identify individuals more likely to progress to dementia, facilitating the maximum impact of lifestyle modifications and medical treatments.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study is not publicly available. The study utilized baseline data collected in SAS, along with insights from various experts, to consider 90 variables across nine categories as candidate predictors. These variables were used to construct prediction models. The study was approved by the Medical Ethics Committee of Huashan Hospital, Fudan University, and all participants or their legal representatives provided written informed consent.\n\nThe specific data splits and the detailed dataset are not released in a public forum. The focus of the study was on the significance of plasma p-tau217 in predicting long-term dementia risk in older community residents using machine learning approaches. The dataset remains proprietary and is not subject to public access or distribution under any specific license.",
  "optimization/algorithm": "The machine-learning algorithms used in our study belong to the class of ensemble and probabilistic methods. Specifically, we employed Logistic Regression (LR), Naive Bayes (NB), Bagged Trees (BT), and Random Forest (RF). These algorithms are well-established in the field of machine learning and have been extensively used in various predictive modeling tasks.\n\nThe algorithms used are not new; they are widely recognized and have been applied in numerous studies across different domains. The choice of these algorithms was driven by their robustness and ability to handle complex and non-linear relationships in data. Naive Bayes is known for its simplicity and efficiency, particularly in handling small datasets and multiclass problems. Bagged Trees significantly reduce variance in predictions and combat overfitting, offering flexibility across different types of problems and efficiency through parallel processing. Random Forest excels in managing non-linear data, reducing overfitting, providing insights into feature importance, and handling unbalanced datasets effectively.\n\nThe reason these algorithms were not published in a machine-learning journal is that they are standard and well-documented in the literature. Our focus was on applying these established methods to a specific problem\u2014predicting incident dementia in older adults\u2014rather than developing new algorithms. The novelty of our work lies in the application of these algorithms to a unique dataset and the integration of plasma biomarkers, such as p-tau217, with age and cognitive tests to improve predictive performance. This approach demonstrates the practical utility of these algorithms in a real-world healthcare context.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for preparing the dataset for the machine-learning algorithms. Initially, missing values were addressed using multivariate imputation by chained equations (MICE), employing the random forest algorithm. This method ensured that the missing data were imputed based on the relationships between the variables, maintaining the integrity of the dataset.\n\nAfter imputation, all numerical variables were scaled to have a mean of 0 and a standard deviation of 1. This standardization process is essential for algorithms that are sensitive to the scale of the input features, ensuring that each feature contributes equally to the model's performance.\n\nThe dataset was then randomly split into two subsets: 80% for training and 20% for testing. This split allowed for the development and validation of the models, ensuring that the performance metrics were reliable and generalizable to new data. The training dataset was used to construct and optimize the models, while the testing dataset was used to evaluate their performance.",
  "optimization/parameters": "In our study, we initially considered a larger set of variables for model construction. However, to ensure simplicity and clinical practicability, we selected a final set of five key variables for constructing our prediction models. These variables are age, plasma p-tau217, Mini-Mental State Examination (MMSE) score, Auditory Verbal Learning Test (AVLT) long-term delayed recall, and Stick Test (STICK) recall. These variables were chosen because they reflect aging, Alzheimer's disease pathology, global cognition, verbal memory, and visual memory, all of which are significant contributors to dementia onset from a clinical perspective.\n\nThe selection of these variables was guided by a recursive feature elimination (RFE) analysis, which helped identify the most important predictors. The RFE analysis, along with the use of machine learning algorithms, allowed us to prioritize variables that demonstrated strong predictive power. Additionally, we considered the clinical relevance of each variable, ensuring that the final model would be practical for use in real-world settings.\n\nThe chosen variables were then used to construct and train four different machine learning models: logistic regression, naive Bayes, bagged trees, and random forest. These models were evaluated using area under the receiver operator characteristic curve (AUC) as the primary metric, along with sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). The models demonstrated good to excellent performance in both training and testing datasets, indicating the robustness of the selected variables.",
  "optimization/features": "In the optimization process of our study, we initially considered a wide range of candidate predictors. To enhance the predictive performance and simplicity of our models, we employed feature selection techniques. Specifically, we used recursive feature elimination (RFE) to identify the most relevant features for predicting dementia. This process was conducted using the training dataset only, ensuring that the feature selection was unbiased and did not leak information from the testing dataset.\n\nThe RFE analysis was applied to four different machine learning algorithms: logistic regression (LR), naive Bayes (NB), bagged trees (BT), and random forest (RF). Each algorithm identified a different number of optimal features. For instance, the LR model selected 12 features, the NB model chose 18, the BT model picked 21, and the RF model included 14 features.\n\nConsidering both clinical practicability and the top-selected variables by RFE, we prioritized a set of final variables for model construction. These final variables included age, plasma p-tau217, Mini-Mental State Examination (MMSE) score, long-term delayed recall subscore of the Auditory Verbal Learning Test (AVLT), and the recall subscore of the Stick Test (STICK). These features were selected because they reflect critical aspects such as aging, Alzheimer's disease pathology, global cognition, verbal memory, and visual memory, all of which are significant contributors to dementia onset from a clinical perspective.\n\nThus, the final models were constructed using these five key features, ensuring a balance between model performance and clinical applicability.",
  "optimization/fitting": "In our study, we employed several machine learning models, including logistic regression (LR), naive Bayes (NB), bagged trees (BT), and random forest (RF), to predict incident dementia. The number of parameters in these models was not excessively large compared to the number of training points, which helped mitigate the risk of overfitting.\n\nTo further ensure that our models did not overfit, we used repeated 10-fold cross-validation with five repetitions. This technique provided a robust estimate of model performance and helped in assessing the generalizability of the models to unseen data. Additionally, we validated our models on a separate testing dataset, which showed excellent performance with no signs of overfitting.\n\nTo address underfitting, we selected models that are known for their ability to capture complex relationships in the data. For instance, random forests and bagged trees are ensemble methods that can handle non-linear data and reduce overfitting by averaging multiple decision trees. Naive Bayes, while simpler, is effective in handling small datasets and multiclass problems. Logistic regression, though linear, was used in conjunction with other models to provide a baseline comparison.\n\nThe performance metrics, such as the area under the receiver operator characteristic curve (AUC), sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV), were evaluated to ensure that the models were neither underfitting nor overfitting. The models demonstrated high AUC values and moderate to high sensitivity and specificity, indicating a good balance between bias and variance.\n\nIn summary, the combination of cross-validation, separate testing datasets, and the choice of robust machine learning algorithms helped us to effectively rule out both overfitting and underfitting in our models.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. We utilized repeated 10-fold cross-validation with five repetitions to evaluate the performance of our models. This method helps to provide a more reliable estimate of model performance by averaging the results over multiple train-test splits.\n\nAdditionally, we compared the performance of our models in both training and testing datasets. The consistent performance across these datasets indicates that our models did not overfit to the training data. For instance, the logistic regression model achieved an AUC of 0.91 in both the training and testing datasets, demonstrating its generalizability.\n\nFurthermore, we conducted subgroup and sensitivity analyses to validate the models in different subsets of the data, including different sexes, age groups, and baseline diagnoses. This approach helps to assess the models' robustness and their ability to perform well across various conditions.\n\nWe also evaluated the importance of each variable using SHapley Additive exPlanations (SHAP) values, which provide a way to interpret the output of machine learning models. This helped us to understand the contribution of each feature to the model's predictions and to ensure that the models were not relying too heavily on any single feature.\n\nIn summary, our study employed cross-validation, performance comparison across datasets, subgroup and sensitivity analyses, and feature importance evaluation to prevent overfitting and ensure the reliability of our models.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models employed in this study, namely Logistic Regression (LR), Naive Bayes (NB), Bagged Trees (BT), and Random Forest (RF), vary in their interpretability. LR is generally considered more transparent, as it provides clear coefficients that indicate the direction and magnitude of the relationship between each predictor and the outcome. This allows for straightforward interpretation of how each variable contributes to the prediction of incident dementia.\n\nNB, while simple and efficient, can be less interpretable due to its probabilistic nature, making it somewhat of a grey box model. It provides insights into the likelihood of different classes based on the input features, but the relationships between features are not as explicitly defined as in LR.\n\nBT and RF, on the other hand, are more complex and are often considered black-box models. These ensemble methods aggregate the predictions of multiple decision trees, which can capture intricate patterns in the data but at the cost of interpretability. However, techniques like SHapley Additive exPlanations (SHAP) values were used to evaluate the importance of each variable in these models. SHAP values provide a way to understand the contribution of each feature to the model's predictions, making these models more interpretable. For instance, higher scores on cognitive tests like MMSE, STICK recall, and AVLT long-term delayed recall were associated with a lower incidence of dementia, while higher concentrations of plasma p-tau217 and older age were associated with a higher incidence. This approach helps in understanding the relative importance and impact of each feature in the prediction process.",
  "model/output": "The models constructed in this study are classification models. They are designed to predict the incidence of dementia, specifically distinguishing between individuals who will develop dementia and those who will not. The performance of these models is evaluated using metrics such as the area under the receiver operator characteristic curve (AUC), sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics are typical for classification tasks, where the goal is to classify outcomes into discrete categories, in this case, the presence or absence of incident dementia.\n\nThe models include logistic regression, naive Bayes, bagged trees, and random forest. Each of these algorithms is used to build a classifier that can predict the likelihood of an individual developing dementia based on a set of input variables. The variables used in the models include age, plasma p-tau217 levels, Mini-Mental State Examination (MMSE) scores, Auditory Verbal Learning Test (AVLT) long-term delayed recall, and Stick Test (STICK) recall. These variables are selected for their relevance to dementia prediction and their importance in the models, as indicated by SHAP values.\n\nThe performance of the models is assessed in both training and testing datasets. In the training dataset, the models show high AUC values, indicating good discriminative ability. Similarly, in the testing dataset, the models maintain high AUC values, demonstrating their generalizability and robustness. The models also exhibit moderate sensitivity and specificity, along with high negative predictive values and relatively low positive predictive values. This suggests that the models are effective in correctly identifying individuals who will not develop dementia but have some limitations in accurately predicting those who will.\n\nIn summary, the models are classification models aimed at predicting the incidence of dementia. They utilize a combination of demographic, cognitive, and biological markers to make predictions and demonstrate strong performance in both training and testing datasets.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the models involved several rigorous steps to ensure their robustness and generalizability. Initially, the models were constructed and trained using logistic regression (LR), naive Bayes (NB), bagged trees (BT), and random forest (RF) algorithms. The primary metric for evaluating model performance was the area under the receiver operating characteristic curve (AUC). Additionally, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) were reported.\n\nTo assess the models' performance, repeated 10-fold cross-validation with five repetitions was employed. This method helps in obtaining mean measures with 95% confidence intervals (CI), providing a comprehensive evaluation of the models' predictive accuracy. The SHapley Additive exPlanations (SHAP) value was used to evaluate the importance of each variable in the models, offering insights into which factors contributed most to the predictions.\n\nThe trained models were further validated on a separate testing dataset to ensure they did not overfit the training data. This step is crucial for confirming that the models can generalize well to new, unseen data.\n\nTo specifically validate the predictive value of plasma p-tau217, the Net Reclassification Improvement Index (NRI) and Integrated Discrimination Improvement Index (IDI) were used. These metrics assessed whether adding plasma p-tau217 to the models improved their performance.\n\nSubgroup and sensitivity analyses were conducted to test the models' robustness. These analyses involved validating the models in different subsets of the dataset, including different sexes, age groups, and baseline diagnoses. The models were also tested for their performance in predicting incident Alzheimer's disease (AD) and in participants with varying follow-up times. This comprehensive evaluation ensured that the models were reliable and applicable across diverse conditions.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our machine learning models in predicting incident dementia. The primary metric used was the Area Under the Receiver Operating Characteristic Curve (AUC), which provides a comprehensive measure of a model's ability to distinguish between positive and negative cases across all threshold levels.\n\nIn addition to AUC, we reported accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). These metrics offer a more detailed view of model performance. Accuracy indicates the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall, measures the proportion of actual positives that are correctly identified by the model. Specificity, on the other hand, measures the proportion of actual negatives that are correctly identified. PPV, or precision, represents the proportion of positive identifications that are actually correct, while NPV indicates the proportion of negative identifications that are actually correct.\n\nThe reported metrics are representative of standard practices in the literature for evaluating predictive models, particularly in the context of medical and biological research. These metrics collectively provide a robust assessment of model performance, ensuring that our findings are both reliable and comparable to other studies in the field. The use of these metrics allows for a thorough evaluation of the models' predictive capabilities, sensitivity, and specificity, which are crucial for their potential application in clinical settings.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. However, we did compare the performance of our models with simpler baselines. Specifically, we constructed and evaluated four different machine learning models: logistic regression (LR), naive Bayes (NB), bagged trees (BT), and random forest (RF). These models were chosen for their varying complexities and strengths. Logistic regression served as a simpler baseline model, providing a straightforward approach to classification. Naive Bayes, known for its simplicity and efficiency, especially with small datasets, offered another baseline comparison. Bagged trees and random forest, being more complex models, provided insights into how advanced machine learning techniques could improve predictive performance. We assessed the performance of these models using metrics such as the area under the receiver operator characteristic curve (AUC), accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). This comparison allowed us to evaluate the trade-offs between model complexity and predictive accuracy, ensuring that our chosen models were robust and reliable for predicting incident dementia.",
  "evaluation/confidence": "The evaluation of our models included several performance metrics, each accompanied by confidence intervals to provide a range of likely values for the true performance. These metrics included the area under the receiver operator characteristic curve (AUC), accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). The confidence intervals were calculated using repeated 10-fold cross-validation with five repetitions, ensuring a robust estimation of model performance.\n\nStatistical significance was assessed to determine if the inclusion of plasma p-tau217 improved model performance. The Integrated Discrimination Improvement Index (IDI) was used for this purpose. The results indicated significant improvements in the logistic regression, naive Bayes, and random forest models when p-tau217 was added, with p-values of 0.033, 0.040, and less than 0.001, respectively. However, the bagged trees model did not show a significant improvement with the addition of p-tau217, having a p-value of 0.125.\n\nIn the testing dataset, the models demonstrated excellent performance with high AUC values and moderate to high sensitivity and specificity. The negative predictive values were also high, indicating the models' effectiveness in correctly identifying individuals who would not develop dementia. However, the positive predictive values were relatively low, suggesting that while the models are good at ruling out dementia, they are less reliable in confirming it.\n\nOverall, the performance metrics and statistical analyses provide strong evidence of the models' effectiveness and the importance of including plasma p-tau217 in the predictive models. The results are statistically significant and robust, supporting the claim that these models are superior in predicting incident dementia among community older adults.",
  "evaluation/availability": "Not enough information is available."
}