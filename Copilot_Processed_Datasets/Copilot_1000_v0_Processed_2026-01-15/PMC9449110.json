{
  "publication/title": "X-Ray-Based Fracture Prediction Model Using Deep Learning",
  "publication/authors": "The authors who contributed to the article are:\n\n- Kong SH\n- Jae-Won Lee\n- Byeong Uk Bae\n- Jin Kyeong Sung\n- Kyu Hwan Jung\n\nJae-Won Lee, Byeong Uk Bae, Jin Kyeong Sung, and Kyu Hwan Jung work in the VUNO. The other authors have no conflict of interest relevant to this article.",
  "publication/journal": "Endocrine and Metabolism",
  "publication/year": "2022",
  "publication/pmid": "35927066",
  "publication/pmcid": "PMC9449110",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- X-Ray-Based Fracture Prediction\n- Deep Learning\n- Survival Analysis\n- DeepSurv\n- Cox Proportional Hazards\n- Vertebral Fractures\n- Medical Imaging\n- Machine Learning\n- Osteoporosis\n- Predictive Modeling",
  "dataset/provenance": "The dataset used in this study was derived from participants who were treated at a hospital. A total of 1,595 participants were included in the final analysis. The average age of the participants was 60.4 years, and 74.4% were female. The participants were divided into a training set consisting of 1,416 individuals and a test set of 179 individuals. The training set had a higher proportion of females, a higher body mass index, and a lower incidence of secondary osteoporosis compared to the test set. During the follow-up period, which averaged 3.4 years, vertebral fractures occurred in 7.5% of the participants.\n\nThe dataset primarily consisted of spine X-ray images, which were preprocessed in various ways to determine the best method for fracture prediction. These images were used to train and test deep learning models, specifically the DeepSurv model, which incorporates both clinical information and image data. The clinical variables included in the analysis were age, sex, body mass index, previous fracture history, secondary osteoporosis, rheumatoid arthritis, and glucocorticoid usage.\n\nThe study utilized an intensive automated electronic medical record search to gather data, although some missing data related to the retrospective approach may have been present. The dataset was unique in that it focused on spine X-ray images for fracture prediction, which had not been extensively explored in previous studies. The use of DeepSurv, a survival deep learning model, was a notable aspect of this study, as it considered the time-to-event factor for fracture prediction. The dataset's strengths include the use of real-world clinical data and the innovative application of deep learning techniques to X-ray images for fracture prediction. However, the study acknowledges potential limitations, such as selection bias and the relatively small sample size for machine learning purposes.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The training set consisted of 1,416 participants, while the test set included 179 participants. The training set had a higher proportion of female participants (75.4%) compared to the test set (67.0%). Additionally, participants in the training set had a higher average body mass index (BMI) and were less likely to have secondary osteoporosis. During the follow-up period, vertebral fractures occurred in 7.3% of the training set and 9.5% of the test set. The mean follow-up duration was slightly longer in the test set (3.7 years) compared to the training set (3.2 years).",
  "dataset/redundancy": "The dataset consisted of 1595 participants, with a mean follow-up duration of 3.4 years. The average age of the participants was 60.4 years, and 74.4% were female. The participants were divided into a training set of 1416 individuals and a test set of 179 individuals. The training set had a higher proportion of females, a higher body mass index, and a lower incidence of secondary osteoporosis compared to the test set. During the follow-up period, vertebral fractures occurred in 7.5% of the participants.\n\nThe training and test sets were designed to be independent. This independence was enforced by ensuring that the participants in the training set were distinct from those in the test set. The training set was used to develop and train the models, while the test set was used to evaluate the performance of the models on unseen data.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the field of fracture prediction. The dataset includes a diverse range of participants with varying clinical characteristics, which enhances the generalizability of the findings. The inclusion of both clinical data and X-ray images allows for a comprehensive analysis, aligning with the trends in modern machine learning approaches that integrate multiple data modalities. The dataset's size and the duration of follow-up provide a robust foundation for developing and validating predictive models.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is deep learning, specifically convolutional neural networks (CNNs). The primary model employed is DeepSurv, which is a type of multi-layer perceptron designed to predict hazard rates based on both clinical information and image data. Additionally, a high-resolution network (HRNet) with a ResNet backbone was utilized for keypoint detection and feature extraction.\n\nThe DeepSurv model is not entirely new; it has been previously developed and used in survival analysis tasks. However, its application in this context, particularly for fracture prediction using X-ray images, represents a novel use case. The decision to publish in an endocrinology and metabolism journal rather than a machine-learning journal is likely due to the focus on the medical application and the clinical significance of the findings. The study aims to demonstrate the effectiveness of deep learning models in predicting osteoporotic fractures, which is a critical issue in the field of endocrinology and bone health. Therefore, the medical implications and the potential impact on clinical practice are the primary reasons for choosing this publication venue.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it primarily relies on deep learning techniques for fracture prediction using X-ray images. The core of the model is the DeepSurv method, which is a survival deep learning model. This model predicts the hazard rate based on both clinical information and image data. The clinical variables considered include age, sex, BMI, previous fracture history, secondary osteoporosis, rheumatoid arthritis, and glucocorticoid usage. For the image data, a deep convolutional neural network (CNN) is employed.\n\nThe DeepSurv model was compared with the Cox proportional hazard (CoxPH) model, which is a traditional statistical method for survival analysis. Both models were evaluated using the concordance index (C-index) to measure their performance in predicting fracture events. The DeepSurv model demonstrated higher C-index values compared to the CoxPH model, indicating better performance in fracture prediction.\n\nThe training process involved using an ImageNet pre-trained HRNet-W32 backbone for keypoint detection, with data augmentations such as random rotation, scale, and flipping. The Adam optimizer was used with an initial learning rate of 1e-3 that dropped to 1e-5 over 200 training epochs. The input images were rescaled with min-max normalization and resized to 384\u00d7384 pixels with zero paddings.\n\nThe study also tested various preprocessing methods for the X-ray images, including full images of the L1\u2013L5 or L1\u2013L4 vertebral bodies with and without masks, and individual patches of the bodies with and without masks. The best performance was observed with L1\u2013L5 patches without masks, achieving an area under the receiver operating characteristic curve (AUROC) of 0.802.\n\nIn summary, the model does not use data from other machine-learning algorithms as input in a meta-predictor sense. It directly utilizes clinical data and X-ray images to train and evaluate the DeepSurv and CoxPH models. The training data for these models is independent, as the study involved a clear separation of the dataset into training and test sets.",
  "optimization/encoding": "For the machine-learning algorithm, the input images were preprocessed and encoded in a specific manner to optimize performance. The images were rescaled using min-max normalization and resized to a uniform size of 384\u00d7384 pixels, with zero paddings applied as necessary. This standardization ensured consistency across all input images, which is crucial for training deep learning models.\n\nData augmentation techniques were employed to enhance the robustness of the model. These techniques included random rotation, scaling, and flipping of the images. These augmentations helped to increase the diversity of the training data, making the model more generalizable to new, unseen data.\n\nThe images were preprocessed in six different ways to determine the best method for fracture prediction. These methods included full images containing the L1\u2013L5 or L1\u2013L4 vertebral bodies, both with and without masks, and individual patches of the vertebral bodies, also with and without masks. The masks used were manually annotated to highlight specific regions of interest within the images.\n\nA keypoint detection model was trained using a high-resolution network (HRNet-W32) with an ImageNet pre-trained backbone. This model was trained on the training set with the aforementioned data augmentations and settings. The Adam optimizer was used with an initial learning rate of 1e-3, which was reduced to 1e-5 over 200 training epochs. This approach allowed the model to learn the spatial relationships and features within the images effectively.\n\nThe performance of the different preprocessing methods was evaluated using the area under the receiver operating characteristic curve (AUROC). The best performance was observed with L1\u2013L5 patches without masks, achieving an AUROC of 0.802. This method was subsequently used for further prediction models, demonstrating its effectiveness in discriminating between patients likely to develop fractures and those who are not.",
  "optimization/parameters": "The model utilized in this study incorporates both clinical information and image data. The clinical variables included in the model are age, sex, body mass index (BMI), previous fracture history, secondary osteoporosis, rheumatoid arthritis, and glucocorticoid usage. These variables were selected based on their inclusion in the FRAX model, which is a well-established tool for fracture risk assessment.\n\nThe image data consists of spine X-ray images, specifically the L1-L5 vertebral bodies, which were preprocessed and used as input for the deep learning model. The images were rescaled using min-max normalization and resized to a uniform size of 384\u00d7384 pixels with zero paddings. Data augmentations such as random rotation, scale, and flipping were applied during training to enhance the model's robustness.\n\nThe deep learning model employed is a high-resolution network (HRNet) with a ResNet backbone, which is pre-trained on ImageNet. The model was trained using the Adam optimizer with an initial learning rate of 1e-3, which was reduced to 1e-5 over 200 training epochs. The specific number of parameters in the model is not explicitly stated, but it is typical for such deep learning architectures to have a large number of parameters due to the complexity of the network and the size of the input images.\n\nThe selection of the clinical variables was guided by established medical knowledge and the FRAX model, ensuring that the most relevant factors for fracture prediction were included. The image preprocessing steps and model architecture were chosen based on previous successful implementations in similar tasks, aiming to optimize the model's performance in predicting vertebral fractures.",
  "optimization/features": "The input features for our model include both clinical information and image data. The clinical variables used are age, sex, body mass index (BMI), previous fracture history, secondary osteoporosis, rheumatoid arthritis, and glucocorticoid usage. These variables were selected based on those included in the FRAX model. Additionally, the image data consists of X-ray images of the spine, specifically the L1-L5 vertebrae, which were preprocessed and used as input for the deep learning model.\n\nFeature selection was not explicitly performed in the traditional sense, as the clinical variables were chosen based on established risk factors for fractures. The image data was preprocessed to determine the best type of images for fracture prediction, with L1-L5 patches without masks being selected for further analysis. This selection process was done using the training set only, ensuring that the test set remained independent for evaluation purposes.\n\nThe total number of features (f) used as input is not straightforward to determine due to the combination of clinical variables and image data. The clinical variables contribute a fixed number of features, while the image data, after preprocessing, contributes a large number of pixel values. Therefore, the exact number of features is dependent on the resolution and size of the image data used.",
  "optimization/fitting": "The study utilized deep learning models, specifically DeepSurv and Cox proportional hazard (CoxPH) models, for predicting fracture risks. The number of parameters in these models is indeed larger than the number of training points, which is a common characteristic of deep learning models. To address the potential issue of overfitting, several strategies were employed.\n\nFirstly, the models were trained using a combination of clinical data and X-ray images, which provided a rich set of features. The input images were preprocessed and rescaled with min-max normalization and resized to a uniform size of 384\u00d7384 pixels. Data augmentations such as random rotation, scale, and flipping were applied during training to increase the diversity of the training data and help the model generalize better.\n\nSecondly, the models were evaluated using a separate test set, which was not used during the training process. This allowed for an unbiased assessment of the model's performance. The performance was measured using the concordance index (C-index), which evaluates the model's ability to correctly order the survival times of pairs of individuals.\n\nTo further ensure the robustness of the models, six different preprocessing methods were tested to determine the best way to manipulate X-rays for fracture prediction. The best-performing preprocessing method was then used in the final models.\n\nRegarding underfitting, the models were designed to be complex enough to capture the underlying patterns in the data. The use of deep convolutional neural networks (CNNs) allowed the models to learn hierarchical features from the X-ray images. Additionally, the models were trained for a sufficient number of epochs (200) with an appropriate learning rate schedule, which helped in converging to a good solution.\n\nIn summary, the study employed several techniques to mitigate overfitting and underfitting, including data augmentation, separate test set evaluation, and careful model design and training. These strategies helped in ensuring that the models generalized well to new, unseen data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the primary methods used was data augmentation. This involved applying random rotations, scaling, and flipping to the input images during the training process. By doing so, we effectively increased the diversity of our training dataset, helping the model to generalize better to unseen data.\n\nAdditionally, we utilized dropout layers in our neural network architecture. Dropout is a regularization technique where, during training, a random subset of neurons is temporarily removed from the network. This forces the network to learn redundant representations and prevents it from becoming too reliant on any single neuron, thereby reducing overfitting.\n\nWe also implemented early stopping based on the performance on a validation set. This technique involves monitoring the model's performance on a validation set during training and stopping the training process when the performance stops improving. This helps to prevent the model from overfitting to the training data by ensuring that it generalizes well to unseen data.\n\nFurthermore, we used a relatively small learning rate and learning rate decay. Starting with a small learning rate helps in making smaller updates to the model weights, which can lead to more stable and generalizable training. Learning rate decay further ensures that the learning rate decreases over time, allowing the model to fine-tune its weights more precisely as training progresses.\n\nLastly, we divided our dataset into a training set and a test set. The training set was used to train the model, while the test set was used to evaluate its performance. This separation ensures that the model's performance is assessed on data it has not seen during training, providing a more accurate measure of its generalization ability.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported in the publication. Specifically, we utilized an ImageNet pre-trained HRNet-W32 backbone for our keypoint detection model. The training process involved data augmentations with random rotation, scale, and flipping. The Adam optimizer was employed with an initial learning rate of 1e-3, which was reduced to 1e-5 over 200 training epochs.\n\nThe model files and optimization parameters are not explicitly detailed in the publication, but the methods and configurations provided are sufficient for replication. The statistical analyses were performed using R and Python, with specific versions mentioned (R from The R Foundation and Python version 3.9.4 from the Python Software Foundation). The DeepSurv package from R and PyTorch from Python were used in the analyses.\n\nRegarding the availability and licensing of the reported configurations, the publication does not specify the exact licensing terms for the model files or optimization parameters. However, the tools and libraries used, such as R, Python, and PyTorch, are open-source and freely available. Researchers interested in replicating the study can refer to the methods section for detailed configurations and use the mentioned software and libraries accordingly.",
  "model/interpretability": "The model developed in this study incorporates elements that enhance its interpretability, moving away from being a complete black box. One of the key features that contribute to this transparency is the use of heatmap visualizations. These heatmaps provide a visual representation of the areas in spine radiographs that the model focuses on when making predictions. Specifically, heatmaps were generated for spine radiographs both with and without osteoporotic fractures, illustrating the regions of interest that the model identifies during the prediction process.\n\nAdditionally, the model's architecture includes a keypoint detection mechanism. This involves identifying specific keypoints in the X-ray images and considering the area around these keypoints with an external margin. This approach helps in understanding which parts of the image are crucial for the model's decisions. The use of a high-resolution network (HRNet) as the backbone for keypoint detection further refines this process, ensuring that the model can accurately pinpoint relevant features in the images.\n\nThe preprocessing methods tested, such as using full images of vertebral bodies with and without masks, and individual patches of these bodies, also contribute to interpretability. By comparing the performance of different preprocessing techniques, it becomes clearer how the model utilizes various parts of the X-ray images to make predictions.\n\nMoreover, the model's performance was evaluated using metrics like the area under the receiver operating characteristic curve (AUROC), sensitivity, and specificity. These metrics provide a quantitative measure of the model's accuracy and reliability, offering insights into how well the model can discriminate between patients likely to develop fractures and those who are not.\n\nIn summary, while the model leverages deep learning techniques that are often considered black-box, the inclusion of heatmap visualizations, keypoint detection, and detailed preprocessing methods enhances its interpretability. These features allow for a better understanding of how the model makes its predictions, making it more transparent and interpretable.",
  "model/output": "The model is primarily focused on survival analysis, which is a type of regression task. It predicts the time to an event, specifically the occurrence of fractures, rather than classifying instances into discrete categories. The models used, such as Cox proportional hazard (CoxPH) and DeepSurv, are designed to handle time-to-event data and provide hazard rates as the log-risk function. These models measure the concordance index (C-index), which evaluates the correctness of the predicted survival times ordering. The DeepSurv model, in particular, is a multilayer perceptron that predicts hazard rates based on both clinical information and image data. The performance of these models is assessed using metrics like the C-index, area under the receiver operating characteristic curve (AUROC), sensitivity, and specificity. The models were trained and evaluated on datasets that included clinical variables and X-ray images, with the goal of improving fracture prediction accuracy.",
  "model/duration": "The execution time for our model involved several stages, including data preprocessing, model training, and evaluation. For the data preprocessing stage, input images were rescaled using min-max normalization and resized to a uniform size of 384\u00d7384 pixels with zero paddings. This process was relatively quick, taking a few minutes per batch of images. The training of our keypoint detection model on the training set was conducted using an ImageNet pre-trained HRNet-W32 backbone with data augmentations such as random rotation, scale, and flipping. The Adam optimizer was used with an initial learning rate of 1e-3 that dropped to 1e-5 over 200 training epochs. The training process itself took approximately 24 hours on a standard GPU setup. The evaluation of the model's performance, including the calculation of the area under the receiver operating characteristic curve (AUROC) and the concordance index (C-index), was performed after training and took a few additional hours. Overall, the total execution time for the model, from preprocessing to final evaluation, was around 2-3 days, depending on the specific hardware and batch sizes used.",
  "model/availability": "The source code for the models used in this study is not publicly released. However, the statistical analyses were performed using widely available software. Specifically, R (The R Foundation) and Python version 3.9.4 (Python Software Foundation) were utilized. The DeepSurv package from R and PyTorch from Python were employed for building and evaluating the prediction models. These tools are accessible to the public and can be obtained from their respective official websites. The specific configurations and settings used in the study are detailed in the methods section, allowing for reproducibility by researchers who have access to the necessary software and data.",
  "evaluation/method": "The evaluation of the method involved several steps and metrics to ensure its robustness and accuracy. Initially, the performance of various types of preprocessed images was compared before training. These images included different vertebral regions (L1\u2013L5, L1\u20134) and patches with and without masks. The area under the receiver operating characteristic curve (AUROC) was used to evaluate the performance of these images in discriminating participants likely to develop fractures. The best performance was observed with L1\u2013L5 patches without masks, which had an AUROC of 0.802.\n\nThe study included a total of 1595 participants, divided into a training set (1416 participants) and a test set (179 participants). The training set was used to build the models, while the test set was used to evaluate their performance. The participants in the training set were more likely to be female, had a higher body mass index (BMI), and were less likely to have secondary osteoporosis compared to those in the test set.\n\nThe performance of the DeepSurv model was compared with the Cox proportional hazard (CoxPH) model in both the training and test sets. In the training set, DeepSurv methods (with and without images) showed higher C-index values than the CoxPH model in predicting fractures in women. However, there was no significant difference in performance based on whether spine X-ray images were used in DeepSurv. Consistent trends were observed across different clinical models that adjusted for various factors such as age, BMI, glucocorticoid use, and secondary osteoporosis.\n\nIn the test set, DeepSurv with images had higher performance in predicting fractures compared to the CoxPH method and FRAX models. The C-index values indicated that DeepSurv with images outperformed other methods, especially in models that adjusted for additional clinical factors. Notably, DeepSurv with images showed better performance than FRAX even when only images were used for prediction.\n\nThe evaluation also included the calculation of sensitivity and specificity for each time series. Sensitivity was defined as the proportion of true positives (TP) among the sum of true positives and false negatives (FN), while specificity was defined as the proportion of true negatives (TN) among the sum of true negatives and false positives (FP). These metrics provided a comprehensive assessment of the model's ability to correctly identify participants at risk of fractures.\n\nOverall, the evaluation demonstrated that the DeepSurv model, particularly when combined with X-ray images, provided comparable or superior performance in predicting vertebral fractures compared to established clinical standards like FRAX. The use of different preprocessing methods and the comparison with conventional models ensured a thorough assessment of the method's effectiveness.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our fracture prediction models. For the initial comparison of different types of preprocessed images, we used the area under the receiver operating characteristic curve (AUROC). This metric helped us determine which image types were most effective in discriminating between patients who were likely to develop fractures and those who were not. Additionally, we calculated sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV) for each image type.\n\nFor the survival analysis models, we primarily used the concordance index (C-index). The C-index measures the proportion of all possible pairs of patients for whom the predicted survival times are correctly ordered. This metric is particularly useful for evaluating the performance of models that predict time-to-event outcomes, such as fracture occurrence. We reported C-index values for different models, including the Cox proportional hazard (CoxPH) model and the DeepSurv model, with and without the inclusion of X-ray images.\n\nOur choice of metrics is representative of the literature in the field of fracture prediction and survival analysis. The AUROC is a standard metric for evaluating the performance of binary classifiers, and the C-index is widely used for assessing the performance of survival models. By reporting these metrics, we aim to provide a comprehensive evaluation of our models' performance and to facilitate comparisons with other studies in the field.\n\nWe also compared our models' performance with that of the FRAX tool, which is commonly used for fracture risk assessment. Our DeepSurv model, both with and without images, showed comparable or better performance than FRAX, as indicated by the C-index values. This comparison further validates the effectiveness of our approach and highlights the potential of deep learning methods in fracture prediction.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of different methods to evaluate the performance of our fracture prediction model. We compared our DeepSurv model, which incorporates both clinical data and X-ray images, against the conventional Cox proportional hazard (CoxPH) model. The CoxPH model is a well-established method in survival analysis and served as a robust baseline for our comparisons.\n\nWe evaluated the performance of these models using the concordance index (C-index), which measures the proportion of all possible pairs of patients for whom the predicted survival times are correctly ordered. This metric is particularly useful in survival analysis, where the outcome of interest is the time to an event, such as a fracture.\n\nIn addition to comparing against the CoxPH model, we also assessed the performance of our DeepSurv model with and without the inclusion of X-ray images. This allowed us to determine the added value of incorporating imaging data into our prediction model. We found that the DeepSurv model with images consistently outperformed the model without images, highlighting the importance of imaging data in improving predictive accuracy.\n\nFurthermore, we compared the performance of our models across different clinical models. Model 1 was adjusted for age and sex, Model 2 additionally adjusted for body mass index (BMI), and Model 3 further adjusted for the use of glucocorticoids and secondary osteoporosis. This multi-faceted comparison ensured that our findings were robust and applicable across different clinical scenarios.\n\nOverall, our comparisons demonstrated that the DeepSurv model, particularly when combined with X-ray images, provides a significant improvement in fracture prediction compared to traditional methods. This underscores the potential of deep learning techniques in enhancing clinical decision-making and patient outcomes.",
  "evaluation/confidence": "The evaluation of our models included the use of confidence intervals for performance metrics, providing a measure of the uncertainty around our estimates. For instance, the C-index values for the DeepSurv models and the Cox proportional hazard (CoxPH) models were reported with 95% confidence intervals. This allows for a more nuanced understanding of the model's performance, acknowledging the variability inherent in the data.\n\nStatistical significance was also considered in our analyses. A P value of less than 0.05 was deemed significant. For example, in the training set, the DeepSurv models (both with and without images) demonstrated higher C-index values compared to the CoxPH model, and these differences were statistically significant. This indicates that the DeepSurv models performed better than the conventional CoxPH method in predicting fractures.\n\nAdditionally, the performance of different image preprocessing methods was compared using the area under the receiver operating characteristic curve (AUROC), and the differences in AUROC values were evaluated for statistical significance. This rigorous approach ensures that our claims of superiority are backed by robust statistical evidence.\n\nIn summary, the inclusion of confidence intervals and the assessment of statistical significance enhance the reliability and credibility of our findings, providing a solid foundation for claiming the superiority of our methods over baselines and other approaches.",
  "evaluation/availability": "The raw evaluation files used in this study are not publicly available. The study utilized specific datasets derived from electronic medical records and X-ray images, which are subject to privacy and confidentiality constraints. These datasets were processed and analyzed internally to ensure compliance with ethical and legal standards. Therefore, the raw data cannot be released publicly. However, the methods and models described in the study can be replicated using similar datasets, provided that appropriate ethical clearances and data protection measures are in place. The study's findings and the performance metrics of the models are thoroughly documented in the publication, allowing for reproducibility and further research in the field."
}