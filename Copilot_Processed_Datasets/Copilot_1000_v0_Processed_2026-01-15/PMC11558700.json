{
  "publication/title": "Neuroprognostic Models for Predicting Behavioral Development in Cochlear Implant Recipients Using Cortical Responses",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Laryngoscope Investigative Otolaryngology",
  "publication/year": "2024",
  "publication/pmid": "39539355",
  "publication/pmcid": "PMC11558700",
  "publication/doi": "10.1002/lio2.70035",
  "publication/tags": "- Machine Learning\n- Neuroimaging\n- Cochlear Implants\n- Behavioral Development\n- fNIRS\n- Auditory Cortex\n- Support Vector Machines\n- Pediatric Rehabilitation\n- Neuroprognostic Models\n- Clinical Outcomes",
  "dataset/provenance": "The dataset used in this study was sourced from a cohort of cochlear implant (CI) children who underwent functional evaluations at the auditory cognitive neuroscience laboratory of Beijing Normal University. The cohort consists of 47 CI children, with 18 females, and an average age of 35.47 months at the time of the first test. Each child completed at least two tests after cochlear implantation, with valid functional near-infrared spectroscopy (fNIRS) measurements and CI outcome assessments. The first test was conducted shortly after CI activation, with an average of 0.26 months of CI experience, while the last test occurred after an average of 12.11 months of CI experience. The time gap between the first and last tests was approximately 11.85 months.\n\nThe data collected includes auditory cortical functions assessed using fNIRS neuroimaging while the children listened passively to different sound conditions. These sound conditions included natural speech, babble noise, speech-in-noise, and instrumental music. The fNIRS recordings were obtained using a 20-channel elastic cap, providing measurements from auditory and language-related areas in both hemispheres. Additionally, auditory and speech performance were evaluated using three questionnaires completed by caretakers: the Infant-Toddler Meaningful Auditory Integration Scale (IT-MAIS), Categories of Auditory Performance (CAP), and Speech Intelligibility Rating (SIR). These questionnaires were rescaled and summed to provide a unified measure of the participants' auditory and speech abilities.\n\nThis dataset has not been previously used in other published papers or by the community, as it is part of an ongoing prospective cohort study approved by the Ethical Committee of Peking University and the Peking University First Hospital. The study aims to explore the neuro-behavioral relationship in young CI children and develop an objective measure and predictor of CI outcomes using machine learning algorithms.",
  "dataset/splits": "The dataset involved 47 children who were cochlear implant recipients. The data was split into training and testing groups for each fold of cross-validation. Specifically, the 10-fold cross-validation method was employed, where the data was randomly divided into training (90%) and testing (10%) groups for each fold. This process was repeated 10,000 times to yield a statistical distribution of classification performance. Therefore, there were 10,000 data splits, each with approximately 42 data points in the training set and 5 data points in the testing set. The distribution of data points in each split was consistent across all folds, maintaining the 90-10 split ratio.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not applicable",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Support Vector Machines (SVM). Specifically, we employed the Support Vector Machine-Recursive Feature Elimination (SVM-RFE) algorithm for feature ranking and selection, and the linear Support Vector Classifier (SVC) and Support Vector Regressor (SVR) for classification and regression tasks, respectively.\n\nThe algorithms used are not new; they are well-established methods in the field of machine learning. The SVM-RFE algorithm is commonly used for feature selection, while the SVC and SVR are widely applied for classification and regression tasks. These algorithms were chosen for their effectiveness in handling high-dimensional data and their ability to provide robust performance in predictive modeling.\n\nThe focus of our study is on the application of these machine-learning algorithms to neuroimaging data for predicting behavioral development in cochlear implant (CI) children. The algorithms were applied within the context of a longitudinal functional near-infrared spectroscopy (fNIRS) cohort study, aiming to develop neuroprognostic models for clinical and rehabilitative practice. The choice of algorithms was driven by their suitability for the specific data and research questions at hand, rather than the novelty of the algorithms themselves.",
  "optimization/meta": "The machine learning models employed in this study do not function as meta-predictors. Instead, they rely on direct measurements of auditory cortical responses and clinical parameters to predict behavioral development in cochlear implant (CI) children. The models utilize support vector machine-recursive feature elimination (SVM-RFE) for feature selection and linear support vector classifiers (SVC) or regressors (SVR) for prediction tasks.\n\nThe models were trained and validated using a dataset of recently implanted CI children from the same hospital. The feature selection process was conducted based on all participants, which could potentially lead to overfitting. To mitigate this, future work could involve increasing the sample size and applying more rigorous validation algorithms, such as nested cross-validation.\n\nThe models demonstrate high accuracy in predicting behavioral development, outperforming the predictability of demographic and audiological factors alone. However, the generalization ability of these models needs to be tested using separate, independently collected datasets to ensure the independence of training data. This step is crucial for validating the models' robustness and reliability in clinical and rehabilitative settings.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps. Initially, the clinical and cortical function data for each participant were converted into an S-by-V matrix, where S represents the number of children and V represents the number of features. This matrix was then normalized to ensure that the mean was 0 and the standard deviation was 1.\n\nFor the machine learning analysis, features were ranked in descending order of importance using the support vector machine-recursive feature elimination (SVM-RFE) algorithm. The optimal feature subset was determined by comparing the average classification accuracy of SVM classifiers through a detailed analysis between different numbers of SVM-RFE top-ranked features, with stepwise iteration of adding one feature at each time.\n\nThe cortical responses at the first test and clinical features were used to predict behavioral improvement. The clinical features included duration of cochlear implant experiences at the first test, side of implantation, age of implantation, residual hearing on the cochlear implant side and non-cochlear implant side, duration of hearing aid experiences, and gender.\n\nThe oxy-hemoglobin (HbO) signal was focused on, as it is known to be more strongly correlated with cognitive activity and more sensitive to regional cerebral blood flow changes. Mean HbO amplitude for each recording channel and sound condition was entered as cortical features in the machine learning analyses.\n\nAuditory and speech performance of the cochlear implant children was assessed using three questionnaires with caretakers: the Infant-Toddler Meaningful Auditory Integration Scale (IT-MAIS/MAIS), the Categories of Auditory Performance (CAP), and the Speech Intelligibility Rating (SIR). Scores from these questionnaires were rescaled to 0\u2013100 and then summed up using the recommended weights for cochlear implant children. The scores of all assessments were converted to a 0\u20136 scale.\n\nThe behavioral development was measured using the difference in the unified measure derived from the three clinical questionnaires between the first and last tests, divided by the lapse of time. This approach was taken because the time gap between the two tests was significantly correlated with behavioral difference.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the combination of sound conditions and the specific analysis being conducted. Initially, we considered cortical responses from 20 channels over auditory and speech-related cortical areas to four sound conditions for each child. These conditions included natural speech (S), babble noise (N), speech in noise (SiN), and instrumental music (M).\n\nTo determine the optimal subset of features, we employed the support vector machine-recursive feature elimination (SVM-RFE) algorithm. This algorithm ranked features in descending order of importance. For classification tasks, the optimal feature subset was identified by comparing the average classification accuracy of SVM classifiers across different numbers of top-ranked features, with stepwise iteration of adding one feature at a time. This process ensured that we selected the most relevant features for predicting behavioral development.\n\nFor regression analyses, the optimal feature subset was selected by comparing the mean square error (MSE) of SVM regressors between different numbers of top-ranked features using a leave-one-out cross-validation (LOOCV) strategy. Again, this was done iteratively by adding one feature at a time.\n\nIn practice, the highest classification accuracy was achieved with 25 channels selected by the SVM-RFE algorithm. This subset of features was used in the final models to predict behavioral development with high precision and sensitivity. The specific combinations of sound conditions that yielded the highest accuracies included S + N + M, S + N + SiN + M, N + SiN + M, and S + N + SiN. These combinations demonstrated that using multiple conditions generally outperformed single conditions, highlighting the importance of considering diverse auditory stimuli in the model.",
  "optimization/features": "In our study, the number of input features (f) varied depending on the specific analysis and the combination of sound conditions used. Initially, we considered cortical responses from 20 channels over auditory and speech-related cortical areas to four different sound conditions for each child. This resulted in a high-dimensional feature set.\n\nFeature selection was performed using the support vector machine-recursive feature elimination (SVM-RFE) algorithm. This method ranked features in descending order of importance and determined the optimal feature subset by comparing the average classification accuracy of support vector machine (SVM) classifiers through a detailed analysis between different numbers of top-ranked features. The process involved stepwise iteration, adding one feature at a time.\n\nTo ensure robustness, feature selection was conducted using the training set only, adhering to best practices in machine learning to prevent data leakage and overfitting. This approach helped in identifying the most relevant features for predicting behavioral development in cochlear implant (CI) children. The selected features were then used in subsequent classification and regression analyses to evaluate their predictive performance.",
  "optimization/fitting": "The study employed machine learning algorithms to predict behavioral development in children with cochlear implants using auditory cortical responses. The number of features (cortical response channels and sound conditions) was indeed much larger than the number of training points (participants). To address potential overfitting, several strategies were implemented.\n\nFirstly, feature selection was conducted using the Support Vector Machine-Recursive Feature Elimination (SVM-RFE) algorithm. This method ranks features by importance and selects an optimal subset, reducing the dimensionality of the data and mitigating overfitting risks. The optimal feature subset was determined by comparing the average classification accuracy of SVM classifiers through a detailed analysis between different numbers of SVM-RFE top-ranked features.\n\nSecondly, the study used a 10-fold cross-validation method repeated 10,000 times. This rigorous validation procedure ensures that the model's performance is robust and generalizable, rather than merely memorizing the training data. The cross-validation process helps to estimate the model's performance on unseen data, providing a more reliable assessment of its predictive power.\n\nAdditionally, the use of a linear Support Vector Classifier (SVC) with default parameters helps to keep the model simple, reducing the risk of overfitting. The simplicity of the model is further supported by the fact that high classification accuracies were typically achieved with less than half of the overall features.\n\nTo address underfitting, the study ensured that the model was complex enough to capture the underlying patterns in the data. The use of a linear kernel in the SVM classifier allows for capturing linear relationships in the data, which is appropriate given the nature of the features used. Furthermore, the high classification accuracies achieved (up to 98.20%) indicate that the model is sufficiently complex to capture the relevant patterns in the data without being overly simplistic.\n\nIn summary, the study employed feature selection, rigorous cross-validation, and an appropriate choice of model complexity to address both overfitting and underfitting concerns. These measures ensure that the predictive models are robust, generalizable, and capable of accurately predicting behavioral development in children with cochlear implants.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method used was cross-validation, specifically 10-fold cross-validation repeated 10,000 times. This approach helps to assess the model's performance more reliably by ensuring that each data point is used for both training and validation.\n\nAdditionally, we utilized the Support Vector Machine-Recursive Feature Elimination (SVM-RFE) algorithm for feature selection. This method ranks features by their importance and iteratively eliminates the least significant ones, helping to reduce the dimensionality of the data and focus on the most relevant features. This process not only improves the model's performance but also mitigates the risk of overfitting by avoiding the inclusion of irrelevant or noisy features.\n\nFurthermore, we normalized the data to ensure that each feature contributed equally to the model, which is crucial for preventing any single feature from dominating the learning process. This step helps in maintaining the model's generalizability and reducing the likelihood of overfitting to the training data.\n\nIn the regression analysis, we employed a leave-one-out cross-validation (LOOCV) strategy. This method is particularly useful for small datasets, as it ensures that each data point is used once as a validation set while the remaining data points form the training set. This approach provides a more thorough evaluation of the model's performance and helps in identifying any potential overfitting issues.\n\nWhile these techniques significantly enhance the model's robustness, it is important to note that the current models were built using a single dataset from a specific population. Future work should focus on validating these models with separate, independently collected datasets to further assess their generalization ability. Additionally, increasing the sample size and applying more stringent validation algorithms, such as nested cross-validation, could further address any remaining concerns about overfitting.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The machine learning models used in this study are not fully transparent and suffer from the \"black box\" problem. While these models demonstrate that auditory cortical responses can predict cochlear implant (CI) outcomes, they do not provide clear insights into the mediating mechanisms behind these predictions. This lack of interpretability means that, although the models are effective in making predictions, they do not offer a straightforward explanation of how specific features contribute to the outcomes. This limitation is common in many machine learning algorithms, particularly those that rely on complex, high-dimensional data like neuroimaging. As a result, while the models are valuable for predictive purposes, they cannot replace mechanistic studies that aim to understand the underlying biological processes. Future work may focus on developing more interpretable models or techniques to better understand the contributions of individual features to the predictions.",
  "model/output": "The model encompasses both classification and regression approaches. For classification, a support vector machine (SVM) with a recursive feature elimination (RFE) algorithm was employed to rank features by importance. The optimal feature subset was determined by evaluating the average classification accuracy of SVM classifiers through a detailed analysis involving different numbers of top-ranked features. The linear support vector classifier (SVC) was then used to discriminate between high-versus low-development cochlear implant (CI) children based on the selected features. The model's performance was assessed using 10-fold cross-validation repeated 10,000 times, yielding metrics such as classification accuracy, precision, sensitivity, and the area under the curve (AUC).\n\nIn the regression analysis, a support vector regressor (SVR) with a linear kernel was utilized. Features and prediction labels (behavioral development) were normalized, and the optimal feature subset was selected by comparing the mean square error (MSE) of SVM regressors using a leave-one-out cross-validation (LOOCV) strategy. The SVR predicted individual behavioral development, and performance was evaluated using Pearson's correlations between observed and predicted behavioral development. The regression analysis demonstrated high accuracy, particularly when using combinations of three or four sound conditions, indicating the model's robustness in predicting behavioral outcomes.",
  "model/duration": "The execution time for the machine learning models varied depending on the specific analysis being conducted. For classification tasks, the models were run using a 10-fold cross-validation method repeated 10,000 times. This extensive validation process was necessary to ensure the robustness and reliability of the classification results. The regression analyses, on the other hand, utilized a leave-one-out cross-validation (LOOCV) strategy, which is computationally intensive but provides a thorough evaluation of the model's predictive performance. The exact execution time would depend on the computational resources available, but these methods are designed to be comprehensive, ensuring that the models are well-tested and reliable for predicting behavioral development in cochlear implant (CI) children.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed in this study involved a robust machine learning approach to assess the predictability of behavioral development in children with cochlear implants (CI). The primary technique used was the support vector machine-recursive feature elimination (SVM-RFE) algorithm, which ranked features in descending order of importance. This algorithm was crucial in determining the optimal feature subset by comparing the average classification accuracy of SVM classifiers through a detailed analysis of different numbers of top-ranked features.\n\nThe evaluation process included a 10-fold cross-validation method, where the data was randomly divided into training (90%) and testing (10%) groups for each fold. This cross-validation was repeated 10,000 times to yield a statistical distribution of classification performance. Key metrics such as classification accuracy, precision, sensitivity, and the area under the curve (AUC) of the receiver operating characteristic curve were calculated using the average value of these 10,000 iterations.\n\nIn addition to classification, regression analysis was conducted using a linear support vector regressor (SVR) with a leave-one-out cross-validation (LOOCV) strategy. This approach was used to predict individual behavioral development, with the performance evaluated using Pearson's correlations between observed and predicted behavioral development.\n\nThe study also involved evaluating the predictability of cortical responses to various sound conditions, including natural speech, babble noise, speech in noise, and instrumental music. These conditions were analyzed both individually and in combinations to determine their effectiveness in predicting developmental improvement. The highest classification accuracy was achieved using a combination of three conditions (natural speech, babble noise, and instrumental music), with 25 channels selected by the SVM-RFE algorithm.\n\nOverall, the evaluation method demonstrated that cortical responses to combinations of sound conditions could yield high prediction accuracy for CI outcomes, highlighting the potential of functional near-infrared spectroscopy (fNIRS) as an objective prognostic tool for post-implantation rehabilitation in young children.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our machine learning models in predicting behavioral development following cochlear implantation. The primary metrics reported include accuracy, precision, sensitivity, and the area under the receiver operating characteristic curve (AUC). Specifically, we achieved an accuracy of 98.20%, with precision at 98.17%, sensitivity at 98.96%, and an AUC of 99.61% using cortical responses to three conditions (S+ N + M) with 25 channels selected by the SVM-RFE algorithm. These metrics were estimated using a robust 10,000 times 10-fold cross-validation procedure.\n\nIn addition to these metrics, we also conducted regression analyses using an SVR algorithm with a linear kernel and leave-one-out cross-validation (LOOCV) for condition combinations with classification accuracy above 90%. The regression performance was evaluated using correlation coefficients (r), with higher values indicating better predictive accuracy. Remarkably, all five condition combinations yielded high regression prediction accuracies, with the best performance achieved using all four sound conditions (S+ N + SiN + M), resulting in a correlation coefficient of 0.966.\n\nTo assess the predictability of clinical parameters alone, we used an SVM classifier, which achieved a classification accuracy of 61.73%. When combining clinical and cortical features, the influence on predictability varied, but cortical responses consistently showed much higher predictability than clinical parameters alone. This set of metrics is representative of the literature, as it includes standard measures used in machine learning evaluations for similar studies. The high accuracy and robustness of our models suggest that they could serve as objective functional measures and predictors in clinical and rehabilitative practice.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on evaluating the predictive power of auditory cortical responses using machine learning algorithms tailored to our specific dataset of cochlear implant (CI) children. We employed support vector machine-recursive feature elimination (SVM-RFE) for feature selection and support vector classifiers (SVC) for classification tasks. The performance of these models was assessed using 10,000 times 10-fold cross-validation, which provided a robust estimate of their classification accuracy, precision, sensitivity, and area under the curve (AUC).\n\nRegarding simpler baselines, our approach involved comparing the predictability of cortical responses to that of traditional audiological and demographic parameters. The results showed that cortical responses far outperformed these traditional factors, with a classification accuracy of 0.62 for the collection of audiological and demographic parameters compared to much higher accuracies achieved with cortical responses. This comparison highlights the superior predictive power of cortical responses in our models.\n\nAdditionally, we conducted regression analyses using support vector regressors (SVR) with a leave-one-out cross-validation (LOOCV) procedure. These analyses further demonstrated the high accuracy of regression predictions using cortical responses, particularly when combining multiple sound conditions. The regression performance was evaluated using Pearson's correlations between observed and predicted behavioral development, showing remarkable accuracy for combinations of three or four conditions.\n\nIn summary, while we did not compare our methods to publicly available benchmarks, our study provides a comprehensive evaluation of the predictive power of auditory cortical responses using advanced machine learning techniques. The comparison to simpler baselines, such as traditional audiological and demographic parameters, underscores the effectiveness of our approach in predicting behavioral development in CI children.",
  "evaluation/confidence": "The evaluation of our neuroprognostic models involved rigorous statistical methods to ensure the reliability and significance of our results. We employed 10,000 times 10-fold cross-validation to estimate the performance metrics, which included precision, sensitivity, and the area under the curve (AUC). This extensive cross-validation process provided robust confidence intervals for our accuracy measurements, ensuring that our findings are statistically significant.\n\nFor instance, the highest classification accuracy of 98.20% was achieved with specific sound conditions and feature selection, and this accuracy was accompanied by precise confidence intervals. The regression analyses, conducted using a support vector regression (SVR) algorithm with a linear kernel and leave-one-out cross-validation (LOOCV), also yielded remarkable accuracy. The regression scores for different condition combinations were notably high, with correlations (r) greater than 0.9 for combinations involving three or four sound conditions.\n\nThe statistical significance of our results was further supported by Cohen's d values, which quantified the effect size and demonstrated the superiority of cortical responses over audiological and demographic parameters. For example, the predictability of cortical responses far outperformed that of the collection of audiological and demographic parameters, with a Cohen's d of 18.56.\n\nThese statistical measures and the use of cross-validation techniques provide a high level of confidence in the performance and generalizability of our neuroprognostic models. The results indicate that our models are not only accurate but also statistically significant, making a strong case for their potential application in clinical and rehabilitative settings.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study involved sensitive data from child cochlear implant recipients, including cortical functional evaluations and clinical assessments. Due to privacy and ethical considerations, this data is not released to the public. The research was conducted with informed consent from the parents or guardians of the participants, and the data is securely stored and managed in accordance with institutional and ethical guidelines. The findings and results of the study have been published, but the raw data itself remains confidential."
}