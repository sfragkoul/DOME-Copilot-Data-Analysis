{
  "publication/title": "Application of Machine Learning Algorithm Incorporating Dietary Intake in Prediction of Gestational Diabetes Mellitus",
  "publication/authors": "The authors who contributed to this article are:\n\n- Tianze Ding, who was involved in programming, manuscript drafting, data analysis, and result interpretation.\n- Kaiyu Yang and Jian Zhang, who contributed to the study design and concept.\n- Lijuan Peng, who assisted with programming and manuscript drafting.\n- Jianjun Jiang and Hongwei Wang, who participated in data collection and the critical revision of the manuscript.\n\nAll authors read and approved the final manuscript. None of the authors reported a conflict of interest related to the study.",
  "publication/journal": "Endocrine Connections",
  "publication/year": "2024",
  "publication/pmid": "39393404",
  "publication/pmcid": "PMC11623027",
  "publication/doi": "10.1530/EC-24-0169",
  "publication/tags": "- Gestational Diabetes Mellitus\n- Machine Learning\n- Predictive Models\n- Dietary Intake\n- Logistic Regression\n- XGBoost\n- LightGBM\n- Feature Selection\n- Random Forest\n- Cross-Validation\n- Model Evaluation\n- Clinical Data\n- Sociodemographic Data\n- Pregnancy Outcomes\n- Data Imputation\n- Statistical Analysis\n- Python Programming\n- Medical Ethics\n- Endocrine Connections\n- Gestational Diabetes Prediction",
  "dataset/provenance": "The dataset used in this study was collected from pregnant women who met specific inclusion criteria, such as natural conception, singleton pregnancy, and the ability to provide informed consent. Exclusions were applied for women with pre-existing diabetes or severe health conditions. Ultimately, 554 pregnant women were enrolled in the study.\n\nClinical data were gathered from routine blood tests and lipid examinations conducted between the 10th and 12th weeks of pregnancy. Additionally, dietary surveys were conducted around the 24th week of pregnancy using a validated semi-quantitative food frequency questionnaire (FFQ). This FFQ included 222 food-related items and was administered through face-to-face interviews by experienced dietitians. The dietary data were complemented by universal screening for gestational diabetes mellitus (GDM) using the 75g oral glucose tolerance test (OGTT), which diagnosed 152 women with GDM.\n\nThe dataset comprised 78 features initially, but one feature was excluded due to excessive missing values, leaving 77 features for modeling. The data collection process ensured the protection of participants' privacy by replacing sensitive information with codes.\n\nThe study was registered at www.chictr.org.cn (ChiCTR1900027764) and approved by the Medical Ethics Committee of the Seventh People\u2019s Hospital affiliated with Shanghai University of Traditional Chinese Medicine. Written informed consent was obtained from all participants. The datasets generated during the study are not publicly available due to ethical approval limitations, but they can be obtained from the corresponding author upon reasonable request.",
  "dataset/splits": "In our study, we employed a five-fold cross-validation approach to split the dataset. This method involves dividing the data into five subsets, or folds. The model is then trained on four of these folds and tested on the remaining one. This process is repeated five times, with each fold serving as the test set once. Consequently, each data point is used for both training and testing, ensuring a comprehensive evaluation of the model's performance.\n\nThe distribution of data points in each split is as follows: since we have 554 pregnant women in the final data analysis, each fold contains approximately 443 data points for training and 111 data points for testing. This approach maximizes the use of the limited data available, providing a robust assessment of the models' predictive performance.",
  "dataset/redundancy": "The datasets used in this study were split using a five-fold cross-validation approach. This method ensures that the training and test sets are independent by dividing the data into five subsets. In each iteration of the cross-validation, one subset is used as the test set, while the remaining four subsets are used for training. This process is repeated five times, with each subset serving as the test set once. This technique helps to maximize the use of the limited data available and provides a more robust evaluation of the models' performance.\n\nThe distribution of the datasets used in this study is comparable to previously published machine learning datasets in the context of gestational diabetes mellitus (GDM) prediction. The datasets include sociodemographic and clinical data, with one dataset also incorporating dietary data. This approach allows for a comprehensive analysis of various factors that may influence GDM. The inclusion of dietary data is particularly noteworthy, as it is not commonly studied in predictive models for GDM. By comparing the predictive performance of models constructed with and without dietary data, the study aims to determine whether dietary information can enhance the accuracy of GDM prediction models.",
  "dataset/availability": "The datasets generated during this study are not publicly available due to ethical approval limitations. However, researchers can obtain the data by requesting it from the corresponding author. This approach ensures that the data is shared responsibly while adhering to ethical guidelines. The ethical approval for the study was obtained from the Medical Ethics Committee of the Seventh People\u2019s Hospital affiliated with Shanghai University of Traditional Chinese Medicine. This committee oversees the ethical conduct of research involving human participants, ensuring that all data handling and sharing practices comply with relevant regulations and standards. The study was also registered at www.chictr.org.cn (ChiCTR1900027764), further ensuring transparency and accountability in the research process.",
  "optimization/algorithm": "The study employed three distinct machine-learning algorithms to develop predictive models for gestational diabetes mellitus (GDM). These algorithms included logistic regression, XGBoost, and LightGBM. Logistic regression is a well-established statistical method used for binary classification problems, modeling the probability of a binary outcome. XGBoost and LightGBM are both gradient boosting frameworks that build predictive models by sequentially adding trees to correct errors made by previous trees. These algorithms are not new but are widely recognized for their effectiveness in handling complex datasets and capturing non-linear relationships.\n\nThe choice of these algorithms was driven by their proven track records in predictive modeling and their ability to handle different types of data. Logistic regression was included as a baseline model due to its simplicity and interpretability. XGBoost and LightGBM were selected for their superior performance in handling large and complex datasets, which are common in medical research. These algorithms have been extensively used in various domains, including healthcare, and have demonstrated high accuracy and efficiency.\n\nThe decision to use these specific algorithms in this study was influenced by their ability to incorporate a wide range of features, including sociodemographic, clinical, and dietary data. The inclusion of dietary data was particularly significant, as it enhanced the models' predictive performance. The study found that XGBoost performed the best among the three algorithms, followed by LightGBM, and then logistic regression. This performance was attributed to the algorithms' capability to manage non-linear relationships and complex interactions within the data.\n\nThe algorithms were chosen for their robustness and ability to provide reliable predictions, which are crucial for guiding timely interventions in GDM. The study's findings highlight the importance of integrating dietary data into predictive models, as it significantly improves their accuracy. The use of these established algorithms ensures that the models are both reliable and interpretable, making them valuable tools for clinicians and researchers in the field of gestational diabetes.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the quality and reliability of the machine-learning models. We began by handling missing values in the dataset. Features with more than 10% missing data were removed to maintain data integrity. For the remaining data, missing values in continuous variables were imputed using mean values. Categorical variables were assigned default values: parity was set to 1, and both education level and family history of diabetes were set to zero.\n\nFeature selection was performed using random forest mean decrease impurity, which helped us identify the most relevant features for predicting gestational diabetes mellitus (GDM). This process resulted in the extraction of 18 out of 77 features, including sociodemographic, clinical, and dietary data. The top five features identified were blood glucose, age, pre-pregnancy BMI, triglycerides, and HDL. In the dietary indexes, vitamin E (\u03b4-E), livestock meat, vitamin E (\u03b1-E), aquatic products, selenium, and grain were found to contribute significantly to the outcome.\n\nTwo datasets were created for model training: one containing sociodemographic and clinical data, and the other including additional dietary data. This approach allowed us to compare the predictive performance of models with and without dietary information. The models were trained using logistic regression, XGBoost, and LightGBM algorithms. A five-fold cross-validation was employed to split the training and test sets, and Grid Search was used to find the optimal parameters for each model. This comprehensive preprocessing and encoding strategy ensured that our models were robust and capable of accurately predicting GDM.",
  "optimization/parameters": "In our study, we initially considered a total of 77 features. However, after a thorough data cleaning process and the elimination of redundant variables, we employed random forest mean decrease impurity for feature selection. This process allowed us to extract and focus on 18 key features that significantly contributed to the outcome.\n\nThe top five features identified were blood glucose, age, pre-pregnancy BMI, triglycerides, and HDL. Additionally, in the dietary indexes, vitamin E (\u03b4-E), livestock meat, vitamin E (\u03b1-E), aquatic products, selenium, and grain were found to be remarkably influential.\n\nTo ensure the robustness of our models, we utilized two datasets: one containing sociodemographic and clinical data, and the other including sociodemographic data, clinical data, and dietary data. This approach enabled us to compare the predictive performance of the models constructed with these two datasets separately, thereby assessing whether dietary data could enhance the models' accuracy.\n\nFor model training, we employed logistic regression, XGBoost, and LightGBM algorithms. To optimize the use of our limited data, we performed a five-fold cross-validation to split the training and test sets. Furthermore, we used Grid Search to identify the optimal parameters for each model. This systematic approach ensured that our models were well-calibrated and capable of providing reliable predictions.",
  "optimization/features": "In the optimization process of our study, we utilized a total of 18 features as input for our models. These features were carefully selected from an initial pool of 77 variables. To ensure the most relevant and informative features were included, we performed feature selection using the random forest mean decrease impurity method. This technique helps in identifying the most significant features that contribute to the prediction of gestational diabetes mellitus (GDM).\n\nThe feature selection process was conducted using the training set only, ensuring that the model's performance on the test set remained unbiased. This approach helps in avoiding overfitting and ensures that the model generalizes well to new, unseen data. The selected features included a mix of sociodemographic, clinical, and dietary data, which were found to be the most influential in predicting GDM.",
  "optimization/fitting": "In our study, we employed three different machine learning algorithms: logistic regression, XGBoost, and LightGBM. Each of these algorithms has its own strengths and potential pitfalls, particularly in terms of overfitting and underfitting.\n\nFor logistic regression, the model is relatively simple and linear, which makes it less prone to overfitting but can sometimes lead to underfitting, especially with complex datasets. To mitigate this, we ensured that our feature selection process was robust, using random forest mean decrease impurity to identify the most relevant features. This helped in reducing the dimensionality of the data and focusing on the most predictive variables.\n\nXGBoost and LightGBM, on the other hand, are more complex models capable of capturing non-linear relationships in the data. These models can build deep decision trees, which increases the risk of overfitting, especially with smaller datasets. To address this, we implemented several strategies. First, we used a five-fold cross-validation technique to split the training and test sets, which helps in generalizing the model's performance. Second, we employed Grid Search to find the optimal parameters, ensuring that the models were neither too complex nor too simple. Additionally, we monitored the calibration of the models using the Hosmer-Lemeshow test. The LightGBM model, in particular, showed signs of overfitting, as indicated by a P-value below 0.05 in the calibration test. This was likely due to the model's leaf-wise growth strategy, which can result in deeper decision trees. To mitigate this, we considered reducing the number of features and increasing the sample size, although the latter was not feasible within the scope of our study.\n\nIn summary, while logistic regression was less prone to overfitting, it sometimes underfit the data due to its linearity. XGBoost and LightGBM, though more powerful in capturing complex patterns, required careful tuning to avoid overfitting. Our use of cross-validation, parameter tuning, and calibration tests helped in balancing the models' complexity and ensuring robust performance.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting, particularly focusing on the LightGBM model, which is prone to overfitting due to its ability to build very deep decision trees. One effective method we used was feature selection. By reducing the number of features, especially in the non-dietary model, we observed improved calibration in the LightGBM model. This approach helps in mitigating overfitting by simplifying the model and making it less sensitive to specific details in the training data.\n\nAnother strategy we considered was increasing the sample size. A larger sample size can help the model generalize better to unseen data by providing more diverse examples for training. This is particularly relevant for the LightGBM model, where a small sample size contributed to suboptimal calibration.\n\nAdditionally, we compared the performance of different algorithms. XGBoost, for instance, performed better than LightGBM in avoiding overfitting. XGBoost's regularization techniques, such as L1 and L2 regularization, help in penalizing complex models and thus prevent overfitting. These techniques add a penalty to the loss function based on the magnitude of the coefficients, encouraging simpler models that generalize better.\n\nIn summary, our study utilized feature selection, sample size increase, and algorithm comparison as regularization methods to prevent overfitting. These techniques collectively helped in building more robust and generalizable predictive models for gestational diabetes mellitus.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models employed in this study, specifically logistic regression, XGBoost, and LightGBM, vary in their levels of interpretability. Logistic regression is generally considered more transparent and interpretable. It provides clear coefficients for each feature, indicating the direction and magnitude of their influence on the outcome. For instance, a positive coefficient for blood glucose would suggest that higher blood glucose levels increase the likelihood of gestational diabetes mellitus (GDM).\n\nIn contrast, XGBoost and LightGBM are more complex and can be seen as black-box models. These models use ensemble methods involving multiple decision trees, which make them powerful but less interpretable. However, techniques such as feature importance scores can be extracted from these models to understand which features contribute most to the predictions. For example, feature importance scores might reveal that blood glucose, age, and pre-pregnancy BMI are among the top contributors to the model's predictions.\n\nWhile XGBoost and LightGBM do not offer the same level of transparency as logistic regression, they provide valuable insights through feature importance and partial dependence plots. These tools help in understanding how individual features influence the model's predictions, albeit in a more indirect manner compared to logistic regression.",
  "model/output": "The model is a classification model. It is designed to predict the occurrence of gestational diabetes mellitus (GDM) in pregnant women. The evaluation metrics used, such as accuracy, sensitivity, specificity, and the area under the curve (AUC) of the receiver operating characteristic (ROC), are typical for classification tasks. Additionally, the use of confusion matrices further confirms that the model is intended for classification purposes. The models employed\u2014logistic regression, XGBoost, and LightGBM\u2014are all algorithms commonly used for binary classification problems.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, we employed several metrics to evaluate the performance of our models. These included accuracy, sensitivity, specificity, and the area under the curve (AUC) of the receiver operating characteristic (ROC). Additionally, we used the Hosmer\u2013Lemeshow test to assess the calibration of our models.\n\nTo maximize the use of our limited data, we implemented a five-fold cross-validation technique. This approach involved splitting the data into five subsets, where each subset was used once as a test set while the remaining four subsets were used for training. This process was repeated five times, ensuring that each subset was used as a test set once.\n\nWe utilized Grid Search to find the optimal parameters for our models. This method involved systematically working through multiple combinations of parameter tunes to determine which combination produced the best outcome.\n\nThe evaluation was conducted using Python, specifically version 3.11.9, and Visual Studio Code, version 1.91.1. This environment allowed us to efficiently implement and test our models, ensuring robust and reliable results.",
  "evaluation/measure": "In the evaluation of our models, we employed several key performance metrics to comprehensively assess their predictive capabilities. These metrics include accuracy (Ac), sensitivity (Sn), specificity (Sp), and the area under the curve (AUC) of the receiver operating characteristic (ROC). Additionally, we used the Hosmer\u2013Lemeshow test (HL test) to evaluate the calibration of our models.\n\nAccuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as the true positive rate, indicates the proportion of actual positives that are correctly identified by the model. Specificity, or the true negative rate, represents the proportion of actual negatives that are correctly identified. The AUC provides an aggregate measure of performance across all classification thresholds, with higher values indicating better model performance.\n\nThe ROC curves and confusion matrixes for the three models (logistic regression, XGBoost, and LightGBM) and the two datasets (dietary and non-dietary) are visually represented in the figures. These visualizations help in understanding the trade-off between sensitivity and specificity at various threshold settings.\n\nThe reported metrics are representative of standard practices in the literature for evaluating predictive models, particularly in the context of medical diagnostics. Accuracy, sensitivity, specificity, and AUC are commonly used metrics that provide a holistic view of model performance. The inclusion of the Hosmer\u2013Lemeshow test further ensures that the models are well-calibrated, which is crucial for reliable predictive modeling in clinical settings.\n\nIn summary, the performance metrics reported in this study are comprehensive and align with established standards in the field, ensuring a robust evaluation of the models' predictive capabilities.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on evaluating the performance of three different machine learning algorithms\u2014logistic regression, XGBoost, and LightGBM\u2014using two distinct datasets: one containing sociodemographic and clinical data, and the other including additional dietary data.\n\nTo assess the models' performance, we utilized several metrics, including accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). These evaluations were conducted using a five-fold cross-validation approach to ensure robust and reliable results.\n\nRegarding simpler baselines, we did not explicitly compare our models to simpler baselines such as decision trees or naive Bayes classifiers. However, the inclusion of logistic regression, which is a relatively straightforward and widely used algorithm, served as a baseline for comparison against the more complex models, XGBoost and LightGBM.\n\nOur primary objective was to determine whether incorporating dietary data could enhance the predictive performance of the models. The results indicated that both XGBoost and LightGBM models performed better with the dietary dataset compared to the non-dietary dataset, suggesting that dietary information can indeed improve prediction accuracy. The logistic regression model, however, showed nearly identical performance with both datasets, likely due to its limitations in handling non-linear relationships present in the data.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of our models focused on several key performance metrics, including accuracy, sensitivity, specificity, and the area under the curve (AUC) of the receiver operating characteristic (ROC). These metrics were chosen to provide a comprehensive assessment of the models' predictive capabilities.\n\nTo ensure the robustness of our findings, we employed a five-fold cross-validation technique. This method helps to maximize the use of limited data by splitting the dataset into training and test sets multiple times, thereby providing a more reliable estimate of model performance.\n\nStatistical significance was determined using various tests, such as the independent samples t-test, chi-square test, and Mann\u2013Whitney U test, depending on the nature of the data. A P-value threshold of less than 0.05 was used to indicate statistical significance. This rigorous approach ensures that the differences observed between the models and datasets are not due to random chance.\n\nThe ROC curves and confusion matrixes for the three models (logistic regression, XGBoost, and LightGBM) and the two datasets (dietary and non-dietary) were analyzed to compare their performance. The AUC values, in particular, provide a single scalar value that summarizes the model's ability to discriminate between the positive and negative classes. The XGBoost model demonstrated the highest AUC of 0.788, indicating superior performance compared to the logistic regression model (AUC = 0.712) and the LightGBM model (AUC = 0.749).\n\nAdditionally, the dietary dataset outperformed the non-dietary dataset in both the XGBoost and LightGBM models, suggesting that incorporating dietary data can enhance the predictive accuracy of the models. This finding is supported by the statistical analysis, which showed significant differences in key features such as blood glucose, age, pre-pregnancy BMI, triglycerides, and HDL.\n\nIn summary, the evaluation of our models was conducted with a high degree of confidence, utilizing robust statistical methods and comprehensive performance metrics. The results indicate that the inclusion of dietary data can significantly improve the predictive performance of machine learning models for gestational diabetes mellitus.",
  "evaluation/availability": "The raw evaluation files, such as the confusion matrices and calibration curves for the models, are provided in the supplementary material. These files include detailed visual representations of the models' performance, specifically eFigure 1 and eFigure 2. The supplementary material is accessible to readers who wish to review the additional information supporting the work. The supplementary material is provided by the authors to give readers additional information about their work."
}