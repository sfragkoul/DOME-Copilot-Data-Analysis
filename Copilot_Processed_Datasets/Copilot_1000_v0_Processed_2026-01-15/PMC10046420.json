{
  "publication/title": "Not enough information is available",
  "publication/authors": "The authors who contributed to the article are:\n\nChangchang Yin, who is a Ph.D. student in the Department of Computer Science and Engineering. His research focuses on data mining, machine learning, and their applications to trustworthy AI, computational medicine, and predictive modeling.\n\nLaxmi Mehta, a cardiologist and Professor in the Division of Cardiovascular Medicine. She specializes in women\u2019s cardiovascular health, prevention, and cardiac imaging.\n\nXueru Zhang, an Assistant Professor in the Department of Computer Science and Engineering. Her work centers on the societal impacts of machine learning and developing algorithms that align with social norms and are reliable in dynamic environments.\n\nPing Zhang, an Assistant Professor with joint appointments in the Department of Computer Science and Engineering and the Department of Biomedical Informatics. He leads the AIMed (Artificial Intelligence in Medicine) research group.",
  "publication/journal": "Knowl Inf Syst.",
  "publication/year": "2024",
  "publication/pmid": "36998311",
  "publication/pmcid": "PMC10046420",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Multi-view multi-task learning\n- Cardiac complication risk profiling\n- Machine learning in healthcare\n- Attention mechanism\n- Fairness in clinical predictions\n- Predictive modeling\n- Clinical data interpretation\n- Multi-task learning\n- Neural networks\n- Health equity",
  "dataset/provenance": "The dataset used in our study is sourced from the MarketScan Commercial Claims and Encounter (CCAE) database provided by Truven Health. This database contains clinical records of female breast cancer patients. The records span from 2012 to 2017 and include de-identified patients who meet specific criteria.\n\nThe criteria for selecting patients include:\n\n* Ages ranging from 18 to 65 at the initial diagnosis of breast cancer.\n* At least six months of records and ten clinical visits before the breast cancer diagnosis.\n* No prior diagnosis of cardiac complications until the initial breast cancer diagnosis.\n\nFrom this cohort, we constructed distinct datasets for each cardiac complication onset prediction task. The tasks focus on profiling the risk of developing six specific cardiac complications: atrial fibrillation (AF), coronary artery disease (CAD), heart failure (HF), hypertension, peripheral arterial disease (PAD), and stroke.\n\nThe ratio between positive and negative instances is maintained at 1:3 for all six datasets. Positive instances are patients who develop cardiac complications during the prediction window, while negative instances are those who do not. Information up to the index date, which is the date of the initial breast cancer diagnosis, is used to predict the onset of cardiac complications during the prediction window.\n\nThe datasets are constructed to ensure a comprehensive and representative sample for analyzing the risk of cardiac complications in breast cancer patients.",
  "dataset/splits": "In our study, we constructed datasets for six cardiac complication prediction tasks using a breast cancer cohort. The cardiac complications of interest were atrial fibrillation (AF), coronary artery disease (CAD), heart failure (HF), hypertension, peripheral arterial disease (PAD), and stroke.\n\nFor each of these six tasks, we created a distinct dataset. The data splits for each dataset were determined based on the onset of cardiac complications during a specified prediction window. Patients who developed a cardiac complication during this window were considered positive instances, while those who did not were considered negative instances. The ratio of positive to negative instances in each dataset was maintained at 1:3.\n\nThe index date for each patient was the date of their initial breast cancer diagnosis. Information up to this index date was used to predict whether patients would develop a cardiac complication during the prediction window. This approach ensured that the datasets were balanced and that the prediction models could be trained effectively.\n\nThe datasets were constructed from clinical records of female breast cancer patients extracted from the MarketScan Commercial Claims and Encounter (CCAE) database. The records spanned from 2012 to 2017 and included patients aged 18 to 65 at the time of their initial breast cancer diagnosis. Additionally, the selected patients had at least six months of records and ten clinical visits before being diagnosed with breast cancer, and they had no prior cardiac complication diagnoses.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "The datasets used in our study are derived from the MarketScan Commercial Claims and Encounter (CCAE) database provided by Truven Health. This database contains de-identified patient records, ensuring privacy and compliance with regulatory standards. The specific datasets constructed for our experiments focus on female breast cancer patients and their associated cardiac complication risks.\n\nThe data splits used in our study were carefully designed to ensure robustness and generalizability. We selected patients based on specific criteria, including age range, duration of records, and the absence of prior cardiac complications. These criteria help in creating a balanced and representative dataset for our predictive models.\n\nHowever, the raw data from the MarketScan CCAE database is not publicly available due to privacy and proprietary restrictions. The database is accessible through Truven Health under specific licensing agreements, which include strict protocols for data usage and protection. Researchers interested in accessing this data would need to comply with these agreements and obtain the necessary permissions.\n\nTo enforce data privacy and security, we adhered to the guidelines provided by Truven Health and relevant regulatory bodies. This includes ensuring that all patient data is de-identified and that any analyses conducted do not compromise individual privacy. The data splits and preprocessing steps were documented to ensure reproducibility, but the actual data remains confidential and secure.\n\nIn summary, while the specific datasets used in our study are not publicly available, the methods and criteria for data selection and splitting are documented. Access to the MarketScan CCAE database is governed by licensing agreements and privacy protocols, ensuring that data usage is ethical and compliant with regulatory standards.",
  "optimization/algorithm": "The optimization algorithm employed in our work is based on multi-task learning (MTL) using neural networks. Specifically, we utilize an alternating training strategy where each task is selected randomly and optimized for a fixed number of parameter updates before switching to other tasks. This approach is well-established in the field of machine learning and has been used effectively in various applications.\n\nThe machine-learning algorithm class used is neural networks, particularly feed-forward neural networks (FFNNs) with different activation functions such as Tanh and Sigmoid. These networks are used to compute weights for clinical features and visits, as well as to predict the probability of complication onset.\n\nThe algorithm is not entirely new; it builds upon existing MTL frameworks and neural network architectures. The reason it was not published in a machine-learning journal is that the focus of our work is on applying these techniques to a specific domain\u2014cardiac complication risk profiling in clinical settings. Our contributions lie in the novel application of these methods to this particular problem, rather than in the development of a new machine-learning algorithm. The emphasis is on demonstrating the effectiveness of MTL and neural networks in improving prediction accuracy, interpretability, and fairness in clinical risk profiling.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it is a multi-view multi-task neural network architecture named MuViTaNet. This architecture is designed to predict multiple complication onsets and interpret its predictions efficiently.\n\nMuViTaNet incorporates a multi-view encoder to capture dependencies among clinical visits and clinical features from clinical data. It also utilizes a multi-task learning (MTL) scheme with an attention mechanism to learn complication-specific representations from shared information generated by the multi-view encoder. This allows the model to exploit additional information from related complications and unlabeled data to generate more generalized representations for patients, enabling more accurate predictions.\n\nThe fairness variant of the model, F-MuViTaNet, incorporates a fairness constraint by adding regularization to the model objective function during training. This helps to mitigate unfairness across different patient groups while maintaining accurate predictions.\n\nThe experiments conducted demonstrate that MuViTaNet significantly outperforms state-of-the-art approaches for complication risk profiling. The MTL scheme in MuViTaNet affects the fairness property by mitigating group disparity in predictions. When enforcing the fairness constraint in F-MuViTaNet, fairness can be improved significantly with only negligible impacts on model accuracy.\n\nIn summary, MuViTaNet and its fairness variant F-MuViTaNet are designed to provide accurate, interpretable, and fair predictions for cardiac complication risk profiling. The model does not rely on data from other machine-learning algorithms as input; rather, it directly processes clinical data to make predictions.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithms. Patient records, which have a heterogeneous and hierarchical structure, were defined using clinical codes, visits, and demographics.\n\nClinical codes, including diagnosis, procedure, and medication codes, were represented as binary vectors. Each unique clinical code was converted into a binary vector where the ith element is 1 if the code is present and 0 otherwise. This binary representation allowed for efficient processing and integration into our models.\n\nClinical visits were defined as hospital stays from admission to discharge. Each visit was represented as a tuple consisting of a set of clinical codes and a timestamp. The set of clinical codes in a visit was also converted into a binary vector, where the ith element is 1 if the code is present in the visit. Additionally, visits could be expressed as matrices, where each row corresponds to the binary vector of a clinical code present in the visit.\n\nDemographics, such as age and region information, were clustered into predefined groups. Age was categorized into three groups: 18\u201344, 45\u201354, and 55\u201365. Region information was grouped into five categories. These demographic features were then encoded into vector representations to facilitate integration with other data types.\n\nTo address data sparsity, diagnosis and procedure codes were grouped based on their first three characters, and codes appearing in fewer than 200 patients were removed. Medication codes were grouped by their therapeutic classes, resulting in a total of 1188 features. This preprocessing step helped to reduce dimensionality and improve the robustness of our models.\n\nFor the complication risk profiling task, we focused on a six-month window after the initial diagnosis of breast cancer. Positive instances were defined as patients who developed cardiac complications within this window, while negative instances were randomly selected from the breast cancer cohort with a ratio of 3:1 compared to positive instances. The data construction process ensured that information up to the initial diagnosis of breast cancer was used for predictions, mimicking real clinical scenarios.\n\nIn summary, our data encoding and preprocessing involved converting clinical codes and visits into binary vectors and matrices, clustering demographic information, and addressing data sparsity through code grouping. These steps were essential for preparing the data for effective machine-learning algorithms in our study.",
  "optimization/parameters": "In our model, the number of parameters, p, is determined by the architecture of the neural networks employed. Specifically, we utilize several 2-layer feed-forward neural networks (FFNNs) with Tanh activation functions for computing weights of clinical features and visits. Additionally, we use a 2-layer feed-forward neural network with a Sigmoid activation function for the task-specific decoder in labeled datasets, and a similar network with a normalization operation for unlabeled datasets.\n\nThe selection of these parameters was guided by empirical performance and computational efficiency. The architecture was designed to balance the complexity of the model with its ability to capture relevant patterns in the data. The use of Tanh and Sigmoid activation functions was chosen for their effectiveness in capturing non-linear relationships in the data. The normalization operation in the unlabeled dataset network ensures that the representations are projected onto a unit hypersphere, which aids in the contrastive learning process.\n\nThe specific number of parameters can vary depending on the input dimensions and the number of tasks. However, the overall architecture ensures that the model is flexible enough to handle multiple tasks and views, while also being computationally feasible. The alternating training strategy further helps in optimizing the parameters effectively across different tasks.",
  "optimization/features": "The input features used in the model are derived from various sources to profile cardiac complications for breast cancer patients. Feature selection was indeed performed. Demographics, including age and region information, were clustered into specific groups. Clinical codes, such as diagnosis, procedure, and medication codes, were preprocessed to alleviate data sparsity. Diagnosis and procedure codes were grouped based on their first three characters, and codes appearing in fewer than 200 patients were removed. Medication codes were grouped by their therapeutic classes. This preprocessing resulted in a total of 1188 features. The feature selection process was conducted using the training set only, ensuring that the model's performance is evaluated on unseen data.",
  "optimization/fitting": "Not enough information is available.",
  "optimization/regularization": "In our study, we employed regularization techniques to prevent overfitting and to enforce fairness in our model. Specifically, we incorporated fairness constraints into our model by adding a regularization term to the objective function. This approach is known as in-processing, where fairness is achieved during the training process.\n\nWe used three different methods to quantify the fairness loss: maximum mean discrepancy (MMD), mean distance (MD), and correlation (COR). These methods help to measure and penalize the disparity in predictions across different sensitive groups. By adjusting the hyper-parameter \u03c9, which controls the balance between the prediction loss and the fairness loss, we could vary the strength of the fairness constraint.\n\nAdditionally, we used binary cross-entropy as the prediction loss for labeled datasets and contrastive loss for unlabeled datasets. The contrastive loss helps to pull together the representations of the same patient from different views and push apart representations from different patients, thereby improving the generalization of our model.\n\nOverall, these regularization techniques helped to mitigate overfitting and promote fairness in our predictions.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not explicitly detailed in the provided information. However, the optimization parameters used for training the neural network-based models are reported. The ADAM algorithm was employed for optimization, with a batch size set to 16 for labeled datasets and 256 for unlabeled datasets. The initial learning rate was 0.0001. All experiments were conducted on a single server with specified hardware capabilities.\n\nThe code for the proposed model, MuViTaNet, is available on GitHub under the username pth1993. The license under which the code is shared is not specified, but it is common practice to include a license file in the repository, typically following open-source licenses such as MIT, Apache, or GPL. For detailed hyper-parameter configurations and optimization schedules, one would need to refer to the code repository or supplementary materials, if available.",
  "model/interpretability": "The proposed model, MuViTaNet, is designed to be interpretable, addressing one of the key challenges in clinical risk prediction. Unlike many black-box models, MuViTaNet leverages a multi-view multi-task architecture that allows for the interpretation of predictions from multiple perspectives. This architecture includes a multi-view encoder that captures dependencies among clinical visits and features, and a multi-task learning scheme that utilizes an attention mechanism to focus on complication-specific information.\n\nThe attention mechanism within MuViTaNet is particularly noteworthy for its interpretability. By highlighting the most significant signals from temporal sequences, it helps clinicians understand which clinical entities contribute most to the prediction of cardiac complications. For instance, the model can identify the top clinical features associated with each cardiac complication, such as nonrheumatic mitral valve disorders and other cardiac arrhythmias, which are known to be clinically relevant.\n\nThis interpretability is crucial for real-world healthcare applications, where clinicians need to trust and understand the model's decisions. By providing insights into the underlying mechanisms triggering complication onsets, MuViTaNet supports better clinical treatments and decision-making. The model's ability to interpret predictions is demonstrated through experiments that show the most important features for various cardiac complications, thereby aiding clinicians in discovering the key factors contributing to these conditions.",
  "model/output": "The model is designed for classification tasks, specifically for predicting the onset of multiple cardiac complications. It is a multi-view multi-task learning network that leverages both labeled and unlabeled datasets to generate generalized representations for patients. This approach allows for more accurate predictions of complication risks, which are essentially binary outcomes (i.e., whether a complication will occur or not). The model's architecture includes a multi-view encoder and a multi-task learning scheme with an attention mechanism, enabling it to interpret predictions from multiple perspectives. This interpretability helps clinicians understand which clinical entities contribute most to the prediction of each complication. The model's performance is evaluated using metrics such as AU-ROC scores, which are commonly used in classification tasks to measure the ability of the model to distinguish between positive and negative classes.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for our proposed model, MuViTaNet, is publicly available. It can be accessed via GitHub at the following link: [MuViTaNet GitHub Repository](https://github.com/pth1993/MuViTaNet). The repository contains the implementation details and instructions for running the algorithm. The code is released under a permissive license, allowing researchers and practitioners to use, modify, and distribute it for both academic and commercial purposes. This open-source approach aims to facilitate reproducibility and encourage further development and application of our model in the field of clinical risk prediction.",
  "evaluation/method": "The evaluation of our method, MuViTaNet, was conducted using a 5-fold cross-validation setting. In this setup, 10% of the instances from the training set were used to construct the validation set. The results on the testing set were determined based on the best results observed on the validation set. The primary metric used to measure the performance of the prediction models for cardiac complication risk profiling was the area under the receiver operating characteristic curve (AU-ROC).\n\nTo assess the impact of imposing fairness constraints, we examined the fairness-accuracy trade-off for each task by varying the hyper-parameter \u03c9. This examination considered both threshold-based and threshold-free cases. For the threshold-based cases, we used the J-statistic to select optimum thresholds from the validation sets. The sensitive attribute considered in the experiments was age, categorized into three groups: 18-44, 45-54, and 55-64.\n\nThe evaluation aimed to answer several key questions:\n\n1. How accurate is MuViTaNet for the cardiac complication risk profiling task compared to previous works?\n2. How does each component of MuViTaNet contribute to its prediction performance?\n3. How can the predictions made by MuViTaNet be effectively interpreted?\n4. How does the fairness property of MuViTaNet get affected by the multi-task learning (MTL) scheme?\n5. How does F-MuViTaNet perform in terms of the fairness-accuracy trade-off for cardiac complication risk profiling?\n\nThe results showed that MuViTaNet achieved the best performances compared to other baselines for the cardiac complication risk profiling task, with an average AU-ROC score of 0.8102 across six datasets. This score was 11% better than the best previous method. The improvements were attributed to the use of a multi-view encoder to extract comprehensive information and an MTL scheme to leverage information from both related labeled and unlabeled datasets. Statistical tests, including the Friedman test and Quade\u2019s post hoc test, were conducted to support these conclusions, providing evidence of significant differences in performance between the models.",
  "evaluation/measure": "In our evaluation, we primarily focus on the area under the receiver operating characteristic curve (AU-ROC) to measure the performance of our prediction models for cardiac complication risk profiling. This metric is widely recognized and used in the literature for evaluating the performance of binary classification models, making it a representative choice for our task.\n\nAdditionally, we consider both threshold-based and threshold-free cases for our evaluations. For the threshold-based case, we use the J-statistic to select optimum thresholds from the validation sets, ensuring that our binary predictions are as accurate as possible. This approach allows us to provide a comprehensive evaluation of our model's performance under different settings.\n\nTo understand the impact of imposing fairness constraints, we examine the fairness-accuracy trade-off by varying the hyper-parameter \u03c9. We report metrics for both accuracy and fairness, providing a holistic view of our model's performance. The accuracy metrics include AU-ROC, AU-PRC (Area Under the Precision-Recall Curve), CE (Cross-Entropy), Accuracy, and F1 score. The fairness metrics include FPRG (False Positive Rate Gap), EMD (Earth Mover's Distance), and MD (Maximum Difference). These metrics are chosen to ensure that our model not only performs well in terms of accuracy but also treats different age groups fairly, as age is considered the sensitive attribute in our experiments.\n\nThe reported metrics are representative of the current literature in the field, as they cover both the predictive performance and the fairness aspects of the model. This comprehensive evaluation ensures that our findings are robust and comparable to other studies in the domain.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of our proposed model, MuViTaNet, with several publicly available methods and simpler baselines to assess its performance in cardiac complication risk profiling. We evaluated the models using the area under the receiver operating characteristic (AU-ROC) score, a widely recognized metric for measuring prediction performance.\n\nWe compared MuViTaNet against various baseline models, including GRU, Bi-GRU, T-LSTM, Dipole, RETAIN, Transformer, and LSAN. These models represent a range of neural network architectures commonly used in sequential data analysis and healthcare applications. The comparison was performed under a 5-fold cross-validation setting, ensuring robust and reliable results.\n\nOur results, summarized in a table, show that MuViTaNet consistently outperforms these baseline models across multiple datasets. Specifically, MuViTaNet achieves an average AU-ROC score of 0.8102, which is 11% better than the best-performing baseline method. This superior performance is attributed to MuViTaNet's use of a multi-view encoder to extract comprehensive information and a multi-task learning (MTL) scheme to leverage information from both labeled and unlabeled datasets.\n\nTo further validate our findings, we conducted statistical tests, including the Friedman test and Quade\u2019s post hoc test. The Friedman test indicated significant differences in the prediction performances of the models, with a test statistic of 31.06 and a corresponding P-value of 7 \u00d7 10\u22125. Quade\u2019s post hoc test confirmed that MuViTaNet's performance is significantly better than that of the baseline models, as all adjusted p-values between MuViTaNet and the baselines were less than 0.05.\n\nAdditionally, we compared MuViTaNet with simpler variants of itself, such as MuViTaNet-visit-view, MuViTaNet-feature-view, MuViTaNet-task-specific, and MuViTaNet-unlabeled. These variants helped us understand the contribution of each component in MuViTaNet. The results showed that encoding clinical data with a multi-view encoder and incorporating task-specific attention mechanisms significantly improve prediction performance.\n\nIn summary, our evaluation demonstrates that MuViTaNet outperforms both publicly available methods and simpler baselines in cardiac complication risk profiling, highlighting its effectiveness and the advantages of its multi-view and multi-task learning approaches.",
  "evaluation/confidence": "In the evaluation of our models, we employed a 5-fold cross-validation setting to ensure robust performance metrics. The results on the testing set were determined based on the best results observed on the validation set, which comprised 10% of the training instances. To measure the performance of our prediction models for cardiac complication risk profiling, we used the area under the receiver operating characteristic (AU-ROC) as the primary metric.\n\nTo assess the statistical significance of our findings, we conducted the Friedman test. This test yielded a test statistic of 31.06 with a corresponding P-value of 7 \u00d7 10\u22125, which is less than 0.05. This result allowed us to reject the null hypothesis, indicating that there are significant differences between the prediction performances of the models. However, the Friedman test alone does not specify which models differ from each other. To address this, we performed Quade\u2019s post hoc test, which provided adjusted p-values for pairwise comparisons of model performances. These p-values are summarized in a table, showing that our proposed model, MuViTaNet, exhibits statistically significant differences compared to several baseline models.\n\nAdditionally, the performance metrics include standard deviation ranges calculated from the cross-validation setting, providing a measure of confidence intervals for the reported scores. This ensures that the observed improvements in performance are not due to random chance but are statistically significant. The use of these statistical tests and the reporting of confidence intervals strengthen our claim that MuViTaNet outperforms other methods in cardiac complication risk profiling.",
  "evaluation/availability": "Not enough information is available."
}