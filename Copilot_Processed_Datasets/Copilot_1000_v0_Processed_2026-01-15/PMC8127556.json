{
  "publication/title": "Construction and validation of a machine learning\u2010based nomogram: A tool to predict the risk of getting severe coronavirus disease 2019 (COVID\u201019)",
  "publication/authors": "The authors who contributed to this article are:\n\n- Junhua Zheng, who formulated the original concept and designed the investigation.\n- Ke Wu, who engaged in designing the research as well as in the data extraction.\n- Zhong Zheng, who engaged in designing the research as well as in the data extraction.\n- Zhixian Yao, who engaged in designing the research as well as in the data extraction.\n- Xinyi Zheng, who examined the data and drafted the paper.\n\nAll authors read and approved the ultimate document.",
  "publication/journal": "Immunity, Inflammation and Disease",
  "publication/year": "2021",
  "publication/pmid": "33713584",
  "publication/pmcid": "PMC8127556",
  "publication/doi": "10.1002/iid3.421",
  "publication/tags": "- COVID-19\n- Machine learning\n- Nomogram\n- Severe COVID-19 prediction\n- Clinical features\n- Predictive modeling\n- Logistic regression\n- Risk factors\n- Epidemiology\n- Medical management",
  "dataset/provenance": "The dataset used in this study was sourced from patients treated at Jinyintan Hospital in Wuhan City. The data collection spanned from January 1, 2020, to March 10, 2020. Initially, 439 patients were considered, but 27 were excluded due to incomplete medical information or being classified as Critical or Common types, leaving 412 patients for analysis.\n\nThese 412 patients were divided into two main groups: a training set consisting of 285 patients and an internal validation set of 127 patients. Additionally, 178 patients were prospectively recruited for extra validation. The patients were diagnosed with either the Common or Severe type of COVID-19, as classified according to the \"New Coronavirus Pneumonia Diagnosis and Treatment Program (Trial Version 6)\" promulgated by the General Office of the National Health Commission.\n\nThe dataset includes various clinical data points such as gender, age, date of onset, time of first diagnosis, time of definite diagnosis, time of admission, time of discharge, occupation, history of exposure, underlying disease, and several laboratory test results. This comprehensive dataset was used to develop and validate a prediction model for the progression of COVID-19.\n\nThe study was approved by the Ethics Review Committee of Wuhan Jinyintan Hospital and Shanghai General Hospital, ensuring that all data collection and analysis were conducted in accordance with ethical standards.",
  "dataset/splits": "The dataset was divided into three splits: a training set, an internal validation set, and a prospective validation set.\n\nThe training set consisted of 285 patients, which accounted for approximately 69.2% of the total 412 patients collected retrospectively. The internal validation set included 127 patients, making up about 30.8% of the retrospective cohort. Additionally, for prospective validation, 178 patients were recruited, providing an external validation set.\n\nThe distribution of data points in each split was designed to ensure a comprehensive evaluation of the predictive models. The training set was used to develop the models, the internal validation set was used to tune and validate the models internally, and the prospective validation set was used to assess the models' performance on new, unseen data. This approach helps in evaluating the generalizability and robustness of the models.",
  "dataset/redundancy": "The dataset used in this study consisted of 412 patients who were retrospectively collected from January 1 to February 6, 2020, at Jinyintan Hospital in Wuhan City. These patients were centrally treated and diagnosed with either the Common or Severe type of COVID-19. The dataset was initially filtered to exclude patients with incomplete medical information, resulting in a total of 412 patients.\n\nThe subsequent 412 patients were divided into a training set and an internal validation set using a random seed with a 7:3 ratio. This split resulted in 285 patients in the training set and 127 patients in the internal validation set. The training set was used to develop the predictive models, while the internal validation set was used to assess the performance of these models within the same cohort.\n\nFor additional validation, 178 patients were prospectively recruited from February 6, 2020, to March 10, 2020. This external validation set was used to evaluate the generalizability of the models to a new, independent cohort.\n\nThe outcome variables were defined as Critical type = 1 and Common type = 0 in the statistical analyses. For continuous variables, the Maximally Selected Rank Statistics (MSRS) was used to generate the optimal cutoff value, transforming all variables into dichotomous data. This approach ensured that the models could effectively distinguish between the different types of COVID-19.\n\nThe training and test sets were independent, with the training set used for model development and the internal and external validation sets used for performance assessment. This independence was enforced through the random splitting of the initial dataset and the prospective recruitment of an additional cohort.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of COVID-19. The use of a large, well-defined cohort and the inclusion of both retrospective and prospective data enhance the robustness and generalizability of the findings. The application of advanced statistical methods, such as LASSO and SVM-RFE, further ensures the reliability of the models developed from this dataset.",
  "dataset/availability": "The data used in this study is not publicly available. The study involved retrospective and prospective collection of patient data from Jinyintan Hospital in Wuhan, China, focusing on individuals diagnosed with COVID-19. The dataset includes clinical information such as gender, age, symptoms, laboratory test results, and disease progression details. However, due to privacy and ethical considerations, the raw data has not been released in a public forum. The study was approved by the Ethics Review Committee of Wuhan Jinyintan Hospital and Shanghai General Hospital, ensuring that all data collection and usage adhered to ethical guidelines and patient confidentiality. The data splits, including the training set, internal validation set, and prospective validation set, were created within the study but are not available for public access.",
  "optimization/algorithm": "The optimization algorithm used in this study involves two main machine-learning techniques: Least Absolute Shrinkage and Selector Operation (LASSO) and Support Vector Machine-Recursive Feature Elimination (SVM-RFE). These are well-established methods in the field of machine learning and statistics, particularly for feature selection and regularization.\n\nLASSO is a regression analysis method that performs both variable selection and regularization to enhance the prediction accuracy and interpretability of the statistical model it produces. It is widely used in various domains, including genomics, finance, and healthcare, for its ability to handle high-dimensional data and select important features.\n\nSVM-RFE, on the other hand, is a feature selection algorithm that works by recursively removing the least important features based on the weights assigned by a Support Vector Machine (SVM). This method is effective in identifying a subset of relevant features that contribute most to the prediction task.\n\nBoth LASSO and SVM-RFE are not new algorithms; they have been extensively studied and applied in numerous research areas. The choice of these methods in this study is driven by their robustness and effectiveness in handling complex datasets, which is crucial for predicting the severity of COVID-19.\n\nThe reason these algorithms were not published in a machine-learning journal is that this study focuses on their application in a specific medical context rather than the development of new machine-learning techniques. The primary goal is to construct and validate a predictive model for severe COVID-19 using established methods, demonstrating their practical utility in a real-world healthcare setting.",
  "optimization/meta": "The model employs a meta-predictor approach, integrating outputs from multiple machine-learning algorithms to enhance predictive accuracy. Specifically, two distinct machine-learning methods were used: Least Absolute Shrinkage and Selector Operation (LASSO) and Support Vector Machine-Recursive Feature Elimination (SVM-RFE). These methods were applied to filter and select the most relevant clinical features from the initial dataset.\n\nThe LASSO method, known for its ability to perform both variable selection and regularization to enhance the prediction accuracy and interpretability of the statistical model it produces, was used with a 10-fold cross-validation. Concurrently, SVM-RFE, which is effective in identifying the most relevant features by recursively removing the least important ones, was employed with a 5-fold cross-validation.\n\nThe features selected by both LASSO and SVM-RFE were then intersected to ensure robustness. This intersection yielded five critical clinical features: C-reactive protein (CRP), lactate dehydrogenase (LDH), age, Charlson/Deyo comorbidity score (CDCS), and erythrocyte sedimentation rate (ESR). These features were subsequently used to build the predictive model using multivariate logistic regression (LG).\n\nTo validate the model's performance, it was tested using different cohorts: a training set, an internal validation set, and a prospective validation cohort. The training set consisted of 285 patients, the internal validation set had 127 patients, and the prospective validation cohort included 178 patients. The use of independent validation sets ensures that the training data is distinct from the validation data, thereby providing an unbiased assessment of the model's generalizability.\n\nThe model's performance was evaluated using receiver operating characteristic (ROC) analysis and decision curve analysis (DCA). The ROC analysis showed area under the curve (AUC) values of 0.822 for the training set, 0.762 for the internal validation set, and 0.705 for the prospective validation cohort, indicating strong predictive power. The DCA further confirmed the model's clinical utility by demonstrating a high net benefit across different threshold probabilities.",
  "optimization/encoding": "For the machine-learning algorithm, continuous variables were transformed into dichotomous data. This transformation was achieved using the Maximally Selected Rank Statistics (MSRS) to generate the optimal cutoff value for each variable. This process ensured that all variables were binary, which is suitable for the subsequent machine-learning methods employed.\n\nThe dataset initially consisted of 590 COVID-19 patients. After filtering out cases with incomplete medical information and those classified as Common or Critical types, 412 patients remained. These were divided into a training set of 285 patients and an internal validation set of 127 patients, maintaining a 7:3 ratio. The outcome variables were defined as Critical type = 1 and Common type = 0 for statistical analyses.\n\nTwo machine-learning methods were used for feature selection: the Least Absolute Shrinkage and Selector Operation (LASSO) with 10-fold cross-validation and the Support Vector Machine-Recursive Feature Elimination (SVM-RFE). These methods helped in identifying the most relevant clinical features from the dataset. The selected features were then intersected to ensure robustness, and multivariate logistic regression was applied to build the predictive model. This approach ensured that the model was based on the most significant predictors of severe COVID-19.",
  "optimization/parameters": "In our study, we utilized five input parameters to build our predictive model for severe COVID-19. These parameters were selected through a rigorous process involving two machine learning algorithms: the Least Absolute Shrinkage and Selector Operation (LASSO) method and Support Vector Machine-Recursive Feature Elimination (SVM-RFE). The LASSO method was implemented with 10-fold cross-validation, while the SVM-RFE used 5-fold cross-validation. Both methods were applied to a dataset of 412 patients, which was divided into a training set (285 patients) and an internal validation set (127 patients) using a 7:3 ratio.\n\nThe five selected parameters are:\n\n1. Erythrocyte Sedimentation Rate (ESR)\n2. Charlson/Deyo Comorbidity Score (CDCS)\n3. Age\n4. Lactate Dehydrogenase (LDH)\n5. C-Reactive Protein (CRP)\n\nThese parameters were chosen based on their significance in predicting the progression of COVID-19 to a severe state. The cutoff values for continuous variables were determined using the Maximally Selected Rank Statistics (MSRS) to ensure optimal dichotomization. The selected parameters were then used to build a multivariate logistic regression model, which demonstrated superior performance compared to a random forest model in predicting severe COVID-19 cases. The model's performance was validated using an internal validation set and a prospective validation cohort, showing consistent area under the curve (AUC) values across different datasets.",
  "optimization/features": "In our study, we initially considered a wide range of clinical features. To identify the most relevant predictors for severe COVID-19, we employed two machine learning techniques: the Least Absolute Shrinkage and Selector Operation (LASSO) method and Support Vector Machine-Recursive Feature Elimination (SVM-RFE). These methods were applied to select suitable traits from the dataset.\n\nThe LASSO method, with a 10-fold cross-validation, and SVM-RFE, with a 5-fold cross-validation, were used to filter and rank the features. By intersecting the results from both methods, we identified five key clinical features that were consistently important across both techniques. These features were then used as inputs for our predictive model.\n\nThe feature selection process was performed using the training set only, ensuring that the validation and testing phases remained unbiased. This approach helped us to build a robust and generalizable predictive model for identifying patients at risk of developing severe COVID-19. The selected features included C-reactive protein (CRP), lactate dehydrogenase (LDH), age, Charlson/Deyo comorbidity score (CDCS), and erythrocyte sedimentation rate (ESR). These five features were used as inputs in our final predictive model.",
  "optimization/fitting": "The study involved 412 patients, divided into training and internal validation sets with a 7:3 ratio. This division helped in ensuring that the model was trained on a sufficiently large dataset while also having a separate set for validation.\n\nTo address the potential issue of overfitting, given the number of parameters relative to the training points, several techniques were employed. Firstly, the Maximally Selected Rank Statistics (MSRS) was used to generate optimal cutoff values, transforming continuous variables into dichotomous data. This step reduced the complexity of the model by simplifying the input features.\n\nAdditionally, the Least Absolute Shrinkage and Selector Operation (LASSO) method with 10-fold cross-validation was utilized. LASSO is particularly effective in selecting relevant features and shrinking the coefficients of less important features to zero, thereby reducing the risk of overfitting. The cross-validation process further ensured that the model's performance was consistent across different subsets of the data.\n\nSupport Vector Machine-Recursive Feature Elimination (SVM-RFE) was also applied to collect hallmarks, providing an additional layer of feature selection. The intersection of clinical features from both LASSO and SVM-RFE methods ensured that only the most relevant features were retained for the final model.\n\nMultivariate logistic regression (LG) and random forest (RF) were then used to test the predictive power of the model. The superior performance of multivariate logistic regression led to its use in building the predictive nomogram. The model's performance was assessed using the concordance index, calibration plots, and receiver operating characteristic (ROC) analysis, including the area under the curve (AUC). These metrics helped in evaluating the model's ability to generalize to new data, thereby mitigating the risk of overfitting.\n\nTo rule out underfitting, the model's complexity was carefully managed. The use of LASSO and SVM-RFE ensured that important features were not excluded, maintaining the model's ability to capture the underlying patterns in the data. The random forest algorithm, with 1000 decision-making trees, provided a robust framework for capturing complex interactions between features. The decision curve analysis (DCA) further assessed the model's utility for decision-making, ensuring that it provided meaningful predictions.\n\nIn summary, the combination of feature selection techniques, cross-validation, and robust evaluation metrics helped in balancing the model's complexity, ruling out both overfitting and underfitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our predictive model. One of the key methods used was the Least Absolute Shrinkage and Selector Operation (LASSO). This regularization technique is particularly effective in selecting relevant features and shrinking the coefficients of less important ones to zero, thereby reducing the complexity of the model and preventing overfitting. We utilized a 10-fold cross-validation approach with LASSO to identify the optimal set of features.\n\nAdditionally, we employed the Support Vector Machine-Recursive Feature Elimination (SVM-RFE) method. This technique iteratively removes the least significant features and builds the model again, helping to retain only the most relevant features. By intersecting the features selected by both LASSO and SVM-RFE, we ensured that our final model was built on a robust set of predictors.\n\nFurthermore, we used multivariate logistic regression to build the predictive nomogram. This method helps in understanding the relationship between multiple predictors and the outcome variable, providing a more reliable and generalizable model. The performance of the model was validated using internal and external validation cohorts, ensuring that it generalizes well to new data.\n\nTo measure the model's performance, we used the area under the curve (AUC) from the receiver operating characteristic (ROC) analysis. This metric provides a comprehensive evaluation of the model's ability to discriminate between different outcomes. Additionally, we performed decision curve analysis (DCA) to assess the clinical net benefit of the model, ensuring that it adds value in real-world clinical decision-making.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the publication. Specifically, we detailed the use of the Least Absolute Shrinkage and Selector Operation (LASSO) method with a 10-fold cross-validation level, and the Support Vector Machine-Recursive Feature Elimination (SVM-RFE) for feature selection. Additionally, we employed a random forest algorithm with 1000 decision-making trees. The statistical analyses were conducted using the R language, with specific packages such as glmnet for LASSO, e1071 for SVM-RFE, and randomForest for the random forest algorithm. The calibration plots, concordance index, and receiver operating characteristic (ROC) curves were generated using the rms package in R. The decision curve analysis (DCA) was performed to assess the net benefit and cost-benefit ratio of the models.\n\nThe model files and specific optimization parameters are not explicitly provided in the publication, as the focus was on the methodology and results rather than the raw data or code. However, the detailed steps and parameters used for the analyses are thoroughly described, allowing for reproducibility by other researchers. The publication does not specify the availability of model files or optimization parameters under a particular license, but the methods and parameters are openly described for transparency and reproducibility purposes.",
  "model/interpretability": "The model developed in this study is not a blackbox model. It is designed to be transparent and interpretable, ensuring that clinicians can understand how predictions are made. This transparency is achieved through the use of a nomogram, which is a graphical representation of a predictive model. The nomogram includes several key features: ESR (erythrocyte sedimentation rate), CDCS (Charlson/Deyo comorbidity score), Age, LDH (lactate dehydrogenase), and CRP (C-reactive protein). Each of these features contributes to a total score, which can be used to predict the likelihood of a patient progressing from a common type of COVID-19 to a severe type.\n\nThe nomogram allows for clear visualization of the risk factors and their respective weights. For example, a higher CDCS indicates a greater likelihood of poorer outcomes, as it accounts for the presence and severity of comorbidities. Similarly, elevated levels of CRP and LDH are associated with increased inflammation and tissue damage, respectively, which are critical indicators of disease severity. Age is another significant factor, with older patients generally at higher risk.\n\nThe model's interpretability is further enhanced by the use of machine learning techniques such as LASSO (Least Absolute Shrinkage and Selection Operator) and SVM-RFE (Support Vector Machine Recursive Feature Elimination). These methods help in selecting the most relevant features and reducing the complexity of the model, making it easier to understand and apply in clinical settings. The use of ROC (Receiver Operating Characteristic) curves, DCA (Decision Curve Analysis), and calibration plots provides additional layers of validation and performance assessment, ensuring that the model's predictions are reliable and clinically useful.\n\nIn summary, the nomogram model is designed to be transparent and interpretable, providing clear insights into the risk factors associated with severe COVID-19. This transparency is crucial for clinicians, as it allows them to make informed decisions and tailor treatments based on individual patient characteristics.",
  "model/output": "The model developed is primarily a classification model designed to predict the progression of COVID-19 from a common type to a severe type. It utilizes multivariate logistic regression, which is a classification technique, to build the predictive nomogram. The model incorporates several significant indices, including ESR, CDCS, Age, LDH, and CRP, which were identified through LASSO and SVM analyses. These machine learning methods were employed to enhance the prediction accuracy and interpretability of the statistical model.\n\nThe performance of the model was assessed using various metrics, including the area under the curve (AUC) for receiver operating characteristic (ROC) analysis. The AUC values for the internal training set, testing set, and external testing set were 0.822, 0.762, and 0.705, respectively. These values indicate the model's ability to distinguish between patients who will progress to severe COVID-19 and those who will not.\n\nAdditionally, decision curve analysis (DCA) was performed to evaluate the net benefit and cost versus benefit ratio of the model. The DCA plots showed a favorable net benefit for clinical use compared to no model conditions. The calibration plots and Hosmer-Lemeshow goodness-of-fit test were also used to validate the model's fitness and ensure its reliability in clinical settings.\n\nThe model's output is presented in the form of a nomogram, which allows for the visualization of the probability of disease progression based on the input features. For example, a patient with a total score of 197 points has a 50% chance of progressing from a common type to a severe type of COVID-19. This nomogram serves as a practical tool for clinicians to assess the risk of severe outcomes in COVID-19 patients and to make informed decisions regarding patient management and resource allocation.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the predictive model involved several rigorous steps to ensure its robustness and clinical applicability. Initially, a 10-fold cross-validated LASSO and a 5-fold cross-validated SVM-RFE algorithm were employed to select the most relevant features. These algorithms were implemented using the R packages glmnet and e1071, respectively.\n\nThe random forest algorithm, with 1000 decision-making trees, was utilized to test the predictive power of the model. However, multivariate logistic regression outperformed the random forest and was used to build the predictive nomogram. This nomogram was constructed using data from 285 patients and internally validated with a separate set of 127 patients.\n\nIn the independent validation phase, the candidate features were further validated in a prospective cohort consisting of 178 patients. The performance of the nomogram was assessed using the concordance index and calibration plots, which were generated using the R package rms. Additionally, the receiver operating characteristic (ROC) curve and the area under the curve (AUC) were analyzed to evaluate the predictive display of the nomogram.\n\nDecision curve analysis (DCA) was performed to plot the net benefit and cost versus benefit ratio, providing insights into the utility of the model for clinical decision-making. The Hosmer\u2013Lemeshow goodness-of-fit test was used to validate the model's fitness. All statistical investigations were conducted using R version 3.6.1, with a significance level set at p < .05.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our predictive models for severe COVID-19 cases. The primary metrics used were the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, the concordance index, and calibration plots. These metrics are widely recognized and used in the literature for assessing the performance of predictive models in medical research.\n\nThe AUC of the ROC curve is a crucial metric that provides a single scalar value representing the model's ability to discriminate between positive and negative classes. We reported the AUC for three different cohorts: the training set, the internal validation set, and the external validation set. These values were 0.822, 0.762, and 0.705, respectively, indicating good model performance across different datasets.\n\nAdditionally, we used the concordance index to measure the model's predictive accuracy. This metric assesses the agreement between predicted and observed outcomes and is particularly useful for evaluating the performance of logistic regression models.\n\nCalibration plots were employed to assess the goodness-of-fit of our models. These plots compare the predicted probabilities with the actual outcomes, providing a visual representation of how well the model's predictions align with the observed data. The calibration plots for our models showed good agreement between predicted and observed probabilities, further validating the model's performance.\n\nDecision Curve Analysis (DCA) was also performed to evaluate the clinical utility of our models. DCA plots the net benefit against the threshold probability, allowing for the assessment of the model's performance in a clinical decision-making context. The DCA plots for our models demonstrated a favorable net benefit, indicating that our models have practical value in clinical settings.\n\nOverall, the set of performance metrics used in our study is representative of those commonly reported in the literature. These metrics provide a comprehensive evaluation of our models' discriminative ability, calibration, and clinical utility, ensuring that our findings are robust and reliable.",
  "evaluation/comparison": "Not applicable. The publication does not provide information about comparisons to publicly available methods or simpler baselines. The focus is on the development and validation of a predictive model for severe COVID-19 using specific machine learning techniques and statistical analyses. The model's performance was assessed using ROC analysis, DCA, and calibration plots, but there is no mention of benchmarking against other publicly available methods or simpler baselines.",
  "evaluation/confidence": "The evaluation of the predictive models employed in this study includes several key metrics and statistical analyses to ensure the reliability and significance of the results.\n\nPerformance metrics such as the area under the curve (AUC) were calculated for the training, internal validation, and external validation cohorts. These metrics provide a measure of the model's ability to discriminate between different types of COVID-19 cases. The AUC values for the internal training set, testing set, and external testing set were reported as 0.822, 0.762, and 0.705, respectively. These values indicate the model's performance across different datasets, showcasing its generalizability.\n\nConfidence intervals were considered in the evaluation process. For instance, the calibration plots included confidence intervals to show the range within which the observed outcomes are likely to fall. This provides a visual representation of the model's calibration and helps in understanding the uncertainty associated with the predictions.\n\nStatistical significance was assessed using various tests. The Hosmer\u2013Lemeshow goodness-of-fit test was used to validate the model's fit. Additionally, p-values were reported for the odds ratios in the univariate and multivariate logistic regression analyses, indicating the statistical significance of the associations between the predictors and the outcome. For example, variables such as ESR, CDCS, age, LDH, and CRP showed statistically significant p-values, suggesting strong associations with the progression of COVID-19.\n\nThe decision curve analysis (DCA) was performed to evaluate the net benefit of the models. This analysis helps in assessing the clinical utility of the models by plotting the net benefit against different threshold probabilities. The DCA provides insights into the trade-offs between true positive and false positive rates, aiding in decision-making.\n\nOverall, the evaluation process included robust statistical methods and performance metrics to ensure the confidence and reliability of the results. The use of cross-validation, calibration plots, and statistical tests such as the Hosmer\u2013Lemeshow test and DCA contributes to the credibility of the findings.",
  "evaluation/availability": "Not enough information is available."
}