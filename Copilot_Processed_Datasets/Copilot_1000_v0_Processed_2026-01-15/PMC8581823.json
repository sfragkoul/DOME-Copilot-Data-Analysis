{
  "publication/title": "Deep learning prediction of attention-deficit hyperactivity disorder in African Americans by copy number variation",
  "publication/authors": "The authors who contributed to the article are:\n\n- Yichuan Liu\n- Hui-Qi Qu\n- Xiao Chang\n- Kenny Nguyen\n- Jingchun Qu\n- Lifeng Tian\n- Joseph Glessner\n- Patrick MA Sleiman\n- Hakon Hakonarson\n\nYichuan Liu and Hakon Hakonarson are the corresponding authors. The specific contributions of each author are not detailed in the provided information.",
  "publication/journal": "Experimental Biology and Medicine",
  "publication/year": "2021",
  "publication/pmid": "34233526",
  "publication/pmcid": "PMC8581823",
  "publication/doi": "10.1177/15353702211018970",
  "publication/tags": "- Deep learning\n- African Americans\n- Attention-deficit hyperactivity disorder\n- Copy number variations\n- Whole genome sequencing\n- Machine learning\n- Genomic structural variations\n- ADHD prediction\n- Multi-layer perceptron\n- Neurodevelopmental disorders\n- Genetic susceptibility\n- Molecular underpinnings\n- Structural variation intensities\n- Feature vectors\n- Phenotype prediction\n- Random forest algorithm\n- K-means clustering\n- Population-specific performance\n- Non-coding genomic regions\n- Metabotropic glutamate receptor signaling",
  "dataset/provenance": "The dataset used in this study was sourced from the Philadelphia Neurodevelopmental Cohort (PNC), archived in the biobank of the Center for Applied Genomics (CAG) at the Children\u2019s Hospital of Philadelphia (CHOP). The dataset includes whole genome sequencing (WGS) data with high read depth (>30x coverage) for 524 African American (AA) children. This cohort consists of 116 ADHD patients and 408 healthy controls. Additionally, an independent dataset of 351 European American (EA) children was used for validation, including 89 ADHD cases and 262 controls. The data was processed using standard pipelines, including alignment to the GRCh37 reference using bwa and further processing with Samtools and BEDTools. Copy number variations (CNVs) were detected using MANTA and categorized into different classes based on genomic annotations, such as exonic, intronic, and intergenic regions. The dataset has been uploaded to the database of Genotypes and Phenotypes (dbGaP) with the accession number phs001165.",
  "dataset/splits": "In our study, we utilized a two-fold random shuffle test to evaluate the predictive abilities of our deep learning model. This involved splitting the dataset of 524 African American (AA) individuals, which included 116 ADHD patients and 408 controls, into two equal parts. One part was used as the training set, and the other as the testing set. This process was repeated 50 times independently to ensure the robustness and reproducibility of our results.\n\nAdditionally, we validated our model using an independent dataset consisting of 351 European American (EA) individuals, which included 89 ADHD patients and 262 controls. The feature vectors for this validation were selected based on the data from the 524 AA subjects. This independent dataset served as a testing set to assess the generalizability of our model across different ethnicities.",
  "dataset/redundancy": "The datasets used in this study were split using a two-fold random shuffle test. This involved dividing 524 African American (AA) subjects, including 116 ADHD patients and 408 controls, into two equal-sized datasets. One dataset was used for training the deep learning model, while the other was used for testing. This process was repeated 50 times independently to ensure the robustness of the results.\n\nTo verify the model's accuracy, an independent dataset of 351 European American (EA) individuals, including 89 ADHD patients and 262 controls, was used. The feature vectors for this independent test were selected based on the data from the 524 AA subjects. This approach ensured that the training and test sets were independent, reducing the risk of data leakage and overfitting.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the field of genomics. The use of whole-genome sequencing (WGS) data with high coverage (>30x) and the inclusion of both coding and non-coding structural variations provide a comprehensive view of the genetic landscape associated with ADHD. The random shuffle test and the use of an independent dataset for validation are rigorous methods that enhance the reliability and generalizability of the findings.",
  "dataset/availability": "The data utilized in this study has been made publicly available to facilitate reproducibility and further research. It can be accessed through the Database of Genotypes and Phenotypes (dbGaP), which is a well-established repository for genomic data. The specific accession number for this dataset is phs001165. This database is maintained by the National Center for Biotechnology Information (NCBI), ensuring that the data is stored securely and is accessible to qualified researchers.\n\nThe data release process was managed to comply with ethical and regulatory standards. All participants provided informed consent, and the study protocols were approved by the Institutional Review Board (IRB) of the Children\u2019s Hospital of Philadelphia (CHOP). This ensures that the data was collected and shared in accordance with relevant guidelines and regulations, protecting the privacy and rights of the participants.\n\nThe dbGaP platform provides a controlled access mechanism, which means that researchers must apply for access and demonstrate that their proposed use of the data is scientifically valid and ethically sound. This controlled access helps to enforce the responsible use of the data, ensuring that it is utilized for legitimate research purposes only. The data is released under terms that allow for its use in scientific research while protecting the confidentiality of the participants.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is a multi-layer perceptron (MLP), which is a type of feedforward artificial neural network. This class of algorithms is well-established and widely used in various fields, including bioinformatics and genomics.\n\nThe specific implementation of the MLP used in this research is not new; it was applied using the Scikit-learn package, a popular machine learning library in Python. The version of Scikit-learn used was 0.21.3. This library provides a robust and efficient implementation of the MLP algorithm, making it suitable for a wide range of applications.\n\nThe optimization of the deep learning model parameters, including maximum iterations, alpha value in L2 regularization, activation functions, solvers, learning rate, number of layers, and numbers of neurons per layer, was performed using the \"gp_minimize\" function from the scikit-optimize 0.7.2 Python library. This function employs a Gaussian process-based optimization algorithm to fine-tune the model parameters for optimal performance.\n\nThe choice of using an established MLP implementation from Scikit-learn and optimizing it with a well-known optimization library aligns with the focus of this study on applying machine learning to genetic data rather than developing new algorithms. The primary goal was to leverage the strengths of existing machine learning techniques to gain insights into the genetic underpinnings of ADHD, rather than innovating in the field of machine learning itself. Therefore, publishing the findings in a machine-learning journal was not the primary objective.",
  "optimization/meta": "The model employed in this study is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on structural variations in the genome, specifically copy number variations (CNVs) and other types of variations, as feature vectors. These variations are categorized into different classes based on genomic annotations, such as exonic, intronic, and intergenic regions.\n\nThe deep learning model used is a multi-layer perceptron (MLP) neuronal network. The parameters for this model, including maximum iterations, alpha value in L2 regularization, activation functions, solvers, learning rate, number of layers, and numbers of neurons per layer, were optimized using the \u201cgp_minimize\u201d function from the scikit-optimize 0.7.2 Python library.\n\nThe feature vectors were selected using a random forest algorithm, which computed the relative importance or contribution of each genomic piece. Feature vectors with zero importance were removed. This process was repeated for all individuals in the study.\n\nThe model's accuracy was evaluated using a two-fold random shuffle test, repeated 50 times, and an independent dataset. The training data consisted of whole genome sequencing (WGS) data from 524 African American children, including 116 ADHD patients and 408 controls. The independent testing set consisted of WGS data from 351 European American children, including 89 ADHD patients and 262 controls. The feature vectors for the independent testing set were selected based on the data from the African American subjects.",
  "optimization/encoding": "The data encoding process involved dividing the human genome into 150 regions, each spanning 20 megabase pairs. For each of these regions, the occurrence counts of nine different types of genomic variations were calculated. These variations included deletions, duplications, and other types of structural variations in exonic, intronic, and intergenic regions. These counts served as feature vectors for the deep learning model.\n\nThe feature vectors were then reduced using a random forest algorithm, which computed the relative importance or contribution of each genomic region. Feature vectors with zero importance were removed to streamline the data and enhance the model's efficiency. This preprocessing step ensured that only the most relevant genomic variations were used in the deep learning model, improving its predictive accuracy.\n\nThe deep learning model utilized was a multi-layer perceptron (MLP) neuronal network, which was implemented using the Scikit-learn package in Python. The MLP was optimized using parameters such as maximum iterations, alpha value in L2 regularization, activation functions, solvers, learning rate, number of layers, and number of neurons per layer. The \"gp_minimize\" function from the scikit-optimize library was employed to fine-tune these parameters, ensuring the model's robustness and accuracy.",
  "optimization/parameters": "In our study, we utilized a multi-layer perceptron (MLP) model from the Scikit-learn package, version 0.21.3, to predict ADHD based on various types of mutations. The model's parameters, including maximum iterations, alpha value in L2 regularization, activation functions, solvers, learning rate, number of layers, and number of neurons per layer, were optimized using the \"gp_minimize\" function from the scikit-optimize 0.7.2 Python library.\n\nThe activation functions for copy number variations (CNVs) of the MLP were primarily \"relu,\" except for intronic deletion CNVs, which used the \"logistic\" activation function. The solvers employed included \"sgd\" and \"lbfgs.\" The number of layers in the neural network ranged from seven to nine. These parameters were carefully selected and optimized to enhance the model's predictive accuracy for ADHD classification.\n\nThe optimization process involved evaluating the model's performance through a two-fold random shuffle test, repeated 50 times independently. This rigorous testing ensured that the selected parameters were robust and reliable for predicting ADHD in the given dataset.",
  "optimization/features": "The input features for the deep learning model consisted of the occurrence counts of nine different types of variations, including deletions, duplications, and other types of variations in exonic, intronic, and intergenic regions. These variations were calculated for each of the 150 genomic regions, resulting in a total of 1350 features (f = 1350).\n\nFeature selection was performed using the random forest algorithm to reduce the feature vectors by computing the relative importance or contribution of each genomic piece. This process involved removing feature vectors that had zero importance, ensuring that only the most relevant features were retained. The feature selection was conducted using the training set only, adhering to best practices to prevent data leakage and maintain the integrity of the model's performance evaluation.",
  "optimization/fitting": "The deep learning model employed in this study utilized a multi-layer perceptron (MLP) from the Scikit-learn package. The model was trained using feature vectors derived from 15 different types of mutations across the genome, divided into 150 regions. Given the complexity and high dimensionality of the data, the number of parameters in the model was indeed much larger than the number of training points.\n\nTo address the risk of over-fitting, several strategies were implemented. Firstly, the model parameters, including the number of layers, neurons per layer, activation functions, solvers, and learning rates, were optimized using the \"gp_minimize\" function from the scikit-optimize library. This optimization process helped in finding the best hyperparameters that generalized well to unseen data. Secondly, a two-fold random shuffle test was applied, where the dataset of 524 African American subjects was split into training and testing sets 50 times independently. This cross-validation approach ensured that the model's performance was evaluated on multiple subsets of the data, reducing the likelihood of over-fitting to any single split.\n\nTo mitigate under-fitting, the model's architecture was carefully designed with multiple layers and neurons, allowing it to capture complex patterns in the data. The use of different activation functions, such as \"relu\" and \"logistic,\" and solvers like \"sgd\" and \"lbfgs,\" provided the model with the flexibility to learn from the data effectively. Additionally, the random forest algorithm was used to reduce the feature vectors by computing their relative importance, ensuring that only the most relevant features were used for training the model. This feature selection process helped in focusing the model on the most informative aspects of the data, thereby improving its learning capacity and reducing the risk of under-fitting.\n\nThe model's performance was further validated on an independent dataset of 351 European American subjects, demonstrating its robustness and generalizability. The consistent accuracy of around 78% in the two-fold shuffle tests and above 70% in the independent dataset indicated that the model was neither over-fitting nor under-fitting the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our deep learning model. One of the key methods used was L2 regularization, which helps to penalize large weights in the model, thereby reducing the complexity and preventing overfitting. The alpha value in L2 regularization was optimized using the \"gp_minimize\" function from the scikit-optimize library.\n\nAdditionally, we utilized a two-fold random shuffle test, which involved splitting the dataset into training and testing sets multiple times (50 independent repetitions) to evaluate the model's predictive abilities. This approach helps to ensure that the model generalizes well to unseen data and is not merely memorizing the training set.\n\nFurthermore, we reduced the feature vectors using a random forest algorithm, which computes the relative importance or contribution of each genomic piece. Feature vectors with zero importance were removed, thereby selecting only the most relevant features for the model. This feature selection process helps to simplify the model and reduce the risk of overfitting.\n\nOverall, these techniques collectively contributed to the model's stability and reproducibility, achieving an average accuracy of around 78% in classifying ADHD individuals versus controls.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in this study are available and can be inferred from the provided details. The deep learning model employed was a multi-layer perceptron (MLP) from the Scikit-learn package (version 0.21.3). The parameters for this model, including maximum iterations, alpha value in L2 regularization, activation functions, solvers, learning rate, number of layers, and number of neurons per layer, were optimized using the \u201cgp_minimize\u201d function from the scikit-optimize 0.7.2 Python library.\n\nMost activation functions for copy number variations (CNVs) of the MLP were \"relu,\" except for intronic deletion CNVs, which used the \"logistic\" activation function. The solvers included \"sgd\" and \"lbfgs,\" and the number of layers ranged from seven to nine. These configurations were used to achieve a reproducible prediction accuracy of around 78% in classifying ADHD individuals versus controls.\n\nThe specific model files and optimization schedules are not explicitly detailed in the provided information, but the methods and parameters used for optimization are described. The study also mentions the use of a two-fold random shuffle test repeated 50 times independently, which provides a robust evaluation of the model's performance.\n\nRegarding the availability and licensing of the configurations and parameters, the study relies on open-source libraries such as Scikit-learn and scikit-optimize, which are distributed under permissive licenses. The Python code used for the random forest algorithm and feature vector reduction is also built on the Scikit-learn package, indicating that the methods and configurations are reproducible using publicly available tools. However, the exact scripts and datasets used in the study are not explicitly mentioned as being publicly available.",
  "model/interpretability": "The model employed in this study is not entirely a black box, as efforts were made to interpret and understand its predictions. The deep learning model used is a multi-layer perceptron (MLP) neural network, which is typically considered a black-box model due to its complex, non-linear nature. However, several steps were taken to enhance interpretability.\n\nFirstly, the model's feature vectors were derived from specific genomic regions, divided into 150 pieces across the human genome. The occurrence counts of various types of variations, such as deletions, duplications, and other structural variations in exonic, intronic, and intergenic regions, were calculated for each piece. This approach allowed for a structured input to the model, making it possible to trace back the model's decisions to specific genomic regions.\n\nSecondly, a random forest algorithm was used to reduce the feature vectors by computing the relative importance or contribution of each genomic piece. This process helped identify which genomic regions were most influential in the model's predictions. For instance, some regions containing coding copy number variations (CNVs) had significantly higher weights and overlapped with previously reported ADHD-associated CNVs. Specifically, the feature vectors at chr7:1\u201320000000 and chr6:140000001\u2013160000000, which ranked high in weight, overlapped with the GRM8 and GRM1 gene regions. These genes are key drivers of metabotropic glutamate receptor signaling, which has been implicated in ADHD.\n\nAdditionally, the model's predictions were evaluated using a two-fold random shuffle test, repeated 50 times, to ensure reproducibility and stability. The accuracy of the model was consistently around 78%, which is a significant improvement compared to traditional clustering methods like k-means.\n\nFurthermore, the model's performance was validated using an independent dataset of 351 European American children, demonstrating its generalizability and robustness. The accuracy was slightly reduced but still above 70%, indicating potential genomic differences between ethnicities.\n\nIn summary, while the deep learning model itself is complex, the use of structured feature vectors, random forest-based feature importance, and validation with independent datasets enhances its interpretability. The model's predictions can be traced back to specific genomic regions, and key regions identified by the model overlap with known ADHD-associated genes.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict whether an individual has attention-deficit hyperactivity disorder (ADHD) or not, based on genomic data. Specifically, the model uses copy number variations (CNVs) and other structural variation intensities from different genomic regions as feature vectors to classify individuals into ADHD cases or controls.\n\nThe model's performance was evaluated using a two-fold random shuffle test, which involves splitting the data into training and testing sets multiple times to assess the predictive accuracy. The results showed that the model achieved an average accuracy of around 78% in classifying ADHD individuals versus controls. This indicates that the model is effective in distinguishing between the two groups based on the genomic features provided.\n\nAdditionally, the model was tested on an independent dataset of European American (EA) children, using feature vectors obtained from the African American (AA) ethnicity analysis. The accuracy of ADHD labeling in this independent dataset was slightly reduced but still above 70%, demonstrating the model's robustness and generalizability across different populations.\n\nThe model's superior performance compared to traditional clustering methods, such as k-means, highlights its effectiveness in handling complex genomic data and capturing the underlying molecular factors associated with ADHD. The use of deep learning algorithms, particularly the multi-layer perceptron (MLP) neuronal network, allows the model to solve extremely complex problems and provide accurate predictions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the deep learning model used in this study is not publicly released. The model was built using the Scikit-learn package, specifically version 0.21.3, and the scikit-optimize library, version 0.7.2. The programming codes are written in Python. The deep learning model employed a multi-layer perceptron (MLP) neural network, with parameters optimized using the \"gp_minimize\" function. The random forest algorithm was also utilized for feature vector reduction.\n\nThe study does not provide a method to run the algorithm, such as an executable, web server, virtual machine, or container instance. Therefore, the software is not available for public use or further implementation by other researchers at this time.",
  "evaluation/method": "The evaluation of the deep learning model involved several rigorous methods to ensure its predictive accuracy and robustness. Initially, a two-fold random shuffle test was employed, where the dataset of 524 African American (AA) subjects, comprising 116 ADHD patients and 408 controls, was split into training and testing sets. This process was repeated 50 times independently to assess the model's predictive abilities. The feature vectors, derived from various types of mutations across different genomic regions, were used to build the deep learning model. The model's performance was then evaluated by labeling individuals in the testing set as either ADHD or controls.\n\nTo compare the deep learning model with traditional clustering methods, the k-means algorithm was used. This algorithm was chosen for its stability and excellent performance when the number of clusters is known, which in this case was two (ADHD and controls). The results showed that the deep learning model achieved a reproducible prediction accuracy of around 78%, with a standard deviation of 3%, significantly outperforming the k-means clustering method, which performed at random (50%).\n\nAdditionally, an independent dataset of 351 European American (EA) children, including 89 ADHD patients and 262 controls, was used to verify the model's accuracy. The feature vectors selected from the AA dataset were applied to this independent EA dataset. While the accuracy slightly decreased, it remained above 70%, indicating the model's robustness and potential for general application across different ethnicities. This evaluation also suggested possible genomic differences between AA and EA populations, highlighting the need for population-specific considerations in deep learning models for disease prediction.",
  "evaluation/measure": "In our study, we primarily focused on prediction accuracy as the key performance metric to evaluate the effectiveness of our deep learning model in classifying ADHD individuals versus controls. We conducted a two-fold random shuffle test, repeated 50 times, to assess the model's predictive abilities. This approach involved splitting the dataset of 524 African American (AA) subjects, including 116 ADHD patients and 408 controls, into training and testing sets with an equal ratio. The average accuracy achieved was approximately 78%, with a standard deviation of around 3%. This metric is representative of the model's stability and reproducibility in predicting ADHD labels.\n\nTo compare the performance of our deep learning model with traditional methods, we also employed the k-means clustering algorithm. The k-means clustering accuracy was found to be around 50%, which is equivalent to random guessing. This stark contrast highlights the superior performance of the deep learning approach in handling complex genomic data.\n\nAdditionally, we validated our model using an independent dataset of 351 European American (EA) children, including 89 ADHD cases and 262 controls. The feature vectors were selected based on the data from the 524 AA subjects. The accuracy of labeling in this independent dataset was slightly reduced but still above 70%. This indicates that while the model generalizes well to a different population, there may be genomic differences between the two ethnicities that affect prediction accuracy.\n\nThe use of accuracy as the primary performance metric is consistent with the literature on similar studies involving deep learning and genomic data. Accuracy provides a straightforward measure of the model's ability to correctly classify individuals as ADHD or controls, making it a relevant and representative metric for our research.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of our deep learning approach with traditional clustering methods to evaluate its effectiveness in predicting ADHD. Specifically, we used the k-means algorithm as a baseline for comparison. The k-means clustering method was chosen because it has shown stable and excellent performance when the number of clusters is known, which in our case was two (ADHD and controls).\n\nTo ensure a fair comparison, we applied the same set of feature vectors derived from the genomic data to both the deep learning model and the k-means algorithm. The feature vectors were selected based on the occurrence counts of various types of structural variations, including deletions, duplications, and other types of variations in exonic, intronic, and intergenic regions.\n\nThe results of this comparison were striking. The deep learning model demonstrated a significantly higher accuracy in predicting ADHD diagnosis, with an average accuracy of around 78% in two-fold random shuffle tests. In contrast, the k-means clustering method performed at a level equivalent to random guessing, achieving an accuracy of approximately 50%. This stark difference highlights the superior predictive power of the deep learning approach over traditional clustering methods.\n\nAdditionally, we validated our model using an independent dataset of 351 European American children, which included 89 ADHD cases and 262 controls. While the accuracy was slightly reduced in this independent dataset, it remained above 70%, further supporting the robustness and generalizability of our deep learning model. This comparison underscores the advantages of using deep learning for complex genetic data analysis, particularly in the context of psychiatric disorders like ADHD.",
  "evaluation/confidence": "The evaluation of the deep learning model's performance was conducted using a two-fold random shuffle test, repeated 50 times, to ensure reproducibility and stability. The model achieved an average accuracy of approximately 78% with a standard deviation of around 4%, indicating consistent performance across different test runs. This level of accuracy is significantly higher than the traditional k-means clustering method, which performed at a random level of 50%.\n\nTo further validate the model, an independent dataset of 351 European American (EA) children was used. The accuracy in this dataset was slightly reduced but remained above 70%, suggesting that the model retains its predictive power even when applied to a different ethnic group. The reduction in accuracy when applied to EA individuals compared to African American (AA) individuals suggests potential genomic differences between these populations.\n\nThe statistical significance of the results is supported by the consistent performance metrics across multiple tests and the clear superiority of the deep learning model over traditional clustering methods. The use of standard deviations and the comparison with a baseline method (k-means clustering) provide confidence in the reliability and robustness of the deep learning approach. The model's ability to maintain high accuracy in an independent dataset further strengthens the claim that the deep learning method is superior for predicting ADHD based on genomic data.",
  "evaluation/availability": "The data used for evaluation in this study has been made publicly available. It can be accessed through the database of Genotypes and Phenotypes (dbGaP). The specific accession number for the dataset is phs001165. This database is a repository for genomic data and provides a platform for researchers to share and access large-scale genomic datasets. The data is intended for use by the scientific community for further research and validation of findings related to ADHD and other genomic studies. The availability of this data ensures transparency and reproducibility in the research process."
}