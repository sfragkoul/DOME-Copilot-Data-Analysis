{
  "publication/title": "COVID-19 Drug Discovery and Pandemic Preparedness",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2021",
  "publication/pmid": "32961040",
  "publication/pmcid": "PMC7537153",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- SARS-CoV-2\n- COVID-19\n- DeepNEU\n- Artificial Intelligence\n- Machine Learning\n- Lung Cells\n- Induced Pluripotent Stem Cells\n- Drug Repurposing\n- Viral Infection\n- Computational Biology\n- Therapeutic Targets\n- Genotypic and Phenotypic Profiles\n- Simulation Models\n- Viral Genome\n- Drug Discovery",
  "dataset/provenance": "The dataset utilized in this study is sourced from the DeepNEU database, specifically version 5.0. This version contains 4206 gene/protein or phenotypic concepts and 37,223 nonzero relationships. This represents a significant expansion from the previous version, 3.6, which included 3187 gene/proteins or phenotypic concepts and 31,027 nonzero relationships. The current version has added more than 1200 new relationships, many of which are specifically relevant to the SARS-CoV-2 viral genome. Each gene/protein and phenotypic concept in DeepNEU v5.0 has on average 249 gene/protein or phenotypic inputs and outputs. This extensive dataset allows for comprehensive simulations and analyses, particularly in the context of viral infections and potential therapeutic interventions. The data has been validated through literature and previous experimental results, ensuring its reliability for the simulations conducted in this study.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is a hybrid deep-machine learning system. This system incorporates elements of fully connected recurrent neural networks (RNNs), cognitive maps (CMs), and evolutionary systems (GA). The platform is not entirely new, as it has been previously used to generate various cell simulations, including artificially induced pluripotent stem cells (aiPSCs), neural stem cells, cardiomyocytes, and skeletal muscle cells. The DeepNEU platform has been validated through literature and has been described in previous works. The focus of the current research is on evaluating an updated version of this platform, specifically version 5.0, for creating simulations of artificially induced type 1 and type 2 alveolar lung cells derived from aiPSCs. These simulations were then exposed to a simulated SARS-CoV-2 virus to study the infection and potential drug repurposing. The platform's effectiveness was validated against published experimental data, demonstrating its ability to accurately reproduce wet lab results.",
  "optimization/meta": "The DeepNEU platform is a hybrid deep-machine learning system that integrates multiple machine learning techniques. It combines elements of fully connected recurrent neural networks (RNNs), cellular models (CMs), and evolutionary systems (genetic algorithms, GA). This integration allows the platform to leverage the strengths of different machine learning approaches to simulate complex biological systems.\n\nThe platform does not explicitly use data from other machine-learning algorithms as input in the traditional sense of a meta-predictor. Instead, it incorporates various machine learning techniques within its architecture to enhance its predictive capabilities. The DeepNEU database, version 5.0, contains a vast amount of gene/protein and phenotypic relationship data, which is used to train and validate the models. This data is derived from literature and experimental results, ensuring that the training data is independent and diverse.\n\nThe system's architecture includes a fully connected recurrent network, which allows for the dynamic flow of information between nodes. Each node in the network has an average of 249 inputs and outputs, facilitating complex interactions and dependencies. The platform's bias toward positive outputs is accounted for during the statistical analysis, ensuring that the predictions are reliable and unbiased.\n\nIn summary, while the DeepNEU platform is not a traditional meta-predictor that combines the outputs of other machine-learning algorithms, it does integrate multiple machine learning techniques within its architecture. The training data is independent and derived from a comprehensive database of gene/protein and phenotypic relationships, ensuring the robustness and reliability of the simulations.",
  "optimization/encoding": "The data encoding process for the machine-learning algorithm involved initializing a state vector of dimension N with all zeros, except for specific transcription factors. These factors, OCT4, KLF4, SOX2, and cMYC (collectively known as OKSM), were assigned a value of +1 to indicate their activation for the initial iteration. This setup allowed these factors to influence the system's behavior from the start. Following the first iteration, all values were dynamically determined by the evolving system behavior, without any fixed constraints.\n\nFor the simulated lung cell models, the conversion from induced pluripotent stem cells to lung cells was achieved through the overexpression of NK2 Homeobox 1 (NKX-2.1) and Wnt Family Member 5A (Wnt5a) in a simulated lung cell medium. This process ensured that the initial conditions were biologically relevant and aligned with known cellular reprogramming methods.\n\nThe simulations were further validated by comparing their outcomes with published peer-reviewed data. This validation step was crucial for ensuring the accuracy and reliability of the simulated models. The final predictions from the simulations regarding gene and protein expression, as well as phenotypic features, were classified based on their values. Predictions with values \u22650 were considered expressed or upregulated, while those with values <0 were classified as downregulated or absent.\n\nStatistical analysis using the unbiased binomial test was employed to compare the simulation predictions with actual data. This test provided an exact probability and compensated for prediction bias, making it ideal for determining the statistical significance of the experimental deviations from the observed distribution. A p-value <0.05 was considered significant, indicating that the observed relationships were unlikely to have occurred by chance.\n\nThe DeepNEU platform, which integrates elements of fully connected recurrent neural networks, cellular models, and evolutionary systems, was used to develop and validate these simulations. The platform's database, version 5.0, contains a comprehensive set of gene, protein, and phenotypic relationships, with over 4206 concepts and 37,223 nonzero relationships. This extensive database ensures that the simulations are based on a robust and well-validated foundation.",
  "optimization/parameters": "In our study, the model utilized a state vector of dimension N, which was initially set with specific values for certain transcription factors. The key transcription factors OCT4, KLF4, SOX2, and cMYC (collectively known as OKSM) were assigned a value of +1 to indicate their activation for the first iteration. This initial setup allowed the system to evolve dynamically, with all subsequent values determined by the evolving behavior of the system.\n\nThe DeepNEU database, version 5.0, contains 4206 gene/protein or phenotypic concepts and 37,223 nonzero relationships. Each node in the fully connected recurrent network initially has approximately 249 inputs and 249 outputs. This extensive network structure ensures a rich flow of information, enabling the model to capture complex biological interactions.\n\nThe selection of parameters was guided by a thorough analysis of positive and negative network connections, revealing a bias toward positive outputs. The pretest probability of a positive outcome prediction is 0.661, while the pretest probability of a negative prediction is 0.339. This bias was taken into account when applying the binomial test to all simulation outcomes, ensuring that the model's predictions were statistically robust.\n\nThe model's parameters were further validated through comparisons with published peer-reviewed data. The simulations rapidly achieved new system-wide steady states within 30 iterations and showed no evidence of overfitting after 1000 iterations. This validation process ensured that the selected parameters accurately reflected biological reality, providing a reliable foundation for the model's predictions.",
  "optimization/features": "The simulations utilized a comprehensive set of input features, with the DeepNEU database (Version 5.0) containing 4206 gene/protein or phenotypic concepts. Each node in the fully connected recurrent network initially has approximately 249 inputs and outputs, indicating a high level of interconnectivity and complexity in the model.\n\nFeature selection was not explicitly mentioned as a separate process. Instead, the model appears to have been designed with a predefined set of reprogramming factors and conditions, such as the transcription factors OCT4, KLF4, SOX2, and cMYC (OKSM), along with ascorbic acid and doxycycline for the aiPSC simulations. For the aiLUNG simulations, factors like NK2 Homeobox 1 (NKX-2.1) and Wnt Family Member 5A (Wnt5a) were used in the presence of a simulated lung cell medium.\n\nThe process of determining the initial state vector and the factors involved in the simulations suggests that the selection of input features was likely based on established biological knowledge and previous studies, rather than a data-driven feature selection method applied to a training set. The model's design and the factors chosen for the simulations were validated against published peer-reviewed data, ensuring their relevance and accuracy.",
  "optimization/fitting": "The simulations demonstrated rapid convergence to new system-wide steady states within fewer than 30 iterations, indicating efficient learning and adaptation. To address the potential issue of overfitting, the simulations were run for up to 1000 iterations without showing any evidence of overfitting. This extensive training period ensured that the models generalized well to new data rather than memorizing the training set.\n\nThe models were validated against published peer-reviewed data, ensuring that they accurately reproduced known results. This validation step is crucial for ruling out underfitting, as it confirms that the models capture the essential dynamics of the biological systems they simulate. Additionally, the use of the bias-adjusted binomial test further ensured that the predictions were statistically significant and not due to chance, providing confidence in the model's performance.\n\nThe simulations were conducted in triplicate with different initial input vectors, which helped to ensure robustness and reliability of the results. This approach mitigates the risk of underfitting by demonstrating that the models can achieve consistent performance across varying initial conditions.",
  "optimization/regularization": "The simulations conducted in this study were designed to rapidly achieve new system-wide steady states, typically within 30 iterations. This quick convergence suggests efficient learning without the need for extensive iterations. To ensure the robustness of the models, simulations were run for up to 1000 iterations, and no evidence of overfitting was observed. This indicates that the models generalized well to the data rather than memorizing it.\n\nAdditionally, the use of the bias-adjusted binomial test further mitigated the risk of overfitting. This statistical method compensates for prediction bias and provides an exact probability, making it ideal for determining the statistical significance of experimental deviations from actual distributions. The pretest probability of a positive outcome prediction was .661, and the pretest probability of a negative prediction was .339. This system bias was accounted for in the binomial test, ensuring that the results were not skewed by the inherent positive bias in the network connections.\n\nThe models were validated against published peer-reviewed data, ensuring that they accurately reproduced wet lab results. This validation step is crucial for confirming that the simulations are not overfitting to the training data but are instead capturing the underlying biological processes. The simulations were also conducted in triplicate using different initial input vectors, further reducing the likelihood of overfitting and enhancing the reliability of the results.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not explicitly detailed in the provided information. The focus is primarily on the biological and computational methods used to simulate induced pluripotent stem cells (iPSCs) and lung cells (aiLUNG), as well as their responses to SARS-CoV-2 infection and potential drug treatments.\n\nThe study mentions the use of the DeepNEU platform, version 5.0, which contains a large database of gene/protein and phenotypic concepts, along with their relationships. However, specific details about the optimization parameters and schedules are not provided. The platform's methodology and validation processes are described, but the exact configurations and files used for optimization are not reported.\n\nRegarding the availability and licensing of these resources, there is no information provided about where to access the model files or the specific terms under which they might be shared. The study emphasizes the validation of the simulations against published data and the potential for future applications in drug discovery and pandemic preparedness.\n\nIn summary, while the study provides a comprehensive overview of the methods and results, it does not offer detailed information about the hyper-parameter configurations, optimization schedule, or the availability of model files.",
  "model/interpretability": "The model employed in this study is not a blackbox. It is designed to be interpretable, providing clear insights into the underlying mechanisms and factors influencing the simulations.\n\nThe model's transparency is evident in several ways. Firstly, the initial state vector was set with specific values for key transcription factors, such as OCT4, KLF4, SOX2, and cMYC, which were turned on for the first iteration. This deliberate initialization allows for a clear understanding of the starting conditions and their impact on the subsequent simulations.\n\nAdditionally, the model's behavior is governed by a fully connected recurrent network, where each node has a defined number of inputs and outputs. This structure facilitates the tracking of information flow and the identification of key interactions within the network.\n\nThe model's predictions are also interpretable. For instance, the expression or repression of genes and proteins, as well as the presence or absence of phenotypic features, are directly compared with published data. This comparison is based on clear criteria: model prediction values greater than or equal to 0 are classified as expressed or upregulated, while values less than 0 are classified as downregulated or not expressed.\n\nFurthermore, the model's predictions are validated against published data using statistical tests, such as the binomial test. This validation process provides a measure of the model's accuracy and reliability, enhancing its interpretability.\n\nIn summary, the model's transparency is achieved through its clear initialization, well-defined structure, and interpretable predictions. These features allow for a deep understanding of the model's behavior and its alignment with biological data.",
  "model/output": "The model is primarily a classification system, as it predicts whether genes/proteins are expressed or upregulated (values \u2265 0) or downregulated or not expressed (values < 0). It also predicts the presence or absence of phenotypic features. The model uses a binomial test to determine the statistical significance of these predictions, which is a common approach in classification problems.\n\nThe model's output is based on a fully connected recurrent network with a bias toward positive outputs. The pretest probability of a positive outcome prediction is 0.661, and the pretest probability of a negative prediction is 0.339. This bias is taken into account when applying the binomial test to all simulation outcomes.\n\nThe model's predictions were compared with published data, and the results were presented in tables and figures. The model's predictions were found to be statistically significant, with a p-value < 0.05, indicating that the observed relationship between the model's predictions and actual outcomes is unlikely to have occurred by chance alone.\n\nThe model was used to simulate induced pluripotent stem cells (iPSCs) and lung cells (aiLUNG), and to evaluate the effects of various factors and drug combinations on these cells. The model's predictions were found to be consistent with previous studies and wet lab results from the peer-reviewed literature.\n\nThe model's output includes the expression levels of various genes/proteins and phenotypic features, as well as the effects of different drug combinations on these expression levels. The model's predictions were found to be accurate and reliable, and the model was able to rapidly achieve new system-wide steady states without evidence of overfitting.",
  "model/duration": "The aiPSC model converged quickly, reaching a new system-wide steady state in just 20 iterations, with no signs of overtraining even after 1000 iterations. Similarly, the aiLUNG simulations also converged rapidly, achieving a new steady state in 24 iterations, and again, no overtraining was observed after 1000 iterations. These results indicate that the models are efficient and do not require extensive computational time to reach a stable state.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method involved a comprehensive validation process to ensure the accuracy and reliability of the simulations. Initially, the artificially induced pluripotent stem cells (aiPSCs) and artificially induced lung cells (aiLUNG) were validated against published peer-reviewed data. This validation step was crucial to establish the credibility of the simulated models.\n\nOnce validated, the aiLUNG simulations were exposed to a simulated SARS-CoV-2 infection by activating the extracellular Spike-RBD in the presence of active TMPRSS2. This setup allowed for the assessment of the model's ability to replicate real-world infection scenarios.\n\nSeveral potential factors and combinations of factor inhibitors were then evaluated for their effectiveness in reducing the production and release of new SARS-CoV-2 viral particles. The results of these evaluations were summarized in key simulations.\n\nThe final predictions from the aiPSC and aiLUNG simulations regarding gene and protein expression, as well as phenotypic features, were directly compared with published data. Model prediction values greater than or equal to 0 were classified as expressed or upregulated, while values less than 0 were classified as downregulated or not expressed.\n\nStatistical analysis was conducted using the unbiased binomial test, which provides an exact probability and can compensate for prediction bias. This test is ideal for determining the statistical significance of experimental deviations from an actual distribution of observations. A p-value of less than 0.05 was considered significant, indicating that the observed relationship between the predictions and actual outcomes is unlikely to have occurred by chance.\n\nThe experiments, except for the earliest screening run, were conducted in triplicate using different initial input vectors to ensure the robustness of the findings. This approach helped to mitigate the risk of overfitting and ensured that the results were reproducible.\n\nOverall, the evaluation method involved a rigorous process of validation, simulation, and statistical analysis to ensure that the models accurately reflected real-world conditions and provided reliable predictions.",
  "evaluation/measure": "In the evaluation of our simulations, several performance metrics were employed to assess the accuracy and significance of our predictions. The primary statistical test used was the binomial test, which provides an exact probability and is ideal for determining the statistical significance of experimental deviations from an actual distribution of observations that fall into two outcome categories, such as agreement or disagreement with published data. A p-value of less than 0.05 was considered significant, indicating that the observed relationship between our predictions and actual outcomes is unlikely to have occurred by chance.\n\nFor the simulated lung cell models (aiLUNG) exposed to SARS-CoV-2 infection, the binomial test was used to evaluate the probability that the genotypic and phenotypic features of the infection were correctly predicted. The probability that all 17 genotypic and all eight phenotypic features of simulated aiLUNG SARS-CoV-2 infection were accurately predicted by chance alone was found to be 0.00003, demonstrating a high level of accuracy in our simulations.\n\nAdditionally, the Mann-Whitney U test was used to compare the predictions for over 4100 genotypic and phenotypic factors from the aiLUNG-COVID-19 and aiLUNG simulations. The estimated p-values for these comparisons were highly significant at P = 0.00001, indicating a strong distinction between the infected and uninfected states.\n\nIn the evaluation of potential therapeutic targets, the paired two-tailed t-test was employed to assess the effects of each treatment on the viral genotypic and phenotypic profiles. The level of significance was set at P < 0.05 for all comparisons. This analysis indicated that overall, the double drug combinations outperformed the single drug treatments based on the genotypic profiles (P < 0.01). However, based on the phenotypic profiles, no significant differences were observed (P > 0.05).\n\nThese performance metrics are representative of standard statistical methods used in the literature to validate computational models and simulations. The use of the binomial test, Mann-Whitney U test, and t-test ensures that our findings are robust and statistically significant, providing a strong foundation for the conclusions drawn from our simulations.",
  "evaluation/comparison": "Not applicable. The publication focuses on the development and validation of a specific machine-learning platform, DeepNEU, for simulating SARS-CoV-2 infection in lung cells. It does not include a subsection dedicated to comparing methods with publicly available ones or simpler baselines on benchmark datasets. The research primarily presents the results of simulations and evaluations conducted using the DeepNEU platform itself, along with statistical analyses to validate these results. The emphasis is on the platform's ability to simulate and predict outcomes related to COVID-19, rather than comparing it to other methods or baselines.",
  "evaluation/confidence": "The evaluation of the simulations involved several statistical tests to ensure the robustness and significance of the results. The paired two-tailed t-test was used to assess the effects of treatments on viral genotypic and phenotypic profiles, with a significance level set at P < .05. This test indicated that drug combinations outperformed single drug treatments based on genotypic profiles with a P value of less than .01. However, no significant differences were observed in phenotypic profiles (P > .05).\n\nThe binomial test was employed to compare the predictions from the simulations with published data. This test is ideal for determining the statistical significance of deviations from an actual distribution of observations, with a P value of less than .05 considered significant. The results showed that the probability of accurately predicting all genotypic and phenotypic features of simulated SARS-CoV-2 infection by chance alone was extremely low (.00003), indicating strong statistical significance.\n\nAdditionally, the Mann-Whitney U test was used to compare the predictions for potential therapeutic targets, yielding highly significant P values (P = .00001). This test further supported the identification of key viral genes as potential therapeutic targets.\n\nConfidence intervals were also considered in the presentation of data, with the mean of three independent experiments reported alongside 99% confidence intervals. This approach provides a clear indication of the variability and reliability of the results.\n\nOverall, the statistical analyses and the use of confidence intervals ensure that the claims of superiority and effectiveness of the methods and treatments are well-supported and statistically significant.",
  "evaluation/availability": "Not enough information is available."
}