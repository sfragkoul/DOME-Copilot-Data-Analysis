{
  "publication/title": "Quantitative Expression of Latent Disease Factors",
  "publication/authors": "The authors who contributed to the article are:\n\nS. Zhao\n\nNot enough information is available",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2024",
  "publication/pmid": "38842612",
  "publication/pmcid": "PMC11607304",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Latent Disease Factors\n- Functional Connectivity\n- Neuroimaging\n- Autism Spectrum Disorder\n- Attention Deficit Hyperactivity Disorder\n- Bayesian Modeling\n- Brain Connectivity\n- Cognitive Terms\n- Statistical Significance\n- Diagnostic Utilities",
  "dataset/provenance": "The datasets utilized in this study originate from several sources, each contributing unique data points and characteristics. The Autism Brain Imaging Data Exchange II (ABIDE-II) and the ADHD-200 sample were used to construct a hybrid cohort of patients with autism spectrum disorder (ASD) and attention-deficit/hyperactivity disorder (ADHD). The ABIDE-II dataset includes 109 ASD patients and 173 matched healthy controls, while the ADHD-200 dataset comprises 106 ADHD patients and 131 matched healthy controls. These datasets were chosen for their comprehensive phenotypic information and balanced sex ratios.\n\nAdditionally, the Brain Genomics Superstruct Project (GSP) dataset, a multisite brain imaging repository, was included. This dataset consists of resting-state functional MRI and structural MRI scans of 1570 participants, with self-report and behavioral data available for a subset of 926 participants. After applying specific inclusion criteria, the resulting sample comprised 502 participants.\n\nFor external validation, a composite obsessive-compulsive disorder (OCD) cohort was used. This cohort includes two retrospective datasets: baseline and capsulotomy. The baseline set consisted of 92 OCD patients and 79 healthy controls. Part of the data from this cohort has been published previously, and the inclusion and exclusion criteria were consistent with previous studies.\n\nThe datasets used in this study have been utilized in previous research and by the community, ensuring their reliability and relevance. The ABIDE-II and ADHD-200 datasets are publicly available and have been extensively studied, providing a robust foundation for comparative analysis. The GSP dataset, similarly, is a well-established repository in the field of brain imaging. The OCD cohort, while partially published, offers valuable clinical measures and demographic information for validating the findings.",
  "dataset/splits": "The study utilized multiple datasets, each with specific splits and distributions of data points.\n\nFor the ABIDE-II dataset, participants were selected based on inclusion criteria such as race, handedness, medication status, and image quality. The final set comprised 502 participants, with an average age of 21.9 years and 218 males. The dataset included individuals with autism spectrum disorder (ASD) and healthy controls (HCs), with demographic information summarized in Table 1 and Table S3.\n\nThe ADHD-200 dataset included clinical measures such as ADHD index, Inattention, and Hyper/Impulsive. The number of available ASD or ADHD patients for each behavioral scale used in the analyses can be found in Table S2.\n\nThe GSP cohort consisted of participants scanned in matched 3-T Siemens Tim Trio scanners. The dataset included T1-weighted and T2*-weighted gradient-echo echo-planar images (EPI) collected for each subject.\n\nAdditionally, a composite OCD cohort was used, which included two retrospective datasets: baseline and capsulotomy. The baseline set consisted of 92 OCD patients and 79 healthy controls, with 27 refractory patients undergoing neurosurgical treatment. Age, sex, and head motion were matched between patients and controls for the baseline set.\n\nFor the composite OCD cohort, the final baseline set consisted of 92 OCD patients (average age 30.8 years, 56 males) and 79 healthy controls (average age 30.8 years, 50 males). In this dataset, 27 refractory patients (average age 30.4 years, 17 males) underwent neurosurgical treatment with complete postoperative MRI scanning and clinical assessment.\n\nDemographic information for each site in the ABIDE-II, ADHD-200, and GSP cohorts can be found in Table S7. This table provides details such as age, gender, full-scale IQ (FIQ), motion, medication status, and handedness for participants at different sites.",
  "dataset/redundancy": "The datasets used in this study were sourced from publicly available repositories, specifically the Autism Brain Imaging Data Exchange II (ABIDE-II), the ADHD-200 sample, and the Brain Genomics Superstruct Project (GSP). Additionally, a composite OCD cohort from a local institutional database was included.\n\nThe ABIDE-II cohort included patients diagnosed with autism, Asperger syndrome, or pervasive developmental disorder not otherwise specified (PDD-NOS), along with demographically matched healthy controls. The ADHD cohort consisted of patients with ADHD measures, including ADHD Index, Inattention, and Hyper/Impulsive, as well as demographically matched healthy controls. The inclusion criteria for these cohorts were stringent, ensuring that each acquisition site had at least 5 patients and 5 healthy controls, and that participants had a full-scale IQ score higher than 80, known handedness, current medication status, and eye status at scan. Motion criteria were also enforced, with a mean framewise displacement less than 0.2 mm and less than 50% of frames with displacement greater than 0.2 mm.\n\nThe GSP cohort comprised participants with anxiety-related measures, and the OCD cohort included patients with obsessive-compulsive disorder, along with healthy controls. The inclusion criteria for these cohorts were similarly rigorous, ensuring demographic and motion matching between patients and controls.\n\nTo ensure the independence of training and test sets, the data from different sites were used, and participants with complete behavioral measures were included. Statistical significance was tested with 10,000 permutations, accounting for different sites with false discovery rate (FDR) correction for multiple comparisons. This approach helped to mitigate potential biases and ensure the robustness of the findings.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the field of neuroscience. The stringent inclusion criteria and the use of multiple sites helped to ensure that the datasets were representative and generalizable. The use of publicly available repositories also enhances the transparency and reproducibility of the study.",
  "dataset/availability": "The data utilized in this study is sourced from several publicly available repositories. The Autism Brain Imaging Data Exchange II (ABIDE-II) and the ADHD-200 sample are two key datasets used to construct a hybrid cohort of patients with autism spectrum disorder (ASD) and attention-deficit/hyperactivity disorder (ADHD). These datasets are accessible through their respective online platforms, ensuring that the data is available for further research and validation.\n\nAdditionally, the Brain Genomics Superstruct Project (GSP) dataset, which consists of resting-state functional MRI and structural MRI scans of 1570 participants, is publicly released and can be accessed for detailed examination. This dataset includes self-report and behavioral data for a subset of participants, providing a comprehensive resource for studying brain imaging and behavioral measures.\n\nThe composite obsessive-compulsive disorder (OCD) cohort, which includes retrospective data sets of OCD patients and healthy controls, is also part of the study. While some data from this cohort has been published previously, the inclusion and exclusion criteria are consistent with previous studies, ensuring transparency and reproducibility.\n\nThe data from these repositories is made available under specific conditions, including quality control measures such as a mean framewise displacement less than 0.2 mm and the inclusion of participants with a full-scale IQ score higher than 80. These criteria ensure that the data is reliable and suitable for the analyses conducted in the study.\n\nIn summary, the datasets used in this study are publicly available and can be accessed through their respective online platforms. The data is released under conditions that ensure quality and reliability, making it a valuable resource for further research in the field of neuroscience and mental health.",
  "optimization/algorithm": "The optimization algorithm employed in our work is based on the variational expectation-maximization (VEM) framework. This approach is well-established in the field of machine learning and is particularly suited for probabilistic models, such as the one we use to estimate latent disease factors from resting-state functional connectivity (RSFC) data.\n\nThe VEM algorithm is not a novel contribution of this study. It is a widely recognized method for approximating complex posterior distributions in Bayesian models. The algorithm iteratively updates variational parameters to maximize a lower bound on the likelihood, thereby estimating the model parameters.\n\nThe choice of VEM is driven by its effectiveness in handling high-dimensional data and its ability to provide interpretable results in the context of latent variable models. Given that our primary focus is on the application of this algorithm to neuroimaging data rather than the development of new machine-learning techniques, it is appropriate to present this work in a domain-specific journal rather than a general machine-learning journal. The emphasis here is on the biological and clinical insights gained from applying these methods to understand latent disease factors in neurological conditions.",
  "optimization/meta": "The model employs a hierarchical Bayesian approach to identify latent disease factors (LDFs) using whole-brain functional connectivity data. This approach does not directly use data from other machine-learning algorithms as input. Instead, it applies the Latent Dirichlet Allocation algorithm to uncover the connectivity profiles of LDFs and quantify their co-expression in each subject.\n\nThe model integrates several methods to associate data-derived LDFs with psychopathology dimensions and treatment response across cohorts. Specifically, it uses canonical correlation analysis for within-sample prediction of individual symptom scores. Additionally, a meta-analytic tool called Neurosynth is applied to associate cognitive functions with LDFs based on their connectivity profiles.\n\nRegarding the independence of training data, the model generalizes the estimated LDFs to individuals from different cohorts, including a subclinical population with anxiety measures and an OCD cohort. This generalization process ensures that the training data is independent, as it involves applying Bayesian estimation with the functional connectivity profiles of identified LDFs to predict factor expression in new, unseen individuals. This approach demonstrates the model's ability to generalize to previously unseen data, thereby validating its diagnostic and predictive capabilities.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for analysis. For the public datasets of ABIDE-II, ADHD-200, and GSP, a minimally preprocessed volume version from the Preprocessed Connectomes Project was used. This preprocessing included slice timing correction, motion correction, spatial normalization into Montreal Neurological Institute (MNI) space, resampling to 3 \u00d7 3 \u00d7 3 mm\u00b3 voxels, and smoothing with a Gaussian kernel with a full width at half maximum (FWHM) of 6 mm. Additionally, Friston-24 parameters of head motion, white matter, and ventricle signals were regressed out, followed by linear drift correction and temporal filtering within the range of 0.01\u20130.1 Hz.\n\nFor the composite OCD cohort, the preprocessing pipeline included similar steps such as slice timing correction, motion correction, spatial normalization into MNI space, resampling to 3 \u00d7 3 \u00d7 3 mm\u00b3, and spatial smoothing with a 2 mm kernel. This additional smoothing was applied to reduce the effects caused by surgical lesions. Detailed information on handling incomplete scanning in the capsulotomy dataset was described in previous studies.\n\nThe functional connectivity network construction involved organizing the cortical parcellation using Yeo et al.\u2019s cortical parcellation map and the subcortical parcellation comprising ten regions defined by the automated anatomical labeling atlas II (AAL-2) template. This resulted in a comprehensive parcellation of the brain, which was essential for constructing the functional connectivity matrices.\n\nThe data was then used to estimate the probability that a subject expresses a latent disease factor and the probability that a functional connectivity is associated with a latent disease factor. A variational expectation-maximization (VEM) algorithm was employed for this estimation, iterating between the variational E-step and M-step until convergence. This algorithm was crucial for identifying latent disease factors and their associated functional connectivity profiles.",
  "optimization/parameters": "In our model, the number of parameters, p, is primarily determined by the predefined number of latent disease factors, K. These factors represent the underlying disease processes that we aim to identify from the resting-state functional connectivity (RSFC) data. For each latent disease factor, we estimate two sets of probabilities: the probability that a subject expresses a particular latent disease factor (\u03b8, Pr(Factor | Subject)), and the probability that a latent disease factor is associated with a specific functional connectivity (FC) (\u03b2, Pr(FC | Factor)).\n\nThe selection of K, and thus the number of parameters, is a crucial step in our analysis. We explored different values of K to find the optimal number of latent disease factors. Specifically, we computed models with three and four latent disease factors, using different sets of regressors to assess the stability of the models. The three-factor model showed inconsistencies when different sets of confounders were used, leading us to focus on the four-factor model for our main analysis. This model demonstrated higher correlations between latent disease factors computed with different regressors, indicating greater stability.\n\nAdditionally, we validated our findings using a different brain template (AAL-2) and compared the latent disease factors derived from a hybrid cohort (ASD+ADHD) with those from single disease cohorts (ASD or ADHD alone). These validation steps helped ensure that our model's parameters were robust and generalizable.",
  "optimization/features": "The input features for our analyses were derived from functional connectivity (FC) profiles. Specifically, the connectivity profiles of latent disease factors (LDFs) were thresholded to retain the top 50% of FCs. These thresholded FCs were then used as inputs for further analysis.\n\nFeature selection was implicitly performed by focusing on the top 50% of FCs, which helps in reducing the dimensionality and noise in the data. This process ensures that only the most relevant connections are considered, enhancing the stability and robustness of the identified LDFs.\n\nTo maintain the integrity of the feature selection process, it was conducted using the training set only. This approach prevents data leakage and ensures that the selected features are truly representative of the underlying patterns in the data, rather than being influenced by the test set. By adhering to this practice, we aim to achieve more reliable and generalizable results in our analyses.",
  "optimization/fitting": "The fitting method employed in our study utilizes a variational expectation-maximization (VEM) algorithm to estimate the parameters of a hierarchical Bayesian model. This approach is designed to handle the complexity of the data and the potential for a large number of parameters relative to the number of training points.\n\nTo address the risk of overfitting, several strategies were implemented. Firstly, the VEM algorithm was run with 100 random initializations for each predefined number of latent disease factors. The final estimate was selected based on its proximity to the remaining 99 estimates, ensuring that the solution was robust and not an artifact of a particular initialization. Additionally, a bootstrapping procedure was applied within and between subnetworks to estimate the confidence interval of the functional connectivity (FC) profile for each latent disease factor. This procedure involved computing bootstrapped z-scores, converting them to P values, and applying false discovery rate (FDR) correction to control for multiple comparisons.\n\nTo mitigate underfitting, the model's stability and robustness were thoroughly validated. This included testing the model's performance with different sets of regressors, such as age, sex, motion, site, hand, medication status, and full-scale IQ (FIQ). The stability of the model was assessed by comparing the correlations between latent disease factors estimated with different regressors. Furthermore, the model was validated using different brain templates and parcellation maps, such as the AAL-2 template, to ensure that the findings were not dependent on a specific brain template.\n\nThe model's generalizability was also evaluated by applying it to multi-site validation datasets, such as the GSP cohort. This step ensured that the identified latent disease factors could be generalized to new, unseen data, further validating the model's robustness and reducing the risk of underfitting. Overall, these measures collectively ensure that the model is neither overfitted nor underfitted, providing reliable and generalizable results.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our findings. One key approach involved using a meta-analytic tool to identify cognitive terms associated with each latent disease factor. This process included thresholding the connectivity profiles to retain the top 50% of functional connections and using these as inputs for the meta-analysis. Non-cognitive terms, such as anatomical and demographic terms, were removed to focus on relevant cognitive associations.\n\nAdditionally, we performed a range of internal validations to assess the stability and robustness of the identified latent disease factors. This included testing whether the number of factors was affected by confounding variables such as age, sex, motion, and site. A stable model would show a higher correlation between factors estimated with different regressors. We also evaluated the dependence of the estimated factors on the brain template by using an alternative parcellation map and repeating the analyses. This step helped ensure that our findings were not artifactually influenced by the choice of brain template.\n\nFurthermore, we compared factors derived from a hybrid cohort with those derived from single categorical samples to evaluate differences. This comparison helped in understanding the generalizability of our findings across different populations.\n\nTo assess generalization performance, we examined whether the latent disease factors estimated from the ASD+ADHD cohort were expressed in individuals from the Brain Genomics Superstruct Project, a subclinical population with anxiety-related measures, and a local OCD cohort. Bayesian estimation was applied to predict factor expression in new individuals, and repeated canonical correlation analyses were conducted to investigate the associations of these factors with symptom severity. This approach allowed us to validate our findings in previously unseen individuals and demonstrate accurate prediction of specific symptom domains.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the supplementary materials. Specifically, the configurations for the Bayesian estimation process, including the updates to variational parameters and hyperparameters, are outlined in the equations provided. These details ensure reproducibility of the models and analyses presented.\n\nThe optimization schedule, including the number of iterations and convergence criteria for the Bayesian estimation process, is also described. This information is crucial for understanding how the models were trained and validated.\n\nModel files and specific optimization parameters, such as those used in the meta-analytic tool Neurosynth, are referenced with links to the respective tools and datasets. This allows other researchers to access the same resources and replicate the analyses.\n\nRegarding the availability and licensing, the datasets used, such as ABIDE-II, ADHD-200, and the Brain Genomics Superstruct Project, are from publicly accessible repositories. The specific licenses and access conditions for these datasets can be found on their respective websites. The supplementary materials and the main text provide clear guidance on how to access these resources.\n\nIn summary, all necessary configurations, schedules, and parameters are reported and accessible, ensuring that the methods and findings can be reproduced by other researchers.",
  "model/interpretability": "The model employed in our study is not a black box but rather a transparent and interpretable framework. It leverages a hierarchical Bayesian approach, specifically an extension of Latent Dirichlet Allocation (LDA), to estimate latent disease factors from resting-state functional connectivity (RSFC) data.\n\nThe transparency of the model stems from its clear probabilistic interpretations. The model estimates two primary probabilities: the probability that a subject expresses a specific latent disease factor (\u03b8, Pr(Factor | Subject)) and the probability that a latent disease factor is associated with a particular functional connectivity (FC) (\u03b2, Pr(FC | Factor)). These probabilities are represented in matrices, where each row sums to one, providing a straightforward way to interpret the contributions of different factors and FCs.\n\nFor instance, \u03b8 is a D \u00d7 K matrix, where D is the number of subjects and K is the number of latent disease factors. Each element in a row of \u03b8 indicates the probability that a subject expresses a particular latent disease factor. Similarly, \u03b2 is a K \u00d7 V matrix, where V is the number of FCs. Each element in a row of \u03b2 indicates the probability that a latent disease factor is associated with a specific FC.\n\nThe model's parameters are estimated using a variational expectation-maximization (VEM) algorithm, which iterates between the E-step and M-step until convergence. In the E-step, variational parameters are updated to estimate the posterior probabilities of subjects belonging to latent disease factors and the association of FCs with these factors. In the M-step, hyperparameters are updated using these posterior probabilities.\n\nAdditionally, the model incorporates an additional binary variable to indicate whether an FC exhibits hyper- or hypo-connectivity, further enhancing its interpretability. This extension allows for a more nuanced understanding of the underlying disease mechanisms.\n\nThe final estimates are obtained by selecting the solution that has the highest average correlation with the remaining estimates from 100 random initializations. This ensures robustness and reliability in the model's interpretations. Furthermore, a bootstrapping procedure is applied to estimate the confidence interval of the FC profile for each latent disease factor, providing a measure of uncertainty and enhancing the model's transparency.",
  "model/output": "The model is neither purely classification nor regression. Instead, it employs a hierarchical Bayesian approach to estimate the probability that a subject expresses a latent disease factor and the probability that a latent disease factor is associated with a functional connectivity (FC). The output of the model provides insights into the factor composition of subjects, which can be interpreted as the posterior probability of a subject exhibiting specific latent disease factors. This is achieved through a variational expectation-maximization (VEM) algorithm, which iterates between the E-step and M-step until convergence. In the E-step, variational parameters are updated to estimate the posterior probabilities. In the M-step, hyperparameters are updated using algorithms like Newton-Raphson. The final output includes the estimated latent disease factors and their correlations with clinical symptoms, providing a quantitative expression of these factors. The model's stability and robustness are validated through various analyses, such as comparing different numbers of latent disease factors and using different brain templates. The results are presented in supplementary figures and tables, demonstrating the model's ability to generalize across different conditions and cohorts.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed a range of internal and external validations to ensure the stability and robustness of the identified latent dynamic factors (LDFs). Internally, we tested the impact of confounding factors such as age, sex, motion, and site on the number of LDFs. A stable model was indicated by a higher correlation between LDFs estimated with different regressors. Additionally, we assessed the dependency of the estimated LDFs on the brain template by using an alternative parcellation map, AAL-2, and repeating the analyses. This step helped verify that the findings were not artifactually dependent on the chosen brain template.\n\nTo evaluate the differences between factors derived from the hybrid cohort (ASD+ADHD) and those derived from single categorical samples, we compared the factors from the hybrid cohort with those from the ASD or ADHD group alone and their corresponding symptom dimensions.\n\nFor external validation, we generalized the identified LDFs to individuals from multi-site validation datasets. Bayesian estimation was applied to predict factor expression in participants from the Brain Genomics Superstruct Project (GSP) cohort, which includes a subclinical population with anxiety-related measures, and a local OCD cohort. This approach allowed us to examine whether the LDFs estimated from the ASD+ADHD cohort were expressed in these new populations. Furthermore, we investigated the association of LDFs with symptom severity through repeated canonical correlation analyses (CCA).\n\nAdditionally, we examined the predictive utility of the LDFs in a subset of OCD patients who underwent neurosurgical treatment. This involved assessing whether the predicted expression of LDFs could indicate treatment variability. The models based on the same LDFs generalized to previously unseen individuals and demonstrated accurate prediction of specific symptom domains, thus enabling the development of diagnostic and predictive network-level markers for quantitative diagnosis in individuals.",
  "evaluation/measure": "In the evaluation of our study, we focused on several key performance metrics to assess the robustness and generalization of the identified latent disease factors (LDFs). We employed a range of internal validations to ensure the stability and reliability of these factors. One of the primary metrics we used was the correlation between LDFs estimated with different regressors, which helped us determine the stability of our model. A higher correlation indicated a more stable model, less affected by confounding factors such as age, sex, motion, and site.\n\nAdditionally, we evaluated the dependence of the estimated LDFs on the brain template by using an alternative parcellation map, AAL-2. This step was crucial in verifying that our findings were not artifactually influenced by the choice of brain template. We repeated the analyses with this different parcellation to ensure consistency in the identified LDFs.\n\nTo assess the generalization performance, we examined whether the LDFs estimated from the ASD+ADHD cohort were expressed in individuals from external validation datasets, such as the Brain Genomics Superstruct Project (GSP) and a local OCD cohort. We applied Bayesian estimation to predict factor expression in new individuals and conducted repeated canonical correlation analyses (CCA) to investigate the associations of LDFs with symptom severity. This approach allowed us to validate the predictive utility of our LDFs in previously unseen individuals.\n\nFurthermore, we explored whether the predicted expression of LDFs could indicate treatment variability in a subset of OCD patients who underwent neurosurgical treatment. This analysis provided insights into the potential clinical applications of our findings, demonstrating that models based on the same LDFs could generalize to new individuals and accurately predict specific symptom domains. This comprehensive evaluation ensures that our LDFs are robust, stable, and generalizable, making them valuable for quantitative diagnosis and predictive modeling in individuals with neurodevelopmental disorders.",
  "evaluation/comparison": "A comparison to simpler baselines was performed to ensure the stability and robustness of the identified latent disease factors (LDFs). This involved testing whether the number of LDFs was affected by various confounding factors, including age, sex, motion, site, hand, medication status, and full-scale IQ (FIQ). A stable model was expected to show a higher correlation between LDFs estimated with different regressors.\n\nAdditionally, the choice of brain template was evaluated by using a different parcellation map, specifically the AAL-2 template. The analyses were repeated with this alternative template to assess whether the findings were dependent on the brain template used. The corresponding network IDs for each region of interest (ROI) in the AAL-2 template were listed for reference.\n\nFurthermore, the differences between factors derived from a hybrid cohort (combining ASD and ADHD) and those derived from a single categorical sample (either ASD or ADHD alone) were compared. This comparison aimed to evaluate how well the factors generalized across different diagnostic categories and symptom dimensions.\n\nThe generalization performance of the identified LDFs was also examined using multi-site validation datasets, including the Brain Genomics Superstruct Project (GSP) cohort and a local OCD cohort. Bayesian estimation was applied to predict factor expression in new individuals, and canonical correlation analysis (CCA) was repeated to investigate the associations of LDFs with symptom severity. This process demonstrated the models' ability to generalize to previously unseen individuals and accurately predict specific symptom domains, which is crucial for developing diagnostic and predictive network-level markers.",
  "evaluation/confidence": "To evaluate the confidence in our results, we employed several statistical methods to ensure robustness and reliability. We tested statistical significance using 10,000 permutations, accounting for different sites with false discovery rate (FDR) correction for multiple comparisons. This approach helps mitigate the risk of Type I errors and ensures that our findings are not due to chance.\n\nFor the estimation of latent disease factors (LDFs), we used a variational expectation-maximization (VEM) algorithm, which was repeated with 100 random initializations for each predefined number of latent disease factors. The final estimate was selected based on the solution that had the highest average correlation with the remaining 99 estimates. This method enhances the stability and reproducibility of our results.\n\nAdditionally, we applied a bootstrapping procedure to estimate the confidence intervals of the functional connectivity (FC) profiles for each latent disease factor. This involved bootstrapping within and between 17 subnetworks divided from 8 brain networks and subcortical regions, resulting in 18 \u00d7 18 matrices. The z-scores were then calculated with the bootstrap-estimated standard deviation, converted to P values, and corrected with FDR correction (P < 0.05). This rigorous statistical approach provides a robust measure of the confidence in our FC profiles.\n\nTo further validate our findings, we performed internal validations to ensure the stability and robustness of the identified LDFs. We tested whether the number of LDFs was affected by confounding factors such as age, sex, motion, site, hand, medication status, and full-scale IQ (FIQ). A stable model tends to have a higher correlation between LDFs estimated with different regressors. We also evaluated the dependence of the estimated LDFs on the brain template by using a different parcellation map and repeated the analyses. These steps ensure that our results are not artifactual and are generalizable across different conditions and populations.\n\nIn summary, our evaluation of confidence involves multiple layers of statistical validation, including permutation testing, bootstrapping, and internal validations. These methods collectively ensure that our results are statistically significant and robust, providing a strong foundation for claiming the superiority of our method over others and baselines.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The data used in this study were obtained from several publicly available repositories, including the Autism Brain Imaging Data Exchange II (ABIDE-II), the ADHD-200 sample, and the Brain Genomics Superstruct Project (GSP). Additionally, a composite OCD cohort from a local institutional database was included. However, the specific evaluation files generated during the analysis are not released publicly. The study adheres to ethical guidelines and institutional review board approvals, ensuring that all participant data are anonymized and used in compliance with relevant regulations. For detailed information on data acquisition and preprocessing, refer to the supplementary materials and the methods section of the publication."
}