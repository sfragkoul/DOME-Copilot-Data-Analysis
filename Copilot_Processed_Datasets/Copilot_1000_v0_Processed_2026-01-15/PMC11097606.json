{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\nFranziska E. Hildesheim, who was involved in data curation, formal analysis, investigation, methodology, validation, visualization, and writing the original draft and reviewing & editing.\n\nAnja Ophey, who contributed to data curation, formal analysis, investigation, and writing\u2014review & editing.\n\nAnna Zumbansen, who was involved in conceptualization, data curation, formal analysis, investigation, methodology, and writing\u2014review & editing.\n\nThomas Funck, who contributed to data curation, formal analysis, investigation, methodology, visualization, and writing\u2014review & editing.\n\nTibor Schuster, who was involved in data curation, formal analysis, investigation, methodology, visualization, and writing\u2014review & editing.\n\nKeith Jamison, who contributed to formal analysis, investigation, methodology, software, visualization, and writing\u2014review & editing.\n\nAmy Kuceyeski, who was involved in methodology, software, and writing\u2014review & editing.\n\nAlexander Thiel, who contributed to conceptualization, data curation, formal analysis, funding acquisition, investigation, methodology, project administration, supervision, validation, and writing\u2014review & editing.",
  "publication/journal": "Neurorehabilitation and Neural Repair",
  "publication/year": "2023",
  "publication/pmid": "38602161",
  "publication/pmcid": "PMC11097606",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Stroke\n- Aphasia\n- Language recovery\n- Connectivity disruption\n- Random Forest\n- Machine learning\n- Neuroimaging\n- Brain connectivity\n- Predictive modeling\n- Post-stroke rehabilitation\n- Gray matter regions\n- Language function\n- Structural connectivity\n- Predictive factors\n- Lesion volume\n- Non-verbal cognitive function\n- Language expression\n- Language comprehension\n- Cardiovascular risk factors\n- Functional outcomes",
  "dataset/provenance": "The dataset used in this study was sourced from a group of 76 stroke patients. The data includes demographic and clinical information, as well as imaging data from 74 of these patients, who underwent 3T MR scans using the ADNI protocol. For two patients, computed tomography (CT) scans were acquired instead. The imaging data includes anatomical T1-weighted images and T2-weighted fluid-attenuated inversion recovery (FLAIR) sequences. The dataset also includes lesion masks that were hand-drawn and adjudicated by stroke neurologists. These masks were normalized to the MNI152 template using a combination of linear and non-linear transformations. The dataset further includes connectivity disruption scores calculated using the NeMo tool, which superimposes individual infarct masks onto a DTI tractogram reference set derived from healthy control subjects. The dataset has been used to predict language function in stroke patients using a Random Forest machine-learning algorithm. The data supporting this study can be made available upon reasonable request to the corresponding author. The Network Modification tool used for model-based connectivity analysis in this study is an open-access online tool.",
  "dataset/splits": "The dataset was split into two main parts: a training sample and a test sample. For each decision tree, a bootstrapped training sample was drawn from the data pool, comprising by default 2/3 of the whole patient sample. The remaining 1/3 of patients was used as the test sample for internal validation. This means that approximately 51 patients were used for training, while the remaining 25 patients were used for testing. The algorithm predicts the test data using the decision trees grown on the training data. The predictions of each individual regression tree are then aggregated.",
  "dataset/redundancy": "The dataset used in this study consisted of 76 stroke patients, with 41% being female. The mean age at stroke was 63.1 years, and the median normalized lesion volume was 63.4 cm\u00b3. The dataset included various demographic, clinical, and brain-structural variables.\n\nFor the Random Forest prediction models, the dataset was split into training and test sets. Specifically, for each decision tree within the Random Forest, a bootstrapped training sample was drawn from the data pool, comprising by default 2/3 of the whole patient sample. The remaining 1/3 of patients served as the test sample for internal validation. This process ensures that the training and test sets are independent, as the test set is not used in the training of the decision trees.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of stroke and language recovery. The inclusion of a diverse set of predictor variables, such as connectivity disruption scores of language-relevant brain regions, demographic information, and clinical measures, provides a comprehensive basis for predicting language function post-stroke. The use of bootstrapping and the division of the dataset into training and test sets help to mitigate overfitting and ensure the robustness of the models.",
  "dataset/availability": "The data supporting this study can be made available upon reasonable request to the corresponding author. This means that the dataset is not publicly released in a forum. The data is not open-access, and there is no specific license associated with it. The availability of the data is controlled and managed by the corresponding author, who will evaluate requests for data access on a case-by-case basis. This approach ensures that the data is used responsibly and ethically, aligning with the principles of data sharing in scientific research.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the Random Forest algorithm. This is a well-established supervised learning method that falls under the ensemble learning category. The Random Forest algorithm is not new; it has been extensively used and validated in various fields, including medical research.\n\nThe Random Forest algorithm was chosen for its robustness and ability to handle complex datasets with multiple predictor variables. It operates by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees. This approach helps to improve the predictive accuracy and control over-fitting compared to using a single decision tree.\n\nThe decision to use the Random Forest algorithm in our study was driven by its effectiveness in capturing the independent and complementary predictive effects of each input variable without making strong assumptions about the relationships between predictors. This is particularly useful in medical research, where datasets often contain a mix of demographic, clinical, and structural variables.\n\nGiven that the Random Forest algorithm is a widely recognized and established method, it was not necessary to publish it in a machine-learning journal. Instead, our focus was on applying this algorithm to predict language function in stroke patients, which is a novel application in the context of neurorehabilitation and neural repair. The algorithm's implementation and results are thoroughly described in our publication, ensuring transparency and reproducibility for other researchers in the field.",
  "optimization/meta": "The model employed in this study does not use data from other machine-learning algorithms as input. Instead, it relies on a variety of demographic, clinical, and brain-structural variables. These variables include connectivity disruption scores of specific brain regions, age at stroke, sex, education, lesion volume, days since stroke, initial non-verbal cognitive ability, and baseline language scores.\n\nThe Random Forest algorithm is the core machine-learning method used. This approach is based on ensemble learning, where multiple decision trees are combined to enhance prediction accuracy. Each decision tree within the Random Forest is trained on a bootstrapped sample of the data, ensuring that the training data for each tree is independent. This independence is crucial for the robustness and generalizability of the model.\n\nThe Random Forest model estimates the importance of each predictor variable by calculating the percentage increase in prediction error when a variable is omitted. This method avoids issues of non-normality and collinearity, which are common concerns in traditional regression models. The robustness of the models was assessed by performing 500 repetitions of fitting 1,000 decision trees, ensuring that the standard deviation of the total variance explained was less than 0.05.\n\nIn summary, the model is a standalone Random Forest algorithm that does not incorporate outputs from other machine-learning methods. The training data for each decision tree within the Random Forest is independent, ensuring the reliability of the predictions.",
  "optimization/encoding": "For the machine-learning algorithm, several demographic, clinical, and brain-structural variables were selected and encoded for inclusion into the multivariable Random Forest prediction models. These variables included connectivity disruption scores of specific gray matter regions, both in the left and right hemispheres, as well as residual hemispheric regions. The connectivity disruption was quantified using Change in Connectivity (ChaCo) scores, which measure the ratio between the total number of fibers connecting a given gray matter region to the rest of the brain and the number of those fibers passing through an area of infarct.\n\nAdditionally, demographic variables such as age at aphasia onset, sex, and education level were included. Clinical variables encompassed the number of days between stroke and baseline assessment, initial non-verbal cognitive ability, and lesion volume. Lesion volume was assessed after normalization to MNI space to account for variance in total brain volume between subjects. For models predicting language function at 30-day follow-up, the baseline language score of the respective test and the treatment arm of the patient (rTMS, tDCS, or sham) were also included as predictor variables.\n\nThe data was pre-processed to ensure compatibility with the Random Forest algorithm. This involved normalizing lesion volumes to MNI space and dilating labels of interest in the Automated Anatomical Labeling (AAL) atlas by 1mm. This dilation ensured that the Network Modification tool captured streamlines ending at the border between white matter and gray matter. The ChaCo scores were calculated to reflect the estimated connectivity disruption experienced by a given gray matter region, with higher scores indicating greater disruption.\n\nThe Random Forest algorithm itself is based on the concept of ensemble learning, where the predictions of multiple decision trees are combined to increase prediction accuracy. Each decision tree consists of a root node, branches, and leaf nodes, with each node representing a predictor variable and each branch representing a binary split option of that variable. At each node, the algorithm searches for the best split variable within a subset of the predictor variables. For each decision tree, a bootstrapped training sample is drawn from the data pool, comprising two-thirds of the whole patient sample, with the remaining one-third used as the test sample for internal validation. The predictions of each individual regression tree are then aggregated to produce the final model output.",
  "optimization/parameters": "In our study, a total of 34 predictor variables were included in the Random Forest prediction models. These variables encompassed a range of demographic, clinical, and brain-structural factors. Specifically, the model considered age at stroke, sex, education, lesion volume, days since stroke, initial non-verbal cognitive ability, and connectivity disruption scores for 13 left-hemispheric regions of interest (ROIs) and their right-hemispheric homologues. Additionally, for models predicting language function at 30-day follow-up, baseline language scores and the treatment arm of the patient were also included.\n\nThe selection of these predictor variables was guided by their known or suspected relevance to language function post-stroke, as supported by previous research and clinical expertise. The connectivity disruption scores were calculated using the Change in Connectivity (ChaCo) metric, which assesses the ratio of fibers connecting a given gray matter region to the rest of the brain and those passing through the infarct area. This metric was chosen for its ability to quantify structural connectivity disruption, which is crucial for understanding language impairment after stroke.\n\nThe robustness of the Random Forest models was ensured through extensive validation. We performed 500 repetitions of fitting 1,000 decision trees, and the model was deemed robust if the standard deviation of the total variance explained between the 500 Random Forests was less than 0.05. This rigorous approach helped to validate the reliability and generalizability of our findings.",
  "optimization/features": "In the optimization process, a total of 34 predictor variables were used as input features for the Random Forest prediction models. These features encompassed a mix of demographic, clinical, and brain-structural variables. The selection of these variables was not performed using the training set alone but was rather based on a combination of literature review and domain knowledge. The variables included connectivity disruption scores of specific gray matter regions, demographic information such as age and sex, clinical data like lesion volume and time since stroke, and cognitive assessments. This approach ensured that the most relevant features were considered, enhancing the model's predictive accuracy.",
  "optimization/fitting": "The fitting method employed in this study utilized a Random Forest algorithm, which is inherently designed to handle a large number of parameters relative to the number of training points. This ensemble learning approach combines the predictions of multiple decision trees to enhance prediction accuracy and robustness.\n\nTo mitigate overfitting, the Random Forest algorithm employs several strategies. Firstly, each decision tree is trained on a bootstrapped sample of the data, which means that each tree is trained on a different subset of the data. This technique, known as bagging, helps to reduce the variance and prevent the model from memorizing the training data. Secondly, at each node of a decision tree, the algorithm considers a random subset of predictor variables, further reducing the risk of overfitting by ensuring that the trees are not too similar to each other.\n\nTo address underfitting, the Random Forest algorithm leverages the diversity of the individual decision trees. By aggregating the predictions of many trees, the model can capture complex patterns in the data that a single decision tree might miss. Additionally, the use of a large number of trees ensures that the model has sufficient capacity to learn from the data without being too simplistic.\n\nThe robustness of the Random Forest models was assessed by performing 500 repetitions of fitting 1,000 decision trees. The model was deemed robust when the standard deviation of the amount of total variance explained between the 500 Random Forests was less than 0.05. This rigorous validation process ensures that the model's performance is consistent and reliable.",
  "optimization/regularization": "In our study, we employed a Random Forest algorithm, which inherently includes regularization methods to prevent overfitting. The Random Forest approach uses ensemble learning, combining the predictions of multiple decision trees. This method reduces the risk of overfitting by averaging the results, which helps to mitigate the impact of any single decision tree that might have learned noise in the training data.\n\nAdditionally, the algorithm uses bootstrapping, where each decision tree is trained on a different subset of the data. This technique ensures that each tree is exposed to a variety of data points, further reducing the likelihood of overfitting. The use of a subset of predictor variables at each node also contributes to the robustness of the model by preventing any single variable from dominating the predictions.\n\nMoreover, the internal validation process, where one-third of the data is used as a test sample, provides an additional layer of validation. This ensures that the model's performance is evaluated on data it has not seen during training, helping to assess its generalizability and prevent overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the provided information. However, the methodology section describes the use of a Random Forest algorithm for prediction modeling, which includes details about the variable selection process and the structure of the decision trees. The specific configurations and schedules for hyper-parameter tuning are not reported.\n\nThe data supporting this study can be made available upon reasonable request to the corresponding author. This includes the demographic, clinical, and brain-structural variables used in the models. The Network Modification tool (NeMo) used for model-based connectivity analysis is an open-access online tool, which suggests that the tool itself is freely available for use. However, the exact model files and optimization parameters are not specified as being publicly accessible.\n\nFor those interested in replicating or building upon our work, reaching out to the corresponding author for detailed information on the hyper-parameter configurations and optimization parameters would be necessary. The study acknowledges the importance of making data available for further research, but specific details on the optimization process are not provided in the current context.",
  "model/interpretability": "The model employed in this study is not a blackbox. The Random Forest approach used provides transparency by showing the independent and complementary predictive effect of each individual input variable. This method avoids issues commonly found in traditional regression models, such as non-normality and collinearity.\n\nOne of the key advantages of the Random Forest model is its ability to estimate the importance of each predictor variable. This is done by calculating the percentage increase of the prediction error (mean squared error) when omitting a single predictor variable from the model. This tells us how much the model\u2019s performance improves or deteriorates when excluding one of the predictor variables. For example, if omitting the connectivity disruption score of the left middle temporal gyrus increases the prediction error by 12.8%, it indicates that this variable plays a significant role in explaining the model variance.\n\nVariable importance is reported as the percentage increase of the mean squared error (%IncMSE). A higher %IncMSE specifies a larger role of the predictor variable in explaining the model variance. In this study, a predictor variable was considered relevant if the %IncMSE was greater than or equal to 4%.\n\nAdditionally, the robustness of the Random Forest models was assessed by performing 500 repetitions of fitting 1,000 decision trees. This ensures that the model is reliable and that the results are not due to random chance. The model was deemed robust when the standard deviation of the amount of total variance explained between the 500 Random Forests was less than 0.05.\n\nIn summary, the Random Forest model used in this study is transparent and provides clear insights into the importance of each predictor variable. This transparency allows for a better understanding of the factors that influence language function post-stroke.",
  "model/output": "The model employed in our study is a regression model, specifically utilizing the Random Forest algorithm. This approach is designed to predict continuous outcomes, in this case, language function scores, rather than classifying patients into discrete categories. The Random Forest regression model aggregates the predictions of multiple decision trees to enhance prediction accuracy. Each decision tree within the forest is constructed using a bootstrapped sample of the data, and the algorithm searches for the best split variable at each node to minimize prediction error. The final output is an aggregated prediction from all the trees, providing a robust estimate of the expected language function scores for individual patients post-stroke. This method allows for the prediction of expected aphasia severity levels, which can guide patient-centered treatment decisions. The model's performance is evaluated using metrics such as mean squared error (MSE) and the percentage increase in MSE (%IncMSE) when omitting predictor variables, indicating the importance of each variable in the model.",
  "model/duration": "The execution time for the Random Forest models involved performing 500 repetitions of fitting 1,000 decision trees each. This process was designed to assess the robustness of the models, ensuring that the standard deviation of the amount of total variance explained between the 500 Random Forests was less than 0.05. The specific duration for this computation was not explicitly stated, but the methodology indicates a substantial computational effort to achieve reliable and robust predictions. The models were built using a supervised machine-learning approach, combining the predictions of multiple decision trees to enhance accuracy. Each decision tree was constructed using a bootstrapped training sample, comprising two-thirds of the patient data, with the remaining one-third used for internal validation. This ensemble learning method is known for its efficiency in handling large datasets and providing accurate predictions.",
  "model/availability": "The source code for the specific algorithm used in our study is not publicly released. However, the Network Modification tool, which was employed for model-based connectivity analysis, is available as an open-access online tool. This tool can be accessed and used by researchers and clinicians without the need for local installation or specific hardware requirements. The tool provides a quantitative metric for connectivity disruption, offering a user-friendly interface with minimal interaction and a high degree of automation. This accessibility ensures that others in the field can replicate and build upon our findings, facilitating further advancements in the understanding and treatment of post-stroke language impairments.",
  "evaluation/method": "The evaluation method employed in this study involved a robust assessment of the Random Forest models used to predict language function in stroke patients. The robustness of these models was evaluated by performing 500 repetitions of fitting 1,000 decision trees. This extensive repetition ensured that the models were thoroughly tested and validated. The model was deemed robust when the standard deviation of the amount of total variance explained between the 500 Random Forests was less than 0.05. This stringent criterion ensured that the models were stable and reliable.\n\nAdditionally, the prediction error was captured using the mean squared error (MSE). The importance of each predictor variable was determined by calculating the percentage increase of the MSE (%IncMSE) when omitting a single predictor variable from the model. A higher %IncMSE indicated a larger role of the predictor variable in explaining the model variance. A predictor variable was considered relevant if the %IncMSE was greater than or equal to 4%.\n\nThe study included a total of 76 stroke patients, with demographic and clinical data carefully collected. The patients had a mean age at stroke of 63.1 years, and the median normalized lesion volume was 63.4 cm\u00b3. The initial non-verbal MoCA score averaged 8.9 out of 23 points, and the mean raw language test scores at baseline were 15.3 for the Token Test, 18.8 for the Boston Naming Test, and 5.6 for the Semantic Verbal Fluency Test. These scores showed significant improvement over a 30-day follow-up period, as assessed by the Wilcoxon Signed Ranks test (P < .001).\n\nConnectivity disruption was measured using the Change in Connectivity (ChaCo) score, which indicated the degree of connectivity disruption in pre-defined language-relevant regions of the left hemisphere. The average ChaCo score for these regions was significantly higher than that of the residual left hemisphere, suggesting a higher degree of connectivity disruption in the language-relevant areas. Regions with the highest ChaCo scores included the left-hemispheric inferior frontal gyrus pars opercularis, rolandic operculum, insula, and supramarginal gyrus.\n\nThe Random Forest prediction models included 34 predictor variables, such as age at stroke, sex, education, lesion volume, days since stroke, initial non-verbal MoCA subscore, and connectivity disruption scores of various brain regions. The models were used to predict language function at baseline and follow-up, with additional predictor variables included for the follow-up models, such as the baseline language score and the treatment arm of the patient. This comprehensive approach ensured that the evaluation method was thorough and reliable, providing valuable insights into the prediction of language function in stroke patients.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our Random Forest models in predicting language function post-stroke. The primary metric used was the mean squared error (MSE), which quantifies the average squared difference between the predicted language scores and the actual observed scores. This metric is widely used in regression tasks and provides a clear indication of the model's predictive accuracy.\n\nTo assess the importance of individual predictor variables, we utilized the percentage increase of the MSE (%IncMSE). This metric measures how much the model's prediction error increases when a specific predictor variable is omitted, indicating the variable's contribution to the model's explanatory power. A higher %IncMSE value signifies a greater role of the predictor variable in explaining the model variance. We considered a predictor variable relevant if its %IncMSE was 4% or higher, based on established methodology.\n\nAdditionally, we evaluated the robustness of our Random Forest models by performing 500 repetitions of fitting 1,000 decision trees. The model was deemed robust if the standard deviation of the total variance explained between the 500 Random Forests was less than 0.05. This approach ensures that our models are stable and reliable, providing consistent predictions across multiple iterations.\n\nThese performance metrics are representative of those commonly used in the literature for evaluating predictive models, particularly in the context of machine learning and regression analysis. The use of MSE and %IncMSE allows for a comprehensive assessment of model accuracy and the contribution of individual predictors, ensuring that our findings are both rigorous and comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we compared our model-based approach to the gold-standard individual tractogram-based approach, specifically Diffusion Tensor Imaging (DTI). The model-based approach offers several clinical advantages. Firstly, it relies exclusively on structural T1/FLAIR images, which are routinely collected in clinical settings. This makes it more accessible and less dependent on specialized imaging techniques. Secondly, the model-based analysis is less complex and labor-intensive, requiring minimal user interaction and offering a high degree of automation. This is in contrast to individual tractography, which is more time-consuming and requires more expertise.\n\nAdditionally, our model-based approach provides a quantitative metric for connectivity disruption, rather than just the probability of a track being disconnected. This metric, known as the Change in Connectivity (ChaCo) score, offers a more nuanced understanding of the impact of stroke on brain connectivity.\n\nWe also compared our approach to simpler baselines, such as using lesion volume alone to predict language outcomes. Our results demonstrated that structural connectivity disruption of key left-hemispheric language-relevant gray matter regions had a predictive effect beyond just lesion volume. This suggests that our model-based approach provides additional valuable information for predicting post-stroke language outcomes.\n\nFurthermore, we built upon previous findings that used the Network Modification (NeMo) tool to predict clinical performance measures from structural connectivity disruption. Our study included both subacute and chronic aphasic stroke patients and modeled specific language functions, rather than just an overall aphasia score. This approach was clinically more informative, as it allowed us to predict different aspects of language separately.",
  "evaluation/confidence": "The evaluation of our study's performance metrics includes statistical significance assessments to ensure the robustness of our findings. We employed the Wilcoxon Signed Ranks test to determine the significance of changes in language test scores over a 30-day follow-up period. The results indicated a significant mean absolute change in all three language tests (P < .001), suggesting that the observed improvements are statistically significant and not due to random variation.\n\nFor the Random Forest models, we assessed the robustness by performing 500 repetitions of fitting 1,000 decision trees. The model was deemed robust when the standard deviation of the amount of total variance explained between the 500 Random Forests was less than 0.05. This approach ensures that our models are stable and reliable.\n\nAdditionally, we used the mean squared error (MSE) to capture the prediction error, and variable importance was reported as the percentage increase of the MSE (%IncMSE). A predictor variable was considered relevant if the %IncMSE was greater than or equal to 4%, based on previous methodology. This threshold helps in identifying variables that significantly contribute to the model's predictive power.\n\nThe statistical significance of our results, combined with the robustness of our models, provides a high level of confidence in the superiority of our method over traditional regression models and baselines. The use of multiple repetitions and stringent criteria for variable importance further strengthens the reliability of our findings.",
  "evaluation/availability": "The data supporting this study can be made available upon reasonable request to the corresponding author. This indicates that the raw evaluation files are not publicly released but can be accessed by contacting the corresponding author. The specific details about the licensing or terms of use for the data are not provided, so it is advisable to discuss this directly with the corresponding author when making a request."
}