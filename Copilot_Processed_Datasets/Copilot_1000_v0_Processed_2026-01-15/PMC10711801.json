{
  "publication/title": "Feature-wise Transformations for Prostate Cancer Segmentation in Multiparametric MRI",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Proc IEEE Int Symp Biomed Imaging",
  "publication/year": "2024",
  "publication/pmid": "38090633",
  "publication/pmcid": "PMC10711801",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Prostate Cancer Segmentation\n- Deep Learning\n- U-Net Architecture\n- Feature-wise Transformations\n- Biomarkers Integration\n- PSAD (Prostate-Specific Antigen Density)\n- Clinical Information\n- Medical Imaging\n- Dice Coefficient\n- Centroid Distance\n- Model Evaluation\n- Neural Networks\n- Medical AI\n- Prostate MRI\n- Segmentation Performance",
  "dataset/provenance": "The dataset used in this work is sourced from the Public Training and Development Dataset of the PI-CAI challenge. This dataset comprises 1,500 bi-parametric MRI scans, specifically T2-weighted (T2W) and Apparent Diffusion Coefficient (ADC) sequences, acquired at three different sites. Out of these, 220 cases were annotated by a human expert, and 214 of these annotated scans are provided with additional information such as PSA levels and patient age. The dataset also includes AI-derived whole-gland prostate segmentation masks, created using an algorithm validated to have a mean Dice similarity of 0.90. These 214 scans contain a total of 230 lesions, distributed across different zones and regions of the prostate. The dataset was split into independent training, validation, and testing sets to ensure robust evaluation of the models.",
  "dataset/splits": "The dataset was divided into three independent splits: training, validation, and testing. The training set consisted of 128 cases, while both the validation and testing sets contained 43 cases each. This division allowed for robust training and evaluation of the model. The dataset included bpMRI scans with annotations and clinical information such as PSA and patient age, which were crucial for the segmentation tasks. The splits ensured that the model could be trained effectively and evaluated on unseen data to assess its generalization capabilities.",
  "dataset/redundancy": "The dataset used in this study consists of 214 bpMRI scans, which were annotated by a human expert. These scans include PSA and patient age information. The dataset contains AI-derived whole-gland prostate segmentation masks, validated to have a mean Dice similarity of 0.90. The scans include 230 lesions distributed across different zones and regions of the prostate.\n\nThe dataset was split into independent training, validation, and testing sets. Specifically, the training set consists of 128 cases, the validation set has 43 cases, and the testing set also has 43 cases. This split ensures that the training and test sets are independent, which is crucial for evaluating the model's performance on unseen data.\n\nTo enforce the independence of the datasets, the scans were divided such that there is no overlap between the training, validation, and testing sets. This division helps in assessing the model's generalization capability and prevents data leakage, where information from the training set might inadvertently influence the test set.\n\nComparing this dataset to previously published machine learning datasets, the distribution of cases and the independent split are designed to provide a robust evaluation framework. The use of AI-derived segmentation masks with high Dice similarity ensures that the ground truth data is reliable, which is essential for training and evaluating segmentation models. The inclusion of clinical information such as PSA and patient age adds an additional layer of complexity and realism to the dataset, making it more representative of real-world scenarios.",
  "dataset/availability": "The dataset used in this study is the Public Training and Development Dataset from the PI-CAI challenge. This dataset consists of 1,500 bi-parametric MRI scans, specifically T2-weighted (T2W) and Apparent Diffusion Coefficient (ADC) sequences. Of these, 220 cases were annotated by a human expert, and 214 annotated scans are provided with additional information such as PSA levels and patient age. The dataset includes AI-derived whole-gland prostate segmentation masks, which were created using an algorithm validated to have a mean Dice similarity of 0.90. The 214 scans included in this study contain 230 lesions, distributed across different zones and regions of the prostate.\n\nThe dataset was split into independent training, validation, and testing sets. The training set consists of 128 cases, the validation set has 43 cases, and the testing set also has 43 cases. This split ensures that the model is trained, validated, and tested on distinct subsets of the data, promoting robust evaluation and generalization.\n\nThe dataset is publicly available, and the specific details about the license and access can be found through the PI-CAI challenge's official channels. The availability of this dataset in a public forum ensures reproducibility and allows other researchers to validate and build upon the findings presented in this study. The dataset's public availability is enforced through the challenge's guidelines and the terms of use specified by the dataset providers.",
  "optimization/algorithm": "The optimization algorithm used in our study is the Adam optimizer. This is a well-established method for stochastic optimization, known for its efficiency and effectiveness in training deep learning models. It is not a new algorithm; it was introduced by Kingma and Ba in 2014 and has since become a standard choice in the field of machine learning.\n\nThe Adam optimizer was chosen for its ability to adapt the learning rate for each parameter, which helps in achieving faster convergence and better performance. This optimizer combines the advantages of two other extensions of stochastic gradient descent: AdaGrad and RMSProp. It computes adaptive learning rates for each parameter, which makes it particularly suitable for problems that are large in terms of data and/or parameters.\n\nGiven that Adam is a widely recognized and extensively used optimization algorithm, it was not necessary to publish it in a machine-learning journal. Instead, our focus was on applying this established method to enhance the performance of our deep learning model for prostate cancer segmentation. The use of Adam allowed us to efficiently train our model, achieving significant improvements in segmentation accuracy by integrating additional biomarkers and clinical information.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model is a 3D U-Net architecture that integrates biomarkers and clinical information directly into the network. The biomarkers used include PSAD (Prostate-Specific Antigen Density) and patient age. These are integrated using feature-wise transformations (FWTs) at specific locations within the U-Net, particularly at the bottleneck layer. The training, validation, and testing datasets are independent, ensuring that the model's performance is evaluated on unseen data. The dataset consists of bpMRI scans annotated by human experts, with additional clinical information such as PSA levels and patient age. The model's performance is assessed using metrics like the Dice coefficient and centroid distance, demonstrating the effectiveness of integrating these biomarkers into the segmentation process.",
  "optimization/encoding": "The data used in this study consisted of biparametric MRI (bpMRI) scans, specifically T2-weighted (T2W) and apparent diffusion coefficient (ADC) sequences, acquired from three different sites. A total of 220 cases were annotated by a human expert, with 214 of these annotated scans including prostate-specific antigen (PSA) and patient age information. The dataset also contained AI-derived whole-gland prostate segmentation masks, created using an algorithm validated to have a mean Dice similarity of 0.90.\n\nThe 214 scans included in the study contained 230 lesions, distributed across different zones and regions of the prostate. Prostate-specific antigen density (PSAD) values were calculated by dividing the PSA by the AI-derived prostate volume.\n\nFor preprocessing, all 214 bpMRI scans were first co-registered and then resampled to a voxel spacing of 1 \u00d7 1 \u00d7 3.6 mm\u00b3. The scans were then cropped to a size of 160 \u00d7 160 \u00d7 32 around the AI-derived whole gland masks. The intensity values of the scans were scaled from the 25th percentile to the 75th percentile of the original intensity to a range of [-0.5, 0.5].\n\nThe segmentation network input was two-channel bpMRI. Random flipping along the x-axis with a 0.5 probability was applied during training to augment the data. The output logits from the network were converted to binary segmentation using the argmax function, with no additional post-processing performed.\n\nThe model used in this work was a modified version of the Dynamic U-Net from the MONAI framework, implemented using PyTorch and PyTorch Lightning. The network consisted of four encoder/decoder blocks with anisotropic strides in the z-axis to preserve the small lesion structure. Training was conducted on an NVIDIA P5000 GPU using the Adam optimizer with a batch size of 2. The training process converged around 1,500 epochs.\n\nThe evaluation of the results was quantitative, using both the Dice coefficient and centroid distance on a holdout testing set of 43 scans. The Dice coefficient measures the overlap between the predicted and ground-truth lesions, while the centroid distance measures the minimum Euclidean distance between the centers of gravity of the ground-truth lesion and all predicted lesion blobs. This complementary metric was used to better evaluate the models, especially when the Dice coefficient alone may not be informative, such as when both models completely miss the ground-truth lesion.",
  "optimization/parameters": "In our study, the number of parameters in the model varied depending on the specific feature-wise transformation (FWT) approach and the location within the network where these transformations were applied. The model architecture was based on a 3D U-Net, which is known for its efficiency in handling medical image segmentation tasks.\n\nThe FWTs were implemented in four different ways:\n\n1. Direct scalar multiplication of the PSAD value with the encoder features.\n2. Using a multi-layer perceptron (MLP) to expand the PSAD scalar into a vector of the same size as the number of feature channels, followed by channel-wise multiplication.\n3. Using an MLP to expand the PSAD scalar into a tensor of the same size as the feature, followed by element-wise multiplication.\n4. Using an MLP to expand the PSAD scalar into a tensor and concatenating it with the original feature as an additional channel.\n\nThe best-performing approach was found to be the channel-wise multiplication using an MLP, which significantly improved the mean Dice coefficient by 28% compared to the baseline model. This approach allowed for individual control of each feature channel, enhancing the model's ability to integrate biomarker information effectively.\n\nThe location within the network where the FWTs were applied also played a crucial role. The bottleneck layer of the U-Net was identified as the optimal location for adding the extra information. Features at the bottleneck are highly compressed, making it an ideal point to apply constraints from biomarker information without overpowering the model.\n\nThe selection of the number of parameters was guided by the need to balance model complexity and performance. The use of an MLP to expand the PSAD scalar into a vector or tensor added a controlled number of parameters, ensuring that the model remained efficient while leveraging the additional clinical information. The specific architecture and parameter counts were determined through experimental validation, focusing on achieving the best segmentation performance while maintaining computational efficiency.",
  "optimization/features": "The input features for the model consist of two-channel biparametric MRI (bpMRI) scans, specifically T2-weighted (T2W) and apparent diffusion coefficient (ADC) sequences. These scans were acquired from three different sites, with a total of 214 annotated scans provided along with prostate-specific antigen (PSA) and patient age information.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the focus was on integrating additional clinical biomarkers, specifically the prostate-specific antigen density (PSAD) and patient age, into the model. The PSAD values were calculated by dividing the PSA by the AI-derived prostate volume, which was obtained using a segmentation algorithm validated to have a mean Dice similarity of 0.90.\n\nThe integration of these biomarkers was done through feature-wise transformations (FWTs), which were applied in various ways to study their effects on the segmentation performance. These transformations included direct multiplication of the PSAD scalar with encoder features, using a multi-layer perceptron (MLP) to expand the PSAD scalar into a vector or tensor for more granular control over the features, and concatenating the expanded PSAD tensor with the original features as an additional channel.\n\nThe transformations were applied at different locations within the 3D U-Net architecture, specifically at the bottleneck and at the end of every encoder block. The bottleneck was found to be the more effective location for applying these transformations, as features are most compressed at this point, allowing the biomarker information to be more effectively integrated.\n\nIn summary, the model uses two primary input features from the bpMRI scans, with additional clinical information integrated through feature-wise transformations. The transformations were applied using the training set only, ensuring that the validation and testing sets remained independent for unbiased evaluation.",
  "optimization/fitting": "The model used in this work is a 3D U-Net, which is a type of convolutional neural network designed for image segmentation tasks. The architecture consists of four encoder/decoder blocks with anisotropic strides in the z-axis to preserve the small lesion structure. The input to the segmentation network is two-channel bpMRI scans, which were co-registered, resampled, and cropped around the AI-derived whole gland masks. The intensities of the scans were scaled from the 25th to the 75th percentile of the original intensity to a range of [-0.5, 0.5].\n\nThe model was implemented using PyTorch and PyTorch Lightning frameworks and trained on an NVIDIA P5000 GPU with the Adam optimizer and a batch size of 2. The training process involved random flipping along the x-axis with a 0.5 probability. Argmax was applied to the output logits to generate the final binary segmentation, and no additional post-processing was performed. The loss function used was generalized Dice loss, which is designed for imbalanced datasets by weighting each class by the inverse size of the region.\n\nTo address the potential issue of overfitting, given the relatively small number of training points (128 scans), several strategies were employed. First, the model was trained for a large number of epochs (around 1,500) to ensure convergence. Second, a holdout testing set of 43 scans was used for quantitative evaluation, which included both Dice coefficient and centroid distance metrics. This evaluation helped to ensure that the model generalized well to unseen data. Additionally, the use of data augmentation techniques, such as random flipping, helped to increase the effective size of the training dataset and reduce overfitting.\n\nUnderfitting was addressed by incorporating additional biomarkers and clinical information into the network through feature-wise transformations (FWTs). These transformations allowed the model to better integrate relevant clinical data, such as PSAD and patient age, which improved the segmentation performance. The best-performing approach involved using a multi-layer perceptron (MLP) to expand the PSAD scalar into a vector and then multiplying this vector with the features channel-wise. This method significantly improved the mean Dice coefficient to 0.36, indicating that the model was able to learn from the additional information and avoid underfitting.\n\nIn summary, the model's architecture, training procedures, and the incorporation of additional clinical information helped to mitigate both overfitting and underfitting issues. The use of a holdout testing set and quantitative evaluation metrics ensured that the model's performance was robust and generalizable.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was random flipping along the x-axis with a 0.5 probability during the training phase. This data augmentation technique helps to increase the diversity of the training data, making the model more generalizable and less likely to overfit to the specific patterns in the training set.\n\nAdditionally, we utilized a generalized Dice loss function, which is particularly effective for imbalanced datasets. This loss function weights each class by the inverse size of the region, ensuring that the model pays adequate attention to smaller, less frequent classes. This approach helps in balancing the learning process and prevents the model from being biased towards the majority class.\n\nThe training process was conducted over approximately 1,500 epochs, during which the model converged. This extensive training period allowed the model to learn the underlying patterns in the data thoroughly without overfitting to the training examples.\n\nFurthermore, we evaluated our model using both Dice coefficient and centroid distance on a holdout testing set of 43 scans. This evaluation strategy ensures that the model's performance is assessed on unseen data, providing a reliable measure of its generalization capability. The use of centroid distance as a complementary metric to Dice coefficient helps in better evaluating the model's performance, especially when dealing with imbalanced datasets where Dice alone might fail to capture the true performance.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we utilized a 3D U-Net architecture with four encoder/decoder blocks and anisotropic strides in the z-axis to preserve small lesion structures. The models were trained using the Adam optimizer with a batch size of 2 on an NVIDIA P5000 GPU. The training process involved random flipping along the x-axis with a 0.5 probability and applied argmax to the output logits for binary segmentation. Generalized Dice loss was used as the loss function, which is particularly effective for imbalanced datasets.\n\nThe dataset used for training, validation, and testing is described, including the number of scans and their respective clinical information such as PSA, PSAD, and age. The dataset was split into independent training, validation, and testing sets, with specific details provided in Table 1.\n\nRegarding the availability of model files and optimization parameters, these are not explicitly mentioned as being publicly available. However, the methods and configurations are thoroughly described, allowing for replication of the experiments. The code and models were implemented using PyTorch (v1.9.0) and PyTorch Lightning (v1.4.2), which are open-source frameworks. The specific versions of these frameworks are cited, ensuring reproducibility.\n\nFor those interested in accessing the dataset or further details, it is noted that the dataset contains AI-derived whole-gland prostate segmentation masks validated to have a mean Dice similarity of 0.90. The dataset includes bpMRI scans with annotations and clinical information, providing a comprehensive resource for similar studies.\n\nIn summary, while the exact model files and optimization parameters are not explicitly provided, the detailed methodology and configurations described in the publication allow for the replication of the experiments. The use of open-source frameworks and the thorough description of the dataset and training process support the reproducibility of the results.",
  "model/interpretability": "The model we developed is not entirely a black box, as it incorporates interpretable features through the use of feature-wise transformations (FWTs). These transformations allow us to integrate biomarkers and clinical information in a way that can be understood and controlled. Specifically, we use a multi-layer perceptron (MLP) to expand the prostate-specific antigen density (PSAD) scalar into a vector, which is then used to multiply the features channel-wise. This approach provides a clear mechanism for how the PSAD value influences the model's predictions. For instance, increasing the PSAD value tends to increase the size of the predicted lesion, demonstrating a clinically realistic relationship between the biomarker and the model's output. Additionally, the use of centroid distance as an evaluation metric provides insight into the spatial accuracy of the model's predictions, further enhancing interpretability. The model's architecture, based on a 3D U-Net, is also well-understood in the field, adding to its transparency. However, the exact inner workings of the neural network layers themselves remain opaque, as is typical with deep learning models.",
  "model/output": "The model is designed for segmentation, which is a type of classification task at the pixel or voxel level. It specifically focuses on segmenting prostate cancer (PCa) lesions in biomedical imaging data. The output of the model is a binary segmentation map, where each voxel is classified as either belonging to a lesion or not. This is achieved using an argmax operation on the output logits, without any additional post-processing. The model's performance is evaluated using metrics such as the Dice coefficient and centroid distance, which are commonly used in segmentation tasks to assess the overlap and spatial accuracy of the predicted segments compared to the ground truth.\n\nThe model integrates biomarkers and clinical information, such as the Prostate-Specific Antigen Density (PSAD) and patient age, to improve segmentation performance. The PSAD value, in particular, is used to control the size of the final prediction output. By adjusting the PSAD value within a specific range, the model can scale the features and thus control the volume of the predicted lesions. This integration is achieved through Feature-wise Transformations (FWTs), which apply the biomarkers at different locations within the network, with the bottleneck layer being the most effective.\n\nThe model was trained using a generalized Dice loss function, which is suitable for imbalanced datasets like the one used in this study. The training process involved data augmentation techniques such as random flipping along the x-axis. The model's architecture is based on a 3D U-Net, which is well-suited for biomedical image segmentation tasks. The input to the model consists of two-channel biomedical imaging data, specifically bpMRI scans (T2W and ADC sequences), which were preprocessed and co-registered before training. The model was implemented using PyTorch and PyTorch Lightning frameworks and trained on an NVIDIA P5000 GPU.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our method was conducted using a holdout testing set consisting of 43 scans. We employed two primary metrics for quantitative assessment: the Dice coefficient and centroid distance. The Dice coefficient measures the overlap between the predicted segmentation and the ground truth, providing a volume-based evaluation. However, in cases where models completely miss the ground truth, the Dice coefficient may not be informative. To address this, we introduced centroid distance as a complementary metric. Centroid distance measures the minimum Euclidean distance between the centers of gravity of the ground-truth lesion and all predicted lesion blobs, offering a location-based evaluation that is particularly useful when the volume of the prediction is not the primary concern.\n\nOur baseline method, utilizing a 3D Dynamic U-Net from the MONAI framework, achieved a mean Dice coefficient of 0.28. We then compared various feature-wise transformation (FWT) approaches that integrated additional biomarkers and clinical information into the network. Among these, the channel-wise multiplication method demonstrated the best performance, significantly improving the mean Dice coefficient by 28% to 0.36. This approach also slightly reduced the mean centroid distance between the ground-truth and predicted lesions compared to the baseline model.\n\nWe tested different FWT approaches, including scalar multiplication, feature-wise multiplication, and concatenation, and applied them at various locations within the U-Net architecture. The channel-wise multiplication approach, which uses a multi-layer perceptron (MLP) to expand the biomarker scalar into a vector and then multiplies this vector with the features channel-wise, proved to be the most effective. This method allows for individual control of each feature channel, unlike global scalar multiplication or feature-wise multiplication, which may not provide sufficient information to scale every element in the feature.\n\nThe bottleneck layer of the U-Net was identified as the optimal location for applying the FWT, as features are most compressed at this point, making the integration of biomarker information most effective. Additionally, we found that the prostate-specific antigen density (PSAD) biomarker performed better than patient age when integrated into the neural network for the prostate cancer segmentation task.\n\nIn summary, our evaluation method involved a comprehensive assessment using both Dice coefficient and centroid distance on a holdout testing set. We demonstrated that integrating additional biomarkers through channel-wise multiplication at the bottleneck layer significantly improved segmentation performance.",
  "evaluation/measure": "In our evaluation, we employed two primary performance metrics to assess the effectiveness of our models: the Dice coefficient and the centroid distance. The Dice coefficient is a widely used metric in medical image segmentation that measures the overlap between the predicted segmentation and the ground truth. It provides a straightforward way to evaluate the volumetric accuracy of the segmentation.\n\nHowever, the Dice coefficient alone may not be sufficient, especially when dealing with imbalanced datasets or when the location of the prediction is crucial. To address this, we introduced the centroid distance as a complementary metric. The centroid distance measures the minimum Euclidean distance between the centers of gravity of the ground-truth lesion and all predicted lesion blobs. This metric is particularly informative when the focus is on the spatial accuracy of the predictions rather than just the volume.\n\nThe use of these two metrics together allows for a more comprehensive evaluation of our models. The Dice coefficient ensures that we are capturing the overall volumetric accuracy, while the centroid distance provides insights into the spatial precision of the predictions. This combination is representative of the current literature, where multiple metrics are often used to provide a more nuanced understanding of model performance.",
  "evaluation/comparison": "In our evaluation, we compared our methods to a publicly available baseline, specifically the 3D Dynamic U-Net from MONAI. This baseline was tested on a holdout testing set consisting of 43 scans. The baseline method demonstrated a mean Dice coefficient of 0.28, which served as our reference point for comparison.\n\nWe also evaluated simpler baselines to understand the impact of integrating additional biomarkers and clinical information. Our feature-wise transformation (FWT) approaches, which included scalar multiplication, channel-wise multiplication, feature-wise multiplication, and concatenation, were all compared against this baseline. Among these, the channel-wise multiplication approach showed the most significant improvement, achieving a mean Dice coefficient of 0.36. This represents a 28% improvement over the baseline, indicating that integrating extra biomarkers and clinical information can enhance model performance.\n\nThe channel-wise multiplication method was particularly effective because it applies weights to each channel, scaling the contribution of each filter in the U-Net. This approach outperformed simpler methods like scalar multiplication, which conditions all features globally, and feature-wise multiplication, which may not provide sufficient information to scale every element in the feature map. Additionally, the concatenation method was less effective due to the lack of cross-channel information exchange at the bottleneck of the U-Net.\n\nOur experiments also explored different locations within the network for applying these transformations. The bottleneck layer was found to be the most effective location for integrating biomarker information, as features are most compressed at this point, allowing the biomarker information to act as a strong constraint. This finding underscores the importance of strategic integration points within the neural network architecture.",
  "evaluation/confidence": "The evaluation of our model's performance includes confidence intervals for the metrics used. Specifically, the Dice coefficient and centroid distance are reported with their respective standard deviations, providing a measure of variability and confidence in these metrics.\n\nStatistical significance is also considered in our evaluation. For instance, the improvement in mean Dice coefficient from the baseline to the best-performing feature-wise transformation (FWT) approach is noted to be significant with a p-value less than 0.05, as determined by a paired t-test. This statistical test helps to ensure that the observed improvements are not due to random chance, thereby strengthening the claim that the proposed method is superior to the baseline.\n\nIn summary, the performance metrics include confidence intervals, and the results demonstrate statistical significance, supporting the assertion that the method outperforms the baseline and other compared approaches.",
  "evaluation/availability": "Not enough information is available."
}