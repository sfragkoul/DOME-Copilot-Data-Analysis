{
  "publication/title": "Voice Features for Emotional Disorder Identification in Children and Adolescents",
  "publication/authors": "The authors involved in this article are JL, JHL, MQL, LHF, YZW, ZJL, ZY, and FH. JL performed the data analysis and wrote the final manuscript. JHL made important revisions to the first draft of the manuscript. MQL, LHF, YZW, and ZJL were involved throughout the data collection process. ZY, FH, and LHF made practical contributions to the conduct and advancement of the trial.",
  "publication/journal": "Child and Adolescent Psychiatry and Mental Health",
  "publication/year": "2024",
  "publication/pmid": "38287442",
  "publication/pmcid": "PMC10826007",
  "publication/doi": "10.1186/s13034-024-00708-0",
  "publication/tags": "- Child and Adolescent Psychiatry\n- Mental Health\n- Voice Features\n- Machine Learning\n- Emotional Disorders\n- Depression\n- Bipolar Disorder\n- Diagnostic Tools\n- Feature Selection\n- Clinical Applications",
  "dataset/provenance": "The dataset used in this study was collected through a controlled experiment involving children and adolescents. The subjects were asked to read aloud from a set of seven reading materials, which included a short story, positive and negative emotional vocabulary lists, and neutral non-emotional vocabulary lists. The recordings were made in a quiet indoor environment using a MacBook Air 2020, with subjects maintaining a consistent distance from the microphone to ensure data quality.\n\nThe dataset consists of speech recordings from 150 subjects, divided into three groups: 50 with Major Depressive Disorder (MDD), 50 with Bipolar Disorder (BD), and 50 healthy controls (HC). The demographic and clinical characteristics of these groups are detailed in the study, showing no significant differences in age and gender among the groups.\n\nThis dataset has not been previously used in other published papers or by the community. The data collection process was designed to ensure privacy and confidentiality, with all subjects and their families signing informed consent forms. The collected data were validated for reliability and used to extract voice features for further analysis.\n\nThe dataset is not publicly available due to privacy and ethical restrictions, but it is available upon request from the corresponding author. The study emphasizes the importance of protecting subject privacy while ensuring the data's validity and reliability for research purposes.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a testing set. The ratio used for this split was 7:3, meaning 70% of the data was allocated to the training set, and 30% was reserved for the testing set. This division was employed to ensure that the model could be trained effectively while also having a separate set of data to evaluate its performance.\n\nThe training set consisted of 105 data points, while the testing set comprised 45 data points. This split allowed for a robust evaluation of the model's diagnostic efficiency. The training set was used to select the optimal classification method through various machine learning algorithms, including Decision Tree (DT), Na\u00efve Bayes Classifier (NB), Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Ensemble Learning (EL), and Convolutional Neural Network (CNN). The testing set was then used to calculate the diagnostic efficiency of the final model.",
  "dataset/redundancy": "The dataset used in this study was divided into training and testing sets in a 7:3 ratio. This split ensures that the training set is sufficiently large to train robust models, while the testing set is large enough to provide a reliable evaluation of the model's performance.\n\nThe training and testing sets are independent. This independence was enforced by randomly assigning subjects to either the training or testing set, ensuring that there is no overlap between the two sets. This approach helps to prevent data leakage and ensures that the model's performance on the testing set is a true reflection of its generalizability to new, unseen data.\n\nRegarding the distribution of the dataset, it is not directly comparable to previously published machine learning datasets, as this study focuses on a specific population of children and adolescents with emotional disorders. However, the dataset includes a balanced representation of subjects with bipolar disorder, major depressive disorder, and healthy controls, which is crucial for building an effective classification model. The demographic and clinical characteristics of the subjects are detailed in Table 2, showing no significant differences in age and gender among the three groups, which helps to mitigate potential biases in the model.\n\nThe feature selection process involved using the chi-square test to identify the top 120 most effective features for differentiating between the three groups. This method ensures that the selected features have a high correlation with the target variable while minimizing redundancy and the risk of overfitting. The top 12 features with the highest scores are visualized in a difference visualization map, demonstrating distinct cluster centers for the three groups.\n\nIn summary, the dataset was carefully split and managed to ensure independence between training and testing sets, with a focus on balanced representation and effective feature selection to build a robust classification model.",
  "dataset/availability": "The data that support the findings of this study are available on request from the corresponding author. The data are not publicly available due to privacy or ethical restrictions. This ensures that the sensitive information of the participants is protected and that the data is used responsibly. The decision to restrict public access is in line with ethical guidelines and regulations that prioritize the confidentiality and privacy of the individuals involved in the study.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Support Vector Machine (SVM). This algorithm was chosen due to its excellent performance on high-dimensional data, high tolerance for noisy data, and the advantage that the training process can be highly optimized. SVM has been previously reported to perform better when classifying the severity of depression and other psychiatric disorders.\n\nThe SVM algorithm used in this study is not new. It is a well-established machine-learning algorithm that has been extensively studied and applied in various fields, including medical diagnostics. The reason it was not published in a machine-learning journal is that the focus of our research is on the application of machine-learning techniques to the diagnosis of mood disorders in children and adolescents, rather than the development of new machine-learning algorithms. Our study contributes to the field of child and adolescent psychiatry and mental health by demonstrating the effectiveness of voice features in distinguishing between major depressive disorder and bipolar disorder using established machine-learning methods.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model is based on a Support Vector Machine (SVM) algorithm, which was chosen for its excellent performance on high-dimensional data, high tolerance for noisy data, and the advantage that the training process can be highly optimized. The SVM algorithm demonstrated excellent classification performance on the test set, with sensitivity, specificity, and diagnostic accuracy all above 90%, and the AUC of the ROC curve all above 0.95.\n\nThe study compared various machine learning algorithms, including Decision Tree (DT), Na\u00efve Bayes Classifier (NB), K-Nearest Neighbor (KNN), Ensemble Learning (EL), and Convolutional Neural Network (CNN). However, SVM was ultimately selected due to its superior performance in classifying the severity of depression and other psychiatric disorders. The training and testing sets were divided in a 7:3 ratio to ensure that the model's diagnostic efficiency could be accurately calculated. The features used for classification were selected using the chi-square test, ensuring that the selected features maintained the highest possible correlation while minimizing redundancy and the risk of overfitting. The top 120 features were chosen for differentiating between bipolar disorder, major depressive disorder, and healthy controls.",
  "optimization/encoding": "The data encoding process involved several steps to ensure the voice data was suitable for machine learning analysis. Initially, the voice data was collected in a controlled environment using a MacBook Air 2020. Subjects read from a standardized set of materials, including short stories and vocabulary lists with varying emotional tones. The recordings were made in a quiet indoor setting, with subjects maintaining a consistent distance from the microphone to minimize variability.\n\nThe raw voice data underwent basic pre-processing, including power normalization. This step was crucial to reduce power differences between recordings, ensuring comparability across all samples. Following normalization, the speech recordings were segmented into seven parts, corresponding to the seven different reading materials used. This segmentation allowed for detailed analysis of each segment's features.\n\nThe descriptors used in this study were derived from the INTERSPEECH 2016 feature set, which includes 6373 statistical features. These features were calculated using various functions applied to the contours of low-level descriptors (LLD). The feature set covers a wide range of acoustic properties, from low-frequency to high-frequency components, providing a comprehensive representation of the speech signals.\n\nTo further refine the data, a chi-square test was employed for feature selection. This statistical method helped identify the top 120 most effective features for differentiating between bipolar disorder, major depressive disorder, and healthy controls. The selected features were chosen to maximize correlation with the target variables while minimizing redundancy and the risk of overfitting. This rigorous selection process ensured that the most relevant and informative features were used in the machine learning models.\n\nThe pre-processed and encoded data were then divided into training and testing sets in a 7:3 ratio. This division allowed for the evaluation of different machine learning algorithms, including Decision Tree, na\u00efve Bayes Classifier, Support Vector Machine, K-Nearest Neighbor, Ensemble Learning, and Convolutional Neural Network. The Support Vector Machine (SVM) ultimately demonstrated the best classification performance, with sensitivity, specificity, and diagnostic accuracy all above 90%, and an AUC of the ROC curve above 0.95. This indicates that the encoded data and the chosen features were highly effective in distinguishing between the different emotional states.",
  "optimization/parameters": "In our study, we utilized a feature selection process to determine the optimal number of parameters for our model. Initially, we employed the chi-square test to evaluate the correlation between features and the target variable, ensuring that the selected features maintained high correlation while minimizing redundancy and the risk of overfitting. Through this method, we identified the top 120 features that were most effective for differentiating between bipolar disorder (BD), major depressive disorder (MDD), and healthy controls (HC).\n\nThe selection of 120 features was validated through extensive experimentation. We tested the model with fewer features and found that reducing the number of features led to a degradation in classification performance. Therefore, 120 features were determined to be the optimal number for achieving the best classification results.\n\nThis feature selection process was crucial in ensuring that our model was robust and efficient, capable of handling the complexity of the data while maintaining high accuracy and reliability. The chosen features were then used in various machine learning algorithms, including Support Vector Machine (SVM), which ultimately demonstrated the best classification performance.",
  "optimization/features": "In our study, we utilized a comprehensive set of voice features to differentiate between various emotional disorders in children and adolescents. Initially, we employed a feature set containing 6373 statistical features derived from the INTERSPEECH 2016 descriptors. These features were obtained by calculating various functions on the contours of low-level descriptors (LLD), covering a wide range of speech characteristics.\n\nTo enhance the model's performance and reduce redundancy, we performed feature selection. We used the chi-square test to identify the most effective features for differentiating between bipolar disorder (BD), major depressive disorder (MDD), and healthy controls (HC). This process ensured that the selected features maintained a high correlation with the target variables while minimizing the risk of overfitting. Ultimately, we chose 120 features that demonstrated the highest scores in the feature selection process.\n\nThe top 12 features with the highest scores were particularly highlighted, and a difference visualization map was created to observe the cluster centers in the three groups when multiple feature combinations were considered. This visualization helped in understanding the distinct patterns associated with each group.\n\nFeature selection was conducted using the training set only, ensuring that the model's performance on the test set remained unbiased. This approach allowed us to validate the selected features' effectiveness in a real-world scenario, demonstrating the model's robustness and reliability.",
  "optimization/fitting": "The fitting method employed in this study involved a careful balance to avoid both overfitting and underfitting. Initially, a feature selection process was conducted using the chi-square test to identify the top 120 most effective features for differentiating between bipolar disorder (BD), major depressive disorder (MDD), and healthy controls (HC). This step ensured that the selected features maintained high correlation with the target variables while minimizing redundancy and the risk of overfitting.\n\nSeveral machine learning algorithms were evaluated, including Decision Tree (DT), Na\u00efve Bayes Classifier (NB), Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Ensemble Learning (EL), and Convolutional Neural Network (CNN). The dataset was divided into training and testing sets in a 7:3 ratio. The training set was used to select the optimal classification method, and the testing set was used to calculate the diagnostic efficiency of the model.\n\nDuring the training process, it was observed that the Support Vector Machine (SVM) exhibited the best classification ability. This is attributed to SVM's excellent performance with high-dimensional data, high tolerance for noisy data, and the advantage of highly optimized training processes. In contrast, algorithms like DT, KNN, and EL may experience overfitting or underfitting in certain situations, leading to decreased accuracy on test data. Additionally, the computational complexity of KNN and EL algorithms is high, which can result in efficiency issues when processing large-scale data.\n\nTo ensure the model's robustness and replicability, the feature selection method was crucial. Experiments revealed that using 120 features achieved optimal classification performance. Reducing the number of features selected could lead to performance degradation. Furthermore, the proposed method was applied to public datasets (MODMA and DAIC-WOZ), achieving accuracies higher than 80% in distinguishing different types of data. This validation step helped in ruling out overfitting and underfitting by demonstrating the model's generalizability across different datasets.\n\nIn summary, the fitting method involved a rigorous feature selection process and evaluation of multiple machine learning algorithms. The choice of SVM as the optimal classification method, along with validation on public datasets, ensured that the model was neither overfitted nor underfitted, providing reliable diagnostic efficiency.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was feature selection. We utilized the chi-square test to select the top 120 most effective features for differentiating between bipolar disorder, major depressive disorder, and healthy controls. This process helped in reducing the number of features while maintaining a high level of information, thereby minimizing redundancy and the risk of overfitting.\n\nAdditionally, we compared various machine learning algorithms, including Decision Tree, Na\u00efve Bayes Classifier, Support Vector Machine, K-Nearest Neighbor, Ensemble Learning, and Convolutional Neural Network. Through this comparison, we identified that the Support Vector Machine (SVM) exhibited the best classification ability. SVM is known for its excellent performance on high-dimensional data and high tolerance for noisy data, which further aids in preventing overfitting.\n\nWe also divided our human sample into training and testing sets in a 7:3 ratio. This division allowed us to train our model on a larger dataset while evaluating its performance on a separate test set, ensuring that the model generalizes well to unseen data. Furthermore, we ensured that the selected features maintained the highest possible correlation while minimizing redundancy, which is crucial for preventing overfitting.\n\nIn summary, our approach to preventing overfitting involved rigorous feature selection, algorithm comparison, and proper data splitting, all of which contributed to the reliability and generalizability of our final model.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study is not a blackbox. It utilizes a Support Vector Machine (SVM) algorithm, which is known for its transparency and interpretability. SVM is particularly effective in high-dimensional spaces and is robust against overfitting, making it a reliable choice for classification tasks.\n\nOne of the key aspects of the SVM's transparency is its ability to provide clear decision boundaries. These boundaries are defined by support vectors, which are the data points closest to the decision boundary. By examining these support vectors, one can gain insights into which features are most influential in the classification process.\n\nAdditionally, the feature selection process involved using the chi-square test to identify the top 120 most effective features for differentiating between bipolar disorder, major depressive disorder, and healthy controls. This method ensures that the selected features maintain a high correlation with the target variable while minimizing redundancy and the risk of overfitting. The top 12 features with the highest scores were visualized in a difference visualization map, revealing distinct cluster centers for the three groups. This visualization helps in understanding how different combinations of features contribute to the classification.\n\nFurthermore, the model's performance was evaluated using metrics such as speech accuracy, subject accuracy, AUC, and time cost. Speech accuracy refers to the ratio of correct speech recordings from patients to all speech recordings, while subject accuracy is the ratio of correct diagnoses made on different subjects. These metrics provide a clear understanding of the model's effectiveness and reliability in real-world applications.\n\nIn summary, the SVM model used in this study is transparent and interpretable. The use of support vectors, the chi-square test for feature selection, and the visualization of top features all contribute to the model's clarity and reliability. This transparency is crucial for stakeholders, including psychiatrists and clinicians, to trust and effectively use the model in clinical settings.",
  "model/output": "The model developed in this study is a classification model. It is designed to differentiate between three distinct groups: children and adolescents with major depressive disorder (MDD), those with bipolar disorder (BD), and healthy controls (HC). The model utilizes a ternary classifier to verify the validity of selected features and evaluates various machine learning algorithms, including Decision Tree (DT), Na\u00efve Bayes Classifier (NB), Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Ensemble Learning (EL), and Convolutional Neural Network (CNN). Among these, the Support Vector Machine (SVM) exhibited the best classification ability, demonstrating excellent diagnostic efficacy with sensitivity, specificity, and diagnostic accuracy all above 90%. The model's performance was assessed using metrics such as speech accuracy, subject accuracy, AUC, and time cost, with the SVM classifier achieving a total accuracy of 95.6% for the three groups. The results indicate that the model can effectively distinguish between the different emotional states and disorders, making it a valuable tool for auxiliary diagnosis in clinical settings.",
  "model/duration": "The execution time of the model was evaluated as part of the assessment metrics. While specific numerical values for the time cost were considered, the primary focus was on the model's performance in terms of speech accuracy, subject accuracy, and AUC. The Support Vector Machine (SVM) algorithm was ultimately chosen for its superior classification ability and efficiency, demonstrating excellent diagnostic efficacy with sensitivity, specificity, and diagnostic accuracy all above 90%. The model's performance was validated on a test set, showing high precision, recall, and accuracy for distinguishing between bipolar disorder, major depressive disorder, and healthy control groups. The SVM classifier's results indicated robust performance, with the AUC of the ROC curve exceeding 0.95, confirming its reliability and efficiency in clinical applications.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method involved a comprehensive approach to ensure the robustness and validity of the classification models. The dataset was divided into training and testing sets in a 7:3 ratio. This split allowed for the selection of the optimal classification method using the training sets, which consisted of 105 samples. The diagnostic efficiency of the model was then calculated using the 45 testing sets.\n\nSeveral machine learning algorithms were compared, including Decision Tree (DT), Na\u00efve Bayes Classifier (NB), Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Ensemble Learning (EL). Additionally, a deep learning algorithm, Convolutional Neural Network (CNN), was evaluated. The performance of these algorithms was assessed using multiple metrics: speech accuracy, subject accuracy, Area Under the Curve (AUC), and time cost. Speech accuracy refers to the ratio of correct speech recordings from patients to all speech recordings from all subjects. Subject accuracy is defined as the ratio of correct diagnoses made on different subjects.\n\nTo ensure the reliability of the results, each algorithm was tested six times, and the average of these tests was calculated for all evaluation metrics. This approach helped to exclude anomalies and provided a more accurate assessment of the models' performance. The SVM algorithm performed the best among the evaluated methods, demonstrating high accuracy and sensitivity.\n\nThe classification results of the test set using SVM showed a total accuracy of 95.6% for the three groups. The sensitivity for Major Depressive Disorder (MDD) was 93.3%, and for Bipolar Disorder (BD), it was 100%, with a specificity of 93.3%. The Receiver Operating Characteristic (ROC) curve indicated an Area Under the Curve (AUC) of 1 for BD and 0.967 for MDD, further validating the model's effectiveness.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our classification models. These metrics include speech accuracy, subject accuracy, the Area Under the Curve (AUC), and time cost. Speech accuracy is defined as the ratio of correct speech recordings from patients to all the speech recordings from all subjects. Subject accuracy, on the other hand, is the ratio of correct diagnoses made on the different subjects. The AUC provides a measure of the model's ability to distinguish between different classes, with higher values indicating better performance. Time cost is also considered to assess the efficiency of the models.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in the context of medical diagnostics. They provide a comprehensive view of the model's performance, covering aspects such as accuracy, diagnostic ability, and efficiency. The inclusion of both speech accuracy and subject accuracy ensures that we capture the model's performance at both the individual recording level and the subject level. The AUC is a standard metric for evaluating the performance of binary classifiers, and its use in our study aligns with common practices in the field. Time cost is an important consideration, especially for models that may be deployed in real-world clinical settings where efficiency is crucial.",
  "evaluation/comparison": "In our study, we adopted a feature selection method to ensure that the chosen features were informative and reduced the risk of overfitting. We evaluated the performance of various machine learning algorithms, including Decision Tree (DT), Na\u00efve Bayes Classifier (NB), Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Ensemble Learning (EL), as well as deep learning algorithms like Convolutional Neural Networks (CNN). To validate the robustness of our model, we applied it to public datasets such as MODMA and DAIC-WOZ. The accuracy of our method in distinguishing different types of data in these datasets was higher than 80%, demonstrating its effectiveness and generalizability.\n\nWe also compared the performance of different algorithms. Each algorithm was tested six times to exclude anomalies, and the average results were calculated. SVM performed the best among the evaluated algorithms. The classification results of the test set using SVM showed a total accuracy of 95.6%, with a sensitivity of 93.3% for MDD and 100% for BD, and a specificity of 93.3%. The AUC for BD was 1, and for MDD, it was 0.967, indicating excellent diagnostic efficacy.\n\nThe choice of SVM was driven by its superior performance on high-dimensional data and its ability to handle noisy data effectively. Other algorithms like DT, KNN, and EL may suffer from overfitting or underfitting, leading to decreased accuracy on test data. Additionally, the computational complexity of KNN and EL can be high, which may affect efficiency when processing large-scale data. Therefore, SVM was ultimately chosen for its robustness and high classification performance.",
  "evaluation/confidence": "The evaluation of our model's performance included several key metrics such as speech accuracy, subject accuracy, AUC, and time cost. To ensure the robustness of our results, each algorithm was tested six times, and the average of these tests was calculated for all evaluation metrics. This approach helps to mitigate the impact of any anomalies and provides a more reliable estimate of the model's performance.\n\nStatistical significance was assessed using p-values, with values less than 0.05 considered significant. This threshold was applied to determine the significance of differences in demographic and clinical symptom data among the groups. For instance, significant differences were found in HAMD and YMRS scores among the three groups, indicating that these metrics are reliable indicators of the differences between the groups.\n\nThe Support Vector Machine (SVM) classification results for the test set showed a total accuracy of 95.6%, with a sensitivity of 93.3% for MDD and 100% for BD. The specificity was also 93.3%. The AUC for BD was 1, and for MDD, it was 0.967, demonstrating the high discriminative power of the model. These results suggest that the model's performance is not only accurate but also statistically significant, providing strong evidence that the method is superior to others and baselines.\n\nHowever, it is important to note that while the performance metrics are robust, the sample size is relatively small, and the number of datasets used for testing is limited. Further experiments with larger and more diverse datasets could provide additional confidence in the model's generalizability and robustness. Additionally, the model's performance was evaluated using cross-validation, which helps to ensure that the results are not due to overfitting and that the model can generalize well to new, unseen data.",
  "evaluation/availability": "The data that support the findings of this study are available on request from the corresponding author. However, the data are not publicly available due to privacy or ethical restrictions. This ensures that the privacy and confidentiality of the subjects are protected. The data collection process involved a set of reading materials, including short stories and vocabulary lists with varying emotional tones, which were used to collect speech data from the subjects. The speech data were recorded using a MacBook Air 2020 in a quiet indoor environment, with subjects maintaining a consistent distance from the microphone to ensure data quality. The recorded data underwent pre-processing, including power normalization and speech segmentation, to ensure comparability and reliability. The features extracted from the speech data were based on the INTERSPEECH 2016 descriptors, which include a comprehensive set of statistical features derived from low-level descriptors. The study utilized various machine learning algorithms, including Decision Tree (DT), na\u00efve Bayes Classifier (NB), Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Ensemble learning (EL), and Convolutional Neural Network (CNN), to evaluate the performance of the selected features. The evaluation metrics included speech accuracy, subject accuracy, AUC, and time cost. The study also compared the model's performance on public datasets, such as MODMA and DAIC-WOZ, achieving high accuracy in distinguishing different types of data. The findings demonstrate the potential of voice features as an effective objective physiological indicator for the diagnosis of emotional disorders in children and adolescents."
}