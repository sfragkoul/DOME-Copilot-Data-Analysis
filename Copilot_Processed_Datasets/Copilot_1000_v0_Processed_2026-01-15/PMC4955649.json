{
  "publication/title": "Multivariate profiles of impulsivity and related constructs in heroin and amphetamine dependence",
  "publication/authors": "The authors who contributed to the article are Woo-Young Ahn and Jasmin Vassileva. Woo-Young Ahn analyzed the data, interpreted the results, and wrote the paper. Jasmin Vassileva designed the study, interpreted the results, and wrote the paper.",
  "publication/journal": "Drug Alcohol Depend.",
  "publication/year": "2017",
  "publication/pmid": "26905209",
  "publication/pmcid": "PMC4955649",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Machine Learning\n- Substance Dependence\n- Heroin Dependence\n- Amphetamine Dependence\n- Neurocognitive Measures\n- Psychiatric Disorders\n- Impulsivity\n- Drug Addiction\n- Behavioral Markers\n- Multivariate Analysis",
  "dataset/provenance": "The dataset used in this study was sourced from a larger study on impulsivity among drug users in Sofia, Bulgaria. The study included 222 individuals, who were recruited through flyers placed at various locations such as substance abuse clinics, nightclubs, bars, and cafes, as well as by word of mouth. Participants were initially screened via telephone and in-person for their medical and substance use histories.\n\nThe dataset comprises individuals who met specific inclusion criteria, including age between 18 and 50 years, an estimated IQ greater than 75, a minimum of 8th grade education, no history of neurological illness, HIV seronegative status, and negative results for various substances in breathalyzer and urine toxicology screens. The participants were categorized into four groups: those with mono-dependence on heroin, mono-dependence on amphetamines, polysubstance dependence, and those with no history of substance dependence.\n\nThe data used in this study included a comprehensive set of measures, encompassing demographic, psychiatric, personality, and neurocognitive indices. These measures were collected through various assessments and tasks, such as the Structured Clinical Interview for DSM-IV, the Barratt Impulsiveness Scale, the Iowa Gambling Task, and the Stop Signal Task, among others. The dataset is unique to this study and has not been previously used in other publications by the community.",
  "dataset/splits": "In our study, we utilized two primary data splits: a training set and a test set. The data, consisting of 222 individuals, was divided such that the training set comprised 67% of the data, amounting to 148 data points. The test set, or validation set, included the remaining 33%, totaling 74 data points. This split was employed to fit the elastic net model using the training set and subsequently evaluate its performance on the test set.\n\nTo further assess the generalizability of our findings, we conducted an additional analysis where the data was randomly divided into training and test sets 1,000 times. This approach allowed us to check the model's performance across multiple iterations, ensuring robustness and reliability in our classification accuracy. The area under the curve (AUC) of the receiver operating characteristic (ROC) curve was used as the primary index of model performance in these evaluations.",
  "dataset/redundancy": "The dataset was split into a training set and a test set to evaluate the model's performance. The training set comprised 67% of the data, while the test set included the remaining 33%. This split was done to ensure that the model's classification accuracy could be assessed on unseen data, thereby providing a measure of its generalizability.\n\nThe training and test sets were designed to be independent. To enforce this independence, the data was randomly divided into these sets. Additionally, to further validate the model's performance and ensure robustness, the process of randomly dividing the data into training and test sets was repeated 1,000 times. This approach helped in assessing the consistency and reliability of the model's performance across different subsets of the data.\n\nRegarding the distribution of the dataset, it included a diverse range of participants with varying histories of substance dependence. The participants were categorized into groups based on their dependence status: mono-dependence on heroin, mono-dependence on amphetamines, polysubstance dependence, and no history of substance dependence. This categorization allowed for a comprehensive analysis of the multivariate profiles associated with heroin dependence and amphetamine dependence.\n\nThe dataset's structure and the method of splitting it into training and test sets were chosen to minimize bias and ensure that the model's performance could be reliably evaluated. The use of machine-learning methods, specifically the elastic net, facilitated the identification of predictive markers for psychiatric disorders and the classification of psychiatric populations with high-dimensional data. This approach is particularly useful when dealing with complex, high-dimensional datasets, as it helps in minimizing both Type I and Type II errors.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is the elastic net, which is a type of penalized regression method. This approach is not new; it has been previously established and used in various studies. The elastic net is particularly useful for high-dimensional data as it enjoys automatic variable selection and can handle highly correlated variables effectively. It was chosen for this study due to its ability to uncover multivariate profiles that contribute to the classification of heroin and amphetamine dependence. The decision to use the elastic net was driven by its suitability for the specific goals of the research, which involved identifying substance-specific behavioral markers. The algorithm's effectiveness in this context is demonstrated through its ability to classify dependence with a high degree of accuracy, as evidenced by the area under the curve (AUC) values reported in the results.",
  "optimization/meta": "The study employed a machine-learning approach known as the elastic net, which is a type of penalized regression method. This method is used to uncover multivariate profiles that contribute to the classification of heroin and amphetamine dependence. The elastic net is particularly useful for high-dimensional data, as it performs automatic variable selection and can handle correlated variables effectively.\n\nThe elastic net model was applied to a comprehensive dataset comprising 54 demographic, psychiatric, personality, and neurocognitive measures. This approach allowed for the identification of patterns that could predict group membership in new samples. The model was trained on a subset of the data (67%) and then tested on a separate subset (33%) to evaluate its performance. To ensure the robustness of the findings, the data was randomly divided into training and test sets 1,000 times, and the model's performance was assessed using the area under the curve (AUC) of the receiver operating characteristic (ROC) curve.\n\nThe elastic net method does not explicitly use data from other machine-learning algorithms as input. Instead, it directly analyzes the raw data to identify predictive patterns. The training and test sets were carefully split to ensure independence, and the model's performance was validated through multiple random splits of the data. This process helps to confirm that the identified patterns are generalizable to new samples.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved a comprehensive set of measures. We included 54 demographic, psychiatric, personality, and neurocognitive measures as predictors. These measures encompassed various dimensions of impulsivity, psychopathy, aggression, sensation seeking, attention deficit hyperactivity disorder, conduct disorder, antisocial personality disorder, anxiety, depression, and neurocognitive tasks such as Delay Discounting, Go/No-Go, Stop Signal, Immediate Memory, Balloon Analogue Risk, Cambridge Gambling, and Iowa Gambling tasks.\n\nThe data was split into a training set, which comprised 67% of the total data (148 individuals), and a test set, which comprised 33% of the total data (74 individuals). This split allowed us to fit the elastic net model using the training set and then evaluate its performance on the test set. To ensure the robustness of our findings, we repeated this process 1,000 times with randomly selected training and test sets, using the area under the curve (AUC) of the receiver operating characteristic (ROC) curve as an index of model performance.\n\nThe elastic net method, a type of penalized regression, was employed to handle the high-dimensional data. This method automatically selects important variables and shrinks the regression coefficients of unimportant variables to zero. It also has a grouping effect, allowing highly correlated variables to be selected together if they are predictive. This approach helped us uncover multivariate profiles that contribute to the out-of-sample classification of heroin and amphetamine dependence.",
  "optimization/parameters": "In our study, we utilized a total of 54 demographic, psychiatric, personality, and neurocognitive measures as input parameters for our machine-learning model. These parameters were selected to capture a wide range of variables that could potentially contribute to the classification of heroin and amphetamine dependence. The selection of these parameters was guided by the goal of identifying multivariate profiles that could accurately characterize and predict group membership in new samples. The elastic net method, which we employed, is particularly well-suited for handling high-dimensional data and automatically performs variable selection, ensuring that only the most relevant parameters are included in the final model. This approach helps to minimize both Type I and Type II errors, making it a robust choice for our analysis.",
  "optimization/features": "The study utilized a total of 54 demographic, psychiatric, personality, and neurocognitive measures as input features. These features were derived from various tasks and assessments, including the Iowa Gambling Task, Stop Signal Task, Information Sampling Task, Delayed Reward Discounting Task, Balloon Analogue Risk Task, Go/No-Go Task, and Cambridge Gambling Task.\n\nFeature selection was performed using a machine-learning method called the elastic net. This method enjoys automatic variable selection, meaning that the regression coefficients of unimportant variables shrink to zero. Additionally, highly correlated variables can be selected together if they are predictive, due to the elastic net's grouping effect.\n\nThe elastic net model was fitted using the training set, which consisted of 67% of the data. This ensures that the feature selection process was done using the training set only, maintaining the integrity of the test set for unbiased evaluation. The model's performance was then assessed on both the training and test sets, with the area under the curve (AUC) of the receiver operating characteristic (ROC) curve serving as the index of model performance.",
  "optimization/fitting": "The study employed a machine-learning method known as the elastic net, which is a type of penalized regression. This method is particularly useful when dealing with high-dimensional data, where the number of parameters (features) is much larger than the number of training points (samples). In our case, we had 54 demographic, psychiatric, personality, and neurocognitive measures, which is indeed a high-dimensional dataset compared to the 222 participants.\n\nTo address the risk of over-fitting, the elastic net method includes automatic variable selection. This means that the regression coefficients of unimportant variables shrink to zero, effectively reducing the model complexity and preventing over-fitting. Additionally, the elastic net has a grouping effect, allowing it to select highly correlated variables together if they are predictive. This helps in stabilizing the model and improving its generalizability.\n\nTo further ensure the model's performance and generalizability, we split the data into a training set (67% of the data) and a test set (33% of the data). We fitted the elastic net model using the training set and then evaluated its performance on the test set. This process was repeated 1,000 times with randomly selected training and test sets to check the model's consistency and robustness.\n\nThe area under the curve (AUC) of the receiver operating characteristic (ROC) curve was used as an index of model performance. The AUC values for the training and test sets were reported, along with the mean AUC values from the 1,000 random splits. These steps helped to rule out both over-fitting and under-fitting by ensuring that the model performed well on unseen data and was not too complex or too simple.\n\nIn summary, the elastic net method, combined with rigorous cross-validation procedures, helped to mitigate the risks of over-fitting and under-fitting in our high-dimensional dataset.",
  "optimization/regularization": "In our study, we employed a regularization method to prevent overfitting. Specifically, we used the elastic net, a type of penalized regression that combines the advantages of both ridge regression and lasso regression. This method is particularly useful for high-dimensional data, as it performs automatic variable selection and shrinks the regression coefficients of unimportant variables to zero. Additionally, the elastic net's grouping effect allows it to select highly correlated variables together if they are predictive. This approach helps to minimize both Type I and Type II errors, ensuring that our model generalizes well to new samples. To further validate the generalizability of our findings, we randomly divided the data into training and test sets multiple times and checked the model performance each time.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The model employed in this study is not a black box. It utilizes a machine-learning method called the elastic net, which is a type of penalized regression. This method is advantageous because it provides automatic variable selection, meaning that it can identify and prioritize the most relevant features from the data. The regression coefficients of less important variables shrink to zero, making the model more interpretable.\n\nOne of the key strengths of the elastic net is its ability to handle highly correlated variables. It can select groups of correlated variables together if they are predictive, which is beneficial for understanding the underlying patterns in the data. This grouping effect helps in identifying multivariate profiles that contribute to the classification of heroin and amphetamine dependence.\n\nThe elastic net's ability to shrink coefficients to zero also aids in feature selection, making it easier to interpret which variables are most influential in the classification process. This transparency is crucial for validating the findings and ensuring that the model's predictions are based on meaningful and relevant data.\n\nIn summary, the elastic net model used in this study is transparent and provides clear insights into the variables that contribute to the classification of heroin and amphetamine dependence. This transparency is essential for understanding the underlying patterns and for validating the model's predictions.",
  "model/output": "The model employed in this study is a classification model. Specifically, it utilizes the elastic net, a type of penalized regression, to classify individuals based on their dependence on heroin or amphetamine. The dependent variable in this model is whether an individual meets the dependence criteria for heroin or amphetamine. The model was trained to distinguish between individuals with and without these dependencies, using a combination of demographic, psychiatric, personality, and neurocognitive measures. The performance of the model was evaluated using the area under the curve (AUC) of the receiver operating characteristic (ROC) curve, which indicates the model's ability to correctly classify individuals into the appropriate categories. The model was tested on both training and validation sets, with the AUC values providing insights into its classification accuracy.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a combination of traditional statistical analyses and machine-learning techniques. Initially, we employed omnibus analysis of variance (ANOVA) across all groups for each measure, followed by Tukey\u2019s Honestly Significant Difference (HSD) test for post hoc pairwise group comparisons. This approach allowed us to identify significant differences between groups on individual measures.\n\nTo uncover multivariate profiles that contribute to the classification of heroin and amphetamine dependence, we utilized the elastic net, a penalized regression method. This technique is advantageous for its automatic variable selection and ability to handle highly correlated variables. We split the data into a training set (67% of the data) and a test set (33% of the data). The elastic net model was fitted using the training set, and classifications were made on both the training and test sets.\n\nTo assess the generalizability of our findings, we performed 1,000 random splits of the data into training and test sets, evaluating model performance each time. The area under the curve (AUC) of the receiver operating characteristic (ROC) curve was used as the primary index of model performance. This comprehensive evaluation ensured that our classification model was robust and could accurately predict dependence status in new, unseen samples.",
  "evaluation/measure": "The performance of our machine-learning models was primarily evaluated using the area under the curve (AUC) of the receiver operating characteristic (ROC) curve. This metric is widely used in the literature for assessing the performance of classification models, particularly in the context of medical and psychological research. The ROC curve plots the true positive rate against the false positive rate at various threshold settings, providing a comprehensive view of the model's ability to discriminate between different classes.\n\nFor the classification of heroin dependence, the AUC was reported as 0.955 for the training set and 0.870 for the test set. To ensure the robustness of these findings, we further validated the model by randomly dividing the data into training and test sets 1,000 times. The mean AUCs for these random splits were 0.946 for the training set and 0.863 for the test set. These results indicate strong classification performance, suggesting that the model generalizes well to new, unseen data.\n\nSimilarly, for the classification of amphetamine dependence, the AUC was 0.851 for the training set and 0.744 for the test set. The mean AUCs from the 1,000 random splits were 0.847 for the training set and 0.712 for the test set. While these values are slightly lower than those for heroin dependence, they still demonstrate a reasonable level of classification accuracy.\n\nThe use of AUC as the primary performance metric is representative of standard practices in the field. It provides a single scalar value that summarizes the model's performance across all possible classification thresholds, making it a reliable and interpretable measure. Additionally, the ROC curve itself offers a visual representation of the trade-off between sensitivity and specificity, which is crucial for understanding the model's behavior in different scenarios.\n\nIn summary, the reported performance metrics are well-aligned with established practices in the literature. The AUC values for both heroin and amphetamine dependence classifications indicate that the models are effective and robust, capable of generalizing to new data. This set of metrics provides a comprehensive evaluation of the models' discriminative power and reliability.",
  "evaluation/comparison": "In our study, we employed a machine-learning method called the elastic net for classification tasks, which is a type of penalized regression. This method is particularly useful for high-dimensional data, as it performs automatic variable selection and handles multicollinearity effectively. The elastic net was chosen for its ability to shrink the regression coefficients of unimportant variables to zero, thereby selecting only the most predictive features.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on the specific application of classifying heroin and amphetamine dependence using a comprehensive set of demographic, psychiatric, personality, and neurocognitive measures. The elastic net's performance was evaluated through out-of-sample classification accuracy, using the area under the curve (AUC) of the receiver operating characteristic (ROC) curve as the primary metric.\n\nTo assess the robustness of our findings, we conducted multiple random splits of the data into training and test sets, repeating the process 1,000 times. This approach allowed us to evaluate the generalizability of our model and ensure that the classification accuracy was not dependent on a particular split of the data. The mean AUC values across these random splits provided a reliable estimate of the model's performance.\n\nRegarding simpler baselines, our study did not explicitly compare the elastic net to simpler machine-learning algorithms. However, the elastic net's ability to handle high-dimensional data and perform automatic variable selection makes it a robust choice for complex classification tasks. The method's performance, as indicated by the high AUC values, suggests that it effectively captures the multivariate patterns associated with heroin and amphetamine dependence.\n\nIn summary, while we did not conduct a direct comparison to publicly available methods or simpler baselines on benchmark datasets, the elastic net's performance in our study demonstrates its effectiveness in classifying substance dependence using a comprehensive set of measures. The use of multiple random splits and the evaluation of out-of-sample classification accuracy provide strong evidence of the model's generalizability and reliability.",
  "evaluation/confidence": "The study employed a machine-learning method called the elastic net to analyze data from various measures to classify heroin and amphetamine dependence. The performance of the model was evaluated using the area under the curve (AUC) of the receiver operating characteristic (ROC) curve. To assess the generalizability of the findings, the data was randomly divided into training and test sets 1,000 times, and the model's performance was checked each time. This approach provides a robust measure of the model's performance and its ability to generalize to new samples.\n\nThe histograms of AUCs from these random divisions are presented in the figures, with dashed black lines indicating the mean values of the histograms. This visualization helps to understand the distribution of the model's performance across different splits of the data. The use of multiple random splits and the reporting of mean AUC values provide a comprehensive view of the model's reliability and consistency.\n\nStatistical significance was assessed using omnibus analysis of variance (ANOVA) and Tukey\u2019s HSD test for post hoc pair-wise group comparisons. The findings from these analyses are summarized in tables, indicating which group comparisons are statistically significant. This ensures that the observed differences between groups are not due to chance.\n\nThe study also compared the groups using traditional statistical methods before applying the machine-learning approach. This dual approach strengthens the confidence in the results, as it combines both traditional statistical rigor and modern machine-learning techniques. The use of penalized regression methods like the elastic net, which includes automatic variable selection and handles highly correlated variables, further enhances the reliability of the findings.\n\nIn summary, the performance metrics include confidence intervals through the use of multiple random splits of the data, and the results are statistically significant. The combination of traditional statistical methods and advanced machine-learning techniques provides a high level of confidence in the study's findings.",
  "evaluation/availability": "Not enough information is available."
}