{
  "publication/title": "Gaucher disease identification using machine learning algorithms in electronic health records",
  "publication/authors": "The authors who contributed to this article are:\n\n- Andrew Wilson\n- Anna Chahine\n- Michael A. Amato\n- David S. Smith\n- Pierre Pothier\n- Nidhi Shah\n- Lisa S. Klesse\n- Michael Glick\n- Michael R. Rosenbaum\n- Michael B. Benis\n- Shoshana Gabay\n- Michael Maass\n- Catherine M. McGowan\n- Andrea Deleonardis\n\nThe contributions of each author to the paper are as follows:\n\n- Andrew Wilson, Anna Chahine, Pierre Pothier, Nidhi Shah, Lisa S. Klesse, Michael Glick, Michael B. Benis, Michael Maass, and Andrea Deleonardis contributed to the conceptual design of the study and/or data analyses.\n- Andrew Wilson, Anna Chahine, Michael A. Amato, David S. Smith, Pierre Pothier, Nidhi Shah, Lisa S. Klesse, Michael Glick, Michael R. Rosenbaum, Michael B. Benis, Shoshana Gabay, Michael Maass, Catherine M. McGowan, and Andrea Deleonardis contributed to the interpretation of the data and participated in the drafting and critical revision of the article.\n- All authors approved the final version of the manuscript and are accountable for its accuracy and integrity.",
  "publication/journal": "Orphanet Journal of Rare Diseases",
  "publication/year": "2023",
  "publication/pmid": "37689674",
  "publication/pmcid": "PMC10492341",
  "publication/doi": "10.1186/s13023-023-02868-2",
  "publication/tags": "- Gaucher disease\n- Rare diseases\n- Machine learning\n- Algorithm development\n- Electronic health records\n- Clinical characteristics\n- Feature identification\n- Diagnostic algorithms\n- Precision-recall curve\n- Healthcare interactions\n- Data-driven features\n- Clinical decision tools\n- Patient cohort selection\n- Hierarchical clustering\n- Gradient boosting\n- Shapley additive explanations\n- Disease prediction\n- Clinical diagnostics\n- Medical genetics\n- Specialty visits",
  "dataset/provenance": "The dataset utilized in this study is derived from electronic health records (EHRs). The primary cohort consists of patients diagnosed with Gaucher disease (GD), a rare genetic disorder. The diagnosed GD cohort initially comprised 829 patients, but after excluding those with missing information or potential misdiagnoses, the final cohort included 815 patients. Of these, 100 were set aside for the test cohort, and 656 were used for algorithm training, ensuring each had at least one year of coverage.\n\nThe control cohort was selected from patients who did not meet the GD inclusion criteria but were subject to similar exclusion criteria. The training control cohort consisted of 328,000 patients, matched at a ratio of 500 controls for every patient with GD. The test control cohort was significantly larger, comprising 1,000,000 patients, matched at a ratio of 10,000 controls for every patient with GD. This large control group was used to evaluate the algorithm's performance in real-life conditions.\n\nThe data used in this study includes a variety of features categorized into clinical characteristics, demographic information, healthcare interactions, and data-driven features. Clinical characteristics were identified through a review of scientific literature and included information from the Genetic and Rare Diseases Information Center. Demographic features comprised race, US region, and gender. Healthcare interactions were encoded by the frequency of encounters with various specialists and types of visits. Data-driven features were derived to capture aspects prevalent in the GD cohort but not covered by the literature review.\n\nThe dataset has been used to develop and evaluate algorithms for predicting the likelihood of GD. The algorithms were trained using Light Gradient Boosting Machine (LightGBM) and evaluated using the area under the precision-recall curve (AUPRC), a standard approach for imbalanced dataset classification. The performance of the algorithms was assessed on a test dataset with a 1:10,000 GD to control ratio, ensuring robustness and generalizability. The Shapley additive explanations (SHAP) method was utilized to understand the role each feature played in the algorithm predictions, providing insights into the most important factors contributing to the diagnosis of GD.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The training set consisted of 656 patients with Gaucher disease (GD) and 328,000 controls. The test set included 100 patients with GD and 1,000,000 controls. The training set was used to develop the algorithms, while the test set was used to evaluate their performance. The distribution of data points in each split was designed to ensure a robust training and testing process, with a significantly larger number of controls to account for the rarity of GD. The training set had an average age of 44 years, 7 years of coverage, and about 5 symptoms per patient. The test set had a similar average age and symptom count but differed in the frequency of specialist visits. For instance, patients in the test set had more visits to internal medicine specialists, neurologists, and radiologists compared to those in the training set. This distribution helped in assessing the algorithm's performance under real-life conditions.",
  "dataset/redundancy": "The datasets were split into training and test cohorts to evaluate the algorithm's performance. The diagnosed Gaucher disease (GD) cohort was divided into 656 patients for training and 100 patients for testing. The training dataset had an average age of 44 years, 7 years of coverage, and approximately 5 symptoms per patient. The test dataset had similar demographics but, by chance, included patients with a higher prevalence of visits to specialists such as internal medicine, neurology, and radiology.\n\nThe control cohort was significantly larger, with 328,000 patients in the training set and 1,000,000 in the test set. This large disparity was intentional to mimic real-world conditions where GD is rare. The training and test sets were independent, with no overlap between the patients in each set. This independence was enforced by randomly selecting patients for each cohort and ensuring that the same patients were not included in both training and testing phases.\n\nThe distribution of the datasets differs from many previously published machine learning datasets due to the rarity of GD. The imbalanced nature of the datasets, with a much higher number of controls than GD patients, is a key characteristic. This imbalance is addressed through techniques such as bootstrapping and using the area under the precision-recall curve (AUPRC) for evaluation, which are standard approaches for handling imbalanced datasets. The use of a 1:10 GD to control ratio in the training set and a 1:10,000 ratio in the test set reflects the rarity of the disease and ensures that the algorithm is robust and generalizable to real-world applications.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is Gradient Boosting Machines, specifically Light Gradient Boosting Machine (LightGBM). This algorithm is not new; it has been previously developed and published in the context of neural information processing systems.\n\nLightGBM was chosen for its efficiency and effectiveness in handling large datasets and providing accurate predictions. The decision to use this established algorithm was driven by its proven performance in similar tasks, rather than the need to develop a novel method. The focus of the study was on applying machine learning to identify patients highly suspected of having Gaucher disease, leveraging the strengths of LightGBM to achieve this goal.",
  "optimization/meta": "The algorithms developed for predicting the likelihood of Gaucher disease (GD) do not function as a meta-predictor. Instead, they are standalone models trained using specific feature sets derived from electronic health records (EHRs). The features used in the models include clinical characteristics, demographic information, healthcare interactions, and data-driven features. These features were encoded in two ways: age at first occurrence and binary presence/absence.\n\nTwo final algorithms were retained: an age-based algorithm and a prevalence-based algorithm. Both algorithms were trained using a Light Gradient Boosting Machine (LightGBM) and evaluated using the area under the precision and recall curve (AUPRC). The training cohort consisted of patients with GD and controls in a 1:10 ratio, while the test cohort had a 1:10,000 ratio. The algorithms were trained and evaluated independently, ensuring that the training data was distinct from the test data.\n\nThe performance of the algorithms was assessed using cross-validation and bootstrapping techniques to ensure robustness and limit sample bias. The final algorithm selected was based on the best hyper-parameters determined through cross-validation. The Shapley additive explanations (SHAP) method was used to understand the contribution of each feature to the algorithm's predictions.\n\nIn summary, the models are not meta-predictors but rather individual machine-learning algorithms trained and evaluated on separate datasets to predict the likelihood of GD. The training and test data were kept independent to ensure the reliability of the results.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to prepare the electronic health records (EHRs) for the machine-learning algorithms. We identified four main categories of features: clinical characteristics of Gaucher disease (GD), demographic features, healthcare interactions, and data-driven features.\n\nClinical characteristics were derived from a comprehensive review of scientific literature and included information from the Genetic and Rare Diseases Information Center. These characteristics were grouped into organ classes and encoded using two primary methods: age at first occurrence and binary presence/absence. The age-based encoding considered the earliest age at which a feature was recorded, censuring it beyond a reasonable human lifetime at 200 years if not presented. The prevalence-based encoding simply indicated whether a feature was present or absent in a patient's record.\n\nDemographic features included race, US region, and gender. These were straightforward categorical variables that did not require complex encoding.\n\nHealthcare interactions were encoded by the frequency of encounters with various healthcare providers and types of visits (emergency, inpatient, outpatient). This encoding helped capture the intensity and nature of a patient's interactions with the healthcare system.\n\nData-driven features were identified using Cramer\u2019s V test to find associations with the GD cohort. Features with significant associations (Cramer\u2019s V coefficients > 0.1 and p-values < 0.05) were selected and defined using information from de-identified EHRs. These features were also encoded using age-based or prevalence-based methods.\n\nTo define the features, we utilized four data sources within the EHR: diagnosis codes (ICD-9 and ICD-10), procedure codes, laboratory measurements, and pre-extracted Signs/Disease/Symptoms (SDS) terms from providers\u2019 notes. This multi-source approach ensured a comprehensive and accurate representation of each feature.\n\nTreatments were encoded with binary flags indicating their presence or absence, providing a clear indication of whether a patient had received specific treatments related to GD.\n\nHierarchical agglomerative clustering was employed to identify and remove non-representative patients with GD who had insufficient information, ensuring that the training dataset was robust and representative. The GD cohort for algorithm training was restricted to patients with at least one year of coverage, and events across the study period were considered to account for disease evolution after diagnosis.\n\nIn summary, our data encoding and preprocessing involved a meticulous combination of clinical, demographic, and interaction features, encoded using age-based and prevalence-based methods. This approach ensured that the machine-learning algorithms had a comprehensive and accurate dataset to predict the likelihood of GD.",
  "optimization/parameters": "In our study, we utilized a comprehensive set of features to train our algorithms for predicting Gaucher disease (GD). These features were categorized into four main groups:\n\n1. **Clinical Characteristics**: We identified 80 clinical characteristics of GD, grouped into organ classes, based on a review of scientific literature and information from the Genetic and Rare Diseases Information Center (GARD).\n\n2. **Demographic Features**: Three demographic features were included\u2014race, US region, and gender.\n\n3. **Healthcare Interactions**: Information on 16 types of interactions with healthcare providers, including the type of patient visit and encounter frequency, was encoded.\n\n4. **Data-Driven Features**: Eight features were derived from data that were prevalent in the GD cohort but not captured by the literature review. These were selected using Cramer\u2019s V test and expert clinical opinion to ensure relevance.\n\nThe total number of parameters (p) used in the model is the sum of these features. However, the exact number of parameters can vary slightly depending on the specific encoding and preprocessing steps applied to the data.\n\nTo select the most relevant features, we employed Cramer\u2019s V test to identify features that were significantly associated with the GD cohort. Features with Cramer\u2019s V coefficients greater than 0.1 and p-values less than 0.05 were retained. This process ensured that only the most informative features were included in the model, reducing the risk of overfitting and improving the generalizability of the algorithms.\n\nAdditionally, hierarchical agglomerative clustering was used to identify and remove non-representative patients with GD who had a paucity of information, ensuring that the training dataset was robust and representative of the GD population.\n\nThe final set of features was then used to train the Light Gradient Boosting Machine (LightGBM) algorithms. Hyper-parameter tuning and optimization were performed using 10-fold cross-validation to maximize the area under the precision-recall curve (AUPRC), a standard approach for evaluating models on imbalanced datasets. This rigorous selection and optimization process ensured that the algorithms were both accurate and reliable in predicting the likelihood of GD.",
  "optimization/features": "In our study, we utilized a comprehensive set of features to train our algorithms. We identified four main categories of features: clinical characteristics, demographic features, healthcare system interactions, and data-driven features.\n\nThe clinical characteristics were derived from a thorough review of scientific literature and included information from the Genetic and Rare Diseases Information Center. This resulted in 80 clinical characteristics of Gaucher Disease, grouped into organ classes.\n\nDemographic features consisted of three variables: race, US region, and gender.\n\nHealthcare system interactions encompassed information on 16 types of specialists visited, categorized by the type of patient visit and all patient interaction types.\n\nAdditionally, we derived eight data-driven features that were prevalent in the Gaucher Disease cohort but not captured by the scientific literature review. To assess these data-driven features, we employed Cramer\u2019s V test to identify features more or less frequently associated with the Gaucher Disease cohort compared to controls. We used an exact matching method without replacement based on years of coverage to create a similar control population to the Gaucher Disease cohort. Expert clinical opinion was then used to trim features that were likely false associations or irrelevant to the clinical picture. Features selected had Cramer\u2019s V coefficients greater than 0.1 and p-values less than 0.05 using a Chi-square test.\n\nFeature selection was indeed performed, and it was done using a separate control cohort specifically for this exercise, ensuring that the control patients selected for algorithm training were not considered in this step. This approach helped in identifying relevant features that contributed to the prediction of Gaucher Disease.",
  "optimization/fitting": "The fitting method employed in this study utilized the Light Gradient Boosting Machine (LightGBM) algorithm, which is designed to handle large datasets efficiently. The number of parameters in the model was indeed larger than the number of training points, given the extensive feature set and the relatively smaller number of patients with Gaucher disease (GD) in the training cohort.\n\nTo rule out over-fitting, several strategies were implemented. Firstly, hierarchical agglomerative clustering was used to identify and remove non-representative patients with GD who had insufficient information, ensuring that the training dataset was robust. Secondly, a 10-fold cross-validation process was performed, with each fold containing a 1:10 ratio of GD patients to controls. This cross-validation was repeated 10 times, each time selecting unique controls for each bootstrap to limit sample bias. The distribution of the top 10 Area Under the Precision-Recall Curve (AUPRC) values from these bootstraps was analyzed to ensure the algorithm's robustness. Additionally, bootstrapping on controls was performed to mitigate the risk of over-fitting due to the imbalanced dataset.\n\nTo address under-fitting, the algorithm was trained on a comprehensive set of features derived from clinical characteristics, demographic information, healthcare interactions, and data-driven features. The features were carefully selected using statistical methods such as Cramer\u2019s V test and expert clinical opinion to ensure relevance and significance. The use of LightGBM, known for its efficiency and effectiveness in handling large datasets, further helped in mitigating under-fitting by capturing complex relationships in the data. The algorithm's performance was evaluated using the AUPRC, a standard approach for imbalanced dataset classification, ensuring that the model was adequately capturing the nuances of the data without being too simplistic.",
  "optimization/regularization": "To prevent overfitting, several techniques were employed during the optimization process. One key method used was hierarchical agglomerative clustering, which helped identify and remove non-representative patients with a paucity of information from the algorithm training. This ensured that the training dataset consisted of more representative and informative cases.\n\nAdditionally, bootstrapping was performed on the control group to limit sample bias during random selection. This involved creating multiple subsets of the data by sampling with replacement, which helped to ensure that the model's performance was robust and not overly dependent on any particular subset of the data.\n\nCross-validation was also utilized, specifically 10-fold cross-validation, to assess the model's performance and tune hyperparameters. This process involved dividing the training data into 10 subsets, training the model on 9 of these subsets, and validating it on the remaining subset. This was repeated 10 times, each time with a different subset held out for validation. This method helps to ensure that the model generalizes well to unseen data.\n\nFurthermore, the distribution of the top 10 AUPRC (Area Under the Precision-Recall Curve) values from the bootstrapping process was analyzed to ensure the robustness of the algorithm. The final algorithm was selected from these bootstrapped models, ensuring that it performed well across multiple iterations and was not overfitted to any single subset of the data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are not explicitly detailed in the publication. However, the process involved using a 10-folds cross-validation approach with a specific ratio of patients with Gaucher disease (GD) to controls. This process was repeated 10 times, each time selecting a different set of controls for each patient with GD from the training dataset. The distribution of the top 10 area under the precision and recall curve (AUPRC) values from these bootstraps was analyzed to ensure the robustness of the algorithm. The final algorithm selected was one of these bootstraps, chosen randomly.\n\nThe model files and optimization parameters themselves are not provided in the publication. The study focuses on the methodology and results of using machine learning techniques to identify patients highly suspected of having GD, rather than on making the specific model files or detailed optimization parameters publicly available. The algorithms were developed using the Light Gradient Boosting Machine (LightGBM), and the performance was evaluated using the AUPRC, a standard approach for imbalanced dataset classification.\n\nFor those interested in replicating or building upon this work, the general approach and key parameters used in the optimization process are described. However, the specific model files and detailed hyper-parameter configurations are not made available in this publication.",
  "model/interpretability": "The model employed in our study is not a black box. To ensure transparency and interpretability, we utilized the Shapley additive explanations (SHAP) method. This method assigns each feature an importance value based on its contribution to the prediction probability of Gaucher disease (GD). The larger the SHAP value, the higher the feature\u2019s importance in predicting the outcome.\n\nFor instance, the top features identified by SHAP as significant predictors of GD included splenomegaly, geographic location (specifically the northeast region), thrombocytopenia, and osteonecrosis. These features increased the probability of predicting GD. Other notable features that influenced the predictions were bone density issues, bone pain, and the frequency of visits to neurologists, which also heightened the likelihood of a GD prediction. Conversely, features like fever, being located in the midwest region, and abdominal pain decreased the probability of predicting GD.\n\nBy using SHAP, we were able to provide clear insights into which factors were most influential in the model's predictions, making the decision-making process more transparent and understandable. This approach allowed us to rank patients based on their suspicion of having GD, using a prediction probability threshold of \u2265 0.95 to define the \"highly suspected population.\" Additionally, we adapted filter criteria from existing clinical decision tools to further identify patients suspected of having GD, enhancing the model's clinical relevance and interpretability.",
  "model/output": "The model developed is a classification model. It is designed to predict the likelihood of a patient having Gaucher disease (GD) using various features derived from electronic health records (EHR). The model employs a Light Gradient Boosting Machine (LightGBM), which is a type of gradient boosting decision tree algorithm. This algorithm is well-suited for classification tasks, particularly when dealing with imbalanced datasets, which is a common scenario in rare disease prediction.\n\nThe performance of the model was evaluated using the area under the precision-recall curve (AUPRC), a standard metric for assessing classification models on imbalanced datasets. The model was trained on a dataset with a 1:10 ratio of GD patients to controls and tested on a dataset with a 1:10,000 ratio. This approach ensures that the model can effectively identify GD patients even when they are rare in the population.\n\nThe output of the model is a prediction probability for each patient, indicating the likelihood that the patient has GD. Patients with a prediction probability of 0.95 or higher are considered highly suspected of having GD. This threshold was chosen to balance the need for high sensitivity and specificity in identifying potential GD cases.\n\nThe Shapley additive explanations (SHAP) method was used to interpret the model's predictions. SHAP values assign an importance score to each feature, indicating its contribution to the prediction probability. This helps in understanding which features are most influential in predicting GD.\n\nIn summary, the model is a classification model that predicts the likelihood of GD using LightGBM and evaluates performance using AUPRC. The output is a prediction probability, with a threshold of 0.95 used to identify highly suspected GD cases. SHAP values provide insights into the importance of different features in the model's predictions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed for the algorithm involved a comprehensive approach to ensure its robustness and generalizability. The trained algorithms were assessed on a test cohort that included both patients with Gaucher disease (GD) and controls, maintaining a ratio of 1:10,000 GD to controls. This test cohort consisted of 100 patients with GD and 1 million controls, all independent from the training cohort. The evaluation was conducted without censoring any events during the observation period, simulating real-life application conditions.\n\nThe performance of the algorithms was evaluated using the area under the precision and recall curve (AUPRC), a standard approach for imbalanced dataset classification. Hyper-parameter tuning and optimization were performed on the AUPRC through a 10-fold cross-validation process. This cross-validation was repeated 10 times, each time selecting 10 controls for every patient with GD from the training dataset. Bootstrapping on controls was employed to mitigate sample bias during random selection, ensuring that controls were unique within each bootstrap but could be selected across different bootstraps.\n\nThe distribution of the 10 best AUPRC values, one for each bootstrap, was analyzed to confirm the algorithm's robustness. The final algorithm selected was a randomly chosen bootstrap from the 10 options, ensuring a balanced training dataset with a 1:10 GD to control ratio and associated best hyper-parameters determined through cross-validation.\n\nAdditionally, the Shapley additive explanations (SHAP) method was utilized to interpret the role of each feature in the algorithm's predictions. This method assigns an importance value to each feature based on its contribution to the prediction probability of GD. Features with higher SHAP values were deemed more significant in predicting the outcome. The prediction probabilities generated by the algorithm were used to rank patients, identifying those most highly suspected of having GD. A prediction probability threshold of \u2265 0.95 was set to define the \"highly suspected population.\"\n\nThe performance of the algorithms was further compared with an existing clinical diagnostic algorithm by evaluating the number of patients requiring diagnostic testing to identify a given number of GD patients. The demographic and clinical characteristics of the \"highly suspected population\" identified by the algorithms were described and compared with those identified using the clinical diagnostic algorithm and the entire diagnosed GD cohort.",
  "evaluation/measure": "The performance of the algorithms was primarily evaluated using the area under the precision-recall curve (AUPRC). This metric is particularly suitable for imbalanced datasets, which is the case in our study due to the rarity of Gaucher disease (GD). The AUPRC provides a more informative assessment than the traditional ROC curve when dealing with such imbalances.\n\nThe AUPRC values for both the age-based and prevalence-based algorithms were reported to be 0.66. This indicates that the algorithms perform 6.6 times better than a random classifier in predicting the likelihood of GD. The baseline AUPRC, equivalent to a random classifier, is 0.1 given the 1:10 GD to control ratio in the training set.\n\nIn addition to the AUPRC, the algorithms' performance was assessed by comparing the number of patients needing diagnostic testing to find a given number of patients with GD. This comparison was made against an existing clinical diagnostic algorithm, providing a real-world context for the algorithms' effectiveness.\n\nThe use of AUPRC as the primary performance metric aligns with established practices in the literature for evaluating classifiers on imbalanced datasets. This metric, along with the comparison to the clinical diagnostic algorithm, ensures that the reported performance is both representative and relevant to the practical application of the algorithms.",
  "evaluation/comparison": "In the evaluation of our algorithms, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, we focused on developing and validating our own algorithms using a large dataset specific to Gaucher disease (GD).\n\nHowever, we did compare the performance of our algorithms to a baseline classifier. The baseline was established using the area under the precision-recall curve (AUPRC), which is a standard approach for evaluating classifiers on imbalanced datasets. The baseline AUPRC was set at 0.1, reflecting the fraction of positives in our training set, which had a 1:10 GD to control ratio. Both of our final algorithms, the age-based and prevalence-based algorithms, achieved an AUPRC of 0.66, indicating that they performed 6.6 times better than the baseline classifier.\n\nAdditionally, we compared the performance of our algorithms to an existing clinical diagnostic algorithm. This comparison involved assessing the number of patients needing diagnostic testing to identify a given number of patients with GD. We also characterized the patient groups identified by our algorithms and the clinical diagnostic algorithm using descriptive statistics, including age distribution, prevalence of clinical characteristics, and visits to specialists.\n\nWhile we did not use simpler baselines in the traditional sense, our approach involved a rigorous evaluation process that included cross-validation, bootstrapping, and the use of SHAP values to understand feature importance. These methods ensured that our algorithms were robust and that their performance was not due to overfitting or sample bias.",
  "evaluation/confidence": "The evaluation of the algorithms involved assessing their performance using the area under the precision-recall curve (AUPRC), which is a standard approach for imbalanced dataset classification. The AUPRC values for both the age-based and prevalence-based algorithms were 0.66, indicating that the algorithms performed 6.6 times better than a baseline classifier. The baseline AUPRC was 0.1, given the 1:10 GD to control ratio in the training set.\n\nTo ensure the robustness of the algorithms, bootstrapping was performed on the controls, and cross-validation was conducted 10 times. This process involved selecting 10 controls for each patient with GD from the training dataset, helping to limit sample bias during random selection. The distribution of the 10 best AUPRC values was analyzed to confirm the algorithms' reliability.\n\nThe final algorithm was chosen randomly from the 10 bootstraps, ensuring that the training dataset maintained a 1:10 ratio of patients with GD to controls. This approach, combined with hyper-parameter tuning and optimization through 10-fold cross-validation, provided a comprehensive evaluation of the algorithms' performance.\n\nThe statistical significance of the results was assessed using Chi-square and T-tests for categorical and continuous variables, respectively. These tests helped determine the prevalence of clinical characteristics and visits to specialists, ensuring that the differences observed between the GD and control cohorts were statistically significant.\n\nThe algorithms' performance was also compared with a clinical diagnostic algorithm by evaluating the number of patients needing diagnostic testing to identify a given number of patients with GD. This comparison provided additional confidence in the algorithms' effectiveness and their potential real-world application.\n\nOverall, the evaluation process included multiple layers of statistical analysis and validation, ensuring that the algorithms' performance metrics were reliable and statistically significant. The use of bootstrapping, cross-validation, and appropriate statistical tests contributed to the confidence in the algorithms' superiority over baseline classifiers and other methods.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study utilized de-identified electronic health records (EHR) data, which are subject to strict privacy regulations. Therefore, the specific datasets used for training and testing the algorithms cannot be released publicly. The algorithms were developed and evaluated using proprietary data from a specific EHR database, and sharing this data would compromise patient privacy and confidentiality. However, the methods and results of the evaluation are thoroughly documented in the publication, allowing for reproducibility and validation by other researchers. The study adheres to ethical guidelines and regulatory requirements to ensure the protection of patient information."
}