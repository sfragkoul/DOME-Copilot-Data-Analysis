{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- Sharon Turner, Mark Grosvenor, and Eva Hanley provided technical support.\n- Ray Wilson contributed local knowledge of Mere Tarn and assistance with core sampling.\n- JL received a NERC Strategic Environmental Science Capital Grant for supporting the ImageStream imaging flow cytometer.\n- AEC was supported by funding from the National Institutes of Health.\n- CMB acknowledges the NEUBIAS funded STSM to Broad Institute of MIT and Harvard for supporting this work.\n- PR and HDS acknowledge the UK Engineering and Physical Sciences Research Council and UK Biotechnology and Biological Sciences Research Council for supporting this work.",
  "publication/journal": "New Phytologist",
  "publication/year": "2024",
  "publication/pmid": "37678361",
  "publication/pmcid": "PMC10594409",
  "publication/doi": "10.1111/nph.19186",
  "publication/tags": "- Pollen classification\n- Deep learning\n- Palaeoenvironmental samples\n- Taxonomy\n- Morphological features\n- Weak supervision\n- Cross-entropy loss function\n- UMAP visualization\n- Environmental applications\n- Fossil pollen identification",
  "dataset/provenance": "Our dataset was compiled from the analysis of 198,549 pollen grains. These grains were imaged using three channels: bright field (BF), channel 2 (Ch02), and side scatter (SSC), resulting in a total of 595,647 images. The dataset includes 58 classifications, encompassing 53 pollen species and 5 background types. This dataset was split into training, validation, and test sets with a 70/20/10 ratio, respectively. The test data, referred to as hold-out data, was not used during the training process to ensure an unbiased evaluation of the network's performance.\n\nThe images were pre-processed to include normalization, center cropping, and augmentation techniques such as resizing, rotation, and translation. These steps were taken to enhance the robustness of the network and to mitigate overfitting. Additionally, the dataset included examples of background events, such as minerogenic and biogenic particulate, to train the network to recognize and classify non-pollen objects.\n\nTo address potential batch effects from intra-instrument variability, our network was designed to handle variations in the data. Five reference pollen species were also prepared using acid digest techniques, mimicking the treatment of fossil pollen, to assess the effects of sample preparation on the classification accuracy. This approach ensured that the network could generalize well to real-world, environmental samples.",
  "dataset/splits": "The dataset was divided into three splits: training, validation, and test. The distribution of data points in each split was 70% for training, 20% for validation, and 10% for testing. This split was applied to a dataset consisting of 595,647 images across 58 classifications, which included 53 pollen species and 5 background types. The test data, also referred to as hold-out data, was not used to inform the training process in any way. This split ensures that the network's performance can be accurately assessed on unseen data, helping to detect overfitting.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our work is deep learning, specifically a type of convolutional neural network (CNN). This approach is not entirely new, as CNNs have been widely used in image classification tasks. However, the specific implementation and application to pollen classification in palaeoenvironmental samples are unique.\n\nWe term our approach 'Guided Deep Learning'. This method combines multi-labels related to pollen morphology and taxonomy for training images. This unique approach differs from previous studies that have either adopted purely deductive, classical machine learning techniques, which require substantial human input and can fail to capture important subtle features crucial for classification; or purely inductive deep learning networks, requiring minimal human input by creating its own rules for classification, and is therefore deemed a 'black box'.\n\nOur work sits between these two approaches, by allowing the expert to include labels deemed important for classification whilst also taking advantage of features extracted by the network, essentially, lifting the lid on the black box of deep learning. This approach was developed to address the specific challenges of pollen classification in environmental samples, which often contain a broad range of species, including those not present in training libraries, and background objects.\n\nThe reason this algorithm was not published in a machine-learning journal is that the focus of our work is on the application of this method to pollen classification in palaeoenvironmental samples, rather than the development of the machine-learning algorithm itself. The innovation lies in the application and the unique combination of morphological and taxonomical labels, which allows for more accurate and flexible classification of pollen types.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. Instead, it employs a guided deep learning approach that combines multi-labels related to pollen morphology and taxonomy for training images. This method leverages the advantages of deep learning to extract subtle features from images, allowing for the classification of pollen samples across various taxonomic levels.\n\nThe overall approach involves several key steps. Initially, images are labeled based on their morphology and taxonomy, which helps direct the training process to focus on important features. The network is then trained using an adjusted cross-entropy loss function to learn these important features. Features extracted from the global pooling layer are visualized using Uniform Manifold Approximation and Projection (UMAP), a technique that places manifolds according to external labels and preserves both local and global information.\n\nSupport Vector Machine (SVM) learning is subsequently used to classify images based on their positions in the 2D UMAP plot. This process involves supervised learning according to various taxonomy labels, and the models generated are tested on hold-out data and palaeoenvironmental samples. The SVM helps in finding optimized hyperplanes in N-dimensional space that distinctly classify the data points, providing classifications to nearest neighbors in feature space and determining levels of uncertainty.\n\nThe flexibility of the network allows it to handle complex environmental samples and predict the presence of pollen types outside pre-defined classes in a reference library. This approach ensures that the model can identify pollen against non-pollen objects, classify pollen to species and genus levels, and predict at order, family, or genus levels the presence of pollen types independent of the training library. The use of weak supervision further enhances the efficiency of the training process by saving time and reducing the need for extensive manual annotation.",
  "optimization/encoding": "For the data encoding and preprocessing in our study, we employed a multi-label approach to assign multiple labels to each image based on both morphology and taxonomy. This method allowed us to direct the training process to focus on the most important features in the data while also enabling the network to learn more subtle features linked across various levels of the phylogenetic tree.\n\nThe images were labeled with morphology-related tags to highlight key features, and taxonomy labels were used to connect images at different taxonomic levels, such as order, family, genus, and species. This multi-label strategy provided a flexible framework for the network to learn a wide range of features at different taxonomic resolutions.\n\nDuring the training process, each classification was treated as a binary classification problem, and a cross-entropy loss function was used to combine the performance across these various subtasks. This approach allowed the network to update its weights based on the combined loss from all subtasks, ensuring that it could learn both general and specific features effectively.\n\nThe use of weak supervision further enhanced the efficiency of our approach. Instead of manually annotating each image, labels were assigned to subsets of images, which saved time and reduced the need for extensive expert knowledge. This method also allowed the network to learn more flexible features that could scale well across different taxonomy levels.\n\nAdditionally, the global pooling layer was utilized to pool input features over all spatial locations, summarizing the information learned by the entire network. These features were then visualized using Uniform Manifold Approximation and Projection (UMAP), a dimension reduction technique that preserves both local and global information. UMAP was applied to the features extracted from the images, allowing us to visualize high-dimensional data in 2D or 3D space. This visualization was crucial for exploratory analysis and for understanding the relationships between different pollen types at various taxonomic levels.",
  "optimization/parameters": "In our study, the number of parameters (p) used in the model is not explicitly stated, as the focus is on the methodology and performance of the network rather than the specific number of parameters. However, it is important to note that the model employs a multi-classification, multi-label approach, which involves assigning multiple labels to images based on their taxonomy and morphology. This approach allows the network to learn a wide range of features at different taxonomical resolutions.\n\nThe selection of parameters in our model is guided by the use of a cross-entropy loss function, which combines performance across various subtasks and informs the weights of the different layers of the network. Each classification subtask is treated as a binary classification problem, and the loss functions for each subtask are summed together for all images in a batch to update the weights of the network. This method ensures that the network can learn flexible features that scale well across different taxonomy levels.\n\nAdditionally, the network's flexibility is enhanced by the use of weak supervision, where labels are assigned to subsets of images rather than manually annotating each image. This approach saves time during the preparation of training data and allows the network to learn more subtle and abstract features that would be difficult to summarize as a metric.\n\nThe network's performance is further optimized through the use of clustering and visualization techniques, such as Uniform Manifold Approximation and Projection (UMAP), which help in exploring high-dimensional features learned during training. These techniques allow for the visualization of data in 2 or 3 dimensions, making it easier to identify clusters and compare them against classification labels at different levels of the phylogenetic tree.\n\nOverall, the selection of parameters in our model is driven by the need for flexibility and the ability to handle a mixture of testing pollen made up of previously seen pollen and potentially new pollen. The use of weak supervision and advanced visualization techniques ensures that the network can learn a comprehensive set of features, leading to high accuracy in pollen classification.",
  "optimization/features": "The input features for our network are derived from images of pollen samples, which are assigned multiple labels based on their morphology and taxonomy. These labels include both general features such as size and edge formation, as well as more specialized features specific to particular genera or species. The network is designed to handle up to 110 different assigned classifications for each image, allowing it to learn flexible features that can scale across different taxonomy levels.\n\nFeature selection is inherently performed during the training process. The network learns which features are the most informative during this stage, giving higher weighting to some feature labels over others. This process is guided by a cross-entropy loss function that combines performance across various subtasks, informing the weights of the different layers of the network. The use of weak supervision, where labels are assigned to subsets of images rather than each individual image, also contributes to the feature selection process by focusing on the most relevant features for classification.\n\nThe feature selection is done using the training set only. The network is trained on a reference library of modern pollen species and background images, which are manually annotated by an expert. This training data is used to develop the network's ability to identify and classify pollen at various taxonomic levels, from species to order. The features learned by the network are then extracted and visualized using techniques such as Uniform Manifold Approximation and Projection (UMAP), which helps in exploring and interpreting the high-dimensional feature space.",
  "optimization/fitting": "The fitting method employed in our study utilized a deep learning approach based on a modified version of Deepometry, which is built upon the ResNet-50 architecture. This network is designed to handle complex image classification tasks, including those involving pollen grains.\n\nThe number of parameters in our neural network is indeed much larger than the number of training points. To mitigate the risk of overfitting, several strategies were implemented. Firstly, data augmentation techniques such as resizing, rotation, and translation were applied to the training images. This helped to increase the effective size of the training dataset and encouraged the network to learn more robust features. Secondly, a hold-out validation set was used to monitor the network's performance during training. This allowed us to detect and address any signs of overfitting early in the training process. Additionally, the use of a complex loss function that combined multiple binary classification subtasks helped to guide the network's learning towards more generalizable features.\n\nTo ensure that the model was not underfitting, we carefully designed the network architecture and training process. The ResNet-50 architecture, with its residual connections, allows for deeper networks that can learn more complex features without suffering from vanishing gradients. This depth was crucial for capturing the subtle differences between pollen species and higher taxonomic levels. Furthermore, the use of a multi-label classification system enabled the network to learn a wide range of features at different taxonomic resolutions, from general morphological features to more specific characteristics.\n\nThe training process was also designed to balance the trade-off between bias and variance. By using a combination of supervised and guided deep learning, the network was able to learn from both labeled and weakly labeled data. This approach provided the network with a rich set of features to learn from, reducing the risk of underfitting. The performance of the network was thoroughly evaluated on hold-out data, ensuring that it generalized well to unseen data. The results demonstrated high accuracy at various taxonomic levels, indicating that the model was neither overfitting nor underfitting.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our deep learning models. One of the primary methods used was data augmentation. This involved resizing, rotating, and translating the images during the training process. By introducing these variations, the network was encouraged to learn more generalized features rather than memorizing specific details from the training data.\n\nAdditionally, we utilized a hold-out validation set that was not used during the training phase. This set was crucial for assessing the model's performance on unseen data and detecting any signs of overfitting. Confusion plots based on this hold-out data provided insights into the model's accuracy and helped in fine-tuning the training process.\n\nAnother important technique was the use of a modified version of weak supervision. Instead of manually annotating each image, labels were assigned to subsets of images, which allowed the network to learn more flexible features. This approach not only saved time but also helped in reducing overfitting by providing a broader range of labeled data.\n\nThe network architecture itself, based on ResNet-50, included skip connections that improved gradient flow during backpropagation. These skip connections helped in mitigating issues associated with training deeper networks, such as vanishing gradients, and allowed the network to extract more complex features without overfitting.\n\nFurthermore, the use of a multi-label classification system with a complex loss function ensured that the network focused on learning the most informative features. This guided the learning process to key parts of the feature space, making the model more robust and less prone to overfitting.\n\nIn summary, a combination of data augmentation, hold-out validation, weak supervision, and an advanced network architecture with skip connections were employed to prevent overfitting and enhance the generalization capabilities of our models.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the provided information. However, the workflow and modifications made to the Deepometry network, which is based on ResNet-50, are described. The network was trained using a multi-classification, multi-label approach with a complex loss function that combines performance across various subtasks. The loss functions for each subtask were summed together for all images in a batch to update the weights of the network.\n\nThe specific optimization schedule and model files are not reported in the provided information. The network was trained on a dataset of 595,647 images from 198,549 individual modern pollen grains, with a training/validation/test split of 70/20/10. The test data was not used to inform training, and confusion plots were based on hold-out data to assess the accuracy of the network after training and to detect overfitting.\n\nThe Deepometry workflow, which forms the basis of our network, is open-source. However, the specific modifications made to the network and the exact hyper-parameter configurations used in our study are not detailed in the provided information. Therefore, while the general approach and some details about the training process are available, the specific hyper-parameter configurations, optimization schedule, and model files are not explicitly reported.",
  "model/interpretability": "The model employed in our study is not entirely a black box, as we have incorporated several techniques to enhance its interpretability. One key aspect is the use of a global pooling layer, which summarizes information learned by the entire network. This allows for the visualization of high-dimensional features in 2D or 3D, providing insights into the data's structure and the model's decision-making process.\n\nTo further interpret the model's outputs, we utilized Uniform Manifold Approximation and Projection (UMAP), a dimension reduction technique. UMAP produces lower-dimensional representations of high-dimensional data, making it easier to visualize and explore. This technique helps in modeling manifolds in feature space with a fuzzy topological structure, which can be plotted based on external labels or classifications such as pollen order or genus. This approach allows us to interrogate the data for clusters and compare them against classification labels at different levels of the phylogenetic tree.\n\nAdditionally, we employed Support Vector Machine (SVM) learning to classify images based on their representations in low-dimensional space. This method not only provides classifications but also determines and visualizes levels of uncertainty, aiding in further discussion and exploration.\n\nThe Guided Deep Learning approach used in our study also contributes to interpretability. By assigning multiple labels to images based on their morphology and taxonomy, we direct the network to focus on important features. This weak supervision method allows the network to learn more flexible features that can scale well across different taxonomy levels, making the model's decision-making process more transparent.\n\nOverall, while the model leverages the complexity of deep learning, the integration of visualization techniques and guided learning methods enhances its interpretability, providing clear examples of how the model processes and classifies data.",
  "model/output": "The model primarily focuses on classification tasks. It is designed to classify pollen images at various taxonomic levels, including species, genus, family, and order. The model employs a guided deep learning approach, utilizing a multi-classification, multi-label strategy to assign multiple labels to images based on their taxonomy and morphological features. This allows the model to learn flexible features that can scale well across different taxonomy levels.\n\nThe model's performance was evaluated using a reference library of modern pollen species, achieving high accuracy at the species level with an initial network. However, to handle unseen pollen types and provide a more flexible system, a second network was trained to identify pollen at the order level, although with lower accuracy due to feature variability within higher taxonomical levels.\n\nA third network, incorporating guided deep learning, was developed to extract features from images and classify them at multiple taxonomic levels. This network demonstrated high accuracy in typical deep learning tasks and was successfully applied to classify fossil pollen in environmental samples, showing strong performance at order, family, and genus levels.\n\nSupport Vector Machine learning was also used to classify images based on their representations in low-dimensional space, providing classifications and visualizing levels of uncertainty. The model's outputs include visualizations of high-dimensional features using techniques like Uniform Manifold Approximation and Projection (UMAP), which help in exploring and interpreting the data.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the deep learning workflow used in our study is publicly available. We utilized an open-source workflow called Deepometry, which is based on the ResNet50 architecture. This workflow can be accessed and used by researchers for their own projects. The specific details about the implementation, including the modifications made for our study, are provided in the supplementary materials of our publication. The code is released under a permissive license, allowing for broad use and adaptation by the scientific community. Additionally, the workflow includes tools for dimension reduction and visualization, such as Uniform Manifold Approximation and Projection (UMAP), and support vector machine learning for classification. These tools are integrated into the workflow, making it a comprehensive solution for automated pollen classification.",
  "evaluation/method": "The evaluation of our method involved several key steps to ensure its robustness and accuracy. Initially, we prepared a reference library consisting of 53 modern pollen species and background images, which were manually annotated by an expert. This library was used to train our initial network, Network 1, which achieved a 93% accuracy at the species level when tested on hold-out data. The hold-out data was split into training, validation, and test sets in a 70/20/10 ratio, respectively.\n\nTo assess the network's performance, we utilized confusion matrices, which provided insights into the number of correctly identified images and misclassifications. These matrices were crucial for understanding the network's strengths and areas for improvement.\n\nWe also trained Network 2 to identify pollen at the order level, which resulted in a lower accuracy of 67.9% on hold-out data. This discrepancy highlighted the challenges posed by feature variability within higher taxonomical levels.\n\nFor a more flexible approach, we developed Network 3 using a guided deep learning method. This network incorporated expert knowledge of key morphological features and taxonomy, making it robust to noise and background images. We achieved classification accuracies greater than 97% for a subpopulation of pollen analyzed over different days, demonstrating the method's reliability against intra-instrument variability.\n\nAdditionally, we employed Uniform Manifold Approximation and Projection (UMAP) for dimension reduction and visualization of high-dimensional features. This technique allowed us to model manifolds in feature space with a fuzzy topological structure, aiding in the exploration and classification of pollen images.\n\nSupport vector machine learning was then used to classify images based on their positions in the low-dimensional feature space. This approach not only provided classifications but also determined levels of uncertainty, which were visualized for further discussion and exploration.\n\nOverall, our evaluation method combined hold-out data testing, confusion matrices, and advanced visualization techniques to ensure the accuracy and flexibility of our pollen classification system.",
  "evaluation/measure": "In our evaluation, we primarily reported accuracy as our key performance metric. For species-level classification using Network 1, we achieved an overall instance-level accuracy of 93% on hold-out data. This metric is representative of the literature, as accuracy is commonly used to evaluate classification performance in similar studies.\n\nFor order-level classification using Network 2, we reported an overall instance-level accuracy of 67.9%. This lower accuracy reflects the increased feature variability within higher taxonomical levels.\n\nAdditionally, we used confusion matrices to provide a detailed breakdown of classification performance. These matrices show the number of correctly identified images on the diagonal and misclassifications off-diagonal, offering insights into which classes were most often confused.\n\nWe also reported the average probability of an image belonging to a particular class, with an average probability of 0.9714 achieved for fossil pollen classifications. Probabilities less than 0.95 indicated the presence of previously unseen pollen types.\n\nFurthermore, we compared the network's performance to manual counts by a human analyst. The network successfully identified 100% of order, 77% of family, and 96% of genus types present in the environmental sample.\n\nThese metrics collectively provide a comprehensive evaluation of our network's performance, demonstrating its accuracy and flexibility in classifying both seen and unseen pollen types across various taxonomical levels.",
  "evaluation/comparison": "A comparison to simpler baselines was performed, specifically between different networks designed for pollen classification. Initially, Network 1 was trained to identify pollen at the species level, achieving high accuracy but lacking flexibility for unseen pollen types. Network 2 was then trained to identify pollen at the order level, demonstrating lower accuracy due to the increased variability within higher taxonomical levels. This comparison highlighted the need for a more flexible approach.\n\nTo address this, Network 3 was developed using a guided deep learning method. This network utilized broad morphological and taxonomic labels to train on a diverse set of pollen images, allowing it to extract features that could generalize across multiple levels of taxonomy. The performance of Network 3 was evaluated on both hold-out data and environmental samples, showing high accuracy and the ability to identify pollen types not represented in the training library at higher taxonomic levels.\n\nThe comparison between these networks underscored the advantages of the guided deep learning approach in handling complex environmental samples. Network 3's flexibility and accuracy in classifying pollen at various taxonomic levels demonstrated its superiority over simpler baselines and traditional machine learning methods. This approach not only improved classification accuracy but also provided a robust framework for identifying unseen pollen types in environmental samples.",
  "evaluation/confidence": "The evaluation of our deep learning networks for pollen classification includes several performance metrics, but specific confidence intervals for these metrics are not explicitly detailed. However, the overall instance level accuracy for Network 1 is reported as 93%, and for Network 2, it is 67.9%. These accuracies are derived from a dataset split into training, validation, and test sets in a 70/20/10 ratio, ensuring a robust evaluation process.\n\nThe statistical significance of our results is supported by the high accuracy achieved, particularly in distinguishing between morphologically similar pollen species, which is challenging for human analysts. The use of a confusion matrix provides a clear visualization of correctly identified images and misclassifications, further validating the performance of our networks.\n\nAdditionally, the average probability of 0.9714 for fossil pollen classifications indicates a high level of confidence in the predictions made by our network. Probabilities less than 0.95 are flagged as potentially indicating previously unseen pollen types, which is a crucial feature for identifying new or rare species in environmental samples.\n\nThe UMAP visualization tool complements these metrics by clearly indicating the presence of pollen that do not cluster with those represented during training. This tool, along with the probability scores, highlights unseen pollen types within the sample, suggesting the need for further investigation.\n\nWhile specific confidence intervals for the performance metrics are not provided, the combination of high accuracy, detailed confusion matrices, and the use of visualization tools like UMAP provides a comprehensive evaluation of our method's effectiveness. The results demonstrate that our approach is superior to traditional methods and baselines, particularly in handling real-world environmental samples with high uncertainty and variability.",
  "evaluation/availability": "Not enough information is available."
}