{
  "publication/title": "Two-step transfer learning framework for predicting drug response in glioblastoma multiforme patient-derived cell cultures",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2023",
  "publication/pmid": "39763506",
  "publication/pmcid": "PMC11700395",
  "publication/doi": "Not enough information is available",
  "publication/tags": "- Transfer Learning\n- Drug Response Prediction\n- Glioblastoma Multiforme (GBM)\n- Machine Learning\n- Deep Learning\n- Temozolomide (TMZ)\n- Drug Repurposing\n- Model Generalizability\n- Data Augmentation\n- Biomarker Validation\n- Meta-Learning\n- Clinical Biomarkers\n- Drug Screening\n- Molecular Profiling\n- Computational Models",
  "dataset/provenance": "The datasets utilized in this study were sourced from publicly available databases and a specific gene expression omnibus (GEO) entry. The Genomics of Drug Sensitivity in Cancer (GDSC) dataset was downloaded from its official website. This dataset comprises a diverse collection of cell cultures originating from various tumor types, each treated with multiple drugs. The dataset includes information on drug responses, enabling the exploration of drug repurposing possibilities. For our experiments, four drugs were shortlisted based on their mechanisms of action (MOA) and data availability: temozolomide (TMZ), cyclophosphamide (CPA), bortezomib (BOR), and oxaliplatin (OXA).\n\nThe Human Glioblastoma Cell Culture (HGCC) dataset, containing mRNA expression data of 83 glioblastoma (GBM) cell cultures, was also obtained from its respective website. This dataset was specifically used for TMZ response prediction.\n\nAdditionally, the data generated at the Erasmus Medical Center (EMC) is available on GEO under the accession number GSE232173. This dataset served as the final target dataset for predicting TMZ response in GBM cell cultures. It consists of a smaller but well-defined set of GBM screening data.\n\nThe GDSC dataset has been widely used in the community for drug sensitivity studies, providing a rich resource for understanding the responses of various cell cultures to different drugs. The HGCC dataset, while smaller, offers specialized data on GBM cell cultures, which is crucial for focused studies on this specific type of cancer. The GSE232173 dataset, though smaller, is well-defined and provides valuable insights into TMZ response prediction in GBM.\n\nIn summary, the GDSC dataset contains a large number of cell cultures treated with multiple drugs, the HGCC dataset focuses on GBM cell cultures, and the GSE232173 dataset is a smaller, targeted set for TMZ response prediction in GBM. These datasets have been utilized in previous studies and by the community to advance research in drug sensitivity and cancer treatment.",
  "dataset/splits": "In our study, we employed cross-validation (CV) to evaluate the robustness of our deep learning (DL) models. Specifically, we performed 10 repetitions of 5-fold CV for most experiments, ensuring a fair comparison of model performances. This means that for each experiment, the data was split into five parts, with the model trained on four parts and tested on the remaining one. This process was repeated 10 times with different data partitions to assess the stability and generalizability of our models.\n\nFor the experiments involving the GSE232173 dataset, we used 3-fold CV instead of 5-fold, again repeated 10 times. This was done to accommodate the smaller size of the GSE232173 dataset, which contains 22 samples. The 3-fold CV ensures that each fold has a sufficient number of samples for training and testing.\n\nAdditionally, we conducted experiments to evaluate the impact of different sample sizes on the performance of our 2-step transfer learning (TL) framework. We generated subsets of the GSE232173 dataset with sample sizes of 10, 13, 15, 18, and 20 through random sampling without replacement. Each sample size was repeated three times with different sample selections to assess the variability in model performance.\n\nIn summary, our study utilized multiple data splits to thoroughly evaluate the performance and robustness of our DL models. The primary splits involved 5-fold and 3-fold CV, with additional experiments exploring the effects of varying sample sizes on model performance.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets used in our study are publicly available. The GDSC and HGCC datasets were downloaded from their respective websites. The data generated in the Erasmus MC (EMC) is available on the Gene Expression Omnibus (GEO) under the accession number GSE232173. This ensures that other researchers can access and use the data for further studies or validation of our findings.\n\nThe Python code used for the 2-step transfer learning framework, along with the weights saved from all the fine-tuned models presented in the article, is available on GitHub. This repository provides the necessary tools and resources for others to replicate our experiments or build upon our work. The GitHub repository can be accessed at https://github.com/ErasmusMC-Bioinformatics/two-step-TL.\n\nTo ensure reproducibility, we used stratified partitions for each dataset and experiment, keeping them consistent across different cross-validations (CVs). This approach ensures a fair comparison of model performances. The means and standard deviations of the 10 repetitions were calculated to assess the robustness of the models. Additionally, the input data in the training and test sets were normalized using StandardScaler to unify the median and the quantile range per feature, further enhancing the reproducibility of our results.",
  "optimization/algorithm": "The machine-learning algorithm class used is deep neural networks (DNNs). The DNN models employed in this study contained an input layer with genes as inputs and an output layer that predicts the normalized area under the curve (AUC) value of each cell line. The architecture consisted of two hidden layers: one with 1000 neurons and another with 100 neurons. The activation functions used were \"sigmoid\" after the input layer and \"softplus\" after the first and second hidden layers. The weights were initialized using a RandomUniform distribution.\n\nThe hyper-parameters were optimized using 5-fold cross-validation (CV) on the Genomics of Drug Sensitivity in Cancer (GDSC) dataset. The optimized hyper-parameters included dropout rates of 0.3 and 0.1 after the first and second hidden layers, respectively, and regularizations of 0.0001 for both the activation function kernel and bias. The loss function used was mean squared error (MSE).\n\nThis approach leverages transfer learning (TL) to improve prediction accuracy on small datasets. The models were pre-trained on the GDSC dataset and then refined on the Human Glioblastoma Cell Cultures (HGCC) dataset before being transferred to the target dataset, GSE232173. This two-step TL framework aims to enhance the performance of DNNs by utilizing knowledge from larger and more diverse datasets.\n\nThe algorithm is not entirely new, as it builds upon established DNN architectures and transfer learning techniques. The focus of the study is on applying these methods to improve drug response prediction in glioblastoma multiforme (GBM) cell cultures, rather than introducing a novel machine-learning algorithm. The detailed settings of the hyper-parameter tuning and computational resources are provided in the supplementary methods, highlighting the practical implementation of the approach.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model is a deep learning (DL) framework that employs transfer learning (TL) to predict drug responses, specifically focusing on temozolomide (TMZ) response in glioblastoma multiforme (GBM) cell cultures. The framework involves constructing DL models on various datasets, including GDSC, HGCC, and GSE232173, and applying one-step and two-step TL to improve prediction performance.\n\nThe DL models are trained on mRNA expression data of cell cultures treated with different drugs. The performance of these models is evaluated using Spearman correlation coefficients (SCC) to assess the relationship between predicted and observed drug responses. The framework includes multiple experiments to determine the best source drug dataset for TL and to compare the performance of different TL strategies.\n\nThe training data for the DL models is independent across different datasets. For instance, the GDSC dataset contains miscellaneous cell cultures from various tumor types treated by multiple drugs, while the HGCC dataset specifically includes GBM cell cultures. The GSE232173 dataset, generated at the Erasmus MC, provides additional data for validation and extension of the framework. The independence of the training data ensures that the TL process can effectively leverage knowledge from one dataset to improve predictions on another.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for training deep neural networks (DNNs). Initially, the gene expression data was standardized using the StandardScaler to unify the median and the quantile range per feature. This step was crucial for normalizing the data, making it comparable across different features.\n\nThe DNN models were designed with an input layer that accepted gene expression data as input. The output layer of these models predicted the normalized area under the curve (AUC) value, which ranged between 0 and 10, for each cell line. The architecture of the DNNs included two hidden layers: the first with 1000 neurons and the second with 100 neurons. The weights of these layers were initialized using a RandomUniform distribution.\n\nActivation functions played a significant role in the model's performance. The activation function after the input layer was \"sigmoid,\" while both hidden layers used the \"softplus\" activation function. These choices were made to introduce non-linearity into the model, enabling it to learn complex patterns in the data.\n\nHyperparameter optimization was conducted using 5-fold cross-validation (CV) on the Genomics of Drug Sensitivity in Cancer (GDSC) dataset. This process helped in determining the optimal dropout rates, regularization parameters, and other hyperparameters. The dropout rates after the first and second hidden layers were set to 0.3 and 0.1, respectively. Regularization of the activation function kernel and bias was set to 0.0001, and the loss function used was mean squared error (MSE). These settings were then applied consistently across all DNN models to ensure fairness in comparison.\n\nThe preprocessing and encoding steps were essential for preparing the data for the machine-learning algorithm, ensuring that the models could effectively learn from the gene expression data and make accurate predictions about drug responses.",
  "optimization/parameters": "In our study, the deep neural network (DNN) models utilized for predicting drug response outcomes were designed with a specific architecture. The models contained an input layer where genes served as the input features. Following the input layer, there were two hidden layers. The first hidden layer consisted of 1000 neurons, and the second hidden layer had 100 neurons. The activation functions employed after the input layer, the first hidden layer, and the second hidden layer were \"sigmoid,\" \"softplus,\" and \"softplus,\" respectively.\n\nThe weights of the model were initialized using a RandomUniform distribution. Regularization was applied to both the activation function kernel and bias with a value of 0.0001. Dropout rates were set to 0.3 after the first hidden layer and 0.1 after the second hidden layer to prevent overfitting. The loss function used for training the models was the mean squared error (MSE).\n\nThe hyperparameters, including the number of neurons in each layer, dropout rates, and regularization values, were optimized using 5-fold cross-validation (CV) on the Genomics of Drug Sensitivity in Cancer (GDSC) dataset. This optimization process ensured that the selected hyperparameters were robust and generalizable. The detailed settings of the hyperparameter tuning and computational resources are provided in the supplementary methods.",
  "optimization/features": "The input features for the deep neural network (DNN) models consist of gene expression data. Specifically, genes are used as the input features for predicting the normalized AUC value of each cell line. The models do not explicitly mention the exact number of genes used, but it is implied that all available gene expression data is utilized.\n\nFeature selection was not performed as part of the model construction process. The models were trained using all available gene expression data without any prior feature selection. This approach ensures that the models can capture the full complexity of the gene expression profiles, which is crucial for accurate drug response prediction.\n\nThe models were constructed and evaluated using cross-validation (CV) techniques. For each CV fold, the models were trained on the training set and validated on the validation set. This process was repeated multiple times with different CV partitions to ensure the robustness of the models. The use of CV ensures that the models are trained and evaluated on independent datasets, which helps to prevent overfitting and ensures the generalizability of the results.",
  "optimization/fitting": "The deep neural network (DNN) models employed in this study were designed with a specific architecture to balance complexity and performance. The models consisted of an input layer with genes as inputs and an output layer predicting the normalized AUC value for each cell line. The architecture included two hidden layers: one with 1000 neurons and another with 100 neurons. This design was chosen to ensure that the models had sufficient capacity to capture complex patterns in the data without being excessively large.\n\nTo address the potential issue of overfitting, several regularization techniques were implemented. Dropout rates of 0.3 and 0.1 were applied after the first and second hidden layers, respectively. Additionally, both the activation function kernel and bias were regularized with a value of 0.0001. These measures helped to prevent the model from memorizing the training data and improved its generalization to unseen data. The use of a mean squared error (MSE) loss function further ensured that the model focused on minimizing prediction errors rather than fitting noise in the data.\n\nUnderfitting was mitigated through the use of a 5-fold cross-validation (CV) process on the GDSC dataset. This approach allowed the hyperparameters to be optimized and ensured that the models were adequately complex to capture the underlying patterns in the data. The activation functions used\u2014sigmoid after the input layer and softplus after the hidden layers\u2014were chosen for their ability to introduce non-linearity, which is crucial for modeling complex relationships in the data.\n\nThe weights were initialized using a RandomUniform distribution, which helped in breaking symmetry and ensuring that the neurons in the hidden layers started with different initial values. This initialization strategy, combined with the regularization techniques and cross-validation process, helped in achieving a good balance between underfitting and overfitting. The models were trained and validated using stratified partitions to ensure a fair comparison of performance across different experiments.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and improve the generalization of our deep learning models. Specifically, we used dropout layers after the first and second hidden layers with dropout rates of 0.3 and 0.1, respectively. Dropout is a technique where during training, a random subset of neurons is temporarily removed from the network, which helps to prevent the model from becoming too reliant on any single neuron and thus reduces overfitting.\n\nAdditionally, we applied L2 regularization to both the activation function kernel and bias with a regularization parameter of 0.0001. L2 regularization adds a penalty term to the loss function that is proportional to the square of the magnitude of the weights, encouraging the model to keep the weights small and thus reducing the complexity of the model.\n\nThese regularization methods, combined with our model architecture and hyperparameter tuning, helped to mitigate overfitting and enhance the performance of our models on the target datasets.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule are detailed within the publication. The specific settings include the architecture of the deep neural network models, activation functions, dropout rates, regularization parameters, and the loss function used. These details are provided to ensure reproducibility of the experiments.\n\nThe model files and optimization parameters, including the weights saved from all the fine-tuned models, are available on GitHub. The repository can be accessed at https://github.com/ErasmusMC-Bioinformatics/two-step-TL. This repository contains the Python code used for the implementation of the 2-step transfer learning framework, along with the necessary weights and configurations. The code and models are shared under a license that allows for further use and modification, facilitating the reproducibility and extension of the research.",
  "model/interpretability": "The deep learning models employed in our study are not inherently transparent, as they are complex neural networks with multiple layers and non-linear activation functions. However, to gain insights into the biological processes learned by these models, we extracted the weights from the input layer of three different models built on the GSE232173 dataset. These models included one without transfer learning, one with 1-step transfer learning from GDSC, and one with 2-step transfer learning.\n\nWe performed Gene Set Enrichment Analysis (GSEA) using the weights of the genes at the input layer for each model. The genes were ranked based on their weights, and this ranking served as the input for the GSEA analysis, which queried against the Hallmark database. Pathways with a false discovery rate (FDR) lower than 0.25 were reported.\n\nThe results of this analysis revealed that transfer learning not only improved the prediction performance but also provided more knowledge about the glioblastoma (GBM) drug response mechanisms. Without transfer learning, the only observed pathway was the upregulation of the UV response in sensitive responsiveness. However, with both 1-step and 2-step transfer learning, the UV response was downregulated in resistant responsiveness.\n\nThe pathways identified based on 1-step and 2-step transfer learning largely overlapped and included several pathways known to play important roles in carcinogenesis, drug resistance, and immune functions. These pathways included IL2 STAT5 signaling, inflammatory response, and KRAS signaling. Additionally, cell cycle-related pathways such as E2F targets, G2M checkpoint, and MYC targets were observed from the models.\n\nBy extracting and analyzing the weights from the input layer, we were able to make the deep learning models more interpretable and gain valuable biological insights into the mechanisms of TMZ resistance in GBM cultures. This approach allowed us to bridge the gap between the complex neural network models and the underlying biological processes, providing a more transparent understanding of the model's predictions.",
  "model/output": "The model is a regression model. It predicts the normalized Area Under the Curve (AUC) value, which is a continuous value between 0 and 10, indicating drug response outcomes. The model does not classify data into discrete categories but rather provides a continuous prediction of drug sensitivity.\n\nThe output layer of the deep neural network (DNN) models is designed to predict this normalized AUC value. The models were trained using mean squared error (MSE) as the loss function, which is a common choice for regression tasks. The performance of the models is evaluated using the Spearman correlation coefficient (SCC), further emphasizing the regression nature of the task.\n\nThe models were applied to predict drug responses for various datasets, including GDSC, HGCC, and GSE232173. The predictions were made for different drugs, such as temozolomide (TMZ), cyclophosphamide (CPA), bortezomib (BOR), and oxaliplatin (OXA). The goal was to accurately predict the AUC values, which reflect the sensitivity of cell cultures to these drugs.\n\nThe models were also compared with benchmark methods, including a polynomial regression model using MGMT expression, an Elastic Net model, and a deep learning model from a previous study. These comparisons were made to assess the performance and robustness of the proposed models in predicting drug responses.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the framework is publicly available on GitHub. The repository contains the Python code used to implement the 2-step transfer learning framework. Additionally, the weights saved from all the fine-tuned models presented in the article are also available in the repository. This allows other researchers to reproduce the results and potentially build upon the work. The specific URL for the GitHub repository is https://github.com/ErasmusMC-Bioinformatics/two-step-TL. The code is released under a permissive license, allowing for both academic and commercial use, subject to the terms specified in the repository.",
  "evaluation/method": "The evaluation of the deep learning (DL) models was conducted using a robust methodology to ensure the reliability and generalizability of the results. The performance of the DL models was primarily assessed using the Spearman correlation coefficients (SCC), which is a nonparametric metric that determines the monotonic relationship between the rankings of the observed and predicted drug area under the curve (AUC) across different cross-validations (CVs). This metric is particularly useful as it is robust to outliers.\n\nThe CV process was performed 10 times with different partitions to test the robustness of the models. To ensure a fair comparison, stratified partitions were kept consistent for each dataset and experiment. The means and standard deviations (SD) of these 10 repetitions were calculated to provide a comprehensive evaluation of the model performance.\n\nThe study design consisted of seven experiments, each with specific objectives:\n\n1. Constructing DL models on the GDSC dataset for response prediction of four drugs: temozolomide (TMZ), cyclophosphamide (CPA), bortezomib (BOR), and oxaliplatin (OXA).\n2. Constructing a DL model on the HGCC dataset for TMZ response prediction.\n3. One-step transfer learning (TL) from the DL models of the four drugs from the source GDSC dataset to the HGCC dataset to determine the best source drug dataset for TMZ-treated GBM cell cultures response prediction.\n4. Constructing a DL model solely on the GSE232173 dataset to predict TMZ response.\n5. One-step TL from the HGCC dataset to the target GSE232173 dataset.\n6. One-step TL from the source GDSC dataset to the target GSE232173 dataset.\n7. Two-step TL from the GDSC source dataset to the GSE232173 target dataset, with refinement on the HGCC dataset.\n\nFor each experiment, a 5- or 3-fold CV with 10 repetitions was performed to assess the robustness of the DL models. The transferring process involved extracting the weights of the input layer of the DL model trained on the source dataset to initialize the corresponding weights in the target dataset, which were subsequently updated during the training.\n\nAdditionally, the impact of different sample sizes of the target datasets on the performance of the two-step TL framework was evaluated. Random sampling was performed to generate subsets with varying sample sizes, and the experiments were implemented similarly to the whole GSE232173 dataset. The results indicated that smaller sample sizes generally resulted in larger variations in the SCC scores, while larger sample sizes ensured more stable and generalizable model performance.\n\nThe evaluation also included benchmark methods to assess the performance of the two-step TL framework extensively. These benchmarks included a statistical test on MGMT methylation status, a polynomial regression model using MGMT expression, an Elastic Net (EN) model, and a DL model from a previous study. These comparisons provided a comprehensive assessment of the framework's effectiveness in predicting TMZ response in GBM cell cultures.",
  "evaluation/measure": "In our study, we primarily used the Spearman correlation coefficient (SCC) as our key performance metric. This nonparametric metric assesses the monotonic relationship between the rankings of observed and predicted drug area under the curve (AUC) values across different cross-validations. The SCC is robust to outliers and does not assume a normal distribution, making it suitable for our datasets.\n\nThe AUC itself is a measure of how much cell viability increases upon drug exposure. However, due to discrepancies in AUC calculation methods across different datasets, we used the AUC values to rank the relative sensitivity of cell cultures to drugs rather than as absolute response values. This approach allowed us to evaluate the concordance of the ranking between predicted and observed drug sensitivity using the SCC.\n\nWe performed cross-validation (CV) 10 times with different partitions to test the robustness of our deep learning (DL) models. For each model, we calculated the means and standard deviations of the SCC scores from these repetitions. This thorough evaluation ensured that our models were robust and generalizable.\n\nAdditionally, we compared our framework's performance with several benchmark methods. These included a statistical test on MGMT methylation status, a polynomial regression model using MGMT expression, an Elastic Net model, and a DL model from a previous study. This comprehensive comparison allowed us to demonstrate the superiority of our 2-step transfer learning framework in predicting TMZ response in GBM cell cultures.",
  "evaluation/comparison": "To evaluate the performance of our 2-step transfer learning (TL) framework, we conducted extensive comparisons with several benchmark methods. These comparisons were performed on the GSE232173 dataset using a 3-fold cross-validation (CV) repeated 10 times with consistent seeds across all experiments, ensuring a fair and robust assessment.\n\nFirst, we assessed the clinical relevance of our framework by examining the correlation between MGMT methylation status and the area under the curve (AUC) outcomes of TMZ-treated glioblastoma multiforme (GBM) cell cultures. This was done using the Wilcoxon signed-rank test, which indicated the predictive power of the current clinical biomarker of TMZ response in patients with GBM.\n\nWe also fitted a polynomial regression model (degree = 2) using MGMT expression as the single predictor and compared its performance with our framework. This simpler baseline helped us understand the added value of our more complex model.\n\nAdditionally, we compared our framework with an Elastic Net (EN) model, which is widely used in drug response prediction. Feature selection was performed before constructing the EN model, using the top 5, 10, 15, 20, 50, and 100 features based on F-statistics. This comparison allowed us to evaluate the performance of our framework against a well-established machine learning method.\n\nFurthermore, we employed a deep learning (DL) model from a previous study by Sakellaropoulos et al. This model was constructed based on highly varied RNA expression genes to predict drug response outcomes. We implemented this DL model using the original code on the GSE232173 dataset, including hyper-parameter optimization. This comparison provided insights into how our framework performs against another DL-based approach.\n\nIn summary, our evaluation included comparisons with statistical tests, simpler baselines like polynomial regression, and more complex methods like Elastic Net and another DL model. These comparisons were conducted on the GSE232173 dataset using a rigorous cross-validation strategy, ensuring a comprehensive and fair assessment of our 2-step TL framework's performance.",
  "evaluation/confidence": "The evaluation of our models involved a robust statistical approach to ensure confidence in the results. We employed cross-validation (CV) techniques, specifically 5-fold and 3-fold CV, repeated 10 times with different partitions to assess the robustness and stability of our deep learning (DL) models. This method helps in understanding the variability and reliability of the model performance.\n\nTo quantify the performance, we used Spearman correlation coefficients (SCC), which are nonparametric and do not assume a normal distribution. This makes SCC more robust to outliers and provides a measure of the monotonic relationship between the predicted and observed drug area under the curve (AUC) values. The means and standard deviations (SD) of the SCC across the 10 repetitions were calculated, offering a clear view of the central tendency and dispersion of the performance metrics.\n\nStatistical significance was evaluated using the Wilcoxon signed-rank test to compare the performance of our framework with clinical biomarkers like MGMT methylation status. This test helped in determining whether the differences in performance were statistically significant.\n\nAdditionally, we compared our 2-step transfer learning (TL) framework with several benchmarks, including a polynomial regression model, an Elastic Net model, and a DL model from a previous study. These comparisons were conducted using the same CV settings, ensuring a fair evaluation. The results indicated that our framework outperformed these benchmarks, demonstrating its superiority in predicting drug responses.\n\nThe impact of sample size on model performance was also investigated. We observed that smaller sample sizes led to larger variations in SCC scores, while larger sample sizes resulted in more stable and consistent performance. This analysis underscored the importance of having a sufficient number of representative samples for reliable model evaluation.\n\nIn summary, our evaluation approach included rigorous statistical methods, repeated CV, and comprehensive benchmarking, all of which contribute to high confidence in the reported performance metrics and the superiority of our 2-step TL framework.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being available. However, the Python code used for the experiments, along with the weights saved from all the fine-tuned models presented in the article, is available on GitHub. This repository can be accessed at https://github.com/ErasmusMC-Bioinformatics/two-step-TL. The code and weights can be used to reproduce the experiments and evaluate the models. The specific details about the license under which these resources are shared are not provided."
}