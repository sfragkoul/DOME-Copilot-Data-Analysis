{
  "publication/title": "Application of machine learning to ultrasound images to differentiate follicular neoplasms of the thyroid gland.",
  "publication/authors": "The authors who contributed to the article are:\n\nIlah Shin, YJ Kim, K Han, E Lee, HJ Kim, JH Shin, and others.\n\nThe specific contributions of each author are not detailed in the provided information.",
  "publication/journal": "Ultrasonography",
  "publication/year": "2020",
  "publication/pmid": "32299197",
  "publication/pmcid": "PMC7315296",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Follicular neoplasms\n- Thyroid gland\n- Ultrasound imaging\n- Machine learning\n- Classifier models\n- Artificial neural networks\n- Support vector machines\n- Feature extraction\n- Texture analysis\n- Diagnostic performance",
  "dataset/provenance": "The dataset used in this study consisted of preoperative ultrasound (US) images of thyroid nodules. These images were collected as grayscale images from a picture archiving and communication system by radiologists with varying levels of experience in thyroid imaging. The study population included 348 nodules, comprising 252 surgically proven follicular adenoma nodules and 96 follicular carcinoma nodules. These nodules were sourced from two institutions: 104 nodules from 104 patients at Severance Hospital and 244 nodules from 236 patients at Samsung Medical Center. The images were reviewed by an experienced radiologist, who selected a representative image for each nodule. A region of interest (ROI) was manually drawn on these images for further analysis.\n\nThe dataset was not used in previous papers or by the community prior to this study. The images were specifically collected and analyzed for this research to develop and validate classifier models for differentiating between follicular adenoma and carcinoma using machine learning techniques. The study focused on a specific subset of thyroid nodules, ensuring that the data was relevant and targeted for the research objectives.",
  "dataset/splits": "Not applicable.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study belong to the class of supervised learning algorithms. Specifically, two types of algorithms were employed: Support Vector Machine (SVM) and Artificial Neural Network (ANN).\n\nThe SVM algorithm is a well-established method in the field of machine learning, known for its effectiveness in classification tasks. It works by finding the optimal hyperplane that best separates the data into different classes. In this study, a linear classification model was used within the SVM framework.\n\nThe ANN algorithm, on the other hand, is a type of neural network that is designed to mimic the way the human brain processes information. The ANN used in this study had a feed-forward architecture, which means that the information moves in one direction\u2014from the input layer, through the hidden layer, to the output layer. The network was trained using the back-propagation algorithm with a hyperbolic tangent activation function. The ANN consisted of an input layer with 10 neurons, a hidden layer with 12 neurons, and an output layer with two neurons.\n\nThese algorithms are not new but are widely recognized and used in various applications, including medical imaging. The choice to use these specific algorithms was driven by their proven effectiveness in handling complex classification tasks, which is crucial for differentiating between follicular adenoma and carcinoma in preoperative ultrasound images.\n\nThe focus of this study was on the application of these machine-learning techniques to a specific medical problem, rather than on the development of new algorithms. Therefore, the algorithms were implemented using in-house developed software tailored to the needs of the study. The results demonstrate the potential of these algorithms to aid in the diagnostic process, highlighting their utility in medical imaging.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding process involved extracting features from preoperative ultrasound images of thyroid nodules. These images were collected as grayscale images and reviewed by experienced radiologists to select representative images for each nodule. A region of interest (ROI) was manually drawn on these images.\n\nA total of 96 image features were extracted from the ROIs using 2-dimensional image analysis software. These features were categorized into four subgroups based on their extraction methods and characteristics: gray-level co-occurrence matrix (GLCM), gray-level run length matrix (GLRLM), Gabor, and Haar wavelet. For the GLCM and GLRLM methods, a matrix was created for each of the four directions, while the Gabor method considered four directions and three scales.\n\nFrom these 96 features, ten significant features were selected for use as input variables in the classifier models. These selected features included min, mean, entropy, and 0\u00b0 contrast from the GLCM features; 0\u00b0 gray level nonuniformity from the GLRLM features; roundness, rectangularity, and concavity from the morphology features; and entropy (HH2) and entropy (HH1) from the Haar features.\n\nThe extracted features from the preoperative ultrasound images of 252 surgically proven follicular adenoma nodules and 96 follicular carcinoma nodules were then implemented in the in-house developed support vector machine (SVM) and artificial neural network (ANN) classifiers. The SVM used a linear classification model to calculate the optimal hyperplane, while the ANN had a feed-forward architecture trained using the back-propagation algorithm with the hyperbolic tangent activation function. The ANN model consisted of an input layer of 10 neurons, a hidden layer of 12 neurons, and an output layer of two neurons. Due to the small training data size, the leave-one-out cross-validation method was used for model validation.",
  "optimization/parameters": "In our study, we utilized ten features as input parameters for our classifier models. These features were selected from a larger pool of extracted features using a statistical selection process. Specifically, we employed the least absolute shrinkage and selection operator (LASSO) method to identify significant candidates among the extracted features. The selected features included min, mean, entropy, and 0\u00b0 contrast from the gray-level co-occurrence matrix (GLCM) features; 0\u00b0 gray level nonuniformity from the gray-level run length matrix (GLRLM) features; roundness, rectangularity, and concavity from the morphology features; and entropy (HH2) and entropy (HH1) from the Haar features. These ten features were chosen based on their ability to discriminate between follicular adenoma and follicular carcinoma nodules in preoperative ultrasound images. The extracted features from the ultrasound images of 252 surgically proven follicular adenoma nodules and 96 follicular carcinoma nodules were then implemented in our in-house developed support vector machine (SVM) and artificial neural network (ANN) classifiers.",
  "optimization/features": "In the optimization process of our classifier models, we utilized a total of ten features as input variables. These features were carefully selected from an initial pool of ninety-six extracted features, which were derived from preoperative ultrasound images of thyroid nodules.\n\nTo ensure the robustness and relevance of the selected features, a feature selection process was indeed performed. This process involved using the least absolute shrinkage and selection operator (LASSO) method, which is a statistical technique known for its effectiveness in identifying significant features while minimizing overfitting.\n\nIt is crucial to note that the feature selection was conducted using only the training set. This approach ensures that the selected features are unbiased and truly representative of the underlying patterns in the data, thereby enhancing the generalizability of our models. By focusing on the training set, we avoided any potential leakage of information from the test set, which could otherwise compromise the validity of our results.",
  "optimization/fitting": "The fitting method employed in our study involved the use of two classification algorithms: an Artificial Neural Network (ANN) and a Support Vector Machine (SVM). The ANN model had a feed-forward architecture with an input layer of 10 neurons, a hidden layer of 12 neurons, and an output layer of two neurons. The SVM utilized a linear classification model to calculate the optimal hyperplane.\n\nGiven the relatively small training data size, we implemented the leave-one-out cross-validation method to validate our models. This method is particularly useful in scenarios where the number of parameters is not significantly larger than the number of training points, as it ensures that each data point is used once as a validation set while the remaining data points form the training set. This approach helps in mitigating overfitting by providing a robust estimate of model performance.\n\nTo further address the potential for overfitting, we employed the least absolute shrinkage and selection operator (LASSO) method for feature selection. This technique helps in selecting the most relevant features by shrinking the coefficients of less important features to zero, thereby reducing the complexity of the model and enhancing its generalization capability.\n\nUnderfitting was addressed by ensuring that the models were sufficiently complex to capture the underlying patterns in the data. The ANN, with its hidden layer, and the SVM, with its ability to find the optimal hyperplane, were both designed to capture the nuances in the data. Additionally, the use of a hidden layer in the ANN allowed for the modeling of non-linear relationships, which is crucial for capturing the intricate patterns in the ultrasound images of thyroid nodules.\n\nIn summary, the leave-one-out cross-validation method, combined with feature selection via LASSO, helped in ruling out overfitting. The complexity of the models and the use of non-linear activation functions in the ANN ensured that underfitting was avoided, providing a balanced approach to model fitting.",
  "optimization/regularization": "In our study, we employed the least absolute shrinkage and selection operator (LASSO) method as a regularization technique to prevent overfitting. This method was crucial in selecting significant features from the extensive list of extracted features. By applying LASSO, we were able to identify and retain only the most relevant features, thereby reducing the complexity of the model and enhancing its generalization capability. This approach helped in mitigating the risk of overfitting, especially given the relatively small size of our training dataset.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the publication. The classifier models were built using in-house developed software, and the specific configurations and schedules for optimization are not provided. The models employed were a Support Vector Machine (SVM) and an Artificial Neural Network (ANN). The SVM used a linear classification model to calculate the optimal hyperplane, while the ANN had a feed-forward architecture trained with the back-propagation algorithm and a hyperbolic tangent activation function. The ANN consisted of an input layer with 10 neurons, a hidden layer with 12 neurons, and an output layer with two neurons.\n\nThe study utilized leave-one-out cross-validation due to the small training data size, which is a method of model validation but does not provide specific details on the optimization schedule or hyper-parameter tuning process. The features selected for the models were chosen through a statistical selection process using the least absolute shrinkage and selection operator (LASSO) method. However, the exact parameters and configurations for this process are not reported.\n\nModel files and optimization parameters are not made available in the publication. The study focuses on the diagnostic performance of the models rather than the technical details of their configuration and optimization. For further information on the models and their optimization, direct contact with the authors or access to supplementary materials may be necessary.",
  "model/interpretability": "The models developed in this study, specifically the Support Vector Machine (SVM) and Artificial Neural Network (ANN), are generally considered black-box models. This means that while they can provide accurate predictions, the internal workings and the reasoning behind these predictions are not easily interpretable.\n\nThe SVM model, for instance, operates by finding the optimal hyperplane that best separates the data into different classes. While the decision boundary itself can be visualized in lower dimensions, the process of selecting this hyperplane and the features that contribute most to it are not straightforward to interpret.\n\nSimilarly, the ANN model, with its feed-forward architecture and back-propagation algorithm, involves complex interactions between neurons across multiple layers. The weights and biases within these layers are adjusted during training to minimize error, but the specific contributions of individual features to the final output are not easily discernible. The use of a hyperbolic tangent activation function adds another layer of complexity, making it difficult to trace back how specific input features influence the model's decisions.\n\nIn summary, while these models demonstrate high specificity and comparable diagnostic performance to experienced radiologists, their internal mechanisms remain largely opaque. This lack of interpretability is a common characteristic of advanced machine learning models, which often trade off transparency for improved predictive accuracy.",
  "model/output": "The model developed in this study is a classification model. It was designed to differentiate between follicular adenoma and follicular carcinoma nodules using preoperative ultrasound images. Two classification algorithms were employed: an Artificial Neural Network (ANN) and a Support Vector Machine (SVM). The ANN model had a feed-forward architecture with an input layer of 10 neurons, a hidden layer of 12 neurons, and an output layer of two neurons. The SVM model calculated the optimal hyperplane using a linear classification model to classify the data into two classes. The model's performance was evaluated using metrics such as sensitivity, specificity, accuracy, and the area under the receiver operating characteristic curve (AUC). The ANN classifier model showed an accuracy of 74.1%, with a sensitivity of 32.3% and a specificity of 90.1%. The SVM classifier model had an accuracy of 69.0%, a sensitivity of 41.7%, and a specificity of 79.4%. Both models demonstrated higher accuracy than the average values of the radiologists, indicating their potential to aid in the differentiation of thyroid follicular neoplasms.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The software used to build the classifier models in this study was developed in-house. The source code for these models has not been publicly released. Therefore, there is no executable, web server, virtual machine, or container instance available for public use. The software is proprietary and not distributed under any specific license.",
  "evaluation/method": "The evaluation of our classifier models involved several key steps to ensure robust and reliable performance. We utilized leave-one-out cross-validation due to the small size of our training data. This method involves training the model on all but one sample and then testing it on the remaining sample, repeating this process for each sample in the dataset. This approach helps to maximize the use of available data and provides a thorough evaluation of the model's performance.\n\nTo quantify the performance of our models, we calculated sensitivity, specificity, and accuracy. Sensitivity measures the proportion of true positives correctly identified by the model, specificity measures the proportion of true negatives correctly identified, and accuracy measures the overall correctness of the model's predictions. These metrics were compared using logistic regression with generalized estimating equations to account for data clustering caused by patients having multiple thyroid nodules.\n\nAdditionally, we measured the area under the receiver operating characteristic curve (AUC) for both the radiologists and the classifier models. The AUC provides a single scalar value that summarizes the model's ability to discriminate between the two classes. To consider data clustering, we used the Obuchowski method to compare AUC values and calculate 95% confidence intervals.\n\nThe interobserver agreement between the two radiologists was assessed using Cohen kappa coefficients. This statistic measures the agreement between two raters, adjusting for the agreement that could occur by chance. We also calculated positive and negative percent agreement to account for the unbalanced nature of our study population.\n\nStatistical significance was determined using P-values, with values less than 0.05 indicating statistical significance. All statistical analyses were performed using R version 3.4.2. This comprehensive evaluation method ensures that our models are thoroughly tested and validated, providing reliable results for differentiating between follicular adenoma and carcinoma.",
  "evaluation/measure": "In our study, we evaluated the performance of both radiologists and classifier models using several key metrics to ensure a comprehensive assessment. The primary metrics reported include sensitivity, specificity, accuracy, and the area under the receiver operating characteristic curve (AUC). Sensitivity measures the ability of the models and radiologists to correctly identify positive cases (follicular carcinoma), while specificity assesses the ability to correctly identify negative cases (follicular adenoma). Accuracy provides an overall measure of correct classifications, balancing both true positives and true negatives. The AUC offers a single scalar value that summarizes the performance across all classification thresholds, providing a more nuanced view of the model's discriminative ability.\n\nThese metrics are widely recognized and used in the literature for evaluating diagnostic performance, making our set of metrics representative and comparable to other studies in the field. Additionally, we calculated the kappa value to assess interobserver agreement between the two radiologists, which is crucial for understanding the consistency of human interpretation. The positive and negative percent agreement were also reported to account for the unbalanced nature of our study population.\n\nTo ensure robustness, we compared the performance metrics of the classifier models against the average values of the radiologists using logistic regression with generalized estimating equations. This approach allowed us to statistically validate the superiority of the classifier models in certain aspects, such as accuracy and specificity. The cross-validated AUC values were also derived during model construction to provide an unbiased estimate of model performance.\n\nIn summary, the reported performance metrics are comprehensive and aligned with standard practices in the literature, providing a clear and comparable evaluation of both human and machine-based diagnostic approaches.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, our focus was on evaluating the performance of our in-house developed classifier models\u2014specifically, Support Vector Machine (SVM) and Artificial Neural Network (ANN)\u2014against the diagnostic performance of experienced radiologists.\n\nThe radiologists' performance was assessed based on their adherence to the 2015 American Thyroid Association (ATA) guideline for thyroid nodule classification. We calculated sensitivity, specificity, and accuracy for both radiologists and compared these metrics using logistic regression with generalized estimating equations. Additionally, we measured the area under the receiver operating characteristic curve (AUC) for both the radiologists and the classifier models.\n\nTo ensure a fair comparison, we considered data clustering caused by patients having multiple thyroid nodules and used the Obuchowski method to compare AUC values and calculate 95% confidence intervals. The radiologists' average values of sensitivity, specificity, and accuracy were also derived and compared with the corresponding values of the classifier models.\n\nRegarding simpler baselines, our study did not explicitly include a comparison with such baselines. However, the performance of the radiologists, who relied on established guidelines and their expertise, can be considered a baseline for comparison. The classifier models demonstrated higher accuracy than the radiologists' average values, with statistical significance for the ANN model. This suggests that our models, which utilize texture features extracted from preoperative ultrasound images, offer a promising alternative or supplement to traditional radiologist assessments.",
  "evaluation/confidence": "The evaluation of our classifier models and radiologists' performance included several statistical measures to ensure confidence in the results. Confidence intervals were calculated for various metrics to provide a range within which the true value is likely to fall. For instance, the area under the receiver operating characteristic curve (AUC) values for both radiologists and classifier models were accompanied by 95% confidence intervals (CIs). These intervals help in understanding the precision of the AUC estimates.\n\nStatistical significance was assessed using various tests. The independent two-sample t-test and chi-square test were used to compare different variables between follicular adenoma and carcinoma subgroups. The Mann-Whitney U test was employed to compare the mean nodule diameter between these subgroups. Sensitivity, specificity, and accuracy were compared using logistic regression with generalized estimating equations. P-values less than 0.05 were considered statistically significant, indicating that the observed differences were unlikely to have occurred by chance.\n\nThe interobserver agreement between the two radiologists was evaluated using Cohen kappa coefficients, with 95% confidence intervals derived using the bootstrap method. This provided insight into the reliability of the radiologists' agreement beyond mere chance. Additionally, the positive and negative percent agreement were calculated to account for the unbalanced nature of the study population.\n\nThe diagnostic performance of the classifier models was compared with the radiologists' average values, and statistical significance was determined. For example, the ANN classifier model showed higher accuracy than the radiologists' average values, with a statistically significant P-value. The AUC values of the classifier models were also compared with those of the radiologists, demonstrating the superior performance of the models in some cases.\n\nIn summary, the performance metrics included confidence intervals, and the results were statistically significant in many comparisons, supporting the claim that the classifier models can be superior to traditional radiologist assessments in differentiating follicular adenoma from carcinoma.",
  "evaluation/availability": "Not enough information is available."
}