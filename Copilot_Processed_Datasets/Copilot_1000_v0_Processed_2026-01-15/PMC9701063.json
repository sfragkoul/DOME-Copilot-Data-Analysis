{
  "publication/title": "Predicting Hospice Transitions in Dementia Caregiving Dyads: An Exploratory Machine Learning Approach",
  "publication/authors": "The authors who contributed to this article are:\n\n- **Sullivan, D. C.** - Not sure\n- **Hunt, L. M.** - Not sure\n- **Li, L.** - Not sure\n- **Kelley, A. S.** - Not sure\n- **Husain, M.** - Not sure\n- **Aldridge, M. D.** - Not sure\n- **Armstrong, M. J.** - Not sure\n- **Corsentino, P.** - Not sure\n- **DeKosky, S. T.** - Not sure\n- **Taylor, A.** - Not sure\n- **Corwin, E. J.** - Not sure\n- **Bronfenbrenner, U.** - Not sure\n- **Axelsson, M.** - Not sure\n- **Cohen, S. R.** - Not sure",
  "publication/journal": "Innovation in Aging",
  "publication/year": "2022",
  "publication/pmid": "36452051",
  "publication/pmcid": "PMC9701063",
  "publication/doi": "https://doi.org/10.1093/geroni/igac051",
  "publication/tags": "- Hospice Care\n- Dementia\n- Caregiving\n- Machine Learning\n- Quality of Life\n- Social Determinants of Health\n- End-of-Life Care\n- Longitudinal Studies\n- Predictive Modeling\n- Aging and Health",
  "dataset/provenance": "The dataset utilized in this study is derived from the National Health and Aging Trends Study (NHATS) and the National Study of Caregiving (NSOC). These are prospective, longitudinal, annual surveys conducted among Medicare beneficiaries aged 65 years and older and their caregivers across the United States. The NHATS dataset includes data from 12,427 older adults and 3,305 primary caregivers, spanning the years 2011 to 2019. Both studies are sponsored by the National Institutes of Aging (NIA) and are conducted at The Johns Hopkins University.\n\nThe NHATS covers a wide array of important domains for determining health and disability trends among older adults. These domains include physical condition, social needs, cognitive capacity (including dementia), self-care activities and capacity, medical care, participation in valued activities, and well-being. Additional content areas encompass the presence of chronic conditions, symptoms, sensory impairments, subjective and economic well-being, and demographics. The last month of life interview specifically focuses on the quality of end-of-life care.\n\nThe NSOC is a companion study to the NHATS, involving up to five family and unpaid caregivers of a subset of NHATS participants. Caregivers are interviewed on activities, the duration and intensity of care, effects of caregiving on social participation and well-being, and demographic factors. The NSOC corresponds with the NHATS timeline, with caregiver interviews conducted in 2011, 2015, and 2017.\n\nThe data used in this study has been previously analyzed and published, particularly in methods for linking the NHATS/NSOC longitudinally and identifying persons living with dementia within the linked files. This study employs a multiyear secondary data analysis approach, approved by the university Institutional Review Board (IRB), and is used with the permission of the NHATS principal investigators under a written data use agreement.",
  "dataset/splits": "The dataset utilized in this study consists of data from the National Health and Aging Trends Study (NHATS) linked to the National Study of Caregiving (NSOC). The specific data splits are derived from rounds 5 (2015) and 7 (2017), with the baseline year being 2015. The target variable, hospice use, is indicated by the feature pd8hospcelml from round 8 (2018).\n\nThe final dataset includes 117 persons living with dementia. Among these, 65 received hospice care, and 52 did not. This dataset is focused on individuals who died in round 8, as the hospice feature is only applicable to decedents in the NHATS dataset. The data points are distributed based on the presence or absence of hospice use, with a nearly even split between those who received hospice care and those who did not.\n\nThe candidate predictor variables were identified using two interrelated quality-of-life frameworks: the Quality-of-Life in Life Threatening Illness-Family Caregiver Version (QOLLTI-F) for caregivers and the McGill End-of-Life Quality-of-Life (MQOL-E) for persons living with dementia. These frameworks guided the selection of features across various domains, including physical condition, psychological/cognitive features, existential needs, social situation, caregiver features, and sociodemographics.\n\nThe dataset was analyzed using multiple machine learning approaches, including correlation matrix analysis, principal component analysis (PCA), information gain ratio (IGR), and random forest (RF). These methods helped to reveal the most important features for predicting hospice utilization and to narrow the feature space by excluding variables deemed unimportant by most methods. The agreement between models on important features determined the starting point for constructing future models.",
  "dataset/redundancy": "The datasets used in this study were collected from rounds 5 and 7 of the National Health and Aging Trends Study (NHATS) and the National Study of Caregiving (NSOC). The data from these rounds were analyzed together to explore differences in the relationship between predictive variables and target variables.\n\nThe datasets were split into different rounds to reveal more insights through multiyear analysis. The independence of the datasets was ensured by conducting independence analysis using Pearson\u2019s correlation heatmap matrices. This step helped to reduce redundancies and reveal correlation insights among variables.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the context of healthcare and aging studies. The datasets include a variety of sociodemographic features related to persons living with dementia and their caregivers, as well as health-related variables. This comprehensive approach ensures that the datasets are robust and representative of the population under study.\n\nTo enforce independence, the datasets were preprocessed by converting negative values into N/A values and handling N/A values according to the type of feature. For continuous features, N/A values were replaced with column medians, while the most frequent levels replaced categorical feature N/A values. This preprocessing step is crucial for maintaining the integrity and independence of the datasets.\n\nIn summary, the datasets were split by round, and their independence was enforced through correlation analysis and preprocessing steps. The distribution of the datasets is consistent with other published datasets in the field, ensuring the reliability and validity of the study's findings.",
  "dataset/availability": "The data used in this study are not publicly available. The study employs data from the National Health and Aging Trends Study (NHATS) and the National Study of Caregiving (NSOC), which are prospective, longitudinal, annual surveys conducted among Medicare beneficiaries aged 65 years and older and their caregivers across the United States. These datasets are sponsored by the National Institutes of Aging (NIA) and are conducted at The Johns Hopkins University.\n\nThe data were used with the permission of the NHATS principal investigators under a written data use agreement. This agreement ensures that the data are used in accordance with the terms set by the NHATS and NSOC studies, which include restrictions on public release to protect participant confidentiality and comply with ethical guidelines. The study received human subject approval from the university Institutional Review Board (IRB) #MODCR00005076, further ensuring that the data handling and analysis adhered to ethical standards and regulations.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is ensemble learning, specifically the Random Forest (RF) algorithm. RF is not a new algorithm; it is a well-established method in the field of machine learning. It integrates multiple decision trees through ensemble learning, using random resampling and random node splitting techniques to generate multiple decision trees. The final classification result is determined by the voting selection of these decision trees.\n\nThe choice of RF was driven by its robustness and ability to handle complex, nonlinear patterns in data, which is particularly useful for identifying critical quality-of-life and social determinants of health factors associated with hospice use in dementia caregiving dyads. The algorithm's capability to provide feature importance scores was also crucial for selecting the most relevant predictors.\n\nThe study focuses on applying machine learning to a specific healthcare domain rather than introducing a new algorithm. Therefore, it was published in a journal that aligns with the study's primary focus on aging and healthcare, rather than a machine-learning journal. The emphasis is on the application and implications of machine learning in predicting hospice transitions, which is more relevant to the target audience of the journal.",
  "optimization/meta": "The model employed in this study does not function as a meta-predictor. Instead, it utilizes multiple machine learning approaches individually to identify important features for predicting hospice utilization. These approaches include correlation matrix analysis, principal component analysis (PCA), information gain ratio (IGR), and random forest (RF). Each method is applied separately to the data from different rounds (rounds 5 and 7) to reveal insights and reduce the feature space by excluding variables deemed unimportant.\n\nThe random forest algorithm is used to calculate feature importance, and features are selected based on their importance values. The model does not combine the outputs of different machine learning algorithms as input for another predictive model. Instead, it uses the results from these individual methods to inform feature selection and model construction.\n\nThe training data for each round is independent, as the study analyzes data from different time points (rounds 5 and 7) separately. This independence is crucial for the multiyear analysis, which aims to reveal differences in the relationships between predictive variables and the target variable over time. The use of five-fold cross-validation in the random forest algorithm further ensures that the model's performance is robust and generalizable.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for preparing the dataset for the machine-learning algorithms. The original dataset contained many negative and N/A values, and the sample size was small, necessitating careful preprocessing.\n\nFor continuous features, N/A values were replaced with the column medians. This approach helps to maintain the central tendency of the data while handling missing values. For categorical features, the most frequent levels were used to replace N/A values. This method ensures that the most common categories are retained, reducing the impact of missing data on the analysis.\n\nDichotomous predictor variables retained their original coding provided by NHATS/NSOC, where \"yes\" was encoded as 1 and \"no\" as 2. This consistent encoding facilitated straightforward interpretation and analysis of the categorical data.\n\nNegative values in the dataset were converted into N/A values to address the small sample size issue. This conversion helped in standardizing the data format, making it more suitable for the subsequent feature selection and model training processes.\n\nThe target variable, hospice use, was dichotomized as 1 for \"yes\" and 0 for \"no,\" aligning with the original coding provided by NHATS. This binary encoding was essential for the classification tasks in the machine-learning models.\n\nThe preprocessing steps ensured that the data was clean and ready for feature selection and model training. By handling missing values appropriately and standardizing the encoding of categorical variables, the dataset was prepared to reveal meaningful insights and build robust predictive models.",
  "optimization/parameters": "In our study, we utilized a multipronged approach to identify the most important features for predicting hospice utilization, which involved several machine learning techniques. Initially, we had 61 candidate quality-of-life and social determinants of health (SDH) predictors. To narrow down these features, we employed two primary feature selection methods: Information Gain Ratio (IGR) and Random Forest (RF).\n\nThe IGR method identified seven important features, with three from round 5 and four from round 7. These features were selected based on their significance, with an importance threshold greater than 0.05. The RF method, on the other hand, identified ten important features. To ensure robustness, we used five-fold cross-validation and selected features that appeared at least three times across the different folds.\n\nGiven the different feature selection methods and the criteria used, the final number of parameters (p) used in our models varied. For the prediction model based on RF important features, we used the top 10 features identified by the RF method. For the prediction model based on IGR important features, we used the seven features identified by the IGR method.\n\nThe selection of these features was driven by the need to reduce dimensionality and focus on the most relevant predictors. This approach helped us to exclude variables deemed unimportant by all or most methods, thereby narrowing the feature space and improving the model's predictive performance. The agreement between the models on important features also provided a starting point for constructing future models.",
  "optimization/features": "In our study, we initially considered 61 candidate quality-of-life and sociodemographic predictors of hospice use among persons living with dementia and their primary caregivers. These features were collected under various domains, including physical condition and symptoms, psychological/cognitive features, existential needs, social situation, caregiver features, and sociodemographics.\n\nFeature selection was indeed performed to identify the most important predictors. Two methods were employed for this purpose: Information Gain Ratio (IGR) and Random Forest (RF). The IGR method was applied to both individual rounds (round 5 and round 7) and to the combined data from both rounds. This method helped us identify seven important features, with three from round 5 and four from round 7. The RF algorithm was also used to calculate feature importance, leading to the selection of ten important features based on frequency statistics.\n\nTo ensure robustness, feature selection was conducted using the training set only. This approach helped us narrow down the feature space and focus on the most relevant predictors for hospice use. The selected features were then used to build prediction models, which were compared with baseline models to evaluate their performance.\n\nIn summary, while we started with 61 candidate features, feature selection reduced this number to seven or ten, depending on the method used. This process was crucial for identifying the most important predictors and improving the accuracy of our prediction models.",
  "optimization/fitting": "The study employed multiple machine learning approaches to handle a dataset with a relatively small sample size and a large number of features. The number of parameters was indeed much larger than the number of training points, which could potentially lead to overfitting. To mitigate this risk, several strategies were implemented.\n\nFirstly, five-fold cross-validation was used to ensure that the models were robust and not overfitting to the training data. This technique involves splitting the data into five parts, training the model on four parts, and validating it on the remaining part. This process is repeated five times, with each part serving as the validation set once. The results are then averaged to provide a more reliable estimate of the model's performance.\n\nSecondly, feature selection methods were employed to reduce the dimensionality of the data and focus on the most important features. Information Gain Ratio (IGR) and Random Forest (RF) algorithms were used to identify and select the top features. This step helped in reducing the complexity of the model and preventing overfitting.\n\nAdditionally, the study used ensemble learning techniques, specifically Random Forests, which are less prone to overfitting compared to single decision trees. Random Forests use multiple decision trees and aggregate their results, which helps in improving the model's generalization ability.\n\nTo address underfitting, the study ensured that the models were complex enough to capture the underlying patterns in the data. The use of ensemble learning and the selection of important features helped in building models that were neither too simple nor too complex. The models were also evaluated using multiple performance metrics to ensure that they were not underfitting the data.\n\nIn summary, the study employed cross-validation, feature selection, and ensemble learning techniques to handle the imbalance between the number of parameters and training points. These methods helped in building robust models that neither overfit nor underfit the data.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting and ensure the robustness of our models. One key method used was five-fold cross-validation. This technique involves dividing the data into five subsets, training the model on four of these subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. The results are then averaged to provide a more reliable estimate of the model's performance. This approach helps to mitigate overfitting by ensuring that the model generalizes well to unseen data.\n\nAdditionally, feature selection was performed using two methods: Information Gain Ratio (IGR) and Random Forest (RF). IGR was used to identify the most informative categorical features, while RF was employed to calculate feature importance and select the top features. By focusing on the most relevant features, we reduced the complexity of the models and minimized the risk of overfitting.\n\nFurthermore, Principal Component Analysis (PCA) was conducted to visualize and analyze the data. PCA helps in dimensionality reduction by identifying the principal components that explain the most variance in the data. This technique not only aids in understanding the underlying structure of the data but also helps in reducing the number of features, thereby preventing overfitting.\n\nIn summary, the combination of cross-validation, feature selection, and dimensionality reduction techniques ensured that our models were robust and generalizable, effectively preventing overfitting.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models employed in this study are not entirely black-box, as we utilized methods that provide insights into feature importance and relationships. The Random Forest (RF) algorithm, for instance, offers a level of transparency by calculating feature importance, which allows us to identify and rank the most influential features in predicting hospice use. This process involved using Gini coefficients as the criterion for training the RF models and performing five-fold cross-validation to ensure robustness. The top features selected through this method were then used to build a prediction model, demonstrating the model's transparency in feature selection.\n\nAdditionally, Information Gain Ratio (IGR) was used to measure the importance of categorical features, further contributing to the interpretability of the models. The features selected through IGR were also used to build a prediction model, providing another layer of transparency.\n\nTo visualize the data and determine variable independence, Pearson\u2019s correlation matrices were displayed as heatmaps. This step helped in identifying strong correlations among variables, reducing conceptual redundancies, and selecting the most representative features. Although Pearson\u2019s correlation has limitations, such as the assumption of independence and continuous variables, it provided valuable insights into the data.\n\nPrincipal Component Analysis (PCA) was conducted to understand the deeper relationships between variables and to identify the most important aspects of the predictive variables. PCA helped in visualizing which variables contributed the most to the principal components, indicating their importance in explaining the variability of the data set.\n\nIn summary, while the models are not entirely transparent, the use of feature importance calculations, correlation analysis, and PCA provides a level of interpretability. This allows for a better understanding of the factors influencing hospice use and the relationships between variables.",
  "model/output": "The model employed in this study is a classification model. The primary objective was to predict hospice utilization, which is a binary outcome (yes or no). This is evident from the use of random forest (RF) algorithms, which are commonly used for classification tasks. The target variable, hospice use, was dichotomized as 1 for yes and 0 for no. The model's performance was evaluated using cross-validation techniques, and feature importance was determined to identify key predictors of hospice utilization. Several prediction models were constructed, including baseline models and models based on important features selected using information gain ratio (IGR) and RF algorithms. The final models aimed to reveal insights into the factors influencing hospice use among persons living with dementia and their primary caregivers.",
  "model/duration": "The execution time for the models varied depending on the specific tasks and methods used. Initially, feature selection was performed using two methods: Information Gain Ratio (IGR) and Random Forest (RF). IGR was applied to both individual rounds of data and combined data to identify important categorical features. This process involved calculating the information gain for each feature, which measures how much information a feature provides about the target class. The RF algorithm was then used to calculate feature importance by integrating multiple decision trees through ensemble learning. This involved random resampling and node splitting to generate multiple trees and determine the final classification result. The Gini coefficients were used as the criterion for training the RF models, and five-fold cross-validation was applied to obtain robust results. This step was crucial for handling the smaller sample size and ensuring the reliability of the feature importance scores.\n\nFollowing feature selection, four different RF prediction models were constructed using five-fold cross-validation. These models included baseline prediction models built on round 5 data, round 7 data, and combined data from both rounds. Additionally, a prediction model was built using only the top 10 important features selected through the RF importance criteria. Another model was constructed using the seven important features identified through IGR. The execution time for these models depended on the complexity of the data and the number of features considered. The use of five-fold cross-validation ensured that the models were trained and validated multiple times, which contributed to the overall execution time.\n\nIn summary, the execution time for the models was influenced by the feature selection process, the construction of multiple RF prediction models, and the application of five-fold cross-validation. The specific duration would depend on the computational resources available and the size of the dataset. However, the detailed execution time for each step is not explicitly mentioned.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "In our study, the evaluation method primarily involved the use of random forest (RF) algorithms and cross-validation techniques to assess the performance and robustness of our predictive models. We constructed four different RF prediction models, each utilizing five-fold cross-validation to ensure the reliability and generalizability of our results.\n\nThe first set of models, referred to as baseline prediction models, were built using data from round 5, round 7, and a combination of both rounds. These models helped us compare the results and highlight the importance of multiyear analysis. For the combined rounds' data model, features from both rounds were treated as distinct to capture temporal changes.\n\nIn the feature selection step, we employed the RF algorithm to calculate the importance of each feature. This process involved sorting features based on their importance values and selecting the top features. Due to the large number of features, we focused on the top 10 features that were consistently important across multiple models. Five-fold cross-validation was used to identify the 50 most important features, and frequency statistics were applied to screen out features that appeared at least three times, ensuring their significance.\n\nAdditionally, we built a new RF model using only the 10 most important features identified through the frequency criterion. This model allowed us to evaluate the predictive power of the most critical features and validate their consistency across different datasets.\n\nThe use of five-fold cross-validation in our evaluation method ensured that our models were trained and tested on different subsets of the data, reducing the risk of overfitting and providing a more accurate assessment of their performance. This rigorous evaluation approach helped us identify key quality-of-life and social determinants of health (SDH) factors associated with hospice use in dementia caregiving dyads, contributing to the development of more precise and actionable predictive models.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our prediction models. Given the nature of our research, which focuses on predicting hospice utilization, we primarily used metrics that are well-suited for binary classification problems.\n\nOne of the key metrics we reported is accuracy, which measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Accuracy provides a general sense of how well the model performs across all classes.\n\nAdditionally, we used the area under the receiver operating characteristic curve (AUC-ROC). The AUC-ROC is a performance measurement for classification problems at various threshold settings. It provides an aggregate measure of performance across all possible classification thresholds. A higher AUC indicates better model performance.\n\nWe also reported precision, recall, and the F1 score. Precision measures the accuracy of the positive predictions made by the model, while recall (or sensitivity) measures the model's ability to identify all relevant instances. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n\nTo ensure the robustness of our models, we utilized five-fold cross-validation. This technique involves dividing the data into five subsets, training the model on four subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once. The performance metrics are then averaged across the five folds to provide a more reliable estimate of the model's performance.\n\nThese metrics are representative of those commonly used in the literature for evaluating binary classification models, particularly in healthcare settings. They provide a comprehensive view of model performance, considering both the correctness of positive predictions and the ability to identify all relevant cases.",
  "evaluation/comparison": "In our study, we employed a multipronged approach to predict hospice utilization, leveraging several machine learning techniques to identify the most important features. This approach was necessary due to the diverse types of data that make up the features in our study. We utilized correlation matrix analysis, principal component analysis (PCA), information gain ratio (IGR), and random forest (RF) algorithms to reveal data features that are most important for predicting hospice utilization.\n\nTo ensure the robustness of our findings, we compared the results from different rounds of data (rounds 5 and 7) and also analyzed the data from both rounds together. This multistep approach allowed us to exclude variables that all or most methods deemed unimportant, thereby narrowing the feature space. The agreement between models on important features helped determine the starting point for constructing future models rather than working with the raw data.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets, as our focus was on the specific context of hospice utilization for persons living with dementia. However, the use of multiple machine learning approaches provided a comprehensive evaluation of the data, ensuring that our findings were not dependent on a single method.\n\nIn terms of simpler baselines, our baseline prediction models were built using data from round 5, round 7, and both rounds together. These models served as a foundation for comparing the results and revealing the necessity of multiyear analysis. Additionally, we constructed a prediction model based on the important features identified by the RF algorithm, which further refined our understanding of the key predictors of hospice utilization.\n\nOverall, our methodological approach ensured a thorough and rigorous analysis, providing new and useful insights into the important features predicting hospice in dementia caregiving dyads over time.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe evaluation of the prediction models involved several statistical methods to ensure the robustness and significance of the results. Five-fold cross-validation was employed to obtain average and robust results, which helps in understanding the variability and reliability of the models. This technique provides a more comprehensive evaluation by dividing the data into five subsets, training the model on four subsets, and validating it on the remaining subset. This process is repeated five times, with each subset serving as the validation set once.\n\nThe importance of features was determined using two methods: Information Gain Ratio (IGR) and Random Forest (RF). For IGR, features with an importance value greater than 0.05 were selected, indicating increased significance compared to other features. For RF, the Gini coefficients were used as the criterion to train the models, and features were sorted based on their importance values. Only the top 10 features were considered due to the large number of features. Five-fold cross-validation provided the 50 most important features, and through frequency statistics, features with a frequency equal to or more than three were screened out as important features.\n\nThe Pearson\u2019s correlation matrices were displayed as heatmaps to visualize the data and determine variable independence. Correlation coefficients with a p-value less than 0.05 were considered significant, ensuring that the identified correlations were statistically meaningful. This approach helped in identifying variables indicating strong correlations and selecting the best representative questions to reduce conceptual redundancies among highly correlated items.\n\nIn the final step, a correlation analysis was conducted using Kendall\u2019s rank correlation coefficients to interpret the final results of the important features selected by IGR. Kendall\u2019s rank correlation coefficient is a nonparametric statistical parameter used to measure the strength of the monotonic relationship between two ordered variables, providing a robust measure of association.\n\nThe results of the prediction models were compared with baseline models built on individual rounds and combined rounds of data. The robust prediction results obtained indicate that multiyear analysis is necessary and can effectively identify important features associated with hospice use. The consistency of certain features using different methods reveals important commonalities for future research.\n\nIn summary, the evaluation confidence is high due to the use of statistical significance tests, cross-validation techniques, and robust feature selection methods. The results are statistically significant, and the methods used ensure that the claims of superiority over baselines are well-supported.",
  "evaluation/availability": "The raw evaluation files used in this study are not publicly available. The data utilized for this research were obtained from the National Health and Aging Trends Study (NHATS) linked to the National Study of Caregiving (NSOC). Access to these datasets is governed by specific permissions and data use agreements with the principal investigators of NHATS and NSOC. These datasets contain sensitive information about Medicare beneficiaries aged 65 and older and their caregivers, and thus, they are not freely accessible to the public. Researchers interested in accessing these datasets would need to follow the procedures outlined by NHATS and NSOC, which typically involve obtaining approval from the respective study's data access committees and signing a data use agreement. This ensures that the data is used responsibly and in accordance with ethical guidelines and privacy regulations."
}