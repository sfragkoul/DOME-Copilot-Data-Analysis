{
  "publication/title": "Predicting Sarcopenia of Female Elderly from Physical Activity Performance Measurement Using Machine Learning Classifiers",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Clinical Interventions in Aging",
  "publication/year": "2021",
  "publication/pmid": "34611396",
  "publication/pmcid": "PMC8485854",
  "publication/doi": "https://doi.org/10.2147/CIA.S323761",
  "publication/tags": "- Sarcopenia\n- Physical activity\n- Machine learning\n- Inertial measurement unit\n- Elderly health\n- Muscle mass\n- Aging\n- Classification model\n- Health monitoring\n- Predictive analytics",
  "dataset/provenance": "The dataset used in this study was collected from 105 elderly women, with an average age of 78.8 years. These participants were recruited based on specific criteria: they were in their 70s, able to live independently, could walk without assistive devices, did not have cardiovascular diseases, and could understand and perform the required experiments. The study focused on measuring muscle mass, handgrip strength, and physical activity performance to assess sarcopenia stages.\n\nFor muscle mass measurement, a DXA device (Prodigy, GE Healthcare, USA) was utilized. Handgrip strength was assessed using an electronic handgrip strength measuring instrument (TKK-5401, TAKEI, Japan), and the highest result from three measurements was recorded. Walking speed was determined by averaging the results from the 6-minute walk test (6mWT).\n\nTo measure physical activity performance, an inertial measurement unit (IMU) was attached to the second lumbar vertebra (L2) of each participant. The IMU, specifically the Research PRO model from Noraxon, USA, includes a 3D accelerometer, a gyroscope, and a geomagnetic sensor. The data sampling rate was set to 100Hz, and the data were collected using MR 3.12 software from Noraxon.\n\nThe physical activity assessments included the Timed Up and Go (TUG) test and the 6mWT. The TUG test involves standing up from a chair, walking to a return point 3 meters away, turning around, walking back to the chair, and sitting down. This test is commonly used to evaluate balance and mobility in clinical settings. The 6mWT requires participants to walk a round trip of 30 meters in a straight line for 6 minutes, assessing aerobic capacity and mobility.\n\nThe data collection process was approved by the Public Institutions Bioethics Committee designated by the Ministry of Health and Welfare of the Republic of Korea. All participants provided written informed consent. The study aimed to develop a sarcopenia classification model using machine-learning techniques, with a focus on identifying key features from the IMU data that influence sarcopenia prediction.",
  "dataset/splits": "The dataset used for implementing the sarcopenia prediction model consisted of data from 105 individuals. However, data from 27 individuals were excluded due to missing or erroneous physical activity data. This left 78 individuals whose data were used for the model.\n\nThe data of these 78 individuals were used to distinguish the sarcopenia stage, classified into \"sarcopenia\" and \"severe sarcopenia,\" based on the SMI, handgrip measurement data, and walking speed data. According to the AWGS criteria, 58 individuals were determined not to have sarcopenia, while 20 individuals were classified as having \"sarcopenia.\" Notably, there were no individuals classified as having \"severe sarcopenia.\"\n\nThe dataset was further divided into feature selection datasets based on the Kruskal\u2013Wallis test results. These datasets were categorized into three groups: one using all TUG and 6mWT features (F_ALL), another using only TUG features (F_TUG), and the last using only 6mWT features (F_6mWT). Each of these datasets was configured with varying numbers of top features (10, 20, 30, 40, or 50) based on their importance coefficients. The performance of the sarcopenia classification model was then compared across these different feature sets.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are well-established and widely recognized in the field. Specifically, the algorithms employed are support vector machines (SVM), k-nearest neighborhood algorithm (kNN), and Na\u00efve Bayes algorithm (NB). These algorithms are commonly used in the analysis of gait and balance in the elderly, making them suitable for the classification tasks in this research.\n\nThese algorithms are not new; they have been extensively studied and applied in various domains, including medical diagnostics and predictive modeling. The choice of these algorithms was driven by their proven effectiveness in handling classification problems, particularly when dealing with imbalanced datasets, which is a common scenario in medical research.\n\nThe decision to use these established algorithms rather than developing a new one was based on their robustness and reliability. The focus of this study was on predicting sarcopenia using physical activity performance measurements, and leveraging well-understood algorithms allowed for a more straightforward and reliable comparison of model performance. Additionally, publishing in a specialized machine-learning journal was not the primary objective of this research. The study aimed to contribute to the field of geriatric health by demonstrating the practical application of machine learning techniques in predicting sarcopenia, rather than introducing novel algorithmic advancements.",
  "optimization/meta": "Not applicable. The model described does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The study focuses on developing a sarcopenia classification model using three main machine learning algorithms: support vector machines (SVM), k-nearest neighborhood algorithm (kNN), and Na\u00efve Bayes algorithm (NB). These algorithms are used independently to classify sarcopenia based on physical activity data measured by inertial measurement units (IMUs). The performance of these models is compared using the F1 score, and the best-performing model is identified based on this metric. The study does not combine the outputs of multiple machine-learning algorithms to make a final prediction.",
  "optimization/encoding": "The data used for the machine-learning algorithm was collected from 78 female subjects who participated in timed-up-and-go (TUG) and 6-minute walk (6mWT) tests while wearing a single inertial measurement unit (IMU). The raw data included vertical linear acceleration (ACCVT), anterior-posterior acceleration (ACCAP), mediolateral acceleration (ACCML), and the resultant acceleration (ACCRES) derived from these three components. Additionally, 3D angular velocities were measured, including vertical axis angular velocity (YAW), anterior-posterior axis angular velocity (ROLL), and mediolateral axis angular velocity (PITCH).\n\nTo preprocess the data, a moving average filter was applied to remove noise. This filtering step ensured that the data was clean and suitable for feature extraction. From the filtered data, 132 features were extracted based on a literature review. These features were then used to configure feature selection datasets, which were classified into three types: a dataset using all TUG and 6mWT features (F ALL), a dataset using only TUG features (F TUG), and a dataset using only 6mWT features (F 6mWT). Each dataset was further configured with top 10, 20, 30, 40, or 50 features depending on their importance coefficient values, as determined by the Kruskal\u2013Wallis test. This feature selection process aimed to identify the most relevant features for predicting sarcopenia, thereby improving the performance of the classification models.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the feature selection dataset and the specific features chosen. We configured feature selection datasets to include the top 10, 20, 30, 40, or 50 features based on their importance coefficient values, as determined by the Kruskal\u2013Wallis test. This approach allowed us to evaluate the performance of the sarcopenia classification model with different numbers of features.\n\nThe selection of the number of features was guided by the goal of optimizing the model's performance. We compared the performance of the classification models using different numbers of features to identify the optimal configuration. For instance, when using the F ALL dataset, which includes both TUG and 6mWT features, the best performance was achieved with 30 features on average. Similarly, for the F TUG dataset, which includes only TUG features, the optimal performance was observed with 30 features. For the F 6mWT dataset, which includes only 6mWT features, the best performance was achieved with 15 features.\n\nThe Kruskal\u2013Wallis test was employed to select features that had a significant impact on the classification of sarcopenia. This statistical test is particularly useful when the data classes are imbalanced or do not follow a normal distribution, which was the case in our study. Features with higher importance coefficients, as indicated by lower p-values from the Kruskal\u2013Wallis test, were prioritized in the feature selection process.\n\nIn summary, the number of parameters used in the model was determined through a systematic feature selection process that considered the importance of each feature in predicting sarcopenia. The optimal number of features varied depending on the dataset and was selected based on the performance of the classification models.",
  "optimization/features": "In our study, we utilized various features derived from two primary physical activity assessments: the Timed Up and Go (TUG) test and the 6-Minute Walk Test (6mWT). These features were carefully selected to enhance the performance of our sarcopenia classification models. The features included time-based metrics, descriptive statistics such as root mean square (RMS), minimum, and maximum values, as well as gait parameters like step regularity, stride length, and approximate entropy (ApEn).\n\nFeature selection was indeed performed to identify the most influential features for classifying sarcopenia. We employed the Kruskal\u2013Wallis test, a non-parametric method suitable for datasets with unequal class distributions and non-normal data. This test helped us determine the importance of each feature by evaluating the p-value, where a lower p-value indicated a higher feature importance coefficient.\n\nThe feature selection process was conducted using the training set only, ensuring that the model's performance was not biased by information from the test set. This approach allowed us to configure feature selection datasets with varying numbers of top features (10, 20, 30, 40, or 50) based on their importance coefficients. By comparing the performance of our classification models across these datasets, we aimed to identify the optimal number of features that maximized predictive accuracy.",
  "optimization/fitting": "Not applicable",
  "optimization/regularization": "In our study, we employed feature selection as a regularization method to prevent overfitting. We used the Kruskal\u2013Wallis test to identify and select the most important features that significantly influence the classification of sarcopenia. This test is particularly useful when the data classes are imbalanced or do not follow a normal distribution, which was the case in our dataset. By focusing on the top features based on their importance coefficients, we were able to enhance the performance of our classification models and mitigate the risk of overfitting. This approach ensured that our models generalized well to new, unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not entirely a black box, as it incorporates feature selection and specific machine learning algorithms that provide some level of interpretability. The feature selection process, based on the Kruskal\u2013Wallis test, identifies the most important features that significantly affect the classification of sarcopenia. These features are related to physical activity data measured by inertial measurement units (IMUs), such as vertical linear acceleration, anterior-posterior acceleration, mediolateral acceleration, and angular velocities.\n\nFor instance, the top five features that influence the classification of sarcopenia were found to be related to the Timed Up and Go (TUG) test, including the minimum YAW of end-turn, the average ACCVT of sit-to-stand, the maximum YAW of end-turn, the time of end-turn, and the minimum ACCAP of gait. These features provide insights into how decreased muscle function affects various physical activities, such as sit-to-stand movements, turning abilities, and walking.\n\nThe use of specific machine learning algorithms, such as support vector machines (SVM), k-nearest neighborhood algorithm (kNN), and Na\u00efve Bayes algorithm (NB), also contributes to the interpretability of the model. Each algorithm has its own strengths and weaknesses, and their performance can be compared using metrics like the F1 score. This comparison helps in understanding which algorithm is most suitable for predicting sarcopenia based on the given features.\n\nAdditionally, the model's performance is evaluated using different feature selection datasets, including datasets with all TUG and 6-meter walk test (6mWT) features, only TUG features, and only 6mWT features. This evaluation provides further insights into which features are most important for accurate classification.\n\nOverall, while the model leverages complex machine learning techniques, the feature selection process and the evaluation of different algorithms and datasets contribute to its interpretability. This allows for a better understanding of how physical activity data measured by IMUs can be used to predict sarcopenia.",
  "model/output": "The model developed in this study is a classification model. It is designed to predict sarcopenia in the elderly based on physical activity data measured by inertial measurement units (IMUs). The model uses machine learning algorithms to classify individuals into categories related to sarcopenia status.\n\nSeveral classification algorithms were evaluated, including support vector machines (SVM), k-nearest neighborhood algorithm (kNN), and Na\u00efve Bayes algorithm (NB). The performance of these models was compared using the F1 score, which is a metric that considers both precision and recall, making it suitable for evaluating models when the data is imbalanced.\n\nThe kNN classification model using the top 40 features from a dataset that includes both Timed Up and Go (TUG) and 6-minute walk test (6mWT) features showed the highest performance, with an F1 value of 0.881. This indicates that the model is effective in classifying sarcopenia when the right features and algorithms are used.\n\nThe study also found that using both TUG and 6mWT physical activities improved the performance of the classification model. This suggests that a comprehensive approach, incorporating multiple types of physical activity data, is beneficial for accurate sarcopenia prediction.\n\nIn summary, the model is a classification model that aims to predict sarcopenia in the elderly using IMU data and machine learning techniques. The kNN algorithm with selected features from combined TUG and 6mWT datasets demonstrated the best performance.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method involved comparing the performance of different machine learning classification models to predict sarcopenia using various feature selection datasets. The datasets were configured based on the results of the Kruskal\u2013Wallis test and included features from the Timed Up and Go (TUG) test, the 6-minute Walk Test (6mWT), or both. These datasets were further divided into subsets containing the top 10, 20, 30, 40, or 50 features based on their importance coefficients.\n\nThree classification algorithms were used: Support Vector Machines (SVM), k-Nearest Neighborhood (kNN), and Na\u00efve Bayes (NB). The performance of these models was evaluated using the F1-score, which is particularly useful when the dataset is imbalanced. The F1-score is calculated as the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n\nPrecision is defined as the ratio of true positives to the sum of true positives and false positives, while recall is the ratio of true positives to the sum of true positives and false negatives. The F1-score ranges from 0 to 1, with higher values indicating better performance.\n\nThe evaluation process involved comparing the F1-scores of the models across different feature selection datasets and the number of features used. For the dataset combining TUG and 6mWT features (FALL), the kNN model showed the highest performance with an F1-score of 0.881 when using the top 40 features. In contrast, the NB model had the lowest performance with an F1-score of 0.648 when all features were used. The average performance was best with 30 features, achieving an F1-score of 0.864 \u00b1 0.002.\n\nFor the dataset using only TUG features (FTUG), the SVM model performed best with an F1-score of 0.860 when using the top 40 features, while the NB model had the lowest performance with an F1-score of 0.697 when all features were used. The best average performance was achieved with 30 features, resulting in an F1-score of 0.845 \u00b1 0.014.\n\nOverall, the kNN and SVM algorithms generally outperformed the NB algorithm across different feature selection datasets. The results indicated that using a subset of the most important features, rather than all available features, tended to improve the performance of the classification models. This evaluation method provided a comprehensive assessment of the models' ability to predict sarcopenia based on physical activity data measured by Inertial Measurement Units (IMUs).",
  "evaluation/measure": "The performance of the classification models was primarily evaluated using the F1-score, which is a metric that combines precision and recall. This metric is particularly useful when dealing with imbalanced datasets, which is common in medical diagnostics. The F1-score ranges from 0 to 1, with higher values indicating better performance. It is calculated using the harmonic mean of precision and recall, which are derived from the confusion matrix. Precision measures the accuracy of the positive predictions made by the model, while recall measures the model's ability to identify all relevant instances.\n\nThe F1-score was chosen because it provides a balanced measure of a model's performance, especially when the classes are imbalanced. This is crucial in the context of sarcopenia classification, where the number of instances in each class may vary significantly. By using the F1-score, we ensure that the model's performance is evaluated comprehensively, taking into account both false positives and false negatives.\n\nIn addition to the F1-score, the performance of the models was also compared using different numbers of features selected based on their importance coefficients. This approach allowed us to determine the optimal number of features for each classification algorithm, ensuring that the models were neither underfitted nor overfitted. The algorithms compared included support vector machines (SVM), k-nearest neighbors (kNN), and Na\u00efve Bayes (NB). The results showed that the kNN algorithm generally performed best when using a specific number of features, particularly 40 features from the combined dataset of TUG and 6mWT.\n\nThe use of these performance metrics is representative of current practices in the field. The F1-score is widely recognized and used in machine learning and medical diagnostics for evaluating classification models, especially when dealing with imbalanced datasets. This metric provides a clear and concise measure of model performance, making it an essential tool for comparing different algorithms and feature selection strategies.",
  "evaluation/comparison": "In our study, we compared the performance of our sarcopenia classification models with other machine learning algorithms to identify the most suitable one for predicting sarcopenia. We evaluated three primary classification algorithms: support vector machines (SVM), k-nearest neighborhood algorithm (kNN), and Na\u00efve Bayes algorithm (NB). These algorithms are commonly used in the analysis of gait and balance in the elderly.\n\nWe assessed the performance of these algorithms using the F1-score, which is particularly useful when dealing with imbalanced datasets. The F1-score ranges from 0 to 1, with higher values indicating better performance. It is calculated using the harmonic mean of precision and recall, derived from the confusion matrix.\n\nFor the dataset that included both TUG and 6mWT features (FALL), the kNN classification model using 40 features showed the highest performance with an F1 value of 0.881. In contrast, the NB classification model using all features had the lowest performance with an F1 value of 0.648. The average performance across all features was best with 30 features, achieving an average F1 of 0.864 \u00b1 0.002, and worst with all features, achieving an average F1 of 0.777 \u00b1 0.114. The kNN algorithm generally performed the best, followed by SVM, with NB showing the lowest performance.\n\nFor the dataset that included only TUG features (FTUG), the SVM classification model using 40 features had the highest performance with an F1 value of 0.860. The NB classification model using all features had the lowest performance with an F1 value of 0.697. The best average performance was achieved with 30 features, with an average F1 of 0.845 \u00b1 0.014, and the worst with 50 features, with an average F1 of 0.778 \u00b1 0.030. SVM and kNN showed similar performance, while NB had the lowest performance.\n\nFor the dataset that included only 6mWT features (F6mWT), the kNN classification model using 15 features had the highest performance with an F1 value of 0.807. The NB classification model using all features had the lowest performance with an F1 value of 0.566. The best average performance was achieved with 15 features, with an average F1 of 0.751 \u00b1 0.085, and the worst with all features, with an average F1 of 0.658 \u00b1 0.083. SVM performed the best, followed by kNN, with NB showing the lowest performance.\n\nIn summary, the kNN classification model using 40 features of the combined dataset (FALL) showed the highest performance with an F1 value of 0.881. The SVM classification model using 40 features of the TUG dataset (FTUG) showed moderate performance with an F1 value of 0.860. The kNN classification model using 15 features of the 6mWT dataset (F6mWT) showed the lowest performance with an F1 value of 0.807. These comparisons highlight the effectiveness of different algorithms and feature sets in predicting sarcopenia.",
  "evaluation/confidence": "The performance metrics in this study include confidence intervals, which are provided for the F1 scores of the classification models. These intervals give an indication of the variability and reliability of the performance estimates. For instance, the average F1 scores for the classification models using different numbers of features are reported with their respective standard deviations, such as 0.864 \u00b1 0.002 for 30 features and 0.777 \u00b1 0.114 for all features. This allows for an assessment of the statistical significance and the confidence in the performance differences observed.\n\nThe study compares the performance of three classification algorithms: support vector machines (SVM), k-nearest neighborhood algorithm (kNN), and Na\u00efve Bayes algorithm (NB). The results show that kNN generally performs better than the other algorithms, particularly when using a selected number of top features. For example, kNN achieved the highest F1 score of 0.881 when using 40 features from the combined dataset (FALL). In contrast, NB showed the lowest performance with an F1 score of 0.648 when all features were used.\n\nStatistical significance is implied through the comparison of these performance metrics. The differences in F1 scores across different algorithms and feature sets suggest that the observed performance improvements are not due to random chance. For example, the kNN algorithm's superior performance with a selected number of features indicates that feature selection plays a crucial role in enhancing model performance. This is further supported by the consistent trend observed across different datasets (FALL, FTUG, and F6mWT), where feature selection consistently improved model performance.\n\nAdditionally, the study compares its results with previous works, highlighting that the kNN and SVM algorithms performed better than logistic regression algorithms used in other studies. This comparison provides further evidence of the statistical significance and superiority of the methods employed in this study. The use of confidence intervals and the consistent performance trends across different datasets and algorithms strengthen the claim that the proposed methods are effective and reliable for predicting sarcopenia.",
  "evaluation/availability": "The raw evaluation files used in this study are not publicly available. The data collection process involved measuring various physical activities and parameters from participants, but these raw datasets have not been released for public access. The study was conducted under specific ethical guidelines and approvals, ensuring the privacy and consent of the participants. Therefore, the raw data remains confidential and is not accessible to the public. The findings and results presented in the publication are based on the analysis of this data, but the actual datasets themselves are not provided. For further details or potential access to the data, interested parties may need to contact the authors or the relevant institutions directly, adhering to the ethical and legal standards that govern the use of such data."
}