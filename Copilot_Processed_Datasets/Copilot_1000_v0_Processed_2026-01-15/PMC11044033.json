{
  "publication/title": "Optimizing breast cancer diagnosis with photoacoustic imaging: An analysis of intratumoral and peritumoral radiomics",
  "publication/authors": "The authors who contributed to this article are Luyao Zhou and Fajin Dong.\n\nLuyao Zhou is the Chief Physician of the Department of Ultrasound at Shenzhen Children\u2019s Hospital. They have authored over 60 publications, with more than 40 of them as the first or corresponding author. These publications include notable works in journals such as Nature Communications, Radiology, the Journal of Internal Medicine, European Radiology, and AJR. Zhou has led two National Natural Science Foundation projects and two Guangdong Provincial Natural Science Foundation projects. They have also received support from the Ke Lin New Star Talent Program and the Young Teacher Basic Research Fund.\n\nFajin Dong is the Chief Physician of the Ultrasound Department at Shenzhen People\u2019s Hospital and a supervisor of master\u2019s students. Dong specializes in abdominal, superficial, and musculoskeletal ultrasound diagnosis and intervention therapy. They have published over 60 SCI papers as the first or corresponding author, with representative works in journals like Medical Image Analysis, Research, and Nature Communications. Dong has led and participated in numerous national, provincial, and municipal projects. They serve on various committees, including the Ultrasound Branch of the Chinese Medical Association\u2019s Superficial and Vascular Group, the Musculoskeletal Ultrasound Special Committee of the Chinese Medical Doctor Association, and the Musculoskeletal Special Committee of the Chinese Society of Ultrasound in Medicine Engineering.",
  "publication/journal": "Photoacoustics",
  "publication/year": "2024",
  "publication/pmid": "38665366",
  "publication/pmcid": "PMC11044033",
  "publication/doi": "10.1016/j.pacs.2024.100606",
  "publication/tags": "- Breast nodules\n- Photoacoustic imaging\n- Ultrasound imaging\n- Radiomics\n- Breast cancer diagnosis\n- Multimodal imaging\n- Breast lesion characterization\n- Machine learning in medical imaging\n- Breast nodule malignancy prediction\n- Breast imaging biomarkers",
  "dataset/provenance": "The dataset utilized in this study was sourced from a consecutive cohort of 358 patients who had BI-RADS 3-5 breast nodules and underwent PA/US examinations followed by surgical interventions for breast lesions. These patients were treated at our institution from January 2022 to November 2023. The pathological validation for benign lesions was obtained through 14-gauge core needle biopsies, while the confirmation of malignant tumors was based on postoperative pathological findings.\n\nThe dataset was meticulously curated by applying stringent exclusion criteria to ensure the integrity and reliability of the data. These criteria included excluding pregnant or lactating women, individuals with compromised skin integrity in the assessment area, patients with ongoing or active breast or axillary infections, those with subcutaneous congestion, hemorrhagic purpura, or nevus nigricans in the imaging area, patients with a history of psychiatric disorders that could affect compliance, those who had received neoadjuvant chemotherapy within three months prior to the examination, and cases with incomplete pathological records, a history of radiotherapy or chemotherapy, or suboptimal US image quality.\n\nThe dataset was divided into training and testing sets to facilitate the development and validation of the photoacoustic radiomics model. The training set consisted of 286 patients, while the testing set included the remaining patients. This division allowed for a comprehensive evaluation of the model's performance and its potential for integrating radiomics in PA imaging for breast nodule diagnosis.",
  "dataset/splits": "The dataset was divided into two primary splits: a training set and a testing set. The training set consisted of 286 patients, while the testing set included 72 patients. Within the training set, there were 156 benign nodules and 130 malignant nodules. In the testing set, there were 39 benign nodules and 33 malignant nodules. The clinical features of these patients, such as age, height, weight, diameter, and location, showed no significant differences between the training and testing sets, ensuring a balanced distribution for model training and validation.",
  "dataset/redundancy": "The dataset consisted of 358 cases of BI-RADS 3\u20135 breast nodule patients, which were divided into two independent groups: a training set with 286 patients and a testing set with 72 patients. The training set included 156 benign nodules and 130 malignant nodules, while the testing set comprised 39 benign nodules and 33 malignant nodules.\n\nThe clinical features of these patients, such as age, height, weight, diameter, and location, were summarized and compared between the training and testing sets. The analysis showed no significant differences among these characteristics, ensuring that the datasets were comparable.\n\nTo enforce independence between the training and testing sets, the patients were randomly assigned to either the training or testing group. This random assignment helped to mitigate any potential bias and ensured that the models developed were generalizable to new, unseen data.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in the field of breast nodule classification. The inclusion of both benign and malignant cases in a balanced manner ensures that the models can effectively distinguish between the two types of nodules. The use of a separate testing set allows for a robust evaluation of the model's performance, providing a clear indication of its diagnostic utility.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the Least Absolute Shrinkage and Selection Operator (LASSO) regression model. This is a well-established machine-learning algorithm class, specifically a type of linear regression that includes a penalty term to enforce sparsity in the model, effectively performing both variable selection and regularization.\n\nThe LASSO regression model is not a new algorithm. It has been widely used in various fields, including radiomics, for feature selection and model building due to its ability to handle high-dimensional data and reduce overfitting.\n\nThe reason this algorithm was not published in a machine-learning journal is that our primary focus is on the application of radiomics in medical imaging, particularly in the differentiation of benign and malignant breast nodules using photoacoustic imaging. The LASSO regression model was chosen for its suitability in this context, rather than as a novel contribution to the field of machine learning. Our study leverages this established method to extract and select relevant radiomic features, which are then used to build predictive models for clinical applications.",
  "optimization/meta": "In our study, we developed a nomogram model that serves as a meta-predictor, integrating multiple sources of information to enhance predictive performance. This model incorporates both clinical features and radiomic features derived from photoacoustic imaging.\n\nThe clinical model, which forms part of our meta-predictor, utilizes age and tumor diameter as primary variables. This model demonstrated strong discriminative ability with an Area Under the Curve (AUC) of 0.863 in the training dataset and 0.794 in the testing dataset.\n\nIn addition to the clinical model, we constructed several radiomic models. These include an intratumoral PA imaging radiomics model, which uses 35 optimal intratumoral features selected via LASSO regression. Furthermore, we developed combined intratumoral-peritumoral PA imaging radiomics models that integrate features from different peritumoral regions (2 mm, 5 mm, and 8 mm). These models incorporate 37, 33, and 32 optimal features, respectively.\n\nThe nomogram model, which is our final meta-predictor, combines the clinical model with these radiomic models. This integration aims to leverage the strengths of both clinical and radiomic data to improve the overall predictive accuracy. The performance of the nomogram model was evaluated using Receiver Operating Characteristic (ROC) curves, calibration curves, and Decision Curve Analysis (DCA).\n\nRegarding the independence of training data, our study involved a separate cohort for validation, ensuring that the training and testing datasets were independent. This approach helps to validate the generalizability and robustness of our models. The training set consisted of 286 patients, while the testing set included 72 patients, with no significant differences in clinical characteristics between the two groups. This independence is crucial for assessing the model's performance and avoiding overfitting.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the robustness and reliability of the features extracted. Initially, photoacoustic (PA) images were archived in the Digital Imaging and Communications in Medicine (DICOM) format. The region of interest (ROI) for feature extraction was manually delineated on the largest cross-sectional area of the PA image using ITK-SNAP software. This task was performed by two experienced breast radiologists, each with over a decade of expertise in breast ultrasound, who were blinded to the final pathological outcomes.\n\nTo assess the reliability and reproducibility of the features, intraclass correlation coefficients (ICC) were calculated using 60 randomly selected PA images. Features demonstrating an ICC greater than 0.75, indicating excellent stability, were selected for further analysis. Standardization of feature values was achieved via z-score normalization, and feature correlations were evaluated using the Spearman correlation coefficient. In cases where the correlation coefficient exceeded 0.9, only one of the correlated features was retained to avoid redundancy. Additionally, a Mann-Whitney test was performed on the features, and any feature with a P value greater than 0.05 was eliminated to ensure statistical significance.\n\nThe construction of radiomic features was facilitated using the least absolute shrinkage and selection operator (LASSO) regression model, applied to the training dataset. The LASSO methodology effectively reduces regression coefficients towards zero, thereby assigning zero coefficients to numerous non-essential features, depending on the weighting parameter \u03bb. The optimal \u03bb was determined through a 10-fold cross-validation process, employing a minimum criterion approach. This method identified the \u03bb value that resulted in the minimal cross-validation error. Subsequently, the parameters of the retained features with non-zero coefficients were incorporated into the regression model fitting. The Pyradiomics platform was utilized for automated extraction of these radiomic features from each image.",
  "optimization/parameters": "In our study, we utilized a total of 214 radiomic features, which included 107 intratumoral features and 107 peritumoral features. From this set, we selected optimal features using LASSO regression to construct our models. Specifically, 35 optimal intratumoral features were chosen for the intratumoral PA imaging radiomics model. Additionally, we incorporated 37 optimal features combining intratumoral and 2 mm peritumoral, 33 combining intratumoral and 5 mm peritumoral, and 32 combining intratumoral and 8 mm peritumoral features to establish distinct combined intratumoral-peritumoral PA imaging radiomics models.\n\nThe selection of these features was facilitated by the LASSO regression model, which effectively diminishes regression coefficients towards zero, thereby assigning zero coefficients to numerous non-essential features. The optimal \u03bb value, which determines the weighting parameter in LASSO, was identified through a 10-fold cross-validation process employing a minimum criterion approach. This method ensured that the \u03bb value resulted in the minimal cross-validation error, thereby retaining the most relevant features for model construction. The parameters of the retained features with non-zero coefficients were then incorporated into the regression model fitting. This systematic approach ensured that the selected features were both reliable and predictive, enhancing the overall performance of our radiomics models.",
  "optimization/features": "In our study, we initially considered a comprehensive set of features for our models. Specifically, we examined 107 intratumoral features and 107 peritumoral features, totaling 214 features. To refine this set, we employed LASSO regression, a technique known for its effectiveness in feature selection and regularization. This process was conducted exclusively on the training dataset to ensure that the model's performance on the testing set remained unbiased.\n\nThrough LASSO regression, we identified and retained the most relevant features for our models. For the intratumoral PA imaging radiomics model, 35 optimal intratumoral features were selected. Additionally, we developed combined intratumoral-peritumoral models that incorporated different peritumoral regions of interest (ROIs). These models included 37 features combining intratumoral and 2 mm peritumoral, 33 features combining intratumoral and 5 mm peritumoral, and 32 features combining intratumoral and 8 mm peritumoral.\n\nBy focusing on the training set for feature selection, we aimed to create robust and generalizable models that could accurately predict outcomes in new, unseen data. This approach helps to mitigate overfitting and ensures that the selected features are truly informative and not merely artifacts of the training data.",
  "optimization/fitting": "In our study, the number of radiomic features initially extracted was indeed much larger than the number of training points. To address potential overfitting, we employed the Least Absolute Shrinkage and Selection Operator (LASSO) regression model. This method is particularly effective in high-dimensional data settings as it applies a penalty to the regression coefficients, driving many of them to zero. This process effectively reduces the number of features, retaining only those that contribute most significantly to the model.\n\nTo determine the optimal penalty parameter (\u03bb), we used a 10-fold cross-validation process. This technique helps in identifying the \u03bb value that minimizes cross-validation error, ensuring that the model generalizes well to unseen data. By selecting the \u03bb that results in the minimal cross-validation error, we mitigate the risk of overfitting.\n\nAdditionally, we assessed the reliability and reproducibility of the features using intraclass correlation coefficients (ICC). Only features with an ICC greater than 0.75 were retained, indicating excellent stability. This step further ensures that the selected features are robust and not merely artifacts of the training data.\n\nTo rule out underfitting, we evaluated the model's performance using various metrics such as accuracy, sensitivity, and specificity derived from the confusion matrix. The model demonstrated strong discriminatory ability with high Area Under the Curve (AUC) values in both the training and testing datasets. Furthermore, we conducted univariate and multivariate analyses to identify independent predictors of benign and malignant breast nodules, incorporating variables such as age, menopausal status, and radiomic characteristics. This comprehensive approach ensures that the model captures essential patterns in the data without being overly simplistic.\n\nIn summary, our use of LASSO regression with cross-validation, along with rigorous feature selection and validation processes, effectively addresses both overfitting and underfitting concerns, resulting in a robust and reliable predictive model.",
  "optimization/regularization": "In our study, we employed the least absolute shrinkage and selection operator (LASSO) regression model to prevent overfitting and to select the most relevant features for our predictive models. LASSO is a regularization technique that adds a penalty equal to the absolute value of the magnitude of coefficients to the loss function. This method effectively shrinks some coefficients to zero, thereby performing both variable selection and regularization. By doing so, LASSO helps in reducing the complexity of the model and mitigating the risk of overfitting, especially when dealing with a large number of features.\n\nTo determine the optimal value of the regularization parameter \u03bb, we utilized a 10-fold cross-validation process. This approach involved dividing the training dataset into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process was repeated 10 times, each time using a different subset as the validation set. The \u03bb value that resulted in the minimal cross-validation error was selected as the optimal parameter. This systematic approach ensured that our model was robust and generalizable to new, unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, the LASSO regression model was employed for feature selection and model construction. The optimal \u03bb value, which is a crucial hyper-parameter, was determined through a 10-fold cross-validation process. This process aimed to minimize cross-validation error, ensuring the most effective feature selection.\n\nThe radiomic features were extracted using the Pyradiomics platform, which is an open-source tool available at https://pyradiomics.readthedocs.io/en/latest/index.html. This platform facilitates the automated extraction of radiomic features from medical images, ensuring reproducibility and accessibility for other researchers.\n\nThe diagnostic performance of the models, including the area under the curve (AUC), sensitivity, specificity, and accuracy, is reported in Table 3. This table provides a comprehensive overview of the model's performance in both training and testing sets, allowing for a clear understanding of the model's efficacy.\n\nAdditionally, the construction of the nomogram model is illustrated in Figure 5, which includes calibration curves and decision curves for both training and testing sets. These visual aids help in understanding the model's calibration and clinical utility.\n\nThe statistical analysis was performed using R version 4.2.2, and the code, along with the datasets used, can be made available upon request. The publication adheres to open science principles, ensuring that the methods and results are transparent and reproducible.\n\nIn summary, the hyper-parameter configurations, optimization schedule, and model files are reported within the publication and are available through open-source tools and upon request. This ensures that the research is reproducible and can be built upon by other researchers in the field.",
  "model/interpretability": "The model developed in this study is not a black-box but rather a transparent and interpretable system. The construction of the nomogram model incorporates both clinical features and radiomic features, which are derived from photoacoustic imaging. This integration allows for a clear understanding of how different variables contribute to the model's predictions.\n\nThe nomogram visually represents the relationship between the input features and the output prediction, making it easier for clinicians to interpret the results. For instance, the nomogram includes clinical features such as age and tumor diameter, which are well-understood and widely used in medical practice. Additionally, the radiomic features, extracted from intratumoral and peritumoral regions, are selected using LASSO regression, a method that provides a sparse model by shrinking less important features to zero. This process ensures that only the most relevant features are retained, enhancing the model's interpretability.\n\nFurthermore, the calibration curves and decision curves provide additional insights into the model's performance and clinical utility. The calibration curves demonstrate how well the predicted probabilities match the actual outcomes, while the decision curves show the net benefit of using the model at different threshold probabilities. These visualizations help clinicians understand the model's reliability and the potential benefits of using it in clinical decision-making.\n\nIn summary, the model's transparency is achieved through the use of interpretable features, visual representations like the nomogram, and performance metrics that provide clear insights into the model's behavior. This transparency is crucial for gaining the trust of clinicians and ensuring that the model's predictions are understood and acted upon appropriately.",
  "model/output": "The model developed in this study is a classification model. It is designed to distinguish between benign and malignant breast nodules. The primary output of the model is a prediction of the likelihood of a breast nodule being malignant or benign. This is achieved through the integration of clinical features, intratumoral radiomic features, and peritumoral radiomic features.\n\nThe model's performance is evaluated using several metrics, including the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, sensitivity, specificity, and accuracy. These metrics provide a comprehensive assessment of the model's ability to correctly classify breast nodules.\n\nThe AUC values for different models vary, with the nomogram model generally showing superior performance compared to the clinical model and radiomic model alone. For instance, the nomogram model incorporating intratumoral and 5 mm peritumoral features achieved an AUC of 0.924 in the training set and 0.873 in the testing set, indicating robust discriminatory power.\n\nThe calibration curves and Decision Curve Analysis (DCA) further validate the model's predictive accuracy and clinical utility. The calibration curves demonstrate how well the predicted probabilities align with the actual outcomes, while the DCA assesses the net benefit of using the model in clinical decision-making.\n\nIn summary, the model is a classification tool aimed at improving the diagnostic accuracy of breast nodule assessments by leveraging a combination of clinical and radiomic features. The outputs provide valuable insights into the likelihood of malignancy, aiding clinicians in making informed decisions.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the radiomic feature extraction was facilitated using the Pyradiomics platform, which is publicly available. This platform can be accessed via its documentation site, providing users with the necessary tools and instructions to extract radiomic features from medical images. The Pyradiomics platform is open-source, allowing for community contributions and improvements.\n\nAdditionally, the ITK-SNAP software, version 3.8.0, was used for manual delineation of the region of interest (ROI) on photoacoustic (PA) images. This software is also publicly available and can be accessed through its official website. ITK-SNAP is an open-source software, providing a user-friendly interface for segmentation tasks in medical imaging.\n\nFor statistical analysis, R version 4.2.2 was employed. R is a widely used open-source programming language and environment for statistical computing and graphics. It is freely available for download and use, with extensive documentation and community support.\n\nRegarding the specific models and algorithms developed in the study, such as the LASSO regression model and the radiomics nomogram, the methods and steps for their construction and validation are detailed in the publication. However, the exact implementation code for these models is not explicitly mentioned as being publicly released. The study focuses on the methodological approach and the results obtained, rather than the provision of executable code or software packages.\n\nIn summary, while the primary tools and platforms used for image analysis and statistical computation are publicly available and open-source, the specific implementation of the models developed in this study is not detailed as being released to the public.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its robustness and clinical utility. Initially, a radiomics nomogram was developed and validated in a separate cohort. The performance of this nomogram was assessed using a Receiver Operating Characteristic (ROC) curve, which provided insights into its diagnostic efficacy. Additionally, a calibration curve was plotted, and the Hosmer-Lemeshow test was utilized to evaluate the calibration accuracy of the nomogram. This ensured that the predicted probabilities aligned closely with the observed outcomes.\n\nFurthermore, a Decision Curve Analysis (DCA) was performed to determine the clinical utility of the predictive model. This analysis helped in understanding the net benefit of using the model at different threshold probabilities, thereby assessing its practical value in clinical settings.\n\nStatistical analysis was conducted using R 4.2.2, with a two-sided p-value threshold of less than 0.05 established as the criterion for statistical significance. Univariate analysis was performed to compare clinical characteristics across different groups, employing the Mann\u2013Whitney U test for continuous variables and the \u03c72 test or Fisher\u2019s exact test for categorical variables. For comparisons involving more than two groups, Analysis of Variance (ANOVA) and the Kruskal\u2013Wallis H test were utilized.\n\nThe study included a total of 358 cases of BI-RADS 3\u20135 breast nodule patients, divided into training and testing sets. The training set consisted of 286 patients, while the testing set had 72 patients. The clinical model demonstrated robust discriminating ability with an Area Under the Curve (AUC) of 0.863 in the training dataset and an AUC of 0.794 in the testing dataset. This consistency in performance across different datasets underscored the reliability of the model.\n\nIntratumoral and peritumoral features were extracted and selected using LASSO regression, ensuring that only the most relevant features were included in the models. The diagnostic performance of the radiomics model was evaluated using metrics such as accuracy, sensitivity, and specificity, derived from the confusion matrix. Univariate logistic regression analysis was conducted to identify independent predictors of benign and malignant breast nodules, incorporating variables such as age, menopausal status, radiomics characteristics, and lesion diameter.\n\nThe construction of the radiomics nomogram integrated these radiomics characteristics and independent prognostic factors, providing a comprehensive tool for distinguishing between benign and malignant breast lesions. The evaluation process ensured that the method was not only statistically sound but also clinically relevant, offering a practical approach for improving diagnostic accuracy in breast nodule assessment.",
  "evaluation/measure": "In our study, we evaluated the performance of various models using several key metrics to ensure a comprehensive assessment. The primary metric reported is the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, which provides a measure of the model's ability to distinguish between benign and malignant breast nodules. We also report the 95% Confidence Interval (CI) for the AUC to indicate the reliability of this estimate.\n\nIn addition to AUC, we provide sensitivity, specificity, and accuracy for each model. Sensitivity measures the proportion of true positives correctly identified by the model, while specificity measures the proportion of true negatives correctly identified. Accuracy provides an overall measure of the model's correctness, calculated as the proportion of true results (both true positives and true negatives) among the total number of cases evaluated.\n\nThese metrics are reported for both the training and testing sets, allowing for an assessment of the model's performance on unseen data. The training set metrics indicate how well the model has learned from the data, while the testing set metrics provide an indication of the model's generalizability and robustness.\n\nThe set of metrics used in this study is representative of those commonly reported in the literature for similar diagnostic models. AUC is a widely accepted metric for evaluating the performance of classification models, particularly in medical imaging and radiomics. Sensitivity, specificity, and accuracy are also standard metrics that provide a clear and interpretable assessment of model performance. By including these metrics, we aim to provide a thorough and transparent evaluation of our models' diagnostic capabilities.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on evaluating the performance of our own models, which included a clinic model, radiomic models, and nomogram models. These models were assessed using various metrics such as AUC, sensitivity, specificity, and accuracy.\n\nWe did, however, compare different configurations of our models to simpler baselines. Specifically, we evaluated the performance of models that used only intratumoral features against those that combined intratumoral and peritumoral features. The results showed that incorporating peritumoral features improved the predictive performance. Among the peritumoral regions considered (2 mm, 5 mm, and 8 mm), the 5 mm region demonstrated the best prediction accuracy.\n\nAdditionally, we constructed and validated a radiomics nomogram that integrated clinical features with radiomic features. The diagnostic utility of this nomogram was evaluated using a Receiver Operating Characteristic (ROC) curve, calibration curves, and Decision Curve Analysis (DCA). These evaluations provided insights into the model's calibration accuracy and clinical utility.\n\nIn summary, while we did not compare our methods to external benchmarks, we conducted internal comparisons to assess the incremental value of different feature sets and model configurations. This approach allowed us to identify the most effective combination of features for predicting breast nodule malignancy.",
  "evaluation/confidence": "The evaluation of our models includes several performance metrics, each accompanied by confidence intervals to provide a range within which the true value is likely to fall. For instance, the Area Under the Curve (AUC) for different models is reported with 95% Confidence Intervals (CIs). This practice ensures that the reported performance metrics are not just point estimates but are accompanied by a measure of uncertainty.\n\nStatistical significance is a crucial aspect of our evaluation. We employed various statistical tests to determine the significance of our results. For continuous variables, the Mann-Whitney U test was used, while categorical variables were analyzed using the \u03c72 test or Fisher's exact test, depending on the data set. Additionally, for comparisons involving more than two groups, Analysis of Variance (ANOVA) and the Kruskal-Wallis H test were utilized. A two-sided p-value threshold of less than 0.05 was established as the criterion for statistical significance.\n\nIn our study, we found that incorporating peritumoral features into the radiomic analysis significantly improved the predictive performance compared to using intratumoral features alone. This improvement was statistically significant, as evidenced by the higher AUC values and the confidence intervals that did not overlap with those of the intratumoral-only models. Specifically, the 5 mm peritumoral region showed the best predictive performance, with an AUC of 0.873 (95% CI: 0.801 \u2013 0.945) in the testing set, which was significantly higher than the AUC of the intratumoral-only model.\n\nFurthermore, the calibration efficacy of our nomogram was assessed using the Hosmer-Lemeshow test, which indicated good calibration accuracy. Decision Curve Analysis (DCA) was also performed to determine the clinical utility of the predictive model, providing additional evidence of its superiority over other models and baselines.\n\nIn summary, the performance metrics in our study are robust, with confidence intervals providing a measure of uncertainty. The results are statistically significant, demonstrating that our method is superior to others and baselines in predicting the outcomes of interest.",
  "evaluation/availability": "Not enough information is available."
}