{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Journal of Antimicrobial Chemotherapy",
  "publication/year": "2021",
  "publication/pmid": "33792714",
  "publication/pmcid": "PMC8212763",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- HIV\n- Viral Load\n- Treatment Response\n- Machine Learning Models\n- Random Forest\n- Cross-Validation\n- Predictive Accuracy\n- Genotype Interpretation\n- Antiretroviral Therapy\n- Clinical Utility\n- Low- and Middle-Income Countries\n- Virological Response\n- Sensitivity and Specificity\n- Receiver Operating Characteristic\n- Absolute Modeling",
  "dataset/provenance": "The dataset used in this study was sourced from the RDI database, which contains treatment change episodes (TCEs) where antiretroviral therapy (ART) was changed following virological failure. The dataset includes a comprehensive set of variables for each TCE, such as on-treatment baseline plasma viral load, CD4 cell count, viral genotype, time on therapy, and details of the drugs used before and after the treatment change. The data were censored using established rules to exclude certain rare or potentially miscoded TCEs.\n\nThe total number of TCEs used in the training set varied depending on the specific models being developed, with some models using as many as 19,080 TCEs and others using fewer, depending on the baseline variables required. For instance, models that did not require genotype information used 62,940 TCEs, while those that included genotype information used fewer TCEs. The test set consisted of 5% of the patients extracted at random from the dataset.\n\nThe dataset used in this study builds upon data used in previous publications and community efforts, incorporating the latest updates and a larger pool of TCEs. The models were developed using a methodology described in detail elsewhere, ensuring consistency and reliability in the results. The dataset's richness and real-life data underpin the utility of the models in supporting treatment decision-making.",
  "dataset/splits": "The dataset was split into two main parts: a training set and a test set. The training set consisted of a significantly larger number of treatment change episodes (TCEs) compared to the test set. Specifically, the training set included 62,940 TCEs, while the test set contained 3,260 TCEs. This split was done randomly, with 5% of the patients extracted at random to provide an independent test set. The training set was used to develop the models, while the test set was used to evaluate their performance independently. The distribution of data points in each split reflects the need for a robust training process to ensure the models' reliability and accuracy when applied to new, unseen data.",
  "dataset/redundancy": "The datasets used in our study were split into training and test sets to ensure independent evaluation of the models. For each round of model development, treatment change episodes (TCEs) were extracted from the RDI dataset, including all the variables required for the specific set of models. The pools of qualifying data varied with each occasion, being larger for models that required fewer baseline variables.\n\nTo enforce independence between the training and test sets, the remaining TCEs, after applying data censoring rules, were partitioned at random. Specifically, 5% of patients were extracted at random to provide an independent test set. This approach ensures that the test set is not used in any way during the training process, providing an unbiased evaluation of the model's performance.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in the field. The training set and test set have similar distributions of key parameters, such as baseline viral load, days since first treatment, number of previous regimens, and treatment history. This similarity ensures that the models are evaluated on data that is representative of the data they were trained on, enhancing the generalizability of the results.\n\nThe data censoring rules, developed over the past 18 years and previously published, were applied to exclude TCEs that were likely to have been non-adherent or whose data were likely to have been miscoded. This process ensures that the datasets are clean and reliable, further enhancing the robustness of the models.",
  "dataset/availability": "The data used in this study were collected from various international cohorts and clinics, contributing to the RDI database. The specific datasets used for training and testing the models are not publicly released in a forum. The data collection involved treatment change episodes (TCEs) where antiretroviral therapy (ART) was changed following virological failure. The data included variables such as baseline plasma viral load, CD4 cell count, viral genotype, time on therapy, and details of the drugs used. The data were censored using established rules to exclude non-adherent patients, TCEs involving single drugs, and those with inadequate or unrealistic data. The models were developed using a 5% cross-validation scheme, and an independent test set was created by randomly extracting 5% of the patients. The performance of the models was evaluated using this independent test set. The models are now available for use through the online HIV-TRePS system at http://www.hivrdi.org/treps. This system allows clinicians to access the models for supporting optimized treatment decision-making. The data itself remains proprietary and is not publicly available due to privacy and ethical considerations.",
  "optimization/algorithm": "The optimization algorithm employed in this study utilizes Random Forest (RF) models. This is a well-established ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees.\n\nThe RF models used here are not new; they are a widely recognized and extensively used machine-learning algorithm in various fields, including bioinformatics and medical research. The choice of RF models is justified by their robustness, ability to handle large datasets, and effectiveness in capturing complex interactions between variables.\n\nThe decision to use RF models in this context, rather than publishing them in a machine-learning journal, is driven by the specific application and the goals of the study. The focus here is on predicting the response to combination antiretroviral therapy (ART) and identifying effective alternative regimens. The RF models were selected for their proven performance in similar predictive tasks and their ability to provide reliable estimates of the probability of response or changes in viral load. This application-oriented approach is more aligned with the objectives of the study, which are to improve clinical outcomes and treatment strategies for HIV patients, rather than advancing the field of machine learning per se.",
  "optimization/meta": "The models discussed in this publication are not meta-predictors. They are committees of five random forest (RF) models. Each committee was developed using a 5% cross-validation scheme. For each partition, the model's output for the validation cases was compared with the actual response observed in the clinic, and the best-performing model was selected for the final committee. This process ensures that the training data for each model is independent, as the cross-validation scheme divides the data into separate training and validation sets.\n\nThe output of each classifier model was the estimated probability of the follow-up plasma viral load being less than 50 copies HIV RNA/mL. The output for each absolute model was the estimated change in follow-up viral load from baseline. The performance of the models was evaluated using independent test cases, with the average of the classifier models' estimates of the probability of response and the responses observed in the clinics used to plot receiver operating characteristic (ROC) curves and assess the area under the curve (AUC). The absolute models' estimates of the change in viral load from baseline and the responses observed in the clinics were correlated using Pearson's product moment method.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the quality and relevance of the input data. Treatment change episodes (TCEs) were collected from a database, focusing on instances where antiretroviral therapy (ART) was changed following virological failure. The gold-standard dataset for a TCE included various baseline variables such as on-treatment plasma viral load, CD4 cell count, viral genotype, time on therapy, and details of the drugs used before and after the treatment change.\n\nData censoring was applied using established rules to exclude non-adherent patients, TCEs with baseline genotypes predicted to respond but failed in the clinic, TCEs involving single drugs, and those with inadequate data for specific drugs. Viral load values were adjusted for indeterminate or unrealistic values, and any TCEs with extreme viral load values or CD4 counts were removed.\n\nThe models were developed using a set of 115 input variables, including baseline CD4 count, time on therapy, and specific mutations detected in the baseline genotype. These mutations covered a range of reverse transcriptase and protease mutations known to be relevant to HIV treatment response.\n\nFor each round of model development, TCEs were extracted from the dataset that included all required variables. The data was then partitioned randomly, with 5% of patients set aside for independent testing. This partitioning ensured that the models were trained and validated on different subsets of the data, enhancing the robustness of the results.\n\nThe preprocessing steps also included handling missing data and ensuring that the data was in a suitable format for the machine-learning algorithms. This involved imputing missing values where necessary and standardizing the data to ensure consistency across different variables. The final dataset was used to train and validate the models, with performance evaluated using cross-validation and independent testing.",
  "optimization/parameters": "The models utilized in this study employed various baseline variables to predict the response to treatment. The number of parameters (p) used in the model varied depending on the specific model configuration. Some models included all available baseline variables, such as genotype, CD4 count, and time on therapy, while others were developed without certain variables.\n\nThe selection of parameters was guided by the availability of data and the goal of improving predictive accuracy. For instance, models that included genotype, CD4 count, and time on therapy demonstrated higher performance metrics, such as AUC values up to 0.90 and overall accuracy ranging from 72% to 82%. This suggests that these variables are crucial for enhancing the model's predictive power.\n\nIn contrast, models developed without genotype, CD4 count, or time on therapy showed slightly lower performance, with AUC values around 0.78 and similar ranges for accuracy, sensitivity, and specificity. This indicates that while these variables are beneficial, the models can still provide valuable predictions even when some data is missing.\n\nThe choice of parameters was also influenced by the need to assess the models' utility in low- and middle-income countries (LMICs), where certain data might be scarce. The models were tested with combinations of widely available and relatively inexpensive drugs, ensuring their practical applicability in diverse clinical settings.",
  "optimization/features": "The latest set of models utilized 115 input variables for modeling. These features encompass a range of clinical and genetic data points, including baseline CD4 count, time on therapy, and various mutations detected in the baseline genotype, specifically within the HIV reverse transcriptase and protease regions. Feature selection was not explicitly mentioned as a separate process, suggesting that all 115 variables were considered relevant and included in the modeling process. The development of these models involved partitioning the data into training and test sets, with the training set used to develop and validate the models. This approach ensures that the feature selection, if any, was performed using the training set only, maintaining the integrity of the independent test set for unbiased evaluation.",
  "optimization/fitting": "The fitting method employed for the models involved a committee of five random forest (RF) models, which were developed using a 5% cross-validation scheme. This approach helps to mitigate overfitting by ensuring that each model is trained and validated on different subsets of the data, reducing the risk of the model becoming too tailored to the training data.\n\nThe number of parameters in the random forest models is indeed large, as each tree in the forest can have a significant number of nodes and splits. However, the use of cross-validation and the ensemble nature of random forests help to manage this complexity. Cross-validation ensures that the model's performance is evaluated on multiple subsets of the data, providing a more robust estimate of its generalization ability. The ensemble approach of random forests, which averages the predictions of multiple trees, further reduces the risk of overfitting by smoothing out the individual trees' predictions.\n\nTo rule out underfitting, the models were evaluated on their ability to capture the underlying patterns in the data. The performance metrics, such as the area under the receiver operating characteristic curve (AUC), overall accuracy, sensitivity, and specificity, indicate that the models achieved high levels of performance. The AUC values ranged from 0.78 to 0.90, demonstrating the models' strong discriminative ability. Additionally, the sensitivity and specificity values showed that the models were effective in correctly identifying both responders and non-responders.\n\nThe models were also tested on independent datasets to ensure that they generalized well to new, unseen data. The consistent performance across cross-validation and independent testing further supports the conclusion that the models are well-fitted and not underfitting the data. The use of a large and diverse dataset, along with the rigorous validation and testing procedures, provides confidence that the models are robust and generalizable.",
  "optimization/regularization": "A 5% cross-validation scheme was employed to develop the committees of five random forest models. This technique helps to prevent overfitting by ensuring that the model is trained and validated on different subsets of the data, reducing the risk of the model becoming too tailored to the training data. For each partition, the model's output for the validation cases was compared with the actual response observed in the clinic, and the best-performing model was selected for the final committee. This process ensures that the models generalize well to unseen data.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The models discussed in this publication are primarily black-box models, meaning their internal workings are not easily interpretable. These models, including both classifier and absolute models, are developed using complex algorithms that do not provide straightforward explanations for their predictions. The classifier models estimate the probability of a follow-up plasma viral load being less than 50 copies HIV RNA/mL, while the absolute models predict the change in viral load from baseline. These predictions are based on various input variables, but the specific reasoning behind each prediction is not explicitly detailed.\n\nThe models were validated using cross-validation and independent testing, which demonstrated their high accuracy and reliability. For example, the classifier models achieved AUC values ranging from 0.78 to 0.90, with overall accuracy, sensitivity, and specificity varying accordingly. Similarly, the absolute models showed significant correlations between predicted and observed changes in viral load, with r values ranging from 0.68 to 0.75.\n\nWhile the models' performance metrics indicate their effectiveness, the lack of interpretability means that the specific factors contributing to each prediction are not transparent. This is a common characteristic of many advanced machine learning models, which prioritize predictive accuracy over interpretability. As a result, healthcare providers using these models would rely on the output probabilities or predicted changes in viral load without a clear understanding of the underlying decision-making process.",
  "model/output": "The models developed in this study include both classifier and absolute models. The classifier models estimate the probability of the follow-up plasma viral load being less than 50 copies HIV RNA/mL. These models are designed to predict whether a patient will respond to a treatment regimen or not, making them classification models. The output of these models is a probability value that indicates the likelihood of a successful response.\n\nOn the other hand, the absolute models estimate the change in follow-up viral load from baseline. These models are regression models, as they predict a continuous outcome\u2014the change in viral load. The output of these models is the estimated change in viral load, which can be used to assess the effectiveness of a treatment regimen in reducing viral load.\n\nThe classifier models were evaluated using metrics such as the area under the receiver operating characteristic curve (AUC), overall accuracy, sensitivity, and specificity. The absolute models were evaluated using Pearson's product moment correlation to assess the relationship between predicted and observed changes in viral load, as well as the mean absolute difference between predicted and observed changes.\n\nIn summary, the study includes both classification and regression models, each with its specific output and evaluation metrics. The classifier models predict the probability of treatment response, while the absolute models predict the change in viral load from baseline.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The models described in this publication are available for use through the online HIV-TRePS system. This system can be accessed at http://www.hivrdi.org/treps. The HIV-TRePS system allows clinicians to support optimized treatment decision-making in the absence of resistance tests. It is designed to be particularly useful in low- and middle-income countries (LMICs) where genotyping and frequent laboratory monitoring may be scarce or unavailable.\n\nThe HIV-TRePS system provides a practical tool for physicians to expand their treatment options with a level of confidence based on real-life experiences. It helps in reducing virological failure and improving patient outcomes globally, but especially in resource-limited settings. The use of this tool by healthcare professionals can also combat the development of drug resistance, contributing to better treatment outcomes and reduced viral transmission.\n\nThe system is freely available, making it a cost-effective solution for settings with limited resources. By utilizing this tool, healthcare providers can make more informed decisions about treatment changes, even when baseline data is missing. This enhances the utility of the models in various clinical settings, ensuring that patients receive the most effective and individualized treatment possible.",
  "evaluation/method": "The evaluation method employed a robust approach to ensure the reliability and generalizability of the models. Each committee of five random forest (RF) models was developed using a 5% cross-validation scheme. For each partition, the model's output for the validation cases was compared with the actual clinical responses to select the best-performing model for the final committee.\n\nThe performance of the models as predictors of response was then evaluated using independent test cases. The average of the classifier models' estimates of the probability of response and the observed responses in the clinics were used to plot receiver operating characteristic (ROC) curves and assess the area under the curve (AUC). Additionally, the overall accuracy, sensitivity, and specificity of the models were obtained using the average optimum operating point (OOP).\n\nFor the absolute models, the estimates of the change in viral load from baseline and the observed responses in the clinics were correlated using Pearson\u2019s product-moment method. A scatterplot was produced, and the correlation of determination (r\u00b2) and mean absolute difference between predicted and observed changes in viral load were compared. This comprehensive evaluation ensured that the models were thoroughly tested and validated.",
  "evaluation/measure": "In the evaluation of our models, several key performance metrics were reported to provide a comprehensive assessment of their predictive capabilities. For the classifier models, the primary metrics included the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve, overall accuracy, sensitivity, and specificity. The AUC values ranged from 0.78 to 0.90, indicating strong discriminative power. Overall accuracy ranged from 72% to 82%, sensitivity from 71% to 80%, and specificity from 70% to 85%. These metrics were evaluated using both cross-validation and independent testing, ensuring robustness and generalizability of the results.\n\nFor the absolute models, which predict the change in viral load from baseline, the performance was assessed using Pearson's correlation coefficient (r) and the coefficient of determination (r\u00b2). The r values ranged from 0.66 to 0.75, and the r\u00b2 values from 0.44 to 0.56, demonstrating significant correlations between predicted and observed changes in viral load. Additionally, the mean absolute error was reported, ranging from 0.65 to 0.75 log10 HIV RNA/mL, providing insight into the models' predictive accuracy.\n\nThe reported metrics are representative of standard practices in the literature for evaluating predictive models in similar contexts. The use of AUC, accuracy, sensitivity, and specificity for classifier models, along with correlation coefficients and mean absolute error for absolute models, aligns with established methods for assessing model performance. This set of metrics offers a thorough evaluation of both the discriminative ability and the predictive accuracy of the models, ensuring that their performance can be compared and contrasted with other studies in the field.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our models against established methods to ensure their robustness and superiority. We compared our classifier models with rules-based interpretation of genotype data, which is a commonly used method in clinical settings. Genotypic sensitivity scores (GSSs) were obtained using three widely used interpretation systems: ANRS (v30), REGA (v10.0), and Stanford HIVdb (v8.9-1). These scores were then used as predictors of response, and their performance was compared directly with that of our models.\n\nThe comparison revealed that our models, including those that do not require genotype information, significantly outperformed the genotyping methods. For instance, our classifier models achieved an AUC of 0.84 in independent testing, whereas the genotype systems achieved AUC values ranging from 0.53 to 0.54. This stark contrast highlights the superior predictive accuracy of our models.\n\nAdditionally, we conducted in silico analyses to assess the potential clinical utility of our models. We evaluated their ability to identify alternative, practical regimens that were predicted to be effective. This involved modeling alternative regimens comprising drugs that are commonly available in low- and middle-income countries (LMICs), such as zidovudine, abacavir, lamivudine, and others. The results showed that our models could identify effective alternative regimens in a high percentage of cases, even when using a restricted list of drugs.\n\nOverall, the comparison to publicly available methods and simpler baselines demonstrated that our models provide a more accurate and reliable prediction of virological response to combination antiretroviral therapy (ART). This reinforces the potential of our models to improve clinical outcomes and guide treatment decisions, particularly in resource-limited settings.",
  "evaluation/confidence": "The evaluation of the models presented in this study includes several key performance metrics, such as the area under the curve (AUC), overall accuracy, sensitivity, and specificity. These metrics were assessed using both cross-validation and independent testing.\n\nThe AUC values, which indicate the ability of the models to distinguish between responders and non-responders, ranged from 0.78 to 0.90 during independent testing. This range suggests a strong discriminative power, particularly for models that included baseline genotype and CD4 count information.\n\nOverall accuracy, which measures the proportion of correctly predicted cases, ranged from 72% to 82%. Sensitivity, the ability to correctly identify responders, ranged from 71% to 80%, while specificity, the ability to correctly identify non-responders, ranged from 70% to 85%. These metrics provide a comprehensive view of the models' performance, showing that they are reliable in predicting virological response.\n\nThe statistical significance of the results is evident in the correlation coefficients (r values) for the absolute models, which ranged from 0.66 to 0.74 during independent testing. These correlations are highly statistically significant, with p-values of 0.0001, indicating that the models' predictions are robust and not due to chance.\n\nThe mean absolute error (MAE) for the absolute models, which measures the difference between predicted and actual changes in viral load, ranged from 0.65 to 0.75 log10 copies HIV RNA/mL. This error is comparable to the typical test-retest error of commercially available assays, further validating the models' accuracy.\n\nIn summary, the performance metrics are robust and statistically significant, providing strong evidence that the models are superior to baselines and other methods. The inclusion of confidence intervals would further enhance the evaluation, but the current results are compelling and indicate the models' potential utility in clinical decision-making.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The evaluation was conducted using data from the RDI database, which includes treatment change episodes (TCEs) where antiretroviral therapy (ART) was changed following virological failure. The data used for model development and evaluation were partitioned at random, with 5% of patients extracted to provide an independent test set. The models were validated using a 5% cross-validation scheme, and their performance was assessed using independent test cases. However, the specific datasets used for evaluation are not released publicly."
}