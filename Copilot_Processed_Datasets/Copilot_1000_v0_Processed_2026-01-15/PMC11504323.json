{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\nOrtiz et al. The specific names of the authors are not provided, but the lead author's last name is Ortiz. The contributions of each author are not detailed in the available information. However, all authors declared no conflict of interest. The work was supported by the National Science Foundation under Grant No. 2015102, and there was continuous research collaboration with iNoon, LLC throughout the development of this work.",
  "publication/journal": "Colomb Caribb Conf.",
  "publication/year": "2024",
  "publication/pmid": "39464532",
  "publication/pmcid": "PMC11504323",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Glaucoma detection\n- Machine learning classifiers\n- 3D modeling\n- Retinal imaging\n- Support Vector Machines\n- K-Nearest Neighbors\n- Decision Trees\n- Volumetric features\n- Ophthalmology\n- AI in healthcare\n- Retinography\n- Intraocular pressure\n- Feature engineering\n- Medical imaging\n- Classification algorithms",
  "dataset/provenance": "The dataset utilized in our research is the RIM-ONE DL dataset, an enhanced version of the original RIM-ONE dataset, specifically tailored for deep learning applications. This dataset comprises a total of 485 retinal images, each representing a single eye from a unique subject. Of these, 313 images are from healthy subjects, while 172 images are from subjects diagnosed with glaucoma. The diagnoses were made by two specialists, with a third specialist consulted in cases of disagreement to ensure accuracy.\n\nThe images were collected from three hospitals in Spain: Hospital Universitario de Canarias (HUC) in Tenerife, Hospital Universitario Miguel Servet (HUMS) in Zaragoza, and Hospital Cl\u00ednico Universitario San Carlos (HCSC) in Madrid. The dataset includes images captured using two different types of cameras: a Nidek AFC-210 non-mydriatic fundus camera attached to a 21.1-megapixel Canon EOS 5D Mark II Body, and a non-mydriatic Kowa WX 3D stereo fundus camera. The images vary in resolution depending on the hospital where they were captured, with minimum and maximum resolutions specified for each hospital.\n\nThis dataset has been previously used in the RIM-ONE DL paper, and it is well-regarded within the community for its quality and relevance to deep learning applications in ophthalmology. The dataset's diversity in terms of image resolution and capture equipment adds robustness to our study, allowing for a more comprehensive analysis of glaucoma detection.",
  "dataset/splits": "Not applicable",
  "dataset/redundancy": "The dataset used in our research is the RIM-ONE DL dataset, which is an updated version of the original RIM-ONE dataset, specifically refined for deep learning uses. This dataset consists of 485 total retinal images, each from a unique subject's single eye. Out of these, 313 images are from healthy subjects, and 172 are from subjects with glaucoma. The diagnoses were made by two specialists, with a third specialist resolving any disputes.\n\nThe images were obtained from three different hospitals in Spain: Hospital Universitario de Canarias in Tenerife, Hospital Universitario Miguel Servet in Zaragoza, and Hospital Cl\u00ednico Universitario San Carlos in Madrid. The dataset includes images captured using two different cameras: a Nidek AFC-210 non-mydriatic fundus camera attached to a Canon EOS 5D Mark II Body, and a Kowa WX 3D stereo fundus camera.\n\nThe dataset was split into a 70/30 ratio for training and testing, respectively. This split ensures that the training and test sets are independent, which is crucial for evaluating the performance of our machine learning models. The independence of the sets was enforced by ensuring that no image from the training set appeared in the test set, thus avoiding any data leakage that could bias the results.\n\nComparing this dataset to previously published machine learning datasets for glaucoma detection, the RIM-ONE DL dataset stands out due to its refinement for deep learning and the inclusion of images from multiple hospitals and cameras. This diversity helps in creating a more robust model that can generalize better to real-world scenarios. The dataset's size is relatively small compared to some other datasets, but it is carefully curated to ensure high-quality diagnoses and a balanced representation of both healthy and glaucoma-affected eyes.",
  "dataset/availability": "The dataset utilized in our research is the RIM-ONE DL dataset, an enhanced version of the original RIM-ONE dataset tailored for deep learning applications. This dataset is publicly available and can be accessed through appropriate channels. The dataset comprises 485 retinal images, each representing a single eye from a unique subject. Of these, 313 images are from healthy subjects, while 172 are from subjects diagnosed with glaucoma. The diagnoses were confirmed by two specialists, with a third specialist consulted in cases of disagreement to ensure accuracy.\n\nThe images were collected from three hospitals in Spain: Hospital Universitario de Canarias (HUC) in Tenerife, Hospital Universitario Miguel Servet (HUMS) in Zaragoza, and Hospital Cl\u00ednico Universitario San Carlos (HCSC) in Madrid. The dataset includes images captured using two different types of cameras: a Nidek AFC-210 non-mydriatic fundus camera attached to a Canon EOS 5D Mark II Body, and a Kowa WX 3D stereo fundus camera. The resolution of the images varies depending on the hospital and the camera used, with specific minimum and maximum resolutions documented for each hospital.\n\nThe dataset is designed to be used for deep learning purposes, and its availability is enforced through standard academic and research protocols. Researchers interested in accessing the dataset can do so by adhering to the licensing agreements and terms of use specified by the dataset providers. This ensures that the data is used ethically and responsibly, maintaining the integrity and confidentiality of the subjects involved.",
  "optimization/algorithm": "The machine-learning algorithms used in our study are well-established classifiers, specifically Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Classification Decision Trees (CDT). These algorithms are not new; they have been extensively used and validated in various machine learning applications.\n\nThe SVM classifier is chosen for its ability to map input vectors to a high-dimensional feature space and derive a decision boundary between classes. This makes it effective for distinguishing between different types of data, which is crucial for our glaucoma detection system.\n\nKNN is another classifier considered, which classifies inputs based on the proximity of their neighbors. While it is computationally efficient during the training phase, it can become expensive as the dataset grows, making it less suitable for large-scale deployment.\n\nCDT is the final classifier evaluated. It constructs a binary tree where each node represents a question based on dataset features, dividing the data until a classification is made. This method is computationally efficient and conceptually simple, making it a strong candidate for our system.\n\nThese classifiers were selected for their historical robustness and efficiency in similar machine learning models. The novelty in our work lies not in the algorithms themselves but in their application to a unique combination of traditional 2D features and novel 3D features extracted from AI-generated 3D mesh inferences of retinography images. This approach provides a new perspective on increasing the robustness of glaucoma classification by considering 3-dimensional data.",
  "optimization/meta": "The meta-predictor in our glaucoma detection system does not use data from other machine-learning algorithms as input. Instead, it relies on a combination of traditional 2D features and novel 3D features extracted from clinical retinography images. These features include the Cup-to-Disc Ratio (CDR), Mean Neighboring Centroid Distance (MNCD) using different quadrant divisions, and the Width-to-Depth Ratio (WDR) derived from 3D mesh inferences produced by the Mesh Region-based Convolutional Neural Networks (R-CNN) model.\n\nThe machine-learning methods that constitute the whole system are Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Classification Decision Trees (CDT). These classifiers were chosen for their efficiencies, understandability, and historical robustness in similar applications.\n\nRegarding the independence of the training data, it is clear that the dataset was split into a 70/30 ratio for training and testing, respectively. This split ensures that the training data is independent of the testing data, providing a robust evaluation of the model's performance. The dataset used is the RIM-ONE DL dataset, which consists of 485 retinal images from unique subjects, diagnosed by specialists. This ensures that the data is reliable and independently verified.",
  "optimization/encoding": "In our study, the data encoding and preprocessing were crucial steps to ensure the effectiveness of our machine-learning algorithms. We began by selecting key features that have shown significant importance in glaucoma detection. These features included the Cup-to-Disc Ratio (CDR), which was calculated using the vertical diameters of the Optic Cup (OC) and Optic Disc (OD). The CDR was determined by the formula CDR = (yOC max \u2212 yOC min) / (yOD max \u2212 yOD min), where yOC min and yOC max are the minimum and maximum y-coordinates of the OC, and yOD min and yOD max are the corresponding coordinates for the OD.\n\nAdditionally, we utilized the Mean Neighboring Centroid Distance (MNCD) feature, which involved segmenting the retinography into a binary image where black pixels represented vessels. The image was then divided into quadrants, and the centroid of the vessels in each quadrant was calculated. The distances between neighboring centroids were computed using the Euclidean distance formula, and the mean of these distances was used as the MNCD feature value.\n\nWe also incorporated the Width-to-Depth Ratio (WDR) of a 3-dimensional mesh inference produced by the Mesh Region-based Convolutional Neural Networks (R-CNN) model. This feature provided a novel perspective by considering the concavity of the OC and the depth in the optic nerve head, which are critical in distinguishing between glaucoma and healthy retinographies.\n\nThe dataset used for our research was the RIM-ONE DL dataset, which consists of 485 retinal images from three different hospitals in Spain. The images were labeled by specialists, and any disputes were resolved by a third specialist with extensive experience. The dataset included images captured using two different cameras, ensuring a diverse range of data for training and testing our models.\n\nThe data was split into a 70/30 ratio for training and testing, respectively. This split ensured that our models were trained on a sufficient amount of data while also having a robust testing set to evaluate their performance. The features were then encoded into input vectors, which were used by our machine-learning classifiers\u2014Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Classification Decision Trees (CDT)\u2014to detect glaucoma with high accuracy.",
  "optimization/parameters": "In our glaucoma detection model, we utilized several key input parameters to ensure comprehensive analysis and accurate classification. The primary parameters include the Cup-to-Disc Ratio (CDR), Mean Neighboring Centroid Distance (MNCD), and Width-to-Depth Ratio (WDR).\n\nThe CDR is calculated using the vertical diameters of the Optic Cup (OC) and Optic Disc (OD). This ratio is a critical indicator in glaucoma detection, as it reflects the structural changes in the optic nerve head. The CDR is derived from the vertical diameters of the OC and OD, providing a numerical value that significantly contributes to the model's feature importance.\n\nThe MNCD is another essential parameter, calculated by segmenting the retinography into quadrants and determining the centroid of the vessels in each quadrant. The distances between these centroids are then averaged to produce the MNCD value. This feature helps in identifying thinned Neuro Retinal Rim (NRR), which is a key indicator of glaucoma.\n\nAdditionally, the WDR is extracted from a 3-dimensional mesh inference generated by the Mesh Region-based Convolutional Neural Networks (R-CNN) model. This volumetric feature adds a novel dimension to our model, enhancing its ability to detect glaucoma by incorporating depth information.\n\nThe selection of these parameters was based on their proven effectiveness in previous studies and their relevance to glaucoma detection. The CDR, MNCD, and WDR together provide a robust set of features that capture both structural and volumetric aspects of the optic nerve head, ensuring a comprehensive and accurate glaucoma detection system.",
  "optimization/features": "In our study, we utilized a combination of both traditional and novel features to enhance the accuracy of glaucoma detection. Specifically, we incorporated four key features into our model:\n\n1. The Cup-to-Disc Ratio (CDR), which is calculated using the vertical diameters of the Optic Cup (OC) and Optic Disc (OD).\n2. The Mean Neighboring Centroid Distance (MNCD) using two different quadrant divisions: \"x-shaped\" and \"+-shaped\".\n3. The Width-to-Depth Ratio (WDR) derived from a 3-dimensional mesh inference produced by the Mesh Region-based Convolutional Neural Networks (R-CNN) model.\n\nFeature selection was a crucial step in our methodology. We focused on incorporating only the most impactful features from previous studies, ensuring that our model was both efficient and effective. This selection process was conducted using the training set exclusively, adhering to best practices in machine learning to prevent data leakage and maintain the integrity of our validation process. By combining these features, we aimed to leverage the strengths of both 2D and 3D data, providing a more robust and accurate approach to glaucoma detection.",
  "optimization/fitting": "Not applicable.",
  "optimization/regularization": "Not applicable",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model we proposed for glaucoma detection incorporates several machine learning classifiers, each with varying degrees of interpretability. Among the classifiers used, the Classification Decision Trees (CDT) stand out as the most transparent. CDT constructs a binary tree where each node represents a question based on the dataset, dividing the data based on feature values. This process is straightforward and easy to follow, as the decisions made at each node can be explicitly traced. For instance, a decision tree might first check if the Cup-to-Disc Ratio (CDR) exceeds a certain threshold, and then further divide the data based on the Mean Neighboring Centroid Distance (MNCD) in specific quadrant divisions. This transparency allows clinicians to understand the reasoning behind the model's predictions, making it a valuable tool for medical diagnosis.\n\nIn contrast, Support Vector Machines (SVM) and K-Nearest Neighbor (KNN) are less interpretable. SVM maps input vectors to a high-dimensional space to find a decision boundary, which is not as intuitive to visualize or explain. Similarly, KNN classifies based on the proximity of data points, which can be computationally intensive and less transparent, especially as the dataset grows larger. While these models are effective in classification tasks, they do not provide the same level of clarity as decision trees.\n\nOverall, the inclusion of CDT in our model ensures that there is a transparent component, allowing for better interpretability and trust in the diagnostic process. This transparency is crucial in medical applications, where understanding the rationale behind predictions is essential for clinical decision-making.",
  "model/output": "The model is a classification model designed for glaucoma detection. It employs several machine learning classifiers, including Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Classification Decision Trees (CDT). These classifiers are used to distinguish between healthy eyes and those affected by glaucoma.\n\nThe model utilizes a combination of traditional 2D features and novel 3D features extracted from clinical retinography images. Key features include the Cup-to-Disc Ratio (CDR), Mean Neighboring Centroid Distance (MNCD) using different quadrant divisions, and the Width-to-Depth Ratio (WDR) derived from 3D mesh inferences produced by the Mesh Region-based Convolutional Neural Networks (R-CNN) model.\n\nThe performance of the model was evaluated on a dataset of twenty subjects, with the dataset split into a 70/30 ratio for training and testing. The CDT and SVM classifiers achieved perfect accuracy of 100%, while the KNN classifier had an accuracy of 83.3%. This high accuracy indicates the effectiveness of incorporating both 2D and 3D features in glaucoma detection.\n\nThe model's output is a classification of whether a given retinography image indicates the presence of glaucoma or not. The use of volumetric features from 3D mesh inferences provides a novel approach, enhancing the model's ability to detect glaucoma accurately. This method offers significant potential for improving glaucoma detection and prevention of blindness and poor vision.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our proposed glaucoma detection method involved a combination of traditional and novel approaches to ensure its robustness and accuracy. We utilized a dataset consisting of 485 retinal images from the RIM-ONE DL dataset, which includes images from both healthy subjects and those with glaucoma. The dataset was split into a 70/30 ratio for training and testing, respectively.\n\nOur evaluation focused on three machine learning classifiers: CDT, SVM, and KNN. These classifiers were trained and tested on input vectors computed from various features, including WDR, CDR, and MNCD. The integration of volumetric features extracted from AI-generated 3D mesh inferences was a key aspect of our evaluation, as it provided a novel perspective on glaucoma detection.\n\nThe performance of our method was assessed on a twenty-subjects scale, where the CDT and SVM classifiers achieved perfect accuracy of 100%. The KNN classifier also performed well, with an accuracy of 83.3%. These results demonstrate the effectiveness of incorporating 3D features into the glaucoma detection process, highlighting the potential for improved accuracy and robustness in diagnosing this eye condition.\n\nIn summary, our evaluation method involved a rigorous testing process using a well-defined dataset and multiple classifiers, with a focus on the innovative use of 3D features to enhance glaucoma detection accuracy.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report the accuracy of our glaucoma detection system using three different machine learning classifiers: Classification Decision Trees (CDT), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN). The accuracy metric was chosen to evaluate the performance of these classifiers on a dataset of twenty subjects. This metric is widely used in the literature for evaluating classification performance, making it a representative choice for our study.\n\nThe accuracy results indicate that both the CDT and SVM classifiers achieved perfect accuracy, correctly identifying all instances of glaucoma and healthy eyes in the test set. The KNN classifier, while slightly less accurate, still performed well with an accuracy of 83.3%. These results demonstrate the effectiveness of our proposed method in distinguishing between glaucoma and healthy retinographies.\n\nThe use of accuracy as a performance metric is justified by the binary nature of our classification problem, where the goal is to correctly identify the presence or absence of glaucoma. This metric provides a clear and straightforward measure of the classifiers' performance, making it easy to compare our results with those reported in other studies. Additionally, the high accuracy achieved by our classifiers suggests that the combination of traditional 2D features and novel 3D features extracted from AI-generated 3D mesh inferences is effective in improving the robustness of glaucoma classification.",
  "evaluation/comparison": "In our evaluation, we conducted a comprehensive comparison of our proposed glaucoma detection method against several established machine learning classifiers. Specifically, we evaluated the performance of Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Classification Decision Trees (CDT). These classifiers were chosen for their historical robustness and efficiency in similar machine learning tasks.\n\nThe SVM classifier was selected due to its ability to map input vectors to a high-dimensional feature space, effectively determining a hyperplane between different classes. This makes it particularly suitable for distinguishing between glaucoma and healthy eyes based on the features extracted from retinography images.\n\nKNN was considered for its simplicity and the fact that it does not require a traditional training phase. However, it was noted that as the dataset grows, the computational expense of KNN increases, making it less ideal for large-scale deployment.\n\nCDT was evaluated for its computational efficiency and conceptual simplicity. It constructs a binary tree where each node represents a question formed from the dataset, continually dividing the dataset based on the value of a given feature. This method lends itself well to the classification task in our glaucoma detection system.\n\nOur method incorporates both traditional 2D features and novel 3D features extracted from AI-generated 3D mesh inferences. This combination of features has shown experimental significance in improving the accuracy of glaucoma detection. The 3D features, in particular, provide a novel approach by considering the concavity of the optic cup and the depth in the optic nerve head, which are critical factors in distinguishing between glaucoma and healthy eyes.\n\nIn our experiments, we achieved perfect accuracy (100%) with the CDT and SVM classifiers on a dataset of twenty subjects. The KNN classifier also performed well, achieving an accuracy of 83.3%. These results demonstrate the effectiveness of our proposed method in accurately detecting glaucoma using a combination of 2D and 3D features.\n\nWhile we did not directly compare our method to publicly available benchmark datasets, our approach of integrating volumetric features from 3D mesh inferences represents a significant advancement over previous methods that relied solely on 2D features. This novel feature engineering method has shown promising results in our preliminary investigations and warrants further exploration on larger datasets.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The dataset employed for our research is the RIM-ONE DL dataset, which is an updated version specifically refined for deep learning uses. This dataset consists of 485 retinal images, each from a unique subject, with diagnoses made by specialists. While the RIM-ONE DL dataset itself is accessible, the specific evaluation files and the exact splits used for training and testing in our study are not publicly released. Therefore, researchers interested in replicating our work would need to obtain the RIM-ONE DL dataset and perform their own splits and evaluations."
}