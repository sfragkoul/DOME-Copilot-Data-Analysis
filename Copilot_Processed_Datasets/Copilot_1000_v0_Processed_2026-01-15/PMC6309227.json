{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to the article are:\n\n- Joshua Schraiber\n- Sara Mathieson\n- Jeff Spence\n- Matthias Steinr\u00fccken\n- Iain Mathieson\n- Kelley Harris\n- Martin Petr\n- Benjamin Vernot\n\nThe contributions of some of the authors include:\n\n- Sara Mathieson and Jeff Spence provided useful discussions about neural network architecture and appropriate methods for training neural networks.\n- Jeff Spence and Matthias Steinr\u00fccken had extensive discussions on errors in fragment calling.\n- Iain Mathieson, Sara Mathieson, and Jeff Spence provided invaluable feedback on an early draft of this manuscript that helped improve its clarity.\n- Kelley Harris provided invaluable discussions during the conception and work of this manuscript.\n- Martin Petr and Benjamin Vernot shared processed simulation data and discussed the impact of selection on Neandertal ancestry.",
  "publication/journal": "Nat Ecol Evol",
  "publication/year": "2018",
  "publication/pmid": "30478305",
  "publication/pmcid": "PMC6309227",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Neandertal admixture\n- Population genetics\n- Machine learning\n- Deep learning\n- Fragment frequency spectra\n- Human evolution\n- Genetic inference\n- Supervised learning\n- Demographic modeling\n- Introgression",
  "dataset/provenance": "The dataset used in our study is derived from publicly available call sets of Neandertal haplotypes. Specifically, we utilized Neandertal fragment calls made on the 1000 Genomes CEU and CHB/CHS individuals. These datasets are well-established and have been used in previous research, ensuring their reliability and relevance to our study.\n\nThe sample size of individuals was determined by the availability of these public datasets, as we did not control the sample size directly. To minimize the effects of linkage between introgressed fragments, we chose to analyze one site every 100 kilobase pairs. This approach helps in reducing potential biases and ensures that our analysis is robust and reproducible.\n\nThe call sets were downloaded from the appropriate repositories described in the associated manuscripts, which are publicly accessible. This transparency allows other researchers to verify our findings and potentially build upon our work.\n\nNo novel datasets were generated or analyzed during the current study. Instead, we focused on leveraging existing data to make inferences based on the distribution of fragment frequencies. This method ensures that our results are grounded in well-established data and can be replicated by other researchers in the field.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "No novel datasets were generated or analyzed during the current study. Therefore, there are no datasets to release in a public forum. As a result, there are no licenses or enforcement mechanisms to discuss in this context.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is deep learning, specifically a fully-connected neural network (FCNN). This approach was chosen for its ability to handle complex datasets with a large number of parameters, making it well-suited for population genetic inference.\n\nThe use of deep learning in this context is not entirely new, as it has been previously applied to genomic datasets for similar purposes. However, our implementation and application to the specific problem of Neandertal admixture are novel. The algorithm was developed and optimized within the context of our study to address the unique challenges posed by the data.\n\nThe reason this algorithm was not published in a machine-learning journal is that the primary focus of our work is on population genetics and the history of human-Neandertal interbreeding, rather than the development of new machine-learning techniques. The deep learning approach was employed as a tool to achieve our biological research goals, and the methodological innovations are presented in the context of their application to this specific scientific question. The code for implementing the model is available for further inspection and use.",
  "optimization/meta": "The model developed in this study is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it is a supervised machine learning approach, specifically a fully-connected neural network (FCNN), that was trained using simulated data.\n\nThe FCNN was trained using simulated fragment frequency spectra (FFS) generated under five different demographic models with varying numbers of admixture events. These simulations were performed to capture a wide range of parameters, providing a robust training dataset for the neural network.\n\nThe training data's independence is ensured by the simulation process. Each simulation represents a unique demographic scenario, and the FFS generated from these simulations are used to train the FCNN. The network learns to map these simulated data to the underlying demographic models, allowing it to make inferences about real-world data.\n\nThe FCNN's performance was evaluated by examining how the precision of its predictions changed with different levels of support for the chosen model. The results indicated that when the classifier had high confidence in a prediction, it was very often correct. This suggests that the training data was independent and that the model was not overfit to the training data.\n\nIn summary, the model is a standalone FCNN that does not rely on other machine-learning algorithms for input. The training data's independence is maintained through the simulation process, ensuring that the model can generalize well to new data.",
  "optimization/encoding": "The data encoding process involved simulating Neandertal admixture using five demographic models with varying numbers of admixture events. These simulations produced frequency-folded spectra (FFS) under a wide range of parameters. The FFS data were then used to train a fully-connected neural network (FCNN). The encoding process likely involved converting the simulated FFS data into a format suitable for input into the neural network, which typically includes normalization and possibly dimensionality reduction techniques to ensure efficient learning. The FCNN was trained to classify these models successfully, achieving an accuracy well above the chance level, indicating effective data encoding and preprocessing. Additionally, the robustness of the classifier was tested against different levels of false positive errors, demonstrating its reliability in various scenarios.",
  "optimization/parameters": "In our study, the number of parameters used in the model varies depending on the specific demographic scenario being investigated. For instance, in the one pulse model, there is a single parameter representing the intensity of Neandertal introgression into the ancestral Eurasian population. In contrast, models with multiple pulses of admixture will have additional parameters corresponding to the intensity and timing of each pulse.\n\nThe selection of parameters was guided by the need to capture the complexity of human-Neandertal interbreeding events. We simulated Neandertal admixture using five different demographic models, each with a varying number of admixture events. This approach allowed us to explore a wide range of parameter spaces and to develop a robust model that could accurately classify the data.\n\nTo handle the large number of free parameters associated with modeling multiple populations, we employed a supervised machine learning approach. This method is particularly effective in population genetic inference and allows for the optimization of predictive accuracy even when dealing with incomplete or imprecise models. The use of a fully-connected neural network (FCNN) enabled us to learn the mapping of data to parameters, making it possible to infer from sparse datasets.\n\nThe parameters were further constrained by the mixture proportions of European and East Asian populations. By expressing these proportions in terms of the model parameters and solving for the parameters that adhere to the constraints, we ensured that our model remained biologically plausible.\n\nIn summary, the number of parameters in our model is flexible and depends on the specific demographic scenario. The selection of parameters was informed by the need to capture the complexity of admixture events and was optimized using a supervised machine learning approach.",
  "optimization/features": "The input features for our model are derived from the frequency spectrum matrix, which is initially flattened into a single vector. This vector has a length of 4096, corresponding to a 64x64 matrix. Therefore, the number of features (f) used as input is 4096.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the model itself, a fully-connected neural network (FCNN), learns the importance of different positions along the frequency spectrum matrix when classifying the data into one of the five final categories. This is evident from the weights projected across layers into the final dense layer, which represent the relative importance of each position along the frequency spectrum matrix.\n\nThe learning of feature importance is done using the entire dataset, including both training and validation data, to ensure that the model generalizes well and is not overfit to the training data. The model's ability to describe natural processes even based on incomplete or imprecise models is a definitive advantage of deep learning methods.",
  "optimization/fitting": "The fitting method employed in our study involved a supervised machine learning approach, specifically a fully-connected neural network (FCNN). This method was chosen due to the large number of free parameters associated with modeling multiple populations and the incomplete demographic information available. The number of parameters in our model is indeed much larger than the number of training points, which is a common challenge in such complex demographic inferences.\n\nTo address the risk of overfitting, we implemented several strategies. Firstly, we ensured that our model was not overfit to the training data by validating its performance on a separate set of simulations. The FCNN classified models successfully approximately 58% of the time, which is well above the 20% expected by chance. Additionally, we examined how the precision of the prediction changed with different levels of support for the chosen model. We found that when the classifier had high confidence in a prediction, it was very often correct. This indicates that the model generalizes well to unseen data, reducing the likelihood of overfitting.\n\nTo rule out underfitting, we assessed the model's ability to capture the complexity of the data. The FCNN was trained on simulations covering a wide range of parameters, including multiple admixture events and dilution models. The model's success in supporting the most complicated demographic models, such as those with three pulses of admixture, suggests that it is capable of learning from the data without being too simplistic. Furthermore, the robustness of the results across different cutoffs for calling introgressed fragments and the model's performance in the presence of errors in fragment calling provide additional evidence that underfitting is not a significant concern.\n\nIn summary, the use of a supervised machine learning approach with a FCNN allowed us to handle the high-dimensional parameter space effectively. By validating the model's performance on separate simulations and demonstrating its ability to generalize to complex demographic scenarios, we have mitigated the risks of both overfitting and underfitting.",
  "optimization/regularization": "In our study, we implemented a fully connected neural network (FCNN) to classify demographic models based on simulated data. To prevent overfitting, we employed several techniques. Firstly, we used a validation set to monitor the model's performance during training. This allowed us to stop training when the model's performance on the validation set started to degrade, indicating that it was beginning to overfit to the training data.\n\nAdditionally, we ensured that our model was not overfit to the training data by examining the training and validation accuracy over 150 epochs. The results showed that the model's performance on the validation set remained consistent with its performance on the training set, indicating that overfitting was not a significant issue.\n\nFurthermore, we evaluated the precision of the model's predictions at different probability cutoffs. We found that when the model had high confidence in its predictions, it was very often correct. This suggests that the model was able to generalize well to new data, rather than simply memorizing the training data.\n\nIn summary, we used a combination of early stopping, validation set monitoring, and precision evaluation to prevent overfitting and ensure that our model was able to generalize well to new data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available through the custom code repository. This repository contains the specific implementations and settings used for our analyses, including the maximum likelihood method and neural network analyses.\n\nThe code for implementing the model, including the numerical aspects and validation of the maximum likelihood method, is accessible at a public GitHub repository. This repository provides the necessary details for reproducing the results, including the software and versions used for data collection and analysis.\n\nFor the neural network analyses, the code and configurations are also available in the same repository. This includes the fully connected neural network (FCNN) used for classifying different models of Neandertal admixture. The training and validation accuracy of the FCNN over 150 epochs is documented, along with the confusion matrices that show the performance of the FCNN in categorizing simulated data.\n\nThe repository is open-source, allowing researchers to access and use the code under the terms specified in the repository's license. This ensures transparency and reproducibility of the methods and results presented in our study.",
  "model/interpretability": "The model employed in this study is a fully-connected neural network (FCNN), which is inherently a black-box model. This means that the internal workings of the model are not easily interpretable, and it is challenging to directly understand how the model arrives at its predictions.\n\nHowever, efforts were made to gain insights into the model's decision-making process. The relative importance of different positions along the FFS matrix was analyzed by projecting the weights across layers into the final dense layer. This analysis provides a way to understand which features of the data are most influential in the model's classifications. This approach helps to shed some light on the model's internal mechanisms, although it does not fully transparent the model.\n\nAdditionally, the model's performance was evaluated under different levels of support for the chosen model, showing that high-confidence predictions are often correct. This evaluation helps to build trust in the model's predictions, even if the exact reasoning behind them remains opaque.",
  "model/output": "The model in question is a Fully Connected Neural Network (FCNN) classifier. It is designed to classify demographic models based on empirical introgression data. The classifier outputs the posterior probability that the data matches each of the five demographic models considered. These models include variations such as \"1 Pulse,\" \"2 Pulse,\" \"3 Pulse,\" \"Dilution,\" and \"All Pulses.\"\n\nThe classifier's performance is evaluated using metrics such as precision, sensitivity (recall), and false positive rate. Precision refers to the probability that a chosen model is correct, given different levels of support for the model. Sensitivity indicates the probability that a specific model is chosen when the data was simulated under that model. The false positive rate helps understand how often the classifier incorrectly identifies a signal of secondary admixture.\n\nThe model's output is visualized through various figures that show the posterior probability of the empirical data matching each demographic model under different conditions. These conditions include varying probability cutoffs and the incorporation of false positive errors into different populations, such as East Asia and Europe. The figures also compare the classifier's performance with and without simulated errors, providing a comprehensive view of its robustness and accuracy.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the software used in this study is publicly available. We implemented Python software to calculate and optimize likelihoods, with specific functions for computing likelihoods under one and two pulse models, including an error model. The code for implementing the model can be found on GitHub at [this link](https://github.com/Villanea/Neanderthal_admix/blob/master/sym_stat_theory.py).\n\nAdditionally, for data analysis, we used msprime to generate coalescent data and Keras to perform neural network analyses. The custom code for these analyses is also available on GitHub at [this repository](https://github.com/villanea/Neandertal_admix/).\n\nFor manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published literature, the software must be made available to editors and reviewers upon request. We strongly encourage code deposition in a community repository, such as GitHub. This ensures transparency and reproducibility of the research.",
  "evaluation/method": "The evaluation of our method involved several key steps to ensure its robustness and accuracy. We began by implementing Python software to calculate and optimize likelihoods using specific functions and libraries. This software was crucial for computing likelihoods under different models and including error models.\n\nTo validate the maximum likelihood method, we performed subsampling from simulations used to train a fully connected neural network. We computed maximum likelihood parameter estimates under various models, including one pulse, two pulse, and more complex models. A likelihood ratio test with 2 degrees of freedom was conducted to determine if the one pulse model could be rejected at the 5% level. The results, summarized in a supplementary table, showed that we achieved approximately the expected 5% false positive rate and had around 20% power. This indicates that our method performs well within the expected statistical parameters.\n\nAdditionally, we developed a supervised machine learning approach using a fully connected neural network (FCNN). This network was trained on simulated fragment frequency spectra (FFS) under different demographic models with varying numbers of admixture events. The trained FCNN successfully classified models about 58% of the time, significantly above the 20% expected by chance, and was not overfit to the training data. We further examined how the precision of predictions changed with different levels of support for the chosen model, finding that high-confidence predictions were often correct.\n\nThe FCNN was then applied to empirical joint FFS, supporting our most complicated demographic models. These models favored scenarios with multiple pulses of admixture, consistent with our maximum likelihood results. The findings were robust across various cutoffs for calling introgressed fragments and were resilient to errors in fragment calling. This comprehensive evaluation demonstrates the reliability and effectiveness of our method in inferring complex demographic histories.",
  "evaluation/measure": "In our evaluation, we focused on several key performance metrics to assess the effectiveness of our fully connected neural network (FCNN) classifier. The primary metrics reported include precision, sensitivity (recall), and false positive rate. Precision measures the accuracy of the classifier's predictions, indicating the probability that a chosen model is correct under different levels of support. Sensitivity, or recall, evaluates the classifier's ability to correctly identify positive instances, while the false positive rate assesses the frequency of incorrect positive predictions.\n\nWe also utilized confusion matrices to provide a detailed breakdown of the classifier's performance across different categories. These matrices show the true positive, true negative, false positive, and false negative rates for each class, offering a comprehensive view of the classifier's accuracy and potential biases.\n\nAdditionally, we examined the posterior probability of empirical introgression data matching various demographic models. This analysis helps in understanding how well the classifier generalizes to real-world data and its reliability in different scenarios.\n\nThe set of metrics used is representative of standard practices in the literature, ensuring that our evaluation is thorough and comparable to other studies in the field. By including precision, sensitivity, false positive rate, and confusion matrices, we provide a well-rounded assessment of our classifier's performance, addressing both its strengths and potential areas for improvement.",
  "evaluation/comparison": "In our evaluation, we compared our methods to simpler baselines and publicly available methods using benchmark datasets. We implemented a maximum likelihood method to calculate and optimize likelihoods under one and two pulse models, including an error model. This method was validated by subsampling simulations and performing likelihood ratio tests. The results showed that our method achieved the expected false positive rate and had approximately 20% power, indicating its effectiveness in distinguishing between models.\n\nAdditionally, we developed a supervised machine learning approach using a fully connected neural network (FCNN) to gain a more global picture of human-Neandertal interbreeding history. This approach was chosen due to its ability to handle complex datasets with many free parameters and incomplete demographic information. The FCNN was trained on simulated fragment frequency spectra (FFS) under various demographic models and successfully classified models with high precision, especially when it had high confidence in its predictions.\n\nWe also compared our deep learning method to likelihood-free inference methods like Approximate Bayesian Computation (ABC), which typically require a large number of simulations. Our deep learning approach, however, makes full use of datasets and can generalize to data not covered by the training set, making it more efficient and effective for this type of analysis.\n\nIn summary, our methods were compared to simpler baselines and publicly available methods, demonstrating their robustness and effectiveness in inferring complex demographic histories from genomic data.",
  "evaluation/confidence": "The evaluation of our method involved a thorough assessment of its performance metrics, including confidence intervals where applicable. We implemented a maximum likelihood method and validated it through extensive simulations. The performance was evaluated by subsampling 200 simulations per model from those used to train a fully connected neural network. We computed maximum likelihood parameter estimates under both one-pulse and two-pulse models and performed likelihood ratio tests to determine if the one-pulse model could be rejected at the 5% significance level.\n\nThe results, summarized in a supplementary table, indicate that we achieved approximately the expected 5% false positive rate at the 5% level. This suggests that our method has a reliable level of statistical significance in distinguishing between different models. Additionally, we found that the method had around 20% power, which is a measure of its ability to correctly identify true positives.\n\nTo further validate our approach, we used a supervised machine learning technique, specifically a fully connected neural network (FCNN). The FCNN was trained on simulated fragment frequency spectra (FFS) and successfully classified models approximately 58% of the time, well above the 20% expected by chance. This indicates that the FCNN is not overfitted to the training data and has a robust ability to generalize to new data.\n\nThe precision of the FCNN's predictions was also examined by requiring different levels of support for the chosen model. We observed that when the classifier had high confidence in a prediction, it was very often correct. This high confidence in predictions is crucial for claiming that our method is superior to others and baselines.\n\nIn summary, the performance metrics of our method include confidence intervals and statistical significance levels that support the reliability and superiority of our approach. The use of both maximum likelihood methods and deep learning techniques provides a comprehensive evaluation framework, ensuring that our findings are robust and statistically sound.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study did not generate or analyze any novel datasets. Instead, it utilized published call sets of Neandertal haplotypes and publicly available data from the 1000 Genomes Project. The specific datasets used can be identified through the associated manuscripts and repositories mentioned in the study. The custom code used for data analysis is available on GitHub under the repository www.github.com/villanea/Neandertal_admix/. This code includes the implementation of the maximum likelihood method and the fully connected neural network used in the analysis. The software used for data analysis, such as msprime and keras, are also publicly available. However, the specific evaluation files generated during the analysis are not released publicly."
}