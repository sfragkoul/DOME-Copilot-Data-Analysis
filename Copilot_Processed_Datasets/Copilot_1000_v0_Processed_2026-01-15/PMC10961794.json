{
  "publication/title": "Leveraging Large Data, Statistics, and Machine Learning to Predict the Emergence of Resistant E. coli Infections",
  "publication/authors": "The authors of the article are Rim Hur, Stephine Golik, and Yifan She. Rim Hur contributed to the conceptualization, methodology, software, validation, formal analysis, investigation, resources, data curation, writing of the original draft, writing of the review and editing, and visualization. Stephine Golik contributed to the validation, formal analysis, investigation, resources, data curation, writing of the review and editing, and project administration. Yifan She contributed to the conceptualization, validation, writing of the review and editing, visualization, supervision, and project administration.",
  "publication/journal": "Pharmacy",
  "publication/year": "2024",
  "publication/pmid": "38525733",
  "publication/pmcid": "PMC10961794",
  "publication/doi": "10.3390/pharmacy12020053",
  "publication/tags": "- Time series models\n- ARIMA\n- Neural networks\n- Random forest algorithm\n- Antimicrobial resistance\n- Antibiotic resistance\n- Length of stay (LOS)\n- Antimicrobial stewardship programs (ASPs)\n- Drug-resistant infections\n- Machine learning in healthcare\n- Statistical modeling\n- Antibiotic usage\n- E. coli infections\n- Hospital operational costs\n- Predictive analytics in pharmacy",
  "dataset/provenance": "The dataset used in this study was sourced from a single Kaiser Permanente facility located in a rural region with relatively low population migration. Specifically, the data was collected from the Kaiser Permanente Vacaville Medical Center, a 152-bed level 2 trauma center situated in Vacaville, California. The study included all microbial cultures of E. coli from various sources of infection, such as abscesses, blood, urine, and wounds, recorded at this facility. Additionally, the dataset encompassed total antibiotic utilization data, reported as days of therapy per 1000 patient days, for several classes of antibiotics, including cephalosporins, beta-lactams, fluoroquinolones, and aminoglycosides, administered via both oral and intravenous routes.\n\nThe dataset spanned from April 1, 2013, to December 31, 2019, and included a total of 4776 microbial cultures identified through Kaiser Permanente\u2019s electronic health record. This longitudinal data was utilized to train statistical and machine learning algorithms. Subsequently, data from the year 2019 was used to test the accuracy of these models and to generate estimates of future antibiotic resistance at the Kaiser Permanente Vacaville Medical Center. The study population consisted of patients admitted to the facility within the specified timeframe who met the inclusion criteria, which involved the administration of specific antibiotics and the presence of E. coli cultures. The dataset has not been previously used in other published studies or by the broader community, as it is specific to this facility and the time period mentioned.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "The study utilized longitudinal data collected from a single Kaiser Permanente facility located in a rural region with relatively low population migration. The data spanned from April 1, 2013, to December 31, 2018, and was used to train statistical and machine learning algorithms. Subsequently, data from the year 2019 (January 1, 2019, to December 31, 2019) was used to test the accuracy of the models and to generate estimates of future antibiotic resistance at the facility.\n\nThe training and test sets were independent, with the training set consisting of data from 2013 to 2018 and the test set consisting of data from 2019. This independence was enforced by using a time-slice approach, where a fixed validation window at the end of the training dataset was kept for testing. This approach simulated a realistic forecasting scenario by ensuring that the test data was not used in the training process.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of antibiotic resistance and healthcare-related research. The dataset included microbial cultures of E. coli from various sources of infection and total antibiotic utilization at the facility. This comprehensive approach allowed for a robust analysis of the relationship between antibiotic usage and the development of antibiotic resistance over time.\n\nThe study's focus on a single facility with relatively low population migration helped to control for external variables that could affect the results. However, it is acknowledged that a broader study using data from multiple facilities could provide more generalizable findings. Additionally, while the performance of the models was evaluated against the test dataset from 2019, a follow-up study could be carried out to validate the predictions made for 2020 using actual data from that year. This would further enhance the robustness and applicability of the findings.",
  "dataset/availability": "The data that support the findings of this study are available from Kaiser Permanente. However, restrictions apply to the availability of these data, which were used under license for the current study, and so are not publicly available. The data are, however, available from the authors upon reasonable request and with permission of Kaiser Permanente.",
  "optimization/algorithm": "The machine-learning algorithms used in this study include random forest and neural networks. These are well-established classes of machine-learning algorithms that have been extensively used in various fields, including healthcare and pharmaceutical research.\n\nThe random forest algorithm is an ensemble learning method that operates by constructing multiple decision trees during training and outputting the mode of the classes (classification) or mean prediction (regression) of the individual trees. It is known for its robustness and ability to handle large datasets with high dimensionality.\n\nThe neural network used in this study is a type of artificial neural network (ANN) built using the nnetar() function in R. This function creates simple neural networks with a single hidden layer, taking non-seasonal lags as inputs. The number of inputs and the number of nodes in the hidden layer were modified to identify the most optimal model.\n\nNeither of these algorithms is new; they have been widely studied and applied in various domains. The random forest algorithm, for instance, was introduced by Breiman in 2001 and has since become a standard tool in machine learning. Similarly, neural networks have been a subject of research for several decades, with significant advancements in recent years due to the rise of deep learning.\n\nThe choice of these algorithms for this study was driven by their proven effectiveness in handling time series data and their ability to capture complex relationships between variables. The random forest algorithm, in particular, has been shown to outperform existing time series models for predicting infectious disease outbreaks, as demonstrated by research conducted by Michael Kane at Yale University.\n\nThe neural network, despite its simplicity, was chosen for its ability to model non-linear relationships and its flexibility in handling different types of data. The nnetar() function, while not the most advanced neural network implementation, was selected for its ease of use and integration with other statistical methods in R.\n\nIn summary, the machine-learning algorithms used in this study are well-established and have been chosen for their proven effectiveness in handling time series data and capturing complex relationships between variables. The focus of this study is on applying these algorithms to a specific problem in healthcare, rather than developing new machine-learning techniques.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it employs several distinct machine learning and statistical methods independently to analyze and predict antibiotic resistance rates. The primary models used include ARIMA, neural networks, and random forest algorithms. Each of these models was built and evaluated separately, using different techniques and datasets.\n\nThe ARIMA model was constructed using the auto.arima() function in R, which automates the process of identifying the best ARIMA parameters. Neural networks were developed using the nnetar() function, which creates simple neural networks with a single hidden layer. The random forest models were built using the RandomForest package in R, with parameter tuning focused on the 'mtry' parameter to optimize performance.\n\nThese models were evaluated based on their performance metrics, such as RMSE and MAE, across both training and test datasets. The ARIMA model generally outperformed the neural network and random forest models in terms of these metrics. The choice of the best model was based on which showed the least signs of overfitting or underfitting, ensuring that it provided a reliable prediction of antibiotic resistance rates.\n\nThe data used for training and testing these models were collected from a single Kaiser Permanente facility, focusing on longitudinal data from 2013 to 2019. The models were evaluated against the test dataset from the final year, 2019, to assess their predictive accuracy. While the study suggests potential for future research using data from multiple facilities and additional years, the current implementation does not integrate data from other machine-learning algorithms as input. Each model operates independently, without combining predictions from different algorithms to form a meta-predictor.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps to ensure the models could effectively learn from the dataset. Initially, the data was collected from a single Kaiser Permanente facility, focusing on antibiotic utilization and microbial cultures of E. coli from various infection sources. The antibiotic utilization data was reported as days of therapy per 1000 patient days, covering a range of antibiotics including cephalosporins, beta-lactams, fluoroquinolones, and aminoglycosides.\n\nFeature selection was a critical part of the preprocessing. Recursive feature selection using the random forest algorithm was employed to identify the most important features based on their contribution to the model, measured by the percent increase in mean squared error. This process helped in retaining the most relevant antibiotics that significantly impacted antibiotic resistance rates.\n\nTime-lag identification was another crucial step. Cross-correlation analysis was conducted on the selected features to determine the optimal time-lag at which antibiotic usage was significantly associated with antibiotic resistance rates. This analysis helped in understanding the temporal dynamics between antibiotic use and resistance emergence.\n\nFor the time series modeling, the data was split into training and testing sets. The training data spanned from April 2013 to December 2018, while the testing data covered the year 2019. This split allowed for the evaluation of model performance on unseen data, ensuring the models' robustness and generalizability.\n\nThe preprocessing also involved handling missing values and normalizing the data to ensure consistency and improve the performance of the machine-learning algorithms. The data was encoded in a format suitable for the ARIMA, neural network, and random forest time series models, with exogenous regressors included to account for the selected antibiotics' usage.\n\nOverall, the data encoding and preprocessing steps were designed to enhance the models' ability to capture the complex relationships between antibiotic usage and resistance rates, ultimately aiding in the prediction of future antibiotic resistance trends.",
  "optimization/parameters": "In our study, we employed several models, each with its own set of input parameters. For the random forest algorithm, the key parameter was 'mtry', which represents the number of variables considered for splitting at each tree node. We utilized a tuning grid with three values for 'mtry': the total number of predictors, a third of this number, and the square root of the number of predictors. This approach is in line with common random forest heuristics.\n\nFor the neural network models, we built simple neural networks with a single hidden layer. The number of inputs and the number of nodes in the hidden layer were modified to identify the most optimal model. The performance of these models was measured by Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE).\n\nThe ARIMA models were built using the auto.arima() function, which automatically selects the optimal parameters based on the data. The exogenous regressors used in these models were selected based on their significance in correlation analyses, stepwise linear regression, and recursive feature elimination processes. These regressors included antibiotics such as cephalexin, amoxicillin, cefazolin, cefotetan, and piperacillin/tazobactam, with corresponding time-lags identified by cross-correlation analyses.\n\nThe selection of these parameters was driven by a combination of statistical methods and domain knowledge. The goal was to identify the most significant features and optimal model configurations that could accurately predict antibiotic resistance rates. The performance of the models was evaluated using MAE and RMSE, ensuring that the selected parameters provided the best fit for the data while avoiding overfitting or underfitting.",
  "optimization/features": "In the \"Input Features\" subsection of the \"Optimization\" section, the study utilized several antibiotics as input features for the time-series models. The specific antibiotics selected were cephalexin, amoxicillin, cefazolin, cefotetan, and piperacillin/tazobactam. These antibiotics were chosen based on their significant correlation with antibiotic resistance rates and through a rigorous feature selection process.\n\nFeature selection was indeed performed using multiple methods, including correlation analysis, stepwise linear regression, and recursive feature elimination with the random forest algorithm. These methods ensured that only the most relevant antibiotics were included as exogenous regressors in the time-series models. The feature selection process was conducted using the training set only, adhering to best practices to prevent data leakage and ensure the robustness of the models.\n\nThe number of features (f) used as input for the time-series models was five. These features were identified through a combination of statistical and machine learning techniques, ensuring that the models were built on a solid foundation of relevant and significant predictors.",
  "optimization/fitting": "The fitting method employed in this study involved several time series modeling techniques, including ARIMA, neural networks, and random forest algorithms. The number of parameters in these models was managed carefully to avoid both overfitting and underfitting.\n\nFor the ARIMA models, the auto.arima() function in R was used, which automatically selects the optimal parameters based on the data. This function helps in preventing overfitting by ensuring that the model is not too complex relative to the number of training points. The performance of the ARIMA models was evaluated using mean absolute error (MAE) and root mean squared error (RMSE) on both training and test datasets. Models that showed a significant discrepancy between training and test performance were discarded to rule out overfitting.\n\nNeural networks were built using the nnetar() function in R, which constructs simple neural networks with a single hidden layer. The number of inputs and nodes in the hidden layer were adjusted to find the most optimal model. To prevent overfitting, the performance of these models was also measured by MAE and RMSE. Models that exhibited poor generalization to the test data were not considered further.\n\nThe random forest algorithm was used for regression time series modeling, with parameter tuning focused on the 'mtry' parameter, which represents the number of variables considered for splitting at each tree node. The 'caret' package\u2019s 'train' function with a time-slice approach was employed, simulating a realistic forecasting scenario. This method involved keeping a fixed validation window at the end of the training dataset, spanning a forecast horizon of twelve months. The tuning grid included three 'mtry' values: the total number of predictors, a third of this number, and the square root of the number of predictors. This approach helped in selecting the optimal number of parameters, thereby avoiding overfitting.\n\nTo rule out underfitting, models were evaluated for their ability to capture the underlying patterns in the data. Models that performed poorly on both training and test datasets were discarded. The final models selected were those that showed the best balance between bias and variance, ensuring that they neither overfit nor underfit the data.\n\nIn summary, the fitting method involved careful selection and tuning of model parameters, along with rigorous evaluation using MAE and RMSE on both training and test datasets. This approach ensured that the models were neither too complex nor too simple, providing reliable predictions for antibiotic resistance rates.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method involved using a time-slice approach for model validation. This approach simulated a realistic forecasting scenario by keeping a fixed validation window at the end of the training dataset, spanning the forecast horizon of twelve months. This technique helped in assessing the model's performance on unseen data, thereby reducing the risk of overfitting.\n\nAdditionally, we utilized recursive feature selection with the random forest algorithm to identify the most important features. This process helped in retaining only the most relevant predictors, which contributed significantly to the model's performance. By focusing on these key features, we minimized the complexity of the models and reduced the likelihood of overfitting.\n\nFor the random forest algorithm, we performed parameter tuning, particularly focusing on the 'mtry' parameter, which represents the number of variables considered for splitting at each tree node. We established a tuning grid with three 'mtry' values: the total number of predictors, a third of this number, and the square root of the number of predictors. This tuning process helped in optimizing the model's performance and preventing overfitting.\n\nFurthermore, we evaluated the performance of our models using mean absolute error (MAE) and root mean squared error (RMSE) on both training and test datasets. This evaluation helped in identifying models that showed the least signs of overfitting or underfitting. The best-performing model was selected based on its performance metrics across both datasets, ensuring that it generalized well to new data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available within the text of the publication. Specifically, details about the random forest algorithm's 'mtry' parameter tuning and the time-slice approach for model validation are provided. The ARIMA models were built using the auto.arima() function, and neural networks were constructed with the nnetar() function, both in R 3.6.2. The performance of these models was measured using MAE and RMSE.\n\nThe exact model files and optimization schedules are not explicitly detailed in the publication, as the focus was on the methodology and results rather than the specific implementation files. However, the steps and parameters used for model building and tuning are thoroughly described, allowing for replication of the study's methods.\n\nThe data used in this study is available from Kaiser Permanente, but restrictions apply due to licensing agreements. Therefore, while the data is not publicly available, it can be accessed upon reasonable request and with the permission of Kaiser Permanente. The study was conducted under the terms of the Creative Commons Attribution (CC BY) license, which allows for the sharing and adaptation of the work with appropriate credit.",
  "model/interpretability": "The models employed in this study include ARIMA, neural networks, and random forest algorithms, each with varying degrees of interpretability.\n\nThe ARIMA model is generally considered more interpretable than machine learning models like neural networks and random forests. ARIMA models are transparent in the sense that they are based on linear combinations of past values and errors, making it relatively straightforward to understand how each component contributes to the predictions. The parameters of the ARIMA model (p, d, q) represent the order of the autoregressive part, the degree of differencing, and the order of the moving average part, respectively. These parameters can be interpreted in the context of the time series data, providing insights into the underlying patterns and trends.\n\nIn contrast, neural networks and random forest models are often considered black-box models due to their complexity and the non-linear relationships they capture. Neural networks, particularly those with multiple hidden layers, can be difficult to interpret because the relationships between inputs and outputs are encoded in the weights and biases of the network. However, the simple neural networks used in this study, built with the nnetar() function in R, have a single hidden layer, which makes them somewhat more interpretable than deeper networks. The inputs to these networks are non-seasonal lags of the time series data, and the number of nodes in the hidden layer can be adjusted to optimize performance.\n\nRandom forest models are also complex and can be challenging to interpret. They consist of multiple decision trees, each of which makes a prediction based on a subset of the data. The final prediction is an average of the predictions from all the trees. However, feature importance can be extracted from random forest models, providing some level of interpretability. In this study, recursive feature selection was performed using the random forest algorithm to identify the most important features (antibiotics) contributing to the model. This process helps in understanding which antibiotics have the most significant impact on the predicted outcomes.\n\nIn summary, while the ARIMA model offers more transparency and interpretability, the neural network and random forest models provide insights through feature importance and the structure of the models. The choice of model depends on the trade-off between interpretability and predictive performance.",
  "model/output": "The model developed in this study is a regression model. It focuses on predicting the rates of resistant E. coli infections using various antibiotics as exogenous regressors. The primary goal was to forecast the antibiotic resistance rates over a specified period, rather than classifying data into distinct categories. The performance of the models was evaluated using metrics such as Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE), which are commonly used in regression analysis to measure the accuracy of predictions.\n\nSeveral time series models were employed, including ARIMA, neural networks, and random forest models. These models were built using functions like auto.arima(), nnetar(), and the RandomForest package in R. The models incorporated different antibiotics as regressors, with time-lags identified through cross-correlation analyses. The best-performing model, in terms of RMSE and MAE, was the ARIMA model with cefazolin as an external regressor. This model was used to predict the rate of resistant E. coli infections for the year 2020, assuming the same rate of cefazolin usage as in 2019.\n\nThe study also highlighted the importance of considering the limitations of observational data and the need for further research to establish causal relationships. The findings suggest that while certain antibiotics, such as cefazolin, are significantly associated with drug-resistant E. coli infections, practical interventions can be made at the point of discharge for antibiotics like amoxicillin and cephalexin. The research provides a foundational structure for integrating statistical and machine-learning methodologies to develop targeted interventions in clinical settings.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the models involved assessing their performance using Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) metrics. These metrics were calculated for both training and test datasets to ensure the models were neither overfitting nor underfitting. The test dataset consisted of data from the final year, 2019, which was not used during the training phase. This approach simulated a realistic forecasting scenario, where the models were evaluated on data they had not seen before.\n\nThe ARIMA model, neural network, and random forest models were built using various antibiotics as exogenous regressors, with time-lags identified through cross-correlation analyses. The performance of these models was compared across different antibiotics, including cephalexin, amoxicillin, cefazolin, cefotetan, and piperacillin/tazobactam. The ARIMA model generally outperformed the neural network and random forest models in terms of RMSE and MAE values.\n\nFor the neural network models, the nnetar() function in R was used, which builds simple neural networks with a single hidden layer. The number of inputs and nodes in the hidden layer were adjusted to identify the most optimal model. The random forest models were built using the RandomForest package in R, with parameter tuning focused on the 'mtry' parameter, which represents the number of variables considered for splitting at each tree node. The 'caret' package\u2019s \u2018train\u2019 function with a time-slice approach was employed to simulate a realistic forecasting scenario.\n\nThe best-performing model, which showed the least signs of overfitting or underfitting, was used to predict antibiotic resistance rates over the next 12 months, from January 2020 to December 2020. The ARIMA model with cefazolin as an external regressor was identified as the optimal model for this prediction. Assuming the same rate of cefazolin usage as in 2019, the predicted rate of resistant E. coli infections in 2020 was 6.2%, with a 95% prediction interval of 0.9% to 11.5%. This evaluation method ensured that the models were robust and reliable for predicting future antibiotic resistance rates.",
  "evaluation/measure": "The performance of the time-series models was primarily evaluated using two key metrics: Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). These metrics are widely recognized and used in the literature for assessing the accuracy of predictive models, particularly in time-series forecasting.\n\nMAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It provides a straightforward interpretation of the average error size, making it easy to understand the typical error magnitude. RMSE, on the other hand, gives more weight to larger errors due to the squaring of the differences. This makes RMSE more sensitive to outliers and larger errors, providing a better sense of the overall model performance when errors are not uniformly distributed.\n\nBoth MAE and RMSE were calculated for the training and test datasets, ensuring a comprehensive evaluation of the models' performance. The training dataset metrics helped in assessing how well the models fit the historical data, while the test dataset metrics provided insights into the models' predictive accuracy on unseen data. This dual evaluation approach is crucial for identifying any signs of overfitting or underfitting, ensuring that the selected model generalizes well to new data.\n\nThe use of these metrics aligns with established practices in the field, making the evaluation robust and comparable to other studies. Additionally, the focus on both training and test datasets ensures that the models are not only accurate but also reliable for future predictions.",
  "evaluation/comparison": "In our study, we compared the performance of three different modeling approaches: ARIMA, neural networks, and random forest models. These comparisons were conducted using time series data from a single Kaiser Permanente facility, focusing on the relationship between antibiotic usage and the emergence of resistant E. coli infections.\n\nThe ARIMA model outperformed both the neural network and random forest models in most scenarios. This finding aligns with a systematic review published in 2019, which indicated that machine learning algorithms do not necessarily outperform logistic regression in clinical prediction models. The neural network model, in particular, did not meet our initial expectations, which might be attributed to the limitations of the simple nnetar() function in R that was used.\n\nWe evaluated the models using root mean square error (RMSE) and mean absolute error (MAE) metrics. The ARIMA model with cefazolin as an exogenous regressor showed the best performance across both training and test datasets. This model was used to predict the rate of resistant E. coli infections for the year 2020, assuming the same rate of cefazolin usage as in 2019.\n\nThe random forest model, while performing well in the test dataset with cefazolin, exhibited underfitting in the training dataset, making it less reliable for real-world predictions. The neural network models, built using the nnetar() function, were relatively simple and did not include advanced architectures that might have improved their performance.\n\nIn summary, our comparison of methods revealed that the ARIMA model was the most robust and reliable for predicting antibiotic resistance rates based on the available data. Future studies could explore more advanced neural network architectures and larger, more diverse datasets to further validate these findings.",
  "evaluation/confidence": "Evaluation Confidence\n\nThe study evaluated the performance of various time series models, including ARIMA, neural networks, and random forest algorithms, using mean absolute error (MAE) and root mean squared error (RMSE) metrics. These metrics were calculated for both training and test datasets, providing a comprehensive view of model performance.\n\nThe ARIMA model with cefazolin as an exogenous regressor demonstrated the lowest RMSE and MAE values across both datasets, indicating robust performance. The neural network and random forest models, while showing competitive performance in some cases, did not consistently outperform the ARIMA model. The ARIMA model's superiority was further supported by its alignment with a systematic review that found no clear evidence of machine learning algorithms outperforming logistic regression in clinical prediction models.\n\nThe study also highlighted the limitations of the neural network model, attributing its underperformance to the simplicity of the nnetar() function used in R. This suggests that more sophisticated neural network architectures might yield better results in future studies.\n\nStatistical significance was not explicitly mentioned for the performance metrics, but the consistent outperformance of the ARIMA model across different antibiotics and datasets implies a strong confidence in its results. The prediction interval for the ARIMA model's forecast of resistant E. coli infections in 2020 was provided, offering a range within which the true value is expected to lie with 95% confidence.\n\nOverall, the evaluation of model performance was thorough, with multiple metrics and datasets used to assess the models' accuracy and reliability. The ARIMA model's consistent superiority provides a high level of confidence in its predictions and the study's conclusions.",
  "evaluation/availability": "The data that support the findings of this study are available from Kaiser Permanente. However, there are restrictions on the availability of these data, as they were used under license for the current study. Therefore, the data are not publicly available. The data are available from the authors upon reasonable request and with permission of Kaiser Permanente."
}