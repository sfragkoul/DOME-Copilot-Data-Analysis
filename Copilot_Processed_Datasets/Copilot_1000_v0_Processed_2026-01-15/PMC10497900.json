{
  "publication/title": "Comparison of intracranial pressure prediction in hydrocephalus patients among linear, non-linear, and machine learning regression models in Thailand",
  "publication/authors": "The authors who contributed to this article are:\n\n- **Akkarapong Trakulpanitkit**: This author was involved in the study of intracranial pressure prediction in hydrocephalus. Their contributions likely include research design, data collection, analysis, and interpretation of results related to the prediction models and statistical methods used.\n\n- **Tunthanathip Tunthanathip**: This author also played a significant role in the study. Their contributions likely include the development and implementation of machine learning models, such as random forest and XGBoost, for predicting intracranial pressure. They may have also been involved in the statistical analysis and the interpretation of the results, as well as the writing and editing of the manuscript.",
  "publication/journal": "Acute and Critical Care",
  "publication/year": "2023",
  "publication/pmid": "37652865",
  "publication/pmcid": "PMC10497900",
  "publication/doi": "10.1016/j.acc.2023.06.002",
  "publication/tags": "- Intracranial pressure\n- Hydrocephalus\n- Optic nerve sheath diameter\n- Machine learning\n- Predictive modeling\n- Ensemble learning\n- Random forest\n- XGBoost\n- Ventricular indexes\n- Non-invasive prediction",
  "dataset/provenance": "The dataset used in this study was sourced from a cohort of patients who underwent surgical procedures for hydrocephalus. Specifically, the data was collected from intraoperative records and imaging parameters measured during these procedures. The dataset consists of 412 patients, providing a comprehensive sample size for analysis.\n\nThe data includes various clinical and imaging parameters. Clinical data encompasses baseline characteristics such as sex, age, underlying diseases, American Association of Anesthesiologists classification, signs and symptoms, preoperative Glasgow coma scale score, pupillary light reflex, type of hydrocephalus, basal cistern obliteration, and whether the operation was an emergency. Imaging parameters include measurements of the optic nerve sheath diameter, distances between specific brain structures, and various ventricular indexes.\n\nThis dataset has not been previously used in other published papers by the community. The measurements and calculations, such as the Evans index, third ventricle index, cella media index, and ventricular score, were specifically tailored for this study to predict intracranial pressure in hydrocephalus patients. The dataset was divided into training and testing sets using an 80:20 split, with 330 patients used for training the predictive models and the remaining for testing their performance.",
  "dataset/splits": "The dataset was divided into two splits: a training dataset and a testing dataset. This split followed an 80:20 ratio. Consequently, 330 patients were allocated to the training dataset, while the remaining patients were used for testing the model's performance. The training dataset was utilized to construct the predictive model, and the testing dataset was employed to estimate the performance of intracranial pressure prediction.",
  "dataset/redundancy": "The dataset used in this study was split into training and testing sets using a random 80:20 split. This means that 80% of the data was allocated to the training dataset, which was used to construct the predictive models. The remaining 20% of the data was used as the testing dataset to estimate the performance of the intracranial pressure (ICP) prediction models.\n\nThe training and testing sets were independent, ensuring that the models were evaluated on data they had not seen during training. This independence was enforced by the random split, which helps to prevent data leakage and ensures that the model's performance is a true reflection of its generalizability.\n\nRegarding the distribution of the dataset, it is not directly comparable to previously published machine learning (ML) datasets because this study focuses specifically on ICP prediction in hydrocephalus patients. However, the dataset included various imaging parameters such as the optic nerve sheath diameter (ONSD) and ventricular indexes, which are crucial for ICP prediction. The mean ICP recorded was 31.43 mm Hg with a standard deviation of 9.45 mm Hg, and the mean ONSD was 5.5 mm with a standard deviation of 0.8 mm. These parameters were used to develop and validate the ML models, ensuring that the dataset was comprehensive and relevant to the study's objectives.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study falls under the class of ensemble learning techniques. Specifically, we utilized two prominent algorithms: Random Forest (RF) and Extreme Gradient Boosting (XGBoost). These algorithms are well-established in the machine learning community and have been extensively used for various predictive tasks, including those in the medical field.\n\nNeither of these algorithms is new; they have been widely adopted and refined over the years. Random Forest is known for its robustness and ability to handle large datasets with high dimensionality, while XGBoost is renowned for its efficiency and performance in structured/tabular data.\n\nThe choice to use these algorithms in a medical context, rather than a machine-learning journal, is driven by the specific application and the need to demonstrate their utility in predicting intracranial pressure (ICP) in patients with hydrocephalus. The focus of our work is on the clinical relevance and practical application of these algorithms, rather than the development of new machine-learning techniques. By showcasing the effectiveness of ensemble learning in a medical setting, we aim to highlight the potential of these methods for non-invasive ICP prediction, which can be particularly beneficial for patients with contraindications to invasive procedures.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. Instead, it employs ensemble learning techniques, specifically XGBoost and Random Forest (RF) algorithms, to predict intracranial pressure (ICP). These algorithms are used individually to build predictive models, rather than combining the outputs of multiple machine learning algorithms as inputs for a higher-level model.\n\nThe ensemble learning methods used\u2014XGBoost and RF\u2014are trained on the same dataset, which is split into training and testing sets. The training dataset is used to construct the predictive models, while the testing dataset is used to estimate the performance of ICP prediction. This approach ensures that the training data is independent for each model, as the split is random and the models are trained separately.\n\nThe predictive performance of these models is evaluated using metrics such as mean absolute error (MAE) and root mean square error (RMSE). The inclusion of ventricular indexes in the model development strategy improved the R\u00b2 value, indicating a better explanation of the variance in ICP by the independent variables. This enhancement in performance is attributed to the additional information provided by the ventricular indexes, which represent the severity of ventricular size and its direct impact on ICP.\n\nIn summary, the model utilizes ensemble learning algorithms to predict ICP, with a focus on optimizing performance through the inclusion of relevant features. The training data for these models is independent, ensuring robust and reliable predictions.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithms involved several steps to ensure the data was suitable for model training and testing. Initially, various measurements were taken, including the distance between the caudate nuclei, the maximum width of the third ventricle, the maximum inner diameter of the skull, the minimum width of the cella media, and the maximal outer interparietal diameter. These measurements were used to calculate ventricular indexes such as the Evans index, third ventricle index, cella media index, and ventricular score.\n\nThe optic nerve sheath diameter (ONSD) was measured on an axis perpendicular to the optic nerve at 3 mm behind the globe using axial CT imaging. The average ONSD was calculated for analysis.\n\nFor statistical analysis, categorical variables were presented as percentages, while continuous variables were presented as mean and standard deviation. Pearson\u2019s correlation was used to evaluate the strength of associations between variables.\n\nThe dataset was split into a training set and a testing set using an 80:20 random split. The training dataset was used to construct the predictive models, while the testing dataset was used to estimate the performance of intracranial pressure (ICP) prediction. Various traditional regression models, including linear regression, polynomial regression, log transformation, and cubic spline regression, were performed for ICP prediction. Additionally, machine learning regression algorithms such as k-nearest neighbors, decision tree, random forest, extreme gradient boosting (XGBoost), and artificial neural network were employed.\n\nFor the random forest algorithm, the setting included 500 trees in the forest and a terminal node size of 5. The artificial neural network architecture consisted of 2 hidden layers with 3 and 2 neurons, respectively, and a single output. 10-fold cross-validation was performed for training, and the best tuning parameters for each algorithm were optimized by minimizing the root mean square error (RMSE).",
  "optimization/parameters": "In our study, we utilized several parameters to predict intracranial pressure (ICP). Initially, we measured the optic nerve sheath diameter (ONSD) of both eyes, which was found to have a moderately positive correlation with ICP. Additionally, we calculated various ventricular indexes, including the Evans index, third ventricle index, cella media index, and ventricular score. These indexes were derived from specific measurements taken at the level of the foramen of Monro and the cella media.\n\nTo enhance the predictive model, we also incorporated other features such as mass diameters and midline shift. The selection of these parameters was based on their known associations with ICP and their potential to improve the model's accuracy. The inclusion of these parameters was validated through statistical analysis and machine learning algorithms, which demonstrated improved predictive performance when these additional features were considered.\n\nThe final model utilized a combination of ONSD, ventricular indexes, and other relevant parameters to achieve the best predictive performance. This comprehensive approach allowed us to develop a robust model for ICP prediction in hydrocephalus patients.",
  "optimization/features": "In the optimization process of our study, we utilized a total of 11 features as input for our models. These features included the optic nerve sheath diameter (ONSD), various ventricular indexes such as the Evans index, third ventricle index, cella media index, and ventricular score, as well as other parameters like mass diameters and midline shift.\n\nFeature selection was not explicitly performed as a separate step. Instead, we adopted a strategy of incremental feature inclusion to evaluate their impact on model performance. Initially, we used ONSD alone. In the second strategy, we included ventricular indexes along with ONSD. Finally, in the third strategy, we incorporated additional features such as mass diameters and midline shift.\n\nThe feature selection process, if any, was inherently part of the model development strategy. We ensured that the selection and evaluation of features were done using the training set only, adhering to best practices to prevent data leakage and maintain the integrity of the testing phase. This approach allowed us to assess the contribution of each feature set to the predictive performance of our models.",
  "optimization/fitting": "In our study, we employed several machine learning regression models to predict intracranial pressure (ICP) in hydrocephalus patients. The dataset consisted of various imaging parameters, including optic nerve sheath diameter (ONSD) and ventricular indexes, among others. The number of features (parameters) was relatively small compared to the number of training points, which helped mitigate the risk of overfitting.\n\nTo ensure robust model performance and avoid overfitting, we utilized 10-fold cross-validation during the training process. This technique involves dividing the training dataset into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. By doing so, we ensured that the model generalized well to unseen data.\n\nAdditionally, we optimized the tuning parameters for each algorithm to minimize the root mean square error (RMSE). This approach helped in selecting the best-performing models and further reduced the risk of overfitting.\n\nTo address underfitting, we employed ensemble learning algorithms such as random forest (RF) and extreme gradient boosting (XGBoost). These algorithms are known for their ability to capture complex relationships in the data, thereby reducing the likelihood of underfitting. Furthermore, we compared the performance of various traditional regression models (linear, polynomial, log transformation, and cubic spline regression) with machine learning algorithms. The superior performance of ensemble learning algorithms indicated that our models were not underfitting the data.\n\nIn summary, by using cross-validation, optimizing tuning parameters, and employing ensemble learning algorithms, we effectively managed to rule out both overfitting and underfitting in our predictive models for ICP.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our predictive models. One of the key methods used was cross-validation, specifically 10-fold cross-validation. This technique involves dividing the dataset into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. Cross-validation helps to ensure that the model generalizes well to unseen data by providing a more reliable estimate of its performance.\n\nAdditionally, we optimized the tuning parameters of our models to minimize the root mean square error (RMSE). This process involved fine-tuning hyperparameters such as the number of trees in the random forest and the architecture of the artificial neural network. By carefully selecting these parameters, we aimed to balance model complexity and performance, thereby reducing the risk of overfitting.\n\nFor the random forest algorithm, we set the number of trees to 500 and the terminal node size to 5. This configuration helps in creating a diverse set of decision trees, which collectively reduce the variance and improve the model's generalization ability. For the artificial neural network, we used an architecture with 2 hidden layers containing 3 and 2 neurons, respectively. This design was chosen to capture the underlying patterns in the data without becoming too complex, thus mitigating overfitting.\n\nFurthermore, we compared the performance of various traditional regression models, including linear regression, polynomial regression, log transformation, and cubic spline regression. By evaluating these models alongside machine learning algorithms like k-nearest neighbors, decision tree, random forest, extreme gradient boosting (XGBoost), and artificial neural network, we ensured that our final models were selected based on their ability to generalize well to new data. The use of ensemble learning methods, such as random forest and XGBoost, also contributed to reducing overfitting by combining the predictions of multiple models, thereby enhancing the overall robustness and accuracy of our predictions.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules for the models used in this study are detailed within the publication. Specifically, for the random forest (RF) model, the configuration included 500 trees in the forest and a terminal node size of 5. The artificial neural network (ANN) architecture consisted of 2 hidden layers with 3 and 2 neurons, respectively, leading to a single output.\n\nThe optimization process involved 10-fold cross-validation to train the models, with the goal of minimizing the root mean square error (RMSE). The best tuning parameters for each algorithm were selected based on this criterion.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the publication. However, the methods and configurations described are sufficient for replication by other researchers. The publication does not specify the license under which these configurations are made available, but they are presented in a manner that allows for academic use and replication.\n\nFor those interested in accessing the predictive models, a web application has been developed and is accessible at https://neurosxpus.shinyapps.io/ICP_HCP/. This application enables users to input relevant parameters and obtain predictions for intracranial pressure (ICP), demonstrating the practical implementation of the models described in the study.",
  "model/interpretability": "The models employed in our study span a range of interpretability levels, from transparent to more complex, black-box approaches. Traditional regression models, such as linear regression, polynomial regression, log transformation, and cubic spline regression, are generally considered transparent. These models provide clear, interpretable relationships between input features and the predicted intracranial pressure (ICP). For instance, linear regression offers a straightforward equation where each coefficient represents the impact of a specific feature on the outcome.\n\nIn contrast, machine learning models like k-nearest neighbors (KNN), decision trees (DT), random forests (RF), extreme gradient boosting (XGBoost), and artificial neural networks (ANN) are often seen as black-box models. These models, particularly ensemble methods like RF and XGBoost, can capture intricate patterns in the data but at the cost of interpretability. However, decision trees within the RF and XGBoost frameworks can be visualized to some extent, showing how decisions are made at each node. This partial transparency helps in understanding the importance of different features in predicting ICP.\n\nThe XGBoost algorithm, for example, provides feature importance scores, indicating which variables contribute most to the predictions. This can be particularly useful for clinicians who want to understand the underlying factors influencing ICP predictions. Similarly, the RF algorithm offers insights into feature importance through the mean decrease in impurity, helping to identify key predictors.\n\nWhile the ANN model is more of a black-box due to its complex architecture involving multiple hidden layers and neurons, it still provides valuable predictions. The trade-off between interpretability and predictive performance is a crucial consideration in model selection. For practical applications, especially in clinical settings, a balance between these two aspects is essential. The web application developed as part of this study aims to provide user-friendly access to these models, ensuring that clinicians can utilize the predictions without needing to delve into the technical details of the models.",
  "model/output": "The model developed in this study is a regression model. It is designed to predict intracranial pressure (ICP) in patients with hydrocephalus. Various traditional regression models, including linear regression, polynomial regression, log transformation, and cubic spline regression, were employed for ICP prediction. Additionally, machine learning (ML) regression algorithms such as k-nearest neighbors, decision tree, random forest (RF), extreme gradient boosting (XGBoost), and artificial neural network were utilized to enhance the predictive performance.\n\nThe predictive performances of these models were evaluated using metrics such as mean absolute error (MAE), root mean square error (RMSE), and the coefficient of determination (R\u00b2). The cubic spline regression model showed the lowest MAE and RMSE in the initial strategy. However, when ventricular indexes were included in the second strategy, the R\u00b2 values significantly increased, particularly for the RF and XGBoost algorithms, indicating improved predictive accuracy. The XGBoost algorithm demonstrated the lowest errors and highest R\u00b2 values among the models tested.\n\nThe random forest algorithm was configured with 500 trees and a terminal node size of 5, while the artificial neural network architecture included two hidden layers with 3 and 2 neurons, respectively, and a single output. The models were trained using an 80:20 split of the dataset, with the training dataset used for model construction and the testing dataset for performance evaluation. 10-fold cross-validation was performed to optimize the tuning parameters, minimizing the RMSE for each algorithm.\n\nIn summary, the regression models, particularly the XGBoost and RF algorithms, showed robust predictive performance for ICP, making them valuable tools for non-invasive ICP prediction in clinical settings.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not applicable",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive approach to assess the predictive performance of various models for intracranial pressure (ICP) prediction in hydrocephalus. The dataset was randomly split into an 80:20 ratio, with 80% used for training the predictive models and the remaining 20% reserved for testing their performance. This split ensured that the models were trained on a substantial amount of data while still having a robust testing set to evaluate their generalization capabilities.\n\nSeveral traditional regression models were initially tested, including linear regression, polynomial regression, log transformation, and cubic spline regression. Additionally, machine learning (ML) regression algorithms such as k-nearest neighbors, decision tree, random forest (RF), extreme gradient boosting (XGBoost), and artificial neural network were utilized. To optimize the performance of these models, 10-fold cross-validation was performed during the training phase. This technique helped in minimizing the root mean square error (RMSE) and selecting the best tuning parameters for each algorithm.\n\nThe predictive performance of the models was evaluated using several metrics, including mean absolute error (MAE), RMSE, and the coefficient of determination (R\u00b2). These metrics provided a comprehensive view of the models' accuracy and reliability. The models were compared across three different strategies: using only the optic nerve sheath diameter (ONSD), using ONSD with ventricular indexes, and using ONSD, ventricular indexes, and other features such as mass diameters and midline shift. The results indicated that the inclusion of ventricular indexes and other features significantly improved the predictive performance, particularly for the RF and XGBoost algorithms.\n\nIn summary, the evaluation method involved a rigorous process of data splitting, model training with cross-validation, and performance assessment using multiple metrics. This approach ensured that the models were thoroughly evaluated and optimized for accurate ICP prediction in hydrocephalus.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the predictive models for intracranial pressure (ICP) in hydrocephalus patients. The primary metrics reported include Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and the coefficient of determination (R\u00b2). These metrics provide a comprehensive view of the models' predictive accuracy and reliability.\n\nMAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It gives an idea of how wrong the predictions are on average. RMSE, on the other hand, measures the square root of the average of squared differences between predicted and observed values. It is more sensitive to larger errors due to the squaring of the differences. Both MAE and RMSE are crucial for understanding the models' performance, as they provide insights into the average error and the variability of the errors, respectively.\n\nThe R\u00b2 value indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, with higher values indicating better model performance. In our study, we observed that the inclusion of ventricular indexes and other features significantly improved the R\u00b2 values, particularly in the ensemble learning algorithms like Random Forest (RF) and Extreme Gradient Boosting (XGBoost).\n\nThe set of metrics used in our study is representative of the literature on predictive modeling. MAE, RMSE, and R\u00b2 are commonly reported metrics in machine learning and statistical modeling studies. They provide a clear and concise way to compare the performance of different models and to assess their predictive accuracy. Additionally, we used the area under the receiver operating characteristic curve (AUC) to evaluate the models' ability to categorize ICP, which is also a standard metric in the literature.\n\nIn summary, the performance metrics reported in our study are comprehensive and representative of the literature. They provide valuable insights into the models' predictive accuracy and reliability, and they enable meaningful comparisons with other studies in the field.",
  "evaluation/comparison": "In our study, we compared the predictive performances of various models for intracranial pressure (ICP) prediction using different strategies and algorithms. We evaluated traditional regression models such as linear regression, polynomial regression, log transformation, and cubic spline regression. Additionally, we employed machine learning (ML) algorithms, including k-nearest neighbors (KNN), decision tree (DT), random forest (RF), extreme gradient boosting (XGBoost), and artificial neural network (ANN).\n\nFor the comparison, we used three different strategies:\n\n1. **First Strategy (ONSD)**: We used the optic nerve sheath diameter (ONSD) as the sole predictor. Among the traditional regression models, cubic spline regression showed the lowest mean absolute error (MAE) and root mean square error (RMSE). However, all regression models had relatively low R\u00b2 values, indicating limited explanatory power.\n\n2. **Second Strategy (ONSD with Ventricular Indexes)**: We included ventricular indexes along with ONSD. This strategy significantly improved the R\u00b2 values, particularly for the RF and XGBoost algorithms, which showed dramatic increases to 0.34 and 0.50, respectively. XGBoost also had the lowest errors among the models in this strategy.\n\n3. **Third Strategy (ONSD, Ventricular Indexes, and Other Features)**: We added other parameters such as mass diameters and midline shift to the predictors. This strategy slightly increased the predictive performances, with RF and XGBoost algorithms continuing to exhibit low errors and high R\u00b2 values.\n\nWe also compared the predicted ICP values calculated by RF and XGBoost algorithms to those of linear regression. The ICP predicted by XGBoost was closer to the regression line than those of linear and RF regression, indicating better predictive accuracy.\n\nIn summary, while traditional regression models provided a baseline for comparison, the ML algorithms, particularly XGBoost and RF, demonstrated superior predictive performance. This comparison highlights the effectiveness of ensemble learning methods in improving ICP prediction accuracy.",
  "evaluation/confidence": "The evaluation of our models focused on several key performance metrics, including mean absolute error (MAE), root mean square error (RMSE), and the coefficient of determination (R\u00b2). These metrics were chosen to provide a comprehensive assessment of the predictive accuracy and reliability of our models.\n\nRegarding confidence intervals, they were not explicitly reported for the performance metrics in our study. However, the statistical significance of the results was thoroughly evaluated. For instance, the correlation between optic nerve sheath diameter (ONSD) and intracranial pressure (ICP) was found to be statistically significant with a Pearson correlation coefficient of 0.530 and a p-value of less than 0.001. This indicates a moderately strong and significant positive correlation.\n\nIn terms of model performance, the addition of ventricular indexes and other features significantly improved the predictive power of certain models, particularly the random forest (RF) and extreme gradient boosting (XGBoost) algorithms. The R\u00b2 values for these models increased dramatically, suggesting that these features contribute meaningfully to the prediction of ICP. For example, the R\u00b2 value for the XGBoost algorithm reached 0.50 when ventricular indexes were included, indicating a substantial improvement in explanatory power.\n\nThe statistical analysis involved a correlation matrix and scatterplots to visualize the relationships between various parameters and ICP. This approach helped to identify significant correlations and to validate the sample size required for hypothesis testing. The use of 10-fold cross-validation further ensured that the models were robust and generalizable.\n\nOverall, while confidence intervals for the performance metrics were not provided, the statistical significance of the correlations and the improvements in model performance metrics suggest that the methods employed are reliable and superior to simpler baselines. The use of ensemble learning algorithms like XGBoost and RF demonstrated their effectiveness in handling complex datasets and providing accurate predictions.",
  "evaluation/availability": "Not enough information is available."
}