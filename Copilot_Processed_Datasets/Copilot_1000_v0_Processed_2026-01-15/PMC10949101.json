{
  "publication/title": "The Evaluation of Ordinal Regression Model's Performance Through the Implementation of Multilayer Feed-Forward Neural Network: A Case Study of Hypertension",
  "publication/authors": "The authors who contributed to this article are:\n\nHazik B. Shahzad, Mohamad N. Adnan, Wan Muhamad Amir W. Ahmad, Faiza Awais, Nor Azlida Aleng, Nor F. Noor, Mohamad Shafiq B. Mohd Ibrahim, and Noor Maizura M. Noor.\n\nAll authors contributed to the concept and design, acquisition, analysis, or interpretation of data, drafting of the manuscript, and critical review of the manuscript for important intellectual content.\n\nWan Muhamad Amir W. Ahmad was responsible for supervision.",
  "publication/journal": "Cureus",
  "publication/year": "2024",
  "publication/pmid": "38505445",
  "publication/pmcid": "PMC10949101",
  "publication/doi": "10.7759/cureus.54387",
  "publication/tags": "- Public Health\n- Epidemiology\n- Hypertension\n- Machine Learning\n- Neural Networks\n- Logistic Regression\n- Bootstrapping\n- Predictive Modeling\n- Cardiovascular Diseases\n- Risk Factors",
  "dataset/provenance": "The dataset utilized in this study was sourced from Hospital Universiti Sains Malaysia. This dataset includes hypertension data categorized into three ordinal groups: normal blood pressure, borderline high blood pressure, and high blood pressure. The data encompasses various factors such as marital status, smoking status, systolic blood pressure readings, fasting blood sugar levels, and high-density lipoprotein levels. The dataset was divided into two groups: 70% for training and 30% for testing, to develop and validate our computational statistical modeling methodology.\n\nThe specific number of data points is not explicitly mentioned. However, the dataset is comprehensive enough to support the development and validation of a multilayer feed-forward neural network combined with ordinal regression. This approach aims to provide insights into hypertension management by evaluating the effectiveness of lifestyle modifications.\n\nThe data used in this study has not been previously published or used by the community in the same context. It is unique to this research and has been specifically curated to address the objectives of our study. The confidentiality and ethical considerations of the patient information were ensured, aligning with the approval obtained from the Universiti Sains Malaysia Research Ethics and Human Research Committee.",
  "dataset/splits": "The dataset was divided into two primary splits: a training set and a testing set. The training set comprised 70% of the total data, while the testing set contained the remaining 30%. This split was chosen to ensure that the model could be effectively trained on a substantial portion of the data while also being rigorously tested on a separate, unseen dataset. The training set was used to develop the multilayer feed-forward neural network (MLFFNN) model, while the testing set was utilized to validate the model's performance and accuracy. This approach helps in demonstrating the reliability and generalizability of the predictions made by the model.",
  "dataset/redundancy": "The datasets used in this study were split into training and testing sets using a 70:30 ratio. This means that 70% of the data was allocated for training the model, while the remaining 30% was reserved for testing its performance. The training and testing sets were designed to be independent to ensure that the model's evaluation was unbiased and that it could generalize well to unseen data.\n\nTo enforce the independence of the training and testing sets, a random split was employed. This process involved randomly dividing the data into two distinct groups, ensuring that there was no overlap between the samples used for training and those used for testing. This approach helps to prevent data leakage and ensures that the model's performance metrics are reliable.\n\nRegarding the distribution of the datasets, it is important to note that the data was obtained from a specific source, ensuring that it was representative of the population under study. The hypertension data included three ordinal categories: normal blood pressure, borderline high blood pressure, and high blood pressure. This categorization is preferred as it mirrors clinical practice and enables clearer comparisons and the identification of trends.\n\nThe distribution of the datasets in this study is comparable to previously published machine learning datasets in the sense that it involves a supervised learning approach with a clear distinction between training and testing phases. However, the specific characteristics of the data, such as the variables selected and the ordinal nature of the dependent variable, are tailored to the objectives of this particular study. The use of a bootstrap method further enhances the robustness of the model by generating multiple subsamples with replacements, ensuring comprehensive and reliable results.",
  "dataset/availability": "The data used in this study is not publicly available. However, the data and the complete R syntax are available upon request from the corresponding author. This approach ensures that the data remains confidential and is used responsibly. The confidentiality of the patient's information and medical status was ensured throughout the study. The data was obtained from Hospital Universiti Sains Malaysia, and ethical approval was obtained from the Universiti Sains Malaysia Research Ethics and Human Research Committee, ensuring the protection of patient privacy and medical information.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a multilayer feed-forward neural network (MLFFNN). This type of neural network is well-established in the field of machine learning and is known for its ability to model complex relationships in data.\n\nThe specific implementation of the MLFFNN in our research is not entirely new, but it is novel in its application to hypertension risk factor analysis. We combined the MLFFNN with ordered logistic regression, creating a hybrid approach that leverages the strengths of both methods. This hybrid model is designed to identify clinically significant variables that minimize the predicted mean square error (PMSE), making it particularly effective for our study's objectives.\n\nThe reason this hybrid model was not published in a machine-learning journal is that our primary focus is on its application in the medical field, specifically in predicting hypertension risk factors. The innovation lies in the integration of the MLFFNN with ordered logistic regression and its application to a specific medical problem, rather than the development of a entirely new machine-learning algorithm. Our study aims to provide healthcare professionals and policymakers with valuable insights into hypertension management, contributing to more effective strategies for prevention and control. The model's performance, with a mean absolute deviance (MAD) value of 0.2614893, demonstrates its effectiveness in this context.",
  "optimization/meta": "The model employed in this study is a hybrid approach that integrates multiple machine-learning techniques, making it a type of meta-predictor. Specifically, it combines bootstrap methods, multilayer feed-forward neural networks (MLFFNN), and ordered logistic regression.\n\nThe MLFFNN is used to identify the optimal model for ordered logistic regression by selecting clinically significant variables that minimize the predicted mean square error. This neural network consists of an input layer, two hidden layers, and an output layer. The input variables include marital status, smoking status, systolic reading, fasting blood sugar, and high-density lipoprotein, all of which are clinically significant factors affecting hypertension.\n\nThe bootstrap method is utilized to validate the selected factors in the integrated ordered logistic regression. This involves creating a \"pseudo-population\" by generating multiple subsamples with replacements, ensuring that the random selection process can result in samples that differ from the original sample. Statistics are computed for each sample drawn with replacement, providing a robust validation of the model.\n\nThe ordered logistic regression is employed to model the categorical dependent variable, hypertension status, which has more than two categories. This technique is particularly useful when the response variable exhibits a natural rank or order. The dependent variable, hypertension reading, is transformed into a three-scaled ordinal variable for this analysis.\n\nThe training and testing datasets are clearly separated, with a 70:30 train-to-test split. This ensures that the training data is used for developing the multilayer neural networks, while the testing data is used for validation purposes. The independence of the training data is maintained throughout the process, ensuring the reliability and accuracy of the predictions.\n\nIn summary, the model is a meta-predictor that leverages the strengths of bootstrap methods, MLFFNN, and ordered logistic regression to provide a comprehensive and accurate analysis of hypertension risk factors. The integration of these techniques ensures that the model is both robust and reliable, with a clear separation of training and testing data.",
  "optimization/encoding": "In our study, the data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithm. The dataset included various factors such as marital status, smoking status, systolic blood pressure reading, fasting blood sugar, and high-density lipoprotein. These variables were carefully selected based on clinical significance and expert opinion.\n\nMarital status was encoded as a binary categorical variable, with '0' representing single and '1' representing married. Smoking status was encoded as a categorical variable with three levels: '1' for never, '2' for former, and '3' for current smokers. Systolic blood pressure reading, fasting blood sugar, and high-density lipoprotein were encoded as numeric variables, as they represent continuous measurements.\n\nThe dependent variable, hypertension status, was categorized into three ordinal levels: '0' for normal blood pressure, '1' for borderline high blood pressure, and '2' for high blood pressure. This ordinal encoding was essential for applying ordinal logistic regression, which is suitable for modeling a dependent variable with a natural rank or order.\n\nTo prepare the data for the machine-learning algorithm, we employed a 70:30 train-to-test split. This means that 70% of the data was used for training the multilayer feed-forward neural network (MLFFNN), while the remaining 30% was used for testing and validating the model. This split ensures that the model is trained on a sufficient amount of data while also having a separate dataset to evaluate its performance.\n\nAdditionally, we utilized the bootstrap method to validate the selected variables. This involved creating multiple subsamples with replacement from the original dataset and fitting the ordinal logistic regression model to each subsample. This process helps to enhance the robustness of the model and ensures that the selected variables are significant.\n\nIn summary, the data encoding involved converting categorical variables into numerical formats suitable for machine-learning algorithms and categorizing the dependent variable into ordinal levels. The preprocessing steps included splitting the data into training and testing sets and using the bootstrap method for variable validation. These steps were essential for developing an accurate and reliable model for predicting hypertension status.",
  "optimization/parameters": "In the optimization process of our model, we utilized five input parameters. These parameters were selected based on their clinical significance and their impact on hypertension. The variables considered were marital status, smoking status, systolic blood pressure, fasting blood sugar levels, and high-density lipoprotein levels. The selection of these parameters was guided by their known associations with hypertension and their ability to minimize the predicted mean square error (PMSE) in our model. This approach ensured that the model was both clinically relevant and statistically robust.",
  "optimization/features": "In our study, we utilized five input features for our model. These features were selected based on their clinical significance and their impact on hypertension. The features included marital status, smoking status, systolic blood pressure reading, fasting blood sugar, and high-density lipoprotein levels.\n\nFeature selection was indeed performed to identify the most relevant variables. This process involved consulting clinical experts to ensure that the selected features were meaningful and impactful in the context of hypertension. The bootstrap method was employed to validate these selected factors, ensuring robustness in our variable selection process.\n\nIt is important to note that the feature selection was conducted using the training dataset only. This approach helps to prevent data leakage and ensures that the model's performance on the test dataset is a true reflection of its generalizability. By using the training data exclusively for feature selection, we maintain the integrity of the evaluation process and avoid overfitting.",
  "optimization/fitting": "The fitting method employed in this study utilized a multilayer feed-forward neural network (MLFFNN) combined with ordered logistic regression. This hybrid approach was designed to effectively handle the complexity of the data while ensuring robust performance.\n\nThe MLFFNN architecture consisted of five input variables, two hidden layers, and three output nodes. This structure was chosen to balance the model's capacity to learn from the data without becoming overly complex. The input variables included marital status, smoking status, systolic reading, fasting blood sugar, and high-density lipoprotein, all of which were selected based on their clinical significance and impact on hypertension.\n\nTo address the potential issue of overfitting, a 70:30 train-to-test split was employed. This split ensured that 70% of the data was used for training the model, while the remaining 30% was reserved for testing. Additionally, the bootstrap method was utilized to validate the selected factors, providing a robust estimation of the model's performance and reducing the risk of overfitting.\n\nThe mean absolute deviance (MAD) value of 0.2614893 indicated a close match between the predicted and actual data, suggesting effective model fitting. A lower MAD value signifies a more accurate distribution of the data, which is crucial for minimizing prediction errors.\n\nTo rule out underfitting, the model's performance was evaluated using sensitivity, specificity, and positive predictive value. The proposed MLFFNN-based model achieved a validation accuracy of 99.82%, demonstrating its ability to generalize well to unseen data. The accuracy of the predictions was 88.24%, further confirming the model's effectiveness in capturing the underlying patterns in the data.\n\nIn summary, the fitting method involved a careful balance between model complexity and performance. The use of a hybrid approach, along with rigorous validation techniques, ensured that the model was neither overfitted nor underfitted, providing reliable and accurate predictions for hypertension status.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was bootstrapping. This technique involves repeatedly sampling from the dataset with replacement to create multiple subsets, or \"pseudo-populations.\" By fitting our model to these subsets and averaging the results, we were able to reduce the variance and improve the stability of our predictions. This approach helped to mitigate the risk of overfitting by ensuring that our model generalized well to unseen data.\n\nAdditionally, we utilized a multilayer feed-forward neural network (MLFFNN) with a specific architecture designed to balance complexity and generalization. The network included two hidden layers, which allowed it to capture intricate patterns in the data without becoming overly complex. This architecture was chosen based on extensive experimentation and validation to ensure optimal performance.\n\nFurthermore, we employed a 70:30 train-to-test split, where 70% of the data was used for training the model and 30% was reserved for testing. This split helped to evaluate the model's performance on unseen data, providing a more accurate assessment of its generalization capabilities. The use of a separate test set ensured that our model's performance metrics, such as the mean absolute deviation (MAD) and accuracy, were reliable indicators of its true predictive power.\n\nBy combining these techniques\u2014bootstrapping, a well-designed neural network architecture, and a rigorous train-test split\u2014we were able to effectively prevent overfitting and develop a model that demonstrated strong predictive performance and generalization to new data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available and can be accessed through the R syntax that was developed for this research. This syntax serves as the implementation vehicle for our innovative methodology, ensuring clarity and accessibility in its application. The R syntax is designed to be straightforward, allowing other researchers to replicate and build upon our work.\n\nThe specific details of the model architecture, including the number of input variables, hidden layers, and output nodes, are outlined in the results section. For instance, the best-performing model featured five input variables, two hidden layers, and three output nodes. These configurations were chosen to minimize the predicted mean square error (PMSE) and optimize the model's performance.\n\nRegarding the availability of model files, while the exact files are not directly provided in this publication, the R syntax and the detailed descriptions of the model architecture and parameters allow for the reconstruction of the model. This ensures that other researchers can implement and validate our findings using the same configurations.\n\nThe study is published under the Creative Commons Attribution License CC-BY 4.0, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. This license ensures that the methodology and findings are accessible to the broader scientific community, fostering further research and development in the field of hypertension risk assessment.",
  "model/interpretability": "The model employed in this study is a hybrid approach that combines ordered logistic regression with a multilayer feed-forward neural network (MLFFNN). This combination allows for a certain level of interpretability, although it is not entirely transparent.\n\nThe ordered logistic regression component of the model is inherently more interpretable. It provides coefficients for each predictor variable, indicating the direction and magnitude of their effect on the dependent variable, hypertension status. For instance, marital status, smoking status, systolic reading, fasting blood sugar, and high-density lipoprotein were identified as significant variables. The coefficients for these variables can be interpreted in a straightforward manner: a positive coefficient indicates a positive relationship with hypertension, while a negative coefficient indicates a negative relationship.\n\nHowever, the MLFFNN component introduces some level of complexity and opacity. Neural networks are often considered black-box models because the relationships between inputs and outputs are determined through complex, non-linear transformations that are not easily interpretable. The MLFFNN in this study consists of multiple layers of nodes, each applying a non-linear activation function to the inputs. This makes it challenging to trace the exact path by which a given input influences the output.\n\nDespite this, the use of ordered logistic regression as the activation function in the MLFFNN helps to maintain some interpretability. The ordered logistic model provides a clear structure for understanding how the input variables relate to the ordered categories of the dependent variable. Additionally, the model's architecture, which includes specific input variables and hidden layers, can be visualized and understood to some extent.\n\nIn summary, while the MLFFNN component of the model adds complexity and reduces transparency, the ordered logistic regression component provides a level of interpretability. The coefficients from the ordered logistic regression can be used to understand the relationships between the predictor variables and hypertension status, even if the exact workings of the neural network are not fully transparent.",
  "model/output": "The model developed in this study is a classification model, specifically designed for ordinal regression. It utilizes a multilayer feed-forward neural network (MLFFNN) with an ordered logistic activation function to predict hypertension status, which is categorized into three ordinal levels: normal, borderline, and high. The model's output provides probabilities for each of these categories, allowing for a nuanced understanding of the predicted hypertension status.\n\nThe model's performance was evaluated using a confusion matrix, which compares the actual hypertension statuses with the predicted ones. This evaluation revealed high sensitivity and specificity for the borderline and high categories, indicating the model's effectiveness in correctly identifying these cases. The overall accuracy of the model's predictions was 88.24%, with a validation accuracy of 99.82%, demonstrating its reliability and precision.\n\nThe model's output includes several key variables that significantly influence hypertension status. These variables are marital status, smoking status, systolic blood pressure, fasting blood sugar levels, and high-density lipoprotein levels. Each of these variables has a specific coefficient and p-value, indicating their significance and direction of effect on the predicted hypertension status.\n\nThe model's architecture consists of five input variables, two hidden layers, and three output nodes, corresponding to the three hypertension categories. This structure allows the model to capture complex relationships between the input variables and the predicted hypertension status. The mean absolute deviance (MAD) value of 0.2614893 suggests a good fit between the predicted and actual data, with a lower MAD indicating a more accurate model.\n\nIn summary, the model's output provides a comprehensive and accurate prediction of hypertension status based on the selected input variables. The high accuracy and reliability of the model make it a valuable tool for identifying individuals at risk of hypertension and for developing targeted interventions to manage this condition.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the methodology presented in this study is not publicly released. The implementation was conducted using R, specifically version 4.3.1, and utilized various packages for ordered logistic regression and neural network modeling. The R syntax developed for this study ensures clarity and accessibility in its application, but the specific code and datasets used are not available for public access.\n\nThe study employed a hybrid approach that integrates bootstrapping, multilayer feed-forward neural networks, and ordered logistic regression. This methodology was meticulously developed and implemented within the R environment. However, the detailed R scripts and any associated data are not provided as part of this publication.\n\nFor those interested in replicating or building upon this work, the general approach and techniques used are described in detail within the study. This includes the use of ordered logistic regression for modeling categorical dependent variables, the application of bootstrap methods for enhancing robustness, and the implementation of multilayer feed-forward neural networks for predictive modeling. The study also discusses the importance of variable selection, guided by clinical expert opinion, and the division of data into training and testing sets.\n\nWhile the specific source code and executable files are not released, the methodological framework and statistical techniques are thoroughly documented. This documentation should enable researchers to understand the underlying principles and potentially adapt the methods to their own datasets and research questions. For further details on the implementation and results, readers are encouraged to refer to the full text of the study.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive approach to assess the performance and accuracy of the proposed model. The dataset was randomly divided into two groups: 70% for training and 30% for testing. This split allowed for a robust evaluation of the model's predictive capabilities.\n\nThe model's performance was evaluated using several key metrics. The mean absolute deviance (MAD) was calculated to measure the accuracy of the predictions. A lower MAD value indicates a closer match between the predicted and actual data, signifying a more effective analysis. The model achieved a MAD value of 0.2614893, which demonstrates a high degree of accuracy in the predictions.\n\nAdditionally, the validation accuracy of the model was assessed. The proposed MLFFNN-based model achieved a validation accuracy of 99.82%, indicating its strong performance in predicting hypertension status. The accuracy of the predictions was further evaluated using a confusion matrix, which tabulated the actual and predicted values. This matrix revealed an overall prediction accuracy of 88.24%, with a 95% confidence interval ranging from 0.7255 to 0.967.\n\nThe evaluation also included sensitivity, specificity, and positive predictive value analyses. These metrics are crucial for assessing the effectiveness of the model. High specificity indicates accurate analysis, while high sensitivity signifies the model's ability to correctly identify positive cases. The model demonstrated good performance in terms of sensitivity, specificity, and positive predictive value, further validating its reliability.\n\nIn summary, the evaluation method involved a rigorous assessment using training and testing datasets, key performance metrics, and statistical analyses. The results affirm the model's high accuracy and reliability in predicting hypertension status.",
  "evaluation/measure": "In the evaluation of our model, several key performance metrics were reported to assess its effectiveness. The primary metrics included accuracy, sensitivity, specificity, positive predictive value, and negative predictive value. These metrics were calculated for each class in the confusion matrix, which compared the actual and predicted values.\n\nThe overall accuracy of the model was reported as 88.24%, with a 95% confidence interval ranging from 0.7255 to 0.967. This indicates a high level of predictive accuracy. Additionally, the validation accuracy of the proposed MLFFNN-based model was noted to be 99.82%, highlighting its robustness in the training phase.\n\nSensitivity and specificity were evaluated for each class to determine the model's ability to correctly identify positive cases and accurately analyze the data. High specificity indicates that the model correctly identifies true negatives, while high sensitivity signifies its ability to correctly identify true positives. The balanced accuracy, which averages sensitivity and specificity, was also reported, providing a comprehensive view of the model's performance across different classes.\n\nThe mean absolute deviation error was reported as 0.2615, which is impressively low and underscores the model's precision in predictions. This metric is crucial as it reflects the average absolute differences between predicted and actual values, indicating the model's fit and reliability.\n\nThese performance metrics are representative of standard practices in the literature, ensuring that our model's evaluation is comprehensive and comparable to other studies in the field. The combination of these metrics provides a thorough assessment of the model's predictive power and reliability, making it a strong contender in hypertension risk assessment.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. Instead, our focus was on developing and evaluating a novel hybrid approach that combines bootstrapping, multilayer feed-forward neural networks (MLFFNN), and ordered logistic regression. This methodology was specifically tailored to analyze hypertension risk factors.\n\nWe did, however, compare our hybrid model's performance against traditional regression modeling techniques. Traditional regression methods often face limitations in terms of complexity, accuracy, and precision, particularly in the estimation process of predictor variables and outcomes. Our hybrid approach addresses these limitations by utilizing a single syntax calculation, which significantly improves the model's performance.\n\nThe evaluation of our model included assessing its predictive power and the smallest error obtained, serving as a robust indicator of its test fit. The statistical analyses presented in this study affirm the superiority of our hybrid model technique, evidenced by an impressively low mean absolute deviation error of 0.2615. This finding underscores the exceptional performance of our proposed method, positioning it as a front-runner in the realm of hypertension risk assessment.\n\nWhile we did not compare our method to simpler baselines in the traditional sense, the comparison with traditional regression modeling highlights the advantages of our hybrid approach. The high accuracy and reliability of our model, as demonstrated through sensitivity, specificity, and positive predictive value analyses, provide strong evidence for its effectiveness in predicting hypertension risk factors.",
  "evaluation/confidence": "The evaluation of our proposed model includes several performance metrics that provide a comprehensive understanding of its effectiveness. The accuracy of the predictions was reported at 88.24%, with a 95% confidence interval ranging from 0.7255 to 0.967. This confidence interval indicates the reliability of our accuracy estimate, suggesting that the true accuracy of the model lies within this range with 95% confidence.\n\nIn terms of statistical significance, our model demonstrated strong performance across various metrics. For instance, the validation accuracy of the proposed MLFFNN-based model was 99.82%, which is notably high and indicates the model's robustness. Additionally, the sensitivity and specificity values for different classes (borderline, high, and normal) were evaluated, showing high values that underscore the model's ability to correctly identify positive cases and accurately analyze the data.\n\nThe p-values associated with the variables in our ordered logistic regression model were also considered. Variables such as marital status, smoking status, fasting blood sugar, and high-density lipoprotein were found to be significant at the 0.25 level, which aligns with our chosen significance threshold. This significance level was selected based on established methodologies in regression analysis, ensuring that the variables deemed significant truly contribute to the model's predictive power.\n\nThe mean absolute deviation error of 0.2615 further supports the model's precision and accuracy, highlighting its superiority over alternative methods. This low error rate is a robust indicator of the model's fit and its ability to make accurate predictions.\n\nOverall, the performance metrics and statistical significance of our model provide strong evidence of its superiority. The confidence intervals and significant p-values reinforce the reliability and validity of our findings, positioning our hybrid approach as a leading method in hypertension risk assessment.",
  "evaluation/availability": "The raw evaluation files are not publicly available. However, the complete R syntax used in the study is accessible upon request from the corresponding author. This approach ensures that interested researchers can replicate the methodology and evaluate the model using their own datasets. The study was conducted with a focus on ethical considerations, including obtaining consent from participants and approval from the Universiti Sains Malaysia Research Ethics and Human Research Committee. This commitment to ethical standards underscores the reliability and integrity of the research findings. For those seeking to validate or build upon the results, reaching out to the corresponding author is the recommended path to obtain the necessary evaluation tools and data."
}