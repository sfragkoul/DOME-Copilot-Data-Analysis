{
  "publication/title": "Automatic COVID-19 Detection Using Exemplar Hybrid Deep Features with X-ray Images",
  "publication/authors": "The authors who contributed to this article are:\n\n- P. D. B.\n- N. F. M. G.\n- K. R.\n- N. R.\n- W. L. N.\n- W. Y. C.\n- T. W.\n- K. H. C.\n- U. R. A.\n- S. D.\n- M. B.\n- O. Y.\n- T. T.\n- M. K.\n\nThe contributions of each author to the paper are as follows:\n\n- P. D. B., N. F. M. G., K. R., N. R., W. L. N., W. Y. C., S. D., T. T., K. H. C., and U. R. A. were involved in conceptualization, methodology, resources, supervision, validation, visualization, and writing\u2014review and editing.\n- P. D. B., N. F. M. G., K. R., N. R., W. L. N., W. Y. C., T. W., and K. H. C. contributed to the resources.\n- P. D. B., N. F. M. G., K. R., N. R., W. L. N., W. Y. C., S. D., T. T., T. W., and K. H. C. were involved in validation.\n- P. D. B., N. F. M. G., K. R., N. R., W. L. N., W. Y. C., M. K., S. D., M. B., O. Y., T. T., T. W., and K. H. C. contributed to visualization.\n- S. D., M. B., O. Y., and T. T. were involved in writing\u2014original draft.\n- P. D. B., N. F. M. G., K. R., N. R., W. L. N., W. Y. C., M. K., S. D., M. B., O. Y., T. T., T. W., K. H. C., and U. R. A. contributed to writing\u2014review and editing.",
  "publication/journal": "International Journal of Environmental Research and Public Health",
  "publication/year": "2021",
  "publication/pmid": "34360343",
  "publication/pmcid": "PMC8345793",
  "publication/doi": "10.3390/ijerph18158052",
  "publication/tags": "- Exemplar COVID-19FclNet9\n- Deep feature generation\n- Transfer learning\n- COVID-19 detection\n- Iterative NCA\n- Machine learning\n- Deep learning\n- X-ray image analysis\n- Support vector machine\n- Feature engineering",
  "dataset/provenance": "In our study, we utilized four distinct X-ray image databases to evaluate the performance of our proposed model, Exemplar COVID-19FclNet9. The first database, DB1, comprises 741 X-ray images, categorized into four classes: normal, bacterial pneumonia, viral pneumonia, and COVID-19. This database is a hybrid, combining normal and pneumonia images from Kermany et al.'s dataset with COVID-19 images from Talo\u2019s database.\n\nThe second database, DB2, is a popular dataset used for comparing results. It was created by Ozturk et al. and includes 1125 X-ray images from 125 subjects, divided into three classes: COVID-19, pneumonia, and control. This database has been widely used in the community for developing and testing COVID-19 detection models.\n\nThe third database, DB3, is a large X-ray image dataset published on Kaggle by Rahman. It contains 8961 images across three classes: no-finding, pneumonia, and COVID-19. This dataset is extensive and provides a robust set of images for training and validating machine learning models.\n\nThe fourth database, DB4, was collected from the University of Malaya Medical Centre. It consists of 277 X-ray images from 214 subjects, categorized into two classes: COVID-19 and healthy. This dataset is smaller but provides a focused set of images for specific analyses.\n\nEach of these databases has been carefully selected to ensure a diverse and comprehensive evaluation of our model's performance. The use of multiple datasets allows us to demonstrate the robustness and generalizability of Exemplar COVID-19FclNet9 across different image sources and conditions.",
  "dataset/splits": "In our study, we utilized multiple datasets, each with distinct splits and distributions. The first dataset (DB1) consisted of 749 X-ray images, divided into four categories: 234 normal, 242 bacterial pneumonia, 148 viral pneumonia, and 125 COVID-19. The second dataset (DB2) contained 1125 X-ray images from 125 subjects, categorized into three classes: 125 COVID-19, 500 pneumonia, and 500 control. The third dataset (DB3) was a large X-ray image dataset with 8961 images, split into three classes: 3616 COVID-19, 1345 pneumonia, and 4000 normal. The fourth dataset (DB4) included 277 X-ray images from 214 subjects, divided into two categories: 127 COVID-19 and 150 healthy patients.\n\nFor our method, we employed a 10-fold cross-validation approach. This involved splitting the data into 10 subsets, where 9 subsets were used for training and 1 subset for validation, repeating this process 10 times with different subsets as the validation set. This method ensures that each data point is used for both training and validation, providing a robust evaluation of our model's performance. The specific splits and distributions for our method varied depending on the dataset used, but the 10-fold cross-validation approach was consistently applied.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data used in this study are not publicly available. This restriction is due to the ethical guidelines set by the Medical Research Ethics Committee. The data were collected from various sources, including the University Malaya Medical Centre and public databases like Kaggle. The ethical committee's regulations prevent the public release of the data to protect patient privacy and comply with institutional policies. The data transcription was acknowledged by the Medical Research Ethics Committee, University Malaya Medical Centre.",
  "optimization/algorithm": "The optimization algorithm employed in our study utilizes a Support Vector Machine (SVM) classifier, which is a well-established machine-learning algorithm class known for its effectiveness in high-dimensional spaces. The SVM classifier was chosen for its ability to handle complex classification tasks and its robustness in dealing with overfitting, especially when combined with techniques like Bayesian optimization.\n\nThe SVM classifier used in our work is not a new algorithm. It has been extensively studied and applied in various fields, including medical imaging and classification tasks. The reason it was not published in a machine-learning journal is that our focus is on applying established methods to a specific problem\u2014COVID-19 detection using X-ray images\u2014rather than developing new machine-learning algorithms. Our contribution lies in the innovative application of SVM in conjunction with deep feature extraction and iterative feature selection techniques to enhance the accuracy and efficiency of COVID-19 detection.\n\nBayesian optimization was employed to fine-tune the hyperparameters of the SVM classifier. This approach allows for the systematic exploration of the hyperparameter space to find the optimal settings that maximize the classifier's performance. The use of Bayesian optimization ensures that the SVM is finely tuned to the specific characteristics of our dataset, leading to improved classification accuracy. The hyperparameters tuned include the multiclass method, box constraint level, kernel type, and standardization, among others. This meticulous tuning process is crucial for achieving the high performance reported in our study.",
  "optimization/meta": "The model described in this publication does not function as a meta-predictor. Instead, it employs a Support Vector Machine (SVM) classifier as its core component for the final classification step. The SVM classifier is fine-tuned using Bayesian optimization to achieve optimal performance. The hyperparameters of the SVM, such as the multiclass method, box constraint level, kernel type, and standardization, are carefully tuned within specified ranges to enhance the model's accuracy.\n\nThe process involves several steps, including the generation of a merged feature vector and the selection of the best features using an iterative Neighborhood Component Analysis (INCA) feature selector. The INCA selector helps in identifying the most appropriate feature vector with an optimal length, which is then used for classification. The final classification is performed using the fine-tuned SVM, which has been optimized through Bayesian optimization.\n\nThe validation technique used for the classifiers is 10-fold cross-validation, ensuring that the model's performance is robust and generalizable. The model's accuracy is evaluated across multiple databases, demonstrating its effectiveness in different scenarios. The use of deep feature generation methods and transfer learning further enhances the model's performance, making it accurate and reliable for COVID-19 detection.",
  "optimization/encoding": "In our study, the data encoding and preprocessing involved several key steps to prepare X-ray images for the machine-learning algorithm. Initially, each X-ray image was divided into nine non-overlapping patches, creating a 3x3 grid. This division allowed for a more detailed feature extraction process.\n\nDeep features were then extracted from both the original X-ray images and the patches using fully connected layers from pre-trained Convolutional Neural Networks (CNNs). Specifically, the fc6, fc7, and fc8 layers of AlexNet, VGG16, and VGG19 were utilized. This process generated feature vectors of varying lengths, with the fc8 layer extracting 1000 features and the fc6 and fc7 layers extracting 4096 features.\n\nFollowing feature extraction, the Neighborhood Component Analysis (NCA) method was applied to select the best 1000 features from each generated feature vector. This step ensured that only the most relevant features were retained for further analysis. The misclassification rates of these selected features were then calculated using a Support Vector Machine (SVM) with a polynomial kernel and 10-fold cross-validation.\n\nThe top three feature vectors, based on their misclassification rates, were selected and merged to form a combined feature vector. This merged vector underwent further refinement using an iterative version of NCA, known as INCA. INCA helped in selecting the most appropriate feature vector with an optimal length, using an SVM classifier as the loss function and iterating over a range of feature vector lengths from 100 to 1000.\n\nThe final selected feature vector was then fed into an SVM classifier, whose hyperparameters were tuned using Bayesian optimization. This optimization process aimed to achieve the best possible performance by minimizing the misclassification rate. The tuned SVM classifier was then used to obtain the final results through 10-fold cross-validation.",
  "optimization/parameters": "In our study, the number of parameters used in the model varies depending on the database and the feature selection process. Initially, deep features are generated from X-ray images and their patches using fully connected layers of pre-trained convolutional neural networks (CNNs). The length of these feature vectors can be either 1000 or 4096, depending on the specific layer used.\n\nAfter generating these feature vectors, we employ the Neighborhood Component Analysis (NCA) to select the top 1000 features from each vector. This step reduces the dimensionality of the feature vectors while retaining the most informative features.\n\nFollowing this, we merge the best three selected feature vectors to create a combined feature vector with a length of 3000. This merged feature vector is then processed using an iterative version of NCA (INCA), which further refines the feature selection. The INCA process involves selecting feature vectors of varying lengths within a specified range (100 to 1000) and calculating their loss values using a Support Vector Machine (SVM) classifier. The feature vector with the minimum error is selected as the optimal feature vector for classification.\n\nThe number of features selected by INCA differs for each database: 340 for DB1, 509 for DB2, 735 for DB3, and 101 for DB4. These selected features are then used as input to the SVM classifier, whose hyperparameters are tuned using Bayesian optimization. The Bayesian optimization process involves 30 iterations, with the fitness function being the misclassification rate. The hyperparameters tuned include the multiclass method, box constraint level, kernel type, and standardization flag.\n\nIn summary, the number of parameters used in the model is dynamically determined through a series of feature selection and optimization steps, ensuring that the most relevant features are retained for accurate classification.",
  "optimization/features": "The Exemplar COVID-19FclNet9 model employs a deep feature extraction process that generates a substantial number of features from X-ray images. Initially, each X-ray image is divided into nine non-overlapping patches, and deep features are extracted from both the original images and these patches using fully connected layers from pre-trained convolutional neural networks (CNNs). Specifically, the fc6, fc7, and fc8 layers of AlexNet, VGG16, and VGG19 are utilized.\n\nThe feature vectors generated from these layers have varying lengths. For the fc8 layer, 1000 features are extracted, while the fc6 and fc7 layers generate 4096 features each. This results in feature vectors of lengths 10,000 and 40,960 for different combinations of these layers.\n\nFeature selection is performed using the Neighborhood Component Analysis (NCA) method. This process involves selecting the top 1000 features from each generated feature vector. The selection is based on the actual output labels and is conducted to ensure that the most discriminative features are retained.\n\nSubsequently, the misclassification rates of the selected features are calculated using a Support Vector Machine (SVM) with a polynomial kernel and 10-fold cross-validation. The three feature vectors with the lowest misclassification rates are then merged to form a combined feature vector.\n\nFurther refinement is achieved through the use of the Iterative NCA (INCA) feature selector. INCA iteratively selects the optimal number of features within a specified range (100 to 1000) to minimize the misclassification rate. This process ensures that the final feature vector is both compact and highly informative.\n\nThe final feature vector, after INCA selection, is fed into an SVM classifier. The hyperparameters of the SVM are tuned using Bayesian optimization to achieve optimal performance. The number of iterations for Bayesian optimization is set to 30, with the fitness function being the misclassification rate.\n\nIn summary, the input features for the SVM classifier are the result of a multi-stage feature extraction and selection process. This process involves generating deep features from X-ray images and patches, selecting the top features using NCA, merging the best feature vectors, and further refining the feature set using INCA. The final feature vector is then used for classification, ensuring high accuracy and robustness.",
  "optimization/fitting": "The fitting method employed in our study involved a Support Vector Machine (SVM) classifier, which is known for its effectiveness in high-dimensional spaces. The number of parameters in our SVM model was indeed larger than the number of training points, particularly due to the extensive feature extraction process involving deep learning techniques.\n\nTo address the risk of overfitting, we utilized Bayesian optimization to fine-tune the hyperparameters of the SVM. This method systematically explored the hyperparameter space to find the optimal settings, thereby reducing the likelihood of overfitting. Additionally, we employed 10-fold cross-validation, a robust technique that ensures the model's performance is evaluated across multiple subsets of the data, further mitigating overfitting.\n\nTo rule out underfitting, we ensured that our model had sufficient complexity to capture the underlying patterns in the data. The deep feature extraction process, involving multiple fully connected layers of pre-trained Convolutional Neural Networks (CNNs), generated a rich set of features. These features were then refined using an iterative Neighborhood Component Analysis (INCA) feature selector, which helped in selecting the most relevant features for classification. This multi-step feature selection and refinement process ensured that the model was neither too simple to capture the data's complexity nor too complex to overfit the training data.\n\nMoreover, the use of different kernels (Cubic, Quadratic, Linear, Gaussian) in the SVM allowed the model to adapt to various data distributions, further enhancing its ability to generalize well to unseen data. The combination of these techniques ensured that our model achieved a balanced fit, avoiding both overfitting and underfitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the key methods used was 10-fold cross-validation. This technique involves dividing the dataset into 10 subsets, training the model on 9 of these subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. This approach helps to ensure that the model generalizes well to unseen data by providing a more comprehensive evaluation of its performance.\n\nAdditionally, we utilized Bayesian optimization to fine-tune the hyperparameters of our Support Vector Machine (SVM) classifier. Bayesian optimization is an efficient method for hyperparameter tuning that helps in finding the optimal set of hyperparameters, thereby improving the model's performance and reducing the risk of overfitting. The hyperparameters tuned included the box constraint level, kernel type, and standardization, among others.\n\nFurthermore, we implemented an iterative Neighborhood Component Analysis (INCA) feature selector. INCA is an iterative and improved version of the Neighborhood Component Analysis that helps in selecting the most appropriate feature vector with an optimal length. By iteratively selecting features based on their contribution to the model's performance, INCA helps in reducing the dimensionality of the feature space and mitigating overfitting.\n\nThese techniques collectively contribute to the robustness and generalizability of our model, ensuring that it performs well on both training and validation datasets.",
  "optimization/config": "The hyperparameter configurations used for the SVM classifier are detailed in the publication. The ranges for these hyperparameters, which include the multiclass method, box constraint level, kernel type, and standardisation, are explicitly provided. These configurations were tuned using Bayesian optimisation, with the main goal of achieving a fine-tuned SVM. The specific values used for different databases are also listed, showing the tuned parameters for each dataset.\n\nThe optimization schedule involved 30 iterations of Bayesian optimisation, with the fitness function being the misclassification rate. This process ensured that the SVM classifier was optimally configured for the best performance.\n\nRegarding model files and optimization parameters, the publication does not explicitly mention the availability of these files or the specific license under which they might be shared. However, the detailed description of the hyperparameter ranges and the optimization process provides a clear framework for replicating the experiments.\n\nNot applicable.",
  "model/interpretability": "The Exemplar COVID-19FclNet9 model is not a black-box model. It is designed to be transparent and interpretable through several key mechanisms.\n\nFirstly, the model employs a cognitive feature extraction process. This involves dividing X-ray images into exemplars or patches, generating deep features from these patches using fully connected layers of pre-trained CNNs, and then merging these features. This process allows for a clear understanding of how the model processes and interprets the input images.\n\nSecondly, the model uses iterative feature selection. This means that the model selects the most relevant features from the generated deep features, which can be examined to understand which parts of the X-ray images are most important for classification. The model specifically selects the top 1000 features using Neighborhood Component Analysis (NCA) and then further refines these features to the best three feature vectors.\n\nAdditionally, the model uses a Support Vector Machine (SVM) classifier, which is known for its interpretability. The parameters of the SVM classifier are tuned to achieve high classification performance, and the final feature vector is fed into this classifier. The use of SVM allows for a clear understanding of the decision boundaries and the importance of different features in the classification process.\n\nFurthermore, the model's performance is validated using four different X-ray image databases, and the results are presented in a detailed manner. This includes accuracy, unweighted average recall, precision, and F1 scores for each database, as well as ROC curves. This transparency in reporting allows for a clear understanding of the model's performance and its robustness across different datasets.\n\nIn summary, the Exemplar COVID-19FclNet9 model is designed to be transparent and interpretable. It achieves this through cognitive feature extraction, iterative feature selection, and the use of an SVM classifier. The model's performance is also validated and reported in a detailed and transparent manner.",
  "model/output": "The model presented in this publication is a classification model. Specifically, it is designed to classify X-ray images into different categories, such as COVID-19, healthy, bacterial pneumonia, viral pneumonia, and other types of pneumonia. The model employs a hybrid approach that combines deep feature extraction with machine learning techniques to achieve high classification performance.\n\nThe Exemplar COVID-19FclNet9 model utilizes three pre-trained deep feature generators to extract features from X-ray images. These features are then merged and selected using Neighborhood Component Analysis (NCA) to choose the most relevant features. The selected features are subsequently classified using a Support Vector Machine (SVM) classifier. The model's performance is evaluated using metrics such as accuracy, precision, recall, and F1 score across four different databases.\n\nThe output of the model includes confusion matrices and performance metrics for each database, demonstrating the model's ability to accurately classify X-ray images. The results indicate that the model achieves high classification performance, with accuracy rates ranging from 89.96% to 99.64% depending on the database used. The model's effectiveness is further validated through ROC curves and accuracy versus the number of features used graphs, which show consistent high performance across various datasets.",
  "model/duration": "The model was executed on a simple configured PC with an i9-9900 processor, 48 GB of memory, and a 256 GB solid-state disk. The operating system used was Windows 10.1 Professional, and MATLAB (2020b) served as the programming environment. The execution time for the model was not explicitly detailed, but the system specifications suggest that it was capable of handling the computational demands efficiently. The use of a high-performance processor and ample memory would have facilitated relatively quick processing times for the tasks involved, such as feature extraction, merging, and classification using the SVM classifier. The model's design, which includes feature engineering and transfer learning, likely contributed to its efficiency in achieving high classification performance across the four X-ray image databases used.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed Exemplar COVID-19FclNet9 model was conducted using four distinct X-ray image databases. This approach ensured a comprehensive assessment of the model's performance across various datasets. The evaluation metrics employed included accuracy, precision, recall, and F1 score, providing a holistic view of the model's effectiveness.\n\nA simple configured PC was used to obtain the results, equipped with an i9-9900 processor, 48 GB of memory, a 256 GB solid-state disk, and running Windows 10.1 Professional. MATLAB (2020b) served as the programming environment for implementing and testing the model.\n\nTo evaluate the performance, four databases were utilized. The results for these databases are detailed in respective tables. For instance, the results obtained using the DB1 database are presented in a confusion matrix format, showcasing the model's performance in classifying different types of pneumonia and COVID-19 cases. Similar tables are provided for DB2, DB3, and DB4, each highlighting the model's accuracy, precision, recall, and F1 score for various classifications.\n\nThe biggest database used was DB3, and its results were obtained through 10-fold cross-validation, a robust method to ensure the model's generalizability. The confusion matrix for DB3 is also provided, offering insights into the model's classification performance.\n\nIn summary, the evaluation method involved using multiple databases and metrics to thoroughly assess the Exemplar COVID-19FclNet9 model's performance, ensuring its reliability and accuracy in classifying COVID-19 and other pneumonia types from X-ray images.",
  "evaluation/measure": "In our evaluation, we employed several key performance metrics to assess the effectiveness of our proposed Exemplar COVID-19FclNet9 model. These metrics include accuracy, precision, recall, and the F1 score. These metrics were chosen because they provide a comprehensive evaluation of the model's performance across different aspects of classification.\n\nAccuracy measures the overall correctness of the model by calculating the ratio of correctly predicted instances to the total instances. Precision focuses on the correctness of positive predictions, which is crucial for ensuring that the model does not falsely identify negative cases as positive. Recall, on the other hand, assesses the model's ability to identify all relevant instances, ensuring that it captures most of the positive cases. The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in medical imaging. By reporting these metrics, we ensure that our results are comparable to other studies in the field. Additionally, we provide detailed confusion matrices for each database, which offer a granular view of the model's performance across different classes.\n\nThe use of these metrics allows us to demonstrate the robustness and reliability of our model. The high values obtained for accuracy, precision, recall, and F1 score across multiple databases indicate that our model performs well in various scenarios. This comprehensive evaluation approach ensures that our findings are both rigorous and representative of the state-of-the-art in medical image classification.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated our proposed Exemplar COVID-19FclNet9 model against several publicly available methods using benchmark datasets. We compared our approach with various convolutional neural network (CNN) models, including ResNet50, VGG-16, EfficientNet, and CoroDet, among others. These comparisons were conducted on multiple datasets, including those containing chest X-ray images classified into categories such as COVID-19, pneumonia, and normal cases.\n\nOur model demonstrated superior performance across different datasets. For instance, when using a dataset with four classes (control, bacterial pneumonia, viral pneumonia, and COVID-19), our method achieved an accuracy of 97.60%. In another dataset with three classes (COVID-19, pneumonia, and control), we attained an accuracy of 89.96%. For a larger dataset with the same three classes, our accuracy was 98.84%. Additionally, on a dataset with two classes (COVID-19 and normal), we achieved an accuracy of 99.64%.\n\nWe also compared our model with simpler baselines, such as those using traditional CNN architectures without transfer learning. These comparisons highlighted the robustness and efficiency of our Exemplar COVID-19FclNet9 model. For example, our model outperformed the CoroDet model, which did not use transfer learning, indicating that our approach is more time-efficient while maintaining high accuracy.\n\nFurthermore, we tested our model on four different databases, including both small and large datasets, to ensure its generalizability and robustness. This comprehensive evaluation underscores the effectiveness of our proposed method in COVID-19 detection using chest X-ray images.",
  "evaluation/confidence": "The evaluation of our proposed Exemplar COVID-19FclNet9 model was conducted using four distinct X-ray image databases, ensuring a robust assessment across various datasets. The performance metrics, including accuracy, precision, recall, and F1 score, were calculated for each database. These metrics provide a comprehensive view of the model's effectiveness in classifying different types of pneumonia and COVID-19 cases.\n\nThe accuracy ranges for the databases were explicitly stated, indicating the variability in performance. For instance, the accuracy for DB1 ranged from 93.06% to 95.59%, while for DB2, it ranged from 83.29% to 88.18%. These ranges give an idea of the confidence intervals for the accuracy metrics. Similarly, the accuracy ranges for DB3 and DB4 were [97.68%, 98.07%] and [98.19%, 99.64%], respectively. These intervals help in understanding the reliability and consistency of the model's performance across different datasets.\n\nThe use of 10-fold cross-validation for the largest database, DB3, further enhances the confidence in the results. This technique ensures that the model is evaluated on multiple subsets of the data, reducing the risk of overfitting and providing a more reliable estimate of its performance.\n\nMoreover, the comparison with other published works, as shown in Table 9, demonstrates that our model outperforms state-of-the-art techniques. For example, our model achieved 89.96% accuracy on DB2, which is higher than the 87.02% accuracy reported by Ozturk et al. This superior performance, coupled with the use of multiple databases, suggests that our model is not only accurate but also robust.\n\nThe overall results, as presented in Table 7, show high accuracy, unweighted average recall, precision, and F1 scores across all databases. These metrics, along with the ROC curves, provide a clear indication of the model's effectiveness and reliability. The ROC curves for each dataset further validate the model's performance, showing its ability to distinguish between different classes with high accuracy.\n\nIn summary, the performance metrics for our Exemplar COVID-19FclNet9 model are supported by confidence intervals and statistically significant results. The use of multiple databases, cross-validation, and comparison with other methods ensure that our claims of superiority are well-founded. The model's high accuracy and reliability make it a strong candidate for real-world applications in COVID-19 and pneumonia classification.",
  "evaluation/availability": "The raw evaluation files are not publicly available. This restriction is due to the ethical guidelines set by the Medical Research Ethics Committee, University Malaya Medical Centre. The data used in this study is subject to these ethical considerations, which prevent its public release."
}