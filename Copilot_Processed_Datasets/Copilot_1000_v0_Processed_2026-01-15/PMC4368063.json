{
  "publication/title": "Not enough information is available",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Current Protein & Peptide Science",
  "publication/year": "2015",
  "publication/pmid": "21787308",
  "publication/pmcid": "PMC4368063",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Protein structure prediction\n- Quality assessment\n- Machine learning\n- Radial basis function networks\n- Consensus methods\n- Protein modeling\n- Structural bioinformatics\n- GDT_TS score\n- Sampling methods\n- Meta-server methods",
  "dataset/provenance": "The datasets used in our study come from two distinct sources. The first dataset consists of server prediction models for CASP8 targets, which were downloaded from the official CASP website. The second dataset includes models generated by our in-house software, MUFOLD. These datasets were chosen to evaluate the performance of our method across different types of structural models.\n\nThe CASP8 dataset provides a diverse set of models, as it includes predictions from various tools submitted to the CASP8 competition. This diversity is beneficial for testing the robustness of our method. The MUFOLD dataset, on the other hand, offers a more controlled environment, as all models are generated by a single software.\n\nThe exact number of data points in each dataset is not specified, but the results indicate that the method was applied to a sufficient number of targets to draw meaningful conclusions. The CASP8 dataset includes models for 88 targets, which were used to compare the performance of our method with individual scoring functions.\n\nBoth datasets have been used in previous studies and by the community for evaluating protein structure prediction methods. The CASP8 dataset is particularly well-known and widely used, as it represents a standardized benchmark for comparing different prediction tools. The MUFOLD dataset, while less known, has also been used in our previous work to develop and test protein structure prediction methods.",
  "dataset/splits": "In our study, we utilized two distinct model sets derived from CASP8 targets. The first set consists of server predictions from CASP8, which are publicly available. The second set comprises models generated by our in-house software, MUFOLD.\n\nFor the training dataset, we selected models from 32 targets of CASP8. The remaining 88 targets were reserved for the test dataset. This split ensures a comprehensive evaluation of our method across both CASP8 server models and MUFOLD models.\n\nThe distribution of data points in each split is as follows: the training dataset includes models from 32 targets, while the test dataset encompasses models from 88 targets. This division allows for a robust assessment of the performance and generalization capabilities of our proposed method.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not applicable.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is radial basis function (RBF) neural networks. This class of algorithms is well-established and widely used for various prediction tasks, including those in structural bioinformatics.\n\nThe specific RBF models employed in our work are not entirely new, as RBF neural networks have been extensively studied and applied in different fields. However, the way we integrate these models with a sampling scheme to mimic consensus approaches and enhance model quality assessment is novel. This integration allows us to combine the strengths of knowledge-based scoring functions, consensus approaches, and machine learning-based scores, providing a more robust and discerning method for ranking structural models.\n\nThe focus of our publication is on the application of these techniques to protein structure prediction and quality assessment, rather than the development of a new machine-learning algorithm per se. Therefore, it is published in a journal focused on protein and peptide science, rather than a machine-learning journal. The innovation lies in the application and integration of existing methods to address a specific problem in structural bioinformatics, leveraging the strengths of multiple approaches to improve the accuracy and robustness of model ranking.",
  "optimization/meta": "The model described in this publication is indeed a meta-predictor, as it integrates multiple existing scores and features to rank protein structural models. It combines different knowledge-based scoring functions and machine-learning scores through a sampling method. The meta-predictor uses radial basis function (RBF) neural networks to learn from the sampling distribution, thereby leveraging the strengths of consensus approaches and machine learning methods.\n\nThe meta-predictor incorporates five popular protein structural quality assessment (QA) scores: Opus-CA, Opus-PSP, DFIRE, RAPDF, and Cheng Score. Additionally, it includes two machine-learning scores derived from RBF models trained on different datasets. These scores are synthesized using a novel sampling process that mimics consensus approaches. The integrated RBF model then takes sampling distribution features as inputs to produce a more robust score for model ranking.\n\nThe training data for the RBF models is independent, as it is derived from two different datasets: the CASP server prediction models of CASP8 targets and models generated by the in-house software MUFOLD. This independence ensures that the meta-predictor's performance is evaluated on unseen data, providing a reliable assessment of its effectiveness.",
  "optimization/encoding": "In our study, data encoding and preprocessing involved several steps to prepare the input features for the machine-learning algorithm. We began by calculating five existing quality assessment (QA) scores for each protein structure model. These scores included Opus-CA, Opus-PSP, DFIRE, RAPDF, and Cheng Score, each providing unique insights into the model's quality based on different molecular interactions and structural properties.\n\nAdditionally, we generated two types of features for the radial basis function (RBF) neural networks. The first type was secondary structure-based features, which compared the secondary structures and solvent accessibilities calculated from the 3D coordinates of a model with those predicted from the protein's amino acid sequence. We used DSSP to calculate the secondary structures and solvent accessibilities of the model, PSIPRED for predicted secondary structures, and SPINE for predicted solvent accessibilities. This comparison yielded several features that captured the discrepancies between the predicted and actual structures.\n\nThe second type of features was statistic-based, focusing on the contact preferences of amino acids within specified distance thresholds. We counted the contact numbers between different types of amino acids in the protein's tertiary structure, resulting in vectors that represented the \"contact ability\" of each amino acid type and the likelihood of interactions between different amino acid pairs. These vectors were calculated for two distance thresholds, 6\u00c5 and 12\u00c5, providing a comprehensive view of the protein's contact landscape.\n\nTo integrate the different scoring functions and features, we normalized each score using z-scores. This normalization ensured that all scores contributed equally to the final assessment. We then generated a large number of weight sets to combine the seven z-scores into new scores, mimicking consensus approaches. The distribution of these new scores was analyzed to retrieve robust features for building the integrated RBF model. This preprocessing and encoding strategy allowed us to systematically combine different features and scores, enhancing the discerning power and robustness of our model quality assessment method.",
  "optimization/parameters": "In our study, the model utilizes a specific number of input nodes and hidden nodes. The number of input nodes is 14, which corresponds to the number of abstracted features used. These features include secondary structures, solvent accessibilities, and contact information derived from the structural models. The number of hidden nodes in the model is set to 35. These parameters were chosen to effectively capture the relevant information from the structural models and to ensure robust performance in predicting the GDT_TS score. The selection of these parameters was based on extensive testing and optimization to achieve the best possible model performance.",
  "optimization/features": "In the optimization process, a total of 14 features are used as input. These features are abstracted from the comparison between the secondary structures and solvent accessibilities calculated from the 3D coordinates of a model and those predicted from the protein amino acid sequence. The features include secondary structure and solvent accessibility information, which are calculated using DSSP, PSIPRED, and SPINE.\n\nFeature selection was not explicitly mentioned as a separate step in the process. The features used were determined through an extensive survey and testing of existing quality assessment scores, leading to the selection of five scoring functions and two RBF scores. The features are derived from these scores and the abstracted secondary structure and solvent accessibility information.\n\nNot applicable.",
  "optimization/fitting": "The fitting method employed in our study involves the use of radial basis function (RBF) neural networks, which are known for their excellent nonlinear approximation properties. The RBF networks used in this study have three layers: input, hidden, and output. The input layer consists of 14 nodes corresponding to the number of abstracted features, while the hidden layer has 35 nodes. The training process is terminated after reaching 3000 cycles.\n\nTo address the potential issue of overfitting, given the relatively large number of parameters compared to the number of training points, several measures were taken. First, the training dataset was carefully selected to ensure diversity and representativeness, which helps in generalizing the model. Second, the parameters of the RBF networks, including the centers of hidden nodes, the widths of Gaussian functions, and the weights linking the hidden layer to the output layer, were trained using the steepest descent method. This method helps in finding a good balance between fitting the training data and generalizing to new data. Additionally, the use of a sampling process to integrate multiple scoring functions adds robustness to the model, reducing the risk of overfitting.\n\nUnderfitting was mitigated by ensuring that the model had sufficient complexity to capture the underlying patterns in the data. The choice of 35 hidden nodes and 3000 training cycles was based on empirical testing and validation to ensure that the model could learn the necessary features without being too simplistic. Furthermore, the integration of multiple scoring functions through the sampling process provides a richer set of features for the RBF model to learn from, enhancing its ability to capture the nuances of the data.",
  "optimization/regularization": "Not applicable.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, the number of input nodes is set to 14, corresponding to the number of abstracted features, and the number of hidden nodes is 35. The training process is terminated after reaching 3000 cycles. These configurations are integral to the sampling process and the integration of the RBF scores.\n\nThe optimization parameters, including the normalization of scores using z-scores and the generation of weight sets, are also described. A large number of weight sets are generated randomly to combine the seven z-scores, with the number of samples taken as 1000 in our study. This process ensures that the new sampling scores are robust and provide more discerning power.\n\nRegarding the availability of model files and optimization parameters, the publication does not explicitly mention the provision of these files. However, the methods and configurations are thoroughly documented, allowing for reproducibility. The scoring functions used, such as Opus-CA, Opus-PSP, DFIRE, RAPDF, and Cheng Score, are well-documented and user-friendly, which aids in the reproducibility of the results.\n\nThe publication is available under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. This license ensures that the methods and configurations described can be accessed and utilized by other researchers.",
  "model/interpretability": "The model presented in this work is not entirely a black box, as it incorporates several interpretable components and processes. The framework includes a sampling process that integrates multiple scoring functions, which are well-established and have known strengths and weaknesses. These scoring functions, such as Opus-CA, Opus-PSP, DFIRE, RAPDF, and Cheng Score, are based on molecular interactions, energy potentials, and structural comparisons, making them interpretable in the context of protein structure assessment.\n\nThe sampling process itself is designed to mimic consensus methods, where multiple scores are combined to generate new scores. This process is transparent in that it involves normalizing scores, generating weight sets, and combining these scores to create a distribution of ranks. The features used in the sampling process, such as the highest rank, upper quartile rank, median rank, lower quartile rank, and lowest rank, are clear and interpretable.\n\nAdditionally, the radial basis function (RBF) model used in this study is a type of neural network that is more interpretable than many other machine learning models. The RBF model uses a set of basis functions to transform the input space into a higher-dimensional space, where a linear model can be used for classification or regression. The basis functions are centered on the input data points, making the model's decisions somewhat interpretable in terms of the input features.\n\nThe integrated RBF model takes several distribution features as inputs, which are derived from the sampling process. These features, such as the maximum frequency (ftop) and the rank associated with ftop (rtop), provide insights into the model's ranking behavior. For example, the trend that rtop increases with the actual rank indicates that better models are frequently ranked higher by many combinations of scoring functions.\n\nIn summary, while the model incorporates complex machine learning techniques, it is not entirely a black box. The use of interpretable scoring functions, a transparent sampling process, and a relatively interpretable RBF model allows for some level of understanding and explanation of the model's decisions.",
  "model/output": "The model is a regression model. It is designed to predict the quality of protein structure models, specifically the GDT_TS score, which measures the similarity of a model to its native structure. The output of the integrated RBF model is a score that estimates the quality of each model, providing a ranking based on this predicted score. This score is used to assess the quality of protein structure models, aiming to identify the models that are closest to the native structure. The model's output is not a classification but a continuous score that reflects the expected GDT_TS of the models.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The method was evaluated using two distinct datasets to ensure its robustness and generalizability. The first dataset consisted of models generated by our in-house software, MUFOLD, for CASP8 targets. The second dataset included server predictions from CASP8, which encompassed models from over 70 diverse servers. This approach allowed us to test our method under different conditions and with varying levels of model diversity.\n\nFor each dataset, we compared the performance of our integrated RBF model against five existing quality assessment (QA) scores and two individual RBF models. The evaluation metrics used were GDT_TS1, GDT_TSMean5, GDT_TS5, and Spearman Correlation. These metrics are commonly used to measure the similarity of a model to its native structure and the correlation between predicted and actual GDT_TS scores.\n\nThe results showed that our integrated RBF model outperformed all individual approaches across all metrics. For the MUFOLD models, the integrated RBF model achieved improvements of 3.00%, 1.51%, 1.59%, and 1.37% in GDT_TS1, GDT_TSMean5, GDT_TS5, and Spearman Correlation, respectively. Similarly, for the CASP8 server models, the improvements were 6.92%, 5.00%, 1.78%, and 5.00% in the same metrics.\n\nAdditionally, we visualized the comparisons through plots, such as Fig. (5a) and Fig. (5b), which illustrated the superiority of our method over individual scores like Opus-PSP and Cheng Score. These visualizations and numerical results collectively demonstrated that our sampling-based machine-learning approach provides a more robust and accurate quality assessment for protein structure models.",
  "evaluation/measure": "To evaluate the performance of our method, we employed four metrics: GDT_TS1, GDT_TSMean5, GDT_TS5, and Spearman Correlation. These metrics provide a comprehensive assessment of our approach's effectiveness in ranking protein structure models.\n\nGDT_TS1 measures the Global Distance Test Total Score (GDT_TS) of the top-ranked model by our quality assessment (QA) approach. This metric is crucial as it directly indicates how well our method identifies the best model in a set.\n\nGDT_TSMean5 calculates the average GDT_TS of the top five ranked models. This metric helps to understand the consistency of our method in selecting high-quality models, rather than just the single best one.\n\nGDT_TS5 represents the GDT_TS of the best model among the top five ranked by our method. This metric is important as it shows the upper limit of our method's performance within the top five predictions.\n\nSpearman Correlation assesses the ranking correlation between the predicted GDT_TS scores (output score of the integrated RBF model) of the models and their actual GDT_TS scores to the native structure. A high Spearman Correlation indicates that our method's rankings are strongly aligned with the actual quality of the models.\n\nThese metrics are widely used in the literature for evaluating protein structure prediction methods, making our evaluation representative and comparable to other studies in the field.",
  "evaluation/comparison": "In the evaluation of our method, we conducted a thorough comparison with both publicly available methods and simpler baselines on benchmark datasets. Specifically, we tested our integrated RBF model against five existing scores: Opus-CA, Opus-PSP, DFIRE, RAPDF, and Cheng Score. Additionally, we compared it with two individual RBF models that we had previously developed. These comparisons were performed on two distinct datasets: the CASP8 server predictions and models generated by our in-house software, MUFOLD.\n\nFor the CASP8 server predictions, which include models from over 70 diverse servers, our integrated RBF model demonstrated significant improvements across all four measurement metrics: GDT_TS1, GDT_TSMean5, GDT_TS5, and Spearman Correlation. The results showed that our method outperformed each individual approach, achieving higher average scores and greater consistency in identifying top-ranked models.\n\nSimilarly, when tested on the MUFOLD models, our integrated RBF model also showed superior performance. It achieved higher GDT_TS scores and better Spearman Correlation compared to the individual scores and RBF models. This consistent performance across different datasets underscores the robustness and effectiveness of our method.\n\nIn addition to comparing with publicly available methods, we also evaluated simpler baselines. For instance, we compared our method with the best individual scores in both GDT_TS1 and GDT_TSMean5 metrics, such as Opus-PSP. The results, visualized in figures, clearly indicated that our integrated RBF model performed better overall, with more points above the diagonal in the comparisons.\n\nOverall, the evaluations confirm that our sampling-based machine-learning method is superior to any individual QA score and simpler baselines, making it a valuable tool for protein structure quality assessment.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not enough information is available."
}