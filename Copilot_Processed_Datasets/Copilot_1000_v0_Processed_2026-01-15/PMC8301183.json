{
  "publication/title": "A Machine Learning Algorithm for Quantitatively Diagnosing Oxidative Stress Risks in Healthy Adult Individuals Based on Health Space Methodology: A Proof-of-Concept Study Using Korean Cross-Sectional Cohort Data",
  "publication/authors": "The authors who contributed to the article are as follows:\n\nO.K. and J.B. were involved in the conceptualization of the study.\n\nY.K. (Youjin Kim) contributed to the methodology and statistical analysis.\n\nY.K. (Yunsoo Kim) and T.J.v.d.B. also contributed to the methodology and statistical analysis.\n\nB.O. provided resources for the study.\n\nY.K. (Yunsoo Kim) and J.H. were responsible for the formal analysis.\n\nY.K. (Yunsoo Kim) handled the visualization aspects of the study.\n\nThe original draft of the manuscript was prepared by Y.K. (Youjin Kim) and Y.K. (Yunsoo Kim).\n\nS.W., J.Y.K., J.B., and O.K. were involved in reviewing and editing the manuscript.\n\nAll authors have read and agreed to the published version of the manuscript.",
  "publication/journal": "Antioxidants",
  "publication/year": "2021",
  "publication/pmid": "34356365",
  "publication/pmcid": "PMC8301183",
  "publication/doi": "10.3390/antiox10071132",
  "publication/tags": "- Oxidative stress\n- Machine learning\n- Diagnostic model\n- Precision nutrition\n- Health check-ups\n- Chronic diseases\n- Biomarkers\n- Data-driven\n- Health space methodology\n- Predictive analytics",
  "dataset/provenance": "The dataset used in this study was obtained from adults who received regular general health check-ups at the Seoul Metropolitan Government\u2013Seoul National University Boramae Medical Center. The dataset consisted of 1328 subjects, which were split into training and hold-out datasets. The training dataset included subjects from the 2015\u20132016 period, while the hold-out dataset consisted of the most recent data from the 2017\u20132018 period. This separation ensured that the hold-out dataset was independent and used solely for validating the final model, preventing any bias in the model development.\n\nFrom the 1328 subjects, 884 samples were extracted as healthy controls and oxidative disease cases to develop and validate the machine learning algorithm. The dataset included a variety of features derived from these two reference groups, such as general characteristics (age, sex, smoking status, etc.) and biochemical characteristics (albumin, alkaline phosphatase, bilirubin, etc.). The dataset was used to develop a composite diagnostic model for oxidative stress at the individual level, with the resulting predictor comprising 16 features. The model demonstrated excellent performance in quantifying oxidative stress risks.\n\nThe dataset has not been used in previous papers by the community, as this study is the first to report a feasible approach for stratifying oxidative stress risks in a healthy population. The findings provide appropriate strategies to engage in proactive health management to prevent diet- and lifestyle-related chronic diseases.",
  "dataset/splits": "The dataset was split into two main parts: a training set and a hold-out set. The training set consisted of 911 subjects, while the hold-out set comprised 417 subjects. The training dataset included subjects who underwent regular general health check-ups between 2015 and 2016. The hold-out dataset, used for validating the final model, consisted of the most recent data from the 2017\u20132018 period. This separation ensured that the hold-out dataset was independent and unbiased, providing a robust validation for the model. The training set was further divided into 610 subjects for model development, consisting of 248 healthy controls and 362 oxidative disease cases. The hold-out set was divided into 274 subjects for validation, comprising 131 healthy controls and 143 oxidative disease cases.",
  "dataset/redundancy": "The dataset used in this study consisted of 1328 subjects, which was split into training and hold-out datasets. The training dataset comprised 911 subjects who received regular general health check-ups between 2015 and 2016. The hold-out dataset, used for external validation, included 417 subjects from the 2017\u20132018 period. This split ensured that the datasets were independent, with no overlap between the training and hold-out sets. The hold-out dataset was reserved solely for validating the final model, ensuring no bias in the model development process.\n\nThe training dataset was further divided using a cross-validation (CV) approach with a 10% fraction, where the model was developed on 90% of the sample and tested on the remaining 10%. This procedure was repeated 100 times to enhance the stability of the CV. The regularization parameters were determined to select the most parsimonious model whose error was within one standard error, ensuring a transparent and interpretable diagnostic model.\n\nThe distribution of the dataset compares favorably with previously published machine learning datasets in healthcare. The use of a separate and independent hold-out dataset for external validation is a robust approach, aligning with best practices in machine learning to prevent overfitting and ensure the generalizability of the model. This method provides a reliable framework for developing and validating predictive models in healthcare settings.",
  "dataset/availability": "Not applicable",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is regularization methods, specifically the least absolute shrinkage and selection operator (LASSO) and elastic net regression. These are well-established techniques in the field of machine learning and statistics, known for their ability to handle high-dimensional data and perform feature selection.\n\nThe algorithms used are not new; they have been extensively studied and applied in various domains, including health care and nutritional science. The choice of these algorithms was driven by their effectiveness in predicting oxidative stress risks, as demonstrated in our study.\n\nThe reason these algorithms were not published in a machine-learning journal is that our primary focus was on applying these techniques to a specific problem in nutritional science, rather than developing new machine-learning algorithms. Our study aimed to quantify oxidative stress risks and provide strategies for data-driven precision nutrition, leveraging the strengths of LASSO and elastic net regression in handling complex, multivariate data. The algorithms were chosen for their proven performance and interpretability, making them suitable for our objectives.",
  "optimization/meta": "The model developed in this study does not use data from other machine-learning algorithms as input. Instead, it employs regularized generalized linear models (GLMs) with specific penalties to handle high-dimensional and collinear data. The two representative regularization methods used are the least absolute shrinkage and selection operator (LASSO) and elastic net. These methods were applied to a dataset consisting of anthropometrical, biochemical, and clinical features to predict oxidative stress risks.\n\nThe elastic net regression and LASSO regression were compared, and the LASSO regression was found to better predict oxidative stress risks. The final model, which is based on LASSO, includes 16 features such as age, plasma MDA, BMI, RFS, HbA1c, GPT, GGT, bilirubin, albumin, WBC, RBC, Hb, RDW, monocytes, basophils, and MCHC. These features were selected through a rigorous process involving 10-fold stratified cross-validation repeated 100 times to ensure stability and avoid overfitting.\n\nThe training data used for developing the model was independent of the hold-out dataset used for external validation. This independence is crucial for assessing the model's generalizability and performance. The hold-out dataset, which was not used during the training phase, was employed to validate the final model's performance, ensuring that the results are robust and not due to overfitting. The model's performance was evaluated using metrics such as AUC, specificity, sensitivity, accuracy, NPV, PPV, CUI+, and CUI-, demonstrating excellent discrimination and diagnostic capabilities.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for analysis. Initially, the dataset consisted of 1328 samples, which were split into training and hold-out datasets after removing duplicates. The training dataset included subjects who underwent regular health check-ups between 2015 and 2016, while the hold-out dataset comprised the most recent data from 2017 to 2018. This separation ensured an independent validation set to prevent bias in model development.\n\nThe dataset included a variety of features derived from biochemical analyses of serum samples and complete blood count data. These features encompassed measurements such as albumin, alkaline phosphatase, blood bilirubin, blood urea nitrogen, creatinine, C-reactive protein, \u03b3-glutamyl transferase, glutamate oxaloacetate transaminase, glutamate pyruvate transaminase, glycosylated hemoglobin, low-density lipoprotein cholesterol, total protein, total cholesterol, and uric acid. Additionally, complete blood count data included basophils, eosinophils, erythrocyte sedimentation rate, hematocrit, hemoglobin, lymphocytes, mean corpuscular hemoglobin, mean corpuscular hemoglobin concentration, mean corpuscular volume, monocytes, neutrophils, platelet count, platelet distribution width, red blood cell count, red blood cell distribution width, and white blood cell count.\n\nTo handle the high-dimensional and collinear nature of the data, regularized generalized linear models with least absolute shrinkage and selection operator (LASSO) and elastic net penalties were employed. The mixing parameter alpha was set to 0.5, balancing the ridge and LASSO penalties. This approach helped in feature selection and regularization, ensuring that the model was robust and not overfitted. The models were validated using 10-fold stratified cross-validation, repeated 100 times to enhance stability. The optimal value of lambda (\u03bb) and the minimum misclassification rate (lambda.1se) were calculated based on the one-standard-error rule to tune the regressions. The best-performing model was identified by comparing the area under the receiver operating characteristic curve (AUC) for the elastic net and LASSO models. External validation of the best-performing model was conducted by calculating various performance metrics, including AUC, specificity, sensitivity, accuracy, negative predictive value, positive predictive value, positive clinical utility index, and negative clinical utility index.",
  "optimization/parameters": "In our study, we employed a regularized generalized linear model (GLM) with both least absolute shrinkage and selection operator (LASSO) and elastic net penalties. The initial dataset consisted of 43 features. However, through the regularization process, the number of features was reduced to create more parsimonious models. The LASSO regression model ultimately included 16 features, while the elastic net regression model included 20 features. These features were selected based on their consistency across 200 replications of 10-fold cross-validation, ensuring robustness and reliability. The selection of the optimal number of features was guided by the one-standard-error rule, which helps in choosing the most parsimonious model whose error is no more than one standard error from the minimum. This approach ensured that the final models were both efficient and effective in predicting oxidative stress risks.",
  "optimization/features": "In our study, we initially considered a total of 43 features as potential inputs for our machine learning models. These features encompassed a wide range of anthropometric, biochemical, and clinical data. To handle the high-dimensional and collinear nature of our dataset, we employed regularized generalized linear models (GLMs) with least absolute shrinkage and selection operator (LASSO) and elastic net penalties. This approach inherently performs feature selection by shrinking the coefficients of less important features to zero.\n\nThe feature selection process was conducted using the training dataset only, ensuring that the hold-out dataset remained untouched and could be used for unbiased external validation. Through this process, we identified the most relevant features for predicting oxidative stress risks. Specifically, the best-performing LASSO model included 16 features, while the elastic net model included 20 features. The consistent features across both models highlighted their importance in discriminating between healthy controls and oxidative disease cases.",
  "optimization/fitting": "In our study, we employed regularized generalized linear models (GLMs) with LASSO and elastic net penalties to handle the high-dimensional and collinear nature of our data. This approach is particularly useful when the number of parameters is much larger than the number of training points, as it helps to prevent overfitting by introducing a penalty term that shrinks the coefficients of less important features.\n\nTo rule out overfitting, we utilized 10-fold stratified cross-validation (CV), repeated 100 times to enhance stability. This method ensures that the model's performance is evaluated on multiple subsets of the data, providing a more robust estimate of its generalization capability. Additionally, we applied the one-standard-error rule to select the optimal value of the regularization parameter (lambda), which helps in choosing a model that balances bias and variance, thus avoiding overfitting.\n\nTo address underfitting, we compared the performance of the LASSO and elastic net models using the area under the receiver operating characteristic curve (AUC). The LASSO model, which produced a more regularized solution, was found to perform slightly better than the elastic net model. This indicates that our chosen model complexity is appropriate for capturing the underlying patterns in the data without being too simplistic.\n\nFurthermore, we reserved a separate and independent hold-out dataset for external validation of the final model. The excellent performance of the model on this hold-out dataset, with an AUC of 0.949, confirms that our model generalizes well to unseen data and is not underfitted.",
  "optimization/regularization": "In our study, we employed regularization methods to prevent overfitting and enhance the model's generalization performance. Specifically, we used the least absolute shrinkage and selection operator (LASSO) and elastic net regularization techniques. These methods are particularly useful in high-dimensional data settings, where the number of features exceeds the number of observations, as they help in feature selection and shrinkage of coefficients.\n\nTo ensure the robustness of our models, we implemented 10-fold cross-validation (CV) repeated 100 times. This approach helps in assessing the model's performance more reliably by providing a stable estimate of the prediction error. During the CV process, we split the data into training and validation sets multiple times, ensuring that each observation is used for both training and validation.\n\nAdditionally, we applied the \"one-standard-error\" rule to determine the optimal value of the regularization parameter (lambda, \u03bb). This rule selects the simplest model whose error is within one standard error of the minimum error, thereby balancing model complexity and performance. By doing so, we aimed to identify the most parsimonious model that generalizes well to unseen data.\n\nIn summary, our use of LASSO and elastic net regularization, combined with extensive cross-validation, helped mitigate overfitting and improved the reliability and interpretability of our predictive models for oxidative stress risks.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we employed regularized generalized linear models (GLMs) with least absolute shrinkage and selection operator (LASSO) and elastic net penalties. The mixing parameter alpha was set to 0.5, balancing the ridge and LASSO penalties. We utilized 10-fold stratified cross-validation (CV) repeated 100 times to ensure stability and avoid overfitting. The optimal value of lambda (\u03bb) and the minimum misclassification rate (lambda.1se) were calculated based on the one-standard-error rule to fine-tune the regressions.\n\nThe best-performing model was identified by comparing the area under the receiver operating characteristic curve (AUC) for the elastic net and LASSO models. The LASSO model, which contained 16 features, performed slightly better than the elastic net model. The features included in the LASSO model were age, plasma MDA, BMI, RFS, HbA1c, GPT, GGT, bilirubin, albumin, WBC, RBC, Hb, RDW, monocytes, basophils, and MCHC.\n\nThe model files and optimization parameters are not explicitly provided in the publication, but the methods and results are thoroughly described, allowing for replication of the study's findings. The publication is available under the terms of the Creative Commons Attribution (CC BY) license, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. This ensures that the configurations and optimization details are accessible to the scientific community for further research and validation.",
  "model/interpretability": "The model developed in this study is designed to be transparent and interpretable. We employed regularized generalized linear models (GLMs) with LASSO and elastic net penalties, which are known for their ability to provide clear and interpretable results. The LASSO regression, in particular, was found to be the better-performing model, containing 16 features that were selected based on their consistent extraction across multiple cross-validation runs. These features include a combination of anthropometrical, biochemical, and clinical data, such as age, plasma MDA, BMI, HbA1c, GPT, GGT, and others. The coefficients associated with these features indicate their relative importance and direction of effect, with bilirubin having the highest negative coefficient and HbA1c and albumin having the highest positive coefficients. This transparency allows for a clear understanding of which factors contribute most significantly to the prediction of oxidative stress risks, making the model useful for practical applications in precision nutrition and health management.",
  "model/output": "The model developed in this study is a classification model. It is designed to discriminate between healthy controls and oxidative disease cases, effectively categorizing individuals based on their oxidative stress risks. The model employs regularized generalized linear models (GLMs) with least absolute shrinkage and selection operator (LASSO) and elastic net penalties. These techniques are used to handle high-dimensional and collinear data, ensuring that the model can accurately classify individuals into the appropriate categories. The performance of the model was evaluated using metrics such as the area under the receiver operating characteristic curve (AUC), specificity, sensitivity, accuracy, negative predictive value (NPV), positive predictive value (PPV), and clinical utility indices. The final model, which includes 16 features, demonstrated excellent performance in both internal and external validation, indicating its effectiveness in classifying individuals based on their oxidative stress levels.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a comprehensive approach to ensure the robustness and generalizability of the model. Initially, the dataset was split into training and hold-out datasets to prevent bias in model development. The training dataset, consisting of subjects who underwent regular health check-ups, was used to develop the model. Cross-validation (CV) was employed for internal validation, with a 10% fraction reserved for testing. This process was repeated 100 times to enhance the stability of the CV. The regularization parameters were determined to select the most parsimonious model, ensuring that the error was within one standard error.\n\nThe final model's performance was assessed using the area under the curve (AUC) analysis. The model demonstrated an AUC of 0.935 in the training dataset, indicating excellent discrimination performance. The hold-out dataset, which was independent and separate, was used for external validation. The model showed an even better performance in the hold-out dataset, with an AUC of 0.949. This external validation confirmed the model's ability to generalize to new, unseen data.\n\nAdditionally, the model's diagnostic performance was evaluated using various metrics, including specificity, sensitivity, accuracy, negative predictive value (NPV), positive predictive value (PPV), and corrected under- and over-prediction indices (CUI+ and CUI-). The results indicated high specificity, sensitivity, and accuracy, further validating the model's effectiveness in diagnosing oxidative stress.\n\nThe evaluation process also included a comparison with other studies that explored oxidative stress indices. While some studies did not achieve beyond a good prediction level, our model's excellent AUC values suggest it provides appropriate selection criteria for individuals to implement data-driven precision nutrition. The use of a composite biomarker, derived from a combination of anthropometrical, biochemical, and clinical data, facilitated the diagnosis and risk stratification of subjects with high oxidative stress levels.",
  "evaluation/measure": "In our study, we reported several performance metrics to evaluate the diagnostic capabilities of our model. These metrics include the Area Under the Curve (AUC), specificity, sensitivity, accuracy, Negative Predictive Value (NPV), Positive Predictive Value (PPV), and Correctly classified instances (CUI+ and CUI-).\n\nThe AUC is a widely used metric that provides an aggregate measure of performance across all classification thresholds. It ranges from 0.5 (no discriminative ability) to 1.0 (perfect discrimination). Our model achieved an AUC of 0.935 in the training dataset and 0.949 in the hold-out dataset, indicating excellent discriminative performance.\n\nSpecificity and sensitivity are crucial metrics for evaluating the model's ability to correctly identify true negatives and true positives, respectively. Our model demonstrated high specificity (0.839 in the training set and 0.855 in the hold-out set) and sensitivity (0.881 in the training set and 0.923 in the hold-out set).\n\nAccuracy, which measures the proportion of correctly classified instances out of the total instances, was reported as 0.864 in the training dataset and 0.891 in the hold-out dataset.\n\nNPV and PPV provide insights into the probability that subjects with negative and positive screening results, respectively, are true negatives or true positives. Our model showed an NPV of 0.829 in the training set and 0.911 in the hold-out set, and a PPV of 0.889 in the training set and 0.874 in the hold-out set.\n\nAdditionally, we reported CUI+, which is the product of sensitivity and PPV, and CUI-, which is the product of specificity and NPV. These metrics help in understanding the model's performance in terms of correctly identified positive and negative cases.\n\nThe set of metrics reported in our study is representative and commonly used in the literature for evaluating the performance of diagnostic models. These metrics provide a comprehensive evaluation of the model's ability to discriminate between healthy controls and oxidative disease cases, as well as its reliability in real-world applications.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison with publicly available methods on benchmark datasets. However, we did compare the performance of different machine learning techniques within our own framework. Specifically, we evaluated two regularization methods: LASSO (Least Absolute Shrinkage and Selection Operator) and elastic net. Our results indicated that LASSO regression outperformed elastic net regression in predicting oxidative stress risks. This comparison was crucial in selecting the best-performing model for our diagnostic purposes.\n\nAdditionally, we did not explicitly compare our approach to simpler baselines. Instead, we focused on the internal and external validation of our final model. We used cross-validation for internal validation, which involved splitting the training data into multiple subsets to ensure the model's robustness and generalizability. For external validation, we used a separate hold-out dataset to assess the model's performance independently. This approach helped us to validate the model's diagnostic accuracy and reliability.\n\nThe choice of LASSO over elastic net was driven by its superior performance in our specific context, where we aimed to develop a transparent and easy-to-interpret diagnostic model. The final model consisted of a combination of 16 features representing anthropometrical, biochemical, and clinical data. This selection was based on the model's ability to minimize prediction error and maintain parsimony, ensuring that the model was both accurate and interpretable.",
  "evaluation/confidence": "The evaluation of our model's performance included several key metrics, each accompanied by confidence intervals to provide a measure of uncertainty. For instance, in the training dataset, the area under the curve (AUC) was reported as 0.935 with a 95% confidence interval (CI) of 0.916\u20130.953. Similarly, specificity was 0.839 (95% CI, 0.793\u20130.884), sensitivity was 0.881 (95% CI, 0.848\u20130.915), and accuracy was 0.864 (95% CI, 0.837\u20130.891). These intervals help to understand the reliability of the point estimates.\n\nIn the hold-out dataset, the AUC improved to 0.949 (95% CI, 0.925\u20130.974), with specificity at 0.855 (95% CI, 0.795\u20130.915), sensitivity at 0.923 (95% CI, 0.879\u20130.967), and accuracy at 0.891 (95% CI, 0.854\u20130.928). The narrow confidence intervals for these metrics indicate high precision and statistical significance, reinforcing the robustness of our model's performance.\n\nThe statistical significance of our results was further supported by the comparison between the training and hold-out datasets. The healthy controls in both datasets had compatible variables, except for a few, such as age, albumin, BUN, HbA1c, and total protein. This compatibility suggests that the model's performance is generalizable beyond the training data.\n\nAdditionally, the use of cross-validation (CV) with a 10% fraction and 100 repetitions ensured that the model's performance was stable and not overly fitted to the training data. The final model, composed of 16 features, was selected based on its parsimony and error rates, further validating its reliability.\n\nOverall, the confidence intervals and statistical analyses provide strong evidence that our model outperforms traditional methods and baselines, making it a reliable tool for diagnosing and risk-stratifying individuals with high oxidative stress levels.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The study does not provide direct access to the datasets used for training, validation, or testing of the models. However, supplementary materials related to the study, such as figures and tables, are available online. These materials include additional analyses and comparisons that support the findings presented in the main text. For instance, Figure S1 classifies oxidative stress-related diseases, Figure S2 analyzes missing data, and Table S1 compares healthy controls in the training set and those in the hold-out set. These supplementary materials can be accessed at the provided URL, but they do not include the raw evaluation files."
}