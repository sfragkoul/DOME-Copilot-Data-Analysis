{
  "publication/title": "DL for Supraspinatus Calcific Tendinopathy",
  "publication/authors": "The authors who contributed to the article are:\n\n- Chiu, et al. The specific contributions of each author are not detailed in the provided information.",
  "publication/journal": "Journal of Medical Ultrasound",
  "publication/year": "2022",
  "publication/pmid": "36484040",
  "publication/pmcid": "PMC9724476",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Deep Learning\n- Supraspinatus Calcific Tendinopathy\n- Medical Ultrasound\n- Convolutional Neural Networks\n- DenseNet-121\n- Model Evaluation\n- ROC Curves\n- Sensitivity and Specificity\n- Data Augmentation\n- Medical Imaging Classification",
  "dataset/provenance": "The dataset used in this study was sourced from one of the largest musculoskeletal ultrasound centers in Taiwan. This center serves a large population and maintains a strict long-term ultrasound image storage process. The images were collected from 7,836 consecutive patients who underwent shoulder ultrasound examinations between January 2017 and December 2019. A total of 133,619 ultrasound images were gathered, focusing on longitudinal or transverse views of the supraspinatus tendons. Images with Doppler ultrasound were excluded to ensure the model was trained solely on B-mode images.\n\nThe dataset included 7,165 images in the longitudinal view, with 2,222 showing calcification and 4,943 without. Additionally, there were 5,201 images in the transverse view, with 1,178 showing calcification and 4,023 without. This comprehensive dataset was accumulated due to the center's high standards in training sonographers and maintaining an internal review process for image quality and diagnostic accuracy.\n\nPrevious studies using deep learning for ultrasound imaging often had datasets with fewer than 300 images, which can limit the accuracy of the algorithms. The large number of high-quality images in this dataset addresses this issue, providing a robust foundation for developing a highly accurate deep learning model. The heterogeneity of the images, obtained from different examiners using various machines, ensures the generalizability of the model.",
  "dataset/splits": "The dataset was divided into three main models: the longitudinal model, the transverse model, and the longi-trans model. Each of these models had distinct training, validation, and testing datasets.\n\nThe longitudinal model was trained using only longitudinal views of the supraspinatus tendon (SST) images. The training dataset for this model consisted of 1200 images, while the validation dataset had 100 images. The testing dataset for the longitudinal model was further divided into three subsets: testing dataset (a) with 260 images, testing dataset (b) with 120 images, and testing dataset (c) with 380 images.\n\nThe transverse model was trained using only transverse views of the SST images. This model's training dataset included 720 images, and the validation dataset had 62 images. Similar to the longitudinal model, the testing dataset for the transverse model was also divided into three subsets: testing dataset (a) with 260 images, testing dataset (b) with 120 images, and testing dataset (c) with 380 images.\n\nThe longi-trans model was trained using all SST images, encompassing both longitudinal and transverse views. The training dataset for this model consisted of 1920 images, and the validation dataset had 162 images. The testing dataset for the longi-trans model was divided into the same three subsets as the other models: testing dataset (a) with 260 images, testing dataset (b) with 120 images, and testing dataset (c) with 380 images.\n\nThe distribution of data points within each testing dataset subset was as follows:\n\n* Testing dataset (a): 130 images with calcification in the longitudinal view, 130 images without calcification in the longitudinal view, 60 images with calcification in the transverse view, and 60 images without calcification in the transverse view.\n* Testing dataset (b): 0 images with calcification in the longitudinal view, 0 images without calcification in the longitudinal view, 60 images with calcification in the transverse view, and 60 images without calcification in the transverse view.\n* Testing dataset (c): 130 images with calcification in the longitudinal view, 130 images without calcification in the longitudinal view, 60 images with calcification in the transverse view, and 60 images without calcification in the transverse view.",
  "dataset/redundancy": "The datasets used in this study were split into training, validation, and testing sets for three different models: longitudinal, transverse, and longi-trans. The longitudinal model was trained exclusively with longitudinal views of supraspinatus tendon (SST) images, while the transverse model was trained with transverse views. The longi-trans model, however, utilized all available SST images, encompassing both longitudinal and transverse views.\n\nThe training, validation, and testing datasets were carefully curated to ensure independence between sets. This independence was enforced through a meticulous data pre-processing pipeline. Each image underwent de-identification to protect patient information and was then cropped to remove any annotations or scales, ensuring that the models were trained on raw ultrasound images without external biases.\n\nThe distribution of the datasets is as follows:\n\n* **Longitudinal Model**: 1200 images for training, 100 for validation, and 260 for testing.\n* **Transverse Model**: 720 images for training, 62 for validation, and 380 for testing.\n* **Longi-Trans Model**: 1920 images for training, 162 for validation, and a combination of three testing datasets (a, b, and c) totaling 660 images.\n\nWithin these datasets, the images were further categorized based on the presence or absence of calcification in both longitudinal and transverse views. For instance, in the longitudinal view, there were 600 images with calcification and 600 without, for both training and validation sets. Similarly, the transverse view had 360 images with calcification and 360 without, for both training and validation sets.\n\nThis structured approach to dataset splitting and categorization aimed to provide a comprehensive and unbiased training environment for the models, ensuring that they could generalize well to new, unseen data. The distribution of the datasets compares favorably with previously published machine learning datasets in medical imaging, emphasizing a balanced and representative sample size for both training and validation purposes.",
  "dataset/availability": "The data used in this study is not publicly available. The dataset consists of ultrasound images collected from a large musculoskeletal ultrasound center, which includes a significant number of high-quality images accumulated over several years. The images were obtained from various machines and examiners to ensure heterogeneity and generalizability of the model. The dataset underwent a rigorous labeling process by experienced physiatrists, with inconsistencies resolved through consensus to ensure the quality of the training data.\n\nThe images were deidentified and cropped to remove any patient information, machine settings, annotations, and scales before being used for model training. This process was crucial to secure patients' personal information and to ensure that the model was trained solely on the relevant ultrasound data.\n\nGiven the sensitive nature of medical imaging data, the dataset was not released in a public forum. The study was conducted under institutional review board approval, and the requirement for informed consent for the review of patient images and medical records was waived. The data was used internally for the development and evaluation of the convolutional neural network-based deep learning algorithms aimed at dichotomizing shoulder ultrasound images with or without supraspinatus calcific tendinopathy.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Convolutional Neural Networks (CNNs), specifically leveraging pretrained networks such as DenseNet-121, ResNet50, and VGG19. These networks are well-established in the field of medical imaging for their effectiveness in feature extraction and classification tasks.\n\nThe algorithm used is not new; it builds upon existing pretrained networks that have been widely used and validated in various medical imaging applications. DenseNet-121, in particular, was chosen for its dense connectivity pattern, which helps in mitigating the vanishing gradient problem and encourages feature reuse, leading to improved performance.\n\nThe reason this work was not published in a machine-learning journal is that the focus of our study is on the application of these established algorithms to a specific medical problem\u2014diagnosing supraspinatus calcific tendinopathy using ultrasound images. Our contributions lie in the adaptation and evaluation of these models for this particular clinical task, rather than in the development of new machine-learning algorithms. The study aims to demonstrate the practical utility of these models in a real-world medical setting, which is more aligned with the scope of medical imaging and ultrasound journals.",
  "optimization/meta": "The models developed in this study do not function as meta-predictors. They are standalone deep learning models based on convolutional neural networks (CNNs), specifically using DenseNet-121, ResNet50, and VGG19 architectures. These models were trained directly on ultrasound images of the supraspinatus tendon (SST) to detect calcific tendinopathy.\n\nThe study involved training three different models: a longitudinal model, a transverse model, and a longi-trans model. Each of these models was trained on specific views of the SST images. The longitudinal model was trained with longitudinal views, the transverse model with transverse views, and the longi-trans model with a combination of both views. The training data for each model was independent, ensuring that the models learned from distinct datasets.\n\nData augmentation techniques were employed to diversify the ultrasound images and mitigate the impact of data shortage. This included random rotations, width and height shifts, shear, zoom, channel shifts, and horizontal flips. These augmentations helped to simulate variations in patient positioning, physician technique, and differences between ultrasound machines.\n\nThe models were evaluated using metrics such as testing accuracy, sensitivity, and specificity, which were calculated from the confusion matrix. The receiver operating characteristic (ROC) curve and the area under the curve (AUC) were also used as evaluation indices. The longi-trans model, which was trained on both longitudinal and transverse views, demonstrated better performance in diagnosing the existence of calcific tendinopathy across different testing datasets.\n\nIn summary, the models developed in this study are not meta-predictors but rather individual deep learning models trained on specific views of ultrasound images. The training data for each model was independent, and various data augmentation techniques were used to enhance the diversity of the training dataset.",
  "optimization/encoding": "Data encoding and preprocessing were crucial steps in preparing the ultrasound images for the machine-learning algorithm. Initially, a total of 12,366 ultrasound images underwent deidentification to ensure the security of patients' personal information. Each image was then cropped to remove any patient identifications, machine settings, annotations, and scales, ensuring that only the original ultrasound images were included in the dataset. Images with annotations representing the position of calcification, labeled by the original sonographers, were excluded to maintain data integrity.\n\nThe dataset consisted of images from both longitudinal and transverse views of the supraspinatus tendon (SST), with and without calcification. Specifically, there were 780 cases with calcification and 3,784 cases without calcification in the longitudinal view, and 451 cases with calcification and 2,822 cases without calcification in the transverse view.\n\nData augmentation techniques were employed to diversify the ultrasound images and mitigate the impact of data shortage. This involved randomly rotating the images between 0\u00b0 and 40\u00b0 to simulate variations in patient positioning. Additionally, width shift, height shift, shear, and zoom were randomly set between 0 and 0.20 to account for personal variability among physicians. A channel shift of 10 was applied to mimic color variations between different ultrasound machine brands, and horizontal flips were used to simulate variations in medial/lateral orientations of the images.\n\nThe images were then labeled by two physiatrists with extensive experience in musculoskeletal ultrasound. They independently classified the images as either with or without supraspinatus calcific tendinopathy (SSCT). An image was classified as \"with SSCT\" if it showed hyper echoic lesions, with or without acoustic shadowing, within the SST. Any inconsistencies between the physiatrists were resolved through discussion to reach a consensus, ensuring the quality of the training data. Images for which a consensus could not be reached were excluded from the dataset.\n\nThe labeled and preprocessed images were then used to train three different models: the longitudinal model, the transverse model, and the longi-trans model. The longitudinal model was trained using only longitudinal views of the SST images, the transverse model using only transverse views, and the longi-trans model using a combination of both views. This approach allowed for a comprehensive evaluation of the models' performance across different datasets.",
  "optimization/parameters": "In our study, we utilized DenseNet-121 as the primary architecture for our models. DenseNet-121 is a deep convolutional neural network with a significant number of parameters, designed to enhance feature propagation and gradient flow. The original DenseNet-121 architecture, pre-trained on the ImageNet dataset, contains over 7 million parameters.\n\nFor our specific task of classifying supraspinatus tendons with and without calcification, we modified the top fully connected layer of DenseNet-121. For the longitudinal and transverse models, we replaced the original top layer with two classes, while for the longi-trans model, we used four classes. This adjustment was necessary to fit the requirements of our classification problem.\n\nThe selection of DenseNet-121 was driven by its proven performance in medical imaging tasks and its ability to handle complex feature extraction. The architecture's dense connectivity pattern ensures that each layer receives direct input from all preceding layers, which helps in mitigating the vanishing gradient problem and encourages feature reuse. This design choice was crucial for achieving high accuracy and robustness in our models.\n\nAdditionally, we employed data augmentation techniques to diversify the ultrasound images and mitigate the impact of data shortage. This included random rotations, width and height shifts, shear transformations, zoom adjustments, channel shifts, and horizontal flips. These augmentations helped in simulating variations in patient positioning, physician variability, and differences between ultrasound machine brands, thereby enriching the training dataset and improving the model's generalization capabilities.\n\nTo prevent overfitting, we incorporated a dropout layer with a dropout rate of 0.50. This layer randomly deletes half of the hidden neurons during training, which helps in regularizing the model and enhancing its performance on unseen data. The Adam optimizer was used with a learning rate of 10^-5, chosen for its efficiency in handling sparse gradients and noise samples, thereby improving the training process.\n\nThe loss function used was categorical cross-entropy, which is suitable for multi-class classification problems. For the longi-trans model, class weights were automatically adjusted to address the imbalance between different classes, ensuring that the model did not become biased towards the majority class.\n\nIn summary, the parameter selection and model architecture were carefully designed to optimize performance for the classification of supraspinatus tendons with and without calcification. The use of DenseNet-121, along with data augmentation and regularization techniques, contributed to the development of robust and accurate models.",
  "optimization/features": "The input features for our models consist of ultrasound (US) images of the supraspinatus tendons (SST) in both longitudinal and transverse views. Specifically, the dataset includes 133,619 US images from 7836 patients, with 71,659 images in the longitudinal view and 52,010 in the transverse view. These images were labeled as either with or without supraspinatus calcific tendinopathy (SSCT) by two experienced physiatrists.\n\nFeature selection was not explicitly performed in the traditional sense, as the input features are the raw US images themselves. However, data augmentation techniques were employed to diversify the US images and mitigate the impact of data shortage. This process involved random rotations, width and height shifts, shear, zoom, channel shifts, and horizontal flips to simulate variations in image acquisition and different US machine brands. This augmentation effectively increases the richness of the input data without reducing the number of features.\n\nThe labeling process ensured high-quality training data by excluding images where a consensus between the two physiatrists could not be reached. This step is crucial for maintaining the integrity of the input features and ensuring that the models are trained on reliable data. The final dataset used for training, validation, and testing was carefully curated to include a balanced representation of both longitudinal and transverse views, with and without calcification.",
  "optimization/fitting": "The models developed in this study utilized DenseNet-121, a pretrained network with a large number of parameters, which is indeed much larger than the number of training points. To address potential overfitting, several strategies were employed. Firstly, data augmentation techniques were applied to diversify the ultrasound images, including random rotations, shifts, shears, zooms, channel shifts, and horizontal flips. This helped to simulate variations in patient positioning, physician technique, and machine settings, effectively increasing the effective size of the training dataset.\n\nAdditionally, a dropout layer was incorporated into the model architecture. With a dropout rate of 0.50, half of the hidden neurons were randomly deleted during training, which helped to prevent the model from becoming too reliant on specific neurons and thus reduced overfitting. The Adam optimizer was used with a low learning rate of 10^-5, which helped in fine-tuning the model parameters without causing large updates that could lead to overfitting.\n\nTo further mitigate overfitting, categorical cross-entropy was used as the loss function, and class weights were automatically adjusted to handle imbalanced data, particularly in the longi-trans model. The models were trained for 300 epochs, and the three final models with the lowest validation loss were selected, ensuring that the models generalized well to unseen data.\n\nRegarding underfitting, the models were evaluated using multiple metrics, including testing accuracy, sensitivity, and specificity. The high performance of the models on the testing datasets, particularly the longi-trans model, indicates that underfitting was not a significant issue. The use of a pretrained network like DenseNet-121, which has been trained on a large and diverse dataset (ImageNet), provided a strong foundation for the models, reducing the risk of underfitting. The models' ability to achieve high accuracy and low loss on both training and validation datasets further supports this.",
  "optimization/regularization": "In our study, we employed several regularization techniques to prevent overfitting and improve the generalization of our models. One of the key methods used was dropout. Specifically, we implemented a dropout layer with a rate of 0.50, which means that half of the hidden neurons in the network were randomly deleted during each training iteration. This helped to reduce the model's reliance on any single neuron and encouraged it to learn more robust features.\n\nAdditionally, we utilized data augmentation techniques to diversify the ultrasound images and mitigate the impact of data shortage. This involved randomly rotating the images, applying width and height shifts, shear transformations, and zoom adjustments. These augmentations helped the model to generalize better by exposing it to a wider variety of image variations.\n\nFurthermore, we adjusted the class weights automatically to handle imbalanced data, particularly in the longi-trans model. This ensured that the model did not become biased towards the majority class and could effectively learn from all classes.\n\nThese regularization methods collectively contributed to the robustness and reliability of our models, enabling them to perform well on unseen testing data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we utilized DenseNet-121, a pretrained network, and modified its top fully connected layer to suit our classification tasks. For the transverse and longitudinal models, we replaced the top layer with two classes, while for the longi-trans model, we used four classes. A dropout layer with a rate of 0.50 was implemented to prevent overfitting, and the Adam optimizer was employed with a learning rate of 10^-5. Categorical cross-entropy served as the loss function, and class weights were automatically adjusted to handle imbalanced data in the longi-trans model. The models were trained for 300 epochs, and the three models with the lowest validation loss were selected for further evaluation.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the methods and configurations described are sufficient for replication by other researchers. The publication does not specify the availability of model files or optimization parameters under a particular license, but the detailed descriptions of the hyper-parameters and training procedures should enable others to reproduce the models.\n\nNot applicable.",
  "model/interpretability": "The decision-making process of our machine learning models is often considered a \"black box,\" where data is inputted and results are outputted without clear visibility into the intermediate steps. To address this and gain human approval, we employed heatmaps as a visualization tool. Heatmaps are data visualization tools that use different colors to depict data in two dimensions. In our study, we utilized Gradient-weighted Class Activation Mapping to generate these heatmaps. This technique calculates weights through backpropagation and multiplies these weights with feature maps to highlight the importance of regions in the last convolutional layer of the Convolutional Neural Network (CNN). This approach allows us to visualize what the model \"sees\" in the input images, making the decision-making process more transparent. For instance, heatmaps were used to show the areas of the supraspinatus tendon that the model focused on to determine the presence or absence of calcification. This visualization helps in understanding which parts of the image are influential in the model's predictions, thereby opening the \"black box\" and providing insights into the model's internal workings.",
  "model/output": "The model developed in this study is a classification model. It is designed to diagnose the presence or absence of calcification in the supraspinatus tendon (SST) using ultrasound images. The model categorizes the images into two classes: those with calcification and those without. This classification is achieved through the use of convolutional neural networks (CNNs), specifically DenseNet-121, which has been adapted for this medical imaging task. The model's performance is evaluated using metrics such as testing accuracy, sensitivity, and specificity, which are derived from the confusion matrix. Additionally, the receiver operating characteristic (ROC) curve and the area under the curve (AUC) are used to assess the model's discriminative ability. The model's output provides a predicted probability for each class, indicating the likelihood of calcification presence in the SST.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the models involved several key metrics and methods to ensure robust performance assessment. The primary evaluation indices used were testing accuracy, sensitivity, and specificity, all of which were derived from the confusion matrix. This matrix distinguished between supraspinatus tendons (SST) with and without calcification, represented by positive and negative signs, respectively. The gold standard for diagnosing SST with and without calcification was established through a consensus between two experts.\n\nIn addition to these metrics, the receiver operating characteristic (ROC) curve was employed as another evaluation index. The ROC curve plots the false-positive rate against the true positive rate, providing a visual representation of the model's performance. The area under the ROC curve (AUC) was used to quantify this performance, with higher AUC values indicating better model discrimination. Specifically, an AUC greater than 0.90 was considered outstanding, between 0.80 and 0.90 was excellent, and between 0.70 and 0.80 was acceptable. Models with an AUC less than 0.50 were deemed to have no discrimination capability.\n\nTo address the \"black box\" nature of machine learning models, heatmaps were utilized. These visual tools, specifically Gradient-weighted Class Activation Mapping, were employed to highlight the regions of input images that the model focused on during prediction. This approach helped in interpreting the model's decision-making process and gaining human approval.\n\nThe models were trained and evaluated using different datasets, including longitudinal, transverse, and combined (longi-trans) views of SST images. The training, validation, and testing datasets were carefully curated to include a diverse range of images, ensuring that the models could generalize well to new, unseen data. The models were trained for 300 epochs, and the three final models with the lowest validation loss were selected for further evaluation.\n\nThe performance of the models was compared against common pretrained networks such as ResNet50 and VGG19. This comparison helped in evidencing the effectiveness of the DenseNet-121 model used in this study. The evaluation results showed that the models developed with DenseNet-121 had the highest composition of testing accuracy, sensitivity, and specificity among the compared models.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our models. The primary metrics reported include testing accuracy, sensitivity, and specificity, all of which were derived from the confusion matrix. These metrics are widely used in the literature and provide a comprehensive evaluation of model performance.\n\nTesting accuracy measures the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as the true positive rate, indicates the model's ability to correctly identify positive cases (SST with calcification). Specificity, or the true negative rate, reflects the model's ability to correctly identify negative cases (SST without calcification).\n\nAdditionally, we utilized the receiver operating characteristic (ROC) curve and the area under the curve (AUC) as evaluation indices. The ROC curve plots the true positive rate against the false positive rate at various threshold settings, providing a visual representation of the model's diagnostic ability. The AUC quantifies the overall ability of the model to discriminate between positive and negative cases. An AUC greater than 0.90 indicates outstanding discrimination, between 0.80 and 0.90 indicates excellent discrimination, and between 0.70 and 0.80 indicates acceptable discrimination. Models with an AUC less than 0.50 have no discrimination capability.\n\nThese metrics collectively offer a robust assessment of our models' performance, ensuring that our findings are both reliable and comparable to other studies in the field. The use of these standard metrics allows for a clear and concise evaluation of our models' diagnostic accuracy and effectiveness in identifying SST with and without calcification.",
  "evaluation/comparison": "In our study, we compared the performance of our models developed with DenseNet-121 against other commonly used pretrained networks in medical imaging classification, specifically ResNet50 and VGG19. This comparison was conducted to provide evidence of the effectiveness of our chosen model architecture.\n\nWe evaluated the models using several key metrics, including testing accuracy, sensitivity, and specificity, which were derived from the confusion matrix. The confusion matrix helped us assess the models' performance in diagnosing supraspinatus tendons (SST) with and without calcification. Additionally, we used the receiver operating characteristic (ROC) curve and the area under the curve (AUC) as evaluation indices. The ROC curve provided a graphical representation of the models' performance, with the AUC indicating the models' discriminative ability.\n\nThe comparison involved testing the models against different datasets, including longitudinal views, transverse views, and a combination of both. This approach allowed us to assess the models' performance across various scenarios and views of the SST.\n\nOur findings indicated that the models developed with DenseNet-121 generally presented the highest composition of testing accuracy, sensitivity, and specificity among the three pretrained models. This superior performance led us to focus on the DenseNet-121 models for further analysis and evaluation.\n\nIn summary, we performed a comprehensive comparison of our models against established baselines, using well-defined evaluation metrics and diverse datasets. This comparison provided a robust assessment of our models' performance and their potential for diagnosing supraspinatus calcific tendinopathy in ultrasound images.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not enough information is available."
}