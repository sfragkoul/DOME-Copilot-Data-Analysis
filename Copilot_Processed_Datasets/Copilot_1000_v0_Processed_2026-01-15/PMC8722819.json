{
  "publication/title": "Using Machine Learning to Construct Nomograms for Patients with Metastatic Colon Cancer",
  "publication/authors": "The authors who contributed to the article are:\n\nBeiqun Zhao, MD MAS, who is the corresponding author and likely played a significant role in the conception, design, and execution of the study, as well as the writing and editing of the manuscript. Beiqun Zhao is affiliated with the Department of Surgery, University of California San Diego.\n\nRodney A. Gabriel, MD MAS, who is affiliated with the Department of Anesthesiology, University of California San Diego.\n\nFlorin Vaida, PhD, who is affiliated with the Department of Family Medicine and Public Health, University of California San Diego.\n\nSamuel Eisenstein, MD, who is affiliated with the Department of Surgery, University of California San Diego. Dr. Eisenstein is a consultant for Auris Health, which had no involvement in this manuscript.\n\nGabriel T. Schnickel, MD MPH, who is affiliated with the Department of Surgery, University of California San Diego.\n\nJason K. Sicklick, MD, who is affiliated with the Department of Surgery, University of California San Diego.\n\nBryan M. Clary, MD MBA, who is affiliated with the Department of Surgery, University of California San Diego.",
  "publication/journal": "Colorectal Disease",
  "publication/year": "2022",
  "publication/pmid": "31991031",
  "publication/pmcid": "PMC8722819",
  "publication/doi": "10.1111/codi.14991",
  "publication/tags": "- Colorectal cancer\n- Metastatic colon cancer\n- Machine learning\n- Predictive modeling\n- Nomograms\n- Overall survival\n- Cancer prognosis\n- Shared decision-making\n- Oncology\n- Surgical outcomes\n- Data analysis\n- Healthcare prediction\n- Cancer treatment\n- Medical algorithms\n- Clinical outcomes",
  "dataset/provenance": "The dataset used in this study was sourced from the National Cancer Database (NCDB), a comprehensive oncology outcomes database jointly sponsored by the American College of Surgeons\u2019 Commissions on Cancer (CoC) and the American Cancer Society. The NCDB contains clinical oncology data from over 1,500 CoC-accredited centers, representing more than 70% of newly diagnosed cancer cases nationwide.\n\nThe initial dataset included 761,528 patients with colon cancer. From this, 53,107 patients with synchronous metastatic disease were identified. After applying exclusion criteria to ensure data completeness and relevance, a total of 19,324 patients were included in the final analysis. This cohort was further divided into training and testing datasets. Specifically, 6,432 patients with right colon cancer and 4,918 patients with left colon cancer were included in the training dataset. The testing dataset consisted of 4,586 patients with right colon cancer and 3,428 patients with left colon cancer.\n\nThe NCDB has been widely used in previous research and by the community for various studies on cancer outcomes, making it a reliable and well-established source for this analysis. The dataset's extensive coverage and detailed clinical information make it particularly valuable for developing predictive models in oncology.",
  "dataset/splits": "The dataset was split into two main groups: a training set and a testing set. The training set included patients diagnosed between 2010 and 2012, while the testing set included patients diagnosed between 2013 and 2014.\n\nFor right colon cancer, the training set consisted of 6,432 patients, and the testing set consisted of 4,586 patients. For left colon cancer, the training set consisted of 4,918 patients, and the testing set consisted of 3,428 patients.\n\nThe splits were made to ensure that the models could be trained on one subset of data and then validated on another, independent subset. This approach helps in assessing the generalizability and performance of the predictive models. The median overall survival (OS) was compared between the training and testing datasets using Kaplan-Meier analysis with log-rank testing. For the right colon cohort, the median OS for the training group was significantly shorter compared to the testing group. For the left colon cohort, there was no significant difference in median OS between the training and testing groups.",
  "dataset/redundancy": "The datasets were split into distinct training and testing sets to evaluate the performance of our predictive models. For the right colon cancer cohort, 6,432 patients were included in the training dataset, and 4,586 patients were in the testing dataset. Similarly, for the left colon cancer cohort, 4,918 patients were in the training dataset, and 3,428 patients were in the testing dataset. This split was done to ensure that the training and testing sets were independent, allowing for an unbiased evaluation of the models' performance.\n\nTo enforce the independence of the training and testing sets, we did not use any overlapping patients between these two groups. This approach helps to prevent data leakage, where information from the testing set might inadvertently influence the training process, leading to overly optimistic performance estimates.\n\nThe distribution of patients in our datasets is comparable to previously published machine learning datasets in the context of metastatic colon cancer. The large sample size, derived from the National Cancer Database (NCDB), which covers over 70% of cancer diagnoses in the United States, ensures that our datasets are representative of the broader patient population. This extensive coverage helps to mitigate concerns about dataset redundancy and ensures that our models are generalizable to new, unseen data.\n\nAdditionally, we performed a pooled cohort analysis that included patients with both right and left colon primary tumor sites. In this analysis, the location of the primary tumor was used as a predictor within the model. This approach further validates the independence and representativeness of our datasets, as it allows for a comprehensive evaluation of the models' performance across different tumor locations.",
  "dataset/availability": "The data used in this study is from the National Cancer Database (NCDB), which covers over 70% of cancer diagnoses in the United States. The specific dataset used for this analysis is not publicly available due to the sensitive nature of the patient information contained within it. The NCDB is a joint program of the Commission on Cancer of the American College of Surgeons and the American Cancer Society. Access to the NCDB data is restricted and requires approval from the NCDB.\n\nThe dataset was split into training and testing sets based on the diagnosis year, with the training set including patients diagnosed from 2010 to 2012 and the testing set including patients diagnosed from 2013 to 2014. This split was enforced by the study design to ensure that the models were trained on older data and tested on more recent data, simulating a real-world scenario where the model would be applied to new, unseen patients.\n\nThe data splits used in this study are not released in a public forum due to the aforementioned restrictions on the NCDB data. The specific splits and the data itself are not available for public download or use. The analysis and results presented in this study are based on the approved use of the NCDB data, and the data splits were enforced by the study protocol and the requirements of the NCDB.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the lasso regression, which is a type of linear regression that includes a penalty term to enforce sparsity in the model. This means it can effectively select important predictors and discard unimportant ones, making the model more interpretable and reducing overfitting.\n\nThe lasso algorithm is not new; it has been well-established in the field of statistics and machine learning. It was first introduced by Robert Tibshirani in 1996 and has since been widely used and studied. The lasso algorithm is particularly useful in high-dimensional data settings where the number of predictors is large compared to the number of observations.\n\nThe reason the lasso algorithm was not published in a machine-learning journal in this context is that our primary focus was on applying established machine-learning techniques to improve predictive modeling in oncology, specifically for patients with metastatic colon cancer. The lasso algorithm was chosen for its ability to handle high-dimensional data and its interpretability, which are crucial for building user-friendly nomograms. Our contribution lies in the application of this algorithm to a specific clinical problem, rather than the development of a new algorithm. The emphasis was on demonstrating the superiority of machine-learning techniques over traditional multivariable regression methods in predicting overall survival in this patient population.",
  "optimization/meta": "Not applicable. The study does not discuss the use of a meta-predictor. The models were constructed using machine learning techniques, specifically the lasso algorithm, but there is no indication that the models use data from other machine-learning algorithms as input. The study focuses on building predictive nomograms for 3-year overall survival in patients with metastatic colon cancer using a single machine learning approach. The datasets were split into training and testing cohorts, with internal and external validation performed to assess the models' performance. However, the study does not mention the use of multiple machine-learning methods or the combination of their outputs to create a final prediction.",
  "optimization/encoding": "The data used for the machine-learning algorithm was sourced from the National Cancer Database, which contains clinical oncology data from over 1,500 accredited centers. The dataset included patients diagnosed with metastatic colon adenocarcinoma between 2010 and 2014. Patients with non-metastatic disease were excluded, and the primary tumor was identified using specific histology codes.\n\nThe dataset was split into two cohorts based on the laterality of the primary tumor: right colon (RC) and left colon (LC). The right colon was defined as the caecum to the transverse colon, while the left colon was defined as the splenic flexure to the sigmoid colon. Patients with overlapping tumors and non-otherwise-specified locations were excluded from the analysis.\n\nVariables were selected based on clinical significance and availability within the database. These variables included patient age, Charlson-Deyo Comorbidity Score, tumor grade, CEA level, tumor size, metastasis sites, resection status, number of positive lymph nodes, and chemotherapy status. The CEA level was split into approximate quartiles, and tumor size was categorized into specific ranges. Metastasis sites were reported as binary variables, and the number of positive lymph nodes was reported as a continuous variable. Chemotherapy was dichotomized into no chemotherapy versus any type of chemotherapy.\n\nFor all variables, patients with unknown data points were excluded from the analysis. The dataset was further split into a training set (diagnosis years 2010-2012) and a testing set (2013-2014). Differences between the training and testing sets were evaluated using appropriate statistical tests. The nomograms were created using a 10-fold cross-validated Cox proportional hazard regression with lasso regression, which performs variable selection and regularization to build accurate and generalizable models. The predictive outcome was the probability of overall survival at 3 years.",
  "optimization/parameters": "In our study, the number of input parameters used in the model was determined through a process of variable selection and regularization using the lasso algorithm. The lasso, or least absolute shrinkage and selection operator, is a machine-learning technique that performs both variable selection and regularization. This means it reduces the number of predictors by removing non-significant ones and decreases each predictor's ability to affect the predicted outcome, thereby building accurate models that are generalizable.\n\nWe started with a set of clinically significant variables available within the National Cancer Database (NCDB). These variables included patient age, Charlson-Deyo Comorbidity Score, tumor grade, CEA level, tumor size, metastasis sites (liver, lung, brain, bone, peritoneum), resection status, number of positive lymph nodes, and chemotherapy status. Each of these variables was carefully selected based on their clinical relevance and availability in the dataset.\n\nThe lasso algorithm was then applied to these variables to perform variable selection. This process involved subjecting the predictors for overall survival to selection and regularization within a 10-fold cross-validated Cox proportional hazard regression framework. The lasso effectively reduced the number of predictors by eliminating those that did not significantly contribute to the model's predictive accuracy. This ensured that the final model was parsimonious and focused on the most relevant predictors.\n\nAs a result, the final models for right colon (RC) and left colon (LC) cohorts included only the most important predictors, making the nomograms both accessible and accurate. The exact number of parameters (p) retained in the final models varied based on the contributions of each predictor to the overall survival outcomes. This approach allowed us to build models that were not only predictive but also clinically meaningful and user-friendly.",
  "optimization/features": "The study utilized several input features for constructing the predictive models. These features were selected based on their clinical significance and availability within the National Cancer Database (NCDB). The specific features included patient age, Charlson-Deyo Comorbidity Score, tumor grade, highest pre-treatment CEA level, tumor size, metastasis status to various organs (liver, lung, brain, bone, and peritoneum), resection status of the primary tumor and metastatic sites, number of positive lymph nodes, and chemotherapy administration.\n\nFeature selection was performed using the lasso (least absolute shrinkage and selection operator) regression technique. This method is a machine-learning approach that combines variable selection and regularization. It helps in reducing the number of predictors by removing non-significant ones, thereby preventing overfitting and ensuring that the model is both accurate and generalizable. The lasso regression was applied within a 10-fold cross-validated Cox proportional hazard regression framework. This process was conducted using the training set only, ensuring that the feature selection was independent of the testing set, thus maintaining the integrity of the validation process.",
  "optimization/fitting": "The fitting method employed in our study involved the use of machine learning algorithms to construct predictive models for overall survival in patients with metastatic colon cancer. The number of parameters in our models was not excessively large compared to the number of training points, as we utilized the lasso algorithm to select important predictors and discard unimportant ones. This approach helped to prevent overfitting by simplifying the model and reducing the number of parameters.\n\nTo further ensure that our models were not overfitting, we performed both internal and external validation. Internal validation involved calculating time-dependent c-indexes at 1, 2, and 3 years using the training dataset. External validation was conducted using a separate testing dataset, which allowed us to assess the generalizability of our models. The consistent performance of our models across both internal and external validation suggests that overfitting was not a significant concern.\n\nUnderfitting was addressed by carefully selecting relevant predictors and using a robust machine learning algorithm. The lasso algorithm helped to identify the most important predictors, ensuring that the models were complex enough to capture the underlying patterns in the data. Additionally, the use of a large and diverse dataset from the National Cancer Database (NCDB) provided a comprehensive training set, which helped to mitigate the risk of underfitting.\n\nIn summary, the fitting method involved the use of the lasso algorithm to select important predictors and prevent overfitting, along with rigorous internal and external validation to ensure the models' generalizability and accuracy. The careful selection of predictors and the use of a large dataset helped to address the risk of underfitting.",
  "optimization/regularization": "In our study, we employed a regularization method to prevent overfitting and improve the generalizability of our predictive models. Specifically, we used the lasso (least absolute shrinkage and selection operator) regression technique. The lasso is a machine-learning method that performs both variable selection and regularization. Variable selection helps in reducing the number of predictors by removing non-significant ones, while regularization decreases the impact of each predictor on the predicted outcome. This dual approach ensures that the model is accurate without under-fitting or over-fitting the training data. By integrating the lasso with Cox proportional hazard analysis, we were able to build models that predict overall survival at 3 years with high accuracy and reliability. This method allowed us to create nomograms that are both accessible and precise, making them valuable tools for clinicians and patients in the shared decision-making process.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The models developed in this study are not black-box but rather transparent and interpretable. This transparency is achieved through the use of nomograms, which are graphical representations of complex mathematical formulas. Nomograms are designed to be user-friendly and approachable, making them accessible to both clinicians and patients. This is particularly important in oncology, where shared decision-making is crucial.\n\nThe nomograms created in this study allow for a clear understanding of how different predictors contribute to the overall survival probability. For instance, a 70-year-old patient with poorly-differentiated right colon cancer, specific pre-operative CEA levels, synchronous liver metastasis, and other clinical factors can have their individual points calculated and summed to predict their 3-year overall survival. This process makes it evident how each variable influences the final prediction, providing a transparent view of the model's decision-making process.\n\nMoreover, the use of the lasso algorithm helps in simplifying the nomograms by dropping \"unimportant\" predictors while maintaining predictive accuracy. This ensures that the nomograms remain accessible and easy to interpret, even when dealing with a large number of potential predictors. The lasso algorithm's ability to select relevant features and assign them appropriate weights further enhances the transparency of the models.\n\nIn summary, the models are designed to be interpretable, with nomograms serving as a clear and accessible tool for both clinicians and patients. The use of the lasso algorithm and the graphical representation of predictors contribute to the transparency and interpretability of the models.",
  "model/output": "The model developed in this study is a regression model. Specifically, it is a predictive nomogram for 3-year overall survival in patients with metastatic colon cancer. The model uses Cox proportional hazard regression with lasso regression to predict the probability of survival at 3 years. This type of model is used to estimate the time to an event, in this case, survival, rather than classifying patients into distinct categories. The output of the model is a continuous probability of survival, which is then translated into a nomogram for ease of use by clinicians and patients. The nomogram assigns points to various predictors, such as age, tumor characteristics, and metastatic sites, which are summed to provide a predicted probability of 3-year overall survival. This approach allows for a more nuanced understanding of a patient's prognosis compared to a simple classification model. The model's performance was evaluated using both calibration and validation methodologies, including the concordance index (c-index), to ensure its accuracy and reliability.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our predictive models involved both calibration and validation processes. For external calibration, we stratified the test dataset into five risk groups based on the probability of overall survival (OS) and compared the predicted versus actual probability of OS at three years for each group. This approach allowed us to assess how well our models' predictions aligned with actual outcomes.\n\nIn terms of validation, we conducted both internal and external validation. Internal validation was performed using time-dependent c-indexes at one, two, and three years. These c-indexes provided a measure of the model's discriminative ability over time within the training dataset. External validation involved applying the models to an independent testing dataset and calculating the c-indexes at the same time points. This step was crucial for evaluating the generalizability and robustness of our models.\n\nAdditionally, we performed a pooled cohort analysis that included patients with both right and left colon primary tumor sites. In this analysis, the location of the primary tumor was used as a predictor within the model. Internal and external validation, as well as external calibration, were also conducted on this pooled cohort to ensure the models' performance was consistent across different patient groups.\n\nAll statistical and machine-learning analyses were carried out using R (Version 3.3.2) and the R package hdnom. The level of significance was set at 0.05, and all comparisons were two-tailed. This rigorous evaluation process ensured that our models were thoroughly tested and validated, providing reliable predictions for overall survival in patients with metastatic colon cancer.",
  "evaluation/measure": "In our study, we employed a comprehensive set of performance metrics to evaluate the predictive models for patients with metastatic colon cancer. The primary metrics reported include time-dependent c-indexes and external calibration.\n\nThe time-dependent c-indexes were calculated at 1, 2, and 3 years for both internal and external validation. These indexes provide a measure of the model's discriminative ability over time, indicating how well the model can distinguish between patients who will experience the event (in this case, death) and those who will not. For the right colon cohort, the internal validation c-indexes were 0.792 at 1 year, 0.768 at 2 years, and 0.754 at 3 years. The external validation c-indexes for the same cohort were 0.804, 0.775, and 0.794, respectively. For the left colon cohort, the internal validation c-indexes were 0.821 at 1 year, 0.782 at 2 years, and 0.768 at 3 years, with external validation c-indexes of 0.801, 0.774, and 0.761, respectively.\n\nIn addition to the c-indexes, we performed external calibration to assess the accuracy of the predicted probabilities of overall survival (OS) at 3 years. The test dataset was stratified into five risk groups based on the probability of OS, and the predicted versus actual probabilities were compared. This calibration process helps ensure that the model's predictions are well-calibrated, meaning that the predicted probabilities closely match the actual observed outcomes.\n\nThese performance metrics are representative of those commonly used in the literature for evaluating predictive models in oncology. The time-dependent c-index is a widely accepted measure of model discrimination, while external calibration is crucial for assessing the clinical utility of the model's predictions. By reporting both internal and external validation results, we provide a robust evaluation of our models' performance and generalizability.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on developing and validating machine learning nomograms specifically for predicting survival in patients with metastatic colon cancer. We utilized a large dataset from the National Cancer Database (NCDB), which covers over 70% of cancer diagnoses in the United States, to ensure the robustness of our models.\n\nHowever, we did compare our models' performance internally and externally. Internal validation was conducted using time-dependent c-indexes at 1, 2, and 3 years, which provided a measure of the models' discriminatory ability. External validation was performed by stratifying the test dataset into five risk groups based on the probability of overall survival (OS) and comparing the predicted versus actual probability of OS at 3 years for each risk group.\n\nAdditionally, we performed a pooled cohort analysis that included patients with both right and left colon primary tumor sites. This analysis helped justify splitting the datasets by laterality and provided further validation of our models.\n\nWhile we did not compare our methods to simpler baselines, our models demonstrated superior performance compared to previous predictive models for metastatic colon cancer. The use of machine learning techniques allowed us to create nomograms that can be easily accessible to patients and clinicians, aiding in the shared decision-making process. Future efforts will concentrate on disseminating these models through various media, such as smartphone apps.",
  "evaluation/confidence": "The evaluation of our predictive models included both calibration and validation processes. For internal and external validation, we reported time-dependent c-indexes at 1, 2, and 3 years, which are accompanied by 95% confidence intervals. These intervals provide a range within which the true c-index is likely to fall, giving an indication of the precision of our estimates.\n\nFor the right colon cohort, the internal validation c-indexes at 1, 2, and 3 years were 0.792 (95% CI 0.789 \u2013 0.795), 0.768 (95% CI 0.765 \u2013 0.771), and 0.754 (95% CI 0.749 \u2013 0.757), respectively. Similarly, for the left colon cohort, the internal validation c-indexes at 1, 2, and 3 years were 0.821 (95% CI 0.818 \u2013 0.824), 0.782 (95% CI 0.781 \u2013 0.785), and 0.768 (95% CI 0.766 \u2013 0.771), respectively. These confidence intervals help to assess the reliability of our model's performance metrics.\n\nIn terms of statistical significance, we set the level of significance at 0.05 for all comparisons. For example, in the right colon cohort, the median overall survival (OS) for the training group was significantly shorter compared to the testing group (p=0.007). However, for the left colon cohort, there was no significant difference in median OS between the training and testing groups (p=0.165). This indicates that while some differences are statistically significant, others are not, which is important to consider when claiming superiority over other methods or baselines.\n\nExternal calibration was also performed, stratifying the test dataset into 5 risk groups by the probability of OS. The predicted versus actual probability of OS at 3 years was reported for each risk group. In this analysis, there was no significant difference in the predicted 3-year OS from the models compared to the actual 3-year OS in the test dataset for 4 out of 5 risk groups. For the risk group that was significantly different, the model under-predicted the 3-year OS in both the right and left colon cohorts. This suggests that while our models generally perform well, there is room for improvement in certain risk groups.\n\nOverall, the inclusion of confidence intervals and the consideration of statistical significance in our evaluation provide a robust assessment of our models' performance. This allows for a more nuanced understanding of our results and helps to ensure that any claims of superiority are supported by strong evidence.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data originates from the National Cancer Database (NCDB), which is a joint program of the Commission on Cancer (CoC) of the American College of Surgeons and the American Cancer Society. Access to the NCDB data is restricted and requires approval from the CoC. Therefore, the specific datasets used for training and testing our models cannot be publicly released due to these restrictions.\n\nThe NCDB data is highly sensitive and contains protected health information. To ensure patient privacy and comply with regulatory requirements, the data is not made publicly available. Researchers interested in accessing the NCDB data must submit a formal request to the CoC and obtain approval. This process involves demonstrating the scientific merit of the proposed research and ensuring that appropriate measures will be taken to protect patient confidentiality.\n\nWhile the raw evaluation files are not available, the methods and results of our study are thoroughly documented in the publication. This includes detailed descriptions of the data preprocessing steps, the machine-learning algorithms used, and the evaluation metrics employed. Additionally, the statistical analyses were performed using R (Version 3.3.2) and the R package hdnom, which are publicly available tools. Researchers can replicate the analytical approach using these tools and their own datasets, provided they adhere to the ethical and regulatory guidelines for handling sensitive health information."
}