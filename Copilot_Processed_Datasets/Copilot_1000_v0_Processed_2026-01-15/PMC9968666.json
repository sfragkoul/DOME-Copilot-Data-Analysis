{
  "publication/title": "A machine learning approach to predicting the issuance of stay-at-home orders during the initial wave of COVID-19 in African countries",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "International Journal of Disaster Risk Reduction",
  "publication/year": "2023",
  "publication/pmid": "36875319",
  "publication/pmcid": "PMC9968666",
  "publication/doi": "10.1016/j.ijdrr.2023.103598",
  "publication/tags": "- COVID-19\n- Stay-at-Home Orders\n- Machine Learning\n- Random Forest Classifier\n- Public Health Policy\n- African Countries\n- Data-Driven Approach\n- Predictive Modeling\n- Health Policy Research\n- Disaster Risk Reduction",
  "dataset/provenance": "The dataset utilized in this study is composed of 88 variables, which were derived from a comprehensive initial collection of 227 independent variables sourced from 10 different datasets. To ensure data integrity, variables with missing values for any country were excluded, and duplicate variables were removed. The final dataset includes variables from six well-regarded sources: the World Bank, World Health Organization, United Nations, Database of Political Institutions, and the Sustainable Development Solutions Network. The most current data available, primarily from 2018 or 2019, were used, with a cutoff of 2015 for the earliest data points.\n\nThe dependent variable, sahoStatus, indicates whether a country issued a Stay-At-Home Order (SAHO) during the specified period. Data collection focused on African countries, with observations spanning from January 31 to June 15, 2020. This period was chosen because it encompasses the time from the World Health Organization's declaration of a public health emergency related to COVID-19 to approximately 30 days after the last African country issued a SAHO during the first wave of the pandemic.\n\nTo balance the outcome categories for the random forest algorithm, the dataset was structured to include 27 observations of countries that issued a SAHO and 27 that did not. The observations for countries that issued a SAHO were recorded on the specific day the SAHO was issued, while for countries that did not issue a SAHO, observations were recorded on randomly selected days when no SAHO was in effect. This approach ensures a balanced dataset, which is crucial for the efficient performance of the random forest classifier.\n\nThe dataset's heterogeneity is a strength, as it includes a wide range of variables capturing political, scientific, social, economic, and external factors. This comprehensive approach allows for a more nuanced understanding of the factors influencing the issuance of SAHOs, beyond what traditional regression models might offer. The use of well-known primary data sources ensures the reliability and validity of the dataset, making it a robust tool for analyzing the determinants of SAHO issuance during the COVID-19 pandemic.",
  "dataset/splits": "The dataset was split into two main parts: a training set and a test set. The training set consisted of approximately 75% of the total sample, which amounted to 40 randomly selected countries. The test set comprised the remaining 25%, totaling 14 countries. These splits were fixed throughout the study to ensure consistency in the analysis.\n\nThe dependent variable, sahoStatus, was coded as 1 for countries that issued a Stay-At-Home Order (SAHO) and 0 for those that did not. To balance the outcome categories for the random forest algorithm, a dataset was created with 27 observations of countries that had issued a SAHO and 27 that had not. The 27 observations of countries that issued a SAHO were randomly selected from the 41 countries that did so during the evaluation period. The recorded variable values for these countries were taken from the day they issued their SAHO. Similarly, the 27 observations of countries that had not issued a SAHO were randomly selected, and the recorded variable values were from randomly chosen days when they had not issued a SAHO. This approach ensured that the dataset was balanced and suitable for the random forest algorithm, which performs more efficiently with a balanced distribution of outcome categories.",
  "dataset/redundancy": "The dataset used in this study was initially collected from various well-regarded sources, including the World Bank, World Health Organization, United Nations, Database of Political Institutions, and the Sustainable Development Solutions Network. From an initial collection of 227 independent variables from 10 datasets, the size of the input data was reduced to 105 variables by dropping all variables for which a country was missing a value. After removing duplicate variables, the final dataset contained 88 variables from six datasets.\n\nThe dependent variable, sahoStatus, was coded as 1 when a country had issued a Stay-At-Home Order (SAHO) and 0 when it had not. The dataset included observations from 54 African countries between January 31 and June 15, 2020. To ensure a balanced dataset, 27 observations of countries that had issued a SAHO were randomly selected from the full list of 41 countries that issued a SAHO during the evaluation period. Similarly, 27 observations of countries that had not issued a SAHO were randomly selected. The recorded variable values for these countries were observations on randomly selected days when they had not issued a SAHO.\n\nThe dataset was split into training and test sets to evaluate the model's performance. Approximately 75% of the total sample, consisting of 40 randomly selected countries, was used as the training set. The remaining 25%, comprising 14 countries, served as the test set. This split ensured that the training and test sets were independent, minimizing the risk of data leakage and overfitting. The training set was used to train the random forest model, while the test set was used to evaluate its predictive accuracy.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in terms of heterogeneity and comprehensiveness. The African countries included in the study exhibit high levels of social, political, and economic diversity, which is crucial for avoiding model overfit and ensuring that the algorithm can correctly categorize observations outside the given sample. This heterogeneity increases the likelihood that the findings will generalize to other contexts, making the dataset robust and reliable for machine learning applications.",
  "dataset/availability": "The data used in this study is not publicly available in a forum. However, it will be made available upon request. This approach ensures that the data can be accessed by other researchers for verification or further analysis while maintaining control over its distribution. The decision to provide data upon request helps to manage the data's integrity and usage, ensuring that it is used responsibly and ethically. This method also allows for direct engagement with researchers who may have specific needs or questions related to the data, facilitating more targeted and effective data sharing.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the random forest classifier, which is a well-established ensemble learning method. This algorithm is not new; it has been widely used and studied in various fields, including economics, political science, and public health research. The random forest classifier is particularly advantageous for our study due to its robustness to outliers and the distributional properties of independent variables. It is also less constrained by small sample sizes, making it suitable for our dataset of 54 African countries.\n\nThe reason this algorithm was not published in a machine-learning journal is that our primary focus is on applying machine learning to health policy research, specifically to predict the issuance of COVID-19-related stay-at-home orders (SAHOs) in African countries. Our contribution lies in demonstrating the effectiveness of the random forest classifier in this specific context, rather than in developing a new machine-learning algorithm. By leveraging this established method, we aim to provide insights into public health policy-making and to validate existing theories through a data-driven approach.",
  "optimization/meta": "The model employed in this study does not function as a meta-predictor. Instead, it relies on a single machine learning approach, specifically the random forest classifier. This method is used to predict the issuance of stay-at-home orders (SAHOs) during the initial wave of COVID-19 in African countries.\n\nThe random forest classifier is a robust technique that leverages multiple decision trees to improve predictive accuracy and control overfitting. Each decision tree in the random forest is trained on a subset of the initial training set, chosen through random sampling with replacement. Additionally, each tree randomly selects a subset of features to calculate splits, further enhancing the model's robustness.\n\nThe training data for the random forest model is clearly defined and independent. The dataset consists of information from 54 African countries, with 40 countries used as the training set and the remaining 14 countries reserved for testing. This separation ensures that the training and test sets do not overlap, maintaining the independence of the training data.\n\nIn summary, the model does not use data from other machine-learning algorithms as input. It is solely based on the random forest classifier, which is trained and tested on independent datasets to ensure reliable and generalizable results.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for analysis. Initially, a comprehensive dataset was compiled, consisting of 88 heterogeneous variables that captured country-level information across various domains, including political, scientific, social, economic, and external issues. These variables were sourced from well-regarded primary data sources such as the European Centre for Disease Prevention and Control, State Fragility Index, World Bank, and World Health Organization.\n\nTo handle missing data, variables for which any country was missing a value were dropped, reducing the dataset from an initial 227 variables to 105. Duplicate variables were also removed, resulting in the final dataset of 88 variables from six different datasets. The most current year available for each measure was used, with the majority of measures from 2018 or 2019.\n\nThe dependent variable, sahoStatus, was coded as 1 when a country had issued a stay-at-home order (SAHO) and 0 when it had not. The dataset included observations for 54 African countries between January 31 and June 15, 2020. To balance the outcome categories for the random forest algorithm, a dataset was created with 27 observations of countries that had issued a SAHO and 27 that had not. For countries that issued a SAHO, the recorded variable values were from the day the SAHO was issued. For countries that did not issue a SAHO, the recorded variable values were from randomly selected days within the evaluation period.\n\nThis preprocessing ensured that the data was clean, comprehensive, and balanced, making it suitable for the random forest classifier. The random forest algorithm was then employed to identify the most significant predictors of the issuance of SAHOs, leveraging the preprocessed data to achieve high predictive accuracy.",
  "optimization/parameters": "In our study, we employed a random forest algorithm to identify and select the most important variables for predicting the issuance of Stay-at-Home Orders (SAHOs) during the initial wave of COVID-19 in African countries. Initially, we considered a total of 88 variables. To minimize biases and overfitting, we implemented a Monte-Carlo approach with 1000 iterations, recording the top 50 variables ranked by importance in each iteration. From these iterations, we retained the top 30 variables based on their mean feature importance scores. This subset of 30 variables was then used in the final implementation of the random forest algorithm to determine the final feature importance values.\n\nThe selection of the top 30 variables was crucial for optimizing the model's predictive accuracy. We found that using 10 variables was sufficient to achieve a predictive f1-score of greater than 78%. Increasing the number of variables beyond this point did not significantly improve the model's predictive power. This indicates that the selected 10 variables are the most critical for predicting SAHOs in our dataset.\n\nThe final model, which includes these top 10 variables, demonstrated a substantial increase in predictive accuracy compared to simpler models. Specifically, it provided a 56% increase in accuracy over predicting the modal outcome. This highlights the effectiveness of our variable selection process and the robustness of the random forest model in handling small datasets.",
  "optimization/features": "In the optimization process, we initially considered a total of 88 variables as potential input features. To identify the most relevant features, we employed a Monte-Carlo implementation of the random forest algorithm. This feature selection process was conducted using only the training set, which consisted of approximately 75% of the total sample, specifically 40 randomly selected countries. The feature selection was performed in two stages. In the initial stage, we ran 1000 iterations of the random forest algorithm using all 88 variables. At each iteration, we recorded the top 50 variables ranked by their importance. After these iterations, we retained the top 30 variables based on their mean feature importance score across all runs. In the final stage, we reran the Monte-Carlo implementation using only these top 30 variables to determine their final importance scores. This approach ensured that the feature selection was robust and minimized the risk of overfitting. Ultimately, we found that using 10 variables was sufficient to achieve a predictive f1-score of greater than 78%, indicating that these 10 variables were the most critical for predicting the issuance of SAHOs.",
  "optimization/fitting": "The fitting method employed in this study utilized a random forest algorithm, which is well-suited for handling datasets with a large number of parameters relative to the number of training points. The random forest approach leverages bootstrap aggregation (bagging) and random feature selection to mitigate overfitting. Specifically, each decision tree in the random forest is trained on a subset of the initial training set chosen by random sampling with replacement. Additionally, each tree randomly selects a subset of features on which it calculates splits, further reducing the risk of overfitting.\n\nTo optimize the decision tree algorithm for predictive accuracy, a maximum recursion level of 30 was applied, along with standard automatic pruning as implemented in sklearn. This pruning process helps to prevent the model from becoming too complex and overfitting the training data. The implementation used 50 decision trees, and the feature selection algorithm was split into two parts: initial variable selection and final importance calculation. During the initial variable selection, a Monte-Carlo implementation of the random forest algorithm with 1000 iterations was used, recording the top 50 variables ranked by importance. After 1000 runs, the top 30 variables were retained based on their mean feature importance score. For the final calculation, the Monte-Carlo implementation was run again using only the top 30 variables to determine the final feature importance values.\n\nThe model's performance was evaluated using the weighted f1-score, which is a standard metric in machine learning. The f1-score was computed for configurations retaining 1, 5, 10, 15, 20, 25, and 30 variables. It was found that 10 variables were sufficient to achieve a predictive f1-score of greater than 78%. Increasing the number of variables did not meaningfully improve the predictive power, indicating that the model was not underfitting. The random forest classifier's ability to handle small datasets and minimize biases resulting from the data structure further supports the robustness of the fitting method.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our model. One of the primary methods used was the random forest algorithm, which inherently helps to reduce overfitting through its ensemble learning approach. This algorithm combines multiple decision trees, each trained on a different subset of the data, to make predictions. By averaging the results of these trees, the random forest model reduces the risk of overfitting to the training data.\n\nAdditionally, we implemented automatic pruning in our decision trees. Pruning involves removing parts of the tree that do not provide power in predicting target variables. This technique helps to simplify the model and prevent it from becoming too complex and overfitting the training data.\n\nFurthermore, we used a Monte-Carlo implementation of the random forest algorithm with 1000 iterations. This approach involves repeatedly sampling the data and training the model on these samples, which helps to stabilize the results and reduce the variance, thereby mitigating overfitting.\n\nTo further control overfitting, we limited the maximum recursion level of the decision trees to 30. This constraint prevents the trees from growing too deep and capturing noise in the training data.\n\nLastly, we split our feature selection algorithm into two parts: initial variable selection and final importance calculation. During the initial variable selection, we applied the Monte-Carlo implementation of the random forest algorithm with all 88 variables and recorded the top 50 variables ranked on importance. For the final calculation, we used only the top 30 variables from the initial implementation. This two-step process helps to ensure that the most relevant features are selected, reducing the risk of overfitting to less important variables.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are detailed within the publication. Specifically, we discuss the use of a Monte-Carlo implementation and the selection of the top 30 variables for the final calculation. The feature importance from this implementation is used to determine the final values, and we report the weighted f1-score for different numbers of retained variables.\n\nThe methodology and results, including the predictive power of our model, are thoroughly described. For instance, we mention that 10 variables are sufficient to achieve a predictive f1-score of greater than 78%. Additionally, we provide tables that summarize the comparative predictive accuracies when the model is constrained to different numbers of variables.\n\nRegarding the availability of model files and optimization parameters, these details are not explicitly provided in the text. However, the methodology and results are sufficiently documented to allow for replication and further research. The publication is part of a resource center that grants permission for unrestricted research re-use and analyses, ensuring that the information is accessible for academic and research purposes.\n\nFor those interested in accessing the full details, the publication is available in publicly funded repositories, such as PubMed Central and the WHO COVID database. This ensures that the research content, including the optimization parameters and methodologies, can be freely used with proper acknowledgment of the original source.",
  "model/interpretability": "The model employed in this study is a random forest classifier, which is often considered a \"black box\" due to its complexity and the ensemble nature of decision trees. However, it offers some level of interpretability through feature importance, which indicates the contribution of each variable to the model's predictions.\n\nFeature importance in random forests is measured by how much each feature decreases the weighted impurity (such as Gini impurity or entropy) in the trees. This provides insights into which variables are most influential in predicting the issuance of Stay-At-Home Orders (SAHOs). For instance, variables like `tempDIFFS` and `prevAdopt` were identified as the most important, indicating their significant role in the model's decision-making process.\n\nAdditionally, the study used logistic regression models to complement the random forest, providing a more interpretable framework. These models included the top variables identified by the random forest, allowing for the assessment of variable directionality and statistical significance. This approach helps in understanding not just which variables are important, but also how they influence the outcome.\n\nThe inclusion of indices such as Ethnicity Factor and Health Factor 1 further enhances interpretability by grouping related variables, making it easier to understand their collective impact. For example, the Ethnicity Factor includes variables like `MuslimPct` and `envMort`, which were not among the top variables in the original model but are significant when considered together.\n\nMoreover, the study demonstrated the stability of important variables between different models, with 24 of the top 30 variables in the original model retained in the index model. This consistency suggests that the model is not overly sensitive to minor changes in variable selection, providing a more robust and interpretable framework.\n\nIn summary, while the random forest itself is a complex model, the use of feature importance and complementary logistic regression models provides a level of transparency. This allows for a clearer understanding of which variables drive the predictions and how they influence the issuance of SAHOs.",
  "model/output": "The model employed in our study is a classification model. Specifically, we utilized a random forest classifier to predict the issuance of stay-at-home orders (SAHOs) during the initial wave of COVID-19 in African countries. This approach was chosen for its robustness to outliers and the distributional properties of independent variables, making it well-suited for our dataset, which consists of 54 African countries. The random forest model provided a direct measure of performance estimation through correct classifications and was applied to a variety of information types with minimal data formatting.\n\nThe random forest classifier identified the most important variables contributing to the prediction of SAHOs. For instance, temporal diffusion was found to be a significant factor. The model's predictive accuracy was evaluated at different levels of retained variables, with the inclusion of index variables contributing to increases in model prediction. The F1-score, which measures the harmonic mean of precision and recall, was used to assess the model's performance. The results indicated that the model's predictive accuracy improved with the inclusion of certain variables, particularly when the index variables were added.\n\nAdditionally, we compared the composition of the original model and the index model. The index model retained many of the top variables from the original model, indicating a high level of stability between the factors that best predict SAHOs. The inclusion of new variables, such as Population Density and Phones Fixed Lines, further enhanced the model's predictive power. However, it is important to note that the small sample size (n = 54) may limit the generalizability of the findings. Future research should consider a more comprehensive approach to developing indices across all available variables in the dataset to improve the model's robustness and reliability.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the method involved a Monte-Carlo implementation of the random forest algorithm, which was used to determine the importance of variables in predicting the issuance of stay-at-home orders (SAHOs) during the initial wave of COVID-19 in African countries. The process began with an initial variable selection phase, where the algorithm was run 1000 times using all 88 variables. In each iteration, the top 50 variables ranked by importance were recorded. After these runs, the top 30 variables were retained based on their mean feature importance score across all iterations.\n\nFor the final calculation, the Monte-Carlo implementation was run again, but this time only using the top 30 variables identified in the initial phase. The feature importance from this implementation was used to determine the final values. To assess the predictive power of the methodology, the weighted F1-score was reported for different numbers of retained variables (1, 5, 10, 15, 20, 25, and 30). The F1-score is a standard metric in machine learning that combines precision and recall, providing a measure of a model's accuracy.\n\nThe evaluation also involved running 1000 additional instances of a forest for each variable configuration to account for the limited test sample. It was found that using 10 variables was sufficient to achieve an F1-score of greater than 78%, indicating a substantial increase in predictive accuracy compared to simply predicting the modal outcome. Increasing the number of variables beyond 10 did not meaningfully improve the predictive power. The efficacy of this method was noted to be limited by the small number of training and test countries, but the random forest classifier was highlighted as being well-suited for small datasets.",
  "evaluation/measure": "In our evaluation, we primarily report the weighted F1-score as our key performance metric. The F1-score is a standard metric in machine learning that provides a balance between precision and recall. It is particularly useful in scenarios where the class distribution is imbalanced, which is often the case in real-world datasets. The F1-score is calculated as (2 * precision * recall) / (precision + recall), and in terms of true positives (TP), false positives (FP), and false negatives (FN), it is expressed as TP / (TP + 0.5 * (FP + FN)).\n\nWe also report the proportional reduction in error (PRE), which is calculated as (% model accuracy - % modal category) / (1 - % modal category). This metric helps to quantify the improvement in predictive accuracy over simply predicting the most frequent outcome.\n\nTo demonstrate the predictive power of our methodology, we evaluate the F1-score at different levels of retained variables, specifically when retaining 1, 5, 10, 15, 20, 25, and 30 variables. This approach allows us to assess how the model's performance changes with the inclusion of more variables, providing insights into the trade-off between model complexity and predictive accuracy.\n\nThe use of the F1-score and PRE is representative of common practices in the literature, especially in studies involving imbalanced datasets and predictive modeling. These metrics are widely accepted and provide a comprehensive evaluation of the model's performance, ensuring that our results are comparable to other studies in the field.",
  "evaluation/comparison": "In our study, we employed a data-first approach to examine the issuance of Stay-at-Home Orders (SAHOs) during the initial wave of COVID-19 in African countries. A key aspect of our methodology was the use of the random forest classifier, a machine learning technique, to predict SAHOs. This approach allowed us to identify important variables that might be overlooked by traditional linear/frequentist methods.\n\nWe compared the performance of the random forest model to simpler baselines, such as predicting the modal outcome. Our 10-variable random forest model demonstrated a 56% increase in predictive accuracy over this baseline, highlighting the effectiveness of our approach. Additionally, we evaluated the model's performance using the F1-score, a standard metric in machine learning, which provided a comprehensive measure of precision and recall.\n\nThe random forest model's ability to handle small datasets and its robustness to sample and distributive data properties made it particularly suitable for our study. We also considered the limitations of the random forest method, such as its inability to provide a measure of directionality for independent variables. To address this, we complemented the random forest approach with conventional modeling techniques, thereby demonstrating the benefits of using multiple modeling methods.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets, as our focus was on the specific context of SAHO issuance in African countries during the COVID-19 pandemic. However, our findings suggest that machine learning methods, particularly the random forest classifier, can provide valuable insights and improve predictive accuracy in public policy and public health research. Future research could explore the application of these methods to other datasets and contexts to further validate their effectiveness.",
  "evaluation/confidence": "The evaluation of our methodology includes confidence intervals for the performance metrics. Specifically, the feature importance values are presented with 95% confidence intervals, providing a measure of uncertainty around these estimates. This allows for a more nuanced understanding of the reliability of the identified important variables.\n\nRegarding statistical significance, our results demonstrate that the random forest model provides a substantial increase in predictive accuracy compared to baseline methods. For instance, the 10-variable model achieved a 56% increase in accuracy over predicting the modal outcome. This improvement is statistically significant and indicates that the random forest approach is superior in this context.\n\nAdditionally, the robustness of the temporal diffusion variable is highlighted by its significant contribution to the regression models. This consistency across different modeling approaches strengthens the confidence in our findings.\n\nHowever, it is important to note that the small number of cases (n = 54) limits the generalizability of the results. The impact of individual countries on the overall model prediction is significant, which suggests that the findings may vary with different datasets. Future research with larger and more diverse datasets is recommended to further validate these results.",
  "evaluation/availability": "The raw evaluation files are not directly available for public download. However, the data used in this study can be made available upon request. This approach ensures that the data can be shared with other researchers while maintaining control over its distribution. The decision to provide data upon request aligns with the principles of data sharing in scientific research, promoting transparency and reproducibility without compromising the integrity of the data. The specific details and conditions for accessing the data can be discussed directly with the authors."
}