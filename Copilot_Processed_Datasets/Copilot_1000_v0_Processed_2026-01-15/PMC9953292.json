{
  "publication/title": "Artificial Neural Network Models for Accurate Predictions of Fat-Free and Fat Masses, Using Easy-to-Measure Anthropometric Parameters",
  "publication/authors": "The authors who contributed to the article are:\n\nIvona Mitu, who was involved in conceptualization, methodology, software, investigation, writing the original draft, and reviewing and editing the manuscript.\n\nCristina-Daniela Dimitriu, who contributed to the conceptualization and methodology of the study.\n\nOvidiu Mitu, who participated in methodology, resources, and data curation.\n\nCristina Preda, who contributed to the resources for the study.\n\nFlorin Mitu, who was involved in the investigation process.\n\nManuela Ciocoiu, who contributed to conceptualization, resources, supervision, and reviewing and editing the manuscript.\n\nAll authors have read and agreed to the published version of the manuscript.",
  "publication/journal": "Biomedicines",
  "publication/year": "2023",
  "publication/pmid": "36831025",
  "publication/pmcid": "PMC9953292",
  "publication/doi": "10.3390/biomedicines11020489",
  "publication/tags": "- Trunk fat mass\n- Trunk fat-free mass\n- Lean mass\n- Fat mass\n- Body composition\n- Machine learning\n- Artificial neural network\n- Obesity\n- Adiposity\n- Cardiometabolic risk",
  "dataset/provenance": "The dataset used in this study was collected from a population of 104 subjects. The data points included various demographic and anthropometric measures, such as age, weight, height, waist circumference, hip circumference, tricipital skinfold, and abdominal skinfold. These measures were easily assessed by trained personnel in any medical facility.\n\nThe dataset did not have any missing data, which eliminated the need for any data substitution algorithms. All variables were analyzed using Microsoft Excel version 16.64, SPSS version 23.0, and MATLAB R2021b. The dataset included both continuous and categorical variables. Continuous variables were tested for normality using the Kolmogorov\u2013Smirnov test. Normally distributed data were reported as means \u00b1 standard deviations, while non-normally distributed data were reported as medians and quartiles. Categorical variables were expressed as frequencies and percentages.\n\nThe initial independent variables used for estimation were seven continuous demographic and anthropometric parameters. These variables were chosen based on their ease of assessment in clinical settings. Pearson correlation was performed to exclude high intercorrelation (\u22650.9) between variables, ensuring that the dataset was robust for analysis.\n\nThe dataset was divided into training, validation, and test sets to build and evaluate the models. The training set consisted of 75% of the data, the validation set 15%, and the test set 15%. This division was done randomly to ensure that the models were trained on a representative sample of the data.\n\nThe dataset was used to build both Multiple Linear Regression (MLR) and Artificial Neural Network (ANN) models. The MLR models were computed using stepwise regression in SPSS, which excluded variables that assumed multicollinearity. The ANN models were built using the Neural Network Toolbox in MATLAB, with a focus on predicting trunk fat mass, trunk fat-free mass, and trunk total mass.\n\nThe study population included 77 females and 27 males, with a majority residing in urban areas. The demographic and anthropometric measures were reported in Table 1, which included parameters such as height, tricipital skinfold, abdominal skinfold, trunk fat percentage, and trunk fat-free percentage. The dataset was carefully curated to ensure that it was suitable for the statistical analyses and model building processes described in the study.",
  "dataset/splits": "The dataset was divided into three splits: training, validation, and test sets. This process was repeated 20 times for each model to mitigate the bias that data division might introduce into model accuracy. Each split contained a specific proportion of the total data points. The training set comprised 75% of the data, the validation set included 15%, and the test set also consisted of 15%. This division ensured that the models were trained on a substantial portion of the data while also being validated and tested on separate, representative subsets. The repeated splitting process aimed to evaluate the consistency and robustness of the models across different data divisions, enhancing the reliability of the results.",
  "dataset/redundancy": "The datasets were split into three distinct sets: a training set, a validation set, and a test set. The data were randomly divided, with 75% allocated to the training set, 15% to the validation set, and the remaining 15% to the test set. This division was performed to ensure that each model was trained, validated, and tested on different subsets of the data, thereby reducing the risk of overfitting and enhancing the generalizability of the models.\n\nThe independence of the training and test sets was enforced through random division. This process was repeated for 20 iterations to evaluate the effect of data division on the model's performance. By doing so, we aimed to create similar but randomly chosen datasets, mimicking real-life scenarios and ensuring that the models were not biased towards any specific subset of the data.\n\nThe distribution of the datasets compares favorably with previously published machine learning datasets in the field. The random division and the use of multiple iterations helped in achieving a balanced and representative distribution across the training, validation, and test sets. This approach ensured that the models were robust and could generalize well to new, unseen data.",
  "dataset/availability": "The data supporting the reported results are available from the corresponding authors. However, the data are not publicly available due to privacy concerns. This means that the dataset, including any specific data splits used, is not released in a public forum. To access the data, interested parties would need to contact the corresponding authors directly. The restriction on public availability is enforced to protect the privacy of the subjects involved in the study.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is artificial neural networks (ANNs), specifically multilayer perceptron feed-forward neural networks. These models are well-established in the field and are not new. They are widely used for predictive modeling due to their ability to approximate complex functions.\n\nThe choice to use ANNs was driven by their proven capability to handle nonlinear relationships and interactions between variables, making them suitable for predicting continuous outcomes such as fat and fat-free masses. The Universal Approximation Theorem supports the use of neural networks with a single hidden layer to approximate any continuous function to any desired precision, which guided our decision to work with a single hidden layer.\n\nThe ANN models were built using the Neural Network Toolbox in MATLAB, leveraging the Levenberg\u2013Marquardt backpropagation learning algorithm. This algorithm is known for its efficiency in training neural networks, particularly for problems involving small to medium-sized datasets.\n\nThe reason these models were not published in a machine-learning journal is that the focus of our research is on their application in biomedical sciences, specifically in predicting body composition parameters. The innovation lies in the application of these models to a specific biomedical problem rather than in the development of a new machine-learning algorithm. Our work contributes to the field by demonstrating the effectiveness of ANNs in predicting clinically relevant outcomes, which is of interest to the biomedical community.",
  "optimization/meta": "The model developed in this study does not use data from other machine-learning algorithms as input. Instead, it relies on continuous demographic and anthropometric parameters that are easily assessed by trained personnel in any medical facility.\n\nThe study compares two types of models: multiple linear regression (MLR) and artificial neural network (ANN) models. The ANN models used are multilayer perceptron, feed-forward neural networks. These models were trained with the Levenberg\u2013Marquardt backpropagation learning algorithm. The input layer consists of continuous demographic and anthropometric variables, and the hidden layer represents the computational engine of the model. The output layer performs the prediction.\n\nThe data was randomly divided into training, validation, and test sets to ensure independence. Each model was trained, validated, and tested in a sequence of iterations, with the mean squared error (MSE) calculated for the entire set after each iteration. The model with the lowest averaged MSE was selected as the one with the best performance. This approach helps to evaluate the effect of data division on the goodness of fit of the model and reduces the risk of bias.\n\nThe study does not explicitly mention the use of a meta-predictor that combines the outputs of different machine-learning methods. The focus is on comparing the performance of MLR and ANN models individually. The training data for each model is independent, as it is randomly divided into training, validation, and test sets. This ensures that the models are evaluated on unseen data, providing a robust assessment of their performance.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the data was suitable for model training. Initially, seven continuous demographic and anthropometric parameters were used as independent variables. These parameters were chosen for their ease of assessment in medical facilities.\n\nThe data was divided into three sets: a training set (75%), a validation set (15%), and a test set (15%). This division was done randomly to ensure that the models were trained, validated, and tested on different subsets of the data, reducing the risk of overfitting.\n\nFor the artificial neural network (ANN) models, the input layer consisted of these continuous demographic and anthropometric variables. The hidden layer, which contained an arbitrary number of units, was the core computational engine of the model. The number of units in the hidden layer ranged from 1 to 20, and the performance of the model was evaluated for each configuration.\n\nThe activation function used for the hidden layer was the hyperbolic tangent sigmoid (tansig), while the output layer used a linear activation function (purelin). The models were trained using the Levenberg\u2013Marquardt backpropagation learning algorithm, with a maximum of 1000 iterations.\n\nTo handle multicollinearity, a Pearson correlation was performed, and variables with high intercorrelation (\u22650.9) were excluded. This step ensured that the independent variables were not redundant and improved the model's performance.\n\nThe data was analyzed using several software tools, including Microsoft Excel, SPSS, and MATLAB. SPSS was used for multiple linear regression (MLR) models with stepwise regression to exclude multicollinear variables. MATLAB's Neural Network Toolbox was used to build the ANN models, and an in-house function was developed to save the network with the best performance for each input in the hidden layer.\n\nThe performance of the models was evaluated using mean squared error (MSE) and root mean squared error (RMSE). The models were trained, validated, and tested in a sequence of 20 iterations to evaluate the effect of data division on the goodness of fit. The model with the lowest averaged MSE was selected as the best-performing model.",
  "optimization/parameters": "In our study, the number of input parameters used in the model varied depending on the specific model and the parameter being predicted. These parameters were selected based on human logic and ease of use in clinical settings. Initially, seven continuous demographic and anthropometric parameters were considered. However, a forward-feature selection method was conducted to identify the best combination of parameters for each model.\n\nFor the multiple linear regression (MLR) models, the stepwise regression method was used to exclude variables that assumed multicollinearity, ensuring that only the most predictive variables were included. This process resulted in different numbers of parameters for each predicted outcome. For instance, the model for trunk fat mass included four parameters: weight, height, hip circumference, and waist circumference.\n\nSimilarly, for the artificial neural network (ANN) models, a forward-feature selection method was employed to determine the optimal set of input parameters. The specific parameters included in each ANN model varied based on the outcome being predicted. For example, the ANN model for total fat mass included weight, waist circumference, hip circumference, and height.\n\nThe selection of parameters was guided by the goal of achieving the best model performance while maintaining practicality in clinical settings. The final number of parameters for each model was determined through a combination of domain knowledge and statistical methods to ensure robustness and accuracy in predictions.",
  "optimization/features": "The input features used in the models were continuous demographic and anthropometric variables. These variables were selected based on their ease of assessment by trained personnel in medical facilities and their relevance to the predictions being made.\n\nThe initial set of input features consisted of seven variables. However, feature selection was performed to identify the most predictive variables for each model. This process involved a forward-feature selection method, which helps in finding the best combination of features that improve model performance.\n\nThe feature selection was conducted using the training set only, ensuring that the validation and test sets remained independent for unbiased evaluation of the models. This approach helps in preventing data leakage and ensures that the selected features generalize well to new, unseen data.",
  "optimization/fitting": "The fitting method employed in this study utilized multilayer perceptron feed-forward neural network models, specifically artificial neural networks (ANNs), to predict dependent variables. The input layer consisted of continuous demographic and anthropometric variables, with a single hidden layer containing an arbitrary number of units. The choice of a single hidden layer was based on the Universal Approximation Theorem, which states that neural networks with a single hidden layer can approximate any continuous function to any desired precision.\n\nTo address the potential issue of overfitting, several measures were taken. The data were randomly divided into training (75%), validation (15%), and test sets (15%). This division was repeated 20 times to evaluate the effect of data division on the model's goodness of fit. The mean squared error (MSE) was calculated for each set, and the averaged MSE was used to select the model with the best performance. This approach helped to ensure that the model generalized well to unseen data and did not merely memorize the training set.\n\nAdditionally, a forward-feature selection method was conducted to identify the best model. This method helped in selecting the most relevant features, reducing the risk of overfitting by avoiding the inclusion of irrelevant or redundant variables. The number of units in the hidden layer was varied from 1 to 20, and the performance did not improve beyond 20 units, indicating that this number was sufficient for optimal performance without overfitting.\n\nTo rule out underfitting, the models were trained for a maximum of 1000 iterations, allowing sufficient time for the network to learn the underlying patterns in the data. The use of the Levenberg\u2013Marquardt backpropagation learning algorithm ensured efficient training. The tansig activation function was used in the hidden layer, and the purelin activation function was used in the output layer, which are standard choices for regression problems and help in capturing complex relationships in the data.\n\nThe performance of the models was evaluated using the R2 and MSE values, with the root mean square error (RMSE) calculated for the chosen model. The models demonstrated high coefficients of determination (R2 values), indicating good predictive accuracy. The RMSE values for the ANN models were significantly lower than those for the multiple linear regression (MLR) models, further confirming the effectiveness of the fitting method in avoiding underfitting.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting in our artificial neural network (ANN) models. One key method involved dividing the data into training, validation, and test sets. The data was randomly split into 75% for training, 15% for validation, and 15% for testing. This division ensured that the model was trained on a substantial portion of the data while being validated and tested on separate, unseen data, helping to assess its generalization performance.\n\nAdditionally, we used a forward-feature selection method to identify the most relevant input variables for our models. This process helped in reducing the complexity of the models by excluding irrelevant or redundant features, which can contribute to overfitting.\n\nWe also implemented a rigorous training process involving 20 iterations for each model configuration. During each iteration, the mean squared error (MSE) was calculated for the training, validation, and test sets. The final model was selected based on the lowest averaged MSE across all iterations, ensuring that the model's performance was consistent and not merely a result of overfitting to the training data.\n\nFurthermore, the number of units in the hidden layer was systematically varied from 1 to 20, and the performance was evaluated for each configuration. This approach allowed us to find the optimal number of units that provided the best generalization performance without overfitting.\n\nThe use of the Levenberg\u2013Marquardt backpropagation learning algorithm, known for its efficiency and robustness, also contributed to preventing overfitting. This algorithm adjusts the weights in the network in a way that minimizes the error, balancing between the speed of convergence and the risk of overfitting.\n\nOverall, these techniques collectively helped in building robust ANN models that generalize well to new, unseen data, thereby mitigating the risk of overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, we utilized multilayer perceptron, feed-forward neural network models for predicting various body composition parameters. The models were trained using the Levenberg\u2013Marquardt backpropagation learning algorithm, with a tansig activation function for the hidden layer and a purelin activation function for the output layer. The maximum number of iterations was set to 1000.\n\nThe data was divided into training (75%), validation (15%), and test sets (15%), and each model was trained, validated, and tested over 20 iterations. The mean squared error (MSE) was calculated for each iteration, and the model with the lowest averaged MSE was selected as the best-performing model. The root mean square error (RMSE) was also calculated for the chosen model.\n\nThe specific configurations, including the number of units in the hidden layer for each model, are reported in the results section. For instance, the best-performing ANN model for trunk fat mass had 6 units in the hidden layer, while the model for trunk fat-free mass also had 6 units. These details ensure reproducibility and transparency in our methodology.\n\nRegarding the availability of model files and optimization parameters, the in-house function constructed for saving the network with the best performance per each input in the hidden layer facilitates the reproducibility of our results. However, the specific model files and optimization parameters are not publicly available due to the nature of the study and the tools used. Interested parties can reach out for further details or collaboration.",
  "model/interpretability": "The models developed in this study include both Multiple Linear Regression (MLR) and Artificial Neural Network (ANN) models. The MLR models are inherently more interpretable as they provide a clear relationship between the input variables and the output. For instance, the coefficients (\u03b2) in the MLR models indicate the strength and direction of the relationship between each predictor variable and the outcome. For example, in the MLR model for Trunk Fat Mass, the weight has a positive coefficient of 0.303, indicating that an increase in weight is associated with an increase in Trunk Fat Mass. Similarly, height has a negative coefficient of -0.243, suggesting that taller individuals tend to have less Trunk Fat Mass, all else being equal.\n\nOn the other hand, ANN models are often considered black-box models due to their complex, non-linear nature. However, efforts were made to enhance interpretability. The input parameters for the ANN models were selected based on human logic and ease of use in clinical settings, ensuring that the variables used are meaningful and relevant. Additionally, a forward-feature selection method was conducted to identify the most important predictors for each outcome. For example, the best-performing ANN model for Trunk Fat Mass includes weight, waist circumference, height, and tricipital skinfold as input variables, which are all clinically relevant measures.\n\nFurthermore, the performance of the ANN models was evaluated using metrics such as Mean Squared Error (MSE) and R-squared (R2) values, which provide insights into the model's accuracy and goodness of fit. The regression plots and performance plots for the ANN models offer visual representations of the model's predictions and errors, aiding in the interpretation of the model's behavior. These plots are available in the supplementary materials, providing transparency into the model's performance across different datasets (training, validation, and test sets).\n\nIn summary, while the ANN models are more complex and less interpretable than the MLR models, efforts were made to enhance their interpretability by selecting clinically relevant input variables and evaluating their performance using transparent metrics and visualizations. The MLR models, with their clear coefficients, offer a more straightforward interpretation of the relationships between predictors and outcomes.",
  "model/output": "The model developed in this study is a regression model. It is designed to predict continuous variables, specifically the mass of fat, fat-free mass, and total mass in kilograms for both the trunk region and the entire body. The models used include Multiple Linear Regression (MLR) and Artificial Neural Networks (ANN). The ANN models, in particular, were built using a feed-forward neural network architecture with a single hidden layer. The performance of these models was evaluated using metrics such as the coefficient of determination (R\u00b2) and the mean squared error (MSE). The regression plots and performance metrics indicate that the models are effective in predicting the specified mass parameters with high accuracy. The ANN models, for instance, showed significantly higher R\u00b2 values compared to the MLR models, suggesting better predictive performance. The root mean square error (RMSE) values for the ANN models were also lower, indicating smaller prediction errors. Overall, the regression models demonstrated strong capability in estimating the mass parameters based on the input demographic and anthropometric variables.",
  "model/duration": "The execution time for our models varied depending on the specific configurations and the computational resources used. We utilized multilayer perceptron, feed-forward neural network models for our predictions. These models were trained using the Levenberg\u2013Marquardt backpropagation learning algorithm, which is known for its efficiency in training medium-sized neural networks.\n\nEach model was trained, validated, and tested in a sequence of 20 iterations. For each iteration, the mean squared error (MSE) was calculated for the entire dataset, which included the training, validation, and test sets. The data were randomly divided into these sets, with 75% allocated for training, 15% for validation, and 15% for testing. This division was repeated 20 times to evaluate the effect of data division on the model's performance and to ensure robustness.\n\nThe maximum number of iterations for the algorithm was set to 1000, but the models typically converged much earlier. The best performance was identified by selecting the model with the lowest averaged MSE across the 20 iterations. This process helped in reducing the risk of bias and ensured that the models were generalizable to new data.\n\nThe computational time for each model varied, but it generally took several hours to complete the training, validation, and testing phases for all configurations. The specific execution time depended on the number of units in the hidden layer, which ranged from 1 to 20. We found that the performance did not improve significantly after reaching 20 units, indicating that this number was sufficient for achieving the best model performance.\n\nIn summary, while the exact execution time varied, the models were designed to be efficient and robust, with a focus on achieving high accuracy and generalizability. The use of the Levenberg\u2013Marquardt algorithm and the thorough validation process ensured that the models were well-trained and reliable for predicting the desired outcomes.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method for the developed models involved a comprehensive approach to ensure their accuracy and reliability. The data was randomly divided into three sets: a training set comprising 75% of the data, a validation set with 15%, and a test set with the remaining 15%. This division was repeated 20 times to evaluate the effect of data partitioning on the models' performance. For each iteration, the mean squared error (MSE) was calculated for the training, validation, and test sets. The overall MSE for each model was then determined by averaging the MSE values from all iterations, weighted by the proportion of data in each set.\n\nThe performance of the models was assessed using the root mean square error (RMSE) and the coefficient of determination (R\u00b2). These metrics provided insights into the models' predictive accuracy and the proportion of variance explained by the models, respectively. The RMSE was calculated for the chosen model with the lowest averaged MSE, indicating the best performance.\n\nTo compare the multiple linear regression (MLR) and artificial neural network (ANN) models, an independent sample t-test was used. This statistical test helped determine if there were significant differences in the RMSE and R\u00b2 values between the two types of models. The t-test was applicable because the RMSE and R\u00b2 values for the chosen models were normally distributed.\n\nAdditionally, the Pearson correlation was used to assess multicollinearity among the variables. This step ensured that the models did not include variables that were highly correlated, which could lead to misleading results. The significance level for all statistical tests was set at p < 0.05.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our models. For both Multiple Linear Regression (MLR) and Artificial Neural Network (ANN) models, we reported the coefficient of determination (R\u00b2) and the mean squared error (MSE). These metrics are widely used in the literature and provide a comprehensive view of model performance.\n\nThe R\u00b2 value indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, with higher values indicating better model performance. We also calculated the root mean square error (RMSE), which provides a measure of the average magnitude of the errors between predicted and observed values. RMSE is particularly useful because it is in the same units as the dependent variable, making it easier to interpret.\n\nTo ensure the robustness of our models, we divided our data into training, validation, and test sets. We reported the R\u00b2 and MSE for each of these sets, allowing for a detailed assessment of model performance across different data subsets. This approach helps to identify any overfitting or underfitting issues and ensures that the models generalize well to unseen data.\n\nAdditionally, we used the independent sample t-test to compare the RMSE and R\u00b2 values between the MLR and ANN models. This statistical test helped us to determine whether the differences in performance between the two types of models were statistically significant.\n\nThe regression plots for the entire set of data for each predicted parameter were analyzed to visually assess the accuracy of the models. These plots, along with performance and training state plots, are included in the supplementary materials. The high R\u00b2 values and low RMSE values reported for the ANN models suggest that they provide a good prediction of the outcome, outperforming the MLR models in most cases.\n\nIn summary, the performance metrics reported in our study are representative of those commonly used in the literature. The use of R\u00b2, MSE, and RMSE, along with the division of data into training, validation, and test sets, provides a thorough evaluation of model performance and ensures the reliability of our findings.",
  "evaluation/comparison": "In our study, we focused on comparing two distinct modeling approaches to predict body composition parameters, specifically trunk fat and fat-free masses. We developed and evaluated multiple linear regression (MLR) models and artificial neural network (ANN) models. The MLR models served as simpler baselines, providing a straightforward and computationally efficient method for prediction. These models were built using stepwise regression in SPSS, which helped exclude variables that exhibited multicollinearity, ensuring robustness in our predictions.\n\nFor the ANN models, we employed multilayer perceptron, feed-forward neural networks. These models were designed to capture non-linear relationships between variables, offering a more complex and potentially more accurate approach to prediction. The ANN models were constructed using the Neural Network Toolbox in MATLAB, with a single hidden layer and various configurations of units within that layer. The performance of these models was optimized through a forward-feature selection method and extensive training, validation, and testing iterations.\n\nWe did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on developing and comparing our own models within the context of our specific study population and parameters. The comparison between MLR and ANN models allowed us to assess the trade-offs between simplicity and computational efficiency (MLR) versus complexity and potential accuracy (ANN). This approach provided valuable insights into the strengths and limitations of each method for predicting body composition parameters in our study.",
  "evaluation/confidence": "The evaluation of our models involved a rigorous statistical analysis to ensure the reliability and significance of our results. We employed several performance metrics, including the coefficient of determination (R2) and the mean squared error (MSE), to assess the accuracy of our models. The root mean square error (RMSE) was also calculated to provide a more practical measure of the mean error.\n\nTo determine the statistical significance of our findings, we used the Kolmogorov\u2013Smirnov test to check the normality of continuous variables. Normally distributed data were reported as means \u00b1 standard deviations, while non-normally distributed data were reported as medians and quartiles. Categorical variables were expressed as frequencies and percentages.\n\nFor comparing the errors and R2 values between the multiple linear regression (MLR) and artificial neural network (ANN) models, we utilized an independent sample t-test. This statistical test helped us to ascertain whether the differences in performance metrics between the models were significant.\n\nThe Pearson correlation was used to assess multicollinearity among the variables. Results were considered statistically significant if the p-value was less than 0.05. This threshold ensured that our conclusions about the superiority of the ANN models over the MLR models were robust and not due to random chance.\n\nThe R2 values for the ANN models were significantly higher than those for the MLR models, with a p-value of 0.006. This indicates a strong predictive performance of the ANN models. Additionally, the RMSE values for the ANN models ranged from 1.48 to 2.71 kg, which was lower than the RMSE values for the MLR models, ranging from 2.20 to 3.96 kg. This difference was statistically significant with a p-value of 0.05, further supporting the superiority of the ANN models.\n\nIn summary, our evaluation confidence is high due to the use of rigorous statistical methods and the significance of the results. The performance metrics, including R2 and RMSE, were thoroughly analyzed, and the statistical significance of the differences between the models was established. This ensures that our claims about the superior performance of the ANN models are well-founded.",
  "evaluation/availability": "Not enough information is available."
}