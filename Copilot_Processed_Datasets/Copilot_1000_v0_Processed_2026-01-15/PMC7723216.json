{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2020",
  "publication/pmid": "32520440",
  "publication/pmcid": "PMC7723216",
  "publication/doi": "10.5281/zenodo.3778351",
  "publication/tags": "- Schizophrenia\n- Epidemiology\n- Simulation Study\n- Machine Learning\n- Data-Driven Approach\n- Interaction Effects\n- Risk Factors\n- Case-Control Study\n- Statistical Methods\n- High-Dimensional Data",
  "dataset/provenance": "The dataset used in this study was simulated to resemble epidemiologic data. It comprised three groups (A, B, C) of three variables each, resulting in nine variables in total. The simulated dataset included 4,500 subjects, with a case-control ratio of 1:2. The prevalence of the variables within each group was set at 20% for the first variables (A1, B1, C1), 15% for the second variables (A2, B2, C2), and 5% for the third variables (A3, B3, C3). A within-group correlation of 0.3 was established for the three groups of variables. The dataset included a main effect with an odds ratio (OR) of 1.3 for the first variable in each group (A1, B1, C1) and one active interaction with an OR of 3.0 (A2 \u2715 B2). This interaction was between variables in uncorrelated groups, each with a prevalence of 15%, resulting in an interaction prevalence of 2.3%.\n\nAdditionally, 13 other types of simulation datasets were defined by varying the number of subjects, the prevalence of the active interaction, the odds ratios of the interaction effect, or the within-group correlation. For each type of dataset, 10,000 simulations were conducted, totaling 140,000 simulations. The empirical power and false positive (FP) rate of main and interaction effects were calculated based on these simulations.\n\nThe dataset was designed to optimize interpretability and to avoid setting multiple active interaction effects from the same variables. The simulation study aimed to capture complex relationships between variables, such as interactions, with minimal a priori restrictions. The dataset was preprocessed to ensure stable models without zero or near-to-zero variance, and interactions with a lower expected count of five among cases and controls were excluded. Interactions between main effects with high correlation were also excluded to minimize the risk of falsely identifying interactions. The predictors were standardized by scaling and centering, while the original binary structure of the predictors was used for inference.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not applicable",
  "dataset/availability": "The data used in this study are not publicly released in a forum. The study primarily relies on simulated datasets, which were generated using specific parameters and definitions outlined in the methods section. These simulations were conducted to mimic epidemiologic data and to test the performance of various statistical models.\n\nThe simulated datasets were created using R functions and packages, such as `simstudy` and `glmnet`, which are publicly available. The code to reproduce the analyses, including the simulation of data, is provided in a GitHub repository. This repository includes R scripts that can be used to generate the simulated datasets and perform the analyses described in the study.\n\nThe repository is accessible at [https://github.com/davgyl/dd_ident](https://github.com/davgyl/dd_ident) and is archived on Zenodo with the DOI: 10.5281/zenodo.3778351. The repository contains the necessary functions and scripts to load the required packages, simulate the data, preprocess it, and perform the analyses. By following the instructions and using the provided code, other researchers can reproduce the simulated datasets and the results of the study.\n\nThe use of simulated data ensures that the findings are reproducible and that the methods can be validated by other researchers. The provision of the code and the repository enforces transparency and allows for independent verification of the results.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the elastic net, which is a type of regularized regression model. It is not a new algorithm; it was introduced by Zou and Hastie in 2005. The elastic net combines the penalties of both ridge regression and lasso regression, making it particularly useful for datasets with correlated predictors.\n\nThe reason it was not published in a machine-learning journal is that our focus is on its application in the context of epidemiological and genetic studies, specifically in the detection of main and interaction effects in high-dimensional case-control data. The elastic net's ability to handle high-dimensional data and produce interpretable results makes it well-suited for this purpose. Our work emphasizes the practical application of this algorithm in a specific scientific domain rather than the development of new machine-learning techniques.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It employs the elastic net algorithm for variable selection, which is a type of regularized regression that combines the penalties of ridge regression and lasso regression. This algorithm is used to select the strongest associations by shrinking the regression coefficients of predictors as a function of the shrinkage parameter lambda and the tuning parameter alpha.\n\nThe elastic net algorithm is applied to a set of predefined predictors, which include main effects and interactions. These predictors are derived from the data itself, rather than from the outputs of other machine-learning algorithms. The main effects are coded as binary variables, and the interactions are also binary, indicating the presence of both risk factors.\n\nThe training data for the elastic net algorithm is independent. The model is trained using a nationwide nested case-control study of schizophrenia in Finland, which provides a large sample size suitable for studying interactions. The data is preprocessed to ensure stable models without zero or near-to-zero variance, and interactions with high correlation are excluded to minimize the risk of falsely identifying interactions. The predictors are then standardized by scaling and centering before modeling.\n\nThe elastic net algorithm is used to select the most informative predictors, and their odds ratios, confidence intervals, and p-values are calculated. A multivariate logistic regression model is then fitted using the selected predictors, and the Wald-type confidence intervals and p-values are corrected with Bonferroni adjustment. This approach ensures that the selected predictors are identified correctly and that the false positive rate is low.",
  "optimization/encoding": "The data encoding and preprocessing steps were designed to maximize the interpretability of interactions and ensure stable modeling. All main effects were coded as binary variables, with 0 indicating the absence and 1 indicating the presence of a risk factor. Consequently, all two-way interactions also had a binary structure, where 1 signified the presence of both risk factors.\n\nTo describe the data, frequencies and proportions of all predictors were calculated. Interactions with an expected count of fewer than five among cases and controls were excluded to avoid zero or near-zero variance, which could destabilize the models. Additionally, interactions between main effects with log(odds ratios) greater than or equal to 0.3 or less than or equal to -0.3 were excluded to minimize the risk of falsely identifying interactions due to high correlation. These criteria were informed by a simulation study.\n\nDuring preprocessing, the prevalence, expected count, and correlation of predictors were extracted for descriptive purposes. Before modeling, predictors were standardized by scaling and centering, although the original binary structure was retained for inference. All preprocessed predictors, including interactions, were studied on the multiplicative scale. This approach ensured that the machine-learning algorithm could effectively capture complex relationships between variables, including interactions, with minimal a priori restrictions.",
  "optimization/parameters": "In the optimization process, the number of predictors, denoted as p, varied depending on the specific analysis and dataset. For instance, in one analysis using the FiPS-S data, the elastic net algorithm selected between 31 predictors. The selection of predictors was performed using the elastic net algorithm, which is an extension of generalized linear models. This algorithm selects the strongest associations by shrinking the regression coefficients of predictors as a function of the shrinkage parameter lambda and the tuning parameter alpha. The alpha value was set to 0.75 based on a simulation study, which showed that this value provided the highest true positive rate for detecting interaction effects. The lambda parameter was defined using 10-fold cross-validation and the 1-SE rule. This approach ensures that the model includes the most informative predictors while controlling for overfitting. The final model included predictors with non-zero coefficients, which were considered the selected predictors. The significance level for the confidence intervals and p-values was adjusted using the Bonferroni correction to account for the number of predictors included in the selection process.",
  "optimization/features": "In our study, we utilized a comprehensive set of predictors, which included both main effects and their interactions. The specific number of features (f) used as input varied depending on the dataset and the preprocessing steps applied. Initially, we considered a large number of potential predictors, but we implemented several criteria to filter and select the most relevant features.\n\nFeature selection was indeed performed to ensure that only the most informative predictors were included in our models. This process involved using the elastic net algorithm, which is designed to handle high-dimensional data by selecting the strongest associations while shrinking the regression coefficients of less important predictors. The elastic net algorithm was applied using the R package glmnet, and we employed a logistic regression version due to our binary outcome (schizophrenia vs. control).\n\nThe tuning parameter alpha in the elastic net algorithm was set to 0.75, which balances between ridge regression and lasso regression. This value was chosen based on simulation studies that aimed to optimize the performance of the model. The shrinkage parameter lambda was defined using 10-fold cross-validation and the 1-SE-rule, ensuring that the selected features were robust and generalizable.\n\nTo further refine the feature set, we excluded interactions with a lower expected count of five among cases and controls. Additionally, we excluded interactions between main effects that had log(odds ratios) greater than or equal to 0.3 or less than or equal to -0.3 to minimize the risk of falsely identifying interactions due to high correlation. These criteria were informed by simulation studies and were applied to ensure stable and interpretable models.\n\nAll preprocessing steps, including feature selection, were performed using the training set only. This approach ensures that the model's performance is not biased by information from the test set, maintaining the integrity of the validation process. The final set of preprocessed predictors was then studied on the multiplicative scale to maximize interpretability.",
  "optimization/fitting": "In our study, we employed the elastic net algorithm for variable selection, which is particularly useful when the number of parameters is much larger than the number of training points. This scenario is common in high-dimensional data, such as ours, where we had a large number of potential predictors.\n\nTo address the risk of over-fitting, we used 10-fold cross-validation to define the lambda parameter. This technique helps in selecting a model that generalizes well to unseen data by minimizing the risk of over-fitting. Additionally, we applied the 1-SE rule, which chooses the largest lambda value within one standard error of the minimum cross-validated error. This approach further ensures that the model is not too complex and thus reduces the likelihood of over-fitting.\n\nTo mitigate under-fitting, we conducted extensive simulation studies to optimize the tuning parameter alpha. We tested different values of alpha (0.5, 0.75, and 1) and found that an alpha value of 0.75 provided the best balance between bias and variance. This value was chosen because it showed the highest true positive rate for detecting interaction effects while maintaining a low false positive rate. Furthermore, theoretical and empirical evidence supports the use of elastic net with alpha values less than 1 for correlated data, as it performs better than lasso regression (alpha = 1) in such cases.\n\nIn summary, our approach involved using cross-validation and careful tuning of the elastic net parameters to balance the trade-off between over-fitting and under-fitting, ensuring robust and interpretable results.",
  "optimization/regularization": "In our study, we employed the elastic net algorithm for variable selection, which inherently serves as an over-fitting prevention technique. This method is an extension of generalized linear models and is particularly useful for handling high-dimensional data by shrinking the regression coefficients of predictors. The elastic net algorithm uses two key parameters: the shrinkage parameter lambda and the tuning parameter alpha. The lambda parameter controls the overall amount of shrinkage, while the alpha parameter determines the balance between ridge regression (alpha near zero) and lasso regression (alpha near one). We conducted a simulation study to choose an optimal alpha value of 0.75, which balances between the two types of regression. This choice was informed by theoretical considerations and literature indicating that elastic net analyses with alpha values less than one perform better in correlated data. Additionally, we used 10-fold cross-validation with the 1-SE-rule to define the lambda parameter, further ensuring that our model generalizes well to new data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in detail within the manuscript and the supporting information. Specifically, we conducted simulation studies to determine the optimal criteria for including interactions in our analyses. We varied the maximum absolute log(odds ratio) between main effects for an interaction to be included, testing criteria of 0.1, 0.3, and 0.5. Based on these simulations, we opted for a criterion of log(OR) at 0.3 to balance the false positive rate and the power to detect interaction effects.\n\nAdditionally, we performed simulations with varying tuning parameter alpha in the elastic net analyses while keeping the criterion of log(OR) constant at 0.3. We tested alpha values of 0.5, 0.75, and 1, and found that an alpha value of 0.75 provided the highest true positive rate for detecting interaction effects. This choice was also supported by theoretical and literature-based evidence that elastic net analyses with alpha values less than 1 perform better in correlated data.\n\nThe simulation studies and the resulting configurations are thoroughly described in the supporting information, including the R-code to reproduce the analyses. This code is available for use under standard academic sharing practices, allowing other researchers to replicate and build upon our findings. The detailed rationale and methods for defining the simulation studies are also provided, ensuring transparency and reproducibility.\n\nThe optimization parameters, such as the lambda parameter in the elastic net algorithm, were defined using 10-fold cross-validation and the 1-SE-rule. This approach ensures that the selected predictors are robust and generalizable. The preprocessed predictors and their interactions were studied on the multiplicative scale, and the elastic net algorithm was used to select the strongest associations by shrinking the regression coefficients of predictors.\n\nIn summary, all relevant hyper-parameter configurations, optimization schedules, and model files are reported and made available through the supporting information and the provided R-code. This ensures that the methods and results of our study are transparent, reproducible, and can be utilized by other researchers in the field.",
  "model/interpretability": "The model employed in our study is designed with a strong emphasis on interpretability, making it transparent rather than a black box. Several key aspects contribute to this transparency.\n\nFirstly, the simulation study was carefully crafted to include groups of correlated variables, variables with different prevalence, and both active main and interaction effects. This design allows for a clear understanding of how different factors interact and contribute to the outcomes. By setting active effects from variables with the same prevalence and avoiding multiple active interaction effects from the same variables, we ensured that the model's results are straightforward to interpret.\n\nIn the data preprocessing stage, all main effects were coded as binary, and interactions were also given a binary structure. This binary coding simplifies the interpretation of interactions, as \"1\" indicates the presence of both risk factors. Additionally, interactions with a lower expected count of five among cases and controls were excluded to ensure stable models. This step helps in avoiding spurious interactions that could complicate the model's interpretability.\n\nThe elastic net algorithm used for variable selection is another factor that enhances transparency. The algorithm's tuning parameter, alpha, was set to 0.75 based on simulation studies, which showed that this value performs well in correlated data. The elastic net algorithm selects the strongest associations by shrinking the regression coefficients of predictors, making it easier to identify the most influential variables.\n\nFurthermore, the model's predictors were standardized by scaling and centering, while the original binary structure was maintained for inference. This standardization process ensures that the model's results are consistent and easy to interpret. The interactions were studied on the multiplicative scale, providing a clear framework for understanding how different factors combine to influence the outcomes.\n\nIn summary, the model's design, data preprocessing steps, and the use of the elastic net algorithm all contribute to its transparency. The binary coding of main effects and interactions, the exclusion of low-count interactions, and the standardization of predictors make the model's results interpretable and easy to understand.",
  "model/output": "The model employed in our study is a logistic regression model, which is a type of classification model. This choice is driven by the binary nature of our outcome variable, specifically the presence or absence of schizophrenia. The logistic regression model is used within the framework of the elastic net algorithm, which is designed to handle high-dimensional data by performing variable selection and regularization. The elastic net algorithm extends generalized linear models and is particularly useful for selecting the strongest associations among predictors by shrinking their regression coefficients. This process is governed by two key parameters: the shrinkage parameter lambda and the tuning parameter alpha. The alpha parameter determines the balance between ridge regression (when alpha is near zero) and lasso regression (when alpha is near one). In our analyses, we opted for an alpha value of 0.75, which was chosen based on simulation studies that indicated this value provided the best performance in detecting interaction effects, especially in correlated data. The output of our model includes the odds ratios (OR), confidence intervals (CI), and p-values for the selected predictors. These values are adjusted using the Bonferroni correction to account for multiple comparisons, ensuring that the significance level is appropriately controlled. The model's performance is further evaluated through power analyses, which help assess the ability of the model to detect true positive and false positive effects under various simulation conditions.",
  "model/duration": "The execution time for the model varied depending on the specific analyses and simulations conducted. For instance, the simulation study to define data preprocessing and analyses involved 30,000 simulations in total, which included varying criteria for the maximum absolute log(odds ratio) between main effects for an interaction to be included. Additionally, another set of simulations was performed with varying tuning parameter alpha in the elastic net analyses, each based on 10,000 simulations for different values of alpha. These extensive simulations were crucial for optimizing the model's performance and ensuring robust results.\n\nFurthermore, the simulation study with three active interactions, which altered definitions for the simulated datasets, also contributed to the overall execution time. This study aimed to optimize interpretability and avoid setting interaction effects from variables already active in other main or interaction effects.\n\nThe actual runtime for these simulations would depend on the computational resources available, but the process was designed to be thorough, ensuring that the model's parameters were finely tuned for accuracy and reliability. The use of elastic net analyses, with an optimal alpha value of 0.75, further refined the model's ability to handle correlated data effectively.",
  "model/availability": "The source code for the analyses described in the publication is publicly available. It can be accessed by cloning the repository from the following URL: https://github.com/davgyl/dd_ident. The repository is archived on Zenodo with the DOI: 10.5281/zenodo.3778351.\n\nThe repository contains R scripts that can be sourced to load the necessary functions and packages. The specific scripts include:\n\n* `01_load_pkgs.R` for loading required R packages.\n* `02_simdata.R` for simulating data.\n* `03_preprocess.R` for preprocessing the data.\n* `04_plot_prev.R` for plotting prevalence.\n* `05_plot_heatmap.R` for plotting heatmaps.\n* `06_glmnet.R` for performing elastic net analyses.\n\nAdditionally, the repository includes an R function named `dd_sim` that can be used to produce simulation data. This function allows for reproducible data generation by setting a seed.\n\nThe R packages used in the analyses include `tidyverse`, `simstudy`, `stringr`, `glmnet`, `furrr`, `tictoc`, `openxlsx`, and `knitr`. These packages are essential for data manipulation, simulation, string operations, regularization, parallel processing, timing, Excel file handling, and dynamic report generation, respectively.\n\nThe code and methods provided in the repository enable users to reproduce the analyses and apply similar techniques to their own datasets. The repository is released under a permissive license, allowing for wide use and modification.",
  "evaluation/method": "The evaluation method employed in this study primarily involved extensive simulation studies to assess the performance of the analytic pipeline. These simulations were designed to mimic epidemiologic data, incorporating groups of correlated variables, variables with differing prevalence, and both active main and interaction effects. The goal was to evaluate the ability of machine learning techniques, specifically the elastic net algorithm, to capture complex relationships between variables.\n\nSeveral criteria were varied in the simulations to understand their impact on the true positive (TP) and false positive (FP) rates. These criteria included the maximum absolute log(odds ratio) between main effects for an interaction to be included in the analyses, the tuning parameter alpha in the elastic net analyses, and the number of active interactions in the datasets. For each criterion, 10,000 simulations were conducted, resulting in a total of 30,000 simulations for different log(odds ratio) criteria and 30,000 simulations for different alpha values.\n\nThe simulations revealed that the FP rate remained below 5% regardless of the log(odds ratio) criterion used. However, the power to detect interaction effects varied, with a log(odds ratio) criterion of 0.3 being chosen for the main analyses due to its balance between TP and FP rates. Additionally, an alpha value of 0.75 was selected for the elastic net analyses, as it showed the highest TP rate for detecting interaction effects and is theoretically better suited for correlated data.\n\nFurther simulations were conducted with varying numbers of subjects, prevalence of active interactions, odds ratios of interaction effects, and within-group correlations. These simulations helped to identify the conditions under which the analytic pipeline performed optimally, with the goal of maximizing the TP rate while keeping the FP rate low.\n\nIn summary, the evaluation method relied heavily on simulation studies to rigorously test the analytic pipeline under various conditions. This approach allowed for a comprehensive assessment of the method's performance in identifying main and interaction effects, ensuring robustness and reliability in the results.",
  "evaluation/measure": "In the evaluation of our simulation study, we primarily focused on two key performance metrics: the true positive (TP) rate and the false positive (FP) rate. These metrics were used to assess the effectiveness of our methods in identifying both main effects and interaction effects within the simulated datasets.\n\nThe TP rate, also known as power, measures the proportion of simulations in which the active effects (either main or interaction) were correctly identified. This metric is crucial for understanding the sensitivity of our approach in detecting relevant effects.\n\nThe FP rate, on the other hand, indicates the proportion of simulations in which non-active effects were incorrectly identified as significant. This metric is essential for evaluating the specificity of our methods and ensuring that our findings are not inflated by false discoveries.\n\nWe reported these metrics under various conditions, including different criteria for the maximum absolute log(odds ratio) between main effects for an interaction to be included in the analyses, varying tuning parameter alpha in the elastic net analyses, and different definitions of simulated datasets with multiple active interactions.\n\nThe reported TP and FP rates provide a comprehensive view of the performance of our methods, showing that the FP rate remained below 5% regardless of the criteria used. However, the power to detect interaction effects varied depending on the specific criteria and definitions applied.\n\nThese performance metrics are representative of those commonly used in the literature for evaluating the effectiveness of statistical and machine learning methods in identifying main and interaction effects in epidemiological and genetic studies. By focusing on TP and FP rates, we ensure that our evaluation is aligned with standard practices in the field, allowing for meaningful comparisons with other studies.",
  "evaluation/comparison": "To evaluate the performance of our analytic approach, we conducted a comparison with traditional marginal screening methods. This involved simulation studies and marginal screening of previously reported interaction effects. Specifically, we applied Bonferroni correction to marginal screening and compared the true positive (TP) and false positive (FP) rates for detecting interactions and main effects.\n\nThe results indicated that the TP and FP rates for detecting interactions were similar between our elastic net variable selection approach and the marginal screening method with Bonferroni correction. However, the FP rate for identifying main effects varied significantly. When using marginal screening, the FP rate ranged between 3.6% and 71.1%, whereas it remained between 0.5% and 1.3% when using variable selection. This comparison highlights the robustness of our approach in maintaining a low FP rate for main effects while effectively identifying interaction effects.\n\nAdditionally, we performed a simulation study with varying criteria that defined the maximum absolute log(odds ratio) between main effects for an interaction to be included in the analyses. We calculated the empirical TP and FP rates for identifying main and interaction effects using different log(odds ratio) criteria (0.1, 0.3, and 0.5). The FP rate remained below 5% regardless of the criterion used, but the power to detect interaction effects varied. We opted for a log(odds ratio) criterion of 0.3 for the analyses reported in the main text due to its balanced performance.\n\nFurthermore, we conducted a simulation study with varying tuning parameter alpha in the elastic net analyses while keeping the log(odds ratio) criterion constant at 0.3. The analysis showed that both the FP and TP rates were similar regardless of the alpha value used (0.5, 0.75, and 1). We chose an alpha value of 0.75 because it demonstrated the highest TP rate for detecting interaction effects and is theoretically and empirically supported for handling correlated data.\n\nIn summary, our comparison with simpler baselines and publicly available methods, along with extensive simulation studies, demonstrates the effectiveness and reliability of our analytic approach in identifying main and interaction effects while maintaining a low FP rate.",
  "evaluation/confidence": "In our study, we employed rigorous statistical methods to evaluate the performance of our approach. We utilized Bonferroni-corrected p-values and confidence intervals (CI) to assess the significance and reliability of our findings. These corrections are crucial for maintaining the family-wise error rate, especially when conducting multiple comparisons.\n\nThe performance metrics, including true positive (TP) and false positive (FP) rates, were derived from extensive simulation studies involving 10,000 datasets for each definition. These simulations allowed us to calculate empirical TP and FP rates, providing a robust estimate of our method's performance.\n\nOur results indicate that the false positive rate remained consistently below 5% across various simulation scenarios, demonstrating the method's reliability in controlling for Type I errors. The true positive rate, which reflects the power to detect active main and interaction effects, varied depending on the simulation parameters. For instance, the power to detect interaction effects increased with higher odds ratios (OR) of the active interactions.\n\nWe also compared our elastic net variable selection approach with traditional marginal screening. The elastic net method showed a lower FP rate for identifying main effects (ranging from 0.5% to 1.3%) compared to marginal screening (ranging from 3.6% to 71.1%). This comparison underscores the superior performance of the elastic net in maintaining a low false positive rate while identifying significant effects.\n\nAdditionally, we conducted power analyses to further validate our findings. These analyses involved modifying and running simulation scripts to summarize the results, ensuring that our conclusions are supported by comprehensive statistical evidence.\n\nIn summary, the performance metrics in our study are accompanied by confidence intervals and statistical significance tests, providing a strong basis for claiming the superiority of our method over traditional approaches. The rigorous simulation studies and comparisons with baseline methods reinforce the reliability and validity of our results.",
  "evaluation/availability": "The raw evaluation files are not publicly available. The evaluation was conducted using simulated datasets, and the code to reproduce these analyses is provided in a repository. This repository can be cloned from a specific URL, and it includes R scripts that load necessary functions and perform various analyses. The simulations were based on predefined criteria and parameters, such as the log(odds ratio) and tuning parameters in elastic net analyses. The results of these simulations, including true positive and false positive rates, are reported in supplemental tables. However, the actual raw data files used for these evaluations are not released publicly."
}