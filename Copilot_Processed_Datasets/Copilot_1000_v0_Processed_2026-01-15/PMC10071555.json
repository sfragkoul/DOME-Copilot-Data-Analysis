{
  "publication/title": "Predicting future falls in older people using NLP of clinical notes",
  "publication/authors": "The authors who contributed to the article are:\n\n- Noman Dormosh, who is associated with the Department of Medical Informatics at Amsterdam UMC and Amsterdam Public Health. He likely played a significant role in the conceptualization and execution of the study, particularly in the application of natural language processing techniques.\n\n- Martijn C. Schut, affiliated with the Department of Clinical Chemistry at Amsterdam UMC and Amsterdam Public Health. His contributions likely involved data analysis and methodological support.\n\n- Martijn W. Heymans, from the Department of Epidemiology and Data Science at Amsterdam UMC and Amsterdam Public Health. He probably contributed to the epidemiological aspects of the study and data interpretation.\n\n- Otto Maarsingh, associated with the Department of General Practice at Amsterdam UMC and Amsterdam Public Health. His expertise in general practice likely aided in the clinical interpretation of the findings.\n\n- Jonathan Bouman, also from the Department of General Practice at Amsterdam UMC. He likely provided insights into the clinical relevance and practical implications of the study.\n\n- Nathalie van der Velde, from the Department of Internal Medicine at Amsterdam UMC and Amsterdam Public Health. Her contributions likely focused on the geriatric aspects of the study.\n\n- Ameen Abu-Hanna, affiliated with the Department of Medical Informatics at Amsterdam UMC and Amsterdam Public Health. He likely oversaw the integration of medical informatics techniques and the overall direction of the research.",
  "publication/journal": "Not enough information is available.",
  "publication/year": "2023",
  "publication/pmid": "37014000",
  "publication/pmcid": "PMC10071555",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Natural Language Processing\n- Clinical Notes\n- Fall Prediction\n- Machine Learning\n- Topic Modeling\n- Older Adults\n- Predictive Performance\n- Structured Clinical Variables\n- Unstructured Data\n- Primary Care",
  "dataset/provenance": "The dataset used in this study was sourced from the pseudonymised database of the Academic General Practitioner\u2019s Network at the Academic Medical Center (AHA AMC). This database contains anonymised primary care electronic health records (EHR) data collected from 50 general practices in the province of North Holland in the Netherlands. The data spans from 2012 to 2019 and includes demographics, diagnoses, medication prescriptions, and de-identified clinical notes in Dutch.\n\nThe study sample included patients enlisted with general practitioners (GPs) between 2018 and 2019. Baseline data, consisting of structured clinical variables and unstructured clinical notes, were obtained from the observation period in the year 2018. Data from the follow-up period in the year 2019 were used to determine the outcome, which was defined as any fall event occurring within a 1-year follow-up period.\n\nThe dataset comprised data from 36,470 older individuals. Of these, 4,778 individuals (13.1%) experienced falls. The structured clinical variables included age, sex, 33 medication groups, and 43 chronic medical conditions associated with patients in the observation period. The clinical notes were mainly written by GPs and followed the SOAP structure (Subjective, Objective, Assessment, and Plan). These notes were pre-processed by lowering the text and removing non-letter characters.\n\nThe study included individuals aged 65 or older at the beginning of 2018 who had more than one word in their clinical notes written in 2018. A total of 1,113 individuals were excluded from the analysis due to missing clinical notes or notes with fewer than two words. The excluded individuals were generally younger.\n\nThe outcome and clinical variables were defined and obtained in the same manner as in a previous study. The list of clinical variables is provided in Supplementary Appendix 1. The clinical notes were extracted and combined into one text record per patient, which was then used for further analysis.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The data underlying this article were provided by the Academic General Practitioner\u2019s Network at the Academic Medical Center. For privacy reasons, the data cannot be made publicly available. However, reasonable requests for conditional reuse of the data can be submitted to the corresponding author. This ensures that the data is accessible for further research while maintaining the privacy and confidentiality of the patients involved. The data includes anonymized primary care electronic health records (EHR) from 50 general practices in the province of North Holland in the Netherlands, covering patients registered between 2012 and 2019. The dataset includes demographics, diagnoses, medication prescriptions, and de-identified clinical notes in Dutch. The data was extracted from a pseudonymized database, which means that all patient identifiers were removed or replaced with pseudonyms to protect patient privacy. This approach aligns with Dutch privacy legislation and ensures that the data can be used for research purposes without compromising patient confidentiality.",
  "optimization/algorithm": "The optimization algorithm employed in our study is the least absolute shrinkage and selection operator (Lasso), a type of penalized logistic regression. This method is well-established and not new, having been introduced by Tibshirani in 1996. It is widely used in statistical and machine learning communities for its ability to perform both variable selection and regularization to enhance the prediction accuracy and interpretability of the statistical model.\n\nLasso was chosen for its effectiveness in handling high-dimensional data by shrinking some coefficient estimates to zero, effectively performing feature selection. This is particularly useful in our context, where we deal with a large number of structured clinical variables and topics extracted from unstructured clinical notes.\n\nThe implementation of Lasso in our study was carried out using the `glmnet` package in R, which is a robust and efficient tool for fitting generalized linear models with penalization. This package is well-documented and widely used in the statistical community, ensuring reliability and reproducibility of our results.\n\nThe decision to use Lasso was driven by its proven track record in similar predictive modeling tasks, particularly in healthcare, where the interpretation of model coefficients is crucial for clinical decision-making. While Lasso is not a novel algorithm, its application in the context of fall risk prediction using both structured and unstructured data is a significant contribution to the field.",
  "optimization/meta": "The models developed for predicting 1-year fall risk in older people do not function as meta-predictors. Instead, three distinct prediction models were created: a Baseline model using only structured clinical variables, a Topic-based model using topics extracted from clinical notes, and a Combi model that combines both structured clinical variables and extracted topics.\n\nThe Combi model, in particular, integrates information from both structured data and unstructured clinical notes, but it does not use the outputs of other machine-learning algorithms as input. Rather, it concatenates the structured clinical variables with the topics derived from the clinical notes, which are generated using the top2vec method.\n\nThe training data for these models were internally validated using 10-fold cross-validation, ensuring that the data used for training and validation were independent within each fold. This approach helps to mitigate overfitting and provides a more robust assessment of the models' performance.\n\nThe models were constructed using penalized logistic regression with the least absolute shrinkage and selection operator (Lasso), which allows for variable selection during the model-fitting process. This method helps in identifying the most relevant features from the structured clinical variables and the topics extracted from the clinical notes.",
  "optimization/encoding": "The data encoding process involved transforming unstructured clinical notes into a numerical format suitable for machine learning algorithms. The clinical notes, primarily written by general practitioners, were pre-processed by converting all text to lowercase and removing non-letter characters. This preprocessing step ensured consistency and reduced noise in the text data.\n\nTo represent the unstructured texts numerically, the top2vec algorithm was employed. This algorithm maps words and documents into an n-dimensional vector space based on semantic relatedness. The process involved clustering document vectors and calculating the arithmetic mean of each cluster to obtain topic vectors. Each document was then represented as a vector of distances to all identified topics. This approach allowed the extraction of meaningful topics from the clinical notes, which could be used as input variables for the machine learning models.\n\nThree prediction models were developed: a Baseline model using only structured clinical variables, a Topic-based model using topics extracted by top2vec, and a Combi model that combined both structured clinical variables and extracted topics. The models were constructed using penalized logistic regression with the least absolute shrinkage and selection operator (Lasso), which facilitates variable selection during model fitting. Internal validation, including lambda tuning, was performed using 10-fold cross-validation to ensure the robustness of the models.",
  "optimization/parameters": "In our study, we developed three prediction models to predict 1-year fall risk in older people. The first model, the Baseline model, used only structured clinical variables. The second model, the Topic-based model, utilized topics extracted from clinical notes using the top2vec algorithm. The third model, the Combi model, combined both the structured clinical variables and the extracted topics.\n\nThe number of parameters (p) in each model varied depending on the input features used. For the Baseline model, p was determined by the number of structured clinical variables, which included age, sex, 33 medication groups, and 43 chronic medical conditions. For the Topic-based model, p was determined by the number of topics extracted from the clinical notes, which totaled 151. The Combi model had the highest number of parameters, as it combined the structured clinical variables and the extracted topics.\n\nThe selection of p was inherently tied to the model development process. For the Baseline and Topic-based models, p was determined by the features available in the respective datasets. For the Combi model, p was the sum of the features from both datasets. Additionally, we applied penalized logistic regression using the least absolute shrinkage and selection operator (Lasso) to allow for variable selection as part of fitting the model. This process helped in selecting the most relevant features, thereby optimizing the number of parameters used in each model.",
  "optimization/features": "In our study, we developed three prediction models to predict 1-year fall risk in older people. The input features for these models varied.\n\nFor the Baseline model, we used only structured clinical variables. The exact number of these variables is not specified here, but they were selected using the least absolute shrinkage and selection operator (Lasso), which allows for variable selection as part of fitting the model. This feature selection was performed using the training set only, ensuring that the model's performance is not overestimated.\n\nThe Topic-based model used topics extracted by top2vec as input. The top2vec algorithm produced 151 topics from the clinical notes. However, not all of these topics were used in the final model. After applying Lasso, 36 topics were retained for the Topic-based model.\n\nThe Combi model combined the structured clinical variables with the extracted topics. In this model, 11 topics and 37 clinical variables were retained after applying Lasso. Again, feature selection was performed using the training set only.\n\nIn all models, internal validation was performed using 10-fold cross-validation, including lambda tuning. This ensures that the models' performance is generalizable to new, unseen data.",
  "optimization/fitting": "In our study, we developed three prediction models to predict 1-year fall risk in older people. The number of parameters in our models was indeed much larger than the number of training points, particularly when considering the unstructured clinical notes. To address this and rule out over-fitting, we employed penalized logistic regression using the least absolute shrinkage and selection operator (Lasso). Lasso is a regularization technique that performs both variable selection and regularization to enhance the prediction accuracy and interpretability of the statistical model it produces. It does this by adding a penalty equal to the absolute value of the magnitude of coefficients to the loss function. This penalty shrinks some coefficients to zero, effectively performing feature selection, and reduces the complexity of the model, which helps to prevent over-fitting.\n\nTo further ensure the robustness of our models, we used 10-fold cross-validation for internal validation, including lambda tuning. This process involved dividing the data into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This procedure was repeated 10 times, with each subset serving as the validation set once. The average performance across all folds was used to evaluate the model, providing a more reliable estimate of its performance on unseen data.\n\nTo rule out under-fitting, we carefully selected relevant features and ensured that our models were complex enough to capture the underlying patterns in the data. The use of Lasso helped in selecting the most relevant features, reducing the risk of under-fitting by not overly simplifying the model. Additionally, the combination of structured clinical variables and topics extracted from unstructured clinical notes in the Combi model provided a richer set of features, enhancing the model's ability to capture the complexities associated with fall risk prediction.",
  "optimization/regularization": "In our study, we employed regularization techniques to prevent overfitting. Specifically, we used the least absolute shrinkage and selection operator (Lasso) for our logistic regression models. Lasso is a type of penalized regression that adds a penalty equal to the absolute value of the magnitude of coefficients. This method encourages sparsity in the model by shrinking some coefficients to zero, effectively performing both variable selection and regularization. By doing so, Lasso helps to simplify the model and reduce the risk of overfitting, especially when dealing with a large number of predictors. This approach was crucial in ensuring that our models generalized well to new data.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not explicitly detailed in the provided information. However, the optimization parameters used in the study are reported. The models were developed using penalized logistic regression with the least absolute shrinkage and selection operator (Lasso), which allows for variable selection as part of fitting the model. Internal validation, including lambda tuning, was performed using 10-fold cross-validation. The specific packages and tools used for these processes are mentioned, such as the R statistical software environment version 4.0, the package glmnet for Lasso, and the python implementation of top2vec interfaced to R using the package reticulate. The study also includes a checklist of the Minimum Information About Clinical Artificial Intelligence (MI-CLAIM) in Supplementary Appendix 3, which may provide additional details on the configuration and optimization processes. The data underlying this article were provided by the Academic General Practitioner\u2019s Network at Academic Medical Center (AHA AMC), but for privacy reasons, the data cannot be made publicly available. Reasonable requests for conditional reuse of the data can be submitted to the corresponding author.",
  "model/interpretability": "The models developed in this study are not entirely black-box. While the machine learning algorithms used, such as penalized logistic regression with Lasso, are inherently complex, efforts were made to ensure interpretability.\n\nThe topic-based model, in particular, leverages the top2vec algorithm to extract meaningful topics from unstructured clinical notes. These topics are represented by clusters of words that are semantically related, making them interpretable by clinicians. For instance, a topic related to cognitive impairment might include words like 'MMSE', 'GDS', 'mental', 'state', and 'examination'. The order of these words reflects their relative importance to the topic, providing a clear context for interpretation.\n\nIn the combined model, which integrates both structured clinical variables and topics extracted from clinical notes, the retained topics and variables can be directly interpreted. For example, topics related to institutionalization, cognitive impairment, previous fractures or injuries, and frailty were found to be associated with a higher fall risk. This transparency allows clinicians to understand the specific reasons contributing to the fall risk prediction.\n\nAdditionally, the use of Lasso for variable selection helps in identifying the most relevant features, further enhancing the interpretability of the models. The retained variables in the baseline model and the combined model are provided in supplementary appendices, allowing for a detailed examination of the factors influencing the predictions.\n\nOverall, while the models involve complex algorithms, the use of interpretable topics and variable selection techniques ensures that the predictions can be understood and validated by clinicians.",
  "model/output": "The model developed in our study is a classification model, specifically designed to predict the risk of falls in older people over a one-year period. It categorizes individuals into two groups: those who are likely to fall and those who are not. This is achieved through the use of logistic regression, which is a type of supervised learning algorithm used for binary classification problems. The model's output is a probability score indicating the likelihood of a fall event occurring within the specified time frame. This probability can then be used to make a binary decision, such as classifying an individual as high risk or low risk for falling. The model's performance was evaluated using metrics such as the area under the receiver operating characteristic curve (AUC), which measures the model's ability to discriminate between fallers and non-fallers. Additionally, calibration plots were used to assess how well the predicted probabilities align with the actual outcomes.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the specific algorithms used in our study is not publicly released. However, the implementation of the top2vec algorithm, which was used for topic modeling, is available through its original authors. Additionally, the Lasso regression was performed using the glmnet package in R, which is openly available under the GPL-2 license. The interface between Python and R, facilitated by the reticulate package, is also publicly accessible. For those interested in replicating parts of our analysis, these packages can be utilized. Unfortunately, the exact models and preprocessing steps specific to our study are not provided as standalone software or executable files.",
  "evaluation/method": "The evaluation method for the prediction models involved a comprehensive approach to ensure robustness and reliability. Three prediction models were developed: a Baseline model using only structured clinical variables, a Topic-based model using topics extracted from clinical notes, and a Combi model that combined both structured clinical variables and extracted topics. Each model was constructed using penalized logistic regression with the least absolute shrinkage and selection operator (Lasso), which facilitates variable selection during model fitting.\n\nTo validate the models, 10-fold cross-validation was employed. This technique involves dividing the dataset into 10 subsets, training the model on 9 subsets, and testing it on the remaining subset. This process is repeated 10 times, with each subset serving as the test set once. The performance metrics, specifically the area under the receiver operating characteristic curve (AUC), were averaged over these 10 folds to provide a mean AUC with a 95% confidence interval.\n\nModel performance was assessed in terms of discrimination and calibration. Discrimination was measured by the AUC, which indicates the model's ability to distinguish between individuals who will fall and those who will not. Calibration was evaluated using calibration plots, which compare the predicted probabilities of falls with the actual outcomes. An ideal model would have a calibration plot that lies along the diagonal line, indicating perfect agreement between predicted and observed probabilities.\n\nTo compare the AUCs of the different models, DeLong's method was used. This statistical test determines whether the differences in AUCs between models are significant. A P-value of less than 0.05 was considered statistically significant, indicating a meaningful difference in performance.\n\nAll analyses were conducted using the R statistical software environment, version 4.0. The Lasso regression was performed using the glmnet package, and the top2vec implementation was interfaced to R using the reticulate package. This integration allowed for the seamless incorporation of natural language processing techniques into the predictive modeling framework.",
  "evaluation/measure": "To evaluate the performance of our prediction models, we focused on two key metrics: discrimination and calibration.\n\nDiscrimination was assessed using the area under the receiver operating characteristic curve (AUC). This metric measures the ability of the model to distinguish between individuals who will fall and those who will not. We reported the mean AUC and its 95% confidence interval (CI) over 10-fold cross-validation. The AUC provides a single scalar value that summarizes the model's performance across all classification thresholds.\n\nCalibration was evaluated using calibration plots. These plots compare the predicted probabilities of falling with the actual outcomes. An ideal model would lie on the diagonal line, indicating perfect calibration. Points below the diagonal suggest overestimation of risk, while points above indicate underestimation. Additionally, we included histograms of the predicted probabilities to show their distribution.\n\nTo compare the performance of different models, we used DeLong's method to assess the statistical significance of differences in AUCs. This non-parametric approach accounts for the correlation between the models' predictions.\n\nThe reported metrics are widely used in the literature for evaluating predictive models, particularly in medical research. The AUC is a standard measure for assessing discrimination, while calibration plots provide a visual assessment of how well the predicted probabilities align with observed outcomes. Together, these metrics offer a comprehensive evaluation of our models' performance.",
  "evaluation/comparison": "In our study, we developed three prediction models to assess 1-year fall risk in older individuals. These models included a Baseline model using only structured clinical variables, a Topic-based model utilizing topics extracted from clinical notes, and a Combi model that combined both structured clinical variables and extracted topics.\n\nTo evaluate the performance of these models, we employed 10-fold cross-validation, which is a robust internal validation technique. This method allowed us to assess the models' discrimination ability using the area under the receiver operating characteristic curve (AUC) and their calibration through calibration plots.\n\nWe compared the AUCs of each model to the Baseline model using DeLong\u2019s method, considering P-values less than 0.05 as statistically significant. This approach ensured that we could determine whether the addition of topics from clinical notes significantly improved the predictive performance compared to using structured clinical variables alone.\n\nThe Combi model, which integrated both structured clinical variables and topics from clinical notes, demonstrated a significantly higher AUC than the Baseline model. This indicates that incorporating unstructured clinical notes can enhance the predictive accuracy of fall risk assessment models.\n\nWhile we did not compare our methods to publicly available benchmark datasets or simpler baselines explicitly mentioned in the context, our approach of using topics extracted from clinical notes represents a novel application of natural language processing (NLP) techniques in fall risk prediction. The use of top2vec for topic extraction and Lasso for variable selection in logistic regression provided a comprehensive framework for leveraging both structured and unstructured data.\n\nIn summary, our evaluation focused on internal validation and comparison within our developed models, highlighting the potential benefits of integrating clinical notes with structured data for improved fall risk prediction.",
  "evaluation/confidence": "The evaluation of our models included the assessment of discrimination and calibration. For discrimination, we used the area under the receiver operating characteristic curve (AUC), which provides a measure of the model's ability to distinguish between those who will fall and those who will not. The AUCs for our models were reported with 95% confidence intervals to indicate the precision of these estimates. Specifically, the Baseline model had an AUC of 0.709 (CI 95% 0.700\u20130.719), the Topic-based model had an AUC of 0.685 (CI 95% 0.676\u20130.694), and the Combi model had an AUC of 0.718 (CI 95% 0.708\u20130.727). The Combi model's AUC was significantly higher than that of the Baseline model, as determined by DeLong's method, with a P-value less than 0.05, indicating statistical significance.\n\nFor calibration, we used calibration plots to assess how well the predicted probabilities matched the actual outcomes. All models showed good calibration, meaning that the predicted probabilities were well-aligned with the observed fall rates. This was visually represented in the calibration plots, where the dashed line indicating the actual model calibration closely followed the diagonal line representing an ideal model.\n\nIn summary, the performance metrics included confidence intervals, and the results demonstrated statistical significance in comparing the Combi model to the Baseline model. This provides a strong basis for claiming that the Combi model, which integrates both structured clinical variables and topics extracted from unstructured clinical notes, offers superior predictive performance.",
  "evaluation/availability": "The raw evaluation files underlying this article were provided by the Academic General Practitioner\u2019s Network at the Academic Medical Center. Due to privacy concerns, these data cannot be made publicly available. However, reasonable requests for conditional reuse of the data can be submitted to the corresponding author. This approach ensures that the data is handled responsibly while allowing for potential future research and validation of the findings."
}