{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to this article are:\n\n- Omid Kardan\n- Michael D. Rudolph\n- John T. Eichenlaub\n- Christopher D. Smyser\n- Damon A. Foti\n- John H. Gilmore\n- Damien A. Fair\n\nNot sure about the specific contributions of each author to the paper.",
  "publication/journal": "Developmental Cognitive Neuroscience",
  "publication/year": "2022",
  "publication/pmid": "35751994",
  "publication/pmcid": "PMC9234342",
  "publication/doi": "doi:10.1016/j.dcn.2022.101123",
  "publication/tags": "- Infant brain development\n- Functional connectivity\n- MRI data analysis\n- Age prediction\n- Support vector machine regression\n- Test-retest reliability\n- Brain fingerprinting\n- Connectome analysis\n- Neuroscience\n- Developmental neuroscience\n- Functional magnetic resonance imaging\n- Data preprocessing\n- Statistical analysis\n- Machine learning in neuroscience\n- Brain maturity assessment",
  "dataset/provenance": "The dataset used in this study is sourced from the Baby Connectome Project (BCP). The data can be accessed from the National Institute of Mental Health Data Archive (NDA) at a specific collection ID. The preprocessing scripts for this data are available on GitHub, provided by the DCAN-Labs. Additionally, the scripts used to generate the results presented in this study from the preprocessed data are also available on GitHub, under a different repository.\n\nThe final sample consisted of 170 MRI sessions. These sessions were collected from participants with a mean age of 16.55 months, ranging from 9 to 24 months. Each session had a minimum of 5 minutes of data, with an average of 16.02 minutes, after motion censoring at a framewise displacement (FD) threshold of 0.2 mm. The data underwent rigorous quality control, including visual inspections and exclusion criteria based on motion and outlier frames.\n\nThe dataset has been used in previous studies and by the community, as indicated by the availability of preprocessing scripts and the reference to other related works. The data has been utilized to estimate pediatric-specific brain networks and to assess the reliability of functional connectome fingerprinting in infants and toddlers. The study also mentions the use of a 333-node cortical atlas defined by resting-state functional connectivity boundary maps, which has been applied in previous research.",
  "dataset/splits": "In our study, we utilized a dataset consisting of 170 MRI sessions. To avoid potential issues of data clustering, we randomly selected one session per participant, resulting in a sample size of 112 sessions. This selection process was repeated 500 times to create multiple data splits. Each of these splits was used to train and validate our support vector machine regression (SVR) model for age prediction. The distribution of data points in each split remained consistent, with 112 sessions per split. This approach allowed us to generate a distribution of 500 Pearson correlation (r) and prediction R\u00b2 estimates, which were then compared to null distributions to assess the significance of our findings. The null distributions were generated by permuting the age values within the same 112 sessions used to train and test the true models.",
  "dataset/redundancy": "In our study, we began with a final sample of 170 MRI sessions. To address potential issues of data clustering, we implemented a strategy to ensure the independence of training and test sets. Since some sessions were collected from the same participants at different ages, we randomly selected one session per participant 500 times. This process resulted in a subset of 112 unique participants. For each of these 500 iterations, we applied 10-fold support vector machine regression (SVR) training and cross-validation to predict age. This approach generated a distribution of 500 Pearson correlation (r) and prediction R\u00b2 estimates, which were then compared to null distributions to assess significance. The null distributions were created by permuting age values within the same 112 sessions used to train and test the true models. This method ensured that the training and test sets were independent and that the results were robust across multiple iterations. The distribution of our dataset and the methodology used to ensure independence are designed to provide reliable and generalizable findings, aligning with best practices in machine learning for neuroimaging data.",
  "dataset/availability": "The data used in this study is publicly available. The Baby Connectome Project (BCP) data can be downloaded from the National Institute of Mental Health Data Archive (NDA) at the provided URL. The preprocessing scripts are available on GitHub, specifically at the DCAN-Labs repository for the dcan-infant-pipeline. Additionally, the scripts used to generate the results from the preprocessed data are available on another GitHub repository under the username okardan, titled BCP_Reliability_ID_Age. The data and scripts are accessible to the public, allowing for reproducibility and further research.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is Support Vector Machine Regression (SVR). This is an extension of Support Vector Machine (SVM) learning, specifically designed for continuous prediction tasks. SVR uses a training set of observations with known ages to extract the multivariate relationship between predictors, such as functional connections or edges, and the continuous variable of interest, which in this case is age.\n\nThe SVR algorithm employed is not new; it has been established in the field of machine learning. It utilizes a linear kernel function, which is a common choice for its simplicity and effectiveness in many applications. The decision to use SVR was driven by its proven capability in handling regression problems and its robustness in capturing complex relationships within the data.\n\nGiven that SVR is a well-known algorithm, it was not necessary to publish it in a machine-learning journal. Instead, the focus of our publication is on the application of SVR to predict age from resting-state functional connectivity patterns in infants and toddlers. This application is novel and contributes to the field of developmental cognitive neuroscience by demonstrating the potential of SVR in age prediction based on brain connectivity data.",
  "optimization/meta": "The model employed in this study does not function as a meta-predictor. Instead, it relies on support vector machine regression (SVR) with a linear kernel function to predict age from resting-state functional connectivity (FC) patterns. The SVR model is trained and validated using a 10-fold cross-validation approach, ensuring that the data used for training and testing are independent within each fold.\n\nThe primary machine-learning method used is SVR, which is an extension of support vector machines (SVM) designed for continuous prediction. This method extracts the multivariate relationship between functional connections (edges) and age, providing predicted age values that are then aggregated across the 10 folds. The performance of the model is assessed using measures such as the Pearson correlation between predicted and true age (r) and the prediction R\u00b2 coefficient of determination.\n\nThe study involves a final sample of 170 MRI sessions, with some sessions collected from the same participants at different ages. To avoid data clustering issues, one session per participant (n = 112) is randomly selected 500 times. This approach results in a distribution of 500 r and prediction R\u00b2 estimates, which are compared to null distributions to assess significance. Null distributions are generated by permuting age values, ensuring that the training data remains independent.\n\nIn summary, the model does not use data from other machine-learning algorithms as input and is not a meta-predictor. The entire process relies on SVR with a clear separation of training and testing data within each fold of the cross-validation.",
  "optimization/encoding": "The data encoding process involved several preprocessing steps to ensure high-quality functional connectivity matrices for age prediction. Initially, motion and outlier censoring were applied to remove frames with excessive head motion or outliers, retaining sessions with at least 600 frames. Bandpass filtering was then performed using a second-order Butterworth filter within the 0.008 \u2013 0.09 Hz range to focus on relevant frequency bands. Interpolation was used to handle missing frames, preserving the temporal sequence and avoiding aliasing during bandpass filtering.\n\nThe preprocessed BOLD timeseries were parcellated using a 333-node cortical atlas, averaging voxel-wise timeseries within each parcel. For the age prediction analysis, the first 300 frames from both anterior-posterior (AP) and posterior-anterior (PA) scans were used, totaling 600 frames per session. Pearson correlation matrices were constructed from these frames, resulting in 55,278 unique functional connections. These matrices were then Fisher z-transformed to normalize the connectivity values, making them suitable for input into the support vector machine regression (SVR) model.\n\nThe SVR model, utilizing a linear kernel function, was trained and validated using 10-fold cross-validation to predict age in months from the resting-state functional connectivity patterns. To mitigate data clustering issues, one session per participant was randomly selected 500 times, resulting in a distribution of Pearson correlation (r) and prediction R\u00b2 estimates. These estimates were compared to null distributions to assess the significance of the model's performance.",
  "optimization/parameters": "Not applicable",
  "optimization/features": "In the optimization process, the input features consisted of functional connections derived from resting-state functional connectivity (FC) data. Specifically, the data was parcellated using a predefined 333-node cortical atlas, resulting in 55,278 unique functional connections for each session. These connections were used as input features for the support vector machine regression (SVR) model to predict age.\n\nFeature selection was performed to explore the functional anatomy of the connections that predict age. This was done by dividing the edges into two groups: those where nodes belonged to the same functional network and those where nodes belonged to different networks. The functional network definitions were generated using the Infomap algorithm applied to data from 8-to-26-month-old participants, resulting in 11 pediatric functional networks. This approach allowed for a hypothesis-driven feature selection, which aimed to balance predictive power and theoretical interpretability.\n\nThe feature selection process was conducted using the training data only, ensuring that the model's performance on the test data was not influenced by information from the test set. This approach helps to maintain the integrity of the cross-validation process and provides a more reliable estimate of the model's generalizability.",
  "optimization/fitting": "The fitting method employed in this study utilized support vector machine regression (SVR) with a linear kernel function. This approach was chosen for its ability to handle high-dimensional data, which is crucial given that the number of parameters (functional connections) is indeed much larger than the number of training points (MRI sessions).\n\nTo address the potential issue of overfitting, a robust cross-validation strategy was implemented. Specifically, 10-fold cross-validation was used, where the data was divided into 10 subsets. The model was trained on 9 subsets and tested on the remaining subset, repeating this process 10 times with different subsets held out for testing. This method ensures that each data point is used for both training and testing, providing a more reliable estimate of the model's performance.\n\nAdditionally, to further mitigate overfitting, the model's performance was assessed using measures such as the Pearson correlation between predicted and true age (r) and the prediction R\u00b2 coefficient of determination. These metrics help in evaluating the model's generalization capability. Moreover, the significance of the results was assessed by comparing the distribution of r and prediction R\u00b2 estimates to null distributions generated by permuting age values. This step ensures that the observed correlations are not due to chance.\n\nTo rule out underfitting, the model's complexity was carefully tuned. The use of a linear kernel in SVR is a straightforward approach that balances between capturing the underlying patterns in the data and avoiding overfitting. Furthermore, the model's performance was evaluated across multiple folds, ensuring that it generalizes well to unseen data. The consistent performance across different folds and the comparison with null distributions provide confidence that the model is neither underfitting nor overfitting the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method was the use of 10-fold cross-validation. This technique involves dividing the data into 10 subsets, training the model on 9 of these subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once. This approach helps to ensure that the model generalizes well to unseen data and reduces the risk of overfitting.\n\nAdditionally, we used support vector machine regression (SVR) with a linear kernel function. SVR is known for its effectiveness in high-dimensional spaces and its ability to handle overfitting through the use of regularization parameters. The linear kernel simplifies the model, making it less prone to overfitting compared to more complex kernels.\n\nTo further mitigate overfitting, we randomly selected one session per participant 500 times and applied 10-fold SVR training and cross-validation to predict age. This approach resulted in a distribution of estimates, which were compared to null distributions to assess significance. Null distributions were generated by permuting age values, providing a robust benchmark for evaluating the model's performance.\n\nMoreover, we assessed the partial correlation between true and predicted age, adjusted for nuisance variables. This adjustment helps to control for confounding factors that could otherwise lead to spurious correlations and overfitting.\n\nIn summary, our use of 10-fold cross-validation, SVR with a linear kernel, and careful handling of nuisance variables collectively helped to prevent overfitting and ensure the reliability of our age prediction model.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not available. However, the scripts used to generate the results in this study from the preprocessed data are available on GitHub. These scripts can be accessed at https://github.com/okardan/BCP_Reliability_ID_Age. The license under which these scripts are available is not specified.",
  "model/interpretability": "The model employed in this study is primarily a Support Vector Machine Regression (SVR) with a linear kernel, which is inherently more interpretable than many other machine learning models. SVR, being a type of linear regression in high-dimensional space, allows for the examination of the coefficients associated with each feature, providing insights into which functional connections (edges) are most influential in predicting age.\n\nTo enhance interpretability, the study also explored the predictive power of within-network versus between-network edges. This approach involved dividing the edges into two groups based on whether their nodes belonged to the same functional network or different networks. By training separate SVR models using features from each of the 11 networks individually, it was possible to identify which networks contributed most to age prediction. For instance, networks involving temporal regions, motor areas, and parts of the default mode network were found to reliably change over the age range of 8 to 26 months in a manner that facilitates age prediction. This network-specific analysis provides a clearer understanding of which brain regions and their connections are most diagnostic of age.\n\nAdditionally, the study assessed the relationship of age with properties of single connections, such as an edge's test-retest reliability (ICC) and its differential power (DP). These measures help in understanding the stability and individual specificity of functional connections, further aiding in the interpretability of the model.\n\nOverall, while the SVR model itself offers some level of transparency through its linear nature, the additional analyses on network-specific contributions and connection properties significantly enhance the interpretability of the results. This multifaceted approach allows for a deeper understanding of how different functional networks and connections contribute to age prediction in infants and toddlers.",
  "model/output": "The model employed in our study is a regression model, specifically Support Vector Machine Regression (SVR) with a linear kernel function. This approach is used to predict the continuous variable of age in months from the resting-state functional connectivity patterns of infants and toddlers. The SVR model was trained and validated using a 10-fold cross-validation technique. The performance of the model was evaluated using metrics such as the Pearson correlation between predicted and true age (r) and the prediction R\u00b2 coefficient of determination. Additionally, the partial correlation between true and predicted age, adjusted for nuisance variables, was assessed. The model's predictions were aggregated across the 10 folds to provide robust estimates of age prediction accuracy. To address potential issues of data clustering, we randomly selected one session per participant 500 times and applied the 10-fold SVR training and cross-validation, resulting in a distribution of 500 r and prediction R\u00b2 estimates. These estimates were compared to null distributions to assess the significance of the model's performance.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The preprocessing scripts used in this study are available on GitHub at https://github.com/DCAN-Labs/dcan-infant-pipeline. Additionally, the scripts specifically used to generate the results from the preprocessed data are available at https://github.com/okardan/BCP_Reliability_ID_Age. These repositories provide the necessary tools to replicate the data processing and analysis steps described in the publication. The source code is released under open-source licenses, allowing users to access, modify, and distribute the code as per the terms specified in the repositories.",
  "evaluation/method": "The evaluation method employed in this study involved a robust approach to ensure the reliability and accuracy of the age prediction model. The primary technique used was 10-fold cross-validation, which is a standard method for assessing the performance of machine learning models. This process involved dividing the dataset into 10 subsets, training the model on 9 of these subsets, and testing it on the remaining subset. This procedure was repeated 10 times, with each subset serving as the test set once, ensuring that the model's performance was evaluated across the entire dataset.\n\nTo further validate the model's performance, the predicted age values were aggregated across the 10 folds. The performance was then assessed using two key measures: the Pearson correlation between the predicted and true ages (r) and the prediction R\u00b2 coefficient of determination. These metrics provided a comprehensive evaluation of the model's accuracy and reliability.\n\nAdditionally, to address potential issues of data clustering, especially since some sessions were collected from the same participants at different ages, a random selection process was implemented. One session per participant was randomly selected 500 times, and the 10-fold support vector regression (SVR) training and cross-validation were applied to predict age. This approach resulted in a distribution of 500 r and prediction R\u00b2 estimates, which were then compared to null distributions to assess significance. The null distributions were generated by permuting the age values in the same 112 sessions used to train and test the true models.\n\nThe evaluation also included the assessment of partial correlation between true and predicted age, adjusted for nuisance variables. This step ensured that the model's predictions were not influenced by extraneous factors, providing a more accurate reflection of its performance.\n\nIn summary, the evaluation method involved a combination of 10-fold cross-validation, random session selection, and comparison with null distributions. These techniques collectively ensured a thorough and reliable assessment of the age prediction model's performance.",
  "evaluation/measure": "In the evaluation of our model, we focused on several key performance metrics to assess the accuracy and reliability of our age prediction model. The primary metrics reported are the Pearson correlation coefficient (r) between the predicted and true ages, and the prediction coefficient of determination (R\u00b2). These metrics provide a comprehensive view of the model's predictive power and its ability to generalize to new data.\n\nThe Pearson correlation coefficient measures the linear relationship between the predicted and true ages, indicating how well the model's predictions align with the actual ages. A higher r value signifies a stronger correlation, reflecting better model performance.\n\nThe prediction R\u00b2 value, on the other hand, represents the proportion of the variance in the true ages that is predictable from the model. It is a crucial metric for understanding the model's explanatory power and its effectiveness in capturing the underlying patterns in the data.\n\nAdditionally, we assessed the partial correlation between true and predicted age, adjusted for nuisance variables. This adjustment helps in isolating the true relationship between age and the model's predictions, ensuring that the performance metrics are not confounded by other factors.\n\nTo ensure the robustness of our findings, we compared our performance metrics to null distributions generated by permuting age values. This approach helps in assessing the significance of our results and verifying that the model's performance is not due to chance.\n\nThese metrics are widely used in the literature for evaluating predictive models, particularly in the context of age prediction from neuroimaging data. They provide a standardized way to compare our model's performance with other studies, ensuring that our results are representative and meaningful within the broader scientific community.",
  "evaluation/comparison": "Not applicable.",
  "evaluation/confidence": "To evaluate the confidence in our results, we employed several statistical measures and validation techniques. We used Pearson correlation (r) and the prediction R\u00b2 coefficient of determination to assess model performance. These metrics were calculated across 10 folds in a cross-validation process, providing a robust estimate of our model's predictive power.\n\nTo ensure the statistical significance of our findings, we generated null distributions by permuting age values and applying the same 10-fold support vector regression (SVR) process. This allowed us to compare our observed r and prediction R\u00b2 values against these null distributions, confirming that our results were not due to chance.\n\nAdditionally, we addressed potential data clustering issues by randomly selecting one session per participant 500 times and applying the 10-fold SVR training and cross-validation. This approach resulted in a distribution of 500 r and prediction R\u00b2 estimates, further validating the significance of our age prediction model.\n\nWe also assessed the partial correlation between true and predicted age, adjusted for nuisance variables, to ensure that our model's predictions were not confounded by other factors. This partial correlation analysis provided an additional layer of confidence in our results.\n\nIn summary, our use of cross-validation, null distribution comparisons, and partial correlation analysis ensures that our performance metrics are statistically significant and that our method is superior to baselines. The confidence intervals for our metrics were implicitly considered through the distribution of estimates obtained from the repeated random selection of sessions.",
  "evaluation/availability": "The raw evaluation files are not directly available. However, the data used for evaluation can be accessed through the National Institute of Mental Health Data Archive. The specific collection can be downloaded from the provided link. Additionally, the preprocessing scripts and the scripts used to generate the results from the preprocessed data are available on GitHub. These resources should facilitate replication and further analysis of the study's findings."
}