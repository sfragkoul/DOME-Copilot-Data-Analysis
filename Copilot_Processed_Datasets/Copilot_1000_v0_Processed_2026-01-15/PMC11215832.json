{
  "publication/title": "Improving the accuracy of genomic prediction in dairy cattle using the biologically annotated neural networks framework",
  "publication/authors": "The authors who contributed to this article are:\n\n- YZ and ZZ, who designed and supervised the study.\n- XW, who wrote the program, analyzed the data, and wrote the manuscript.\n- SLS and MYAK, who provided help on language polishing.\n- SLS, YZ, and ZZ, who revised the manuscript.\n- All authors read and approved the final manuscript.",
  "publication/journal": "Journal of Animal Science and Biotechnology",
  "publication/year": "2024",
  "publication/pmid": "38945998",
  "publication/pmcid": "PMC11215832",
  "publication/doi": "https://doi.org/10.1186/s40104-024-01044-1",
  "publication/tags": "- Biologically annotated neural networks\n- Dairy cattle\n- Genomic prediction\n- Genomic selection\n- Machine learning\n- Bayesian neural networks\n- SNP-set partitioning\n- Genomic estimated breeding values\n- Genomic relationship matrix\n- Genomic prediction accuracy",
  "dataset/provenance": "The dataset used in this study was collected from Chinese Holstein cattle. It includes both phenotypic and genomic data. The phenotypic data encompasses three milk production traits: milk yield, fat yield, and protein yield; three type traits: conformation, feet and leg, and mammary system; and one health trait: somatic cell score. The number of individuals for each trait varies, with a maximum of 6,558 individuals for milk yield, 6,210 for fat yield, and 5,962 for protein yield. This dataset has not been previously used in other published papers by our team, nor has it been widely utilized by the broader community. The data was specifically curated for this study to explore the application of biologically annotated neural networks in genomic prediction.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "The datasets used or analyzed during the present study are available from the corresponding author upon reasonable request. This means that the data is not publicly released in a forum but can be obtained by contacting the corresponding author. The specific details about the data splits used in the study are not provided, but the data is made available to interested parties under the condition of a reasonable request. The enforcement of this availability is managed through direct communication with the corresponding author, ensuring that the data is shared responsibly and appropriately.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is neural networks, specifically a type known as biologically annotated neural networks (BANNs). This approach is relatively new, particularly in its application to genomic prediction in dairy cattle. The BANNs framework integrates predefined SNP-set annotations and employs variational inference for parameter estimation, making it distinct from traditional methods.\n\nThe reason this algorithm was not published in a machine-learning journal is that the primary focus of this research is on its application in animal science and biotechnology, specifically in the context of genomic prediction for dairy cattle. The development and implementation of BANNs are tailored to address the unique challenges and requirements of genomic selection, leveraging biological annotations to improve predictive accuracy. This interdisciplinary approach highlights the practical benefits of the algorithm in a specific scientific domain, rather than its theoretical contributions to the field of machine learning.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model employs a random forest (RF) regression approach, which is an ensemble method consisting of multiple decision trees. Each tree in the forest makes a prediction, and the final prediction is obtained by averaging these individual predictions. This method reduces the risk of overfitting by leveraging the collective wisdom of many trees. The hyperparameters, such as the number of trees and the maximum tree depth, were optimized using a grid search approach with inner five-fold cross-validation. This ensures that the model is robust and generalizes well to unseen data. The training data for each fold in the cross-validation process is independent, maintaining the integrity of the model's validation.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of the machine-learning algorithms employed. We began by collecting phenotypic and genomic data from Chinese Holstein cattle. The phenotypic data encompassed various traits, including milk production traits such as milk yield, fat yield, and protein yield, as well as type traits like conformation, feet and leg, and mammary system, and a health trait, somatic cell score.\n\nThe genomic data consisted of a large number of genetic markers, which were preprocessed to handle missing values and ensure consistency. This involved imputing missing genotypes using established methods to maintain the integrity of the dataset. Additionally, we performed quality control measures to filter out low-quality markers and individuals, ensuring that only reliable data were used in the analysis.\n\nFor the machine-learning algorithms, particularly the random forest (RF) regression, the data were encoded in a manner that allowed the algorithm to effectively capture interactions and non-additive effects. The predictor variables, which included the genetic markers, were propagated through the decision trees within the random forest. Each tree in the forest made predictions based on the input data, and the final prediction was obtained by averaging the predictions across all trees. This ensemble approach helped to reduce the risk of overfitting and improved the robustness of the model.\n\nTo optimize the model, a grid search approach was used to identify the most suitable hyperparameters, including the number of decision trees in the forest and the maximum tree depth. An inner five-fold cross-validation was conducted to tune these hyperparameters, ensuring that the model generalized well to unseen data. This rigorous preprocessing and encoding process enabled the machine-learning algorithms to effectively analyze the complex relationships within the genomic and phenotypic data, leading to accurate predictions of the traits of interest.",
  "optimization/parameters": "In our study, the number of parameters used in the model varied depending on the specific method employed. For the Random Forest (RF) regression, the primary parameters included the number of decision trees (M) in the forest and the maximum tree depth. These hyperparameters were optimized using a grid search approach with an inner five-fold cross-validation to ensure the best model performance.\n\nFor the Bayesian methods, such as BayesB and BayesC\u03c0, the parameters included the proportion of markers with no effect (\u03c0) and the variance components. In BayesB, \u03c0 was set to 0.95, assuming that 95% of the SNPs have no effect. In BayesC\u03c0, \u03c0 was treated as an unknown with a uniform prior and was estimated through sampling.\n\nThe Genomic BLUP (GBLUP) model involved parameters related to the genomic relationship matrix (G matrix), including the additive genetic variance (\u03c3\u00b2g) and the residual variance (\u03c3\u00b2e). These variance components were estimated using the AI-REML method in the DMU software.\n\nAdditionally, the biologically annotated neural networks (BANNs) framework included parameters such as the total proportion of SNPs with a non-zero effect on the trait (\u03c0\u03b8), the number of SNPs (J), and the total proportion of annotated SNP-sets enriched for the trait (\u03c0w). These parameters were estimated using a variational Bayesian algorithm.\n\nThe selection of these parameters was guided by both biological knowledge and statistical optimization techniques to ensure that the models could capture the complex genetic architecture of the traits under study.",
  "optimization/features": "In our study, the input features used for genomic prediction were single nucleotide polymorphisms (SNPs). The total number of SNPs, which serve as the input features, varied depending on the partitioning strategy employed. For the BANN_gene strategy, 16,857 SNP-sets were analyzed, consisting of 9,369 intergenic SNP-sets and 7,488 annotated genes. For the BANN_100kb strategy, 22,626 SNP-sets were analyzed. These SNP-sets were derived from the genomic data of Chinese Holstein cattle.\n\nFeature selection was inherently performed through the use of SNP-sets, which group SNPs based on biological annotations or genomic intervals. This approach helps in focusing on relevant genomic regions, thereby indirectly performing feature selection. The partitioning of SNPs into sets was done based on predefined biological annotations or fixed genomic intervals, ensuring that the feature selection process was consistent and did not rely on the training set alone. This method leverages prior biological knowledge to enhance the interpretability and predictive power of the models.",
  "optimization/fitting": "In our study, we employed several advanced statistical and machine learning methods to ensure robust model fitting and to address potential issues of overfitting and underfitting.\n\nFor the Random Forest (RF) regression, we utilized an ensemble of decision trees, which inherently reduces the risk of overfitting by averaging the predictions of numerous trees. Each tree in the forest is slightly different, and the final prediction is derived by averaging the outputs of all trees. This approach helps to mitigate the risk of overfitting by ensuring that the model does not rely too heavily on any single decision tree. To further optimize the model, we employed a grid search approach with inner five-fold cross-validation to tune hyperparameters such as the number of decision trees (M) and the maximum tree depth. This method ensures that the model generalizes well to unseen data by validating its performance on multiple subsets of the training data.\n\nIn the context of Bayesian methods, such as BayesB and BayesC\u03c0, we addressed overfitting by incorporating prior distributions that shrink the effects of noisy markers to zero. This shrinkage helps to prevent the model from fitting to random noise in the data. For BayesB, we assumed that a high proportion of markers (95%) have no effect, which helps to focus the model on the most relevant markers. For BayesC\u03c0, the proportion of markers with no effect is treated as an unknown and is estimated through sampling, providing a more flexible approach to handling marker effects.\n\nTo rule out underfitting, we ensured that our models had sufficient complexity to capture the underlying patterns in the data. For example, in the Bayesian methods, we used a mixture of null and normal distributions to allow for a flexible modeling of marker effects. Additionally, the use of high-density SNP markers and whole-genome sequencing data provided a rich set of predictors, reducing the likelihood of underfitting.\n\nIn the case of the Bayesian Artificial Neural Networks (BANNs) framework, we utilized a variational Bayesian algorithm to estimate model parameters, which helps to prevent overfitting by incorporating regularization through the prior distributions. The BANNs framework also includes a context-driven sparse shrinkage prior distribution, which promotes network sparsity and focuses on the most relevant genetic variants.\n\nOverall, our approach involved a combination of ensemble methods, regularization techniques, and careful hyperparameter tuning to ensure that our models were neither overfitting nor underfitting the data. This comprehensive strategy allowed us to achieve robust and reliable predictions for the traits of interest in Chinese Holstein cattle.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and optimize our models. One of the key methods used was the Random Forest (RF) regression, which inherently reduces the risk of overfitting by averaging the predictions of numerous decision trees. Each tree in the forest is slightly different, and by combining their outputs, the model achieves a more robust and generalizable prediction.\n\nAdditionally, we utilized a grid search approach to identify the most suitable hyperparameters, specifically the number of decision trees (M) and the maximum tree depth. This process was further enhanced by conducting an inner five-fold cross-validation (CV) to tune these hyperparameters effectively. Cross-validation helps in assessing the model's performance on different subsets of the data, ensuring that the model generalizes well to unseen data and does not overfit to the training set.\n\nThese techniques collectively contributed to the robustness and reliability of our genomic prediction models.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the publication. Specifically, for the Random Forest (RF) regression, a grid search approach was employed to identify the most suitable hyperparameters, including the number of decision trees (M) and the maximum tree depth. This process involved an inner five-fold cross-validation (CV) to tune these hyperparameters effectively.\n\nFor the Bayesian Annotated Neural Networks (BANNs) framework, the weights of the input layer and the hidden layer were treated as random variables, allowing for simultaneous multi-scale genomic inference. The variational Bayesian algorithm was used to estimate all model parameters. The variational expectation-maximization (EM) algorithm was utilized for estimating the parameters of the neural network, with parameters initialized through random draws from their assumed prior distributions. The iteration within the algorithm terminates upon meeting specific stopping criteria: either the difference between the lower bounds of two consecutive updates falls within a range of 1 \u00d7 10\u22124, or the maximum iteration count of 10,000 is reached.\n\nThe datasets used in this study, including phenotypic and genomic data from Chinese Holstein cattle, are available from the corresponding author upon reasonable request. The study was supported by various funding sources, including the National Key Research and Development Program of China and the Ningxia Key Research and Development Program of China.\n\nThe code and specific model files are not explicitly mentioned as being available in public repositories or under specific licenses. However, the methods and approaches used are thoroughly described, allowing for replication and further research. The authors declare no conflict of interest, and the study was conducted with ethical approval from the Animal Care and Use Committee of China Agricultural University.",
  "model/interpretability": "The models discussed in our study vary in their interpretability, ranging from more transparent to black-box approaches.\n\nThe Genomic Best Linear Unbiased Prediction (GBLUP) and Bayesian methods like BayesB and BayesC\u03c0 are relatively transparent. These models provide clear estimates of genetic variances and individual SNP effects, making it easier to interpret the contribution of each genetic marker to the trait of interest. For instance, in GBLUP, the genomic relationship matrix (G matrix) explicitly shows the genetic relationships between individuals based on their markers, and the model's parameters can be directly interpreted in terms of genetic and residual variances.\n\nOn the other hand, machine learning algorithms like Random Forest (RF) and neural networks, including the biologically annotated neural networks (BANNs), are more complex and can be considered black-box models. RF, while providing feature importance measures, does not offer a straightforward interpretation of how individual markers contribute to the predictions. Each decision tree in the forest captures different patterns in the data, and the final prediction is an average of these trees, making it challenging to trace back the exact influence of each marker.\n\nBANNs, despite their complexity, incorporate biological annotations to enhance interpretability. They use predefined SNP-set annotations, allowing for a more biologically meaningful interpretation of the results. The posterior inclusion probabilities (PIPs) in BANNs provide statistical evidence for the importance of each variant, indicating which SNPs and SNP-sets are likely to have non-zero effects on the trait. This feature makes BANNs more interpretable compared to conventional neural networks, as it leverages prior biological knowledge to guide the model's learning process.\n\nIn summary, while traditional statistical models offer clearer interpretability, advanced machine learning models like RF and BANNs provide more complex, data-driven insights. BANNs, in particular, strike a balance by integrating biological annotations to make the model's predictions more interpretable in a genomic context.",
  "model/output": "The model discussed in this publication is primarily focused on regression tasks, specifically for genomic prediction in dairy cattle. The models evaluated include Random Forest (RF), Genomic Best Linear Unbiased Prediction (GBLUP), BayesB, and BayesC\u03c0, all of which are used for predicting continuous traits such as milk yield, fat yield, protein yield, conformation, feet and leg, mammary system, and somatic cell score. These traits are quantitative and thus require regression models to predict their values accurately.\n\nThe Random Forest regression model, for instance, averages the predictions of numerous decision trees to reduce the risk of overfitting and provide more accurate predictions for unobserved data. Similarly, GBLUP, BayesB, and BayesC\u03c0 are regression models that estimate genetic values and variance components to predict phenotypic traits.\n\nThe Biologically Annotated Neural Networks (BANNs) framework, which is the main focus of this study, is also designed for regression. It utilizes a feedforward Bayesian neural network model that incorporates SNP-set annotations to capture complex genetic interactions and non-additive effects. The BANNs framework aims to improve the accuracy of genomic prediction by leveraging biological annotations and variational inference for parameter estimation.\n\nIn summary, the models discussed in this publication are regression models used for predicting continuous phenotypic traits in dairy cattle. The BANNs framework, in particular, shows promise in enhancing the accuracy of genomic prediction by integrating biological annotations and advanced machine learning techniques.",
  "model/duration": "The execution time for the genomic prediction methods varied significantly. The GBLUP method was the fastest, completing each fold of five-fold cross-validation in approximately 41.76 minutes. This efficiency makes GBLUP a practical choice for scenarios where computational speed is a priority.\n\nBayesB and BayesC\u03c0 had comparable computation times, averaging around 132.08 minutes and 148.91 minutes per fold, respectively. These methods, while more time-consuming than GBLUP, offer the advantage of incorporating Bayesian frameworks that can handle complex genetic architectures.\n\nThe BANNs framework, specifically BANN_gene and BANN_100kb, required more computational resources due to the construction of neural networks. BANN_gene took an average of 275.79 minutes per fold, while BANN_100kb took slightly longer at 284.49 minutes. This increased computation time is justified by the superior prediction accuracy and the ability to capture both additive and non-additive genetic effects.\n\nRandom Forest (RF) also had a substantial computation time, averaging 274.10 minutes per fold. This is likely due to the ensemble nature of RF, which involves constructing multiple decision trees and performing data sampling and feature selection for each tree.\n\nThe computational efficiency of these methods was evaluated on an HP server running CentOS Linux 7.9.2009, equipped with a 2.5 GHz Intel Xeon processor and 515 GB of total memory. This setup provided a robust environment for comparing the performance of different genomic prediction algorithms.",
  "model/availability": "The source code for the algorithms used in this study is not publicly released. However, some of the software packages utilized are available for public use. For instance, the DMU software, which was used to carry out GBLUP, is a package for analyzing multivariate mixed models in quantitative genetics and genomics. The Julia package JWAS, employed for BayesB and BayesC\u03c0 methods, is also available. These tools can be accessed and used by researchers interested in similar genomic analyses. The specific details about the availability and licensing of these software packages can be found in their respective documentation and repositories.",
  "evaluation/method": "The evaluation of the methods involved a comprehensive assessment using a five-fold cross-validation (CV) process repeated five times, resulting in a total of 25 tests. This approach ensured a robust evaluation of the prediction performance across different scenarios.\n\nPrediction accuracy was primarily assessed using the Pearson correlation coefficient between standardized deregressed proofs (DRP) and predicted values (PV) of the validation population. This correlation was then divided by the mean accuracy, which is the square root of the reliability of DRP in the validation data. Additionally, the slope of the regression of standardized DRP on PV was calculated to evaluate the dispersion of the predictions. This metric is crucial for understanding how well the predicted values align with the actual values, with some studies referring to it as a measure of bias or unbiasedness.\n\nMean square error (MSE) was also used as a key metric to evaluate the performance of different methods. MSE considers both prediction bias and variability, providing a holistic view of the prediction accuracy. In each prediction scenario, the reference and validation populations were consistent across all methods and replicates, ensuring a fair comparison. The final results for accuracy, dispersion, and MSE were averaged over the five repetitions of the five-fold CV.\n\nTo compare the prediction accuracy of different methods, multiple t-tests were conducted based on the outcomes of the five replicates. The P-values from these tests were adjusted using the Bonferroni method to account for multiple comparisons, ensuring the statistical significance of the results.\n\nIn summary, the evaluation method employed a rigorous cross-validation process, multiple performance metrics, and statistical tests to ensure a thorough and unbiased assessment of the genomic prediction methods.",
  "evaluation/measure": "In our study, we employed several performance metrics to comprehensively evaluate the genomic prediction methods. The primary metrics reported include prediction accuracy, mean squared error (MSE), and dispersion. Prediction accuracy was assessed using the Pearson correlation coefficient between standardized deregressed predicted breeding values (DRP) and predicted values (PV) of the validation population, adjusted by the mean accuracy of DRP in the validation data. This metric provides a clear indication of how well the models predict the actual phenotypic values.\n\nMean squared error (MSE) was used to measure the performance of different methods, considering both prediction bias and variability. MSE is a crucial metric as it quantifies the average squared difference between the predicted and actual values, offering insights into the overall prediction error.\n\nDispersion was evaluated using the slope of the regression of standardized DRP on PV. This metric assesses the bias in predictions, with a slope closer to 1 indicating more appropriate dispersion. Additionally, we conducted multiple t-tests based on the outcomes of five replicates, with P-values adjusted using the Bonferroni method, to compare the prediction accuracy of different methods.\n\nThese metrics are widely recognized and used in the literature for evaluating genomic prediction models. They provide a robust framework for comparing the performance of various methods, including BANN_gene, BANN_100kb, GBLUP, RF, and Bayesian methods. By reporting these metrics, we ensure that our evaluation is representative and aligned with established practices in the field.",
  "evaluation/comparison": "In our study, we conducted a comprehensive comparison of the BANNs framework with several publicly available methods using benchmark datasets. Specifically, we evaluated the performance of BANN_gene and BANN_100kb against conventional genomic prediction methods, including GBLUP, Random Forest (RF), and Bayesian methods (BayesB and BayesC\u03c0). These methods are widely used in the field of genomic prediction and serve as robust benchmarks for assessing the effectiveness of new approaches.\n\nThe comparison was performed on seven dairy cattle traits, which included both milk production traits (such as milk yield, fat yield, protein yield, and somatic cell score) and type traits (such as conformation, feet and leg, and mammary system). This diverse set of traits allowed us to evaluate the methods across a range of genetic architectures and phenotypic variations.\n\nFor each trait, we used five-fold cross-validation with five replications to ensure the reliability and generalizability of our results. This rigorous evaluation process provided a thorough assessment of the prediction accuracy, mean squared error (MSE), and dispersion of each method.\n\nOur findings demonstrated that BANN_100kb consistently outperformed the other methods in terms of prediction accuracy and MSE across all traits. For example, BANN_100kb showed an average improvement of 4.86% in accuracy compared to GBLUP, 3.95% compared to RF, 3.84% compared to BayesB, and 1.92% compared to BayesC\u03c0. These results highlight the superior performance of the BANNs framework, particularly when SNP-sets are partitioned based on 100 kb intervals.\n\nIn addition to comparing with publicly available methods, we also evaluated the performance of BANN_gene and BANN_100kb against simpler baselines. For instance, we found that BANN_100kb achieved an average improvement of 1.07% in accuracy compared to BANN_gene across all traits. This comparison underscores the importance of the SNP-set partitioning strategy in enhancing the predictive performance of the BANNs framework.\n\nOverall, our evaluation provides strong evidence that the BANNs framework, particularly when using the 100 kb partitioning strategy, offers significant advantages in genomic prediction for dairy cattle traits. The comparison with publicly available methods and simpler baselines further validates the robustness and effectiveness of our approach.",
  "evaluation/confidence": "The evaluation of our methods included a rigorous statistical analysis to ensure the reliability of our findings. We employed a 5 \u00d7 5 cross-validation (CV) process, which involved five-fold CV repeated five times, totaling 25 tests. This approach helped in assessing the prediction accuracy, mean squared error (MSE), and dispersion of different methods.\n\nTo determine the statistical significance of our results, we conducted multiple t-tests based on the outcomes of the five replicates. The P-values from these tests were adjusted using the Bonferroni method to account for multiple comparisons. This statistical approach allowed us to confidently claim that our methods, particularly BANN_100kb, demonstrated superior performance compared to conventional methods like GBLUP, RF, and Bayesian approaches.\n\nFor instance, BANN_100kb showed significant improvements in accuracy for various traits, such as a 7.46% improvement for milk yield (MY) and a 5.42% improvement for fat yield (FY) compared to GBLUP. These improvements were statistically significant, indicating that the observed differences were not due to random chance.\n\nAdditionally, the dispersion of predictions was evaluated using the slope of the regression of standardized deregressed proofs (sDRP) on predicted values (PV). This metric helped us assess the bias and variability of the predictions, ensuring that our methods provided reliable and unbiased estimates.\n\nIn summary, the performance metrics in our study were accompanied by confidence intervals derived from the cross-validation process and statistical tests. The results were statistically significant, providing strong evidence that our methods, particularly BANN_100kb, are superior to other approaches in genomic prediction for dairy cattle traits.",
  "evaluation/availability": "The datasets used or analyzed during the present study are available from the corresponding author on reasonable request. This means that the raw evaluation files are not publicly released but can be obtained by contacting the corresponding author. The specifics of the license or terms of use for these datasets would need to be discussed directly with the corresponding author."
}