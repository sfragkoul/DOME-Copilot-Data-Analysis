{
  "publication/title": "Qualitative classification of milled rice grains using computer vision and metaheuristic techniques",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Journal of Food Science and Technology",
  "publication/year": "2016",
  "publication/pmid": "26787936",
  "publication/pmcid": "PMC4711406",
  "publication/doi": "10.1007/s13197-015-1947-4",
  "publication/tags": "- Rice\n- Classification\n- Computer vision\n- Metaheuristic techniques\n- Machine learning\n- Artificial neural networks\n- Support vector machines\n- Decision trees\n- Bayesian networks\n- Image processing\n- Quality grading\n- Milled rice\n- Feature selection\n- Data mining\n- Pattern recognition",
  "dataset/provenance": "The dataset used in this study was obtained through an imaging process involving a CCD camera positioned above the samples. The camera captured images of milled rice grains, which were then processed and stored in RGB color space. The imaging setup included uniform illumination using strip LED lights and a black cardboard background to simplify segmentation. The system was calibrated using a standard grey card to ensure light uniformity.\n\nA total of 1280 images of milled rice grains were obtained, with 320 grains captured for each class. The grains were manually placed under the camera, ensuring no contact between them. The images were captured using a script written in MATLAB R2010a. The dataset was divided into three parts: 50% for the training set, 25% for cross-validation, and 25% for testing. This division allowed for effective training, validation, and testing of the classifiers used in the study.\n\nThe dataset has been used in this study to evaluate different metaheuristic techniques for milled rice classification, including artificial neural networks, support vector machines, decision trees, and Bayesian networks. The performance of these techniques was assessed using statistical parameters such as sensitivity, specificity, classification accuracy, and root mean squared error. The results showed high accuracy in classifying milled rice grains into different quality grades.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "The dataset used in this study was divided into three distinct parts to facilitate the training, cross-validation, and testing stages of the classification process. This division is crucial for ensuring that the classifier is both robust and generalizable.\n\nThe dataset was split as follows:\n\n* 50% of the data, consisting of 640 samples, was randomly selected as the training set. This set was used to train the classifier, allowing it to learn the underlying patterns and relationships within the data.\n* 25% of the data, comprising 320 samples, was allocated for cross-validation. This set was utilized to prevent overfitting, ensuring that the classifier generalizes well to unseen data.\n* The remaining 25% of the data, also consisting of 320 samples, was designated as the testing set. This set was employed to evaluate the performance and validity of the classifier.\n\nThe independence of the training and test sets was enforced through random selection, ensuring that there was no overlap between the samples used in each stage. This approach helps to mitigate the risk of data leakage, where information from the test set inadvertently influences the training process, leading to overly optimistic performance estimates.\n\nThe distribution of the dataset compares favorably to previously published machine learning datasets in the context of milled rice classification. The use of a balanced split ensures that each stage of the classification process has an adequate and representative sample of the data, which is essential for developing a reliable and accurate classifier. This methodology aligns with best practices in machine learning, where the independence and representativeness of the training, cross-validation, and testing sets are critical for achieving robust and generalizable results.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm used in this study is a search algorithm known as Best First. This algorithm is not new and is well-established in the field of machine learning and feature selection. It operates by searching the space of attribute subsets using a greedy hill-climbing approach, which can be augmented with a backtracking facility. The level of backtracking can be controlled by setting the number of consecutive non-improving nodes allowed.\n\nThe Best First algorithm can start with an empty set of attributes and search forward, or it can start with a full set of attributes and search backward. It can also start at any point and search in both directions by considering all possible single attribute additions and deletions at a given point.\n\nThis algorithm was implemented using the CfsSubsetEval attribute evaluator in WEKA software. The CfsSubsetEval algorithm evaluates the worth of a subset of attributes by considering the individual predictive ability of each feature along with the degree of redundancy between them. Subsets of features that are highly correlated with the class while having low intercorrelation are preferred.\n\nThe choice of this algorithm was driven by its effectiveness in feature selection, which is a crucial step in improving the performance of machine learning models. By reducing the feature vector from 57 features to 12, the algorithm helped in identifying the most relevant features for classifying milled rice grains. This reduction not only simplifies the model but also enhances its accuracy and efficiency.\n\nThe Best First algorithm, along with the CfsSubsetEval evaluator, has been widely used and validated in various studies, making it a reliable choice for feature selection in this research. Its implementation in WEKA software further ensures its robustness and ease of use.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "For the machine-learning algorithm, the data encoding and preprocessing involved several key steps. Initially, visual features were extracted from milled rice grains, focusing on size, shape, texture, and color. These features were then subjected to a feature selection process using the Best First search algorithm, which employs greedy hill climbing with backtracking. This algorithm evaluated the worth of attribute subsets by considering both the individual predictive ability of each feature and the degree of redundancy between them. The goal was to select features that were highly correlated with the class label while having low intercorrelation among themselves.\n\nThe feature selection process reduced the initial set of 57 features to 12, which included 3 features for size and shape, 1 for texture, and 8 for color. These selected features were then used as input for the machine-learning models. For the Multilayer Perceptron (MLP) model, the input layer consisted of 12 neurons, each corresponding to one of the selected features. The output layer had 4 neurons, representing the four classes of milled rice: LPS (Low-processed sound grains), LPB (Low-processed broken grains), HPS (High-processed sound grains), and HPB (High-processed broken grains). Hidden layers were added to develop the MLP models further.\n\nThe data was divided into three parts: a training set (50% of the data), a cross-validation set (25%), and a testing set (25%). The training set was used to train the classifiers, the cross-validation set helped prevent overtraining, and the testing set was used to evaluate the performance of the classifiers. This division ensured that the models were trained and validated on different subsets of the data, providing a robust evaluation of their performance.",
  "optimization/parameters": "In the optimization process, the model utilized a set of selected features derived from the milled rice samples. Initially, the feature vector consisted of 57 features. However, through a feature selection operation using the Best First search algorithm and the CfsSubsetEval attribute evaluator, the number of features was reduced to 12. These selected features include 3 for size and shape, 1 for texture, and 8 for color features. The specific features chosen were F1, F4, F5, F7, F12, F21, F39, F44, F50, F51, F53, and F54.\n\nThe selection of these 12 features was based on their individual predictive ability and the degree of redundancy between them. The goal was to prefer subsets of features that are highly correlated with the class while having low intercorrelation among themselves. This reduction in the feature vector size from 57 to 12 was crucial for improving the efficiency and accuracy of the classification models used in the study.",
  "optimization/features": "In the optimization process, the input features for the classification model were carefully selected to ensure optimal performance. Initially, a comprehensive set of features was extracted from the milled rice samples, totaling 57 features. These features encompassed various aspects such as size, shape, texture, and color.\n\nTo enhance the classification accuracy and efficiency, a feature selection procedure was conducted. This process involved evaluating the worth of each feature based on its individual predictive ability and the degree of redundancy among them. The goal was to identify a subset of features that were highly correlated with the class labels while having low intercorrelation among themselves.\n\nThe feature selection was performed using the Best First search algorithm, which employs a greedy hill-climbing approach augmented with backtracking. This algorithm systematically explores the space of attribute subsets to find the most informative features. The evaluation of feature subsets was done using the CfsSubsetEval attribute evaluator, which considers both the predictive ability of individual features and the redundancy between them.\n\nAs a result of this feature selection process, the number of input features was reduced from 57 to 12. These selected features included 3 for size and shape, 1 for texture, and 8 for color. The specific features chosen were F1, F4, F5, F7, F12, F21, F39, F44, F50, F51, F53, and F54.\n\nThe feature selection was conducted using the training set only, ensuring that the evaluation and selection process did not incorporate information from the cross-validation or testing sets. This approach helps to prevent overfitting and ensures that the selected features generalize well to unseen data.",
  "optimization/fitting": "The fitting method employed in this study utilized a multilayer perceptron (MLP) neural network for classification, which is a type of artificial neural network. The MLP consisted of an input layer, a hidden layer, and an output layer. The number of neurons in the input and output layers was fixed based on the feature vector and the number of classes, respectively. However, the number of neurons in the hidden layer was determined through a trial-and-error process, varying from 2 to 20. This process aimed to find the optimal configuration that minimized classification error.\n\nTo address the potential issue of overfitting, which can occur when the number of parameters is much larger than the number of training points, several strategies were implemented. Firstly, the dataset was divided into three parts: a training set (50% of the data), a cross-validation set (25% of the data), and a testing set (25% of the data). The cross-validation set was used to prevent overtraining by providing an unbiased evaluation of the model fit on the training data. Additionally, the gradient descent with momentum approach was used for error minimization, which helps in preventing the system from converging to local minima and ensures more stable and generalizable performance.\n\nThe optimal network topology was determined to be 12-5-4, meaning 12 input neurons, 5 hidden neurons, and 4 output neurons. This configuration was selected based on its lowest classification error, specifically an RMSE of 0.0806. The use of a relatively small number of hidden neurons helped in reducing the complexity of the model, thereby mitigating the risk of overfitting.\n\nTo rule out underfitting, the model's performance was evaluated using statistical parameters such as sensitivity, specificity, and classification accuracy. The high accuracy of the neural network topology, with an overall accuracy of 98.72%, indicates that the model was able to capture the underlying patterns in the data effectively. The sensitivity and specificity values for different classes were also high, demonstrating the model's ability to correctly identify and exclude classes.\n\nIn summary, the fitting method involved a careful balance between model complexity and performance, with strategies in place to prevent both overfitting and underfitting. The use of cross-validation, gradient descent with momentum, and the selection of an optimal network topology contributed to the robustness and generalizability of the classification model.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One key method involved the use of a cross-validation set during the classification process. The dataset was divided into three parts: a training set, a cross-validation set, and a testing set. The training set was used to train the classifier, while the cross-validation set was utilized to prevent overtraining. This approach helped in tuning the model parameters and selecting the best features without overfitting to the training data.\n\nAdditionally, we used feature selection techniques to reduce the dimensionality of the feature vector. Initially, we had 57 features, but after applying the Best First search algorithm with the CfsSubsetEval attribute evaluator, we reduced the feature set to 12. This reduction helped in eliminating redundant and irrelevant features, which can often lead to overfitting. The selected features included those related to size, shape, texture, and color, ensuring that only the most informative features were used for classification.\n\nIn the context of neural networks, we implemented gradient descent with momentum for error minimization. The momentum parameter helped in accelerating convergence and preventing the system from getting stuck in local minima, which is a common issue that can lead to overfitting. We carefully chose a momentum coefficient of 0.2 to balance the speed of convergence and the risk of overshooting the minimum.\n\nFor Bayesian networks, we employed structural learning methods to find the optimal network structure. This involved using point-oriented methods such as genetic search, hill-climber search, K2 search, simulated annealing search, and TAN search. These methods ensured that the network structure was compatible with the dataset and optimized for complexity, thereby reducing the risk of overfitting.\n\nOverall, these techniques collectively contributed to the prevention of overfitting and enhanced the generalization capability of our models.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the publication. Specifically, for the artificial neural network (ANN) model, we detailed the number of neurons in the hidden layer and the number of epochs tested. The optimal configuration was found to be a 12-5-4 topology, which had the lowest classification error with an RMSE of 0.0806. This configuration was chosen based on statistical parameters calculated from the classification matrix.\n\nFor the Bayesian networks, we described the use of five point-oriented methods for structural learning, including genetic search, hill-climber search, K2 search, simulated annealing search, and TAN search. The parameters for these methods, such as generation size, population size, start temperature, delta value, and run number, were also specified.\n\nThe optimization schedule involved dividing the dataset into training, cross-validation, and testing sets, with 50%, 25%, and 25% of the data respectively. The training set was used to train the classifiers, the cross-validation set to prevent overfitting, and the testing set to evaluate the classifier's performance.\n\nRegarding the availability of model files and optimization parameters, these are not explicitly provided in the publication. However, the methods and configurations described can be replicated using the details provided. The software used, WEKA, is open-source and freely available under the GNU General Public License. This allows researchers to implement the described techniques and configurations in their own studies.\n\nFor those interested in replicating our work, the publication provides sufficient information on the hyper-parameter configurations, optimization parameters, and the division of the dataset. The use of open-source software like WEKA ensures that the methods are accessible and can be applied in similar research contexts.",
  "model/interpretability": "The models employed in this study exhibit varying degrees of interpretability, ranging from highly transparent to more opaque.\n\nArtificial neural networks, particularly the Multilayer Perceptron (MLP) used, are often considered black-box models. This is because the relationships between input features and output predictions are encoded in the weights and biases of the network layers, which are not easily interpretable by humans. However, the architecture of the MLP, with its defined input, hidden, and output layers, provides a structured framework for understanding how data flows through the network.\n\nSupport Vector Machines (SVM) offer a different level of interpretability. The SVM model represents samples as points in space, separated by a hyperplane. This hyperplane is defined by a subset of the training data points, known as support vectors. The use of kernel functions allows for non-linear separation, but the underlying concept of a decision boundary in feature space remains interpretable. The choice of kernel function, such as the Universal Pearson VII kernel, influences the shape of this boundary, but the fundamental idea of a separating hyperplane persists.\n\nDecision trees are among the most interpretable models. Each tree consists of nodes and branches that represent decisions based on input features. The structure of the tree, with its clear branching logic, makes it easy to trace the decision-making process. For instance, the REP tree used in this study has a straightforward structure with six branches and four leaves, making it transparent how different classes of milled rice are determined.\n\nBayesian networks provide a probabilistic framework for modeling relationships among variables. The directed acyclic graph structure of Bayesian networks makes the dependencies between variables explicit. Each node represents a random variable, and the edges represent conditional dependencies. This graphical representation allows for a clear understanding of how different features influence the classification outcome. The use of various search methods, such as genetic search and hill-climber search, to optimize the network structure further enhances interpretability by ensuring that the model is aligned with the data.\n\nIn summary, while some models like the MLP are more opaque, others like decision trees and Bayesian networks offer clear, interpretable structures. SVM models strike a balance, with interpretable decision boundaries that can be complex due to kernel functions. This variety allows for a nuanced approach to model interpretability, depending on the specific requirements and preferences of the analysis.",
  "model/output": "The model is designed for classification tasks. Specifically, it is used to classify milled rice grains into four distinct quality classes: LPS, LPB, HPS, and HPB. The output layer of the model consists of four neurons, each corresponding to one of these classes. This setup allows the model to categorize the input data into one of the predefined groups based on the features extracted from the rice grains.\n\nThe classification performance of the model is evaluated using several statistical parameters, including sensitivity (Se), specificity (Sp), classification accuracy (Ac), and root mean squared error (RMSE). These metrics provide a comprehensive assessment of the model's ability to correctly identify and exclude each class. For instance, the sensitivity indicates how well the model can identify a specific class, while the specificity measures its ability to exclude other classes correctly.\n\nThe model's output is determined by the activation of the neurons in the output layer, which corresponds to the predicted class for a given input. The classification results are presented in a classification matrix (CM), which shows the number of true positives, false positives, true negatives, and false negatives for each class. This matrix, along with the statistical parameters, helps in understanding the model's performance and its effectiveness in classifying milled rice grains.\n\nIn summary, the model is a classification system that categorizes milled rice grains into four quality classes. The output layer's neurons activate to indicate the predicted class, and the model's performance is assessed using various statistical measures to ensure accurate and reliable classification.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method for the milled rice grading process involved several stages, including training, cross-validation, and testing. The dataset was divided into three parts: 50% for training, 25% for cross-validation, and 25% for testing. The training set was used to train the classifier, the cross-validation set was utilized to prevent overtraining, and the testing set was employed to validate the classifier's performance.\n\nTo assess the performance of the utilized metaheuristic techniques, a classification matrix (CM) was formed, and statistical parameters such as sensitivity (Se), specificity (Sp), classification accuracy (Ac), and root mean squared error (RMSE) were computed. Sensitivity measures the classifier's ability to correctly identify a class, while specificity represents the classifier's ability to correctly exclude a class. These parameters were calculated using specific equations that consider true positives, false positives, true negatives, and false negatives.\n\nThe evaluation also involved comparing different metaheuristic techniques, including artificial neural networks, decision trees, and support vector machines, using various induction algorithms and kernel functions. The performance of these techniques was assessed based on their ability to classify milled rice samples into predefined quality classes. The results were presented in tables showing the RMSE values for different classifiers and the statistical parameters for the developed classifiers.",
  "evaluation/measure": "In our study, we evaluated the performance of various classifiers using a set of statistical parameters that are commonly reported in the literature for classification tasks. The primary metrics we focused on were sensitivity (Se), specificity (Sp), classification accuracy (Ac), and root mean squared error (RMSE).\n\nSensitivity measures the classifier's ability to correctly identify positive instances, which is crucial for ensuring that true positives are not missed. Specificity, on the other hand, assesses the classifier's ability to correctly identify negative instances, helping to minimize false positives. Classification accuracy provides an overall measure of the classifier's performance by calculating the proportion of correctly classified instances out of the total instances. RMSE is a measure of the differences between predicted and actual values, providing insight into the model's predictive accuracy.\n\nThese metrics were chosen because they offer a comprehensive view of the classifier's performance, covering both the true positive and true negative rates, as well as the overall accuracy and error magnitude. By reporting these metrics, we aim to provide a clear and representative evaluation of our classifiers' effectiveness in milled rice grading.\n\nThe use of these metrics is consistent with established practices in the field, ensuring that our results are comparable to other studies. For instance, sensitivity and specificity are widely used in medical diagnostics and other classification tasks to evaluate the performance of diagnostic tests and classifiers. Similarly, classification accuracy and RMSE are standard metrics in machine learning and statistical analysis for assessing model performance.\n\nIn summary, the performance metrics reported in our study are sensitivity, specificity, classification accuracy, and root mean squared error. These metrics are representative of the literature and provide a thorough evaluation of the classifiers' performance in milled rice grading.",
  "evaluation/comparison": "In our study, we evaluated the performance of various metaheuristic classification techniques for grading milled rice grains. We utilized four different methods: Artificial Neural Networks (ANN), Support Vector Machines (SVM), Decision Trees (DT), and Bayesian Networks. Each of these techniques was implemented using specific algorithms and configurations tailored to our dataset.\n\nFor the ANN classifier, we employed a Multilayer Perceptron (MLP) with a 12-5-4 topology, trained using the back-propagation algorithm with gradient descent and a momentum coefficient of 0.2. This configuration was chosen to optimize the network's ability to learn from the training data and generalize to new samples.\n\nThe SVM classifier was tested with different kernel functions, including Polynomial, Normalized Polynomial, Radial Basis Function (RBF), and Universal Pearson VII. The Universal Pearson VII kernel function yielded the best performance in terms of classification accuracy and root mean squared error (RMSE).\n\nFor Decision Trees, we compared several induction algorithms, such as J48, Logistic Model Trees (LMT), Reduced Error Pruning (REP), and Decision Stump. The REP algorithm demonstrated the lowest RMSE and highest accuracy among the tested methods.\n\nIn the case of Bayesian Networks, we explored various search algorithms for structural learning, including Genetic Search, Hill Climber, Simulated Annealing, and Tree-Augmented Naive Bayes (TAN). The Hill Climber search algorithm proved to be the most effective, achieving the lowest RMSE and highest accuracy in milled rice classification.\n\nTo assess the performance of these classifiers, we used statistical parameters such as sensitivity (Se), specificity (Sp), classification accuracy (Ac), and RMSE. These metrics provided a comprehensive evaluation of each method's ability to correctly identify and exclude quality classes in milled rice grains.\n\nOur comparison showed that all the metaheuristic methods used in this research exhibited high levels of accuracy in classifying milled rice grains. The ANN classifier achieved the highest classification accuracy, followed by SVM, DT, and Bayesian Networks. This performance can be attributed to the flexibility of these classifiers in adjusting their parameters to achieve better results.\n\nIn summary, our study demonstrated the effectiveness of metaheuristic classification techniques in grading milled rice grains based on color images. The comparison of these methods highlighted their strengths and provided insights into their applicability for quality grading in the rice industry.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not enough information is available."
}