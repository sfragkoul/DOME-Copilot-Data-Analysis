{
  "publication/title": "Not enough information is available.",
  "publication/authors": "The authors who contributed to the article are:\n\n- K.K. and G.B. developed the methodology.\n- K.K. carried out all experiments and analyses, and wrote the manuscript.\n- P.G., B.A. and J.v.H. defined the biological problem, provided the data and validated the results.\n- All authors contributed to, read and approved the final version of the manuscript.",
  "publication/journal": "BMC Proceedings",
  "publication/year": "2008",
  "publication/pmid": "19091052",
  "publication/pmcid": "PMC2654973",
  "publication/doi": "10.1186/1753-6561-2-S4-S5",
  "publication/tags": "- Machine Learning\n- Bioinformatics\n- Gene Regulation\n- Nitrogen Catabolite Repression\n- Yeast Genetics\n- Supervised Classification\n- Variable Selection\n- Support Vector Machines\n- Naive Bayes\n- K-Nearest Neighbors\n- Gene Expression Analysis\n- Motif Discovery\n- Statistical Learning\n- Pattern Recognition\n- Computational Biology",
  "dataset/provenance": "The dataset used in our study focuses on the upstream non-coding sequences of yeast genes, specifically those that are over 800 base pairs (bp) upstream from the start codon. These sequences were retrieved using the Regulatory Sequence Analysis Tools (RSAT), a web resource that provides a collection of software tools for regulatory sequence analysis. In cases where the upstream open reading frame (ORF) is closer than 800 bp, a shorter sequence is retrieved to ensure that coding sequences are discarded.\n\nThe dataset includes variables that reflect properties of the occurrences of the GATA motif in these upstream non-coding sequences. These variables are defined to focus on the GATA boxes, which are 5'-GATA-3' core sequences recognized by the GATA family of transcription factors. The variables include measures such as the number of GATA boxes, the positions of these boxes, and various statistical measures like mean, median, and standard deviation of the positions and gaps between GATA boxes.\n\nFor the training of our classifier, we used a positive training set denoted as ANCR, which consists of 37 genes previously annotated as NCR-responding. These genes were selected from a set of 41 genes, with 4 genes discarded because they were not identified as NCR-responding in any of the three genome-wide experimental and bioinformatics studies referenced. The negative training set, denoted as NNCR, is composed of 89 manually-selected genes known to be insensitive to NCR, many of which are involved in house-keeping cellular functions unrelated to nitrogen metabolism.\n\nThe dataset is high-dimensional, with nearly 600 variables, and the classification task involves a relatively small number of samples compared to the number of variables. This high-dimensionality necessitated the use of variable selection methods to improve prediction performance and enhance interpretability. The variables selected include k-mers such as GATAAG, TAGATAA, GATAGG, and GTAGATA, with GATAAG being known for its potential relevance to NCR regulation.",
  "dataset/splits": "The dataset used in this study is split into two main categories for training the classifier: positive and negative training sets.\n\nThe positive training set, denoted as ANCR, consists of 37 genes. These genes were selected from a previously annotated list of 41 NCR-responding genes. Four genes were excluded because they were not identified as NCR-responding in any of the three genome-wide experimental and bioinformatics studies referenced.\n\nThe negative training set, denoted as NNCR, is composed of 89 manually-selected genes. These genes are known to be insensitive to NCR and are primarily involved in house-keeping cellular functions unrelated to nitrogen metabolism.\n\nThe classifier is trained on these sets, and then used to make predictions for genes not included in the training phase. The distribution of data points in each split is therefore 37 for the positive training set and 89 for the negative training set.",
  "dataset/redundancy": "Not applicable",
  "dataset/availability": "The data used in this study is not publicly available. The dataset consists of specific gene sequences and their properties related to the GATA motif in the upstream non-coding regions of yeast genes. The training sets include 37 positive samples (NCR-sensitive genes) and 89 negative samples (NCR-insensitive genes). The upstream non-coding sequences were retrieved using the Regulatory Sequence Analysis Tools (RSAT) for genes with sequences over 800 base pairs upstream from the start codon. However, the specific datasets and splits used in the analysis are not released in a public forum. Therefore, the data is not accessible to the broader scientific community for replication or further analysis.",
  "optimization/algorithm": "The machine-learning approach employed in this study is a supervised two-class classification problem. The classifiers used are not new; they are well-established methods in the field of machine learning. These include Naive Bayes (NB), k-Nearest Neighbors (KNN), and Support Vector Machines (SVM) with a linear kernel. The choice of these classifiers was driven by their effectiveness in handling high-dimensional data and their ability to make biologically valid predictions.\n\nThe reason these classifiers were not published in a machine-learning journal is that the focus of this work is on applying these methods to a specific biological problem\u2014identifying putative NCR genes in the yeast Saccharomyces cerevisiae. The primary contribution lies in the application and validation of these techniques in a biological context, rather than the development of new machine-learning algorithms. The study aims to demonstrate the practical utility of these classifiers in reducing the dimensionality of the problem, thereby saving time and resources in biological research.\n\nThe performance of these classifiers was assessed using various metrics, including the balanced error rate (BER) and the area under the receiver operator characteristic curve (AUC). The results indicate that all classifiers made significant and biologically valid predictions, with the linear kernel support vector machine performing best according to McNemar's test. This validation process involved leave-one-out cross-validation and negative controls to ensure the robustness and significance of the findings.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, we encoded and pre-processed the data to facilitate the application of machine-learning algorithms for identifying putative NCR genes in the yeast Saccharomyces cerevisiae. We focused on the upstream non-coding sequences of genes, extracting a comprehensive set of variables that capture various aspects of GATA boxes, which are known to be relevant for NCR regulation.\n\nWe defined several variables related to the number and distribution of GATA boxes. The variable NUM counts the total number of GATA boxes in the upstream non-coding sequences. Additionally, we measured the gaps between consecutive GATA boxes, defining variables such as 1-GAP, 2-GAP, 3-GAP, and B-GAP to represent the first, second, third smallest, and biggest GATA gaps, respectively. We also calculated the mean, median, and standard deviation of all GATA gaps using the variables M-GAP, MI-GAP, and SD-GAP. Furthermore, we introduced variables i-MINDIST (i = 2,..., 5) to measure the minimum number of base pairs spanning over i GATA boxes.\n\nTo capture variations of GATA boxes, we defined k-mer variables. These include UP-i-MER (i = 1, 2, 3), DOWN-i-MER (i = 1, 2, 3), and GAP-i-MER (i = 1, 2), which count specific k-mers in the upstream non-coding sequences. These k-mers represent motifs that are variants of GATA boxes, such as GATAAG and GATAAH.\n\nWe also encoded variables related to the positions of GATA boxes. The variables F-POS and L-POS measure the positions of the first and last GATA boxes, respectively. Additionally, we calculated the mean, median, and standard deviation of the positions of all GATA boxes using the variables M-POS, MI-POS, and SD-POS.\n\nThe data was pre-processed to handle the high-dimensionality of the classification task, where the number of variables exceeded the number of samples. We employed two variable selection methods to improve prediction performance and enhance interpretability. The first method was a filter approach based on the Gram-Schmidt orthogonalization procedure, which ranks variables and determines the number of selected variables through leave-one-out cross-validation. This method is computationally efficient and considers the collinearity between variables, allowing for an incremental construction of the model.\n\nIn summary, our data encoding and preprocessing involved defining a rich set of variables that capture the number, distribution, and variations of GATA boxes, as well as their positions in the upstream non-coding sequences. We utilized variable selection methods to manage the high-dimensionality of the data, ensuring that our machine-learning algorithms could effectively identify putative NCR genes.",
  "optimization/parameters": "In our study, we utilized a high-dimensional dataset comprising nearly 600 variables to identify putative NCR genes in the yeast Saccharomyces cerevisiae. The selection of these variables was crucial for improving prediction performance and enhancing interpretability, given the high-dimensional nature of the classification task.\n\nTo address the challenge of variable selection, we employed two distinct methods: a filter method and a wrapper method. The filter method, based on the Gram-Schmidt orthogonalization procedure, was used to rank variables according to their relevance. This method is computationally efficient and takes into account the collinearity between variables, ensuring that selected variables are not redundant. The number of variables selected was determined through leave-one-out cross-validation, which helped in identifying the optimal subset of variables for the model.\n\nThe wrapper method, on the other hand, involved a forward stepwise procedure where the prediction performance was assessed using stratified 10-fold cross-validation. The balanced error rate (BER) was used as the performance measure, and the threshold on the corrected posterior probability was set at 0.5. This method offers a powerful way to address variable selection by directly evaluating the impact of variable subsets on the classifier's performance.\n\nFor all classifiers used\u2014naive Bayes, k-nearest-neighbors, and linear kernel support vector machine\u2014the number of selected variables was significantly reduced compared to the total number of variables. Specifically, the top selected variables included various k-mers, such as GATAAG, TAGATAA, GATAGG, and GTAGATA. The GATAAG motif, in particular, is known to be relevant for NCR regulation. The analysis of other motifs is ongoing.\n\nIn summary, the selection of variables was a critical step in our approach, ensuring that the model was both efficient and effective in identifying potential NCR genes. The use of nearly 600 variables initially, combined with rigorous variable selection methods, allowed us to reduce the dimensionality of the problem, thereby saving time and resources.",
  "optimization/features": "In our study, we utilized a high-dimensional feature set to identify putative NCR genes in the yeast Saccharomyces cerevisiae. Specifically, we worked with nearly 600 variables, which were derived from various characteristics of GATA boxes within the genes.\n\nTo manage the high dimensionality and improve prediction performance, we employed two variable selection methods. The first method was a filter approach based on the Gram-Schmidt orthogonalization procedure. This method is computationally efficient and considers the collinearity between variables, allowing for an incremental construction of the model. The number of selected variables was determined using leave-one-out cross-validation, ensuring that the selection process was performed solely on the training set.\n\nThe second method was a wrapper approach, which involved a forward stepwise procedure. This method assessed the prediction performance using stratified 10-fold cross-validation, with the balanced error rate (BER) as the performance measure. The wrapper method also ensured that variable selection was conducted using the training set only, thereby avoiding overfitting.\n\nBoth variable selection methods were crucial in reducing the dimensionality of the problem, making the identification of potential NCR genes more efficient and biologically relevant. The top selected variables included specific k-mers, such as GATAAG, TAGATAA, GATAGG, and GTAGATA, which are known or suspected to be relevant for NCR regulation.",
  "optimization/fitting": "The number of parameters in our study is indeed much larger than the number of training points, as we are dealing with a high-dimensional classification task where the number of variables exceeds the number of samples. To address the risk of overfitting, we employed two variable selection methods: a filter method based on the Gram-Schmidt orthogonalization procedure and a wrapper method using a forward stepwise procedure with stratified 10-fold cross-validation. These methods help to reduce the dimensionality of the problem and select the most relevant variables, thereby mitigating overfitting.\n\nTo further ensure the robustness of our results, we performed negative controls by randomly sampling the labels of the training set and running the same procedure. This allowed us to empirically estimate the random rate of correct classification and determine the significance of our findings.\n\nAdditionally, we used leave-one-out cross-validation to assess the quality of the variable selection methods and classifiers. This technique helps to validate the model's performance and generalizability, providing a more reliable estimate of its predictive accuracy.\n\nTo rule out underfitting, we compared multiple classifiers, including naive Bayes, k-nearest-neighbors, and linear kernel support vector machine. The use of different classifiers helps to ensure that the model is not too simplistic and can capture the underlying patterns in the data. Furthermore, we evaluated the performance of each combination of variable selection method and classifier using balanced error rate and area under the receiver operator characteristic curve, ensuring that the model achieves a good balance between bias and variance.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting, given the high-dimensional nature of our data. One of the primary methods used was variable selection. We compared two variable selection approaches: a filter method based on the Gram-Schmidt orthogonalization procedure and a wrapper method using a forward stepwise procedure with stratified 10-fold cross-validation. The filter method ranks variables by considering collinearity and allows for an incremental model construction, which helps in preventing overfitting by not using all variables. The wrapper method assesses the prediction performance of variable subsets, providing a robust way to select relevant features.\n\nAdditionally, we performed a negative control to determine the significance of our results. This involved running the same procedure with randomized datasets, where the labels of the training set were randomly sampled. By comparing the performance on these randomized datasets, we could empirically estimate the random rate of correct classification and ensure that our results were not due to overfitting.\n\nFurthermore, we used leave-one-out cross-validation to assess the quality of our variable selection methods and classifiers. This technique helps in evaluating the model's performance on unseen data, thereby reducing the risk of overfitting. The balanced error rate (BER) and the area under the receiver operator characteristic curve (AUC) were used as performance measures, providing a comprehensive evaluation of our models.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model employed in this study is not a black box. It utilizes a filter method based on the Gram-Schmidt orthogonalization procedure for variable selection, which provides several advantages in terms of interpretability. This method ranks variables in a way that is computationally fast and takes into account the collinearity between variables. If two variables are almost collinear, the selection of one tends to drive the other to a much lower rank, which helps in understanding the importance of each variable independently.\n\nAdditionally, the orthogonalization process allows for an incremental construction of the model. This means that training can be terminated without using all variables, providing a clear pathway to understand which variables are most influential in the classification task. This incremental approach enhances the interpretability by allowing researchers to see the impact of adding or removing specific variables.\n\nThe use of a filter method also assumes linearity and is based on the minimization of a squared error loss, which, although not always the most appropriate for classification, gives relatively good results. This linearity assumption makes the model more transparent, as the relationships between variables and the outcome are more straightforward to interpret.\n\nFurthermore, the variables themselves are well-defined and related to specific properties of the GATA motif in the upstream non-coding sequences of yeast genes. For example, variables like the number of GATA boxes, the gaps between them, and their positions are directly tied to biological features, making the model's decisions more interpretable in a biological context. This clarity in variable definition and selection process contributes to the overall transparency of the model.",
  "model/output": "The model employed in our study is a classification model. Specifically, it is designed to address a supervised two-class classification problem. The primary objective of this model is to predict whether genes in the yeast Saccharomyces cerevisiae are sensitive to nitrogen catabolite repression (NCR) or not. The model takes as input a data matrix containing rows representing genes and columns representing various properties related to the GATA motif in the upstream non-coding sequences of these genes. These properties are quantified through a range of variables that capture different aspects of the GATA motif's occurrence and distribution. The model is trained on a set of known NCR-sensitive and NCR-insensitive genes, and it then uses this training to make predictions about the NCR sensitivity of other genes. The output of the model is a classification of genes into one of the two classes: NCR-sensitive or NCR-insensitive. This classification helps in identifying putative NCR genes, thereby reducing the dimensionality of the problem and focusing biological efforts on the most promising candidates.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The method was evaluated using leave-one-out cross-validation to assess the quality of the variable selection methods and classifiers. This approach ensures that each gene is used once as a test sample while the remaining genes form the training set. Two primary performance measures were employed:\n\nThe balanced error rate (BER), which is the average of the errors on each class. A threshold of 0.5 on the corrected posterior probability was used. The best combinations of variable selection methods and classifiers, those with a BER not significantly higher than the lowest BER according to McNemar's test with a P-value less than 0.05, are marked with an asterisk.\n\nThe area under the receiver operator characteristic (ROC) curve (AUC), which is recommended for evaluating binary decision problems to avoid effects related to the chosen threshold on the posterior probabilities.\n\nAdditionally, the \"gold standard\" set of true NCR genes was extended in the validation step to include putative NCR genes identified in three genome-wide experimental and bioinformatics studies. The quality of the predictions was then evaluated according to the AUC, with results shown in the \"AUCext\" column.\n\nA negative control was performed to determine the significance of the results. This involved empirically estimating the random rate of correct classification by running the same procedure with randomized data sets obtained by randomly sampling the labels of the training set. The values reported are the mean and standard deviation over 10 repetitions.\n\nGene set comparisons were conducted for each combination of variable selection method and classifier, comparing the set of predicted NCR genes with those identified in the three aforementioned studies. The F-measure, defined as the harmonic mean of precision and recall, was computed for each combination and set. Precision measures the fraction of true positives among those inferred as positive, while recall measures the fraction of true positives among all true NCR genes. Overlapping P-values based on the cumulative distribution function of the hypergeometric distribution were also computed to assess the significance of the overlap between sets.",
  "evaluation/measure": "In our evaluation, we employed several performance metrics to thoroughly assess the quality of our variable selection methods and classifiers. The primary metrics reported are the balanced error rate (BER) and the area under the receiver operator characteristic curve (AUC).\n\nThe balanced error rate is defined as the average of the errors on each class, providing a measure that is not biased towards the majority class. This is particularly important in imbalanced datasets, such as ours, where the number of negative samples far outweighs the positive ones. We used a threshold of 0.5 on the corrected posterior probability for this calculation.\n\nThe AUC, on the other hand, evaluates the performance across all possible classification thresholds, making it a robust metric for binary decision problems. It avoids the pitfalls associated with choosing a single threshold and provides a comprehensive view of the classifier's performance.\n\nAdditionally, we extended our validation by computing the AUC with an extended set of \"true\" NCR genes, incorporating putative NCR genes identified in other genome-wide studies. This approach helps to validate our predictions against a broader range of known and putative NCR genes.\n\nTo ensure the significance of our results, we also performed a negative control by randomly sampling the labels of the training set and running the same procedure. This helped us to empirically estimate the random rate of correct classification and to determine whether our results were significant.\n\nThese metrics are representative of standard practices in the literature for evaluating classification models, especially in bioinformatics and machine learning. They provide a clear and comprehensive assessment of our model's performance, ensuring that our findings are both reliable and comparable to other studies in the field.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of different variable selection methods and classifiers to assess their performance in identifying putative NCR genes. We employed a wrapper method that uses a forward stepwise procedure with stratified 10-fold cross-validation to evaluate prediction performance. This approach allowed us to assess the relative usefulness of subsets of variables based on the balanced error rate (BER), which is defined as the average of the errors on each class.\n\nTo ensure the robustness of our results, we performed leave-one-out cross-validation, which is a rigorous method for validating the performance of machine learning models, especially when dealing with limited data. We used two primary performance measures: the balanced error rate (BER) and the area under the receiver operator characteristic (ROC) curve (AUC). The AUC is particularly useful for evaluating binary decision problems as it avoids the effects related to the chosen threshold on the posterior probabilities.\n\nIn addition to these performance measures, we extended the \"gold standard\" set of true NCR genes by including putative NCR genes identified in three genome-wide experimental and bioinformatics studies. This extension allowed us to further validate our predictions and assess their quality according to the AUC.\n\nTo address the risk of overfitting due to the scarcity of data, we performed a negative control by empirically estimating the random rate of correct classification. This involved running the same procedure with randomized data sets obtained by randomly sampling the labels of the training set. The results of these negative controls are reported as the mean and standard deviation over 10 repetitions, providing a measure of the significance of our findings.\n\nFurthermore, we compared the set of predicted NCR genes with those identified in three previous studies. We computed the F-measure, which is the harmonic mean of precision and recall, for each combination of variable selection method and classifier. Precision measures the fraction of true positives among those inferred as positive, while recall measures the fraction of true positives among all true NCR genes. These comparisons allowed us to evaluate the overlap between our predictions and previously identified NCR genes, providing additional validation of our approach.\n\nIn summary, our evaluation involved a comprehensive comparison of different methods and classifiers, rigorous validation techniques, and extensive negative controls to ensure the significance and robustness of our results. This thorough evaluation demonstrates the effectiveness of our machine learning approach in identifying putative NCR genes in the yeast Saccharomyces cerevisiae.",
  "evaluation/confidence": "The evaluation of our method includes several performance metrics with associated confidence intervals. Specifically, we report the mean and standard deviation of the balanced error rate (BER) and the area under the receiver operator characteristic curve (AUC) over multiple repetitions for our negative control experiments. This provides a measure of the variability and reliability of our results.\n\nTo assess the statistical significance of our findings, we employed McNemar's test. This test helps determine if the differences in performance between our method and others, as well as baselines, are statistically significant. Combinations of variable selection methods and classifiers that did not show a significantly higher BER than the lowest observed BER, with a P-value less than 0.05, are marked with an asterisk. This indicates that these combinations are not significantly worse than the best-performing ones.\n\nAdditionally, we used the hypergeometric distribution to compute overlapping P-values. This approach accounts for the artificial increase in overlap that can occur with a decreasing threshold on the corrected posterior probability, ensuring that our results are robust and not due to chance.\n\nOverall, our evaluation includes rigorous statistical methods to ensure that the performance metrics are reliable and that the claimed superiority of our method over others and baselines is supported by significant evidence.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being publicly available. The publication discusses various methods and results related to gene classification and variable selection, but it does not provide details on the availability of the raw evaluation files. Therefore, it is not clear whether these files have been released to the public or under what terms they might be accessible."
}