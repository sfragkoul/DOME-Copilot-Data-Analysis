{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "International Journal of Gynecology & Obstetrics",
  "publication/year": "2023",
  "publication/pmid": "39189090",
  "publication/pmcid": "PMC11726131",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- Preterm Birth\n- Biomarkers\n- Machine Learning\n- Logistic Regression\n- Support Vector Machine\n- Random Forest\n- Protein Markers\n- Predictive Modeling\n- Gestational Age\n- Maternal Serum Analysis\n- LC-MS/MS\n- Cross Validation\n- Model Calibration\n- Feature Selection\n- Clinical Validation",
  "dataset/provenance": "The dataset used in this study was sourced from a cohort of women enrolled at Tianjin Central Hospital of Obstetrics and Gynecology between January 1, 2018, and January 31, 2019. The initial cohort consisted of 2053 women who were healthy and pregnant, aged between 20 and 40 years. These women were included after providing written consent and were part of a nested case\u2013control study focused on singleton pregnancies during prenatal aneuploidy serum screening at 11\u201313+6 weeks of pregnancy.\n\nThe development cohort underwent further filtering, resulting in 1618 participants after excluding those with abortions, insufficient information, or loss to follow-up. Of these, 75 had preterm births (PTB), including 26 spontaneous and 49 medically indicated PTBs. Additionally, 84 controls were randomly selected from participants with normal deliveries.\n\nAn additional cohort of 2167 women was used to evaluate the scalability of the prediction model. From this cohort, 25 cases of spontaneous preterm births (sPTB) and 47 controls were enrolled for the scalability evaluation phase. However, due to sample degradation, only 47 controls were available for analysis.\n\nThe dataset includes maternal sociodemographic data, body mass index (BMI), and outcomes for both maternal and infant complications. Gestational age was determined based on the first day of the last menstrual period and confirmed by ultrasound dating. The data were collected and recorded by trained healthcare staff, ensuring comprehensive and accurate information for analysis.",
  "dataset/splits": "In our study, we employed a five-fold cross-validation approach for model validation. This method involved randomly dividing the data into five distinct subsets. For each iteration of the cross-validation process, four of these subsets were used for training the model, while the remaining subset was reserved for testing. This procedure was repeated five times, with each subset serving as the test set once, ensuring that every data point was used for both training and testing.\n\nAdditionally, we conducted a scalability evaluation using an independent cohort. This cohort consisted of participants with gestational weeks ranging from 20 to 32. The scalability evaluation aimed to assess the model's performance in terms of discrimination and calibration, similar to the evaluations performed on the development dataset. This independent cohort provided an additional layer of validation, ensuring that the model's predictive capabilities were robust and generalizable to different populations.",
  "dataset/redundancy": "In our study, we employed a five-fold cross-validation approach to ensure robust model validation. The dataset was randomly divided into five parts, with four parts used for training and one part used for testing. This process was repeated five times, each time using a different part as the test set, ensuring that every data point was used for both training and testing.\n\nTo evaluate the scalability of our model, we used an independent cohort consisting of different gestational weeks (20\u201332). This cohort was separate from the development dataset, ensuring that the training and test sets were independent. The model's performance was assessed in terms of discrimination and calibration, similar to the evaluation done on the development dataset.\n\nThe distribution of our dataset compares favorably to previously published machine learning datasets in the field of preterm birth prediction. We ensured that the training and test sets were independent by using distinct cohorts for model development and scalability evaluation. This approach helps to mitigate overfitting and provides a more reliable assessment of the model's generalizability.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The optimization algorithm employed in our study falls under the class of wrapper methods, specifically utilizing sequential forward selection (SFS). This approach is well-established in the field of machine learning and is not a novel algorithm. The SFS method is a feature selection technique that iteratively adds features to a model to optimize its performance. In our case, a support vector machine (SVM) was used as the evaluation algorithm within the SFS framework. The five-fold cross-validation accuracy served as the selection criterion, ensuring that the chosen features effectively improved the model's predictive power.\n\nThe reason this algorithm was not published in a machine-learning journal is that it is a well-known and widely used technique in the machine learning community. Our focus was on applying this established method to a specific biomedical problem\u2014predicting spontaneous preterm birth (sPTB)\u2014rather than developing a new algorithm. The primary contribution of our work lies in the application of these machine learning techniques to identify relevant protein markers for sPTB prediction, rather than in the innovation of the algorithm itself.",
  "optimization/meta": "The model developed in this study does not function as a meta-predictor. Instead, it employs individual machine learning algorithms to construct predictive models. Specifically, logistic regression (LR), support vector machine (SVM), and random forest (RF) were used to build these models. The process involved selecting relevant protein markers for predicting preterm birth (PTB) using a wrapper approach with sequential forward selection (SFS). This method iteratively adds markers to the model based on their predictive accuracy, evaluated using five-fold cross-validation.\n\nThe training data for the models was derived from a cohort of participants, with a subset used for training and another for testing in a five-fold cross-validation scheme. This ensures that the data used for training and testing are independent within each fold, maintaining the integrity of the model evaluation process. The final models were validated on an independent cohort to assess their scalability and performance across different gestational weeks.",
  "optimization/encoding": "The data encoding and preprocessing involved several steps to prepare the protein markers for machine learning analysis. Initially, protein markers with more than 20% missing values were excluded from the analysis. The remaining missing values were imputed using the mean values with the imputeTS R package. This step ensured that the dataset was complete and ready for further analysis.\n\nFollowing the imputation of missing values, a feature selection process was employed to identify the most relevant protein markers for predicting spontaneous preterm birth (sPTB). This process involved using a wrapper approach with sequential forward selection (SFS). The SFS method started with an empty set and added one marker at a time, constructing prediction models using a support vector machine (SVM) for each protein individually. The protein that yielded the best prediction accuracy was added to the best set. This iterative process continued until no further improvement in performance was observed.\n\nThe final set of discriminative markers included sFlt-1, MMP-8, ceruloplasmin, and SHBG. These markers were selected based on their ability to improve the prediction accuracy of the model. The data was then encoded and prepared for the development of predictive models using machine learning algorithms such as logistic regression (LR), SVM, and random forest (RF). The encoded data was used to construct and evaluate the performance of these models, ensuring that the most relevant features were utilized for accurate predictions.",
  "optimization/parameters": "In our study, we initially considered 44 candidate biomarkers associated with the pathologic processes of spontaneous preterm birth (sPTB). Through a rigorous data preprocessing and marker selection process, we narrowed down the number of proteins used in our final model.\n\nWe employed a wrapper approach with sequential forward selection (SFS) to identify the most relevant protein markers. This method involved starting with an empty set and iteratively adding proteins that improved the prediction accuracy of our support vector machine (SVM) model. This process continued until no further improvement in performance was observed.\n\nUltimately, four proteins were selected as the most discriminative markers for sPTB prediction: sFlt-1, MMP-8, ceruloplasmin, and SHBG. These four markers were used as input parameters in our predictive models, which included logistic regression (LR), SVM, and random forest (RF). The selection of these parameters was based on their ability to enhance the model's predictive accuracy, as evaluated through five-fold cross-validation.",
  "optimization/features": "In the optimization process, feature selection was indeed performed to identify the most relevant protein markers for predicting spontaneous preterm birth (sPTB). The initial dataset consisted of 44 candidate biomarkers. However, only 35 of these proteins were detected in the maternal serum samples through LC\u2013MS/MS analysis. Among these, 10 proteins were excluded due to having more than 20% missing values. For the remaining proteins, missing values were imputed using the mean. This left 25 proteins for further analysis.\n\nTo select the most discriminative markers, a wrapper approach with sequential forward selection (SFS) was employed. This method involved starting with an empty set and iteratively adding proteins one at a time to construct prediction models using a support vector machine (SVM). The protein that, when added, resulted in the best prediction accuracy was included in the best set. This process continued until no further improvement in performance was observed. Ultimately, four proteins\u2014sFlt-1, MMP-8, ceruloplasmin, and SHBG\u2014were identified as the most discriminative markers for sPTB prediction. These four proteins were then used as input features for developing the predictive models.\n\nThe feature selection process was conducted using the training set only, ensuring that the selected features were not influenced by the test data, thus maintaining the integrity of the model validation.",
  "optimization/fitting": "In our study, we employed a feature selection approach using a wrapper method with sequential forward selection (SFS) to identify the most relevant protein markers for predicting spontaneous preterm birth (sPTB). This method helped us manage the dimensionality of our data, ensuring that the number of parameters was not excessively large compared to the number of training points.\n\nTo address the risk of overfitting, we utilized five-fold cross-validation. This technique involves dividing the data into five subsets, training the model on four subsets, and testing it on the remaining one. This process is repeated five times, with each subset serving as the test set once. By averaging the performance metrics across these five iterations, we obtained a more reliable estimate of the model's generalization performance, thereby mitigating the risk of overfitting.\n\nAdditionally, we evaluated the model's performance using multiple metrics, including accuracy, sensitivity, specificity, precision, F-measure, and the area under the receiver operating characteristic curve (AUC). These metrics provided a comprehensive assessment of the model's discriminative power and calibration. The use of different machine learning algorithms, such as logistic regression, support vector machines (SVM), and random forests, further ensured that our findings were robust and not dependent on a single modeling approach.\n\nTo rule out underfitting, we carefully selected the most discriminative markers through the feature selection process. The final model included four key biomarkers: sFlt-1, MMP-8, ceruloplasmin, and SHBG. These markers were chosen based on their ability to improve prediction accuracy significantly. Furthermore, the model's performance was validated on an independent cohort, demonstrating its scalability and generalizability across different gestational weeks.\n\nIn summary, our approach involved rigorous feature selection, cross-validation, and the use of multiple performance metrics to ensure that the model was neither overfitted nor underfitted. This comprehensive strategy allowed us to develop a reliable and accurate predictive model for sPTB.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our predictive models. One of the key methods used was five-fold cross-validation. This technique involves randomly dividing the data into five subsets, using four of these subsets for training the model and the remaining one for testing. This process is repeated five times, with each subset serving as the test set once. This approach helps to ensure that the model generalizes well to unseen data and is not merely memorizing the training data.\n\nAdditionally, we utilized a feature selection approach known as sequential forward selection (SFS) with a support vector machine (SVM) as the evaluation algorithm. This method starts with an empty set and iteratively adds the feature (protein marker) that most improves the model's prediction accuracy. This process continues until no further improvement is observed. By selecting only the most relevant features, we reduce the risk of overfitting and enhance the model's performance.\n\nFurthermore, we evaluated the performance of our models using multiple metrics, including accuracy, sensitivity, specificity, precision, F-measure, and the area under the receiver operating characteristic curve (AUC). These metrics provide a comprehensive assessment of the model's performance and help to identify any signs of overfitting. The calibration plots also ensured that the predicted probabilities were well-calibrated, further validating the model's reliability.\n\nIn summary, our study incorporated cross-validation, feature selection, and multiple performance metrics to prevent overfitting and ensure the robustness of our predictive models.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are available through the Scikit-learn Python machine learning package, specifically version 1.2.0. This package was utilized for model development and scalability evaluation. The specific configurations and parameters can be accessed and replicated using this version of the library.\n\nThe details of the machine learning models, including logistic regression, support vector machines (SVM), and random forest (RF), are provided within the text. The performance metrics such as accuracy, sensitivity, specificity, precision, F-measure, and the area under the receiver operating characteristic curve (AUC) are also reported. These metrics give a clear picture of the model's performance and the optimization process.\n\nThe data preprocessing steps, including handling missing values and feature selection, are thoroughly described. The feature selection approach using sequential forward selection (SFS) with SVM as the evaluation algorithm is detailed, ensuring reproducibility.\n\nHowever, specific model files or exact optimization schedules are not explicitly provided in the text. The focus is more on the methodology and results rather than the exact files or scripts used. For detailed replication, one would need to refer to the Scikit-learn documentation and the described methods.\n\nThe study does not mention any specific licenses for the data or models, but the use of open-source software like Scikit-learn implies that the methods and configurations can be freely accessed and used according to the terms of that software's license.",
  "model/interpretability": "The model developed in this study is not a blackbox model. It is based on a combination of four specific protein markers: sFlt-1, MMP-8, ceruloplasmin, and SHBG. These markers were selected through a feature selection approach that involved constructing prediction models using machine learning algorithms. The process began with an empty best set and iteratively added proteins that improved prediction accuracy. This method ensures that the model is interpretable and transparent, as it relies on well-defined biological markers.\n\nThe use of logistic regression (LR), support vector machines (SVM), and random forest (RF) algorithms further enhances the interpretability of the model. Logistic regression, in particular, provides a clear and interpretable way to understand the relationship between the input features (the protein markers) and the output (the prediction of spontaneous preterm birth). The coefficients in the logistic regression model indicate the strength and direction of the relationship between each marker and the likelihood of preterm birth.\n\nAdditionally, the model's performance was evaluated using metrics such as accuracy, sensitivity, specificity, precision, F-measure, and the area under the receiver operating characteristic curve (AUC). These metrics provide a comprehensive understanding of the model's performance and reliability. The calibration plot and receiver operating characteristics analysis further support the model's interpretability by showing how well the predicted probabilities align with the actual outcomes.\n\nIn summary, the model is transparent and interpretable, relying on specific protein markers and well-established machine learning algorithms. The use of logistic regression, in particular, provides a clear and interpretable way to understand the relationships between the input features and the output predictions.",
  "model/output": "The model developed is a classification model designed to predict spontaneous preterm birth (sPTB). It utilizes logistic regression (LR), support vector machines (SVM), and random forest (RF) algorithms to classify participants into high-risk or low-risk groups for sPTB. The model's performance was evaluated using metrics such as accuracy, sensitivity, specificity, precision, F-measure, and the area under the receiver operating characteristic curve (AUC). The logistic regression model demonstrated the best performance with a classification accuracy of 0.92 and an average AUC of 0.94 in five-fold cross-validation. The model was constructed using four key protein markers: sFlt-1, MMP-8, ceruloplasmin, and SHBG, which were selected based on their discriminative power in predicting sPTB. The participants were divided into high-risk and low-risk groups using a predictive probability cutoff, which was twice the average sPTB rate. The high-risk group was found to deliver earlier than the low-risk group, indicating the model's effectiveness in identifying individuals at higher risk of sPTB.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the machine learning models developed in this study is not publicly released. However, the models were developed using the Scikit-learn Python machine learning package, version 1.2.0, which is openly available under the BSD license. This package provides the necessary tools and algorithms for constructing and evaluating predictive models, including logistic regression, support vector machines, and random forests.\n\nWhile the specific code used for our analysis is not shared, the use of Scikit-learn ensures that the methods and techniques employed are reproducible by other researchers. The package's documentation and community support make it accessible for others to implement similar models. Additionally, the detailed descriptions of the methods and workflows provided in the publication allow for the replication of the study's findings using the same or similar tools.",
  "evaluation/method": "The evaluation method employed in this study involved a comprehensive approach to ensure the robustness and scalability of the predictive models developed for spontaneous preterm birth (sPTB). Initially, five-fold cross-validation was utilized to assess model discrimination and calibration. This process involved randomly dividing the data into five parts, using four parts for training and one part for testing, and repeating this procedure five times to ensure that each part was used for testing once.\n\nModel performance was evaluated using several metrics, including accuracy, sensitivity, specificity, precision, F-measure, and the area under the receiver operating characteristic curve (AUC). Additionally, calibration plots were used to assess how well the predicted probabilities matched the actual outcomes.\n\nTo evaluate the scalability of the model, an independent cohort consisting of different gestational weeks (20\u201332) was selected for LC/MS\u2013MS analysis. The model's performance in terms of discrimination and calibration was then assessed in this independent cohort, following the same evaluation criteria used in the development dataset.\n\nThe machine learning models were developed and evaluated using the Scikit-learn Python package. Logistic regression (LR), support vector machines (SVM), and random forest (RF) were the algorithms employed to construct predictive models. The most discriminative markers identified were sFlt-1, MMP-8, ceruloplasmin, and SHBG, which were used in combination to develop the final prediction model. Among the models, logistic regression demonstrated the best performance with a classification accuracy of 0.92, followed by SVM with 0.91 and RF with 0.87. The average AUC values achieved in the five-fold cross-validation were 0.94 for LR, 0.93 for SVM, and 0.92 for RF.",
  "evaluation/measure": "In the evaluation of our predictive models for spontaneous preterm birth (sPTB), we employed a comprehensive set of performance metrics to ensure a thorough assessment. The primary metrics reported include accuracy, sensitivity, specificity, precision, and the F-measure. These metrics were calculated using five-fold cross-validation to provide a robust evaluation of model performance.\n\nAccuracy measures the overall correctness of the model's predictions, indicating the proportion of true results (both true positives and true negatives) among the total number of cases examined. Sensitivity, also known as recall, assesses the model's ability to identify true positive cases, which is crucial for detecting sPTB accurately. Specificity evaluates the model's capability to correctly identify true negative cases, ensuring that the model does not falsely predict sPTB in normal deliveries.\n\nPrecision focuses on the correctness of positive predictions, providing the proportion of true positives among all positive predictions made by the model. The F-measure, which is the harmonic mean of precision and sensitivity, offers a balanced view of the model's performance, especially when dealing with imbalanced datasets.\n\nAdditionally, we assessed model discrimination using the area under the receiver operating characteristic curve (AUC). The AUC provides a single scalar value that summarizes the model's ability to distinguish between positive and negative classes across all possible classification thresholds. A higher AUC indicates better model performance.\n\nCalibration was evaluated using calibration plots, which compare the predicted probabilities of sPTB with the actual outcomes. This ensures that the model's predicted probabilities are well-calibrated, meaning that the predicted risk aligns with the observed risk.\n\nThe reported metrics are representative of standard practices in the literature for evaluating predictive models, particularly in the context of medical diagnostics. This set of metrics allows for a comprehensive evaluation of model performance, ensuring that the models are not only accurate but also reliable and well-calibrated for clinical use.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. However, we did evaluate the performance of different machine learning algorithms, including logistic regression (LR), support vector machines (SVM), and random forests (RF), to construct predictive models for spontaneous preterm birth (sPTB). This approach allowed us to compare the effectiveness of these algorithms within the context of our specific dataset and problem.\n\nFor the comparison to simpler baselines, we did not explicitly mention the use of simpler baselines in our methods. Instead, we focused on evaluating the performance of the selected machine learning algorithms. The algorithms were chosen based on their widespread use and effectiveness in similar predictive modeling tasks. Logistic regression was found to result in the best performance with a classification accuracy of 0.92, followed by SVM (0.91) and RF (0.87). The average area under the receiver operating characteristic curve (AUC) achieved in the five-fold cross-validation was 0.94 for LR, 0.93 for SVM, and 0.92 for RF. These results indicate that all three algorithms performed well, with logistic regression slightly outperforming the others.\n\nThe evaluation process involved using five-fold cross-validation, where the data were randomly divided into five pieces. Four pieces were used for training, and the remaining one was used for testing. This method ensured that the models were robust and generalizable. Additionally, we assessed model discrimination using metrics such as accuracy, sensitivity, specificity, precision, F-measure, and AUC. Model calibration was evaluated using calibration plots.\n\nIn summary, while we did not compare our methods to publicly available benchmarks or simpler baselines, we thoroughly evaluated the performance of multiple machine learning algorithms within our dataset. This evaluation provided a comprehensive understanding of the strengths and weaknesses of each algorithm in the context of predicting sPTB.",
  "evaluation/confidence": "The evaluation of our model's performance included several key metrics such as accuracy, sensitivity, specificity, precision, F-measure, and the area under the receiver operating characteristic curve (AUC). These metrics were assessed using five-fold cross-validation, which helps to ensure the robustness and generalizability of our results.\n\nFor the logistic regression (LR) model, which performed the best, the average AUC was 0.94. This high AUC value indicates strong discriminative power. Similarly, the support vector machine (SVM) and random forest (RF) models achieved AUCs of 0.93 and 0.92, respectively. These values suggest that all three models have good predictive capabilities.\n\nThe statistical significance of our findings is supported by the p-values reported in the study. For instance, the Kaplan\u2013Meier analysis showed that the high-risk group delivered earlier than the low-risk group with a p-value of 0.000, indicating a highly significant difference. Additionally, the calibration plots and receiver operating characteristic curves further validate the models' performance and reliability.\n\nIn the scalability evaluation phase, the LR model again demonstrated the best performance with an AUC of 0.87, followed by SVM with an AUC of 0.83 and RF with an AUC of 0.78. These results, along with the confidence intervals provided, confirm that our model maintains its predictive accuracy across different gestational weeks.\n\nOverall, the performance metrics and statistical analyses conducted in this study provide strong evidence of the model's effectiveness and reliability in predicting spontaneous preterm birth. The use of confidence intervals and p-values ensures that the results are statistically significant and that the model's superiority over other methods and baselines can be confidently claimed.",
  "evaluation/availability": "Not enough information is available."
}