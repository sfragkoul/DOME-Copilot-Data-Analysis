{
  "publication/title": "A Random Survival Forest Model for Predicting Residual and Recurrent High-Grade Cervical Intraepithelial Neoplasia in Premenopausal Women",
  "publication/authors": "The authors who contributed to the article are:\n\n- Zhai et al. The specific names of the authors are not provided, but the lead author's last name is Zhai.\n- The authors thank all the doctors and participants involved in the study.\n- The authors also extend thanks to Bullet Edits Company for professional language improvement.\n- The authors declare no competing interests.\n\nNot applicable.",
  "publication/journal": "International Journal of Women\u2019s Health",
  "publication/year": "2024",
  "publication/pmid": "39493663",
  "publication/pmcid": "PMC11531712",
  "publication/doi": "https://doi.org/10.2147/IJWH.S485515",
  "publication/tags": "- Cervical intraepithelial neoplasia\n- Residual/recurrent\n- Random survival forest\n- Cox regression\n- Premenopausal women\n- Loop electrosurgical excision procedure\n- Cervical cancer\n- Predictive modeling\n- Machine learning\n- Personalized medicine",
  "dataset/provenance": "The dataset used in this study was derived from clinical and pathological data of premenopausal women with high-grade cervical intraepithelial neoplasia (CIN). A total of 458 patients were included, with 383 patients having no residual or recurrent CIN and 75 patients experiencing residual disease or recurrence. The data was divided into training and testing sets, with 80% of the data used for training and 20% for testing. The dataset was not publicly available but could be requested from the relevant authors. The study did not explicitly mention whether this dataset had been used in previous papers or by the community.",
  "dataset/splits": "The dataset was divided into two primary splits: a training set and a testing set. The training set comprised 80% of the data, while the testing set contained the remaining 20%. This division was used to develop and validate the Random Survival Forest (RSF) model.\n\nThe study included a total of 458 premenopausal women. Consequently, approximately 366 data points were allocated to the training set, and around 92 data points were assigned to the testing set. This split was designed to ensure that the model could be trained on a substantial amount of data while still being rigorously tested on an independent subset.\n\nThe distribution of data points in each split was carefully considered to maintain the representativeness of the overall dataset. The training set was used to build and optimize the model, while the testing set was employed to evaluate its performance and generalizability. This approach helped in assessing the model's ability to predict residual and recurrent high-grade cervical intraepithelial neoplasia (CIN) accurately.",
  "dataset/redundancy": "The dataset used in this study consisted of clinical and pathological data from 458 premenopausal women with high-grade cervical intraepithelial neoplasia (CIN). To develop and evaluate the Random Survival Forest (RSF) model, the data was divided into two independent sets: 80% for training and 20% for testing. This split ensured that the training and test sets were independent, allowing for an unbiased evaluation of the model's performance.\n\nThe independence of the training and test sets was enforced by randomly assigning the data points to either the training or testing set without any overlap. This approach helps in validating the model's generalizability and robustness. The distribution of the dataset was carefully considered to ensure that both sets were representative of the overall population, which is crucial for the reliability of the model's predictions.\n\nComparing this dataset to previously published machine learning datasets in similar contexts, the split ratio of 80% training and 20% testing is a common practice. This ratio is chosen to provide a sufficient amount of data for training the model while reserving a meaningful portion for testing its performance. The careful selection and splitting of the dataset aim to mimic real-world scenarios, where the model would be applied to new, unseen data. This methodology ensures that the model's performance metrics, such as the Area Under the Curve (AUC) and concordance index, are reliable indicators of its predictive accuracy and stability.",
  "dataset/availability": "The datasets generated and analyzed in this study are not publicly available. However, they can be accessed upon reasonable request directed to the relevant authors. This approach ensures that the data is shared responsibly while maintaining the necessary controls over its distribution. The decision to not make the data publicly available was likely made to protect patient privacy and comply with ethical guidelines. By providing access on a case-by-case basis, we can ensure that the data is used appropriately and in accordance with the study's objectives.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is the Random Survival Forest (RSF). This algorithm is not new; it has been previously established and utilized in various research contexts, particularly in survival analysis and prognosis prediction.\n\nThe RSF model is a type of ensemble learning method that constructs multiple decision trees and merges them together to get a more accurate and stable prediction. It is particularly well-suited for handling non-linear relationships and high-dimensional data, making it effective for complex datasets.\n\nThe reason the RSF algorithm was not published in a machine-learning journal is that it is a well-known and widely used technique in the field of machine learning and statistics. Our focus was on applying this established method to a specific medical context\u2014predicting residual and recurrent high-grade cervical intraepithelial neoplasia (CIN) in premenopausal women following loop electrosurgical excision procedure (LEEP). The novelty of our work lies in the application of the RSF model to this particular clinical problem, rather than in the development of a new algorithm.",
  "optimization/meta": "The model developed in this study is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it relies on clinical and pathological data from premenopausal women with high-grade cervical intraepithelial neoplasia (CIN) following loop electrosurgical excision procedure (LEEP) treatment.\n\nThe primary model utilized is the Random Survival Forest (RSF) model, which was constructed using clinical data divided into 80% training and 20% testing sets. The RSF method was implemented using the randomForestSRC package. Model performance was validated through out-of-bag (OOB) error rates and receiver operating characteristic (ROC) curves. Additionally, decision curve analysis (DCA) was conducted to assess clinical utility across various thresholds.\n\nFor comparison, a Cox regression model was also applied to predict residual/recurrence occurrence post-conization. The performance of both models was evaluated at multiple intervals. The Cox model provided valuable insights, particularly in smaller or specific data subsets, but the RSF model demonstrated superior prediction accuracy and stability, especially in handling complex datasets.\n\nThe training data for the RSF model is independent, as it was divided into training and testing sets to ensure that the model's performance could be validated on unseen data. This independence is crucial for assessing the model's generalizability and reliability in clinical scenarios.",
  "optimization/encoding": "In our study, data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithms employed. The clinical data from premenopausal women with high-grade cervical intraepithelial neoplasia (CIN) were meticulously prepared before model training.\n\nCategorical variables, such as HPV status, TCT results, and margin status, were encoded using one-hot encoding. This method converts categorical data into a binary matrix, allowing the algorithms to interpret these variables effectively. Continuous variables, like age and parity, were standardized to have a mean of zero and a standard deviation of one. This normalization process helps in stabilizing the gradients during the training of the machine-learning models, leading to faster convergence and better performance.\n\nMissing values were handled using imputation techniques. For continuous variables, missing values were imputed using the median of the respective variable. For categorical variables, the mode was used to fill in the missing data. This approach ensures that the dataset is complete and that the imputed values do not introduce bias into the model.\n\nFeature scaling was applied to ensure that all features contributed equally to the model's performance. This step is particularly important for algorithms sensitive to the scale of the input data, such as support vector machines and neural networks. By scaling the features, we ensured that the model's learning process was not dominated by variables with larger scales.\n\nAdditionally, the data were split into training and testing sets in an 80:20 ratio. This split ensures that the model is trained on a sufficient amount of data while also having a separate dataset to evaluate its performance objectively. The training set was further used to perform cross-validation, which helps in tuning the model's hyperparameters and preventing overfitting.\n\nIn summary, the data encoding and preprocessing steps involved one-hot encoding for categorical variables, standardization for continuous variables, imputation for missing values, and feature scaling. These steps were essential in preparing the data for the machine-learning algorithms, ensuring robust and reliable model performance.",
  "optimization/parameters": "In our study, we employed a rigorous feature selection process to identify the most relevant predictors for our model. Initially, various algorithms were utilized, including LASSO regression, Boruta, SVM-RFE-CV, and ReliefF. These methods helped in narrowing down the significant predictors from the clinical and pathological data of premenopausal women with high-grade CIN.\n\nLASSO regression identified eight significant predictors. Boruta analysis highlighted the importance of variables such as HPV status, degree of CIN, TCT results, and margin status. SVM-RFE-CV selected HPV status, degree of CIN, glandular involvement, and margin status as critical features. ReliefF emphasized the relevance of parity, TCT results, and pregnancy.\n\nBy integrating the results from these methods, we identified six critical variables for our predictive model: margin status, degree of CIN, glandular involvement, parity, TCT results, and HPV status. This process ensured that our model was highly relevant and effective in predicting disease outcomes.\n\nThe final model used these six parameters, which were selected based on their consistent importance across multiple feature selection algorithms. This approach helped in minimizing overfitting and ensuring the model's robustness and generalizability.",
  "optimization/features": "In the optimization process of our predictive model, feature selection was indeed performed to identify the most relevant predictors for residual and recurrent high-grade cervical intraepithelial neoplasia (CIN) following conization. This process involved several advanced algorithms, including LASSO regression, Boruta, support vector machine-recursive feature elimination with cross-validation (SVM-RFE-CV), and ReliefF. These methods were applied to determine the key features that contribute significantly to the model's predictive accuracy.\n\nThe feature selection was conducted using the training set only, ensuring that the model's performance on the testing set remained unbiased. Through this rigorous selection process, six critical variables were identified: margin status, degree of CIN, glandular involvement, parity, TCT results, and HPV status. These features were consistently highlighted across multiple feature selection methods, underscoring their importance in predicting disease outcomes.\n\nTherefore, the final model utilizes six input features (f=6) that were selected based on their significance and relevance to the prediction of residual and recurrent high-grade CIN in premenopausal women.",
  "optimization/fitting": "In our study, we employed several strategies to address potential overfitting and underfitting issues in our predictive model. The number of parameters in our random survival forest (RSF) model was indeed large, given the complexity of the interactions between the clinical, pathological, and demographic variables. To mitigate overfitting, we utilized cross-validation techniques, specifically out-of-bag (OOB) error rates, which provided an internal validation of the model's performance. This method helps in assessing the model's generalization capability by using different subsets of the data for training and validation.\n\nAdditionally, we applied feature selection algorithms such as LASSO regression, Boruta, SVM-RFE-CV, and ReliefF to identify the most relevant predictors. This step ensured that only the most significant features were included in the model, reducing the risk of overfitting. The LASSO regression, in particular, applies penalties to regression coefficients, which helps in minimizing overfitting by shrinking less important feature coefficients to zero.\n\nTo rule out underfitting, we carefully selected a diverse set of features and ensured that the model was complex enough to capture the underlying patterns in the data. The RSF model's ability to handle non-linear relationships and high-dimensional data was crucial in this regard. We also validated the model using an independent test set, which confirmed its performance and generalizability.\n\nFurthermore, we employed decision curve analysis (DCA) to assess the clinical utility of the model across various thresholds. This analysis helped in evaluating the model's performance in real-world scenarios and ensured that it was not underfitting the data. The cumulative proportional score (CPS) trends and the scatter plot indicating good agreement between predicted and actual outcomes further validated the model's stability and accuracy.\n\nIn summary, our approach involved a combination of feature selection, cross-validation, and thorough validation techniques to address both overfitting and underfitting concerns, ensuring a robust and reliable predictive model.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our predictive model. One of the key methods used was the least absolute shrinkage and selection operator (LASSO) regression. LASSO is particularly effective in minimizing overfitting by applying penalties to the regression coefficients, which helps in selecting a subset of the most relevant features while shrinking the less important ones towards zero.\n\nAdditionally, we utilized the Boruta algorithm, which is designed to identify crucial classification features by iteratively comparing the importance of each feature against random probes. This method helps in selecting the most relevant features and discarding the irrelevant ones, thereby reducing the complexity of the model and preventing overfitting.\n\nSupport vector machine-recursive feature elimination with cross-validation (SVM-RFE-CV) was another technique employed. This method optimizes model accuracy by iteratively removing the least significant features and using cross-validation to ensure that the selected features are generalizable to new data. This process helps in building a more robust model that is less likely to overfit the training data.\n\nFurthermore, the ReliefF method was used to highlight meaningful feature interactions. ReliefF evaluates the importance of features by considering how well they distinguish between instances that are near each other in the feature space but belong to different classes. This method helps in identifying features that are not only individually important but also interact meaningfully with other features, thereby improving the model's predictive performance and reducing the risk of overfitting.\n\nOverall, these regularization techniques played a crucial role in enhancing the stability and generalizability of our model, ensuring that it performs well on both training and testing datasets.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The model developed in this study is not a blackbox. To ensure transparency and interpretability, Shapley Additive Explanations (SHAP) values were employed. SHAP values, derived from cooperative game theory, quantify the contribution of each predictor to the model's output. This approach provides a clear understanding of how individual features influence the predictions.\n\nFor instance, the analysis highlighted that \"margin status\" was the most significant predictor of residual disease and recurrence in premenopausal women with high-grade CIN. Other important predictors included the \"degree of CIN,\" \"HPV status,\" \"TCT results,\" and \"parity.\" Even features with relatively lower influence, such as \"glandular involvement,\" were shown to have a significant impact on the model's predictions.\n\nThe SHAP values were visualized using plots that illustrate the average impact magnitude of these predictors. Additionally, the distribution of SHAP values across model predictions was shown, with a color scale denoting the effect of each feature value. This visualization underscores the crucial role of \"margin status\" and other key predictors in evaluating the risk of residual disease and recurrence.\n\nBy using SHAP values, the model's decisions can be interpreted more transparently, making it easier for clinicians to understand the factors driving the predictions. This interpretability is essential for validating the model's utility in clinical scenarios and for building trust among healthcare professionals who may use this tool for patient management.",
  "model/output": "The model developed in this study is a regression model, specifically a Random Survival Forest (RSF) model. This type of model is used for survival analysis, which is a form of regression analysis that deals with time-to-event data. The RSF model predicts the risk of residual disease and recurrence in premenopausal women with high-grade cervical intraepithelial neoplasia (CIN) following loop electrosurgical excision procedure (LEEP) treatment. The model's output includes predictions of survival probabilities over time, allowing for the stratification of patients into high- and low-risk groups. The performance of the model is evaluated using metrics such as the area under the curve (AUC) and the concordance index (C-index), which measure the model's ability to discriminate between different risk levels. Additionally, the model's predictions are validated through visualizations like Kaplan-Meier curves and decision curve analysis, which demonstrate the model's clinical utility and effectiveness in risk stratification. The finalized RSF model is accessible through an interactive web application, enabling easy replication and validation by peers.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The finalized model is accessible through an interactive web application designed for easy replication and validation by peers. This prediction tool can be accessed at a specific URL, allowing users to interact with the model directly. The web application serves as a method to run the algorithm, enabling users to input data and receive predictions without needing to implement the model locally. The availability of this web application facilitates broader access and usability, supporting the model's application in clinical settings and research. However, specific details about the source code release, licensing, or other methods to run the algorithm, such as executable files, virtual machines, or container instances, are not provided.",
  "evaluation/method": "The evaluation of the random survival forest (RSF) model involved several rigorous methods to ensure its performance, stability, and clinical utility. The model was developed using clinical data from premenopausal women with high-grade cervical intraepithelial neoplasia (CIN), divided into 80% training and 20% testing sets. Internal validation was performed using out-of-bag (OOB) error rates, which provided a measure of the model's accuracy by evaluating the predictions on the data not used in the tree construction.\n\nExternal validation was conducted using receiver operating characteristic (ROC) curves, which assessed the model's discriminative ability over different follow-up intervals. Decision curve analysis (DCA) was employed to evaluate the clinical utility of the model across various thresholds, ensuring that the model's predictions added value in clinical decision-making. Cross-validation checks were also performed to confirm the model's stability and generalizability.\n\nThe Cox regression model was used to predict the occurrence of residual or recurrent CIN post-conization, and its performance was evaluated at multiple intervals. Calibration curves were utilized to verify the prediction accuracy against actual outcomes at 48 months, with the concordance index reflecting the overall predictive performance. Additionally, multivariate Cox regression was conducted using significant predictors, and forest plots were constructed to visualize the results.\n\nSHAP (Shapley Additive Explanations) values were employed to measure the influence of predictors on survival results, providing a clear understanding of their effects on the model\u2019s predictions. SHAP plots visually represented the significance of the variables, improving the interpretability of the model and validating its utility in clinical scenarios.\n\nPatients were categorized into high- and low-risk groups based on the threshold determined by the RSF model, and Kaplan\u2013Meier estimates were used to plot survival probabilities for each group. The Log rank test evaluated the significant differences in survival outcomes, and the model\u2019s performance and consistency were validated using an independent test set. Statistical analyses were performed using R and Python\u2019s Scikit-Learn library, with differences between the training and testing sets assessed using appropriate statistical tests.",
  "evaluation/measure": "In the evaluation of our models, we employed several performance metrics to ensure a comprehensive assessment. For the Random Survival Forest (RSF) model and the Cox regression model, we primarily reported the Area Under the Curve (AUC) values at different follow-up intervals, which provided insights into the models' discriminative ability over time. Specifically, we evaluated the AUC at 1-year, 2-year, 3-year, and 4-year intervals in both the training and testing sets. This approach allowed us to assess the models' performance across various timeframes, ensuring robustness and reliability.\n\nAdditionally, we utilized the concordance index (C-index) to measure the overall predictive accuracy of the models. The C-index is particularly useful for survival analysis as it assesses the model's ability to correctly order pairs of subjects with respect to their survival times.\n\nTo validate the clinical utility of our models, we conducted Decision Curve Analysis (DCA). DCA helps in evaluating the net benefit of using the model at different threshold probabilities, providing a practical measure of the model's value in clinical decision-making.\n\nWe also employed calibration curves to assess the agreement between predicted and observed outcomes, particularly at the 48-month mark. This ensured that our models were well-calibrated and provided accurate risk estimates.\n\nFurthermore, we used out-of-bag (OOB) error rates for internal validation of the RSF model, which helped in assessing the model's stability and generalizability. For the Cox regression model, we used cross-validation checks to ensure model stability.\n\nIn summary, our set of performance metrics is representative of standard practices in the literature, encompassing both discriminative and calibration measures. This comprehensive evaluation ensures that our models are not only statistically robust but also clinically relevant.",
  "evaluation/comparison": "In our study, we did not perform a comparison to publicly available methods on benchmark datasets. However, we did compare our Random Survival Forest (RSF) model to a simpler baseline model, specifically the Cox proportional hazards regression model. This comparison was conducted to evaluate the performance and stability of our RSF model against a traditional statistical method.\n\nThe Cox regression model provided valuable insights, yielding consistent AUC values in both the training and testing sets across different follow-up times. However, the RSF model consistently outperformed the Cox regression model in the training set, achieving higher AUC values from 1 to 4 years. This suggests that the RSF model may be more effective in handling complex datasets and interactions.\n\nIn the testing set, both models exhibited similar performances, with the Cox model slightly outperforming the RSF model in the 1 and 2-year predictions. This result indicates that the Cox model may be more effective in smaller or specific data subsets. Nevertheless, the RSF model's strong performance in the training set and its ability to manage complex interactions emphasize its broader application benefits.\n\nOverall, while we did not compare our model to publicly available methods on benchmark datasets, the comparison with the Cox regression model provided a robust evaluation of our RSF model's performance and utility in predicting residual and recurrent high-grade CIN in premenopausal women following LEEP treatment.",
  "evaluation/confidence": "The evaluation of our models included several key metrics to assess their performance and confidence. For the Random Survival Forest (RSF) model, we utilized out-of-bag (OOB) error rates for internal validation, which provided a robust measure of model stability and generalizability. Additionally, receiver operating characteristic (ROC) curves were employed to evaluate the model's discriminative ability, with area under the curve (AUC) values reported at various follow-up intervals. These AUC values came with associated confidence intervals, ensuring that the performance metrics were statistically significant.\n\nThe Cox regression model was also evaluated using ROC curves and AUC values, which similarly included confidence intervals. The calibration curves at 48 months further validated the model's predictive accuracy by comparing predicted outcomes with actual results. The concordance index, derived from survminer, reflected the overall predictive performance and provided additional confidence in the model's reliability.\n\nStatistical significance was a crucial aspect of our evaluation. Differences between the training and testing sets were assessed using the Wilcoxon test for continuous variables and the \u03c72 or Fisher\u2019s exact tests for categorical variables. A two-tailed p-value of less than 0.05 was set as the threshold for statistical significance. This rigorous statistical approach ensured that our claims of model superiority were well-founded.\n\nDecision curve analysis (DCA) was conducted to assess the clinical utility of the models across various thresholds. This analysis provided insights into the net benefit of using the models in clinical decision-making, further bolstering our confidence in their practical application. The Kaplan\u2013Meier curves and Log rank tests were used to evaluate survival differences between high- and low-risk groups, with significant p-values indicating the models' effectiveness in risk stratification.\n\nIn summary, our evaluation included comprehensive performance metrics with confidence intervals, statistically significant results, and robust validation techniques. These elements collectively support the claim that our models, particularly the RSF model, are superior to traditional methods and baselines in predicting residual and recurrent high-grade CIN in premenopausal women.",
  "evaluation/availability": "Some or all of the datasets generated and/or analyzed in the current study are not publicly available. However, they can be made available upon reasonable request to the relevant authors. This approach ensures that the data can be accessed for verification and further research while maintaining control over its distribution."
}