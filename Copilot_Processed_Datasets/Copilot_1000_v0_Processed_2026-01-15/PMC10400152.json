{
  "publication/title": "A leaf-level spectral library to support high-throughput plant phenotyping: predictive accuracy and model transfer",
  "publication/authors": "The authors who contributed to this article are as follows:\n\nNadeesha K. Wijewardane and Yufeng Ge performed the data analysis and wrote the manuscript.\n\nNadeesha K. Wijewardane and Hongyu Zhang contributed to the data collection.\n\nJ. Christopher S. 1, Jianping Yu, David P. Schachtman, and Yufeng Ge conceived, supervised, and implemented the greenhouse and field trials, which provided the samples for data collection.\n\nAll the authors edited and approved the manuscript for publication.",
  "publication/journal": "Not applicable",
  "publication/year": "2023",
  "publication/pmid": "37018460",
  "publication/pmcid": "PMC10400152",
  "publication/doi": "Not enough information is available.",
  "publication/tags": "- VIS-NIR-SWIR spectroscopy\n- Leaf traits\n- Model transferability\n- Spectral library\n- Machine learning\n- Partial least-squares regression\n- Deep neural networks\n- Extra-weighted spiking\n- Plant phenotyping\n- Precision agriculture",
  "dataset/provenance": "The dataset used in this study is a leaf-level VIS-NIR-SWIR spectral library. This library was constructed from maize and sorghum leaves collected across multiple years and experimental conditions. Specifically, the library includes seven datasets from different field and greenhouse experiments conducted between 2018 and 2020. These datasets comprise four maize datasets with a total of 1571 samples and three sorghum datasets with 889 samples, resulting in a combined total of 2460 leaf spectra. Each spectrum is accompanied by associated ground-truth information.\n\nThe external test sets, which were used to validate the models, include four different datasets: soybean, camelina, maize, and sorghum. These datasets collectively contain 445 plant spectra. Notably, the spectral library did not include any soybean or camelina spectra, providing an opportunity to evaluate the library's applicability to non-grass species.\n\nThe spectral library and the external test sets showed significant differences in various leaf properties, such as nitrogen, potassium, magnesium, calcium, leaf water content, and chlorophyll content for maize, and phosphorus, calcium, sulfur, and leaf mass per area for sorghum. When considering all four species, the library and the external test sets were significantly different across all properties except for phosphorus content.\n\nThe spectral differences between the library and the external test sets were prominent in both the wavelength domain and principal component space. The external test datasets exhibited a broader spectral variation, likely due to the inclusion of four different species with diverse leaf morphology, physiology, and biochemistry. This diversity contrasts with the spectral library, which consisted primarily of two similar species. Camelina, in particular, stood out as a distinct spectral group in the principal component space.\n\nThe spectral library has not been used in previous papers by the community, as it is a newly assembled dataset specifically for this study. The objective was to evaluate the utility of this spectral library for predicting leaf properties in external datasets using techniques such as extra-weighted spiking. This approach aims to improve model performance by incorporating local variability into the calibration dataset, thereby enhancing model robustness and transferability.",
  "dataset/splits": "In our study, we utilized a spectral library consisting of seven datasets collected from various field and greenhouse experiments conducted between 2018 and 2020. This library comprised four maize datasets with 1571 samples and three sorghum datasets with 889 samples, totaling 2460 leaf spectra with associated ground-truth information.\n\nFor external validation, we employed four different datasets: soybean, camelina, maize, and sorghum, amounting to 445 plant spectra. Notably, the spectral library did not include any soybean or camelina spectra, allowing us to evaluate the library's applicability to non-grass species.\n\nThe external test sets included 110 soybean samples, 100 camelina samples, 110 maize samples, and 125 sorghum samples. These datasets were used to validate the models calibrated on the spectral library.\n\nThree methods of model calibration and testing were compared. First, models were calibrated from the library and directly applied to the test sets. Secondly, models were calibrated from spiking sets (20 samples randomly drawn as the calibration set) and used to predict the test sets. Thirdly, we investigated 'extra-weighted spiking' by adding spiking sets to the library to form an augmented set, which was then used to develop and validate the calibration models.\n\nFor the spiking analysis, a randomly selected 50 samples from the soybean dataset were set aside for spiking. Different numbers of samples (10, 20, 30, 40, 50) were randomly selected from this spiking dataset and used for PLSR model calibration with extra-weighted spiking. Each model was then used to predict the remaining soybean samples. This approach allowed us to investigate the impact of the size of the spiking set on model transferability.",
  "dataset/redundancy": "The datasets used in this study were split into a spectral library and external test sets. The spectral library consisted of seven datasets collected from different field and greenhouse experiments from 2018 to 2020. It included four maize datasets and three sorghum datasets, totaling 2460 leaf spectra with associated ground-truth information. The external test sets, on the other hand, included four different datasets of soybean, camelina, maize, and sorghum, totaling 445 plant spectra. Notably, the spectral library did not include any soybean or camelina spectra, providing an opportunity to evaluate the library's applicability to other non-grass species.\n\nThe training and test sets were independent, with the spectral library serving as the training set and the external datasets as the test sets. This independence was enforced by ensuring that the external datasets were collected from different species and under different conditions than those in the spectral library. The spectral library consisted of maize and sorghum, while the external datasets included soybean and camelina, which are eudicots, differentiating them from the monocots in the library.\n\nThe distribution of the nine leaf properties for the spectral library and the independent external test sets showed significant differences. For instance, in maize, the library and external test sets differed in nitrogen (N), potassium (K), magnesium (Mg), calcium (Ca), leaf water content (LWC), and chlorophyll (CHL). In sorghum, the differences were observed in phosphorus (P), calcium (Ca), sulfur (S), and leaf mass per area (LMA). When considering all four species, the library and the external test sets were significantly different from each other across all the properties except for phosphorus content.\n\nThe spectral differences between the library and the external test sets were also prominent in both the wavelength domain and principal component (PC) space. The external test datasets had a broader spectral variation, which could be attributed to the greater diversity in leaf morphology, physiology, and biochemistry among the four species in the external datasets compared to the two species in the spectral library. This spectral variation was visually represented in the PC space, where camelina stood out as a different spectral group compared to the other species.",
  "dataset/availability": "The data used in this study is not publicly available. The spectral library was constructed from maize and sorghum leaves collected across multiple years and experimental conditions. However, the study suggests a community-based approach for future work, where researchers could contribute their data to build a central spectral library. This approach has been successfully implemented in the soil spectroscopy community through the 'Soil Spectroscopy 4 Global Good' project. A similar effort for plants could potentially benefit the plant science community by providing access to a diverse sample set. This collaborative approach would address the challenges of data ownership, privacy, standardization, operational costs, maintenance, and high computational requirements for model calibration. The study emphasizes the importance of such a spectral library for diverse applications, including phenotyping, sensing, modeling, and precision agriculture. However, the specific datasets and data splits used in this study are not released in a public forum.",
  "optimization/algorithm": "The optimization algorithm employed in our study utilized two distinct machine-learning approaches: partial least-squares regression (PLSR) and deep neural networks (DNNs). These methods were chosen to represent both linear and non-linear modeling techniques.\n\nPLSR is a conventional and widely used spectroscopic modeling technique. It implements an algorithm similar to principal component analysis to reduce the number of predictors (wavelengths) to a few latent variables. Unlike principal component analysis, PLSR constructs these latent variables considering the response variable (the property of interest) to ensure the highest correlations. A linear model is then fitted between the response variable and these latent variables.\n\nOn the other hand, DNNs consist of layers of nodes operating as non-linear summing devices, similar to biological neurons. Nodes in each layer are connected to the nodes in adjacent layers through weights that are optimized iteratively to produce the best-fitting model. These weights are adjusted by back-propagation, where the learning error is propagated back to the previous layers. Unlike PLSR, DNNs are not interpretable but are considered effective when the signal-to-noise ratio is low.\n\nThe choice of these algorithms was driven by the need to compare a linear, less computationally demanding, and more interpretable method (PLSR) with a non-linear method known for producing superior accuracies with spectral libraries (DNNs). Both methods have been extensively studied and applied in various fields, including spectroscopy, making them suitable for our objectives.\n\nThe algorithms used are not new; they have been established in the field of machine learning and spectroscopy. The focus of our study was not on developing new algorithms but on evaluating the performance of these well-known techniques in the context of leaf trait estimation using VIS-NIR-SWIR spectral data. Therefore, publishing in a machine-learning journal was not the primary goal, as our contributions lie in the application and comparison of these methods within the domain of plant phenotyping.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "Before applying any machine-learning algorithms, wavelength averaging with a window size of 10 nm was implemented on all spectra. This step was taken to reduce the dimensionality of the data and decrease the computational load. Two machine-learning approaches were investigated for building the calibration models: partial least-squares regression (PLSR) and deep neural networks (DNNs). These techniques were chosen to represent both linear and non-linear modeling approaches.\n\nPLSR is a conventional spectroscopic modeling technique that reduces predictors (i.e., the number of wavelengths) to a few latent variables using an algorithm similar to principal component analysis. However, unlike principal component analysis, PLSR considers the response variable (i.e., the property of interest) to ensure the highest correlations. A linear model is then fitted between the response variable and the latent variables.\n\nDNNs, on the other hand, consist of layers of nodes operating as non-linear summing devices similar to biological neurons. Nodes in each layer are connected to the nodes in the adjacent layers through weights that are optimized iteratively to produce the best-fitting model. These weights are adjusted by back-propagation, where the learning error is propagated back to the previous layers.\n\nData analysis and plotting were implemented in Python 3.8 using several libraries, including scikit-learn, pandas, NumPy, and Matplotlib. The entire spectral library was used for model calibration with 10-fold cross-validation to avoid model overfitting and to identify the best tuning parameters. For PLSR, models with up to 30 latent variables were considered. For DNNs, hidden layer sizes (5, 10, 15, and 20) and L2 penalty (0.005, 0.01, and 0.03) with the activation function \u2018relu\u2019 were used as the tuning parameters. The best tuning parameters were selected based on the lowest cross-validated root mean-squared error (RMSECV) in 10-fold cross-validation. These parameters were then used to build the final models for each modeling technique using the entire dataset.",
  "optimization/parameters": "In our study, we employed two machine-learning approaches for model calibration: partial least-squares regression (PLSR) and deep neural networks (DNNs). For PLSR, we considered models with up to 30 latent variables, which serve as the input parameters (p) for this technique. These latent variables are constructed to maximize the correlation with the response variable, ensuring that the most relevant information from the spectral data is captured.\n\nThe selection of the number of latent variables was based on the principle of achieving the lowest cross-validated root mean-squared error (RMSECV) through 10-fold cross-validation. This process helps in identifying the optimal number of latent variables that balance model complexity and performance.\n\nFor DNNs, the input parameters (p) include the sizes of the hidden layers and the L2 penalty. We explored hidden layer sizes of 5, 10, 15, and 20, and L2 penalties of 0.005, 0.01, and 0.03. The activation function used was 'relu'. The best combination of these parameters was determined by selecting the configuration that resulted in the lowest RMSECV during the 10-fold cross-validation process. This approach ensures that the DNN model is optimized for the given dataset and task.",
  "optimization/features": "The input features for our models were derived from spectral data, specifically from the VIS-NIR-SWIR (Visible, Near-Infrared, and Short-Wave Infrared) spectral range. To reduce dimensionality and computational load, wavelength averaging with a window size of 10 nm was implemented on all spectra. This process effectively reduced the number of input features (f) by aggregating nearby wavelengths, making the data more manageable for modeling.\n\nFeature selection was not explicitly performed in the traditional sense of selecting a subset of features from the original set. Instead, the dimensionality reduction through wavelength averaging served a similar purpose by condensing the spectral information into fewer, more informative features. This approach ensured that the models could handle the data efficiently without losing critical spectral information.\n\nThe wavelength averaging was applied uniformly to all datasets, including the training set, ensuring that the feature reduction process did not introduce any bias. This method allowed us to maintain the integrity of the spectral data while making the modeling process more computationally feasible. The resulting features were then used to build calibration models using two machine-learning approaches: partial least-squares regression (PLSR) and deep neural networks (DNNs).",
  "optimization/fitting": "In our study, we employed two distinct machine-learning approaches for model calibration: partial least-squares regression (PLSR) and deep neural networks (DNNs). These methods were chosen to represent both linear and non-linear modeling techniques, respectively.\n\nFor PLSR, we considered models with up to 30 latent variables. This approach reduces the dimensionality of the predictors (wavelengths) while ensuring high correlations with the response variable (leaf properties). To prevent overfitting, we used 10-fold cross-validation, which helps in identifying the best tuning parameters by minimizing the cross-validated root mean-squared error (RMSECV). This method ensures that the model generalizes well to unseen data.\n\nDNNs, on the other hand, consist of layers of nodes that operate as non-linear summing devices. We varied the hidden layer sizes (5, 10, 15, and 20) and L2 penalty (0.005, 0.01, and 0.03) to find the optimal configuration. The activation function used was 'relu'. Similar to PLSR, we employed 10-fold cross-validation to tune the parameters and avoid overfitting. The iterative adjustment of weights through back-propagation ensures that the model learns effectively from the data.\n\nTo address the potential issue of underfitting, we ensured that our models were complex enough to capture the underlying patterns in the data. For PLSR, the use of up to 30 latent variables allowed the model to capture sufficient variability in the data. For DNNs, the varying hidden layer sizes and the non-linear nature of the model helped in capturing complex relationships.\n\nIn summary, we used cross-validation extensively to balance the model complexity and prevent both overfitting and underfitting. This rigorous approach ensured that our models were robust and generalizable to external datasets.",
  "optimization/regularization": "To prevent overfitting, we employed a 10-fold cross-validation technique during the model calibration process. This approach helps to ensure that the model generalizes well to unseen data by dividing the dataset into 10 subsets, training the model on 9 subsets, and validating it on the remaining subset. This process is repeated 10 times, with each subset serving as the validation set once.\n\nAdditionally, we considered the use of regularization techniques specific to each modeling approach. For partial least-squares regression (PLSR), we limited the number of latent variables to a maximum of 30, which helps in reducing the complexity of the model and preventing it from fitting the noise in the data. For deep neural networks (DNNs), we used L2 penalty regularization with different values (0.005, 0.01, and 0.03) to penalize large weights and encourage simpler models. The activation function 'relu' was used, which helps in mitigating the vanishing gradient problem and aids in better convergence during training.\n\nFurthermore, we investigated the impact of the size of the spiking set on model transferability. By recalibrating and validating the models with spiking sets of different sizes (10, 20, 30, 40, 50), we observed that increasing the size of the spiking set generally improved the model performance up to a certain point, after which the improvements started to level off. This analysis helped us to determine an appropriate size for the spiking set, considering both model performance and practical costs.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are reported within the publication. Specifically, for the partial least-squares regression (PLSR) models, we considered up to 30 latent variables. For the deep neural networks (DNNs), we explored various hidden layer sizes (5, 10, 15, and 20) and L2 penalty values (0.005, 0.01, and 0.03) with the activation function 'relu'. The best tuning parameters were selected based on the lowest cross-validated root mean-squared error (RMSECV) in 10-fold cross-validation.\n\nThe model files and optimization parameters are not explicitly provided in the publication. However, the data analysis and plotting were implemented using Python 3.8 with libraries such as scikit-learn, pandas, NumPy, and Matplotlib. These libraries are open-source and freely available under their respective licenses.\n\nFor those interested in replicating our work, the supplementary data, including descriptive statistics and prediction statistics, are available online. This information can be accessed at the Journal of Experimental Botany (JXB) online platform. The supplementary data provide additional details that can aid in understanding and replicating the optimization processes described in our study.",
  "model/interpretability": "The models employed in our study encompass both interpretable and non-interpretable approaches. Partial Least-Squares Regression (PLSR) is a conventional and commonly used spectroscopic modeling technique that implements an algorithm similar to principal component analysis. This method reduces predictors (i.e., the number of wavelengths) to a few latent variables. Unlike principal component analysis, PLSR constructs latent variables considering the response variable (i.e., the property of interest) to ensure the highest correlations. A linear model is then fitted between the response variable and latent variables, making PLSR an interpretable and transparent model. This transparency allows researchers to understand the relationships between the spectral data and the leaf properties being predicted.\n\nIn contrast, Deep Neural Networks (DNNs) consist of layers of nodes operating as non-linear summing devices similar to biological neurons. Nodes in each layer are connected to the nodes in the adjacent layers through weights that are optimized iteratively to produce the best-fitting model. These weights are adjusted by back-propagation, where the learning error is propagated back to the previous layers. DNNs are not interpretable, as the relationships between the input spectral data and the output predictions are encoded in complex, non-linear transformations within the network. This lack of interpretability means that while DNNs can produce superior accuracies, especially when the signal-to-noise ratio is low, they do not provide clear insights into how the predictions are made.",
  "model/output": "The models developed in this study are regression models. We employed two machine-learning approaches for model calibration: partial least-squares regression (PLSR) and deep neural networks (DNNs). Both techniques were used to predict continuous leaf traits based on spectral data. The performance of these models was evaluated using metrics such as the coefficient of determination (R\u00b2) and the root mean-squared error of cross-validation (RMSECV). The goal was to estimate various leaf properties, including nutrient contents and structural traits, rather than classifying them into discrete categories. Therefore, the output of our models is continuous values representing the predicted leaf traits.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The software used for data analysis and plotting in this study was implemented in Python 3.8. The primary libraries utilized include scikit-learn, pandas, NumPy, and Matplotlib. These libraries are widely available and can be installed via standard package managers such as pip or conda. The source code for the specific implementations and models developed in this study is not publicly released. However, the libraries mentioned are open-source and can be accessed through their respective repositories. The methods and algorithms described in the study can be replicated using these libraries, following the procedures outlined in the publication. For those interested in replicating the analysis, detailed information on the libraries and their usage is available in their documentation.",
  "evaluation/method": "The evaluation of the method involved several key steps to assess its performance and robustness. Initially, models were calibrated using a spectral library consisting of data from maize and sorghum. These models were then directly applied to external test sets comprising maize, sorghum, camelina, and soybean to evaluate their predictive performance. This approach allowed for an assessment of how well the models generalized to new, unseen data.\n\nTo further enhance the model's performance, a technique called 'extra-weighted spiking' was employed. This involved adding a small number of samples from the external datasets to the spectral library, with these samples being given extra weight in the calibration process. The impact of this spiking was evaluated by comparing the performance of models calibrated with and without the spiked samples. The evaluation metrics used included the coefficient of determination (R2) and the root mean-squared error (RMSE), which provided insights into the accuracy and reliability of the predictions.\n\nAdditionally, the size of the spiking set was varied to determine the optimal number of samples needed to achieve the best model performance. This analysis involved recalibrating the models with different sizes of spiking sets and evaluating their predictive performance on the external datasets. The results showed that increasing the size of the spiking set generally improved the model's performance, but the improvements started to level off after a certain point.\n\nThe evaluation also included a comparison of two modeling techniques: partial least-squares regression (PLSR) and deep neural networks (DNN). This comparison was based on cross-validation statistics, including R2 and RMSE, to identify the best-performing technique for estimating various leaf properties. The results indicated that both techniques had their strengths, but PLSR generally showed better performance in terms of R2 and RMSE for most of the leaf properties.\n\nOverall, the evaluation method involved a comprehensive assessment of model performance using external datasets, the application of extra-weighted spiking to improve model robustness, and a comparison of different modeling techniques. This approach provided a thorough understanding of the method's effectiveness and its potential for real-world applications.",
  "evaluation/measure": "In our study, we employed several performance metrics to evaluate the effectiveness of our models. The primary metrics reported are the coefficient of determination (R\u00b2) and the root mean-squared error (RMSE). These metrics were used to assess the predictive performance of our models during cross-validation and when applied to external datasets.\n\nR\u00b2 is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. It provides an indication of how well the model's predictions match the actual data, with values ranging from 0 to 1, where 1 indicates perfect prediction.\n\nRMSE, on the other hand, measures the average magnitude of the errors between predicted and observed values. It provides an absolute measure of fit, with lower values indicating better model performance.\n\nIn addition to R\u00b2 and RMSE, we also considered bias and the ratio of performance to deviation (RPD) to evaluate our models. Bias measures the average difference between predicted and observed values, indicating whether the model tends to overestimate or underestimate the true values. RPD is a measure of model accuracy relative to the variability of the data, with higher values indicating better model performance.\n\nThese metrics are widely used in the literature for evaluating predictive models, particularly in the context of spectral data and machine learning. They provide a comprehensive assessment of model performance, covering both the goodness of fit and the accuracy of predictions. By reporting these metrics, we aim to provide a clear and representative evaluation of our models' performance, allowing for comparisons with other studies in the field.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of modeling techniques to identify the best approach for estimating leaf traits. We focused on two primary methods: Partial Least-Squares Regression (PLSR) and Deep Neural Networks (DNNs). PLSR is a conventional and widely used spectroscopic modeling technique known for its simplicity and interpretability. It reduces the number of predictors by constructing latent variables that maximize the correlation with the response variable. On the other hand, DNNs are more complex, non-linear models that consist of layers of nodes operating as non-linear summing devices. These networks are optimized through iterative weight adjustments using back-propagation, making them effective for handling low signal-to-noise ratios.\n\nTo ensure a fair and comprehensive comparison, we implemented wavelength averaging with a window size of 10 nm on all spectra. This step reduced dimensionality and decreased computational load, allowing us to focus on the core differences between the modeling techniques. We used the entire spectral library for model calibration, employing 10-fold cross-validation to avoid overfitting and to identify the best tuning parameters. For PLSR, we considered models with up to 30 latent variables, while for DNNs, we varied hidden layer sizes and L2 penalty values to find the optimal configuration.\n\nThe comparison was based on cross-validation R2 values and Root Mean Squared Error (RMSE). These metrics provided a clear indication of each model's performance in predicting leaf traits. By evaluating both PLSR and DNNs, we aimed to determine which approach offered the best overall performance. The results of this comparison are crucial for understanding the strengths and limitations of each method in the context of leaf trait estimation.",
  "evaluation/confidence": "The evaluation of our models involved a comprehensive assessment of their performance using several metrics, including the coefficient of determination (R\u00b2) and the root mean-squared error of cross-validation (RMSECV). These metrics were calculated for various leaf properties across different species, providing a robust measure of model accuracy and reliability.\n\nTo ensure the statistical significance of our results, we employed cross-validation techniques. This approach helps in assessing how the models will generalize to an independent dataset. The use of cross-validation is crucial because it provides a more reliable estimate of model performance compared to a single train-test split. By repeatedly splitting the data into training and validation sets, we could obtain a distribution of performance metrics, which allowed us to calculate confidence intervals.\n\nThe results indicated that the models calibrated with extra-weighted spiking generally showed better performance compared to those calibrated solely from the spectral library or the spiking sets alone. This improvement was statistically significant for many of the leaf properties, particularly for species not included in the original spectral library, such as camelina and soybean. The significant increases in R\u00b2 and decreases in RMSECV for these species suggest that the extra-weighted spiking method effectively captures the local variabilities of the external datasets, enhancing model robustness.\n\nFurthermore, the analysis of the changes in R\u00b2 and RMSE with increasing numbers of samples in the spiking set revealed a general trend of improvement up to a certain point. This trend was consistent across different leaf properties, indicating that the size of the spiking set is an important factor in model performance. The leveling off of improvements beyond a certain spiking set size (around 50 samples) suggests that there is an optimal number of samples beyond which additional samples do not significantly enhance model performance.\n\nIn summary, the performance metrics used in our evaluation are supported by statistical significance, and the results demonstrate the superiority of the extra-weighted spiking method over other calibration techniques. The confidence intervals derived from cross-validation provide a reliable measure of model performance, ensuring that the observed improvements are not due to random chance.",
  "evaluation/availability": "Not enough information is available."
}