{
  "publication/title": "Not enough information is available.",
  "publication/authors": "Not enough information is available.",
  "publication/journal": "Health and Technology",
  "publication/year": "2022",
  "publication/pmid": "36406186",
  "publication/pmcid": "PMC9646469",
  "publication/doi": "https://doi.org/10.1007/978-3-030-89996-7_17",
  "publication/tags": "- COVID-19\n- Vaccination\n- Machine Learning\n- Predictive Modeling\n- Health Technology\n- Data Analysis\n- Epidemiology\n- Public Health\n- Statistical Models\n- Deep Learning",
  "dataset/provenance": "The dataset utilized in this study was sourced from Kaggle. Specifically, the \"COVID-19 World Vaccination Progress\" dataset was employed, which includes daily and total vaccination data for COVID-19 from \"Our World in Data.\" This dataset encompasses information from various countries, detailing the total number of vaccinations, the number of people vaccinated, the types of vaccines used, and the dates of vaccination.\n\nThe dataset covers a comprehensive range of attributes, including country names, ISO codes, dates, total vaccinations, people vaccinated, people fully vaccinated, daily vaccination figures, and vaccination rates per hundred and per million people. Additionally, it includes information on the types of vaccines administered.\n\nThe dataset was divided into two main parts: a training set and a testing set. The training dataset consists of COVID-19 daily vaccination data from December 13, 2020, to June 13, 2021. The testing dataset covers the period from June 14, 2021, to October 14, 2021. This division allows for a robust evaluation of the prediction models' performance over time.\n\nPrevious works have often been limited in scope, focusing primarily on data from the United States and covering shorter timeframes. For instance, some studies used data from just three months, such as from August 26, 2020, to November 26, 2020. In contrast, our dataset provides a more extensive and global perspective, enabling a more comprehensive analysis of vaccination trends across different continents.\n\nThe attributes of the dataset include country names, ISO codes, dates, total vaccinations, people vaccinated, people fully vaccinated, daily vaccination figures, vaccination rates per hundred and per million people, and types of vaccines. This rich set of attributes allows for detailed and nuanced analysis, contributing to the accuracy and reliability of the prediction models developed in this study.",
  "dataset/splits": "The dataset was divided into two main splits: a training set and a test set. The training set comprised 70% of the data, while the test set contained the remaining 30%. The training dataset included daily COVID-19 vaccination data from December 13, 2020, to June 13, 2021. The test dataset covered the period from June 14, 2021, to October 14, 2021. This split was designed to evaluate the prediction outcomes of daily COVID-19 vaccinations to help decrease pandemic risk.",
  "dataset/redundancy": "The dataset employed in our study was sourced from Kaggle and included comprehensive information on COVID-19 vaccinations across various countries. The dataset attributes encompassed details such as country, ISO code, date, total vaccinations, people vaccinated, people fully vaccinated, daily vaccinations, and types of vaccines used.\n\nTo ensure robust model training and evaluation, the dataset was partitioned into a training set and a test set. Specifically, 70% of the data was allocated to the training set, while the remaining 30% was reserved for the test set. This split was designed to provide a substantial amount of data for training the models while maintaining a sufficient test set to evaluate their performance accurately.\n\nThe training dataset comprised COVID-19 daily vaccination data from December 13, 2020, to June 13, 2021. In contrast, the test dataset included data from June 14, 2021, to October 14, 2021. This temporal separation ensured that the training and test sets were independent, preventing any overlap that could bias the model's performance evaluation.\n\nThe distribution of the dataset in our study differs from some previously published machine learning datasets, which often focused on shorter timeframes or specific regions. For instance, some studies used data limited to the United States or covered only a few months. In contrast, our dataset spans a broader temporal range and includes global vaccination data, providing a more comprehensive and diverse foundation for model training and evaluation. This approach aims to enhance the generalizability and reliability of our predictive models.",
  "dataset/availability": "The dataset utilized in this study is publicly available on Kaggle. It is titled \"COVID-19 World Vaccination Progress\" and includes daily and total vaccination data for COVID-19 worldwide. The dataset can be accessed via the provided link on Kaggle. The data encompasses various attributes such as country, date, total vaccinations, people vaccinated, types of vaccines used, and more. This dataset was used to train and test machine learning models for predicting daily COVID-19 vaccinations.\n\nThe dataset was split into training and testing sets. The training dataset consists of COVID-19 daily data from December 13, 2020, to June 13, 2021, while the testing dataset covers the period from June 14, 2021, to October 14, 2021. This split ensures that the models are trained on historical data and tested on more recent data to evaluate their predictive performance.\n\nThe dataset is available under the terms and conditions specified by Kaggle, which typically include a license that allows for academic and research use. Users are encouraged to review the specific licensing details on the Kaggle platform to ensure compliance with the terms of use. The availability of this dataset on a public forum like Kaggle ensures transparency and reproducibility of the research findings.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are not new. They are well-established techniques that have been widely employed in various applications, including healthcare. The algorithms used include Elastic Net (ENET), CUBIST, Gaussian Process (GAUSS), and Spikes and Slab (SPIKES). These algorithms were chosen for their effectiveness in handling time-series data and their ability to extract spatial features from the dataset.\n\nThe decision to use these specific algorithms was driven by their proven track record in similar predictive modeling tasks. The algorithms were selected based on their ability to provide accurate and reliable predictions for daily COVID-19 vaccination dissemination. The study focuses on applying these algorithms to a specific problem\u2014predicting COVID-19 vaccine acceptance and trends\u2014rather than introducing new machine-learning techniques.\n\nThe algorithms were fine-tuned using parameters such as resampling methods, the number of resampling iterations, and tuning parameter determination. These parameters were carefully selected to optimize the performance of the models. The training process involved partitioning the dataset into training and test sets, with 70% of the data used for training and 30% for testing. This approach ensures that the models are trained on a sufficient amount of data while also being validated on unseen data to assess their generalizability.\n\nThe performance of the models was evaluated using metrics such as Mean Absolute Scaled Error (MASE), Relative Absolute Error (RAE), and Mean Squared Log Error (MSLE). These metrics provide a comprehensive assessment of the models' predictive accuracy and reliability. The study aims to present machine-learning algorithms that can effectively predict COVID-19 vaccine daily dissemination and propose novel systems for predicting vaccination trends across different continents. The focus is on applying existing algorithms in a novel context to address the specific challenges posed by the COVID-19 pandemic.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "In our study, the data encoding and preprocessing steps were crucial for ensuring the effectiveness of the machine-learning algorithms used for COVID-19 vaccination prediction. The dataset, obtained from Kaggle, included various attributes such as Country, iso_code, Date, total_vaccinations, people_vaccinated, people_fully_vaccinated, daily_vaccinations_raw, daily_vaccinations, total_vaccinations_per_hundred, people_vaccinated_per_hundred, people_fully_vaccinated_per_hundred, daily_vaccinations_per_million, and Vaccines.\n\nThe dataset was first partitioned into a training set (70%) and a test set (30%). This split allowed us to train our models on a substantial portion of the data while reserving a separate set for evaluating their performance. The time-series data was preprocessed to extract spatial features, which are essential for capturing the temporal dynamics of vaccination rates.\n\nFeature selection was performed to identify the most relevant attributes for the prediction task. The selected features were then modeled using four different machine-learning algorithms: Elastic Net (ENET), CUBIST, Gaussian Process (GAUSS), and Spikes and Slab (SPIKES). Each of these algorithms has its own strengths and is suited for different types of data and prediction tasks.\n\nThe Elastic Net algorithm combines the penalties of Lasso and Ridge regression, making it effective for handling datasets with multicollinearity. CUBIST is a rule-based regression model that can capture non-linear relationships in the data. Gaussian Process regression is a non-parametric method that provides a probabilistic framework for regression tasks. The Spikes and Slab algorithm is used for variable selection and can handle high-dimensional data by identifying the most important features.\n\nThe preprocessing steps also included handling missing values, normalizing the data, and ensuring that the temporal sequence was maintained. These steps are essential for improving the accuracy and reliability of the machine-learning models. By carefully encoding and preprocessing the data, we were able to enhance the performance of our models and achieve more accurate predictions of daily COVID-19 vaccination rates.",
  "optimization/parameters": "In the optimization of our COVID-19 vaccination prediction system, we utilized several machine learning models, each with its own set of parameters. The specific number of parameters (p) varied depending on the model used.\n\nFor the Elastic Net (ENET) model, the parameters included the mixing parameter between ridge and lasso, the regularization penalty, and the regression coefficients. The selection of these parameters was crucial for balancing the trade-off between bias and variance, ensuring that the model generalizes well to unseen data.\n\nThe CUBIST model, being a rule-based model derived from the M5 model tree, incorporated linear regression models within its terminal leaves. The parameters here included the coefficients of these linear models and the smoothing factor that considers predictions from parent nodes. The selection of these parameters aimed to create a robust model that could handle both linear and non-linear relationships in the data.\n\nThe Gaussian Process (GAUSS) model, a probabilistic framework, relied on parameters that defined the covariance function, which in turn determined the smoothness and variability of the predictions. The selection of these parameters was guided by the need to capture the underlying patterns in the time-series data while providing reliable confidence intervals.\n\nThe Spikes and Slab (SPIKES) algorithm, used for variable selection, had parameters that controlled the sparsity of the model, ensuring that only the most relevant features were included in the final prediction.\n\nThe tuning of these parameters was performed using a combination of grid search and cross-validation techniques. This process involved partitioning the dataset into training and test sets, with the training set further divided into folds for cross-validation. The performance of each model was evaluated using metrics such as Mean Absolute Scaled Error (MASE), Relative Absolute Error (RAE), and Mean Squared Log Error (MSLE). The parameters that yielded the best performance on the validation set were then selected for the final model.\n\nIn summary, the number of parameters (p) and their selection were model-specific and were optimized through rigorous tuning and validation processes to ensure the accuracy and reliability of the COVID-19 vaccination prediction system.",
  "optimization/features": "In the optimization process of our COVID-19 vaccination prediction system, we utilized a dataset comprising several attributes. The dataset, sourced from Kaggle, includes the following features: Country, iso_code, Date, total_vaccinations, people_vaccinated, people_fully_vaccinated, daily_vaccinations_raw, daily_vaccinations, total_vaccinations_per_hundred, people_vaccinated_per_hundred, people_fully_vaccinated_per_hundred, daily_vaccinations_per_million, and Vaccines. This results in a total of 13 features used as input for our models.\n\nFeature selection was indeed performed to enhance the predictive performance of our models. The dataset was partitioned into a training set (70%) and a test set (30%). The selected features from the training data were then modeled using various machine learning algorithms, including Elastic Net (ENET), CUBIST, Gaussian Process (GAUSS), and Spikes and Slab (SPIKES). This approach ensures that the feature selection process was conducted using the training set only, maintaining the integrity of the test set for unbiased evaluation.",
  "optimization/fitting": "In our study, we employed four distinct machine learning models to predict COVID-19 vaccination trends: Elastic Net (ENET), CUBIST, Gaussian Process (GAUSS), and Spikes and Slab (SPIKES). Each of these models has its own set of parameters that need to be tuned to optimize performance.\n\nThe number of parameters in our models is not excessively large compared to the number of training points. Our dataset, sourced from Kaggle, includes a comprehensive set of attributes such as country, date, total vaccinations, and various vaccination rates. This rich dataset allows for robust training without the risk of overfitting. To further mitigate overfitting, we utilized techniques such as cross-validation and regularization. For instance, Elastic Net incorporates both L1 and L2 penalties, which help in reducing the complexity of the model and preventing it from fitting the noise in the data.\n\nTo ensure that our models do not underfit, we carefully selected features and tuned hyperparameters. The dataset was partitioned into a training set (70%) and a test set (30%), allowing us to validate the model's performance on unseen data. Additionally, we evaluated the models using multiple performance metrics, including Mean Absolute Scaled Error (MASE), Relative Absolute Error (RAE), and Mean Squared Log Error (MSLE). These metrics provided a comprehensive assessment of the models' predictive accuracy and generalizability.\n\nIn summary, our approach to fitting the models involved a balance between complexity and simplicity, ensuring that the models neither overfit nor underfit the data. This was achieved through careful feature selection, regularization, cross-validation, and thorough performance evaluation.",
  "optimization/regularization": "In our study, we employed Elastic Net (ENET) as one of the machine learning models for predicting COVID-19 vaccination rates. Elastic Net is a regularization technique that combines both L1 (Lasso) and L2 (Ridge) penalties. This method helps to prevent overfitting by shrinking the regression coefficients. The L1 penalty encourages sparsity by driving some coefficients to zero, effectively performing feature selection. The L2 penalty, on the other hand, shrinks the coefficients but does not drive them to zero, which helps in handling multicollinearity. By combining these two penalties, Elastic Net provides a balanced approach to regularization, making it effective in scenarios where the number of predictors is large compared to the number of observations. This regularization technique was crucial in ensuring that our model generalized well to new data, thereby enhancing the reliability of our predictions.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in this study are reported in the paper. Specifically, the parameters used to regulate the COVID-19 vaccine training set are detailed in a table within the publication. This table provides the necessary information for fine-tuning the model's performance.\n\nThe paper is licensed under a Creative Commons Attribution 4.0 International License. This license permits the use, sharing, adaptation, distribution, and reproduction of the work, provided that appropriate credit is given to the original authors and the source. This includes the ability to access and utilize the reported hyper-parameter configurations and optimization parameters.\n\nModel files and optimization schedules are not explicitly mentioned as being available separately from the paper. Therefore, while the configurations and parameters are reported, the actual model files and schedules are not provided as standalone resources.",
  "model/interpretability": "The models discussed in this publication vary in their interpretability, ranging from more transparent to black-box approaches.\n\nThe Elastic Net (ENET) model, for instance, is relatively interpretable. It combines the penalties of ridge regression and lasso, allowing for both variable shrinkage and selection. This means that the model can identify which predictors are most important, providing a clear understanding of the relationships between the input variables and the output. The mixing parameter in ENET controls the balance between ridge and lasso penalties, offering flexibility in the level of interpretability desired.\n\nCUBIST, a rule-based model derived from the M5 model tree, is also quite interpretable. It generates a set of rules that can be easily understood and followed. Each rule is a pathway from the top to the bottom of the tree, and at the terminal nodes, linear regression models are used to make predictions. These models are \"smoothed\" by considering the predictions from preceding nodes, which adds a layer of interpretability by showing how different parts of the data contribute to the final prediction.\n\nOn the other hand, the Gaussian Process (GAUSS) model is more of a black-box approach. While it is a powerful tool for regression and classification, providing predictions based on past data and offering confidence intervals, the internal workings of the model are not as straightforward to interpret. The model's predictions are based on complex probabilistic calculations, making it difficult to pinpoint exactly how each input variable influences the output.\n\nIn summary, while some models like ENET and CUBIST offer a good degree of interpretability, allowing for clear insights into the relationships between variables, others like GAUSS are more opaque, providing powerful predictive capabilities but at the cost of transparency.",
  "model/output": "The models discussed in this publication are primarily regression models. Several specific models are mentioned, each with its unique approach to regression.\n\nOne of the models is Elastic Net (ENET), which combines the penalties of ridge regression and lasso. This model is used for regression tasks and includes a mixing parameter that balances between ridge and lasso regression.\n\nAnother model is CUBIST, a rule-based model derived from the M5 model tree. It embeds linear regression models in the terminal leaves of a tree and uses predictors from earlier splits to create these models. CUBIST generates predictions using linear regression models at the tree's terminal nodes, which are then smoothed by considering the predictions from preceding nodes.\n\nAdditionally, the Gaussian Processes (GAUSS) model is a probabilistic machine learning framework used for regression and classification. However, in the context discussed, it is primarily used for regression tasks. This model makes predictions based on past data and provides confidence ranges for those predictions.\n\nThe performance of these models is evaluated using various measures such as Mean Absolute Scaled Error (MASE), Mean Squared Logarithmic Error (MSLE), and Relative Absolute Error (RAE) across different continents. The results indicate how well each model performs in predicting outcomes related to vaccination against COVID-19.\n\nIn summary, the models discussed are regression models, each with its methodology and applications in predicting outcomes related to vaccination against COVID-19.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of the proposed methods for predicting COVID-19 vaccination involved several key steps and metrics. Four machine learning models\u2014Elastic Net (ENET), CUBIST, Gaussian Process (GAUSS), and Spikes and Slab (SPIKES)\u2014were employed for this prediction task. The dataset used for evaluation was obtained from Kaggle and included daily COVID-19 vaccination data from December 13, 2020, to October 14, 2021. This dataset was split into training and testing sets, with the training data covering December 13, 2020, to June 13, 2021, and the testing data covering June 14, 2021, to October 14, 2021.\n\nThe dataset attributes included country, ISO code, date, total vaccinations, people vaccinated, people fully vaccinated, daily vaccinations, and types of vaccines used. The dataset was partitioned into a training set (70%) and a test set (30%). The selected features from the dataset were then modeled using the aforementioned machine learning algorithms.\n\nThe performance of these models was evaluated using three primary metrics: Mean Absolute Scaled Error (MASE), Relative Absolute Error (RAE), and Mean Squared Log Error (MSLE). These metrics provided a comprehensive assessment of the prediction accuracy and reliability of the models.\n\nThe evaluation process also involved tuning the parameters of the models to optimize their performance. This step was crucial for ensuring that the models could accurately predict daily COVID-19 vaccinations across different continents, including Africa, Asia, Europe, North America, Oceania, and South America.\n\nThe results of the evaluation were summarized in performance tables, which showed the MASE, MSLE, and RAE for each model across the different continents. This detailed evaluation allowed for a thorough comparison of the models' predictive capabilities and identified the most effective methods for COVID-19 vaccination prediction.",
  "evaluation/measure": "In our study, we employed three key performance metrics to evaluate the accuracy of our machine learning models in predicting daily COVID-19 vaccinations. These metrics are Mean Absolute Scaled Error (MASE), Relative Absolute Error (RAE), and Mean Squared Log Error (MSLE).\n\nMASE is a scale-independent measure that compares the forecasting error of a model to that of a simple naive forecast. It provides a standardized way to evaluate the accuracy of time series forecasts, making it easier to compare models across different datasets.\n\nRAE, on the other hand, measures the accuracy of a model by comparing the absolute errors of the model's predictions to the absolute errors of a simple benchmark model, typically the mean of the observed values. A lower RAE indicates better model performance.\n\nMSLE is particularly useful for evaluating models on datasets with exponential growth, such as vaccination rates during the early stages of a rollout. It measures the squared difference between the logarithm of the predicted values and the logarithm of the actual values, giving more weight to larger errors.\n\nThese metrics were chosen because they provide a comprehensive evaluation of model performance, capturing different aspects of prediction accuracy. MASE and RAE offer a relative measure of performance, while MSLE provides an absolute measure that is sensitive to larger errors. Together, they give a robust assessment of how well our models are performing in predicting daily COVID-19 vaccinations.\n\nOur choice of metrics is also representative of the literature in this field. Many studies on time series forecasting and prediction of health-related outcomes use similar metrics to evaluate model performance. For instance, studies on predicting COVID-19 cases and vaccinations often report MASE, RAE, and MSLE, among other metrics. This consistency in the use of performance metrics allows for better comparison and benchmarking of different models and studies.",
  "evaluation/comparison": "In our study, we developed and evaluated four machine learning models\u2014CUBIST, Gaussian Process (GAUSS), Elastic Net (ENET), and Spikes and Slab (SPIKES)\u2014for predicting daily COVID-19 vaccinations across various continents. To assess the performance of these models, we utilized several metrics, including Mean Absolute Scaled Error (MASE), Relative Absolute Error (RAE), and Mean Squared Log Error (MSLE).\n\nWe did not compare our models to publicly available methods on benchmark datasets. Instead, we focused on evaluating the performance of our selected models using a dataset obtained from Kaggle, which included daily COVID-19 vaccination data from December 13, 2020, to October 14, 2021. This dataset covered countries that had administered COVID-19 vaccines, the types of vaccines used, and the dates of vaccination.\n\nOur evaluation showed that CUBIST outperformed the other models, achieving the lowest error rates across different continents. For instance, CUBIST demonstrated superior performance in predicting daily COVID-19 vaccinations in Asia, North America, Oceania, and South America, as indicated by its MASE values.\n\nRegarding simpler baselines, our study did not explicitly compare our models to simpler baselines. Instead, we concentrated on comparing the performance of the four machine learning algorithms we developed. The comparison was based on their ability to predict daily COVID-19 vaccinations accurately, using the specified performance metrics.\n\nIn summary, while our study did not involve a direct comparison to publicly available methods or simpler baselines, it provided a comprehensive evaluation of the selected machine learning models using a robust dataset and performance metrics. The results indicated that CUBIST was the most accurate model for predicting daily COVID-19 vaccinations across multiple continents.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being available. However, the dataset used for the study is publicly available on Kaggle. This dataset includes COVID-19 vaccination data from various countries, covering attributes such as total vaccinations, people vaccinated, and daily vaccinations. The dataset can be accessed through the provided link on Kaggle, which allows for use, sharing, adaptation, distribution, and reproduction under a Creative Commons Attribution 4.0 International License. This license permits these actions as long as appropriate credit is given to the original authors and the source, a link to the Creative Commons license is provided, and any changes made are indicated. For more details on the license, one can visit the Creative Commons website."
}