{
  "publication/title": "Using machine learning to explore core risk factors associated with the risk of eating disorders among non-clinical young women in China: A decision-tree classification analysis",
  "publication/authors": "The authors who contributed to this article are:\n\n- Yaoxiang Ren, who drafted and revised the manuscript.\n- Chaoyi Lu, who built the machine learning model, performed the statistical analysis, and helped draft and revise the manuscript.\n- Han Yang, who helped perform the statistical analysis and helped draft and revise the manuscript.\n- Qianyue Ma, who built the machine learning model, performed the statistical analysis, and helped draft and revise the manuscript.\n- Wesley R. Barnhart, who helped draft and revise the manuscript.\n- Jianjun Zhou, who helped perform the statistical analysis and helped draft and revise the manuscript.\n- Jinbo He, who led the study design and results interpretation and helped draft and revise the manuscript.",
  "publication/journal": "Journal of Eating Disorders",
  "publication/year": "2022",
  "publication/pmid": "35144682",
  "publication/pmcid": "PMC8832719",
  "publication/doi": "10.1186/s40337-022-00545-6",
  "publication/tags": "- Eating disorders\n- Machine learning\n- Decision tree\n- Risk factors\n- Chinese women\n- Emotion regulation\n- Body image inflexibility\n- Psychological distress\n- Body dissatisfaction\n- Non-clinical sample",
  "dataset/provenance": "The dataset used in this study was sourced from a project approved by the Institutional Review Board of the Chinese University of Hong Kong, Shenzhen. The participants were recruited from Hunan Agriculture University. The survey was conducted using paper and pencil, and psychology teachers at the university introduced the study to their first- and second-year undergraduate students during class time, inviting them to participate.\n\nA total of 1,065 undergraduate students were eligible for the study after removing those who did not provide informed consent or failed the attention check questions. The focus was on the female participants, resulting in a dataset of 830 women aged between 18 and 23 years, with a mean age of 18.91 years and a standard deviation of 0.95 years.\n\nThe dataset includes various measures such as Body Mass Index (BMI), psychological distress assessed using the Kessler Scale (K6), eating inflexibility measured by the Inflexible Eating Questionnaire (IEQ), and body image inflexibility assessed by the Body Image Acceptance and Action Questionnaire short form (BIAAQ-5). Additionally, the dataset includes scores from the Emotional Overeating subscale, the Loss of Control Over Eating Scale-Brief (LOCES-B), and the Short Form of the Eating Disorder Examination Questionnaire (EDE-QS) to measure the risk of eating disorders.\n\nThe dataset has been used to explore eating disorder risk factors among Chinese women, filling a gap in the literature by including a range of well-established eating disorder risk factors from the emotional regulation perspective. This study is novel in its application of machine learning to identify young women in China who might be at high risk of developing eating disorders.",
  "dataset/splits": "The dataset was divided into two primary splits: a training set and a testing set. The training set comprised 70% of the total data, which amounted to 581 samples out of 830. The testing set consisted of the remaining 30%, totaling 249 samples. The original training dataset had 93 positive samples, representing 16.01% of the training set, and 488 negative samples, making up 83.99% of the training set. To address the imbalance, the synthetic minority oversampling technique (SMOTE) was applied, adding 395 synthetic positive samples to the training set, resulting in an equal number of positive and negative samples.\n\nThe testing set was used to evaluate the model's performance, with a sensitivity of 0.88 and a specificity of 0.85. This indicates that the model correctly identified 88% of individuals at high risk of eating disorders and 85% of those not at high risk. Additionally, to further validate the results, a random sampling method was employed, selecting 30% of the overall dataset five different times. The average sensitivity across these samples was 0.85, and the average specificity was 0.86. Furthermore, 50 different test sets were generated by changing the random seed used to split the training and test sets, yielding a mean sensitivity of 0.84 and a mean specificity of 0.86.",
  "dataset/redundancy": "The dataset was split into training and testing subsets to evaluate the decision tree classification model. Specifically, 70% of the data (581 out of 830 samples) was allocated for training, while the remaining 30% (249 out of 830 samples) was reserved for testing. This split ensures that the training and test sets are independent, which is crucial for obtaining unbiased performance metrics.\n\nTo enforce the independence of the training and test sets, the data was randomly split. This random splitting process was repeated multiple times to validate the model's performance consistently. For instance, five different random splits were used to evaluate the model, and the average sensitivity and specificity were calculated to ensure robustness.\n\nThe distribution of the dataset, particularly the imbalance between positive and negative samples, was addressed using the synthetic minority oversampling technique (SMOTE). The original training dataset had 93 positive samples and 488 negative samples. After applying SMOTE, 395 synthetic positive samples were added to balance the training set, making the number of positive samples equal to that of the negative samples. This approach helps in mitigating the bias towards the majority class and improves the model's ability to identify high-risk individuals accurately.\n\nThe decision tree model was then trained on the balanced training set and evaluated on the independent test set. The model's performance was assessed using metrics such as sensitivity and specificity, which reflect the model's ability to correctly identify individuals at high risk of eating disorders and those not at high risk, respectively. The results showed that the model performed well in both identifying high-risk individuals (sensitivity of 0.88) and excluding those not at high risk (specificity of 0.85).\n\nIn summary, the dataset was split into independent training and testing subsets, with the training set balanced using SMOTE to address the class imbalance. This approach ensures that the model's performance is evaluated on unseen data, providing a reliable assessment of its generalizability.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in this study is a decision tree. This algorithm is not new; it is a well-established method in the field of machine learning.\n\nDecision trees are widely used for classification tasks due to their ability to handle both numerical and categorical data, as well as their interpretability. The decision tree algorithm operates by recursively partitioning the data into subsets based on the values of input features, aiming to create branches that lead to nodes with homogeneous data.\n\nThe decision tree algorithm was implemented using the sklearn package in Python, which is a popular library for machine learning and provides a robust implementation of decision trees. This package was chosen for its efficiency and the extensive documentation and community support available.\n\nThe decision tree algorithm was selected for this study because it can effectively handle interactions between variables and provide a clear, hierarchical structure of the most important risk factors for eating disorders. This makes it particularly suitable for exploring the complex relationships between various psychological and behavioral factors associated with eating disorders.\n\nThe decision tree algorithm was not published in a machine-learning journal because the focus of this study is on applying machine learning to understand eating disorders, rather than on developing new machine-learning algorithms. The decision tree algorithm is a well-known and widely used method, and the innovation in this study lies in its application to a specific psychological and behavioral context.",
  "optimization/meta": "The model described in the publication does not use data from other machine-learning algorithms as input. It is not a meta-predictor. Instead, it is a decision tree model that operates independently. The decision tree algorithm works by partitioning the dataset based on the best attribute selected using criteria like Gini or Entropy. This process is repeated recursively until no further splitting improves the model\u2019s predictive accuracy. The model was trained using a subset of the data, with the remaining data used for testing to evaluate its performance.\n\nThe training data was balanced using the synthetic minority oversampling technique (SMOTE) to handle imbalanced data. This technique creates synthetic data for the minority class to ensure that the training set is balanced. The decision tree was then pruned to avoid overfitting, and the maximum number of leaf nodes was restricted to improve predictive accuracy.\n\nThe evaluation of the model involved using a test subset of the data, as well as random sampling methods and different test sets generated by changing the random seed. These methods ensured that the model's performance was stable and reliable. The sensitivity and specificity of the model were calculated to assess its ability to correctly identify individuals at high risk of eating disorders and to exclude those not at high risk.\n\nIn summary, the model is a standalone decision tree that does not rely on other machine-learning algorithms for input. The training data was independently prepared and balanced using SMOTE, and the model's performance was thoroughly evaluated using various methods to ensure its reliability.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for preparing the dataset for the machine-learning algorithm. Initially, missing values were addressed using an iterative imputation method. This involved replacing missing values with predictions from regression, performed iteratively for each feature. This approach ensured that the dataset was complete and ready for further analysis.\n\nThe dataset was imbalanced, with a smaller proportion of positive cases (16.02%) compared to negative ones (83.98%). To handle this imbalance, the synthetic minority oversampling technique (SMOTE) was employed. SMOTE creates synthetic data for the minority class by finding k-nearest neighbors from random data in the minority class and then synthesizing new data between the randomly picked data and its k-nearest neighbors. This technique helped to balance the training set, enhancing the model's performance in classification tasks.\n\nThe dataset was split into training and testing subsets, with 70% of the data used for training and 30% for testing. The training set was then balanced using SMOTE prior to model training. This preprocessing step was essential for ensuring that the model could effectively identify individuals at high risk of eating disorders.\n\nThe decision tree algorithm was used for classification, and it operates by partitioning the data according to the best attribute, selected using criteria such as Gini or Entropy. The algorithm recursively splits the data until no further splitting can improve the model's predictive accuracy. Pruning was applied to avoid overfitting, and the maximum number of leaf nodes allowed in the tree was restricted.\n\nIn summary, the data encoding and preprocessing involved handling missing values through iterative imputation, balancing the dataset using SMOTE, and splitting the data into training and testing subsets. These steps were essential for preparing the data for the decision tree classification algorithm and ensuring robust model performance.",
  "optimization/parameters": "In the optimization process of our model, we initially considered seven attributes. However, the final model selected only three of these attributes for classification. These selected attributes were body image inflexibility, psychological distress, and body dissatisfaction. The selection of these attributes was based on their importance in identifying individuals at high risk of eating disorders. The feature importance scores for these attributes were 0.81 for body image inflexibility, 0.15 for psychological distress, and 0.04 for body dissatisfaction, indicating that body image inflexibility was the most significant factor. The model's performance was evaluated using sensitivity and specificity, which showed that it effectively identified individuals at high risk of eating disorders. The decision to use these three attributes was driven by their ability to provide a clear and hierarchical combination of variables, optimizing the screening process without introducing researcher bias.",
  "optimization/features": "In the optimization process of our model, we initially considered seven attributes as potential input features. To enhance the model's performance and simplicity, we performed feature selection. This process was conducted using only the training set to ensure that the selection was unbiased and to prevent data leakage.\n\nThrough this feature selection process, the model ultimately chose three key attributes. These selected features were found to be the most relevant for identifying individuals at high risk of developing eating disorders. The use of a reduced set of features not only improved the model's efficiency but also made it more interpretable.",
  "optimization/fitting": "The fitting method employed in this study utilized a decision tree algorithm, which is inherently less prone to overfitting compared to more complex models due to its simplicity and interpretability. The decision tree was constructed using the sklearn package in Python, which includes built-in mechanisms to prevent overfitting.\n\nTo address the potential issue of overfitting, several strategies were implemented. Firstly, the decision tree was pruned, which involves removing branches that provide little power in classifying instances. This process helps to simplify the model and reduce its complexity, thereby minimizing the risk of overfitting. Additionally, the maximum number of leaf nodes allowed in the tree was restricted, further controlling the model's complexity.\n\nThe dataset used for training consisted of 581 samples, which included both original and synthetic training samples generated using the Synthetic Minority Over-sampling Technique (SMOTE). This technique helps to balance the dataset by creating synthetic data for the minority class, ensuring that the model is not biased towards the majority class. The use of SMOTE also aids in improving the model's performance by providing a more representative training set.\n\nTo further validate the model's performance and ensure it generalizes well to unseen data, a random sampling method was adopted. By randomly selecting 30% of the overall dataset five different times, the average sensitivity and specificity were calculated. Additionally, 50 different test sets were generated by changing the random seed used to split the training and test sets. The mean sensitivity and specificity across these test sets were found to be consistent, demonstrating the stability and robustness of the model.\n\nThe decision tree algorithm operates by recursively partitioning the data based on the best attribute, selected using criteria such as Gini impurity or entropy. This process continues until no further splitting can improve the model's predictive accuracy. The resulting tree is then pruned to avoid overfitting, ensuring that the model generalizes well to new data.\n\nIn summary, the fitting method employed in this study effectively addressed the potential issues of overfitting and underfitting. The use of decision tree pruning, restriction of leaf nodes, and the generation of synthetic samples through SMOTE ensured that the model was neither too complex nor too simple, striking a balance that allowed for accurate and reliable predictions.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our decision tree model. One of the primary methods used was pruning. Pruning involves removing branches of the tree that provide little power in classifying instances. By restricting the maximum number of leaf nodes allowed in the tree, we aimed to simplify the model and reduce the risk of overfitting to the training data. This process helps in creating a more generalized model that performs well on unseen data.\n\nAdditionally, we utilized a synthetic minority oversampling technique (SMOTE) to balance the training dataset. SMOTE creates synthetic data for the minority class by finding k-nearest neighbors from random data in the minority class and then synthesizing new data between the randomly picked data and its k-nearest neighbors. This technique helps in mitigating the class imbalance issue, which can otherwise lead to a model that is biased towards the majority class and prone to overfitting.\n\nFurthermore, we conducted multiple evaluations by generating 50 different test sets using varying random seeds to split the training and test sets. This approach allowed us to assess the stability and generalizability of our model across different data splits. The mean sensitivity and specificity across these 50 test sets were calculated, demonstrating the sufficiency of our samples for yielding a stable model.\n\nOverall, these regularization techniques\u2014pruning, SMOTE, and multiple evaluations\u2014were integral to our optimization process, ensuring that our decision tree model was robust and less likely to overfit the training data.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are not explicitly detailed in the provided information. However, the decision tree model was constructed using the sklearn package in Python, which is a widely used machine learning library. The specific parameters and configurations for the decision tree, such as the maximum number of leaf nodes and the criteria for splitting (Gini or Entropy), were set to control the complexity and depth of the tree. These details are crucial for reproducibility but are not fully elaborated in the provided context.\n\nThe optimization schedule, including the process of splitting the data into training and testing sets, as well as the use of SMOTE for handling imbalanced data, is described. The training set was balanced using SMOTE prior to model training, and the model was evaluated using sensitivity and specificity metrics. However, the exact parameters used in SMOTE and other preprocessing steps are not specified.\n\nModel files and optimization parameters are not directly mentioned or made available in the provided context. Typically, such files would be shared through repositories like GitHub or included as supplementary materials in the publication. The license under which these materials would be shared is also not specified. For full reproducibility, it is standard practice to provide access to the code, data, and any pre-trained models used in the study. This would allow other researchers to replicate the results and build upon the work.\n\nIn summary, while the general approach and some details of the optimization process are described, specific hyper-parameter configurations, optimization parameters, and model files are not explicitly reported or made available. This information is essential for complete reproducibility and further research.",
  "model/interpretability": "The model employed in this study is a decision tree, which is inherently interpretable and not a black box. Decision trees operate by recursively partitioning the data based on the most informative features, creating a tree-like structure of decisions. Each internal node represents a decision based on a feature, and each leaf node represents an outcome or class label.\n\nFor instance, the decision tree used in this study first partitions participants based on their body image inflexibility scores. Those with higher scores are further evaluated based on their psychological distress scores, and so on. This sequential and hierarchical combination of variables allows for a clear understanding of how the model arrives at its predictions.\n\nThe decision tree's structure makes it easy to trace the path from the root to a specific leaf node, which returns the predicted class for a sample. This transparency is beneficial for practitioners and researchers, as it provides insights into the key factors contributing to the risk of eating disorders. For example, the model highlights that individuals with higher body image inflexibility, psychological distress, and body dissatisfaction scores are more likely to be categorized at high risk of eating disorders.\n\nMoreover, the decision tree's feature importance scores further enhance its interpretability. In this study, body image inflexibility was found to be the most important classifier, followed by psychological distress and body dissatisfaction. This information can guide interventions and prevention programs by prioritizing these risk factors.\n\nIn summary, the decision tree model used in this study is transparent and interpretable, providing clear insights into the decision-making process and the key factors contributing to the risk of eating disorders.",
  "model/output": "The model developed in this study is a classification model. It is designed to identify young women who may be at high risk of developing an eating disorder (ED). The model uses a decision tree algorithm to classify individuals based on specific attributes related to body image inflexibility, psychological distress, and body dissatisfaction. The output of the model is a binary classification indicating whether an individual is at high risk or low risk of EDs. The performance of the model is evaluated using metrics such as sensitivity and specificity, which measure the model's ability to correctly identify individuals at high risk and those not at high risk, respectively. The decision tree structure visually represents the classification rules derived from the training data, showing how different attributes interact to determine the risk level.",
  "model/duration": "Not enough information is available.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation method employed for the decision tree model involved several rigorous steps to ensure its robustness and generalizability. Initially, the model was evaluated on a test subset of the data, comprising 249 out of 830 samples. The model demonstrated a sensitivity of 0.88 and a specificity of 0.85, indicating its effectiveness in identifying individuals at high risk of eating disorders (EDs) and excluding those not at high risk.\n\nTo further validate these results across the entire dataset, a random sampling method was adopted. This involved randomly selecting 30% of the overall dataset five different times. The average sensitivity and specificity from these samples were 0.85 and 0.86, respectively, which aligned well with the evaluation of the test subsample.\n\nAdditionally, the model's complexity was assessed by initially considering seven attributes and ultimately selecting three. The minimum number of samples contained in a single node was 36, which constituted 3.7% of the 976 training samples. These training samples included 395 synthetic samples generated using the synthetic minority oversampling technique (SMOTE) and 581 original samples.\n\nTo ensure the stability and reliability of the model, 50 different test sets were generated by changing the random seed used to split the training and test sets. The mean sensitivity across these 50 test sets was 0.84 with a standard deviation of 0.05, and the mean specificity was 0.86 with a standard deviation of 0.02. These results demonstrated the sufficiency of the samples for yielding a stable model.",
  "evaluation/measure": "In our study, we focused on two primary performance metrics to evaluate the effectiveness of our decision tree model in identifying individuals at high risk of eating disorders (EDs): sensitivity and specificity.\n\nSensitivity, also known as the true positive rate, measures the proportion of actual positive cases (individuals at high risk of EDs) that are correctly identified by the model. A high sensitivity indicates that the model is effective in correctly including individuals who are at high risk. In our evaluation, the model demonstrated a sensitivity of 0.88 on the test subset, meaning it correctly identified 88% of the individuals at high risk of EDs. This metric was further validated through random sampling and multiple test sets, showing an average sensitivity of 0.85 and a mean sensitivity of 0.84 across 50 different test sets.\n\nSpecificity, or the true negative rate, assesses the proportion of actual negative cases (individuals not at high risk of EDs) that are correctly excluded by the model. A high specificity ensures that the model accurately classifies those who are not at high risk. Our model achieved a specificity of 0.85 on the test subset, correctly identifying 85% of the individuals not at high risk of EDs. This was consistent with the average specificity of 0.86 observed through random sampling and the mean specificity of 0.86 across 50 test sets.\n\nThese metrics are widely used in the literature for evaluating classification models, particularly in medical and psychological research where the balance between identifying true positives and true negatives is crucial. The reported sensitivity and specificity values indicate that our model performs well in both correctly identifying individuals at high risk of EDs and excluding those who are not at high risk. This set of metrics is representative and aligns with standard practices in the field, ensuring a comprehensive evaluation of the model's performance.",
  "evaluation/comparison": "Not applicable. The publication does not provide information about comparisons to publicly available methods or simpler baselines. The focus is on the development and evaluation of a decision tree model for identifying individuals at high risk of eating disorders. The evaluation includes metrics such as sensitivity and specificity, and the use of techniques like SMOTE for handling imbalanced data. However, there is no mention of benchmarking against other methods or baselines.",
  "evaluation/confidence": "The evaluation of the model's performance was conducted using sensitivity and specificity metrics. Sensitivity, which reflects the probability that the model will correctly identify individuals at high risk of eating disorders, was found to be 0.88 in the test subset of data. Specificity, which indicates the probability that the model will correctly exclude those not at high risk, was 0.85. These metrics were further validated through random sampling and multiple test sets, showing consistent results.\n\nTo ensure the robustness of the evaluation, the model was tested across 50 different test sets generated by changing the random seed used to split the training and test sets. The mean sensitivity across these test sets was 0.84 with a standard deviation of 0.05, and the mean specificity was 0.86 with a standard deviation of 0.02. These results demonstrate the stability and reliability of the model's performance.\n\nAdditionally, the model's performance was evaluated using a decision tree classification approach, which is known for its interpretability and effectiveness in handling imbalanced datasets. The decision tree was constructed using three selected attributes out of an initial set of seven, ensuring a balanced and efficient model.\n\nThe evaluation also included the use of synthetic minority oversampling technique (SMOTE) to address the imbalanced nature of the dataset. This technique helped in enhancing the model's performance by creating synthetic data for the minority class, thereby improving the classification accuracy for high-risk individuals.\n\nOverall, the evaluation process was rigorous and comprehensive, providing confidence in the model's ability to accurately identify individuals at high risk of eating disorders. The consistent performance across multiple test sets and the use of robust statistical methods further support the reliability of the results.",
  "evaluation/availability": "Not enough information is available."
}