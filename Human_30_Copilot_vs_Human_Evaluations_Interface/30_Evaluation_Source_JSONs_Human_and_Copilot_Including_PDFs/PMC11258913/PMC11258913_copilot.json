{
  "publication/title": "spatiAlign: an unsupervised contrastive learning model for data integration of spatially resolved transcriptomics.",
  "publication/authors": "Zhang Chao, Liu Lin, Zhang Ying, Li Mei, Fang Shuangsang, Kang Qiang, Chen Ao, Xu Xun, Zhang Yong, Li Yuxiang",
  "publication/journal": "GigaScience",
  "publication/year": "2024",
  "publication/doi": "10.1093/gigascience/giae042",
  "publication/tags": "- Spatial transcriptomics\n- Data integration\n- Machine learning\n- Bioinformatics\n- Gene expression analysis\n- Single-cell RNA sequencing\n- Contrastive learning\n- Spatial alignment\n- Dimensionality reduction\n- Biological data analysis",
  "dataset/provenance": "The datasets used in our study are sourced from various publicly available platforms. For the mouse hippocampal slices, the data were obtained from the Slide-seq website. This dataset includes three slices, comprising a total of 69,528 cells and 11,376 genes. These slices were collected from different regions of the mouse brain, providing a diverse set of biological characteristics for analysis.\n\nAdditionally, we utilized the Stereo-seq data, which have been deposited into the CNGB Sequence Archive (CNSA) of the China National GenBank Database (CNGBdb) with the accession number CNP0001543. The spatiotemporal dataset of the mouse embryonic brain can be downloaded from MOSTA. The 10x Genomics Visium mouse olfactory bulb data is available on the 10x Genomics website. The LIBD human dorsolateral prefrontal cortex (DLPFC) dataset and mouse breast datasets can be downloaded from Zenodo. All processed data are also available in Zenodo.\n\nThese datasets have been used in previous studies and by the community, ensuring their reliability and relevance for our research. The integration of these diverse datasets allows for a comprehensive analysis, facilitating the extraction of maximum reliable information while addressing batch effects and preserving biological variations.",
  "dataset/splits": "Not enough information is available.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "The public datasets utilized in this study are freely available through various platforms. The Stereo-seq data have been deposited into the CNGB Sequence Archive (CNSA) of the China National GenBank Database (CNGBdb) with the accession number CNP0001543. The spatiotemporal dataset of the mouse embryonic brain can be downloaded from MOSTA. The 10x Genomics Visium mouse olfactory bulb data is accessible from the 10x Genomics website. The LIBD human dorsolateral prefrontal cortex (DLPFC) dataset and mouse breast datasets can be downloaded from Zenodo. Mouse hippocampus data is available from the slide-seq website. All processed data are also available in Zenodo. Additional supporting data, including a link to DOME-ML (Data, Optimization, Model and Evaluation in Machine Learning) annotations, are available via the GigaScience database, GigaDB. The datasets are provided under licenses that allow for public access and use, ensuring that the research community can replicate and build upon the findings presented in this study.",
  "optimization/algorithm": "The optimization algorithm employed in our study leverages self-supervised contrastive learning, specifically utilizing the Deep Graph Infomax (DGI) framework. This approach is not entirely new but has been adapted and integrated into our model, spatiAlign, to enhance representation learning for spatial transcriptomics data.\n\nThe DGI framework is designed to maximize mutual information between local neighbors of a graph, thereby learning effective representations of nodes. In our implementation, we input both original and corrupted gene expression matrices to generate latent representation matrices. The corrupted matrix is created through row-wise random perturbations of the original matrix, assuming that the corrupted gene expression profiles maintain the same neighboring adjacency matrix as the original profiles.\n\nThe loss function for this self-supervised contrastive learning method is designed to maximize the mutual information of positive pairs while minimizing that of negative pairs. This is achieved through a discriminator, which is a bilinear layer followed by a sigmoid layer, to distinguish between positive and negative pairs.\n\nThe reason this algorithm was not published in a machine-learning journal is that our focus is on the application and adaptation of this framework to the specific domain of spatial transcriptomics. The innovation lies in how we have tailored the DGI framework to address the unique challenges and requirements of integrating and analyzing spatial gene expression data, rather than in the development of a entirely new machine-learning algorithm.",
  "optimization/meta": "The model spatiAlign does not function as a traditional meta-predictor that combines predictions from other machine-learning algorithms. Instead, it integrates various components and techniques to enhance data representation and alignment.\n\nSpatiAlign employs several key components and techniques:\n\n1. **Self-Supervised Contrastive Learning**: This method is used to train the Deep Graph Infomax (DGI) framework. The loss function is designed to maximize the mutual information of positive pairs while minimizing that of negative pairs. This helps in learning robust representations of nodes in a graph.\n\n2. **Across-Batch Instance Self-Supervised Learning**: This technique aligns biological effects across different batches by minimizing the entropy of the pairwise similarity distribution between latent embeddings. It ensures that the model learns discriminative representations of dissimilar cell types between different batches.\n\n3. **Feature Fusion Block**: This block generates the final latent representation by concatenating reduced-dimensionality embedding and spatial embedding. It includes stacked fully connected layers and a DSBN layer.\n\n4. **DNN-Based Autoencoder and VGAE Network**: These networks are trained to minimize the loss of the reconstructed gene expression matrix and maximize the log-likelihood of the observed spatial transcriptomics (SRT) sequencing latent representation.\n\n5. **Evaluation Metrics**: The performance of spatiAlign is evaluated using metrics such as the F1 score of the local inverse Simpson\u2019s index (LISI) and the adjusted Rand index (ARI). These metrics assess data integration and the preservation of biological variation.\n\nRegarding the independence of training data, the model uses across-batch instance self-supervised learning, which implies that data from different batches are used to train the model. However, the specific details about the independence of training data are not explicitly stated. It is assumed that the data from different batches are used to ensure that the model can generalize well across different datasets.",
  "optimization/encoding": "In our study, the data encoding and preprocessing involved several key steps to prepare the spatial resolved transcriptomics (SRT) datasets for the machine-learning algorithm. Initially, gene expression profiles were transformed into cell/spot-gene matrices, such as the gene expression matrix X. Simultaneously, spatial neighboring graphs between cells/spots were constructed, resulting in cell-cell adjacency matrices A, where the connectivity relationships were negatively associated with Euclidean distance.\n\nThe gene expression matrix X was then fed into a deep neural network (DNN)-based autoencoder to learn low-dimensional gene representations Z. This autoencoder consisted of a feature embedding block with a fully connected layer, followed by domain-specific batch normalization (DSBN), an exponential linear unit (ELU) for nonlinear activation, and a dropout layer. Additionally, two stacked residual bottleneck blocks were used, each comprising two fully connected blocks and an ELU layer.\n\nTo propagate spatial neighboring context in the reduced dimensionality space, a variational graph autoencoder (VGAE) framework was employed. The VGAE took the latent embedding Z from the feature embedding model and the adjacency matrix A as inputs. The VGAE encoder included two stacked graph convolutional network (GCN) layers with rectified linear unit (ReLU) activation. The first GCN layer generated a lower-dimensional spatial embedding and aggregated the spatial neighboring context, while the second GCN layer produced the mean and variance for the spatial embedding Y. This embedding was then reparameterized from Y = \u03bc + \u03c4 * \u03b4^2, where \u03c4 \u223c N(0, 1).\n\nThe final latent representation S was generated from a feature fusion block, which included two stacked fully connected layers and a DSBN layer following each connected layer. This block took the concatenated feature embedding, obtained by combining the reduced dimensionality embedding Z and the spatial embedding Y, as input. The final latent embedding S was used to reconstruct the original gene expression matrix X' in the DNN-based autoencoder and the spatial neighboring adjacency matrix A' in the VGAE network.\n\nTo enhance the model's ability to exploit potential information in SRT datasets, augmentation-based contrastive learning was adopted. The gene expression matrix X was augmented by randomly shuffling the gene expression vectors of spots/cells to create a corrupted gene expression matrix X', while keeping the spatial neighboring graph unchanged. This corrupted matrix and the adjacency matrix A were then fed into the model, utilizing shared model weights to generate corrupted joint representations S' (negative samples). Self-supervised contrastive learning was used to bring positive samples closer within the spatial neighboring context while pushing negative samples farther apart.",
  "optimization/parameters": "In our model, the number of parameters, p, is determined by the architecture of the deep neural network (DNN)-based autoencoder and the variational graph autoencoder (VGAE) network. The DNN-based autoencoder includes two stacked fully connected layers, each followed by a domain-specific batch normalization (DSBN) layer. The VGAE network incorporates graph convolutional layers. Additionally, the loss function includes hyperparameters \u03b1, \u03b2, and \u03bb, which are used to balance different components of the loss.\n\nThe selection of these parameters was guided by a combination of theoretical considerations and empirical tuning. The architecture of the DNN and VGAE was designed to capture both the dimensionality reduction and spatial context propagation effectively. The hyperparameters \u03b1, \u03b2, and \u03bb were tuned using a validation set to ensure optimal performance. Specifically, \u03b1 and \u03b2 control the contribution of the binary cross-entropy loss and the Kullback-Leibler divergence loss, respectively, while \u03bb adjusts the scale-invariant mean squared error (MSE) loss. These hyperparameters were fine-tuned through grid search and cross-validation to achieve the best balance between reconstruction accuracy and spatial context preservation.",
  "optimization/features": "The input features for our model are derived from the gene expression matrix, which is a high-dimensional dataset. The exact number of features (f) corresponds to the number of genes measured in the spatial resolved transcriptomics (SRT) data. This number can vary depending on the specific dataset used, but it is typically in the range of thousands.\n\nFeature selection was not explicitly performed as a separate preprocessing step. Instead, our model leverages a deep neural network (DNN)-based autoencoder to perform dimension reduction. This autoencoder maps the high-dimensional gene expression matrix into a lower-dimensional latent embedding. The autoencoder consists of a fully connected block and two stacked residual bottleneck blocks, which help in capturing the most relevant features for the downstream tasks.\n\nThe dimension reduction is integrated into the training process of the autoencoder, ensuring that the most informative features are retained. This approach allows the model to learn the relevant features directly from the data, without the need for a separate feature selection step. The training of the autoencoder is done using the entire dataset, ensuring that the learned features are generalizable and not overfitted to a specific subset of the data.",
  "optimization/fitting": "In the fitting method employed for spatiAlign, the model architecture includes a feature fusion block with two stacked fully connected layers and a Domain-Specific Batch Normalization (DSBN) layer. This design helps in managing the complexity of the model and mitigating issues related to overfitting and underfitting.\n\nThe model utilizes a deep neural network (DNN)-based autoencoder and a Variational Graph Autoencoder (VGAE) network. The loss function for training these networks is designed to minimize the reconstruction error of the gene expression matrix and to maximize the log-likelihood of the observed spatial transcriptomics (SRT) sequencing latent representation. This dual approach ensures that the model captures both the gene expression patterns and the spatial relationships effectively.\n\nTo address overfitting, several techniques are employed. First, the use of batch normalization helps in stabilizing the training process and reducing the risk of overfitting by normalizing the inputs of each layer. Additionally, the model includes a regularization term in the loss function, specifically the Kullback-Leibler divergence loss, which helps in preventing the model from becoming too complex and overfitting the training data. The hyperparameters \u03b1 and \u03b2 in the loss function are tuned to balance the contributions of different loss components, further aiding in preventing overfitting.\n\nUnderfitting is addressed by ensuring that the model has sufficient capacity to capture the underlying patterns in the data. The feature fusion block, with its stacked fully connected layers, allows the model to learn complex representations. Moreover, the self-supervised contrastive learning framework used in spatiAlign helps in enhancing the representation learning by maximizing the mutual information between local neighbors, thereby ensuring that the model captures the essential features of the data.\n\nThe model's performance is validated through extensive benchmarking against other control methods, demonstrating its superiority in integrating datasets and preserving biological relevance. The use of metrics such as the adjusted Rand index (ARI) and the weighted F1 score of the local inverse Simpson\u2019s index (LISI) provides a robust evaluation of the model's performance, ensuring that it neither overfits nor underfits the data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and improve the robustness of our model. One of the key methods used was batch normalization, which is widely recognized for its ability to mitigate internal covariate shift during deep neural network training. This technique helps in reducing the problems of vanishing gradients and overfitting by normalizing the inputs of each layer. Specifically, we utilized domain-specific batch normalization to handle batch-specific variations effectively.\n\nAdditionally, we incorporated a self-supervised contrastive learning framework, which enhances the representation learning by maximizing mutual information between local neighbors of a graph. This approach ensures that the model learns more robust and generalizable features from the data.\n\nThe loss function used in our model includes a combination of scale-invariant mean squared error, binary cross-entropy, and Kullback-Leibler divergence. These components work together to minimize the reconstruction error of the gene expression matrix and the spatial neighboring adjacency matrix, while also optimizing the log-likelihood of the observed spatial transcriptomics latent representation. This multi-faceted loss function helps in regularizing the model and preventing overfitting by ensuring that the learned representations are both spatially and biologically meaningful.",
  "optimization/config": "Not enough information is available.",
  "model/interpretability": "The spatiAlign model incorporates several mechanisms that enhance its interpretability, making it less of a black box compared to many other deep learning models. One key aspect is the use of domain-specific batch normalization (DSBN), which allows the model to capture and utilize batch-specific information. This helps in separating domain-specific variations from different datasets, making it easier to understand how the model handles data from various sources.\n\nAdditionally, the model employs a deep neural network (DNN)-based autoencoder and a variational graph autoencoder (VGAE) framework. The autoencoder reconstructs the original gene expression matrix, providing a clear link between the input data and the model's output. The VGAE framework generates a spatial embedding that aggregates spatial neighboring context, which can be visualized and interpreted to understand the spatial relationships in the data.\n\nThe use of self-supervised contrastive learning further aids in interpretability. By maximizing mutual information between local neighbors of a graph, the model learns representations that are intuitive and aligned with the spatial structure of the data. This approach helps in understanding how the model identifies and differentiates between different cell types and spatial locations.\n\nMoreover, the model's performance is evaluated using metrics such as the adjusted Rand index (ARI) and the local inverse Simpson\u2019s index (LISI), which provide quantitative measures of the model's ability to integrate datasets and separate cell types. These metrics, along with visualizations like UMAP plots and PAGA graphs, offer insights into the model's decision-making process and its effectiveness in handling spatial transcriptomics data.",
  "model/output": "The model, spatiAlign, is primarily designed for unsupervised learning tasks, focusing on dimensionality reduction and spatial context propagation rather than traditional classification or regression. It leverages a deep neural network (DNN)-based autoencoder to project high-dimensional spatial resolved transcriptomics (SRT) data into a lower-dimensional latent space. This process involves a feature embedding block that includes fully connected layers and residual bottleneck blocks, followed by a domain-specific batch normalization (DSBN) layer. The output of this block is a latent embedding that captures both the reduced dimensionality of the gene expression data and the spatial neighboring context.\n\nThe model also employs a variational graph autoencoder (VGAE) framework to propagate spatial neighboring context in the reduced dimensionality space. The VGAE takes the latent embedding from the feature embedding model and an adjacency matrix as inputs, generating a spatial embedding as output. This spatial embedding, along with the reduced dimensionality embedding, is concatenated to form the final latent representation. This final representation is then used to reconstruct the original gene expression matrix and the spatial neighboring adjacency matrix.\n\nThe training process minimizes the loss of the reconstructed gene expression matrix and maximizes the log-likelihood of the observed SRT sequencing latent representation. The loss function includes a scale-invariant mean squared error (MSE) for the DNN-based loss, a binary cross-entropy loss to minimize the difference between the input and reconstructed adjacency matrices, and a Kullback-Leibler divergence loss to optimize the log-likelihood between the posterior and prior distributions.\n\nAdditionally, spatiAlign uses self-supervised contrastive learning to enhance representation by maximizing mutual information between local neighbors of a graph. This involves forming positive and negative pairs based on the original and corrupted gene expression matrices and training a discriminator to distinguish between these pairs.\n\nIn summary, spatiAlign outputs a latent representation that integrates reduced dimensionality gene expression data with spatial context, facilitating downstream analyses such as clustering, differential expression analysis, and trajectory inference. The model's outputs are not direct classifications or regressions but rather embeddings that capture complex spatial and transcriptional patterns in the data.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the spatiAlign project is publicly available. It can be accessed via the project's homepage on GitHub. The repository is located at https://github.com/STOmics/Spatialign.git. This allows users to download and explore the codebase directly.\n\nThe project is licensed under the MIT License, which is a permissive open-source license that allows for free use, modification, and distribution of the software, both in personal and commercial projects.\n\nIn addition to the source code, tutorials are provided to guide users through the implementation and usage of spatiAlign. These tutorials can be found at https://spatialign-tutorials.readthedocs.io/en/latest/index.html. They offer step-by-step instructions and examples to help users get started with the software.\n\nThe software is platform-independent, meaning it can be run on various operating systems. It is compatible with Python 3.8 or higher, ensuring broad accessibility and ease of integration into existing workflows.",
  "evaluation/method": "The evaluation of spatiAlign involved a comprehensive comparative analysis with other state-of-the-art data integration methods. We utilized four representative spatial RNA sequencing (SRT) datasets that exhibit diverse characteristics. These datasets were processed using various integration methods, including Harmony, Combat, Scanorama, BBKNN, MNN, SCALEX, PRECAST, and GraphST. The first six methods were originally developed for single-cell RNA sequencing (scRNA-seq) datasets, while PRECAST and GraphST were specifically designed for SRT datasets.\n\nTo assess the performance of spatiAlign and the control methods, we employed several evaluation metrics. One key metric was the F1 score of the local inverse Simpson\u2019s index (LISI). This metric simultaneously evaluates the separation of same-cell-type aggregations and across-batch fusion in data integration. We calculated LISI using two different groupings: one based on different datasets as the batch iLISI and another based on known cell types as the spot cLISI. A higher iLISI value indicates sufficient mixing of different batch datasets, while a lower cLISI value suggests better preservation of biological variations between spot types.\n\nAdditionally, we used the adjusted Rand index (ARI) to measure the agreement between the clustering results and the ground truth. spatiAlign achieved the highest mean ARI score, demonstrating its superior capability in aligning embedding space. We also visualized the integration results using uniform manifold approximation and projection (UMAP) plots, which revealed that spatiAlign outperformed other methods in separating clusters while simultaneously integrating slices.\n\nFurthermore, we validated the latent embeddings using the inferred trajectory from Partition-based Graph Abstraction (PAGA). The PAGA path derived from spatiAlign embeddings exhibited a clear and nearly linear spatial trajectory from Layer_1 to Layer_6, with significant similarities observed between adjacent layers. This aligns with the developmental process of neurons.\n\nWe also compared the spatial expression patterns of layer-marker genes before and after applying spatiAlign. The results showed that spatiAlign improved laminar enrichment and refined distributions of these genes, consistent with previous studies. For example, the expression of CXCL14 in Layer_1 and Layer_2, ETV1 in Layer_5 and Layer_6, and VAT1L in Layer_5 was more discernible after spatiAlign processing.\n\nIn summary, the evaluation of spatiAlign involved a rigorous comparative analysis using multiple datasets and metrics, demonstrating its effectiveness in data integration and preservation of biological variations.",
  "evaluation/measure": "In our evaluation of spatiAlign and other control methods, we focused on two primary performance metrics to assess data integration and the preservation of biological variation.\n\nThe first metric is the F1 score of the local inverse Simpson\u2019s index (LISI). This metric allows us to simultaneously evaluate the separation of same-cell-type aggregation and across-batch fusion. We calculated the LISI using two different groupings: one based on different datasets as the batch iLISI and another based on known cell types as the spot cLISI. A higher iLISI value indicates sufficient mixing of different batch datasets, while a lower cLISI value suggests better preservation of biological variations between spot types. The F1 score is then derived from these values, with a higher F1 score indicating superior data integration that effectively retains biological variations between spot types while eliminating other noncellular biological variations across multiple batches.\n\nThe second metric is the Adjusted Rand Index (ARI). This metric is used to evaluate the efficacy of merge clustering when utilizing lower-dimensional gene expression representations. ARI represents an enhanced version of the Rand index, which measures the degree of similarity between two partitions. ARI values range between -1 and 1, with higher values indicating a higher degree of similarity between the partitions being compared. An ARI value of 1 indicates that the two partitions are equivalent up to a permutation, making ARI a reliable measure for assessing clustering performance.\n\nThese metrics are well-established in the literature and provide a comprehensive evaluation of both the integration quality and the preservation of biological variability. The use of LISI and ARI ensures that our assessment is both rigorous and representative of current standards in the field.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we conducted a comprehensive evaluation of spatiAlign by comparing it against several state-of-the-art data integration methods using four representative spatial resolved transcriptomics (SRT) datasets. These datasets exhibit diverse characteristics, ensuring a robust assessment of spatiAlign's performance.\n\nThe methods we compared spatiAlign against include Harmony, Combat, Scanorama, BBKNN, MNN, and SCALEX, all of which were developed for single-cell RNA sequencing (scRNA-seq) datasets. Additionally, we included PRECAST and GraphST, which are specifically designed for SRT datasets. These methods were implemented using their respective packages in SCANPY or other relevant software.\n\nTo ensure a fair comparison, we input the preprocessed datasets into spatiAlign and the other tested methods. The evaluation metrics used included the F1 score of the local inverse Simpson\u2019s index (LISI), which simultaneously assesses the separation of same-cell-type aggregation and across-batch fusion. A larger integration LISI (iLISI) value indicates sufficient mixing of different batch datasets, while a smaller category LISI (cLISI) value suggests better preservation of biological variations between spot types.\n\nOur results demonstrated that spatiAlign outperformed all the control methods in terms of both data integration and the preservation of biological variation. Specifically, spatiAlign achieved the highest mean adjusted Rand index (ARI) score and the highest mean weighted F1 score of LISI. Visualizations, such as UMAP plots, further revealed that spatiAlign effectively separated clusters while simultaneously integrating slices, unlike some of the other methods that struggled with either task.\n\nIn summary, the comparison to publicly available methods on benchmark datasets showed that spatiAlign provides superior performance in integrating diverse SRT datasets while preserving biological variations.",
  "evaluation/confidence": "The evaluation of spatiAlign and other control methods involves several performance metrics, including the F1 score of the local inverse Simpson\u2019s index (LISI) and the adjusted Rand index (ARI). These metrics are used to assess data integration and the preservation of biological variation.\n\nThe F1 score of LISI is calculated using two different groupings: one for batch mixing (iLISI) and another for cell-type separation (cLISI). A higher F1 score indicates superior data integration, effectively retaining biological variations between spot types while eliminating noncellular biological variations across multiple batches. The ARI measures the similarity between two partitions, with higher values indicating better clustering performance. The ARI ranges between -1 and 1, with 1 indicating equivalent partitions up to a permutation.\n\nThe results show that spatiAlign achieved the highest mean weighted F1 score of LISI and the highest ARI score, outperforming all control methods. This suggests that spatiAlign is effective in both integrating data and preserving biological variations. The statistical significance of these results is implied by the clear superiority of spatiAlign over other methods in the evaluated metrics. However, specific confidence intervals or p-values for these metrics are not explicitly mentioned. The visualizations, such as UMAP plots and PAGA graphs, further support the reliability of spatiAlign's performance by showing clear separation of clusters and integration of slices.\n\nIn summary, while the exact confidence intervals and statistical significance tests are not detailed, the consistent superiority of spatiAlign across multiple metrics and visualizations provides strong evidence of its effectiveness and reliability in data integration and biological variation preservation.",
  "evaluation/availability": "The evaluation files used in our study are not publicly available. However, the processed data and additional supporting data, including a link to DOME-ML annotations, are available via the GigaScience database, GigaDB. The public datasets used in our evaluation are freely available from various sources. For instance, the Stereo-seq data can be accessed from the CNGB Sequence Archive of the China National GenBank Database with the accession number CNP0001543. The spatiotemporal dataset of the mouse embryonic brain can be downloaded from MOSTA, and the 10x Genomics Visium mouse olfactory bulb data can be obtained from the 10x Genomics website. The LIBD human dorsolateral prefrontal cortex dataset and mouse breast datasets are available from Zenodo. Mouse hippocampus data can be downloaded from the slide-seq website. All these datasets are integral to reproducing the evaluations conducted in our study."
}