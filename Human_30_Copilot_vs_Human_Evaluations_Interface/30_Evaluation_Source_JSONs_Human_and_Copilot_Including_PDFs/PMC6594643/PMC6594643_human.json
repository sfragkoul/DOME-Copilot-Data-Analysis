{
  "publication/pmid": "31199787",
  "publication/authors": "Kymberleigh A. Pagel, Danny Antaki, AoJie Lian, Matthew Mort, David N. Cooper, Jonathan Sebat, Lilia M. Iakoucheva, Sean D. Mooney, and Predrag Radivojac",
  "publication/journal": "PLOS Computational Biology",
  "publication/title": "Pathogenicity and functional impact of non-frameshifting insertion/deletion variation in the human genome",
  "publication/doi": "10.1371/journal.pcbi.1007112",
  "publication/year": "2019",
  "publication/tags": [],
  "dataset/availability": "Training data:\n-Positive class, disease causing indel variant data was sourced from the Human Gene Mutation Database (HGMD), professional version 2017. http://www.hgmd.cf.ac.uk\n\n-Negative class, putatively neutral indel variant data was sourced from the Genome Aggregation Database (gnomAD) databases. https://gnomad.broadinstitute.org/\n\nTest data:\n-1. Somatic test set: Catalogue Of Somatic Mutations In Cancer (COSMIC) genome-wide screen data set (v85) & DataBase of Cancer Driver InDels (dbCID). \n\n-2. De novo test set: REACH Project & Simons Simplex Collection.\n\nThe publicly available data of the study derived from the above databases are available at http://mutpred.mutdb.org/ - training data: http://mutpred.mutdb.org/wo_exclusive_hgmd_mp2_training_data.txt\n\nAlso references in the text to other publications regarding some of the data sources. ",
  "dataset/provenance": "Data source: from databases - both pay to access (HGMD professional) and publicly available ones (COSMIC/gnomAD/+). \n\nData type: DNA - genetic variants, grouped as standard insertions and deletions (indels) and complex indels.\nClass positive: disease causing sequence-retaining insertion, deletion, and complex indel variants. Unclear but likely: 1,296.\nClass negative: putatively neutral insertion/deletion variants. Unclear but likely: 2,392.\n\nDetermination of exact number of training and test data points is difficult to ascertain due to poor alignment with numeric figures provided in the text to that of Table 2 which contains this information. The Table 2 itself is also difficult to interpret due to a second set of bracketed numbers beside each initial figure provided. Neither sets of numbers align exactly to the text and no clear key/description provided. \n\nDataset reuse/community recognised: data used is a subset of avilable data from reputable international databases. Large variety of databases leveraged and combined for training and test data.",
  "dataset/redundancy": "How were the sets split?: \nFor the training data:\n-Validation set (25%): A quarter of the training data is used to fine-tune the model during training (resilient propagation method).\n-Cross-validation (10-fold): The training data is divided into 10 folds. The model is trained on 9 folds and tested on the remaining one, repeated 10 times, to assess generalisability (AUC-ROC).\n\nAre the training and test sets independent?: \nYes, indpendent test and training sets used.\n\nHow does the distribution compare to previously published ML datasets?:\nMutPred-Indel is compared to three existing methods: DDIG-in, VEST-Indel, and CADD  but it uses the training data from the current study, not entirely independent datasets. The paper notes a 'paucity' of such data.",
  "dataset/splits": "Training data set comprised of:\n-5606 single residue deletions\n-1033 single residue insertions\n-2427 multi-residue insertions\n-3052 multi-residue deletions\n-1253 complex indel variants\n\nTest data sets: \n2x test data sets were used to test the models classification efficacy.\n1. Somatic mutation test sets: consisting of two sets of putatively damaging cancer causing somatic variants derived from information in COSMIC AND dbCID databases. Text seems to indicate 576 test data points based on the final sentence '(n = 576)' but not clear or explictly stated/documented in text.  \n\n2. De novo mutation test sets: consisting of non-frameshifting insertion/deletion variants curated from families affected by Autism Spectrum Disorder (ASD). Data sourced from REACH Project (2650 families) and the Simons Simplex Collection (SSC). Final test set after filtering is performed is composed of 1217 candidate de novo indels in 827 offspring (506 cases, 321 controls).\n\nSeparate validation set used, and if yes, how large was it?: \nThe model training utilised the resilient propagation method and 25% of training data set aside for the validation.",
  "dataset/done": 4,
  "dataset/skip": 0,
  "optimization/algorithm": "The ML algorithm used in the paper is an ensemble of bagged two-layer feed-forward neural networks.",
  "optimization/config": "No, not clearly available from the text or software website. Regarding parameters reporting, the text does note: 'Each pathogenicity predictor was developed with the Matlab 2016b Neural Network Toolbox as an ensemble of one hundred bagged two-layer feed-forward neural networks, where the following training parameters were not varied between alternative models'.",
  "optimization/encoding": "Preprocessing was undertaken via Two-sample t-test and principal component analysis (PCA). Encoding used and detailed under feature engineering section such as numerical encoding.",
  "optimization/features": "Precise number of input features not explicitly stated in main publication text. The structural and functional features of protein sequences are detailed in Table 3 of the text and fall into 5x categories with approximately 57 noted across these categories. ",
  "optimization/fitting": "Provided that the feature information and inferred parameter infromation (not easy to discern from text), the risk of overfitting is not very likely due to N >> p and the validation set. For underfitting this is mitigated by minimal feature reduction and 10-fold cross-validation employed, but this is dependent on significance of the features and risk grows if the features used are not significant enough. ",
  "optimization/meta": "No",
  "optimization/parameters": "Without the precise feature count the number of parameters cannot be exactly determined. However, if to use the estimated number of features from Table 3 in the text (57 features from total of 5x categories), it could be inferred that with a network architecture of a two-layer feed-forward neural network with 10 hidden units would be 591.",
  "optimization/regularization": "Yes, as the text mentions using a validation set, specifically retaining 25% of the training data being set aside for validation.",
  "optimization/done": 7,
  "optimization/skip": 1,
  "model/availability": "Source code GitHub repository for MutPred2: https://github.com/vpejaver/mutpred2 - MIT License. Primary resource website of the software (http://mutpred.mutdb.org/) offers  live web service for analyses and downloadable executable.",
  "model/duration": "The standalone model executable can be used for genome-scale data sets. To install and run MutPred2, you will need about 50 GB of hard disk space and at least 4 GB RAM. No further information avaialble regarding prediction run times beyond this.",
  "model/interpretability": "Somewhat of a black box from the text alone. In the text there are reasonable descriptions of the model but given the lack of publicly available model & code (eg: in Huggingface/other model hosting/no GitHub) and exact training & test datasets. It is somewhat of a blackbox if attempting to reproduce and interpret the exacts of the model given its complex ML algorithm nature being that of an ensemble of neural networks from the text alone. However, there is a GitHub online that can be found for the model and related datasets so this helps greatly with the model interpretability in conjunction with the text. However, it should be explictly linked for readers. The Matlab related files and info also not available on GitHub due to licensing.",
  "model/output": "Classification - used to predict pathogenicity of indels",
  "model/done": 4,
  "model/skip": 0,
  "evaluation/availability": "No - no link/files /statistical code relating to the raw evaluation beyond text details.",
  "evaluation/comparison": "Yes, the evaluation of MutPred-Indel included comparisons to both simpler baselines and publicly available methods.\n\nSimpler baseline: authors compared MutPred-Indel to MutPred2. They achieved this by simulating deletions and insertions using MutPred2 and showed that MutPred-Indel outperformed MutPred2 in this scenario (AUC of 0.903 vs 0.797)\n\nComparison to publicly available methods: authors also compared MutPred-Indel to other indel prediction methods like VEST-Indel and DDIG. MutPred-Indel achieved the highest AUC (0.897) compared to VEST-Indel (0.875) and DDIG-in (0.869). ",
  "evaluation/confidence": "Confidence intervals are not explicitly mentioned in the text. No clear indication of t-tests/other approaches to determine statistically significant method improvements beyond the direct AUC comparisons.",
  "evaluation/measure": "The area under the receiver operating characteristic (ROC) curve is detailed and plotted in the evalaution section.\n\nThe paper notes the model: 'shows strong performance in cross-validation with the area under the ROC curve (AUC) of 0.908'. Figure 5 details the performance ROC curves under various comparisons such as against other prediction models such as 'CADD'.",
  "evaluation/method": "Various evaluation methods were employed such as:\n10-fold cross-validation, per-protein and per-cluster cross-validation and comparison of models with different feature sets.",
  "evaluation/done": 5,
  "evaluation/skip": 0
}