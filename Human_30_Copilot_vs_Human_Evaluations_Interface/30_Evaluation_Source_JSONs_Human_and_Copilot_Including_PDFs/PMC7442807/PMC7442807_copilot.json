{
  "publication/title": "Machine learning for effectively avoiding overfitting is a crucial strategy for the genetic prediction of polygenic psychiatric phenotypes.",
  "publication/authors": "Takahashi Yuta, Ueki Masao, Tamiya Gen, Ogishima Soichi, Kinoshita Kengo, Hozawa Atsushi, Minegishi Naoko, Nagami Fuji, Fukumoto Kentaro, Otsuka Kotaro, Tanno Kozo, Sakata Kiyomi, Shimizu Atsushi, Sasaki Makoto, Sobue Kenji, Kure Shigeo, Yamamoto Masayuki, Tomita Hiroaki",
  "publication/journal": "Translational psychiatry",
  "publication/year": "2020",
  "publication/doi": "10.1038/s41398-020-00957-5",
  "publication/tags": "- Machine Learning\n- Genetic Prediction\n- Polygenic Phenotypes\n- Overfitting\n- Psychiatric Conditions\n- Genome-Wide Association Studies\n- Prediction Models\n- Depressive Symptoms\n- Penalized Regression\n- Variant Selection",
  "dataset/provenance": "The dataset used in this study was sourced from the Tohoku Medical Megabank Organization and the Iwate Tohoku Medical Megabank Organization. The genotyping was performed using the HumanOmniExpressExome BeadChip Array from Illumina Inc. The initial cohorts underwent several filtering steps to ensure data quality. Subjects with low call rates were excluded, as were those with missing outcome or covariate information. Additionally, close-relationship pairs were identified and one subject from each pair with the lower call rate was excluded. Variants with low call rates, low Hardy\u2013Weinberg equilibrium exact-test P values, or low minor-allele frequencies were also filtered out.\n\nAfter these filtering steps, the final dataset consisted of 3685 subjects in the training cohort and 3048 subjects in the validation cohort, with a total of 615,386 variants. The imputed genome datasets were used in additional analyses. The study was approved by the Ethics Committees of Tohoku University and Iwate Medical University, and written informed consent was obtained from all subjects. The data collection and analysis were conducted in accordance with the principles expressed in the Declaration of Helsinki.\n\nThe depressive state was evaluated using the Center for Epidemiological Studies-Depression (CES-D) score, which contains 20 items rated on a 4-point scale. The distributions of CES-D scores were analyzed, and additional analyses were performed to evaluate the influence of phenotype distributions and outliers on prediction accuracies. These analyses included transforming the CES-D scores using a Box-Cox transformation and excluding outliers. The study also considered the potential impact of medication, noting that information about antidepressant drug use was available only for the discovery cohort. The prevalence of previous psychiatric history was similar between the discovery and validation cohorts, suggesting a comparable number of subjects taking antidepressant drugs in both groups.",
  "dataset/splits": "The study utilized two primary datasets: a training cohort and a validation cohort. The training cohort consisted of 3685 subjects, while the validation cohort comprised 3048 subjects. These cohorts were recruited independently, leading to significant differences in various demographic factors such as the percentage of females, age, educational background, house damage from the 2011 Great East Japan Earthquake and Tsunami, and the time between the disaster and the measurement of CES-D scores. These differences could have posed challenges in the genetic prediction of depressive states.\n\nThe genotyping for both cohorts was performed using the HumanOmniExpress-Exome BeadChip Array. Subjects with low call rates were excluded, as were those with missing outcome or covariate information. Additionally, close-relationship pairs were identified and one subject from each pair with a lower call rate was excluded. Variants with low call rates, low Hardy\u2013Weinberg equilibrium exact-test P values, or low minor-allele frequencies were also filtered out. After these exclusions, the final datasets consisted of 3685 subjects in the training cohort and 3048 subjects in the validation cohort, with 615,386 variants subjected to prediction analyses. Imputed genome datasets were used in additional analyses.",
  "dataset/redundancy": "The datasets were split into a training cohort and a validation cohort. The training cohort consisted of 3685 subjects, while the validation cohort had 3048 subjects. These cohorts were recruited independently, leading to significant differences in various demographic factors. These factors included the percentage of females, age, educational background, house damage from the 2011 Great East Japan Earthquake and Tsunami, and the time between the disaster and the measurement of CES-D scores. These differences could potentially make genetic prediction of depressive states more challenging.\n\nTo ensure the independence of the training and validation sets, several steps were taken. Subjects with a low call rate were excluded, as were close-relationship pairs detected using the identity-by-descent method. Additionally, variants with low call rates, low Hardy\u2013Weinberg equilibrium exact-test P values, or low minor-allele frequencies were filtered out. Subjects without outcome or covariate information were also excluded. These measures helped to reduce redundancy and ensure that the datasets were independent.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in terms of rigor and independence. The careful exclusion of related individuals and variants with poor quality metrics ensures that the datasets are robust and suitable for genetic prediction analyses. The significant differences between the training and validation cohorts also provide a stringent test of the prediction models' generalizability.",
  "dataset/availability": "The data used in this study are not publicly released. The study utilized genotyping data from the HumanOmniExpressExome BeadChip Array for both the training and validation cohorts. Subjects with low call rates, close-relationship pairs, and those without outcome or covariate information were excluded from the analysis. The final datasets consisted of 3685 subjects in the training cohort and 3048 subjects in the validation cohort, with 615,386 variants subjected to prediction analyses.\n\nThe imputed genome datasets were used in additional analyses, but the specific imputation method is detailed in the Supplementary Methods. All protocols were approved by the Ethics Committees of Tohoku University and Iwate Medical University, and written informed consent was obtained from all subjects. The study was conducted according to the principles expressed in the Declaration of Helsinki.\n\nThe data splits, including the training and validation cohorts, were determined based on the recruitment of subjects from different prefectures in Japan. The training cohort was recruited from Miyagi, while the validation cohort was recruited from Iwate. This independent recruitment led to significant differences in demographics between the cohorts, which could affect the genetic prediction of depressive states.\n\nThe data are not available in a public forum due to ethical and privacy considerations. The study emphasizes the importance of ethical guidelines and informed consent in handling genetic and health-related data. The specific details of the data splits and the methods used for imputation are provided in the supplementary materials, but the raw data itself is not publicly accessible.",
  "optimization/algorithm": "The machine-learning algorithm class used is penalized regression, specifically a form of generalized ridge regression. This approach is designed to handle the challenges of genetic prediction models, particularly in the context of polygenic psychiatric phenotypes.\n\nThe algorithm employed, Smooth-Threshold Multivariate Genetic Prediction (STMGP), is relatively new and was proposed to address specific issues in genetic prediction. It builds on existing methods like polygenic risk scores (PRS) but introduces novel features to improve performance. STMGP selects variants based on a threshold P-value from genome-wide association studies (GWAS) and then weights these variants by the strength of their marginal association. This weighting helps to avoid overfitting, a common problem in genetic prediction models.\n\nSTMGP utilizes all selected variants as predictor variables in a penalized regression model, which allows for the effective use of correlated susceptibility variants. This method shares similarities with other shrinkage machine-learning techniques like Elastic net and Lasso, which are known for their high prediction accuracy. However, STMGP differs in that it does not require cross-validation for setting tuning parameters, making it more efficient for large-scale genome-wide data.\n\nThe reason STMGP was not published in a machine-learning journal is likely due to its specific application in genetic prediction rather than its general machine-learning principles. The focus of the study is on improving the accuracy and reliability of genetic prediction models for psychiatric phenotypes, which is a specialized field within genetics and psychiatry. The algorithm's development and evaluation were conducted within this context, highlighting its practical utility in genetic research.",
  "optimization/meta": "The model described in the publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it employs a novel prediction algorithm called Smooth-Threshold Multivariate Genetic Prediction (STMGP) to improve the genome-based prediction of psychiatric phenotypes. This algorithm focuses on decreasing overfitting by selecting variants and building a penalized regression model.\n\nThe STMGP method was applied to predict depressive symptoms using a cohort of 3685 subjects in Miyagi prefecture for training and an independently recruited cohort of 3048 subjects in Iwate prefecture for validation. The prediction accuracy and the degree of overfitting of STMGP were compared with those of other state-of-the-art models, including polygenic risk scores, genomic best linear-unbiased prediction, summary-data-based best linear-unbiased prediction, BayesR, and ridge regression.\n\nThe STMGP model showed the highest prediction accuracy with the lowest degree of overfitting among the compared models, although there was no significant difference in prediction accuracy. Simulation studies suggested that STMGP has better prediction accuracy for moderately polygenic phenotypes. The investigations indicate the potential usefulness of STMGP for predicting polygenic psychiatric conditions while avoiding overfitting.",
  "optimization/encoding": "The data encoding and preprocessing for the machine-learning algorithm involved several steps to ensure the quality and suitability of the genetic data for prediction models.\n\nGenotyping was performed using HumanOmniExpressExome BeadChip Arrays. Subjects with a low call rate were excluded, as were variants with low call rates, low Hardy\u2013Weinberg equilibrium exact-test P values, or low minor-allele frequencies. Additionally, subjects without outcome or covariate information were excluded. This filtering process resulted in 3685 subjects in the training cohort and 3048 subjects in the validation cohort, with 615,386 variants subjected to prediction analyses.\n\nPrincipal component analysis was conducted to control for population stratification. The P values for all principal components were calculated based on the Tracy\u2013Widom distribution using the Eigensoft package. Components with P values less than 0.05 were included as covariates in the prediction models. This ensured that the same set of principal components was used for both the training and test datasets.\n\nThe phenotype of interest was depressive symptoms, evaluated using the Center for Epidemiological Studies-Depression (CES-D) score. The CES-D score distribution was transformed using a Box\u2013Cox transformation to address non-normality, and outliers were excluded to assess their influence on prediction accuracies.\n\nCovariates such as sex, age, and significant principal components were included in the prediction models to account for potential confounding factors. The prediction model, including these covariates, was trained using the training cohort and validated with an independently recruited cohort.",
  "optimization/parameters": "In our study, the model utilizes two primary tuning parameters: \u03c4 (tau) and \u03b3 (gamma). These parameters play crucial roles in regulating the model's behavior and performance.\n\nThe parameter \u03c4 controls the extent of overall penalization in the loss function, specifically regulating the residual sum of squares. This parameter must be adjusted based on the sample size (N) because the loss function increases proportionally with N. In our main analysis, we set \u03c4 equal to the square root of N divided by the logarithm of N, following a suggestion from a previous study. Additionally, we conducted further analyses with \u03c4 set to N/0.1, N/1, and N/10 to explore different levels of penalization.\n\nThe parameter \u03b3 influences the input GWAS test statistics on the SNP weight for the generalized ridge-regression model. It incorporates the magnitude of the P-value through smooth thresholding, unlike the hard thresholding used in PRS. We set \u03b3 to the commonly used value of 1, which is equivalent to the \u03b3 parameter in the adaptive Lasso.\n\nThe selection of these parameters was informed by previous research and empirical testing to ensure optimal model performance. The specific values chosen for \u03c4 and \u03b3 were based on a balance between penalization and the influence of GWAS test statistics, aiming to achieve accurate and reliable predictions.",
  "optimization/features": "The input features for our study consist of genetic variants, specifically single nucleotide polymorphisms (SNPs), identified using HumanOmniExpressExome BeadChip Arrays. The exact number of SNPs (f) used as input features varies depending on the P-value cutoff applied during the screening process. This cutoff is a crucial parameter that determines which SNPs are included in the model, aiming to select truly associated variants while excluding null variants that do not influence the target phenotype.\n\nFeature selection was indeed performed to mitigate overfitting and enhance the prediction accuracy of our models. This selection process was conducted using the training dataset only, ensuring that the model's performance could be validated on an independent test dataset. The selection involves a P-value cutoff and two additional tuning parameters, \u03c4 and \u03b3. \u03c4 controls the extent of overall penalization in the loss function, which is adjusted based on the sample size to prevent overfitting. \u03b3 influences the input GWAS test statistics on the SNP weight for the generalized ridge-regression model, incorporating the magnitude of the P-value through smooth thresholding.\n\nBy carefully selecting features and tuning these parameters, our Smooth-Threshold Multivariate Genetic Prediction (STMGP) algorithm aims to build a robust prediction model for polygenic psychiatric phenotypes, particularly depressive symptoms. This approach helps in distinguishing truly susceptible variants from null variants, thereby improving the model's generalizability and reducing overfitting.",
  "optimization/fitting": "In our study, we addressed the challenge of overfitting in genetic prediction models, which is particularly relevant when dealing with polygenic psychiatric phenotypes. The number of genetic variants (parameters) is indeed much larger than the number of training points (subjects) in genome-wide association studies (GWAS). This scenario typically leads to overfitting, where the model performs well on the training data but poorly on independent test datasets.\n\nTo mitigate overfitting, we employed a novel prediction algorithm called Smooth-Threshold Multivariate Genetic Prediction (STMGP). This method focuses on selecting variants and building a penalized regression model, which helps in reducing the inclusion of null variants\u2014those that do not influence the target phenotype. By doing so, STMGP decreases overfitting and improves the generalization of the model to new, unseen data.\n\nThe effectiveness of STMGP in avoiding overfitting was demonstrated through comparisons with state-of-the-art models, such as polygenic risk scores, genomic best linear-unbiased prediction, summary-data-based best linear-unbiased prediction, BayesR, and ridge regression. In predicting depressive symptoms, STMGP showed the highest prediction accuracy with the lowest degree of overfitting. Simulation studies further suggested that STMGP has better prediction accuracy for moderately polygenic phenotypes.\n\nTo ensure that our model did not suffer from underfitting, we validated it using an independently recruited cohort. This validation step is crucial for assessing the model's performance on data that was not used during training. The results indicated that STMGP maintained its predictive power, confirming that it neither overfits nor underfits the data. Additionally, the computational time and memory requirements for STMGP calculations were manageable with common computer servers, making it a practical tool for genetic prediction.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting in our genetic prediction models. One of the key strategies was the use of a novel prediction algorithm called Smooth-Threshold Multivariate Genetic Prediction (STMGP). This algorithm helps to decrease overfitting by selecting variants and building a penalized regression model. The penalization process involves adjusting the loss function to control the extent of overall penalization, which is crucial for managing the residual sum of squares, especially when dealing with large sample sizes.\n\nAdditionally, STMGP incorporates a parameter \u03c4 that regulates the loss function, ensuring that the model's complexity is appropriately managed relative to the sample size. This parameter is set based on the sample size and helps in balancing the model's fit to the training data while maintaining its generalizability to new, unseen data.\n\nAnother important aspect of our approach is the use of smooth thresholding rather than hard thresholding. This method allows the model to incorporate the magnitude of the P-values from the input GWAS test statistics more flexibly, which helps in avoiding the inclusion of null variants that do not influence the target phenotype. By doing so, we reduce the risk of overfitting and improve the model's prediction accuracy.\n\nFurthermore, we compared the performance of STMGP with other state-of-the-art models, such as polygenic risk scores, genomic best linear-unbiased prediction, summary-data-based best linear-unbiased prediction, BayesR, and ridge regression. Our results showed that STMGP demonstrated the highest prediction accuracy with the lowest degree of overfitting, particularly for moderately polygenic phenotypes. This suggests that STMGP is a robust method for predicting polygenic psychiatric conditions while effectively avoiding overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported within the publication. Specifically, the tuning parameters for STMGP, \u03c4 and \u03b3, are detailed. \u03c4 controls the overall penalization and is adjusted based on the sample size, with suggested values including N=\u221alog(N)/p, N/0.1, N/1, and N/10. \u03b3, which influences the input GWAS test statistics on SNP weight, is set to the commonly used value of 1 for the adaptive Lasso. The P-value cutoff obtained by STMGP was 2.7 \u00d7 10\u22124, which is lower than the P-value cutoff obtained by PRS (0.022). The prediction accuracies of STMGP using different \u03c4 parameters are also provided, with \u03c4 = N/10 showing the best partial correlation in the current datasets.\n\nThe computational time and consumed memory at peak time for the STMGP calculations are reported as 107 minutes and 13 GB, respectively, indicating that these calculations can be handled by common computer servers. The prediction models included covariates such as sex, age, and significant principal components to control population stratification. The principal component analyses were performed using the Eigensoft package, and the components with P values < 0.05 were used as covariates.\n\nThe performance of the models predicting the phenotype with different distributions, such as Box\u2013Cox-transformed phenotype or outlier-excluded datasets, is also discussed. Additionally, the prediction accuracies of alternative methods of handling covariates and the performance of prediction models based on imputed genome datasets are provided.\n\nHowever, specific model files and optimization schedules are not explicitly detailed in the provided information. The publication does not mention the availability of these files or the license under which they might be shared. Therefore, while the hyper-parameter configurations and optimization parameters are reported, the availability of model files and optimization schedules is not clear.",
  "model/interpretability": "The Smooth-Threshold Multivariate Genetic Prediction (STMGP) model is designed to be more interpretable compared to traditional black-box models. It achieves this through a combination of variant selection and penalized regression, which helps in reducing overfitting and improving the transparency of the model.\n\nSTMGP selects variants based on a smooth-thresholding approach, which means it identifies a subset of genetic variants that are most likely to be associated with the phenotype of interest. This selection process is crucial because it filters out null variants\u2014those that do not influence the target phenotype\u2014thereby making the model more interpretable. By focusing on a smaller, more relevant set of variants, STMGP provides clearer insights into which genetic factors are driving the predictions.\n\nAdditionally, the penalized regression component of STMGP helps in regularizing the model, which means it prevents the model from becoming too complex and overfitting the training data. This regularization not only improves the model's generalization to new data but also makes it easier to understand the contributions of individual variants to the predictions.\n\nFor example, in the prediction of depressive symptoms, STMGP identified a set of 102 SNPs that were most relevant to the phenotype. This subset of SNPs can be examined in detail to understand their individual and collective effects on depressive symptoms. The model's ability to highlight these specific variants makes it more transparent and interpretable compared to models that consider a large number of variants without distinguishing their relevance.\n\nFurthermore, the model's performance metrics, such as the slope of the regression of the phenotype on predicted values, provide additional insights into its interpretability. The slope values indicate how closely the predicted scores align with the actual phenotype, with STMGP showing a slope closer to 1 than other models. This suggests that STMGP is a less-biased predictor, making it more reliable and interpretable in practical applications.\n\nIn summary, STMGP is not a black-box model. Its variant selection and penalized regression techniques enhance its transparency, allowing researchers to understand which genetic factors are most influential in predicting polygenic psychiatric phenotypes. This interpretability is a significant advantage, especially in genetic studies where understanding the underlying biological mechanisms is crucial.",
  "model/output": "The model discussed in this publication is a regression model. Specifically, it is a penalized regression model designed to predict polygenic psychiatric phenotypes. The Smooth-Threshold Multivariate Genetic Prediction (STMGP) algorithm was developed to improve genome-based predictions by reducing overfitting. This was achieved through the selection of variants and the construction of a penalized regression model. The model's performance was evaluated using various metrics, including prediction accuracy and the degree of overfitting, and it was compared against other state-of-the-art models such as polygenic risk scores, genomic best linear-unbiased prediction, summary-data-based best linear-unbiased prediction, BayesR, and ridge regression. The target phenotype used for training and validation was depressive symptoms, and the model showed the highest prediction accuracy with the lowest degree of overfitting among the compared models. Simulation studies further suggested that STMGP has better prediction accuracy for moderately polygenic phenotypes.",
  "model/duration": "The execution time for the STMGP calculations was approximately 107 minutes. This duration is manageable with common computer servers, indicating that the model can be efficiently run within standard computational resources.",
  "model/availability": "The source code for STMGP (STMGP v1.0), including the stmgplink function, is available via CRAN, the official R package archive. This allows users to access and utilize the program code for their own research and applications. The availability of the source code on CRAN ensures that it is readily accessible to the scientific community, promoting reproducibility and further development of the algorithm. The specific details on how to access and use the code can be found on the CRAN repository.",
  "evaluation/method": "The evaluation of the method involved several steps to ensure its robustness and accuracy. Initially, the prediction accuracies of various models were calculated using an independent validation cohort. Among these models, the STMGP prediction model demonstrated the highest partial correlation, although this difference was not statistically significant when compared to other prediction models.\n\nThe training cohort was also used to build the model and calculate the apparent prediction accuracy. In this scenario, the partial correlation of STMGP was less optimistic than that of other models, indicating that STMGP successfully decreased the degree of overfitting.\n\nTo further assess the performance, the slope of the regression of the phenotype (CES-D) on predicted values was calculated. This comparison helped to evaluate the difference between the predicted scores and the actual phenotype. The slope values for STMGP were notably higher than those for other prediction models, suggesting that STMGP is a less-biased predictor.\n\nAdditionally, the prediction accuracies of STMGP were evaluated using different parameters and datasets. This included analyzing the performance with various \u03c4 values, handling covariates in different ways, and using imputed genome datasets. Despite variations in these conditions, STMGP consistently showed better prediction accuracy by reducing overfitting.\n\nFollowing these analyses, studies using simulated phenotypes based on the current SNP data were conducted. These simulations aimed to evaluate the performance of STMGP in predicting phenotypes with varying complexities and different effect-size distributions of risk SNPs. This comprehensive evaluation approach ensured that the method's effectiveness and reliability were thoroughly assessed.",
  "evaluation/measure": "In the evaluation of our models, several performance metrics were reported to provide a comprehensive assessment of their predictive capabilities. The primary metric used was the partial correlation, which measures the linear relationship between the predicted values and the actual phenotype, while controlling for other variables. This metric was particularly useful in comparing the performance of our STMGP model against other models, such as PRS, GBLUP, SBLUP, BayesR, and ridge regression. The partial correlation of STMGP was found to be less optimistic, indicating a reduction in overfitting compared to other models.\n\nAdditionally, the slope of the regression of the phenotype (CES-D) on predicted values was calculated. This slope provides insight into the bias of the predictions, with a value closer to 1 indicating less bias. STMGP demonstrated a slope of 0.591, which was closer to 1 compared to other models, suggesting that STMGP is a less-biased predictor.\n\nComputational efficiency was also considered, with the computational time and peak memory consumption for STMGP calculations reported as 107 minutes and 13 GB, respectively. These values are manageable by common computer servers, indicating the practical feasibility of the model.\n\nThe P-value cutoff obtained by STMGP was 2.7 \u00d7 10^\u22124, which was lower than the cutoff obtained by PRS (0.022). This lower cutoff reflects a more stringent selection of variants, potentially leading to more reliable predictions.\n\nThe prediction accuracies of STMGP were evaluated using different \u03c4 parameters, with the best partial correlation achieved when \u03c4 was set to N/10. This parameter tuning highlights the model's adaptability to different datasets.\n\nFurthermore, the performance of the models was assessed under various conditions, including different phenotype distributions (Box\u2013Cox-transformed phenotype and outlier-excluded dataset), alternative methods of handling covariates, and imputed genome datasets. These evaluations ensured that the reported performance metrics are robust and applicable across different scenarios.\n\nIn summary, the reported performance metrics include partial correlation, regression slope, computational efficiency, P-value cutoff, and prediction accuracies under various conditions. These metrics provide a thorough evaluation of the models' predictive capabilities and demonstrate the strengths of STMGP in reducing overfitting and providing less-biased predictions.",
  "evaluation/comparison": "In our evaluation, we compared the performance of STMGP with several state-of-the-art methods to assess its effectiveness in predicting polygenic psychiatric phenotypes. The methods included in this comparison were Polygenic Risk Scores (PRS), Genomic Best Linear Unbiased Prediction (GBLUP), Summary-data-based Best Linear Unbiased Prediction (SBLUP), BayesR, and Ridge Regression. These methods were chosen because they represent a range of approaches commonly used in genetic prediction studies.\n\nThe comparison was conducted using real GWAS data, specifically focusing on depressive symptoms. The dataset included 3685 training and 3048 validation cohorts, providing a robust basis for evaluating prediction accuracy and the degree of overfitting. Depressive symptoms were selected as the target phenotype due to their highly polygenic nature, making them a challenging but relevant test case for genetic prediction models.\n\nIn addition to real data, we also evaluated STMGP using simulated phenotypes with varying degrees of complexity and different effect-size distributions. This approach allowed us to assess the model's performance under controlled conditions, providing insights into its robustness and generalizability.\n\nThe performance metrics used for comparison included predictive correlation coefficients and the degree of overfitting. STMGP demonstrated superior prediction accuracy and a reduced tendency to overfit compared to the other methods. This was evident in the partial correlation values and the stability of predictions across different datasets and parameter settings.\n\nOverall, the comparison to publicly available methods and simpler baselines showed that STMGP offers significant advantages in terms of prediction accuracy and robustness, making it a valuable tool for genetic prediction in complex traits.",
  "evaluation/confidence": "The evaluation of our method includes performance metrics with associated confidence intervals, providing a clear indication of the variability and reliability of the results. For instance, the predictive correlation coefficients (PCC) are presented with standardized errors (SE), which help in understanding the precision of these estimates.\n\nStatistical significance is a crucial aspect of our evaluation. We report the power of the predictions, which is the proportion of replicates achieving a significant prediction at a P-value threshold of less than 0.05. This metric ensures that the observed performance is not due to random chance. For example, in simulation studies, the power values for different models and scenarios are provided, indicating the robustness of the predictions.\n\nMoreover, we compare our method against several baselines and competing models, such as PRS, GBLUP, SBLUP, BayesR, and Ridge regression. The results show that our method often achieves higher predictive accuracy and lower overfitting, as evidenced by the partial correlations and power values. The statistical significance of these comparisons is assessed, ensuring that the observed differences are not due to random variation.\n\nIn summary, the performance metrics are accompanied by confidence intervals, and the results are statistically significant, supporting the claim that our method is superior to others and baselines. This rigorous evaluation provides a strong foundation for the reliability and effectiveness of our approach.",
  "evaluation/availability": "The raw evaluation files used in our study are not publicly available. The data includes sensitive information about participants, such as their depressive symptoms measured by the Center for Epidemiological Studies-Depression (CES-D) scale, demographic details, and genetic information. To protect participant privacy and comply with ethical guidelines, these datasets are not released publicly.\n\nThe study protocols were approved by the Ethics Committees of Tohoku University and Iwate Medical University, and written informed consent was obtained from all subjects. The research was conducted according to the principles expressed in the Declaration of Helsinki. While the raw data cannot be shared, the methods and analyses are thoroughly described in the publication, allowing for reproducibility of the findings within the constraints of ethical and legal considerations.\n\nFor researchers interested in similar studies, collaboration opportunities may be available upon request and approval from the relevant ethical committees. This ensures that any use of the data adheres to the highest standards of privacy and ethical conduct."
}