{
  "publication/title": "Multi-omic and multi-view clustering algorithms: review and cancer benchmark.",
  "publication/authors": "Rappoport Nimrod, Shamir Ron",
  "publication/journal": "Nucleic acids research",
  "publication/year": "2018",
  "publication/doi": "10.1093/nar/gky889",
  "publication/tags": "- Multi-omics clustering\n- Multi-view clustering\n- Cancer benchmark\n- Machine learning\n- Bioinformatics\n- Computational biology\n- High-throughput data\n- Clustering algorithms\n- Biomedical research\n- Precision medicine",
  "dataset/provenance": "The datasets used in our study were derived from The Cancer Genome Atlas (TCGA), a comprehensive resource managed by the National Cancer Institute (NCI) and the National Human Genome Research Institute (NHGRI). TCGA provides a wealth of multi-omics data, including gene expression, DNA methylation, and miRNA expression, for various cancer types.\n\nThe number of patients in our datasets ranged from 170 for Acute Myeloid Leukemia (AML) to 621 for Breast Invasive Carcinoma (BIC). These datasets have been extensively used by the research community for various studies, making them a reliable source for benchmarking multi-omics clustering methods.\n\nThe datasets contain three types of omics data: gene expression, DNA methylation, and miRNA expression. These data types were chosen because they capture different aspects of cellular biology and have been shown to be informative for cancer classification and prognosis. The datasets have been preprocessed and made available for download, ensuring reproducibility and accessibility for other researchers.\n\nThe use of TCGA data allows for a robust comparison of different clustering methods, as these datasets have been widely studied and validated. This ensures that the results obtained from our benchmarking are relevant and applicable to the broader cancer research community.",
  "dataset/splits": "The datasets used in our study encompass a range of cancer types, each containing multi-omics data. The number of patients varies across different cancer types, with the smallest dataset having 170 patients for Acute Myeloid Leukemia (AML) and the largest having 621 patients for Breast Invasive Carcinoma (BIC). Each dataset includes three types of omics data: gene expression, DNA methylation, and miRNA expression.\n\nThe datasets were not explicitly split into training, validation, and test sets in the traditional sense. Instead, the entire dataset for each cancer type was used to evaluate the performance of the clustering methods. The performance was assessed using three primary metrics: differential survival between clusters, enrichment of clinical labels, and runtime.\n\nFor differential survival, the logrank test was employed to determine if clusters of patients had significantly different survival outcomes, indicating biologically meaningful differences. Clinical labels such as gender, age at diagnosis, and various pathological parameters were tested for enrichment within the clusters. The enrichment was calculated using the chi-square test for independence for discrete parameters and the Kruskal-Wallis test for numeric parameters.\n\nThe runtime of each method was also recorded, including any parameter searches performed. This provided a comprehensive evaluation of both the computational efficiency and the biological relevance of the clustering solutions.\n\nIn summary, the datasets were not divided into multiple splits for training and testing. Instead, the entire dataset for each cancer type was used to evaluate the clustering methods based on survival analysis, clinical label enrichment, and runtime.",
  "dataset/redundancy": "Not applicable.",
  "dataset/availability": "All the processed raw data used in our study are publicly available. They can be accessed at the following URL: http://acgt.cs.tau.ac.il/multiomic-benchmark/download.html. This ensures that other researchers can reproduce our results and build upon our findings.\n\nThe data includes multiple omics types, such as gene expression, DNA methylation, and miRNA expression, across various cancer types. The number of patients ranges from 170 for acute myeloid leukemia (AML) to 621 for breast invasive carcinoma (BIC).\n\nRegarding the data splits, full details on the datasets and cancer type acronyms are provided in Supplementary File 2. This file includes information on how the data was split and preprocessed, ensuring transparency and reproducibility.\n\nThe software scripts used for data processing and analysis are also available. They can be found at the following GitHub repository: https://github.com/Shamir-Lab/Multi-Omics-Cancer-Benchmark/. This repository contains all the necessary code to replicate our experiments and analyze the data.\n\nThe data and software are released under licenses that allow for open access and use by the research community. This promotes collaboration and further advancements in the field of multi-omics cancer research.",
  "optimization/algorithm": "The optimization algorithm discussed is related to dimension reduction-based methods, which are a class of machine-learning algorithms. These methods assume that the data has an intrinsic low-dimensional representation, often corresponding to the number of clusters. The views observed are transformations of this low-dimensional data to a higher dimension, with differing parameters for each view.\n\nThe specific framework mentioned minimizes a loss function across multiple views, with each view having a parametrized transformation and a weight. The optimization algorithm provided is for the case where these transformations are given by matrix multiplication. This approach is widely used and is based on matrix factorization, which is a common technique in dimension reduction methods.\n\nThe algorithm is not entirely new; it builds upon existing principles of dimension reduction and matrix factorization. The reason it might not have been published in a machine-learning journal is that it is more focused on its application in biological data analysis, specifically in the context of multi-omics cancer datasets. The method's utility in providing interpretation for dominant features in each cluster makes it particularly valuable in biological research, where understanding the association between clusters and features is crucial.\n\nThe algorithm's effectiveness has been demonstrated on various cancer types, showing that it improves prognostic value and robustness through the use of multiple kernels and regularization. This practical application and the specific context in which it is used are likely why it was published in a biological research journal rather than a machine-learning one.",
  "optimization/meta": "Not applicable.",
  "optimization/encoding": "The data encoding and preprocessing steps were crucial for the effective application of machine-learning algorithms. For multi-omic datasets, each omic type (e.g., RNA-seq, methylation, miRNA-seq) was represented as a matrix where rows corresponded to samples (or patients) and columns to features. These matrices were concatenated to form a single matrix, which was then used for early integration approaches. Normalization techniques were applied to handle the different distributions and scales of features across omics. This ensured that no single omic dominated the analysis due to having more features.\n\nFeature selection was employed to reduce dimensionality and to give each omic an equal opportunity to influence the results. Regularization methods, such as LASSO and nuclear norm regularization, were used to prevent overfitting and to induce sparsity in the models. For example, LRACluster utilized nuclear norm regularization to encourage a low-rank latent representation of the samples. This preprocessing step was essential for maintaining the integrity of the data and ensuring that the machine-learning algorithms could effectively learn from the multi-omic information.\n\nIn some cases, dimension reduction techniques were applied to transform the high-dimensional data into a lower-dimensional space. This was particularly useful for visualizing the data and for applying clustering algorithms that require a reduced feature space. The choice of dimension reduction method depended on the specific characteristics of the data and the goals of the analysis. Overall, the encoding and preprocessing steps were designed to prepare the data for effective multi-omic integration and analysis.",
  "optimization/parameters": "In our benchmark, we applied various methods to multi-omics datasets, each containing three omics: gene expression, DNA methylation, and miRNA expression. The number of patients ranged from 170 for AML to 621 for BIC.\n\nFor each method, we generally chose parameters as suggested by the authors. In cases where authors recommended a parameter search, we performed such a search and selected the best solution according to the authors' guidelines. This process did not consider the survival and clinical parameters used for assessment, ensuring an unbiased selection. The runtime reported for each method includes the time taken for the parameter search.\n\nThe specific number of parameters (p) used in the model varied depending on the method and the dataset. For instance, methods like MCCA, LRACluster, and rMKL-LPP tended to partition the data into a relatively high number of clusters, with averages of 10.6, 9.4, and 6.7 respectively. In contrast, methods like iCluster and MultiNMF typically resulted in fewer clusters, around 2 or 3 on average.\n\nThe selection of parameters was aimed at reflecting how a typical user would run these methods, considering both the quality of results and the total runtime. Detailed information about the hardware, data preprocessing, and application of the methods can be found in Supplementary File 1. Full clustering results are available in Supplementary File 4.",
  "optimization/features": "The input features for the methods discussed are derived from multi-omic datasets, which include various types of omic data such as RNA-seq, methylation, and miRNA-seq. The total number of features, denoted as p, is the sum of the features from all omics (p = \u03a31Mm=1pm), where pm is the number of features in the m'th omic. The features from different omics are concatenated into a single matrix X, which is then used for clustering.\n\nFeature selection is not explicitly mentioned as a preprocessing step for all methods. However, some methods inherently perform feature selection or regularization to handle the high dimensionality of the data. For instance, LRACluster uses nuclear norm regularization to encourage a low-rank latent representation, effectively reducing the number of features with non-zero effects. Similarly, iCluster uses LASSO regularization to create models where the number of features with non-zero effects is low.\n\nThe feature selection or regularization processes are typically performed within the training phase of the algorithms, ensuring that the selection is done using the training set only. This approach helps to avoid overfitting and ensures that the models generalize well to new data.",
  "optimization/fitting": "In our benchmark, we applied various multi-omics clustering methods to ten different cancer datasets, each containing multiple omics such as gene expression, DNA methylation, and miRNA expression. The number of parameters in these methods can indeed be large, especially in dimension reduction and deep learning approaches. To address the risk of overfitting, several strategies were employed.\n\nFor methods like rMKL-LPP, a regularization term was added to the optimization problem. This term helps to prevent the model from fitting the noise in the data, thereby improving robustness. Additionally, for methods that suggested a parameter search, we performed such searches and chose the best solution as indicated by the authors. This process helped in selecting parameters that generalize well to unseen data, rather than just fitting the training data.\n\nIn the case of deep learning methods, such as autoencoders and deep belief networks, the architectures used were relatively shallow compared to those typically used in imaging datasets. This was done to mitigate overfitting, given the high-dimensional nature of the data and the relatively small number of samples. Furthermore, these methods were applied to multi-omic datasets, which inherently provide more information than single-omic datasets, aiding in better generalization.\n\nTo ensure that the models were not underfitting, we evaluated their performance using multiple metrics. These included differential survival between clusters, enrichment of clinical labels, and runtime. The logrank test was used to assess differential survival, while the \u03c7\u00b2 test for independence and the Kruskal-Wallis test were used for clinical label enrichment. These statistical tests provided a robust evaluation of the models' performance, ensuring that they captured meaningful biological differences.\n\nMoreover, the p-values derived from these tests were estimated using permutation tests, which are more accurate than approximations, especially for small sample sizes and unbalanced cluster sizes. This approach helped in obtaining reliable p-values, further ensuring that the models were not underfitting.\n\nIn summary, we employed regularization, parameter searches, and shallow architectures to prevent overfitting. Simultaneously, we used multiple performance metrics and permutation tests to ensure that the models were not underfitting, thereby achieving a balance between the two.",
  "optimization/regularization": "Regularization techniques are employed to prevent overfitting in various algorithms discussed. One notable method is LASSO (Least Absolute Shrinkage and Selection Operator) regularization, which is used to create models where the number of features with non-zero effects is minimized. This technique is utilized by iCluster, ensuring that the model remains simple and generalizable. Another regularization approach involves the nuclear norm, which induces data sparsity. This method is employed by LRACluster, encouraging the latent representation matrix to be of low rank, thereby simplifying the model and reducing the risk of overfitting.\n\nAdditionally, rMKL-LPP (regularized Multiple Kernel Learning with Locality Preserving Projections) incorporates a regularization term in its optimization problem to avoid overfitting. This algorithm uses multiple kernel functions to measure similarities between samples and performs dimension reduction while maintaining these similarities in a lower-dimensional space. The inclusion of a regularization term helps in achieving a more robust and generalizable clustering solution.\n\nIn summary, regularization methods such as LASSO, nuclear norm regularization, and the inclusion of regularization terms in optimization problems are used to prevent overfitting and ensure that the models are robust and generalizable.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, model files, and optimization parameters used in our study are indeed available. All the software scripts utilized in our benchmark are accessible on GitHub at the following URL: https://github.com/Shamir-Lab/Multi-Omics-Cancer-Benchmark/. This repository contains the necessary code and configurations to replicate the experiments and optimize the methods as described in our publication. The scripts include details on the parameter searches performed, the best solutions chosen, and the runtime measurements, ensuring transparency and reproducibility. The license information for these scripts can be found on the GitHub repository page. Additionally, the processed raw data used in our study can be downloaded from http://acgt.cs.tau.ac.il/multiomic-benchmark/download.html. This data, along with the scripts, allows other researchers to verify our results and apply the methods to their own datasets.",
  "model/interpretability": "The model discussed here is not a black box; it offers several transparent and interpretable aspects. One of the key methods mentioned is Non-negative Matrix Factorization (NMF), which assumes that data have an intrinsic low-dimensional non-negative representation. This method is particularly suitable for non-negative data and provides a clear interpretation of the weight of each feature in each cluster due to its non-negativity constraint. The low-dimensional representation obtained from NMF can be clustered using simple single-omic algorithms, making it easier to understand the contributions of individual features.\n\nAnother method that enhances interpretability is O2-PLS, which partitions the variation in datasets into joint variation between them and variations specific to each dataset. This partitioning helps in understanding how different datasets relate to each other and which variations are unique to each dataset. This makes O2-PLS more interpretable compared to standard PLS, as it clearly separates the shared and unique variations.\n\nAdditionally, the use of factor graphs in PARADIGM provides a transparent way to model cellular processes and the relations among different omics. Each sample and each cellular pathway are represented by a factor graph, which defines a distribution over activation levels of different entities within that pathway. This approach allows for the inference of the activity of non-measured cellular entities, providing activity scores for each entity per patient. These scores can then be used to cluster cancer patients from several tissues, offering a clear and interpretable model of the underlying biological processes.\n\nOverall, the models discussed here emphasize transparency and interpretability, providing clear examples of how different methods can be used to understand the relationships between features and clusters in biological datasets.",
  "model/output": "The model discussed in this publication primarily focuses on clustering and dimension reduction techniques applied to multi-omics data. These methods are used to integrate various types of omics data, such as gene expression, copy number variations, and methylation profiles, to gain insights into cancer subtypes and patient stratification.\n\nThe output of these models typically includes clustering assignments for cancer patients, where each patient is assigned to a cluster based on the integrated omics data. These clusters can then be analyzed for their prognostic value and enrichment of clinical parameters. For example, methods like MCCA, MultiNMF, and LRACluster have shown good prognostic value in terms of survival analysis, while rMKL-LPP and spectral clustering have demonstrated significant enrichment of clinical parameters.\n\nThe models also provide projections or representations of the data in a lower-dimensional space, which can be used for visualization and further analysis. These projections highlight the relationships and agreements between different omics datasets, aiding in the interpretation of the underlying biological processes.\n\nAdditionally, some models, like PARADIGM, output activity scores for cellular entities within pathways, which can be used to infer the activity of non-measured entities and to cluster patients based on these scores. This approach is particularly useful for understanding the cellular processes and interactions among different omics.\n\nIn summary, the output of the models discussed in this publication includes clustering assignments, lower-dimensional representations of the data, and activity scores for cellular entities, all of which contribute to a comprehensive understanding of cancer subtypes and patient stratification.",
  "model/duration": "The execution time of the algorithms varied significantly across different methods and datasets. Most methods, except for LRAcluster and iClusterBayes, completed their runs in less than ten minutes per dataset on average. LRAcluster and iClusterBayes were notably slower, taking approximately 56 and 72 minutes per dataset, respectively. The runtime reported includes the parameter search, reflecting how a typical user might run these methods in terms of both results quality and total runtime. It's important to note that iClusterBayes was run on a Linux cluster utilizing up to 15 nodes in parallel, which might affect its runtime compared to other methods run on a desktop computer. The detailed runtime for each method across ten multi-omics cancer datasets is available in the provided tables.",
  "model/availability": "The software scripts used in our study are publicly available. They can be accessed via the GitHub repository maintained by the Shamir Lab, specifically at the following URL: https://github.com/Shamir-Lab/Multi-Omics-Cancer-Benchmark/. This repository contains all the necessary scripts to replicate the methods and analyses described in our publication.\n\nAdditionally, the processed raw data used in our benchmarking study are available for download. These datasets can be obtained from the following link: http://acgt.cs.tau.ac.il/multiomic-benchmark/download.html. This ensures that other researchers can utilize the same data to validate or build upon our findings.\n\nThe availability of these resources aligns with our commitment to transparency and reproducibility in scientific research. By providing open access to both the software scripts and the datasets, we aim to facilitate further advancements in the field of multi-omics cancer research.",
  "evaluation/method": "To evaluate the performance of the clustering solutions, we employed three primary metrics. Firstly, we assessed differential survival between the obtained clusters using the logrank test. This test assumes that clusters with significantly different survival rates are biologically meaningful. Secondly, we examined the enrichment of clinical labels within the clusters. We tested for enrichment across six clinical labels: gender, age at diagnosis, and three discrete pathological parameters (T, M, and N) that measure tumor progression, metastases, and cancer in lymph nodes, respectively, along with the total progression (pathologic stage). Enrichment for discrete parameters was calculated using the chi-square test for independence, while numeric parameters were evaluated using the Kruskal-Wallis test. Not all clinical parameters were available for every cancer type, resulting in a total of 41 clinical parameters being tested. Lastly, we recorded the runtime of each method to gauge computational efficiency.\n\nFor the statistical tests, we derived p-values using permutation tests rather than relying on the chi-square approximation. This approach was necessary due to the inaccuracies in the chi-square approximation for small sample sizes and unbalanced cluster sizes, especially when the test statistic is large. The permutation tests involved shuffling the cluster labels between samples to obtain an empirical p-value. After permutation testing, the p-values for the clinical labels were corrected for multiple hypotheses using the Bonferroni correction at a significance level of 0.05.\n\nWe applied all nine methods to ten multi-omics datasets and to the thirty single-omic matrices that comprise them, with a few exceptions. MCCA could not be applied to single-omic data, and PINS encountered consistent crashes on all breast invasive carcinoma (BIC) datasets. The methods were run on a Windows machine, except for iCluster, which utilized a Linux cluster with up to 15 nodes in parallel. Parameters for the methods were chosen as suggested by the authors, and when a parameter search was recommended, it was performed to select the best solution without considering the survival and clinical parameters used for assessment. The reported runtime includes the parameter search to reflect real-world usage scenarios.",
  "evaluation/measure": "In our evaluation, we employed three primary metrics to assess the performance of clustering solutions. The first metric was differential survival between the obtained clusters, which we measured using the logrank test. This test assumes that clusters with significantly different survival rates are biologically meaningful. The second metric involved testing for the enrichment of clinical labels within the clusters. We examined six clinical labels: gender, age at diagnosis, and four discrete pathological parameters (T, M, N, and pathologic stage). Enrichment for discrete parameters was calculated using the chi-square test for independence, while numeric parameters were assessed using the Kruskal-Wallis test. Not all clinical parameters were available for every cancer type, resulting in a total of 41 clinical parameters being tested. The third metric recorded was the runtime of each method, which included the parameter search process. We did not consider computational measures for clustering quality, such as heterogeneity, homogeneity, or the silhouette score, due to the varying normalization and feature selection techniques employed by different methods. The p-values for the statistical tests were estimated using permutation tests to address inaccuracies in the chi-square approximation, especially for small sample sizes and unbalanced cluster sizes. After permutation testing, the p-values for the clinical labels were corrected for multiple hypotheses using the Bonferroni correction at a significance level of 0.05. The results of these statistical analyses are detailed in Supplementary File 3.",
  "evaluation/comparison": "A comprehensive comparison of various multi-omic clustering methods was conducted on benchmark datasets. Nine different methods were applied to ten multi-omics datasets, encompassing three omics: gene expression, DNA methylation, and miRNA expression. The number of patients in these datasets ranged from 170 for AML to 621 for BIC.\n\nThe performance of these methods was assessed using three primary metrics: differential survival between clusters, enrichment of clinical labels, and runtime. Differential survival was measured using the logrank test, assuming that significantly different survival rates indicate biologically meaningful clusters. Enrichment of clinical labels was tested for six parameters, including gender, age at diagnosis, and various pathological parameters. The runtime of each method was also recorded, including the time taken for parameter searches.\n\nNotably, no single algorithm consistently outperformed all others across all metrics. For survival prognosis, MCCA had the highest total prognostic value, followed by MultiNMF and LRACluster. In terms of enriched clinical parameters, rMKL-LPP achieved the highest total number, followed by spectral clustering and LRACluster. However, the performance varied across different cancer types, with some methods excelling in specific contexts.\n\nThe comparison also included simpler baselines such as single-omic k-means and spectral clustering, which were applied to both single-omic and multi-omic datasets. This allowed for a broader evaluation of the methods' effectiveness relative to more straightforward approaches.\n\nIn summary, the benchmark provided a thorough comparison of multi-omic clustering methods, highlighting their strengths and weaknesses across different cancer datasets and metrics. This evaluation helps in understanding the relative performance of these methods and guides future research in multi-omic data integration.",
  "evaluation/confidence": "To assess the performance of clustering solutions, several metrics were employed, including differential survival between clusters using the logrank test, enrichment of clinical labels, and runtime. The p-values for these tests were estimated using permutation tests to address inaccuracies in approximations, especially for small sample sizes and unbalanced cluster sizes. This approach provides a more reliable measure of statistical significance.\n\nThe permutation tests involved shuffling cluster labels between samples to obtain empirical p-values, which were then corrected for multiple hypotheses using Bonferroni correction. This method ensures that the results are statistically significant and not due to random chance.\n\nThe performance of the methods was evaluated across ten multi-omics datasets and thirty single-omic matrices. The results indicate that no single algorithm consistently outperformed others across all metrics. However, some methods, such as MCCA and MultiNMF, showed strong prognostic value, while others like rMKL-LPP demonstrated better enrichment of clinical parameters.\n\nThe number of clusters determined by each method varied significantly, with some methods partitioning the data into a higher number of clusters, which may improve prognostic value and clinical significance. The runtime of the methods was also considered, with most methods completing within ten minutes per dataset, except for LRAcluster and iClusterBayes, which took longer.\n\nOverall, the evaluation provides a comprehensive assessment of the methods' performance, with statistical significance ensured through permutation testing and correction for multiple hypotheses. The results suggest that while multi-omics data analysis does not always provide better prognostic value and clinical significance compared to single-omic data, it can offer valuable insights in certain cases.",
  "evaluation/availability": "All the processed raw data used in the evaluation are publicly available. They can be accessed at the URL http://acgt.cs.tau.ac.il/multiomic-benchmark/download.html. This includes the datasets and cancer type acronyms used in the study. Additionally, all software scripts used in the evaluation are available on GitHub at the repository https://github.com/Shamir-Lab/Multi-Omics-Cancer-Benchmark/. The data and scripts are provided to ensure reproducibility and to allow other researchers to build upon the work presented."
}