{
  "publication/authors": "Wegrzyn JL, Lee JM, Liechty J, Neale DB",
  "publication/journal": "Bioinformatics",
  "publication/title": "PineSAP--sequence alignment and SNP identification pipeline.",
  "publication/doi": "10.1093/bioinformatics/btp477",
  "publication/year": "2009",
  "publication/tags": [],
  "dataset/availability": "Class I MHC binding affinity data in IEDB\nhttps://cbs.dtu.dk/services.NetMHCpan-3.0 (broken link)\n\nClass II MHC binding affinity data in IEDB\nhttps://cbs.dtu.dk/services.NetMHCIIpan-3.2 (broken link)\n\nBenchmark dataset (used for comparison with other methods)\nhttps://www.biorxiv.org/content/10.1101/154757v2  https://data.mendeley.com/datasets/jwhmrdx268/1\nThe authors obtained data in the class I MHC-peptide binding affinity benchmark from personal correspondence with Bhattacharya et al. and they have deposited this dataset in Mendeley Data. The accession number for this data is Mendeley Data:\nhttps://doi.org/10.17632/jwhmrdx268.1\n",
  "dataset/provenance": "Regression data\n\nClass I MHC binding affinity data in IEDB\nBroken link\n\nClass II MHC binding affinity data in IEDB\nBroken link\n\nBenchmark dataset (used for comparison with other methods)\nCurated class I MHC benchmark dataset (https://www.biorxiv.org/content/10.1101/154757v2 https://data.mendeley.com/datasets/jwhmrdx268/1)  \nTraining 176,985\nTesting  26,888",
  "dataset/redundancy": "Class I MHC binding affinity data in IEDB\nFor analyses on class I MHC-peptide binding, the IEDB-based dataset of Nielsen et al (2016) was used, in which 5 cross-validation folds were created to ensure no peptide shares a 9-mer sequence with any peptide in a different fold. \t\n\nClass II MHC binding affinity data in IEDB\nFor analyses on class II MHC-peptide binding, the IEDB-based dataset of Jensen et al (2018) was used, in which 5 cross-validation folds were created in the same way as in Nielsen et al (2016).\t\n\nBenchmark dataset (used for comparison with other methods)\nThe dataset of Bhattacharya et al.(2017) was used, who constructed a benchmark in which no peptide in the test set has identical length and greater than 80% sequence identity to any peptide in the training Set.",
  "dataset/splits": "Class I MHC binding affinity data in IEDB\nOnly MHC alleles (114)  with more than 100 examples were included to ensure the quality of training.   1/8 of the training set was held out as a validation set.\t\n\nClass II MHC binding affinity data in IEDB\nOnly MHC alleles (55) with more than 100 examples were included to ensure the quality of training.   1/8 of the training set was held out as a validation set.\t\n\nBenchmark dataset (used for comparison with other methods)\n51 class I MHC alleles are covered in this dataset.   ",
  "optimization/algorithm": "Ensemble of a deep Residual Convolutional Neural Networks.\t",
  "optimization/config": "https://github.com/gifford-lab/PUFFIN",
  "optimization/encoding": "Each MHC allele was represented by a pseudo-sequence consisting of 34 amino acid residues in contact with the peptide.  All peptides sequences were padded on the right end to the same length, 30 for class I and 40 for class II, using a place-holder amino acid.     For each MHC- peptide pair, the MHC feature vector and the peptide feature matrix formed a final input matrix of size 1400 x 30 for class I MHC and 1400 x 40 for class II MHC. The difference between the peptide length L and the expected length L (9 for class I MHC and 15 for class II MHC) was encoded using a sigmoid function.",
  "optimization/features": "Number of initial features on the order of 1400 x 30",
  "optimization/fitting": "Possible redundancy in the sequences",
  "optimization/meta": "NO",
  "optimization/parameters": "The model weights from the epoch with the lowest validation loss were selected.",
  "optimization/regularization": "",
  "model/availability": "https://github.com/gifford-lab/PUFFIN",
  "model/duration": "",
  "model/interpretability": "Black box",
  "model/output": "Regression: The PUFFIN method takes as input a MHC-peptide pair and predicts a probabilistic distribution of peptide-MHC binding affinity. For Classification: positive examples were defined as the ones with a binding affinity stronger than 500 nM.",
  "evaluation/availability": "",
  "evaluation/comparison": "PUFFIN was compared to NetMHCpan, MHCflurry and MHCnuggets. Unlike those methods, PUFFIN provides uncertainty estimates for MHC-peptide affinity prediction. It is shown that PUFFIN\u2019s uncertainty estimates are able to reflect the predictive error on unseen examples.",
  "evaluation/confidence": "Confidence intervals are not reported. As mentioned in the text, there were no significant performance differences among the different tested methods.",
  "evaluation/measure": "auROC, F1 score, mean-squared-error (MSE), R2, Spearman, correlation, and Point-Biserial correlation. For auROC, F1 score, and Point-Biserial correlation, positive examples were defined as the ones with a binding affinity stronger than 500 nM.",
  "evaluation/method": "Cross-validation on training set and independent set"
}