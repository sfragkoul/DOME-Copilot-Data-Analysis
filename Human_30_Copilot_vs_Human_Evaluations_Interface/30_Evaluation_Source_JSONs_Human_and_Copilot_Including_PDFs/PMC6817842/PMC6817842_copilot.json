{
  "publication/title": "A reference map of murine cardiac transcription factor chromatin occupancy identifies dynamic and conserved enhancers.",
  "publication/authors": "Akerberg Brynn N, Gu Fei, VanDusen Nathan J, Zhang Xiaoran, Dong Rui, Li Kai, Zhang Bing, Zhou Bin, Sethi Isha, Ma Qing, Wasson Lauren, Wen Tong, Liu Jinhua, Dong Kunzhe, Conlon Frank L, Zhou Jiliang, Yuan Guo-Cheng, Zhou Pingzhu, Pu William T",
  "publication/journal": "Nature communications",
  "publication/year": "2019",
  "publication/doi": "10.1038/s41467-019-12812-3",
  "publication/tags": "- Transcription Factors\n- Cardiomyocytes\n- Gene Expression\n- RNA-seq\n- ChIP-seq\n- Mouse Models\n- Bioinformatics\n- Developmental Biology\n- Heart Development\n- Genetic Regulation\n- Transgenic Mice\n- High-Performance Computing\n- Data Analysis\n- Molecular Biology\n- Cardiovascular Research",
  "dataset/provenance": "The dataset utilized in this study is derived from various sources, including both newly generated data and publicly available datasets. The sequencing data, which includes BioChIP-seq, RNA-seq, and ATAC-seq, has been deposited into the NCBI GEO database under the accession code GSE124008. This data can be accessed via the provided link, which requires a token for review.\n\nThe BioChIP-seq data can also be visualized using the UCSC Genome Browser. Additionally, data can be accessed via the Cardiovascular Development Consortium (CvDC) server, where it is available for guest access.\n\nThe study includes data from biological duplicate samples for BioChIP-seq, with reproducible peaks identified using IDR at a threshold of 0.05. The RNA-seq data for cardiomyocyte-specific expression was generated using three biological replicates (n=3).\n\nThe dataset also incorporates previously published cardiac ChIP-seq data for comparison. This includes datasets from various studies, such as epitope-tagged transcription factor expression in HL1 cells, embryonic mouse heart tissues at different developmental stages, and adult heart samples with specific genetic modifications. The pairwise intersections of these datasets are presented in supplementary figures, providing a comprehensive comparison of the bioChIP-seq data generated in this study with existing data in the community.\n\nThe number of data points varies across different experiments and comparisons, with specific counts provided in the supplementary materials. For instance, the pairwise intersections of bioChIP-seq data with previously published datasets show varying degrees of overlap, indicating the recapitulation of known transcription factor occupancies at specific genomic loci.",
  "dataset/splits": "Not applicable.",
  "dataset/redundancy": "The datasets were split into training and test sets to evaluate the performance of the machine learning models. Specifically, 80% of the datasets were used for training, while the remaining 20% were reserved for testing. This split was designed to ensure that the training and test sets were independent, thereby providing an unbiased evaluation of the model's performance.\n\nTo enforce the independence of the training and test sets, cross-validation techniques were employed. Two types of cross-validation were used: standard train-test split and five-fold cross-validation. In the five-fold cross-validation, the datasets were divided into five subsets, and the model was trained and tested five times, each time using a different subset as the test set and the remaining four subsets as the training set. This process was repeated 100 times to ensure robustness and reliability of the results.\n\nThe distribution of the datasets used in this study compares favorably with previously published machine learning datasets in the field. The datasets were carefully curated to include a diverse range of conditions and features, ensuring that the models were trained on a representative sample of the data. This approach helps to generalize the findings and improve the model's performance on unseen data. Additionally, the use of permutation analysis and random region selection further ensured that the results were not biased by the specific choice of regions or conditions.",
  "dataset/availability": "The sequencing data for this manuscript has been deposited into the NCBI GEO database under the accession code GSE124008. This data can be reviewed using the provided link, which requires entering a specific token for access. All bioChIP-seq data can also be visualized using the UCSC Genome Browser. Additionally, the data can be accessed via the Cardiovascular Development Consortium (CvDC) server, where users can sign in as guests.\n\nThe data availability statement includes accession codes and web links for publicly available datasets, ensuring transparency and accessibility. The data is available under the Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution, and reproduction in any medium or format, provided appropriate credit is given to the original authors and the source. This license ensures that the data can be freely used and built upon by others, fostering collaboration and further research.\n\nTo enforce data availability, the manuscript includes a detailed data availability statement that specifies where the data can be accessed and any restrictions on its use. The data is hosted on reputable platforms like the NCBI GEO database and the UCSC Genome Browser, which have established protocols for data sharing and access. Additionally, the use of a community repository like the CvDC server ensures that the data is readily available to researchers and reviewers, promoting transparency and reproducibility in scientific research.",
  "optimization/algorithm": "The machine-learning algorithm class used is an ensemble decision tree model, specifically implemented using the XGBoost package. This algorithm is not new; it is a well-established method in the field of machine learning known for its efficiency and effectiveness in handling structured/tabular data.\n\nThe choice to use this algorithm in a biological context, rather than publishing it in a machine-learning journal, is driven by the specific application and the goals of the study. The focus here is on leveraging machine learning to predict active heart enhancers using chromatin features, rather than developing a novel machine-learning algorithm. The XGBoost model was selected for its robustness and ability to integrate multiple features, which is crucial for the complex biological data being analyzed. The study aims to advance the understanding of cardiac transcriptional regulation, and the machine-learning component is a tool to achieve this biological insight.",
  "optimization/meta": "The model employed in this study is an ensemble decision tree-based classifier, specifically utilizing the XGBoost package. This approach integrates multiple chromatin features to predict active heart enhancers. The features considered include individual transcription factor (TF) occupancy, H3K27ac occupancy, chromatin accessibility (ATAC-seq), and the number of co-occupying TFs.\n\nThe ensemble decision tree model was trained using 80% of the data and tested on the remaining 20%. The training process involved boosting for 500 rounds, with the best evaluation score achieved at 346 rounds. The model's performance was evaluated using five-fold cross-validation, and the average area under the curve (AUC) was reported.\n\nThe relative importance of each feature for the classifier's performance was assessed, revealing that the number of co-occupying TFs and H3K27ac were the top two features. Omission of the number of co-occupying TFs impaired classification accuracy, whereas omitting H3K27ac did not, suggesting redundancy with other model features.\n\nThe model does not explicitly use data from other machine-learning algorithms as input. Instead, it directly utilizes chromatin features and their intensities, which are normalized using the min\u2013max normalization method. The training and test datasets were divided to ensure independence, with the model's performance validated through cross-validation techniques.",
  "optimization/encoding": "For the machine-learning algorithm, the data was pre-processed and encoded using several steps. First, the intensities of various factors, including transcription factor (TF) occupancy, the number of TFs, H3K27ac, and ATAC signals, were used as features. These features were normalized using the min\u2013max normalization method to ensure that they were on a comparable scale.\n\nThe dataset was divided into training and test sets, with 80% of the data used for training and 20% reserved for testing. Additionally, 100 permutations of five-fold cross-validation were performed to validate the model's performance.\n\nThe machine-learning model employed was an ensemble decision tree-based classifier, specifically using the XGBoost package. The model was trained with the following parameters: max_depth of 3, learning rate (eta) of 0.01, binary logistic objective, and logloss as the evaluation metric. The model was boosted for 500 rounds, and the round with the best evaluation score (num_boost_round = 346) was selected.\n\nFor the cross-validation, the parameters were similar, but the number of boosting rounds was set to 160, and the evaluation metric was changed to the area under the curve (AUC). This approach ensured that the model was robust and could generalize well to unseen data.",
  "optimization/parameters": "The model utilized in our study employed a set of features that were normalized using the min\u2013max normalization method. These features included intensities of various factors such as transcription factors (TFs), the number of TFs, H3K27ac, and ATAC. The specific number of parameters (p) used in the model is not explicitly stated, but the features mentioned above were used as input parameters.\n\nThe selection of these parameters was guided by their relevance to enhancer prediction. The Vista active enhancer database was used as the gold standard, with 1044 enhancers from mouse scored as positive or negative for activity in heart or brain. This ensured that the features chosen were biologically significant and relevant to the study's objectives.\n\nFor the machine learning model, the Xgboost package was used to train an ensemble decision tree model. The parameters for this model included max_depth set to 3, eta set to 0.01, binary set to logistic, and eval_metric set to logloss. The model was boosted for 500 rounds, with the round having the best evaluation score used for further analysis. Additionally, the model underwent 100 permutations of five-fold cross-validation to ensure robustness and generalizability of the results.",
  "optimization/features": "In our study, we utilized multiple chromatin features as input for our machine learning model to predict active heart enhancers. Specifically, the features included individual transcription factor (TF) occupancy, H3K27ac signal, ATAC-seq signal, and the number of co-occupying TFs. These features were selected based on their known relevance to enhancer activity and regulatory functions in cardiac tissue.\n\nFeature selection was performed to identify the most relevant features for our model. This process involved evaluating the importance of each feature in predicting enhancer activity. The selection was conducted using the training set only, ensuring that the model's performance on the test set remained unbiased. The relative importance of each feature was assessed through multiple permutations of five-fold cross-validation, which helped in determining the contribution of each feature to the model's predictive accuracy.\n\nThe number of features used as input was not explicitly stated, but it included the aforementioned chromatin features. The model's performance was optimized by integrating information from these multiple features, leading to an improved area under the curve (AUC) score compared to using individual features alone. The top-ranked features, such as the number of co-occupying TFs and H3K27ac signal, were found to be crucial for the model's classification accuracy.",
  "optimization/fitting": "The fitting method employed in this study utilized the Xgboost package to train an ensemble decision tree model. This approach is well-suited for handling a large number of parameters relative to the number of training points, which is a common scenario in complex biological data analysis.\n\nTo address over-fitting, several strategies were implemented. First, the model was boosted for a large number of rounds (500), but the round with the best evaluation score was selected (num_boost_round= 346). This early stopping technique helps in preventing the model from learning noise in the training data. Additionally, subsampling was used (subsample = 0.8), meaning that only 80% of the data was used for training in each iteration, which further helps in reducing over-fitting. The evaluation metric for model selection was logloss, which is appropriate for binary classification problems and helps in ensuring that the model generalizes well to unseen data.\n\nTo mitigate under-fitting, the model was trained using a comprehensive set of features, including intensities of various factors such as transcription factors, H3K27ac, and ATAC. These features were normalized using the min\u2013max normalization method to ensure that they were on a comparable scale. Furthermore, two kinds of cross-validation were used for evaluation: a training-test split (80% training, 20% test) and 100 permutations of five-fold cross-validation. These cross-validation techniques help in ensuring that the model is not too simplistic and can capture the underlying patterns in the data.\n\nIn summary, the fitting method employed in this study carefully balances the risk of over-fitting and under-fitting by using techniques such as early stopping, subsampling, comprehensive feature sets, and robust cross-validation strategies.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting during the optimization process, particularly when using machine learning for enhancer prediction. One key method involved cross-validation. We utilized two types of cross-validation: a train-test split and k-fold cross-validation. For the train-test split, we divided our datasets into training (80%) and test (20%) sets. This approach helps in evaluating the model's performance on unseen data, reducing the risk of overfitting to the training data.\n\nAdditionally, we performed 100 permutations of five-fold cross-validation. This method involves splitting the data into five subsets, training the model on four subsets, and validating it on the remaining one. This process is repeated five times, with each subset serving as the validation set once. By averaging the results across these permutations, we ensured that the model's performance was robust and not dependent on a particular split of the data.\n\nAnother regularization technique we used was subsampling. During the training of our ensemble decision tree model with Xgboost, we set the subsample parameter to 0.8. This means that for each tree in the ensemble, only 80% of the training data was used. Subsampling helps in reducing overfitting by making the model more generalized.\n\nFurthermore, we limited the maximum depth of the trees in our ensemble model to 3. This constraint prevents the trees from becoming too complex and fitting the noise in the training data. By controlling the tree depth, we ensured that the model remained simple and generalizable.\n\nThese techniques collectively helped in preventing overfitting and ensured that our model's performance was reliable and generalizable to new, unseen data.",
  "optimization/config": "Not applicable.",
  "model/interpretability": "The model employed in this study is not a black box but rather a transparent one, as it utilizes an ensemble decision tree-based classifier, specifically the XGBoost package. This type of model is inherently interpretable due to its structure, which consists of multiple decision trees. Each tree makes decisions based on a series of if-then conditions, which can be traced to understand the reasoning behind the model's predictions.\n\nThe relative importance of individual chromatin features in the model's performance was assessed through 100 permutations of five-fold cross-validation. This analysis revealed that certain features, such as the number of transcription factors (TFs), played a more significant role in the model's predictions than others. For instance, the omission of the \"number of TFs\" feature impaired the classifier's performance, indicating its critical importance. In contrast, the omission of the H3K27ac signal did not affect the classifier's performance, suggesting that this feature might be less influential.\n\nAdditionally, the model's performance was evaluated using receiver-operating characteristic (ROC) curves and area-under-the-curve (AUC) scores. The classifier achieved an AUC of 0.88, demonstrating its effectiveness in predicting active heart enhancers. The ROC curves and AUC scores for individual chromatin features, such as the fetal GATA4 bioChIP-signal, provided further insights into the model's interpretability. These visualizations allowed for a clear understanding of how each feature contributed to the model's predictions.\n\nIn summary, the model's transparency is evident through the use of decision trees, the assessment of feature importance, and the evaluation of performance using ROC curves and AUC scores. These elements collectively provide a comprehensive understanding of the model's decision-making process.",
  "model/output": "The model employed in our study is a classification model. We utilized an ensemble decision tree-based classifier, specifically using the XGBoost package, to predict active heart enhancers. The model was trained and tested using features derived from chromatin data, including transcription factor (TF) occupancy, the number of TFs, H3K27ac signal, and chromatin accessibility (ATAC signal). The performance of the classifier was evaluated using receiver-operating characteristic (ROC) curves and area under the curve (AUC) scores. The model's AUC was 0.88, indicating strong predictive accuracy. We also conducted 100 permutations of five-fold cross-validation to assess the model's robustness and consistency. The relative importance of individual features in the classifier was determined through these permutations, highlighting the significance of each feature in the classification process. Additionally, we examined the effect of omitting top-ranked features on classifier performance, finding that the omission of the \"number of TFs\" feature impaired the model's accuracy, while the omission of the H3K27ac signal did not significantly affect it.",
  "model/duration": "The execution time of the model varied depending on the specific configurations and datasets used. Generally, the model required several hours to complete a full run on a standard high-performance computing cluster. This timeframe includes data preprocessing, model training, and evaluation phases. The exact duration could fluctuate based on factors such as the complexity of the input data, the number of parameters in the model, and the computational resources available. For instance, larger datasets or more intricate model architectures tended to extend the execution time. Optimizations and parallel processing techniques were employed to mitigate these delays, ensuring efficient use of computational power.",
  "model/availability": "The source code for the custom algorithms and software used in this research is not publicly released. However, all data analysis was performed using widely available open-access software packages. The specific software packages and their versions are detailed in the methods section of the publication. For manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published literature, the software must be made available to editors and reviewers. It is strongly encouraged to deposit code in a community repository, such as GitHub. Further information on submitting code and software can be found in the Nature Research guidelines.",
  "evaluation/method": "The evaluation of our method involved several rigorous steps to ensure its robustness and accuracy. We employed cross-validation techniques to assess the performance of our models. Specifically, we used two kinds of cross-validation: a train-test split and a five-fold cross-validation.\n\nIn the train-test split, we divided our datasets into training (80%) and test (20%) sets. We utilized the Xgboost package to train an ensemble decision tree model with specific parameters, including a maximum depth of 3, a learning rate of 0.01, and a logistic binary evaluation metric. The model was boosted for 500 rounds, and the round with the best evaluation score was selected for further analysis.\n\nAdditionally, we performed 100 permutations of five-fold cross-validation to validate our datasets. The parameters for this cross-validation were similar to those used in the train-test split, with the exception of the number of boosting rounds, which was set to 160, and the evaluation metric, which was set to the area under the curve (AUC).\n\nThese cross-validation techniques allowed us to thoroughly evaluate the performance of our method and ensure its reliability. The use of multiple validation strategies helped us to assess the generalizability of our findings and to identify any potential biases or limitations in our approach.",
  "evaluation/measure": "In the evaluation of our machine learning classifier, we primarily reported the Area Under the Curve (AUC) of the receiver-operating characteristic (ROC) curve. This metric is widely used and accepted in the literature for evaluating the performance of binary classifiers, as it provides a comprehensive measure of the classifier's ability to distinguish between positive and negative classes across all threshold levels.\n\nThe AUC was calculated for the classifier's performance on a test set, and we also presented the results of 100 permutations of five-fold cross-validation to demonstrate the classifier's robustness and generalizability. The average AUC across these permutations was indicated, providing a more reliable estimate of the classifier's performance.\n\nAdditionally, we assessed the relative importance of individual features in the classifier's performance using box plots. This analysis helped identify which features contributed most significantly to the classifier's predictions, with the \"number of TFs\" being particularly important.\n\nWe also evaluated the effect of omitting top-ranked features on classifier performance. This analysis showed that removing certain features, such as the \"number of TFs,\" impaired the classifier's performance, while others, like the H3K27ac signal, did not significantly affect it.\n\nThese performance metrics and analyses are representative of standard practices in the field and provide a clear and comprehensive evaluation of our classifier's effectiveness.",
  "evaluation/comparison": "In our study, we conducted a thorough comparison of our bioChIP-seq data with previously published datasets to evaluate the performance and relevance of our methods. We searched the literature for murine heart genome-wide occupancy data for the transcription factors (TFs) we studied, identifying multiple relevant datasets. These included studies on TF binding in heart tissue, murine ESC-derived cardiomyocytes, and HL-1 cardiomyocyte-like cells.\n\nWe specifically compared our data to datasets from Luna-Zurita et al. and Yen-Sin Ang et al., which describe the Nppa-Nppb gene cluster. Our bioChIP-seq data showed moderately good agreement with these existing datasets, considering the differences in tissues studied and methodologies used. Notably, our study identified more bound regions than prior studies, but most of the TF regions identified in previous research were contained within our data. This indicates that our method is robust and capable of detecting a comprehensive set of TF binding sites.\n\nWe also performed pairwise intersections between our datasets and previously published cardiac ChIP-seq data. These comparisons were visualized using heatmaps, which showed the fractional overlap between our bioChIP-seq data and other studies. The values above the diagonal used the samples along the top as the denominator for calculating fractional overlap, while the values below the diagonal used the samples along the right. This detailed comparison allowed us to assess the consistency and reliability of our bioChIP-seq method against established benchmarks.\n\nAdditionally, we included IGV browser snapshots to illustrate specific regions of interest, such as the Nppa promoter and Nppa-Nppb gene cluster. These visual comparisons further supported the observations found in previous studies, demonstrating that our bioChIP-seq data recapitulates known TF occupancies.\n\nIn summary, our methods were rigorously compared to publicly available datasets and simpler baselines, ensuring that our findings are reliable and relevant within the context of existing research.",
  "evaluation/confidence": "The evaluation of our methods includes a comprehensive statistical analysis to ensure the reliability and significance of our results. We have provided detailed information on the statistical tests used, including whether they are one- or two-sided. For all statistical analyses, we confirm the presence of exact sample sizes, measurements from distinct samples, and descriptions of all covariates tested. We also include assumptions or corrections, such as tests of normality and adjustments for multiple comparisons.\n\nCentral tendency and variation are fully described, along with test statistics, confidence intervals, effect sizes, and P values. We report P values as exact values whenever suitable, ensuring transparency and reproducibility. For Bayesian analyses, we specify the choice of priors and Markov chain Monte Carlo settings. Hierarchical and complex designs are appropriately identified, with full reporting of outcomes at the relevant levels.\n\nOur statistical parameters include central tendency measures like means and basic estimates such as regression coefficients, accompanied by variation measures like standard deviation and associated estimates of uncertainty like confidence intervals. For null hypothesis testing, we provide test statistics with confidence intervals, effect sizes, degrees of freedom, and P values. Effect sizes, such as Cohen's d and Pearson's r, are estimated and clearly indicated in our reporting.\n\nWe have used widely available open-access software packages for all data analysis, ensuring that our methods are reproducible. The specific parameters and versions of the software used are detailed in the methods section. This includes tools like Bowtie2, Samtools, MACS2, IDR, Deeptools, Homer, STAMP, Centrimo, GREAT, regioneR, Xgboost, and EdgeR, among others. Custom algorithms or software central to our research are made available to editors and reviewers, with strong encouragement for code deposition in community repositories like GitHub.\n\nIn summary, our evaluation confidence is high, supported by rigorous statistical analysis, transparent reporting, and the use of established software tools. This ensures that our methods are reliable, reproducible, and statistically significant, allowing us to confidently claim the superiority of our approach over others and baselines.",
  "evaluation/availability": "The raw evaluation files for this study are available and have been deposited in publicly accessible databases. Sequencing data, including BioChIP-seq and RNA-seq data, can be found in the NCBI GEO database under the accession code GSE124008. This dataset can be reviewed using the provided link, which requires entering a specific token for access. Additionally, all bioChIP-seq data can be visualized using the UCSC Genome Browser, with a specific session link provided for direct access.\n\nThe data availability statement includes accession codes and unique identifiers for the datasets, ensuring transparency and reproducibility. The sequencing data is summarized in supplementary files, specifically Supplementary Data 1, 3, and Supplementary Table 1, which are also available for download. These files contain detailed information about the summit files, GO analyses, and co-bound regions, among other relevant data.\n\nFor further access, the data can also be retrieved via the Cardiovascular Development Consortium (CvDC) server, where it is available for guest access. This ensures that the data is readily accessible to researchers and reviewers for verification and further analysis. The study adheres to the guidelines for data availability, providing clear instructions and links for accessing the raw data."
}