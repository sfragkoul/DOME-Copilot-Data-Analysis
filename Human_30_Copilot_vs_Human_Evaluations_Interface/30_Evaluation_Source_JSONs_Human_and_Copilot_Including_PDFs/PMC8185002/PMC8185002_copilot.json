{
  "publication/title": "A deep learning approach to identify gene targets of a therapeutic for human splicing disorders.",
  "publication/authors": "Gao Dadi, Morini Elisabetta, Salani Monica, Krauson Aram J, Chekuri Anil, Sharma Neeraj, Ragavendran Ashok, Erdin Serkan, Logan Emily M, Li Wencheng, Dakka Amal, Narasimhan Jana, Zhao Xin, Naryshkin Nikolai, Trotta Christopher R, Effenberger Kerstin A, Woll Matthew G, Gabbeta Vijayalakshmi, Karp Gary, Yu Yong, Johnson Graham, Paquette William D, Cutting Garry R, Talkowski Michael E, Slaugenhaupt Susan A",
  "publication/journal": "Nature communications",
  "publication/year": "2021",
  "publication/doi": "10.1038/s41467-021-23663-2",
  "publication/tags": "- CFTR\n- Splicing\n- RNA-seq\n- Deep Learning\n- CNN Model\n- Exon Inclusion\n- Drug Response\n- Transcriptome Analysis\n- Bioinformatics\n- Molecular Biology\n\nNot sure if these tags are present in the article, but they are generated based on the information available.",
  "dataset/provenance": "The dataset utilized in this study is derived from RNA sequencing (RNA-seq) data, which is a common method for analyzing the transcriptome. The specific compounds and treatments, such as BPN-15477, were applied to relevant cellular models to observe their effects on splicing.\n\nThe dataset includes a curated set of exon triplets, with a focus on those that exhibit differential splicing upon drug treatment. For instance, the unchanged exon set contains 382 exons, which were used to train and evaluate the convolutional neural network (CNN) model. The model's performance was assessed using metrics such as the area under the receiver operating characteristic curve (AUC) and the area under the precision-recall curve (AUPR).\n\nThe dataset also includes information on the performance of the CNN model on various categories of exon triplets, such as inclusion, exclusion, and unchanged predictions. The model demonstrated significant performance compared to a random classifier, even when applied to less curated datasets.\n\nThe dataset was further evaluated by applying the CNN model to the whole transcriptome, considering all expressed exon triplets with a percent spliced-in (PSI) value between 0.01 and 0.99 before or after treatment. This approach allowed for a more realistic assessment of the model's performance and applicability in real-life usage scenarios.\n\nThe dataset includes various controls and replicates to ensure the robustness and reliability of the findings. For example, the dual luciferase assay was repeated three times, and each experimental validation using RT-PCR was repeated six times, except for one specific case. The protein quantifications using western blot were also repeated six times, and the CFTR chloride channel analysis in CFBE-Flpin cells was repeated at least two times. All attempts at replication were successful, ensuring the consistency of the results.\n\nThe dataset was carefully curated to include only high-confidence unchanged exons for training the CNN, which is crucial for the model's performance. The use of a small negative set was acknowledged, and steps were taken to address this issue by evaluating the model using all available triplets and considering various cutoffs for the prediction score. This approach provides a more comprehensive understanding of the model's performance and its potential applications in real-life scenarios.",
  "dataset/splits": "The dataset was divided into three distinct splits: training, validation, and test sets. The training set comprises 178 inclusion-responded, 476 exclusion-responded, and 268 unchanged exon triplets. The validation set includes 51 inclusion-responded, 136 exclusion-responded, and 76 unchanged exon triplets. The test set consists of 25 inclusion-responded, 68 exclusion-responded, and 38 unchanged exon triplets. These splits were assigned randomly using a seed of 122 in Python. The distribution of data points in each split reflects a focus on ensuring a representative sample of each type of exon triplet response across all splits.",
  "dataset/redundancy": "The datasets used in this study were split into three distinct sets: training, validation, and test sets. The training set consisted of 178 inclusion-responded, 476 exclusion-responded, and 268 unchanged exon triplets. The validation set included 51 inclusion-responded, 136 exclusion-responded, and 76 unchanged exon triplets. The test set comprised 25 inclusion-responded, 68 exclusion-responded, and 38 unchanged exon triplets. These sets were assigned randomly using a seed of 122 in Python, ensuring reproducibility.\n\nThe training and test sets are completely independent from each other. This independence was explicitly stated in the Results section to clarify any potential concerns about dataset redundancy. The random assignment of exon triplets to these sets helps to mitigate any bias that could arise from overlapping data between training and testing phases.\n\nThe distribution of the datasets in this study is comparable to previously published machine learning datasets in the context of exon splicing. The use of a relatively small but high-confidence set of unchanged exons for training is justified by the highly selective effect of the compound BPN-15477 on splicing, where only 0.58% of expressed exon triplets are differentially spliced upon drug treatment. This approach ensures that the model is trained on robust and reliable data, which is crucial for achieving high performance metrics such as the AUC value.\n\nTo further validate the model's performance, additional analyses were conducted using all available exon triplets with PSI (Percent Spliced In) values between 0.01 and 0.99 before or after treatment. This comprehensive evaluation helps to provide a more realistic estimation of the model's false discovery rate and its applicability in real-life usage scenarios. The groups defined for this evaluation included triplets with PSI changes greater than or equal to 0.01 (true inclusion response), less than or equal to -0.01 (true exclusion response), and the remaining triplets as the true unchanged group. These groups contained 5.70%, 14.08%, and 80.22% of the 18,766 exon triplets, respectively.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used in our study is a Convolutional Neural Network (CNN). This class of algorithms is well-established and widely used, particularly in tasks involving sequence data and image recognition.\n\nThe specific CNN architecture employed in our research is not entirely novel, as it builds upon existing CNN structures that have proven effective in similar biological sequence analysis tasks. However, the application of this architecture to predict splicing responses to specific drug treatments, such as BPN-15477, is innovative within the context of our study.\n\nThe reason this work was not published in a machine-learning journal is that the primary focus of our research is on the biological implications and therapeutic potential of the predictions made by the CNN. The development and optimization of the CNN model serve as a means to achieve these biological insights. Our study emphasizes the identification of gene targets for BPN-15477 and the validation of these predictions in relevant cellular patient models, rather than the intricacies of the machine-learning algorithm itself. Therefore, the biological significance and potential clinical applications of our findings are the central themes of our publication.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It is a convolutional neural network (CNN) designed to predict the treatment responses of exon triplets to a specific drug. The CNN does not use data from other machine-learning algorithms as input. Instead, it directly processes sequence data around the splice sites of exon triplets.\n\nThe CNN architecture includes multiple convolutional layers followed by rectified linear unit (ReLU) activation layers and max pooling layers. After two rounds of convolution, the output is connected to a hidden layer with a 90% dropout rate to prevent overfitting. The final output is a vector of three values, representing the probabilities of three different treatment responses (inclusion, exclusion, and unchanged). These probabilities are mapped to values between 0 and 1 using a sigmoid nonlinearity.\n\nThe training process involves measuring the average area-under-curve (AUC) on the validation set across the prediction of the three treatment responses. The training and validation loss are measured using binary cross-entropy. The training process stops if there is no improvement in the average AUC for 10 consecutive epochs, which helps to avoid overfitting. In this study, the training stopped at the 12th epoch.\n\nTo ensure the robustness and reproducibility of the model, it was retrained 1,000 times using random initialization. The correlation between the motifs derived from these randomly initiated models and the original model was tested, confirming the stability and robustness of the CNN even when trained on a relatively small sample size.\n\nThe training and testing data are completely separate, which is explicitly stated in the results section. This separation ensures that the model's performance is evaluated on unseen data, providing a more reliable assessment of its generalizability.",
  "optimization/encoding": "For each exon triplet, sequences from four regions (UI1, I1X, XI2, and I2D) were used. Each of these regions consisted of 25 base pairs (bp) of exonic sequence and 75 bp of intronic sequence, resulting in a total of 400 bp per region. These sequences were concatenated and then one-hot encoded into an input matrix with dimensions of 4 \u00d7 400. This encoding process transformed the nucleotide sequences into a format suitable for input into the convolutional neural network (CNN).\n\nThe first round of convolution was applied using fifty 4 \u00d7 5 weight matrices, converting the input matrix into a 50 \u00d7 396 convoluted matrix. Each row of this matrix represents the convolution of one weight matrix with the input data. This process was followed by a rectified linear unit (ReLU) activation function and a max pooling stage, which took the maximum value from each pair of adjacent positions in each row, thereby shrinking the output matrix to a size of 50 \u00d7 198.\n\nA second round of convolution was then applied, using fifty 4 \u00d7 2 weight matrices, followed by the same ReLU transformation and max pooling as in the first round. The output from this second convolution was converted into a 1 \u00d7 500 matrix to initiate the hidden layer. In the hidden layer, a fully connected network was built with a 90% dropout rate to prevent overfitting. The output from the hidden layer was again transformed using the ReLU activation function and then linearly transformed into a vector of three values, representing three different treatment responses. Finally, a sigmoid nonlinearity was applied to map each element in the vector to a value between 0 and 1, indicating the probability of drug responsiveness.\n\nThe training process involved measuring the average area-under-curve (AUC) on the validation set across the prediction of three treatment responses. Training and validation loss were measured using binary cross-entropy. The training process was stopped if there was no improvement in the average AUC for 10 consecutive epochs, with the process stopping at the 12th epoch to avoid overfitting.",
  "optimization/parameters": "The model employs a convolutional neural network (CNN) architecture with specific layers and parameters designed to predict drug responsiveness. The initial convolutional layer applies fifty 4 \u00d7 2 weight matrices, followed by a rectified linear unit (ReLU) activation function and a max pooling layer that shrinks the output matrix. This process is repeated in a second round of convolution, maintaining the same structure. The output is then converted into a 1 \u00d7 500 matrix, which initiates the hidden layer. This hidden layer is fully connected and utilizes a 90% dropout rate to prevent overfitting. The output from the hidden layer undergoes another ReLU transformation and is linearly transformed into a vector of three values, representing three different treatment responses. Finally, a sigmoid nonlinearity maps each element in the vector to a value between 0 and 1, indicating the probability of drug responsiveness.\n\nThe selection of parameters, such as the number of filters in the convolutional layers and the dropout rate, was empirically determined to optimize model performance. The use of fifty filters in each convolutional layer was chosen based on experimentation and validation to ensure that the model could effectively capture relevant features from the input data. The dropout rate of 90% in the hidden layer was selected to balance between preventing overfitting and maintaining the model's capacity to learn from the data. Additionally, techniques such as L1-regularization were applied during training to further enhance the model's robustness and generalization capabilities. The training process was monitored using metrics like the area under the curve (AUC) and binary cross-entropy loss, with the training stopped at the 12th epoch to avoid overfitting.",
  "optimization/features": "The input features for the CNN model consist of sequences from four regions: UI1, I1X, XI2, and I2D. Each of these regions includes 25 base pairs (bp) of exonic sequence and 75 bp of intronic sequence, resulting in a total of 400 bp per region. These sequences are concatenated and one-hot encoded into an input matrix with a size of 4 \u00d7 400.\n\nFeature selection was not explicitly performed in the traditional sense. Instead, the model relies on the convolutional layers to automatically learn and select relevant features from the input sequences. The first convolutional layer applies fifty 4 \u00d7 5 weight matrices to the input matrix, converting it into a 50 \u00d7 396 convoluted matrix. This process effectively identifies and extracts important patterns and motifs from the input sequences.\n\nThe training, validation, and test sets were assigned randomly using a seed, ensuring that the feature extraction process was consistent across these sets. This approach helps to mitigate overfitting and ensures that the model generalizes well to unseen data. The model's architecture and training procedure are designed to handle the high-dimensional input data efficiently, focusing on the most relevant features for predicting treatment responses.",
  "optimization/fitting": "The fitting method employed in our study utilized a convolutional neural network (CNN) with a significant number of parameters relative to the training dataset. The model architecture included multiple convolutional layers followed by max pooling, a hidden layer with a dropout rate of 90%, and a final output layer with a sigmoid nonlinearity to map probabilities of drug responsiveness.\n\nGiven the relatively small training dataset, consisting of only a few hundred exons in each category, the model's complexity could indeed lead to overfitting. To mitigate this risk, several strategies were implemented. Firstly, L1 regularization with a coefficient of 0.6 was applied in the convolutional layers to penalize large weights and encourage sparsity. Secondly, a dropout strategy was used in the hidden layer to randomly set a fraction of the input units to zero during training, which helps prevent the model from becoming too reliant on any single feature. These techniques contributed to the model converging quickly, within twelve epochs, as shown in Supplementary Fig. 2b.\n\nTo further ensure the robustness and reproducibility of the model, we conducted additional analyses. The model was retrained 1,000 times using random initializations, and the AUC distribution across these models was investigated for each class. This approach demonstrated high consistency in performance metrics, indicating that the discovered motifs were reproducible across different initializations. Additionally, a high correlation was found between the top motifs derived from these random-initiated models and the original CNN model, as depicted in Supplementary Fig. 2e.\n\nTo address the potential for underfitting, the model's performance was evaluated using both AUC and AUPR metrics. The inclusion of AUPR provided a more realistic assessment of the model's performance, especially given the imbalanced nature of the dataset. Furthermore, the model's generalizability was explored by applying it to the entire transcriptome, which included a broader range of exon triplets with varying splice site strengths. This transcriptome-wide evaluation helped to validate the model's ability to generalize beyond the initial training data.\n\nIn summary, while the number of parameters in the CNN is indeed larger than the number of training points, several techniques were employed to rule out overfitting and ensure the model's robustness. These include regularization, dropout, extensive retraining with random initializations, and comprehensive performance evaluations using multiple metrics and datasets.",
  "optimization/regularization": "To prevent overfitting, several techniques were employed during the training of our convolutional neural network (CNN) model. Firstly, L1 regularization was applied to the convolutional layers with a coefficient of 0.6. This technique helps to reduce the complexity of the model by penalizing large weights, which can lead to overfitting. Secondly, a dropout strategy was implemented in the hidden layer with a dropout rate of 90%. Dropout randomly sets a fraction of input units to 0 at each update during training time, which helps to prevent overfitting by ensuring that the model does not become too reliant on any single neuron. These techniques contributed to the model's ability to converge quickly, within twelve epochs, even when trained on a small sample size. Additionally, the model's robustness was further validated through retraining with random initializations, demonstrating consistent performance and motif identification across different model instances.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule used in our study are detailed within the manuscript. Specifically, the architecture of our convolutional neural network (CNN) is described, including the use of fifty filters in each convolution layer, rectified linear unit (ReLU) activation, and max pooling layers. The hidden layer employs a 90% dropout rate to prevent overfitting. The training process was monitored using the area under the curve (AUC) on the validation set, and training was stopped at the 12th epoch to avoid overfitting.\n\nThe model files and optimization parameters are not directly provided in the manuscript but can be inferred from the described methods. For instance, the use of L1-regularization with a coefficient of 0.6 in the convolutional layers and the dropout strategy in the hidden layer are mentioned as techniques to avoid overfitting. The training process involved measuring the average AUC and binary cross-entropy loss on both the training and validation sets.\n\nRegarding the availability and licensing of these configurations, the manuscript does not specify where the exact model files or optimization parameters can be accessed. However, the methods and hyper-parameters are thoroughly described, allowing for replication of the study's findings. For detailed implementation, readers are encouraged to refer to the supplementary materials and the methods section of the paper.",
  "model/interpretability": "The model employed in this study is a convolutional neural network (CNN), which is inherently a black-box model due to its complex, multi-layered architecture. However, efforts have been made to enhance its interpretability and transparency.\n\nTo understand the model's decisions, several analyses were conducted. First, the contribution of specific motifs to the model's predictions was examined. By zeroing out the activation of each motif in the first convolutional layer and observing the changes in the area under the curve (AUC), it was possible to identify which motifs significantly contributed to the model's performance. This approach revealed that thirteen motifs explained 92.62% of the AUC, with nine of these motifs being previously reported as significant.\n\nAdditionally, the positional importance of these motifs was investigated. By analyzing the activation patterns of the first layer, it was found that certain motifs, particularly around the 5' splice site, played a crucial role in determining the treatment response. This positional analysis provided insights into the sequence patterns that the model deemed important.\n\nTo further validate the model's reproducibility and robustness, it was retrained 1000 times using random initialization. The performance of these models was tightly distributed and aligned with the original model, indicating that the model's behavior was consistent and not due to random noise.\n\nMoreover, in silico saturation mutagenesis was performed to understand the contribution of individual bases to the model's predictions. This method involved mutating each position in the input sequence to the other three alternative nucleotides and observing the changes in the model's loss. The results showed distinct activation patterns among sequences, particularly in proximity to the 5' splice sites of the middle exons.\n\nThese analyses collectively enhance the interpretability of the CNN model, providing a clearer understanding of the sequence features and motifs that influence its predictions. While the model remains a black-box to some extent, these interpretability techniques offer valuable insights into its decision-making process.",
  "model/output": "The model is a classification model designed to predict drug responsiveness based on treatment responses. It processes input data through two rounds of convolution, each consisting of fifty filters, followed by a rectified linear unit (ReLU) activation layer and a max pooling layer of size 2. After these convolutional stages, the output is converted into a 1 \u00d7 500 matrix to initiate the hidden layer. This hidden layer is fully connected with a 90% dropout rate to prevent overfitting. The output from the hidden layer undergoes another ReLU transformation and is then linearly transformed into a vector of three values, each representing a different treatment response: inclusion, exclusion, or unchanged. The final sigmoid nonlinearity maps these values to probabilities between 0 and 1, indicating the likelihood of drug responsiveness for each class.\n\nThe model's performance is evaluated using metrics such as the area under the receiver operating characteristic curve (ROC-AUC) and the area under the precision-recall curve (PR-AUC). These metrics are calculated for each of the three treatment responses. The training process includes measuring the average AUC on the validation set across the predictions of the three treatment responses and monitoring the training and validation loss in terms of binary cross-entropy. The training stops if there is no improvement in the average AUC over 10 consecutive epochs, with the process halting at the 12th epoch to avoid overfitting.\n\nThe model's output is further analyzed to determine the final drug response by standardizing the raw prediction scores. For each class, a cutoff representing 95% specificity is identified on the validation set. This ensures that the model's predictions are reliable and that the probabilities of drug responsiveness are accurately reflected. The model's performance is also examined transcriptome-wide, using exon triplets with specific percent spliced-in (PSI) changes to define true inclusion, exclusion, and unchanged responding groups. This comprehensive evaluation ensures that the model's predictions are robust and generalizable.",
  "model/duration": "The training process for the convolutional neural network (CNN) model was monitored using the average area-under-curve (AUC) on the validation set across the prediction of three treatment responses. The training and validation loss, measured in terms of binary cross-entropy, were also tracked. The training process was designed to stop if there was no improvement in the average AUC for 10 consecutive epochs. In this study, the training process was halted at the 12th epoch to prevent overfitting.\n\nThe model's performance was evaluated transcriptome-wide by examining all exon triplets with a percent-spliced-in (PSI) value between 0.01 and 0.99 either before or after treatment. The model's predictions were assessed using ROC-AUC and PR-AUC metrics. Additionally, the contribution of different motifs to the classification was examined by setting the output of specific motifs to zero in the first convolutional layer and observing the change in AUC. This process was repeated for all motifs to identify true and top contributors to drug response prediction.\n\nTo ensure the robustness of the model, random initialization was used by generating initial parameters from 1000 different seeds. Each set of initial parameters was used to train a CNN model with the same structure, and the training, validation, and test rules were consistent across all models. This approach resulted in the training of 1000 random CNN models alongside the original model. For each model, the AUC for each class was calculated to assess performance.\n\nThe positional importance of each motif was investigated by averaging the first layer activation of the same position across all sequences and transforming these positional average activations into z-scores. This analysis provided insights into the contribution of each motif to the classification process.\n\nIn silico saturation mutagenesis was performed by mutating each position in a given input sequence to the other three alternative nucleotides. The loss of the model using the mutated sequences was compared to the loss derived from the original sequence, and the maximum change in loss at each position was recorded. Nucleotides were drawn proportionally to the change in loss, with a minimum height of 0.25.\n\nTo determine the final drug response, the raw prediction score from the model was standardized. For each class, a cutoff representing 95% specificity was identified on the validation set. This cutoff was used to classify the drug response as inclusion, exclusion, or unchanged.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "The evaluation of our convolutional neural network (CNN) model involved several key steps to ensure its robustness and generalizability. Initially, the model was trained on a dataset consisting of 178 inclusion-responsive, 476 exclusion-responsive, and 268 unchanged exon triplets. These triplets were randomly assigned to training, validation, and test sets using a seed in Python to ensure reproducibility. The training set was used to optimize the model parameters, while the validation set was employed to tune hyperparameters and prevent overfitting. The test set, which included 25 inclusion-responsive, 68 exclusion-responsive, and 38 unchanged exon triplets, was used to evaluate the final performance of the model.\n\nTo assess the model's performance, we utilized the area under the receiver operating characteristic curve (ROC-AUC). This metric provided a comprehensive evaluation of the model's ability to distinguish between different types of exon triplets. Additionally, we applied the Benjamini-Hochberg false discovery rate (BH FDR) correction to the p-values obtained from the Cochran\u2013Mantel\u2013Haenszel test for each exon triplet, ensuring the statistical significance of our findings.\n\nWe also addressed concerns about the potential overfitting of the model by explicitly stating that the training and testing datasets were separate. Furthermore, we implemented L1-regularization and dropout strategies during training to mitigate overfitting and enhance the model's generalization capabilities. These techniques helped the model converge quickly and perform well on a small sample size.\n\nTo provide a more realistic evaluation of the model's performance, we applied it to the entire transcriptome. We analyzed all exon triplets with a percent-spliced-in (PSI) value between 0.01 and 0.99 before or after treatment. We defined \"true inclusion response\" and \"true exclusion response\" groups based on PSI changes after treatment and evaluated the model's predictions at various cutoffs. This approach allowed us to assess the model's performance in a more realistic scenario, matching the real-life usage of the model.\n\nAdditionally, we considered the generalizability of our model to other splicing-modulating compounds. While we focused on creating the model and validating its predictions for BPN-15477 in this study, we acknowledged the importance of extending the model to other compounds. This will be a critical area of future exploration, as it will enhance the model's potential impact and applicability.",
  "evaluation/measure": "The performance of our convolutional neural network (CNN) model was primarily evaluated using the ROC-AUC metric. Specifically, we reported ROC-AUC values of 0.70, 0.67, and 0.67 for inclusion, exclusion, and unchanged predictions, respectively. These metrics indicate the model's ability to distinguish between different types of splicing events induced by the treatment.\n\nWhile ROC-AUC is a standard metric in the literature for evaluating binary classifiers, we also acknowledged the importance of considering other metrics, particularly in the context of imbalanced datasets. One reviewer highlighted that the use of a small negative exon set could inflate the performance metrics and make them unrealistic. In response, we conducted additional analyses using all available exon triplets, providing a more comprehensive evaluation of the model's performance.\n\nWe defined groups based on percent-spliced-in (PSI) changes after treatment, categorizing triplets into true inclusion, true exclusion, and true unchanged groups. This approach allowed us to assess the model's performance in a more realistic scenario, matching the real-life usage of the model.\n\nAdditionally, we addressed concerns about the potential overfitting of the model by explicitly stating that the training and testing datasets were separate. We also discussed potential mechanistic explanations for the model's robust performance, such as the focus on a short region flanking the 5\u2019 splice site of the middle exon and the use of regularization techniques to avoid overfitting.\n\nIn summary, while our primary performance metric was ROC-AUC, we recognized the need for a more nuanced evaluation, especially in the context of imbalanced datasets. Our responses to reviewer comments reflect this understanding, and we have taken steps to provide a more representative assessment of the model's performance.",
  "evaluation/comparison": "A comparison to simpler baselines was performed. The CNN model's performance was evaluated against a random classifier, demonstrating that the model's results were highly significant. This comparison was included in the methods and Supplementary Figure 2c. Additionally, the model's performance was assessed using ROC-AUC and PR-AUC values across the entire transcriptome, providing a comprehensive evaluation of its predictive capabilities. The training and validation processes were carefully monitored to prevent overfitting, with the training stopping at the 12th epoch to avoid this issue. The model's robustness was further supported by its ability to converge quickly on a small sample size, aided by L1-regularization and dropout strategies. These evaluations highlight the model's effectiveness and reliability in predicting drug responsiveness.",
  "evaluation/confidence": "The evaluation of our model includes several statistical measures to ensure the confidence and significance of our results. For the Pearson correlation, the gray zone in the plots indicates 95% confidence intervals, providing a visual representation of the variability and reliability of the correlation estimates.\n\nIn our splicing strength comparisons, we used two-tailed Welch\u2019s t-tests to compare the maximum entropy among inclusion, exclusion, and unchanged groups at each splice junction. This statistical test is robust and accounts for unequal variances, ensuring that our comparisons are valid and reliable.\n\nFor the boxplots, the middle lines inside the boxes indicate the medians, while the lower and upper hinges correspond to the first and third quartiles. Each box extends to 1.5 times the inter-quartile range (IQR) from the upper and lower hinges, respectively. This visualization helps in understanding the distribution and variability of the data. Outliers were not shown to maintain clarity.\n\nIn all plots, error bars indicate \u00b1 standard deviation (SD) from mean values, providing a measure of the data's dispersion and the precision of the estimates. Significance levels are marked by *p < 0.05, **p < 0.01, and ***p < 0.001, ensuring that our findings are statistically significant and not due to random chance.\n\nThe performance of our CNN model was evaluated using ROC-AUC metrics, which yielded values of 0.70, 0.67, and 0.67 for inclusion, exclusion, and unchanged predictions, respectively. These metrics are highly significant compared to a random classifier, demonstrating the model's superior performance.\n\nAdditionally, we addressed concerns about the size of the negative exon set by evaluating the CNN model using all available exon triplets. This approach provides a more realistic estimation of the model's performance and applicability in real-life scenarios. The results from these analyses were included in the methods and supplementary figures, ensuring transparency and thorough evaluation.\n\nIn summary, our evaluation includes robust statistical methods, confidence intervals, and significance testing, ensuring that our claims about the model's superiority are well-supported and reliable.",
  "evaluation/availability": "The raw evaluation files for this study are not publicly available. The data generated and analyzed during the current study are available from the corresponding author on reasonable request. This approach ensures that the data can be shared with other researchers while maintaining control over its distribution and use. The decision to not publicly release the raw evaluation files is in line with the policies of the journal and the institution, which prioritize data security and privacy. Researchers interested in accessing the data for further analysis or validation of the results can contact the corresponding author to discuss the terms of data sharing. The corresponding author will evaluate each request on a case-by-case basis, considering the purpose of the request, the qualifications of the requester, and the potential impact on the confidentiality and security of the data. The data will be shared under a non-disclosure agreement to protect the intellectual property rights of the authors and the institution. The corresponding author will also provide guidance on the appropriate use of the data and the citation of the original study. This approach promotes transparency and reproducibility in research while ensuring the responsible use of the data."
}