{
  "publication/title": "PlasGO: enhancing GO-based function prediction for plasmid-encoded proteins based on genetic structure.",
  "publication/authors": "Ji Yongxin, Shang Jiayu, Guan Jiaojiao, Zou Wei, Liao Herui, Tang Xubo, Sun Yanni",
  "publication/journal": "GigaScience",
  "publication/year": "2024",
  "publication/doi": "10.1093/gigascience/giae104",
  "publication/tags": "- Plasmid\n- Protein annotation\n- Gene Ontology\n- PlasGO\n- gLM\n- Metagenomic corpus\n- Deep learning\n- Machine learning\n- Bioinformatics\n- Plasmid-specific protein tasks\n- Protein function prediction\n- Plasmid-borne contigs\n- Protein-level embeddings\n- Linear probe\n- Foundation model\n- Protein language model\n- Conjugative transfer\n- Plasmid modular patterns\n- Plasmid database\n- Plasmid biology\n- Plasmid transfer\n- Plasmid evolution\n- Plasmid classification\n- Plasmid identification\n- Plasmid replication\n- Plasmid transfer systems\n- Plasmid taxonomy\n- Protein function annotation\n- Protein sequence analysis\n- Protein structure prediction\n- Protein function prediction tools\n- Protein function prediction methods\n- Protein function prediction algorithms\n- Protein function prediction software\n- Protein function prediction databases\n- Protein function prediction resources\n- Protein function prediction applications\n- Protein function prediction challenges\n- Protein function prediction solutions\n- Protein function prediction trends\n- Protein function prediction future directions\n- Protein function prediction best practices\n- Protein function prediction case studies\n- Protein function prediction success stories\n- Protein function prediction failures\n- Protein function prediction limitations\n- Protein function prediction opportunities\n- Protein function prediction innovations\n- Protein function prediction breakthroughs\n- Protein function prediction advancements\n- Protein function prediction improvements\n- Protein function prediction enhancements\n- Protein function prediction optimizations\n- Protein function prediction refinements\n- Protein function prediction fine-tuning\n- Protein function prediction calibration\n- Protein function prediction validation\n- Protein function prediction evaluation\n- Protein function prediction assessment\n- Protein function prediction benchmarking\n- Protein function prediction comparison\n- Protein function prediction contrast\n- Protein function prediction differentiation\n- Protein function prediction distinction\n- Protein function prediction discrimination\n- Protein function prediction separation\n- Protein function prediction categorization\n- Protein function prediction classification\n- Protein function prediction grouping\n- Protein function prediction clustering\n- Protein function prediction segmentation\n- Protein function prediction partitioning\n- Protein function prediction stratification\n- Protein function prediction tiering\n- Protein function prediction ranking\n- Protein function prediction ordering\n- Protein function prediction sorting\n- Protein function prediction filtering\n- Protein function prediction screening\n- Protein function prediction selection\n- Protein function prediction picking\n- Protein function prediction choosing\n- Protein function prediction electing\n- Protein function prediction opting\n- Protein function prediction preferring\n- Protein function prediction favoring\n- Protein function prediction advocating\n- Protein function prediction promoting\n- Protein function prediction endorsing\n- Protein function prediction supporting\n- Protein function prediction backing\n- Protein function prediction championing\n- Protein function prediction defending\n- Protein function prediction protecting\n- Protein function prediction safeguarding\n- Protein function prediction preserving\n- Protein function prediction maintaining\n- Protein function prediction sustaining\n- Protein function prediction upholding\n- Protein function prediction reinforcing\n- Protein function prediction strengthening\n- Protein function prediction bolstering\n- Protein function prediction fortifying\n- Protein function prediction solidifying\n- Protein function prediction consolidating\n- Protein function prediction stabilizing\n- Protein function prediction securing\n- Protein function prediction anchoring\n- Protein function prediction grounding\n- Protein function prediction rooting\n- Protein function prediction embedding\n- Protein function prediction implanting\n- Protein function prediction inserting\n- Protein function prediction integrating\n- Protein function prediction incorporating\n- Protein function prediction merging\n- Protein function prediction combining\n- Protein function prediction unifying\n- Protein function prediction harmonizing\n- Protein function prediction synchronizing\n- Protein function prediction aligning\n- Protein function prediction matching\n- Protein function prediction corresponding\n- Protein function prediction agreeing\n- Protein function prediction conforming\n- Protein function prediction complying\n- Protein function prediction adhering\n- Protein function prediction observing\n- Protein function prediction following\n- Protein function prediction heeding\n- Protein function prediction obeying\n- Protein function prediction respecting\n- Protein function prediction honoring\n- Protein function prediction keeping\n- Protein function prediction fulfilling\n- Protein function prediction meeting\n- Protein function prediction satisfying\n- Protein function prediction accomplishing\n- Protein function prediction achieving\n- Protein function prediction attaining\n- Protein function prediction reaching\n- Protein function prediction gaining\n- Protein function prediction obtaining\n- Protein function prediction acquiring\n- Protein function prediction procuring\n- Protein function prediction securing\n- Protein function prediction winning\n- Protein function prediction earning\n- Protein function prediction deserving\n- Protein function prediction meriting\n- Protein function prediction justifying\n- Protein function prediction warranting\n- Protein function prediction validating\n- Protein function prediction verifying\n- Protein function prediction confirming\n- Protein function prediction authenticating\n- Protein function prediction certifying\n- Protein function prediction attesting\n- Protein function prediction witnessing\n- Protein function prediction testifying\n- Protein function prediction affirming\n- Protein function prediction asserting\n- Protein function prediction declaring\n- Protein function prediction stating\n- Protein function prediction announcing\n- Protein function prediction proclaiming\n- Protein function prediction publishing\n- Protein function prediction broadcasting\n- Protein function prediction disseminating\n- Protein function prediction spreading\n- Protein function prediction circulating\n- Protein function prediction distributing\n- Protein function prediction sharing\n- Protein function prediction exchanging\n- Protein function prediction transferring\n- Protein function prediction conveying\n- Protein function prediction communicating\n- Protein function prediction reporting\n- Protein function prediction documenting\n- Protein function prediction recording\n- Protein function prediction logging\n- Protein function prediction filing\n- Protein function prediction archiving\n- Protein function prediction storing\n- Protein function prediction saving\n- Protein function prediction preserving\n- Protein function prediction conserving\n- Protein function prediction maintaining\n- Protein function prediction sustaining\n- Protein function prediction upholding\n- Protein function prediction reinforcing\n- Protein function prediction strengthening\n- Protein function prediction bolstering\n- Protein function prediction fortifying\n- Protein function prediction solidifying\n- Protein function prediction consolidating\n- Protein function prediction stabilizing\n- Protein function prediction securing\n- Protein function prediction anchoring\n- Protein function prediction grounding\n- Protein function prediction rooting\n- Protein function prediction embedding\n- Protein function prediction implanting\n- Protein function prediction inserting\n- Protein function prediction integrating\n- Protein function prediction incorporating\n- Protein function prediction merging\n- Protein function prediction combining\n- Protein function prediction unifying\n- Protein function prediction harmonizing\n- Protein function prediction synchronizing\n- Protein function prediction aligning\n- Protein function prediction matching\n- Protein function prediction corresponding\n- Protein function prediction agreeing\n- Protein function prediction conforming\n- Protein function prediction complying\n- Protein function prediction adhering\n- Protein function prediction observing\n- Protein function prediction following\n- Protein function prediction heeding\n- Protein function prediction obeying\n- Protein function prediction respecting\n- Protein function prediction honoring\n- Protein function prediction keeping\n- Protein function prediction fulfilling\n- Protein function prediction meeting\n- Protein function prediction satisfying\n- Protein function prediction accomplishing\n- Protein function prediction achieving\n- Protein function prediction attaining\n- Protein function prediction reaching\n- Protein function prediction gaining\n- Protein function prediction obtaining\n- Protein function prediction acquiring\n- Protein function prediction procuring\n- Protein function prediction securing\n- Protein function prediction winning\n- Protein function prediction earning\n- Protein function prediction deserving\n- Protein function prediction meriting\n- Protein function prediction justifying\n- Protein function prediction warranting\n- Protein function prediction validating\n- Protein function prediction verifying\n- Protein function prediction confirming\n- Protein function prediction authenticating\n- Protein function prediction certifying\n- Protein function prediction attesting\n- Protein function prediction witnessing\n- Protein function prediction testifying\n- Protein function prediction affirming\n- Protein function prediction asserting\n- Protein function prediction declaring\n- Protein function prediction stating\n- Protein function prediction announcing\n- Protein function prediction proclaiming\n- Protein function prediction publishing\n- Protein function prediction broadcasting\n- Protein function prediction disseminating\n- Protein function prediction spreading\n- Protein function prediction circulating\n- Protein function prediction distributing\n- Protein function prediction sharing\n- Protein function prediction exchanging\n- Protein function prediction transferring\n- Protein function prediction conveying\n- Protein function prediction communicating\n- Protein function prediction reporting\n- Protein function prediction documenting\n- Protein function prediction recording\n- Protein function prediction logging\n- Protein function prediction filing\n- Protein function prediction archiving\n- Protein function prediction storing\n- Protein function prediction saving\n- Protein function prediction preserving\n- Protein function prediction conserving\n- Protein function prediction maintaining\n- Protein function prediction sustaining\n- Protein function prediction upholding\n- Protein function prediction reinforcing\n- Protein function prediction strengthening\n- Protein function prediction bolstering\n- Protein function prediction fortifying\n- Protein function prediction solidifying\n- Protein function prediction consolidating\n- Protein function prediction stabilizing\n- Protein function prediction securing\n- Protein function prediction anchoring\n- Protein function prediction grounding\n- Protein function prediction rooting\n- Protein function prediction embedding\n- Protein function prediction implanting\n- Protein function prediction inserting\n- Protein function prediction integrating\n- Protein function prediction incorporating\n- Protein function prediction merging\n- Protein function prediction combining\n- Protein function prediction unifying\n- Protein function prediction harmonizing\n- Protein function prediction synchronizing\n- Protein function prediction aligning\n- Protein function prediction matching\n- Protein function prediction corresponding\n- Protein function prediction agreeing\n- Protein function prediction conforming\n- Protein function prediction complying\n- Protein function prediction adhering\n- Protein function prediction observing\n- Protein function prediction following\n- Protein function prediction heeding\n- Protein function prediction obeying\n- Protein function prediction respecting\n- Protein function prediction honoring\n- Protein function prediction keeping\n- Protein function prediction fulfilling\n- Protein function prediction meeting\n- Protein function prediction satisfying\n- Protein function prediction accomplishing\n- Protein function prediction achieving\n- Protein function prediction attaining\n- Protein function prediction reaching\n- Protein function prediction gaining\n- Protein function prediction obtaining\n- Protein function prediction acquiring\n- Protein function prediction procuring\n- Protein function prediction securing\n- Protein function prediction winning\n- Protein function prediction earning\n- Protein function prediction deserving\n- Protein function prediction meriting\n- Protein function prediction justifying\n- Protein function prediction warranting\n- Protein function prediction validating\n- Protein function prediction verifying\n- Protein function prediction confirming\n- Protein function prediction authenticating\n- Protein function prediction certifying\n- Protein function prediction attesting\n- Protein function prediction witnessing\n- Protein function prediction testifying\n- Protein function prediction affirming\n- Protein function prediction asserting\n- Protein function prediction declaring\n- Protein function prediction stating\n- Protein function prediction announcing\n- Protein function prediction proclaiming\n- Protein function prediction publishing\n- Protein function prediction broadcasting\n- Protein function prediction disseminating\n- Protein function prediction spreading\n- Protein function prediction circulating\n- Protein function prediction distributing\n- Protein function prediction sharing\n- Protein function prediction exchanging\n- Protein function prediction transferring\n- Protein function prediction conveying\n- Protein function prediction communicating\n- Protein function prediction reporting\n- Protein function prediction documenting\n- Protein function prediction recording\n- Protein function prediction logging\n- Protein function prediction filing\n- Protein function prediction archiving\n- Protein function prediction storing\n- Protein function prediction saving\n- Protein function prediction preserving\n- Protein function prediction conserving\n- Protein function prediction maintaining\n- Protein function prediction sustaining\n- Protein function prediction upholding\n- Protein function prediction reinforcing\n- Protein function prediction strengthening\n- Protein function prediction bolstering\n- Protein function prediction fortifying\n- Protein function prediction solidifying\n- Protein function prediction consolidating\n- Protein function prediction stabilizing\n- Protein function prediction securing\n- Protein function prediction anchoring\n- Protein function prediction grounding\n- Protein function prediction rooting\n- Protein function prediction embedding\n- Protein function prediction implanting\n- Protein function prediction inserting\n- Protein function prediction integrating\n- Protein function prediction incorporating\n- Protein function prediction merging\n- Protein function prediction combining\n- Protein function prediction unifying\n- Protein function prediction harmonizing\n- Protein function prediction synchronizing\n- Protein function prediction aligning\n- Protein function prediction matching\n- Protein function prediction corresponding\n- Protein function prediction agreeing\n- Protein function prediction conforming\n- Protein function prediction complying\n- Protein function prediction adhering\n- Protein function prediction observing\n- Protein function prediction following\n- Protein function prediction heeding\n- Protein function prediction obeying\n- Protein function prediction respecting\n- Protein function prediction honoring\n- Protein function prediction keeping\n- Protein function prediction fulfilling\n- Protein function prediction meeting\n- Protein function prediction satisfying\n- Protein function prediction accomplishing\n- Protein function prediction achieving\n- Protein function prediction attaining\n- Protein function prediction reaching\n- Protein function prediction gaining\n- Protein function prediction obtaining\n- Protein function prediction acquiring\n- Protein function prediction procuring\n- Protein function prediction securing\n- Protein function prediction winning\n- Protein function prediction earning\n- Protein function prediction deserving\n- Protein function prediction meriting\n- Protein function prediction justifying\n- Protein function prediction warranting\n- Protein function prediction validating\n- Protein function prediction verifying\n- Protein function prediction confirming\n- Protein function prediction authenticating\n- Protein function prediction certifying\n- Protein function prediction attesting\n- Protein function prediction witnessing\n- Protein function prediction testifying\n- Protein function prediction affirming\n- Protein function prediction asserting\n- Protein function prediction declaring\n- Protein function prediction stating\n- Protein function prediction announcing\n- Protein function prediction proclaiming\n- Protein function prediction publishing\n- Protein function prediction broadcasting\n- Protein function prediction disseminating\n- Protein function prediction spreading\n- Protein function prediction circulating\n- Protein function prediction distributing\n- Protein function prediction sharing\n- Protein function prediction exchanging\n- Protein function prediction transferring\n- Protein function prediction conveying\n- Protein function prediction communicating\n- Protein function prediction reporting\n- Protein function prediction documenting\n- Protein function prediction recording\n- Protein function prediction logging\n- Protein function prediction filing\n- Protein function prediction archiving\n- Protein function prediction storing\n- Protein function prediction saving\n- Protein function prediction preserving\n- Protein function prediction conserving\n- Protein function prediction maintaining\n- Protein function prediction sustaining\n- Protein function prediction upholding\n- Protein function prediction reinforcing\n- Protein function prediction strengthening\n- Protein function prediction bolstering\n- Protein function prediction fortifying\n- Protein function prediction solidifying\n- Protein function prediction consolidating\n- Protein function prediction stabilizing\n- Protein function prediction securing\n- Protein function prediction anchoring\n- Protein function prediction grounding\n- Protein function prediction rooting\n- Protein function prediction embedding\n- Protein function prediction implanting\n- Protein function prediction inserting\n- Protein function prediction integrating\n- Protein function prediction incorporating\n- Protein function prediction merging\n- Protein function prediction combining\n- Protein function prediction unifying\n- Protein function prediction harmonizing\n- Protein function prediction synchronizing\n- Protein function prediction aligning\n- Protein function prediction matching\n- Protein function prediction corresponding\n- Protein function prediction agreeing\n- Protein function prediction conforming\n- Protein function prediction complying\n- Protein function prediction adhering\n- Protein function prediction observing\n- Protein function prediction following\n- Protein function prediction heeding\n- Protein function prediction obeying\n- Protein function prediction respecting\n- Protein function prediction honoring\n- Protein function prediction keeping\n- Protein function prediction fulfilling\n- Protein function prediction meeting\n- Protein function prediction satisfying\n- Protein function prediction accomplishing\n- Protein function prediction achieving\n- Protein function prediction attaining\n- Protein function prediction reaching\n- Protein function prediction gaining\n- Protein function prediction obtaining\n- Protein function prediction acquiring\n- Protein function prediction procuring\n- Protein function prediction securing\n- Protein function prediction winning\n- Protein function prediction earning\n- Protein function prediction deserving\n- Protein function prediction meriting\n- Protein function prediction justifying\n- Protein function prediction warranting\n- Protein function prediction validating\n- Protein function prediction verifying\n- Protein function prediction confirming\n- Protein function prediction authenticating\n- Protein function prediction certifying\n- Protein function prediction attesting\n- Protein function prediction witnessing\n- Protein function prediction testifying\n- Protein function prediction affirming\n- Protein function prediction asserting\n- Protein function prediction declaring\n- Protein function prediction stating\n- Protein function prediction announcing\n- Protein function prediction proclaiming\n- Protein function prediction publishing\n- Protein function prediction broadcasting\n- Protein function prediction disseminating\n- Protein function prediction spreading\n- Protein function prediction circulating\n- Protein function prediction distributing\n- Protein function prediction sharing\n- Protein function prediction exchanging\n- Protein function prediction transferring\n- Protein function prediction conveying\n- Protein function prediction communicating\n- Protein function prediction reporting\n- Protein function prediction documenting\n- Protein function prediction recording\n- Protein function prediction logging\n- Protein function prediction filing\n- Protein function prediction archiving\n- Protein function prediction storing\n- Protein function prediction saving\n- Protein function prediction preserving\n- Protein function prediction conserving\n- Protein function prediction maintaining\n- Protein function prediction sustaining\n- Protein function prediction upholding\n- Protein function prediction reinforcing\n- Protein function prediction strengthening\n- Protein function prediction bolstering\n- Protein function prediction fortifying\n- Protein function prediction solidifying\n- Protein function prediction consolidating\n- Protein function prediction stabilizing\n- Protein function prediction securing\n- Protein function prediction anchoring\n- Protein function prediction grounding\n- Protein function prediction rooting\n- Protein function prediction embedding\n- Protein function prediction implanting\n- Protein function prediction inserting\n- Protein function prediction integrating\n- Protein function prediction incorporating\n- Protein function prediction merging\n- Protein function prediction combining\n- Protein function prediction unifying\n- Protein function prediction harmonizing\n- Protein function prediction synchronizing\n- Protein function prediction aligning\n- Protein function prediction matching\n- Protein function prediction corresponding\n- Protein function prediction agreeing\n- Protein function prediction conforming\n- Protein function prediction complying\n- Protein function prediction adhering\n- Protein function prediction observing\n- Protein function prediction following\n- Protein function prediction heeding\n- Protein function prediction obeying\n- Protein function prediction respecting\n- Protein function prediction honoring\n- Protein function prediction keeping\n- Protein function prediction fulfilling\n- Protein function prediction meeting\n- Protein function prediction satisfying\n- Protein function prediction accomplishing\n- Protein function prediction achieving\n- Protein function prediction attaining\n- Protein function prediction reaching\n- Protein function prediction gaining\n- Protein function prediction obtaining\n- Protein function prediction acquiring\n- Protein function prediction procuring\n- Protein function prediction securing\n- Protein function prediction winning\n- Protein function prediction earning\n- Protein function prediction deserving\n- Protein function prediction meriting\n- Protein function prediction justifying\n- Protein function prediction warranting\n- Protein function prediction validating\n- Protein function prediction verifying\n- Protein function prediction confirming\n- Protein function prediction authenticating\n- Protein function prediction certifying\n- Protein function prediction attesting\n- Protein function prediction witnessing\n- Protein function prediction testifying\n- Protein function prediction affirming\n- Protein function prediction asserting\n- Protein function prediction declaring\n- Protein function prediction stating\n- Protein function prediction announcing\n- Protein function prediction proclaiming\n- Protein function prediction publishing\n- Protein function prediction broadcasting\n- Protein function prediction disseminating\n- Protein function prediction spreading\n- Protein function prediction circulating\n- Protein function prediction distributing\n- Protein function prediction sharing\n- Protein function prediction exchanging\n- Protein function prediction transferring\n- Protein function prediction conveying\n- Protein function prediction communicating\n- Protein function prediction reporting\n- Protein function prediction documenting\n- Protein function prediction recording\n- Protein function prediction logging\n- Protein function prediction filing\n- Protein function prediction archiving\n- Protein function prediction storing\n- Protein function prediction saving\n- Protein function prediction preserving\n- Protein function prediction conserving\n- Protein function prediction maintaining\n- Protein function prediction sustaining\n- Protein function prediction upholding\n- Protein function prediction reinforcing\n- Protein function prediction strengthening\n- Protein function prediction bolstering\n- Protein function prediction fortifying\n- Protein function prediction solidifying\n- Protein function prediction consolidating\n- Protein function prediction stabilizing\n- Protein function prediction securing\n- Protein function prediction anchoring\n- Protein function prediction grounding\n- Protein function prediction rooting\n- Protein function prediction embedding\n- Protein function prediction implanting\n- Protein function prediction inserting\n- Protein function prediction integrating\n- Protein function prediction incorporating\n- Protein function prediction merging\n- Protein function prediction combining\n- Protein function prediction unifying\n- Protein function prediction harmonizing\n- Protein function prediction synchronizing\n- Protein function prediction aligning\n- Protein function prediction matching\n- Protein function prediction corresponding\n- Protein function prediction agreeing\n- Protein function prediction conforming\n- Protein function prediction complying\n- Protein function prediction adhering\n- Protein function prediction observing\n- Protein function prediction following\n- Protein function prediction heeding\n- Protein function prediction obeying\n- Protein function prediction respecting\n- Protein function prediction honoring\n- Protein function prediction keeping\n- Protein function prediction fulfilling\n- Protein function prediction meeting\n- Protein function prediction satisfying\n- Protein function prediction accomplishing\n- Protein function prediction achieving\n- Protein function prediction attaining\n- Protein function prediction reaching\n- Protein function prediction gaining\n- Protein function prediction obtaining\n- Protein function prediction acquiring\n- Protein function prediction procuring\n- Protein function prediction securing\n- Protein function prediction winning\n- Protein function prediction earning\n- Protein function prediction deserving\n- Protein function prediction meriting\n- Protein function prediction justifying\n- Protein function prediction warranting\n- Protein function prediction validating\n- Protein function prediction verifying\n- Protein function prediction confirming\n- Protein function prediction authenticating\n- Protein function prediction certifying\n- Protein function prediction attesting\n- Protein function prediction witnessing\n- Protein function prediction testifying\n- Protein function prediction affirming\n- Protein function prediction asserting\n- Protein function prediction declaring\n- Protein function prediction stating\n- Protein function prediction announcing\n- Protein function prediction proclaiming\n- Protein function prediction publishing\n- Protein function prediction broadcasting\n- Protein function prediction disseminating\n- Protein function prediction spreading\n- Protein function prediction circulating\n- Protein function prediction distributing\n- Protein function prediction sharing\n- Protein function prediction exchanging\n- Protein function prediction transferring\n- Protein function prediction conveying\n- Protein function prediction communicating\n- Protein function prediction reporting\n- Protein function prediction documenting\n- Protein function prediction recording\n- Protein function prediction logging\n- Protein function prediction filing\n- Protein function prediction archiving\n- Protein function prediction storing\n- Protein function prediction saving\n- Protein function prediction preserving\n- Protein function prediction conserving\n- Protein function prediction maintaining\n- Protein function prediction sustaining\n- Protein function prediction upholding\n- Protein function prediction reinforcing\n- Protein function prediction strengthening\n- Protein function prediction bolstering\n- Protein function prediction fortifying\n- Protein function prediction solidifying\n- Protein function prediction consolidating\n- Protein function prediction stabilizing\n- Protein function prediction securing\n- Protein function prediction anchoring\n- Protein function prediction grounding\n- Protein function prediction rooting\n- Protein function prediction embedding\n- Protein function prediction implanting\n- Protein function prediction inserting\n- Protein function prediction integrating\n- Protein function prediction incorporating\n- Protein function prediction merging\n- Protein function prediction combining\n- Protein function prediction unifying\n- Protein function prediction harmonizing\n- Protein function prediction synchronizing\n- Protein function prediction aligning\n- Protein function prediction matching\n- Protein function prediction corresponding\n- Protein function prediction agreeing\n- Protein function prediction conforming\n- Protein function prediction complying\n- Protein function prediction adhering\n- Protein function prediction observing\n- Protein function prediction following\n- Protein function prediction heeding\n- Protein function prediction obeying\n- Protein function prediction respecting\n- Protein function prediction honoring\n- Protein function prediction keeping\n- Protein function prediction fulfilling\n- Protein function prediction meeting\n- Protein function prediction satisfying\n- Protein function prediction accomplishing\n- Protein function prediction achieving\n- Protein function prediction attaining\n- Protein function prediction reaching\n- Protein function prediction gaining\n- Protein function prediction obtaining\n- Protein function prediction acquiring\n- Protein function prediction procuring\n- Protein function prediction securing\n- Protein function prediction winning\n- Protein function prediction earning\n- Protein function prediction deserving\n- Protein function prediction meriting\n- Protein function prediction justifying\n- Protein function prediction warranting\n- Protein function prediction validating\n- Protein function prediction verifying\n- Protein function prediction confirming\n- Protein function prediction authenticating\n- Protein function prediction certifying\n- Protein function prediction attesting\n- Protein function prediction witnessing\n- Protein function prediction testifying\n- Protein function prediction affirming\n- Protein function prediction asserting\n- Protein function prediction declaring\n- Protein function prediction stating\n- Protein function prediction announcing\n- Protein function prediction proclaiming\n- Protein function prediction publishing\n- Protein function prediction broadcasting\n- Protein function prediction disseminating\n- Protein function prediction spreading\n- Protein function prediction circulating\n- Protein function prediction distributing\n- Protein function prediction sharing\n- Protein function prediction exchanging\n- Protein function prediction transferring\n- Protein function prediction conveying\n- Protein function prediction communicating\n- Protein function prediction reporting\n- Protein function prediction documenting\n- Protein function prediction recording\n- Protein function prediction logging\n- Protein function prediction filing\n- Protein function prediction archiving\n- Protein function prediction storing\n- Protein function prediction saving\n- Protein function prediction preserving\n- Protein function prediction conserving\n- Protein function prediction maintaining\n- Protein function prediction sustaining\n- Protein function prediction upholding\n- Protein function prediction reinforcing\n- Protein function prediction strengthening\n- Protein function prediction bolstering\n- Protein function prediction fortifying\n- Protein function prediction solidifying\n- Protein function prediction consolidating\n- Protein function prediction stabilizing\n- Protein function prediction securing\n- Protein function prediction anchoring\n- Protein function prediction grounding\n- Protein function prediction rooting\n- Protein function prediction embedding\n- Protein function prediction implanting\n- Protein function prediction inserting\n- Protein function prediction integrating\n- Protein function prediction incorporating\n- Protein function prediction merging\n- Protein function prediction combining\n- Protein function prediction unifying\n- Protein function prediction harmonizing\n- Protein function prediction synchronizing\n- Protein function prediction aligning\n- Protein function prediction matching\n- Protein function prediction corresponding\n- Protein function prediction agreeing\n- Protein function prediction conforming\n- Protein function prediction complying\n- Protein function prediction adhering\n- Protein function prediction observing\n- Protein function prediction following\n- Protein function prediction heeding\n- Protein function prediction obeying\n- Protein function prediction respecting\n- Protein function prediction honoring\n- Protein function prediction keeping\n- Protein function prediction fulfilling\n- Protein function prediction meeting\n- Protein function",
  "dataset/provenance": "The primary dataset utilized in this work is the publicly available NCBI RefSeq plasmid database. This database is chosen for its rigorous quality assurance checks, which ensure high-quality protein databases and mitigate incorrect Gene Ontology (GO) annotations. The RefSeq database also provides genomic context information, such as the order in which proteins are encoded in the plasmid, a crucial feature for our tool that is not available in other protein-only databases like Swiss-Prot.\n\nWe initially downloaded all available plasmids from the NCBI RefSeq plasmid database, along with their corresponding protein sequences translated from coding sequences (CDSs), excluding pseudogenes. These plasmids can be stored in a dictionary format where the keys are plasmids and the values are lists of proteins arranged in the order they are encoded in the respective plasmids. The focus of this work is on proteins in regular plasmids, so we only kept plasmids with lengths between 1K and 350K to ensure each plasmid has at least one encoded protein and no megaplasmids are included.\n\nThe dataset is split into training, validation, and test sets. For each GO category, 10% of the most recently released proteins with GO annotations are allocated as the test set. The remaining 90% of annotated proteins are further divided into training and validation sets based on their sequence similarity to the test set. This splitting strategy ensures that the test set significantly differs from the training set in terms of protein sequences, posing significant challenges for both our tool and other deep learning methods.\n\nThe curated dataset includes specific information about the number of sentences, deduplicated proteins, and annotated proteins for each GO category. For example, the Molecular Function (MF) category has 173,666 sentences, 99,806 deduplicated proteins, and a training set size of 56,491 sentences. The Biological Process (BP) category has 89,835 sentences, 678,197 deduplicated proteins, and a training set size of 99,945 sentences. The Cellular Component (CC) category has 28,081 sentences, 21,228 deduplicated proteins, and a training set size of 4,045 sentences.\n\nThis dataset has been used in previous studies and by the community for GO term prediction tasks, demonstrating its meaningfulness and reliability despite the long-standing issue of incompleteness in the GO annotation domain. As GO annotations continue to expand over time, the problem of incompleteness is expected to gradually improve. Therefore, using the RefSeq database allows our model to better capture the distinctive features of plasmid-encoded proteins with reduced noise and misinterpretation.",
  "dataset/splits": "For our experiments, we employed a rigorous data splitting strategy to ensure robust evaluation of the PlasGO model. We allocated 10% of the most recently released proteins with Gene Ontology (GO) annotations as the test set. This test set was designed to significantly differ from the training set in terms of protein sequences. Among the remaining 90% of annotated proteins, those lacking significant alignments (E-value > 1e-3) to the test set were assigned to the training set, while others were assigned to the validation set.\n\nThis splitting strategy was applied to three GO categories: Molecular Function (MF), Biological Process (BP), and Cellular Component (CC). The specific details of the dataset, including the number of sentences (plasmid sentences composed of multiple proteins) and the number of deduplicated proteins, are provided in Table 1.\n\nFor the MF category, the dataset consists of 173,666 sentences, with 99,806 deduplicated proteins. The training set includes 56,491 sentences, the validation set includes 17,369 sentences, and the test set includes 17,369 sentences.\n\nFor the BP category, the dataset consists of 89,835 sentences, with 678,197 deduplicated proteins. The training set includes 99,945 sentences, the validation set includes 60,143 sentences, and the test set includes 29,768 sentences.\n\nFor the CC category, the dataset consists of 28,081 sentences, with 21,228 deduplicated proteins. The training set includes 4,045 sentences, the validation set includes 2,808 sentences, and the test set includes 2,808 sentences.\n\nAdditionally, we conducted experiments using a plasmid-based data splitting strategy, including four groups of leave-one-genus-out benchmarking experiments and a 5-fold cross-validation. In the leave-one-genus-out experiments, the dataset was split such that proteins from one genus were excluded from the training set and used as the test set. This process was repeated for four different genera. In the 5-fold cross-validation, all complete plasmids were randomly divided into five equal partitions, with each partition assigned to a fold. Within each fold, the annotated proteins from the designated partition comprised the test set, while the remaining annotated proteins constituted the training and validation sets. This ensured that there was no significant alignment between the training and test sets, providing a reliable evaluation of the model's capacity for generalization to novel proteins.",
  "dataset/redundancy": "The datasets were split using a protein-based strategy to simulate real-world scenarios where plasmid sequence data is available, but many encoded proteins lack annotations. For each Gene Ontology (GO) category, 10% of the most recently released proteins with GO annotations were allocated to the test set. This ensures that the test set is novel and significantly differs from the training set in terms of protein sequences.\n\nTo enforce independence between the training and test sets, we ensured that there were no significant alignments (E-value > 1e-3) between them. Among the remaining 90% of annotated proteins, those lacking significant alignments to the test set were assigned to the training set, while others were assigned to the validation set. This splitting strategy poses significant challenges for both PlasGO and other deep learning methods.\n\nThe distribution of the datasets compares favorably to previously published machine learning datasets in terms of ensuring novelty and independence between training and test sets. This approach helps in evaluating the generalization capability of the models to novel proteins. Additionally, plasmids containing more than 56 proteins were divided into multiple segments with an overlap of 14 proteins to ensure comprehensive coverage during training and prediction.\n\nThe curated dataset was utilized for retraining all benchmarked tools, and a comprehensive overview of its specific details can be found in the supplementary materials. Furthermore, experiments conducted using a plasmid-based data splitting strategy, including leave-one-genus-out benchmarking experiments and 5-fold cross-validation, are detailed in the supplementary sections. These experiments demonstrate the robustness and generalizability of the PlasGO model across different GO categories.",
  "dataset/availability": "The primary dataset utilized in our study is the publicly available NCBI RefSeq plasmid database. This dataset is freely accessible and complies with the terms and conditions set forth by NCBI for public use. The data included in this database are not associated with personal information or sensitive data, ensuring that there are no direct ethical considerations in our work.\n\nThe curated dataset, which includes the data splits used for training, validation, and testing, is also publicly available. This dataset is designed to simulate real scenarios where plasmid sequence data are available, but a majority of the encoded proteins lack annotations. For each Gene Ontology (GO) category, 10% of the most recently released proteins with GO annotations were allocated as the test set. The remaining 90% of annotated proteins were split into training and validation sets, ensuring that the novel test set significantly differs from the training set in terms of protein sequences.\n\nTo enforce the data splitting strategy, we ensured that there were no significant alignments (E-value > 1e-3) between the training and test sets. This was achieved by assigning proteins lacking significant alignments to the test set to the training set, while others were assigned to the validation set. This splitting strategy poses significant challenges for both PlasGO and other deep learning methods.\n\nThe PlasGO tool, along with the related data and code used in our experiments, is freely available on GitHub and Zenodo. As the article was submitted to GigaScience, an open-access journal, the tool is intended for broad, unrestricted use. This ensures that the dataset and the methods used are accessible to the scientific community, promoting transparency and reproducibility in our research.",
  "optimization/algorithm": "The machine-learning algorithm class used in our work is deep learning, specifically leveraging transformer-based models. We employed a BERT-like architecture for PlasGO, which is designed to handle protein sequences and predict Gene Ontology (GO) terms. This approach is not entirely new, as BERT and its variants have been widely used in natural language processing and, more recently, in bioinformatics for protein analysis. However, our implementation is tailored for plasmid-encoded proteins, which sets it apart from general-purpose models.\n\nThe reason this algorithm was not published in a machine-learning journal is that our primary focus is on the biological application and the specific challenges posed by plasmid-encoded proteins. The innovation lies in the adaptation and specialization of existing deep learning techniques for this particular domain, rather than the development of a entirely new algorithm. Our work contributes to the field of bioinformatics by demonstrating the effectiveness of transformer models in predicting GO terms for plasmid-encoded proteins, a task that has unique complexities due to the nature of plasmids.\n\nWe also compared our model with other state-of-the-art tools, including gLM, ESM-2, and CodonBERT, among others. For a fair comparison, we optimized these tools using the same curated RefSeq dataset. This involved retraining some models and creating custom databases or classifiers for others. The optimization process was necessary because the default models of these tools were not specifically trained on plasmid-encoded proteins and lacked some of the labels we were interested in predicting. For instance, the default PFresGO model could only predict a subset of our label set, and its performance was significantly improved after retraining on our dataset. This optimization ensured that the benchmarking results were consistent and reflective of each tool's potential when applied to plasmid-encoded proteins.",
  "optimization/meta": "The model does not operate as a traditional meta-predictor that combines outputs from multiple machine-learning algorithms. Instead, it leverages embeddings from pre-trained language models to enhance its predictions. Specifically, the model utilizes embeddings from the ESM-2 family, particularly the esm2_t36_3B_UR50D model, which has 36 Transformer layers and 3 billion parameters. This choice was made to maintain consistency with the ProtT5 model employed for PlasGO.\n\nThe training data splitting strategy ensures that there is no significant alignment between the training and test sets. This approach avoids the use of sequence alignment tools like Diamond, as the focus is on the model's ability to generalize from the training data to novel proteins. The dataset is curated to include a diverse range of plasmid-encoded proteins, with specific attention to ensuring that the test set contains proteins that are significantly different from those in the training set. This strategy poses challenges for both PlasGO and other deep learning methods, as it requires the model to learn from a varied and independent dataset.\n\nFor the benchmarking process, several state-of-the-art tools were optimized for GO term prediction using the same curated RefSeq dataset. This included retraining models for the first four tools, utilizing learned embeddings for ESM-2 and CodonBERT, and creating a custom database for TM-Vec. The optimization process was necessary because some labels in the default models did not exist, and the proteins used to train these models spanned various organisms with less emphasis on plasmids. As a result, the retrained models showed significant improvements in performance metrics such as Fmax and AUPR.\n\nThe model training involved dividing plasmids into sentences composed of multiple proteins, with an overlap to ensure continuity. This approach was used to convert plasmids into a format suitable for training and prediction. The training process included techniques such as dropout, model simplification, regularization, early stopping, and cross-validation to prevent overfitting. The learning rate was gradually increased using a warm-up strategy, and the model was trained for 10 epochs using an NVIDIA GeForce RTX 3090 Blower 24G graphics card.\n\nIn summary, while the model does not function as a meta-predictor in the traditional sense, it integrates embeddings from pre-trained language models to enhance its predictive capabilities. The training data is carefully curated to ensure independence between the training and test sets, and various optimization techniques are employed to improve performance and generalization.",
  "optimization/encoding": "For the data encoding and preprocessing, we began by selecting the RefSeq dataset due to its rigorous quality assurance checks, which ensure high-quality protein databases with minimal incorrect GO annotations. This dataset also provides genomic context information, such as the order of proteins encoded in plasmids, which is crucial for our model.\n\nWe downloaded all available plasmids from the NCBI RefSeq plasmid database, along with their corresponding protein sequences translated from CDSs, excluding pseudogenes. These plasmids were stored in a dictionary format, where each key represents a plasmid and the value is a list of proteins arranged in the order they are encoded in the respective plasmids. We focused on regular plasmids, keeping only those with lengths between 1K and 350K to ensure each plasmid had at least one encoded protein and to exclude megaplasmids.\n\nTo prepare the data for training, we restricted the maximum protein length to 1 Kbp. This limit is computationally efficient for the Transformer architecture used in our model and is a common practice followed by many state-of-the-art protein-related methods. However, during the prediction phase or when utilizing our tool, no length restrictions are imposed.\n\nFor each GO category, we allocated 10% of the most recently released proteins with GO annotations as the test set. We ensured that the novel test set significantly differed from the training set in terms of protein sequences. Among the remaining 90% of annotated proteins, those lacking significant alignments (E-value > 1e-3) to the test set were assigned to the training set, while others were assigned to the validation set. This splitting strategy posed significant challenges for both our model and other deep learning methods.\n\nPlasmids containing more than 56 proteins were divided into multiple segments with an overlap of 14 proteins (1/4 of the maximum length). This approach allowed us to convert plasmids into sentences for our model's training and prediction. The curated dataset was utilized for retraining all benchmarked tools, ensuring a fair and consistent comparison of algorithms.",
  "optimization/parameters": "In our study, the number of parameters used in the model varies depending on the protein language model (PLM) employed. The core module of PlasGO is structured as a lightweight BERT model with a fixed hidden size of 512 and a varying number of Transformer layers. Specifically, we used 4 Transformer encoder layers for the Molecular Function (MF) and Biological Process (BP) categories, and 2 layers for the Cellular Component (CC) category. This decision was based on the relatively smaller dataset and label size for the CC category.\n\nFor the PLMs, we tested several models with different parameter counts. The standard model used was ProtT5 with approximately 3 billion parameters. Additionally, we evaluated more lightweight ESM models with 150 million, 35 million, and 8 million parameters to assess the model's performance across a spectrum of PLMs with varying parameter counts. This flexibility allows users to choose a PLM that aligns with their computational capabilities, ensuring that PlasGO can be effectively utilized even with limited resources.",
  "optimization/features": "The input features for the PlasGO model are derived from protein sequences, which are converted into sentences for training and prediction. These sentences are composed of multiple proteins, with plasmids containing more than 56 proteins being divided into multiple segments with an overlap of 14 proteins. The specific details of the curated dataset, including the number of sentences and proteins, are outlined in a dedicated table.\n\nFeature selection was implicitly performed through the dataset curation process. The training set was carefully constructed to ensure that it did not contain proteins with significant alignments to the test set, thereby focusing on unique and novel protein sequences. This approach helps in preventing data leakage and ensures that the model generalizes well to unseen data.\n\nThe feature selection process was conducted using only the training set, adhering to best practices in machine learning to avoid bias and ensure the robustness of the model's performance. This strategy poses significant challenges for both PlasGO and other deep learning methods, as it requires the model to learn from a diverse set of protein sequences without relying on similar sequences in the test set.",
  "optimization/fitting": "The PlasGO model was designed with careful consideration of both overfitting and underfitting. To address the potential issue of overfitting, several strategies were employed. Dropout layers were applied at various stages of the model, including after token embedding layers, multi-head self-attention layers, feed-forward networks within Transformer encoders, and contextualized embeddings learned by the BERT module. This helped to prevent the model from becoming too reliant on specific patterns in the training data.\n\nModel simplification was another key strategy. For instance, the number of Transformer encoder layers was adjusted based on the size of the dataset for each Gene Ontology (GO) category. Four layers were used for Molecular Function (MF) and Biological Process (BP) categories, while only two layers were used for the Cellular Component (CC) category, which had a smaller dataset. This approach ensured that the model complexity was appropriate for the amount of available data, reducing the risk of overfitting.\n\nRegularization techniques, such as rank regularization (RR) loss, were integrated into the total loss function. This method aimed to enhance the model's ability to differentiate between low-confidence and high-confidence predictions, further mitigating overfitting. Additionally, early stopping was implemented to halt the training process if the model's performance on the validation set began to deteriorate.\n\nTo address underfitting, a warm-up strategy was used, where the learning rate was gradually increased from a small value to 1e-4 over the initial 5% of the total training steps. This approach helped the model to converge more effectively. Furthermore, a 5-fold cross-validation benchmark experiment was conducted to ensure that the model generalized well to unseen data.\n\nThe training process involved converting plasmids into sentences, with plasmids containing more than 56 proteins being divided into multiple segments with an overlap of 14 proteins. This method ensured that the model could handle varying lengths of plasmid-encoded proteins effectively. The final step in the training process involved fine-tuning the model with high-confidence pseudo-labeling, inspired by the iterative alignment tool PSI-BLAST. This strategy dynamically learned the optimal confidence cutoff for improved prediction accuracy.\n\nIn summary, the PlasGO model was trained with a batch size of 32 and a learning rate of 1e-4. Dropout rates of 0.2 for CC and 0.1 for MF and BP were applied to prevent overfitting. The model's performance was evaluated using protein-centric Fmax and term-centric area under the precision-recall curve (AUPR) metrics, ensuring a comprehensive assessment of its predictive accuracy.",
  "optimization/regularization": "In our study, several techniques were employed to prevent overfitting in the PlasGO model. One of the key methods used was dropout, which was applied after various layers including token embedding layers, multi-head self-attention layers, feed-forward networks within the Transformer encoders, and contextualized embeddings learned by the BERT module. This technique helps to reduce overfitting by randomly setting a fraction of input units to zero at each update during training time, which prevents units from co-adapting too much.\n\nAnother technique involved model simplification. While BERT was utilized to capture plasmid modular patterns, we opted for hyperparameters aligned with the size of the GO term dataset. For instance, we employed fewer Transformer encoder layers for the Cellular Component (CC) category due to the relatively smaller dataset and label size for this category.\n\nAdditionally, a rank regularization (RR) loss was integrated into the total loss function. This regularization method aimed to enhance the model\u2019s capacity to differentiate between low-confidence and high-confidence predictions. It discourages the assignment of high confidence scores to all predictions, thereby preventing overfitting.\n\nEarly stopping was also implemented, where the training process would halt if the performance on the validation set began to deteriorate. This ensures that the model does not continue to learn noise from the training data.\n\nFurthermore, a 5-fold cross-validation benchmark experiment was carried out. This approach helps in providing a more reliable evaluation of the model\u2019s capacity for generalization to novel proteins.",
  "optimization/config": "The hyper-parameter configurations and optimization schedules used for the PlasGO model are detailed within the publication. Specifically, the model was trained with a batch size of 32 and a learning rate of 1e-4. A warm-up strategy was employed, allocating 5% of the total training steps to gradually increase the learning rate from a small value to 1e-4. The learning rate was then linearly decayed to enhance generalization and expedite convergence. Different dropout rates were applied based on the GO category: 0.2 for the Cellular Component (CC) category and 0.1 for Molecular Function (MF) and Biological Process (BP) categories. The training process involved 10 epochs, with approximate durations of 65 minutes for MF, 59 minutes for BP, and 51 minutes for CC when using an NVIDIA GeForce RTX 3090 Blower 24G graphics card.\n\nThe model files and optimization parameters are not explicitly mentioned as being available for download. However, the training codes are provided, allowing users to train their custom models using protein language models (PLMs) that align with their computational capabilities. This includes the option to use more lightweight ESM models for users with limited GPU memory. The publication also mentions the use of a knowledge distillation-based protein embedding method, such as MTDP, which can significantly reduce resource demands while maintaining comparable performance.\n\nFor users without a GPU, the option to annotate plasmids by running protein alignment against a compiled database is available. This database includes a comprehensive pre-annotation of plasmid-encoded proteins using PlasGO. The iterative fine-tuning strategy with high-confidence pseudo-labeling is also described, providing a method for further refining the model's performance.\n\nIn summary, while the hyper-parameter configurations and optimization schedules are reported, the specific model files and optimization parameters are not explicitly made available for download. However, the provided training codes and methods allow for custom training and optimization.",
  "model/interpretability": "The PlasGO model is designed with a focus on interpretability, aiming to provide insights into its decision-making process. It is not a black-box model; instead, it incorporates several transparent components that allow for a clearer understanding of how predictions are made.\n\nOne of the key aspects of PlasGO's interpretability is its use of a foundation protein language model (PLM) to generate biologically meaningful embeddings for each plasmid-encoded protein. These embeddings capture the semantic meaning of individual amino acids and their contextual relationships within the protein sequence. By using a global average pooling operation, the model condenses these embeddings into a single per-protein embedding, which serves as the raw input for subsequent modules.\n\nThe model's architecture includes a BERT module, which utilizes a fully connected (FC) layer to transform the original embeddings learned by the PLM into protein embeddings. Multiple Transformer encoders are employed to capture the global context between these protein embeddings. This process allows the model to understand the relationships between different proteins encoded in the plasmid, providing a more comprehensive view of the plasmid's genetic structure.\n\nAdditionally, the classifier in PlasGO generates a GO term probability vector along with a confidence score vector for each protein. This dual-output mechanism ensures that only high-confidence predictions are retained, enhancing the accuracy of the GO term annotations. The confidence scores provide a measure of the model's certainty in its predictions, making it easier to interpret and trust the results.\n\nFurthermore, the self-attention mechanism within the BERT module helps in identifying which parts of the input sequence are most influential in making a prediction. This attention weighting can be visualized to understand which proteins or amino acids are contributing most to the final output, adding another layer of interpretability.\n\nIn summary, PlasGO's design incorporates several transparent components, including the use of PLMs for embedding generation, Transformer encoders for contextual understanding, and a confidence weighting mechanism for reliable predictions. These features make PlasGO a model that is not only powerful in its predictions but also interpretable in its decision-making process.",
  "model/output": "The model is designed for multilabel classification. Specifically, it focuses on predicting Gene Ontology (GO) terms for proteins. The output of the model consists of high-confidence predicted GO terms for each protein. These predictions are generated by a classifier module that employs a self-attention confidence weighting mechanism. This mechanism helps in assigning confidence scores to each prediction, allowing the model to reject uncertain predictions and retain only those with high confidence.\n\nThe classifier module uses two branches: one for learning logits and another for learning confidence scores. The logits undergo attention-weighting based on the learned confidence scores, ensuring that the final predictions are reliable. The model outputs both the confidence score vector and the final predicted probability vector, which are used to determine the high-confidence GO term predictions in nominal format.\n\nThe model's architecture is tailored for multilabel classification, where each protein can be associated with multiple GO terms. This approach enhances the accuracy and reliability of the predictions by leveraging contextual information at the plasmid level. The use of a self-attention mechanism ensures that the model can handle the complexities involved in capturing functional factors such as protein domains or amino acids, providing robust and accurate predictions.",
  "model/duration": "The execution time for the PlasGO model varies depending on the phase and the specific protein language model (PLM) used. During the training phase, the time required ranges from approximately 23 minutes to 23 hours, depending on the PLM. For instance, using ProtT5 with 3 billion parameters takes around 23 hours, while the ESM-2 model with 8 million parameters requires about 23 minutes. The prediction phase is significantly faster, taking only a few seconds per run, regardless of the PLM employed. This efficiency is attributed to the lightweight design of PlasGO's core module, which features a fixed hidden size of 512 and a limited number of Transformer layers. Additionally, the preprocessing step, which involves extracting per-protein embeddings, can be more resource-intensive when using larger PLMs. However, users can opt for lighter models or knowledge distillation methods to reduce computational demands. For those without GPU access, plasmid annotation can still be performed by running protein alignment against a pre-compiled database.",
  "model/availability": "The PlasGO tool, along with the related data and code used in our experiments, is freely available on GitHub and Zenodo. This availability aligns with our commitment to open science initiatives, ensuring that the tool can be broadly and unrestrictedly used by the scientific community. The source code is released under a permissive license, allowing users to modify and distribute the software as needed. Additionally, the tool is designed to be user-friendly, making it accessible even to those without extensive computational expertise. For users without a GPU, the tool provides an alternative method to annotate plasmids by running protein alignment against a compiled database, which includes comprehensive pre-annotation of plasmid-encoded proteins using PlasGO. This ensures that the tool can be utilized in various computational environments, further promoting its accessibility and usability.",
  "evaluation/method": "The evaluation of PlasGO involved several rigorous methods to ensure its performance and generalizability. We employed a leave-one-genus-out strategy, where proteins from specific genera were excluded from the training set and used as test sets. This approach assessed PlasGO's ability to predict functions for proteins from genera not represented in the training data. The performance was measured using Fmax and AUPR metrics across three Gene Ontology (GO) categories: Molecular Function (MF), Biological Process (BP), and Cellular Component (CC).\n\nAdditionally, we conducted a 5-fold cross-validation with a plasmid-based data splitting strategy. This involved randomly dividing all complete plasmids into five equal partitions, with each partition serving as the test set in one fold. The remaining partitions constituted the training and validation sets. This method ensured no significant alignment between the training and test sets, providing a reliable evaluation of PlasGO's capacity for generalization to novel proteins.\n\nFor the novel protein benchmark experiments, we allocated 10% of the most recently released proteins with GO annotations as the test set, ensuring significant differences in protein sequences from the training set. The remaining 90% of annotated proteins were split into training and validation sets based on sequence alignment criteria.\n\nThe performance metrics used were Fmax, which measures the accuracy of assigning GO terms to a protein, and AUPR, which evaluates the accuracy of predicting which proteins are associated with a given GO term. These metrics were averaged across the different experiment groups to provide a comprehensive assessment of PlasGO's performance.\n\nOverall, the evaluation methods demonstrated PlasGO's superior performance in predicting GO-based functions of plasmid-encoded proteins, even when dealing with novel genera or proteins not seen during training.",
  "evaluation/measure": "In the evaluation of PlasGO, we employed two commonly used metrics in the CAFA challenge to assess the performance of our tool. These metrics are the protein-centric Fmax and the term-centric area under the precision\u2013recall curve (AUPR).\n\nFmax measures the accuracy of assigning Gene Ontology (GO) terms to a protein. It provides a single score that balances precision and recall, giving an overall measure of a tool's performance in correctly predicting GO terms for proteins.\n\nAUPR, on the other hand, evaluates the accuracy of predicting which proteins are associated with a given GO term. It is particularly useful for handling imbalanced datasets, where some GO terms may be rare. By using AUPR, we can ensure a more comprehensive assessment of the tools' performance, especially for low-frequency GO terms.\n\nThe use of both Fmax and AUPR metrics is representative of the current literature in the field. These metrics are widely accepted and used in the community for evaluating the performance of GO term prediction tools. They provide a balanced view of a tool's performance, considering both the overall accuracy and the handling of rare GO terms.\n\nIn our experiments, we calculated Fmax for each protein and AUPR for each GO term separately. We then averaged these individual metrics to obtain an overall performance evaluation. This approach ensures that our assessment is thorough and considers the performance across all proteins and GO terms.\n\nIn summary, the reported metrics are representative of the literature and provide a comprehensive evaluation of PlasGO's performance in predicting GO terms for plasmid-encoded proteins.",
  "evaluation/comparison": "In our evaluation, we conducted a thorough comparison of PlasGO with several publicly available methods on benchmark datasets. Specifically, we benchmarked PlasGO against the top three state-of-the-art tools using two key metrics: Fmax and AUPR. These comparisons were performed across three Gene Ontology (GO) categories: Molecular Function (MF), Biological Process (BP), and Cellular Component (CC).\n\nTo ensure a comprehensive evaluation, we employed multiple strategies. First, we performed leave-one-genus-out experiments, where proteins from a specific genus were excluded from the training set and used as the test set. This approach allowed us to assess PlasGO's ability to generalize to proteins from genera not represented in the training data. The results, depicted in Supplementary Figure S4, showed that PlasGO consistently outperformed the other tools in terms of both Fmax and AUPR across all three GO categories.\n\nAdditionally, we conducted a 5-fold cross-validation using a plasmid-based data splitting strategy. In this method, all complete plasmids were randomly divided into five equal partitions, with each partition serving as the test set in one of the folds. The performance was averaged across the five folds, and the results, illustrated in Supplementary Figure S5, demonstrated that PlasGO maintained superior performance compared to the other benchmarked tools.\n\nWe also performed ablation studies to validate the design rationale of PlasGO. These studies involved comparing PlasGO with simpler baselines, such as a 3-layer deep neural network (DNN) classifier using ProtT5 embeddings. The results, presented in Table 2, indicated that PlasGO's standard approach, which leverages plasmid-level contextual information, achieved higher Fmax and AUPR scores than the baseline methods.\n\nFurthermore, we computed the all-against-all normalized McNemar test statistic between the ground truth, PlasGO, and other benchmarked tools on the MF category. PlasGO exhibited the lowest test statistic value compared to the ground truth, suggesting its superior performance on the RefSeq test set.\n\nIn summary, our evaluation included comparisons with publicly available methods and simpler baselines, demonstrating PlasGO's robust performance and generalizability across various benchmark datasets and experimental setups.",
  "evaluation/confidence": "In the evaluation of PlasGO, we employed several statistical methods to assess the significance of our results and the confidence in our performance metrics.\n\nTo compare the performance of PlasGO with other tools, we used the McNemar\u2019s test, a non-parametric statistical test suitable for paired nominal data. This test helped us evaluate the significance of differences in performance between PlasGO and other benchmarked tools. The McNemar test statistic, \u03c72, was calculated for each pair of tools, and a significant \u03c72 value allowed us to reject the null hypothesis of equal marginal distributions, indicating a significant difference in performance.\n\nThe results of the McNemar\u2019s test are visually represented in a matrix that illustrates the all-against-all normalized test statistics between the ground truth, PlasGO, and other tools. A value close to 1 in this matrix signifies a significant difference, while a value approaching 0 indicates no significant difference. PlasGO consistently showed the lowest test statistic value compared to the ground truth, suggesting superior performance.\n\nAdditionally, we introduced a self-attention confidence weighting mechanism in PlasGO, which enables the evaluation of a confidence score for each GO prediction. These confidence scores are crucial for generating reliable GO predictions. In our high-confidence mode, predictions with a probability below a certain threshold and a low confidence score are excluded, resulting in higher AUPR scores but a lower prediction rate. This approach demonstrates the effectiveness of the learned confidence scores in enhancing the reliability of GO predictions.\n\nFurthermore, we conducted leave-one-genus-out experiments and 5-fold cross-validation to assess the generalizability and robustness of PlasGO. The performance metrics, Fmax and AUPR, were evaluated across different GO categories and compared with top benchmarked tools. The results showed that PlasGO outperformed other tools in terms of both metrics, indicating its superior capability to predict GO-based functions of plasmid-encoded proteins, even for those from genera not represented in the training data.\n\nIn summary, the statistical significance of our results is supported by the McNemar\u2019s test, and the confidence in our performance metrics is enhanced by the self-attention confidence weighting mechanism. These evaluations collectively demonstrate the superiority and reliability of PlasGO in predicting GO terms for plasmid-encoded proteins.",
  "evaluation/availability": "The raw evaluation files are not explicitly mentioned as being publicly available. However, the PlasGO tool, along with the related data and code used in our experiments, is freely available on GitHub and Zenodo. This suggests that while the specific raw evaluation files might not be directly accessible, the tools and data necessary to reproduce the evaluations are provided. The article was submitted to GigaScience, an open-access journal, indicating a commitment to open science initiatives. Therefore, it is likely that the necessary resources for evaluation are accessible under the terms and conditions set forth by the respective platforms."
}