{
  "publication/pmid": "31877719",
  "publication/authors": "Floriane Montanari, Lara Kuhnke, Antonius Ter Laak, Djork-Arn\u00e9 Clevert",
  "publication/journal": "Molecules",
  "publication/title": "Modeling Physico-Chemical ADMET Endpoints with Multitask Graph Convolutional Networks\n",
  "publication/doi": "10.3390/molecules25010044",
  "publication/year": "2019",
  "publication/tags": [],
  "dataset/availability": "No",
  "dataset/provenance": "The authors used in-house (Bayer) datasets related to 10 ADMET endpoints\n1. LogD (pH7.5) (LOD) = 76,548 \n2. LogD (pH2.3) (LOA) = 236,280\n3. Membrane affinity (LOM) = 64,506 \n4. Human serum albumin binding (LOH) = 61,398 \n5. Melting point (LMP) = 90,589 \n6. Solubility (DMSO)  (LOO) = 38,841 \n7. Solubility (powder) (LOP) = 2334 \n8. Solubility (nephelometry) (LON )= 88,301 \n9. Solubility (DMSO not fully dissolved) (LOX) = 7392 \n10. Solubility (no assay annotation) (LOQ) = 50,016",
  "dataset/redundancy": "Models were evaluated in both a cross-validation and a separate test set fashion.\nDifferent splitting strategies were used that includes:\n1. Cluster split using k-means to cluster the compounds (K = 10)\n2. Random splits ensuring that each fold contains representatives from each task\n3. Time splits with no cross-validation based on measurement dates, in which later measurements used as test sets",
  "dataset/splits": "Different splitting strategies were used independently and only the test size for time split dataset is reported:\nLOD = 32,794\nLOA = 46,481\nLOM = 197\nLOH = 614\nLMP = 55\nLOO = 22,803\nLOP = 935",
  "dataset/done": 3,
  "dataset/skip": 1,
  "optimization/algorithm": "Multiple models were used and compared, but the main model that was focused by the authors is a Multitask Graph Convolutional Neural Network",
  "optimization/config": "The code to train multitask graph convolutional networks is available on github: https://github.com/fmonta/mtnngc_admet",
  "optimization/encoding": "The authors used molecular graphs and 75 simple atomic descriptors as initial node features.",
  "optimization/features": "75 atomic features for each atom in a molecule.\nNo explanation on feature selection.",
  "optimization/fitting": "No",
  "optimization/meta": "The model is not a meta-predictor",
  "optimization/parameters": "The authors used the implementation of the Duvenaud algorithm in DeepChem v.1.2.1 and kept the architecture and hyperparameters suggested by the authors for ADMET predictions.\n(Duvenaud, D.; Maclaurin, D.; Aguilera-Iparraguirre, J.; G\u00f3mez-Bombarelli, R.; Hirzel, T.; Aspuru-Guzik, A.; Adams, R.P. Convolutional Networks on Graphs for Learning Molecular Fingerprints. In Proceedings of the Advances in Neural Information Processing Systems 28 (NIPS 2015), Montreal, QC, Canada, 7\u201312 December 2015)",
  "optimization/regularization": "cross validation was performed for random splits and cluster splits.",
  "optimization/done": 7,
  "optimization/skip": 1,
  "model/availability": "The code to train multitask graph convolutional networks is available on github: https://github.com/fmonta/mtnngc_admet",
  "model/duration": "No",
  "model/interpretability": "The model is a black box.",
  "model/output": "The model is a regression model for predicting 7 ADMET endpoints.",
  "model/done": 3,
  "model/skip": 1,
  "evaluation/availability": "No",
  "evaluation/comparison": "The model was compared to simpler models developed by authors, including:\nRandom Forest\nFully-Connected Single Task Network\nFully-Connected Multitask Network\nSingle Task Graph Convultional Network",
  "evaluation/confidence": "Standard deviations are reported in supplementary materials.",
  "evaluation/measure": "The performance of such regression models is evaluated by the coefficient of determination r2 (which measures the concordance between predicted and experimental values) and the Spearman correlation coefficient rho (which measures the ranking capabilities of the models).",
  "evaluation/method": "The model was evaluated a in cross-validation fashion for random and cluster split strategies.\nIn time split method, the model that was trained on earlier measurements is evaluated on recent measurements.",
  "evaluation/done": 4,
  "evaluation/skip": 1
}