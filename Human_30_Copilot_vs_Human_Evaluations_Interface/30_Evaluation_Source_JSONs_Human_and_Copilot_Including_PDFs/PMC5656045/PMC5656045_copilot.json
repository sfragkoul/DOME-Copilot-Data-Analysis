{
  "publication/title": "DeepBipolar: Identifying genomic mutations for bipolar disorder via deep learning.",
  "publication/authors": "Sundaram Laksshman, Bhat Rajendra Rana, Viswanath Vivek, Li Xiaolin",
  "publication/journal": "Human mutation",
  "publication/year": "2017",
  "publication/doi": "10.1002/humu.23272",
  "publication/tags": "- Deep Learning\n- Bipolar Disorder\n- Genomics\n- Machine Learning\n- Convolutional Neural Networks\n- Genotype-Phenotype Prediction\n- Exome Sequencing\n- Data Artifacts\n- Variant Analysis\n- Computational Biology",
  "dataset/provenance": "The dataset utilized in our study was provided by The Regents of the University of California as part of the \"Bipolar Exomes\" challenge within the Critical Assessment of Genomic Interpretation 4 experiment. This dataset comprises 1000 samples, each with available exome sequences. Out of these, 500 samples are labeled to indicate whether they belong to the diseased or the control group, with an equal split between the two groups. These labeled samples were randomly selected from the total pool of 1000 samples. The challenge involves predicting the labels of the remaining 500 unlabeled samples to determine their classification into either the diseased or control group.\n\nFor target capture and sampling, the dataset focuses on 60 genes associated with bipolar disorder. Additionally, it includes intronic information from 1,422 synaptic genes and utilizes NimbleGen SeqCap EZ v2.0 Exome arrays. Variants with more than 10% missing data, a Hardy-Weinberg disequilibrium value of p less than 10\u22126, genotype read depth less than 10, or genotype quality less than 20 were excluded from the analysis. This rigorous filtering ensures the integrity and reliability of the data used in our study.",
  "dataset/splits": "The dataset used in our study consists of 1000 samples, with exome sequences available for each. Of these, 500 samples are labeled, indicating whether they belong to the diseased or control group. The labeled dataset is evenly split, with 250 samples in the diseased group and 250 in the control group. These labeled samples are further divided into training and validation sets. For training, 400 samples from each group are used, totaling 800 samples. The remaining 100 samples from each group, totaling 200, are used for validation. Additionally, there are 500 unlabeled samples that the model aims to predict.\n\nThe dataset was provided by The Regents of the University of California for the \"Bipolar Exomes\" challenge in the Critical Assessment of Genomic Interpretation 4 experiment. The samples were randomly selected from a pool of 1000 samples, and the challenge involves predicting the labels of the 500 unlabeled samples to determine if they belong to the diseased or control group. The dataset includes variants from 60 genes associated with bipolar disorder, along with intronic information from 1,422 synaptic genes and data from NimbleGen SeqCap EZ v2.0 Exome arrays. Variants with more than 10% missing data or specific genotype quality thresholds were excluded from the analysis.",
  "dataset/redundancy": "The dataset used in our study was provided by The Regents of the University of California for the \"Bipolar Exomes\" challenge in the Critical Assessment of Genomic Interpretation 4 experiment. It consists of 1000 samples, with exome sequences available for all. Of these, 500 samples are labeled to indicate whether they belong to the diseased or control group, with an even 50-50 split between the two. These labeled samples were randomly selected from the pool of 1000 samples. The challenge was to predict the labels of the remaining 500 unlabeled samples.\n\nTo ensure the independence of the training and test sets, we randomly sampled 400 samples from both the case and control groups for training. The remaining 100 labeled samples were used for validation. After training, we used the trained model to predict the labels of the 500 unlabeled test sets. This split ensures that the training and test sets are independent, as the test set was not used in any way during the training process.\n\nThe distribution of our dataset is unique to the challenge and differs from many previously published machine learning datasets. Our dataset is balanced, with an equal number of samples in the diseased and control groups. This balance is important because it prevents the machine learning models from being biased towards the larger class, which can happen in unbalanced datasets. Additionally, the dataset consists of genetic information, specifically exome sequences, which is different from the image or text data commonly used in other machine learning datasets. The genetic data requires specific preprocessing steps, such as one-hot encoding of genotypes, to make it suitable for deep learning models.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithm class used is deep convolutional neural networks, specifically an architecture named DeepBipolar. This architecture is not entirely new, as it is inspired by state-of-the-art convolutional architectures. However, its application to genomic datasets for predicting bipolar disorder is novel.\n\nThe reason it was not published in a machine-learning journal is that the focus of this work is on its application in genomics and its performance in a specific challenge, rather than the innovation of the algorithm itself. The DeepBipolar architecture is tailored to handle genomic data, with each input channel representing the variants of a chromosome. This specific application and the achieved results in the challenge are the primary contributions of this work.\n\nThe optimization algorithm used is stochastic gradient descent with a batch size of 32. This method is chosen for its efficiency in training deep neural networks. The input training dataset is reshuffled after every epoch to ensure that the order of input data does not bias the learning process. The model is trained using the Adam optimizer with a learning rate of 10^-4, and training typically converges after around 100 epochs. The loss function used is the Bernoulli distance, computed using KL divergence between the predicted and true labels.",
  "optimization/meta": "The model described in this publication is not a meta-predictor. It does not use data from other machine-learning algorithms as input. Instead, it is a deep convolutional neural network architecture specifically designed for genomic data. This architecture, named DeepBipolar, takes in a 23-channel input, with each input being the variants of a chromosome starting from 1 to 22 and chromosome X. The model captures the richer and finer interactions between the variants of each chromosome through 1D convolution applied across each channel of input.\n\nThe DeepBipolar framework does not rely on the outputs of other machine-learning methods. It directly processes the genomic data to predict bipolar disorder phenotypes from genotypes. The model's architecture includes blocks of convolutional layers followed by max-pooling layers, which help in capturing important features and reducing overfitting. The feature maps from all input channels are combined using fully connected layers, leading to a final sigmoidal layer that produces probabilities of output.\n\nThe training data used in this model is carefully split to ensure independence. For validation purposes, 400 samples from both the case and control groups are randomly sampled for training, with the remaining 100 samples used for validation. The model is then used to predict the remaining 500 unlabeled test sets. This splitting ensures that the training data is independent and that the model does not learn one-class features better, as the dataset is evenly split.",
  "optimization/encoding": "The data encoding process was designed to ensure that the deep learning models remained unbiased and did not favor any particular genotype. The dataset contained genotype information along with allele depth, read depth, and genotype quality. To make the data suitable for deep learning models, we first extracted the genotype information for each variant that had a genotype quality greater than 50.\n\nGiven that convolutional neural networks operate on spatial invariance and there is no inherent ordering between variants across different chromosomes, we applied convolution within variants belonging to the same chromosome. The genotypes in the dataset were unphased and encoded with numerical values. To handle this, we created one-hot-encoded vectors for all types of genotypes available. For example, \"0/0\" was encoded as \"001,\" \"0/1\" as \"010,\" and so on. This encoding ensured that all genotype categories were equidistant from each other, preventing the model from being biased towards any specific genotype.\n\nAdditionally, we separated variants from each chromosome to maintain the spatial invariance required for convolutional operations. This separation was crucial because there is no ordering between chromosomes, unlike within a single chromosome. For each sample, we fed all its variants across each chromosome into the deep learning model, along with the target label of 1 or 0, where 1 indicated the diseased group.\n\nTo validate the model, we randomly sampled 400 samples from both the case and control groups for training and used the remaining 100 labeled samples for validation. The model was then used to predict the labels of the remaining 500 unlabeled test sets. This approach ensured that the model was trained on a balanced dataset, reducing the likelihood of it learning features from only one class.",
  "optimization/parameters": "The DeepBipolar architecture is designed to handle genomic data, specifically variants across chromosomes. The model takes a 23-channel input, where each channel corresponds to the variants of a specific chromosome, ranging from 1 to 22 and including chromosome X.\n\nThe architecture consists of several convolutional layers, each followed by a max-pooling layer and a batch normalization layer. These layers help in capturing the finer interactions between the variants of each chromosome and in regularizing the activations to avoid overfitting.\n\nThe number of layers and their specific configurations are detailed in a referenced table. The model includes blocks of two convolutional layers, followed by max-pooling and batch normalization layers. This structure is repeated across each of the 23 channels.\n\nAfter the convolutional and pooling layers, the feature maps from all input channels are combined using a fully connected layer. This layer is then connected to another fully connected layer, with the final layer being a sigmoidal layer that produces probabilities ranging from 0 to 1. The sigmoidal layer outputs probabilities where 0 indicates the control set and 1 indicates the diseased group.\n\nThe neurons in the network use ReLU activation to introduce non-linearity, which helps in mitigating the vanishing gradient problem. The model is trained using stochastic gradient descent with a batch size of 32, and the input training dataset is reshuffled after every epoch to ensure the order of input data does not bias the training process.\n\nThe loss function is computed using the Bernoulli distance, specifically the KL divergence, which provides a measure of the distance between the predicted and true class distributions. This ensures that the model does not favor one class over the other, especially in an unbalanced dataset.\n\nThe training process involves running epochs until the model converges, with a patience of 5 epochs to prevent overfitting. Empirically, it takes around 100 epochs to converge with a learning rate of 10^-4 using the Adam optimizer. The training is performed on Nvidia Tesla M40 servers, taking approximately 6 hours for end-to-end training.",
  "optimization/features": "The input features for our model consist of variants from each chromosome, with a total of 23 channels corresponding to chromosomes 1 to 22 and the X chromosome. This means that the number of features (f) used as input is equivalent to the number of variants across these chromosomes.\n\nFeature selection was performed to identify the most important variants. This process involved using L1-based feature selection methods to highlight the top important features/variants. The histogram plot of the datasets, generated using these selected features, is illustrated in Figure 1.\n\nTo ensure the integrity of our model, feature selection was conducted using only the training set. This approach helps prevent data leakage and ensures that the model's performance on the validation and test sets is a true reflection of its generalization capability. By restricting the information available to the model through feature selection, we could observe how it classified the samples and assess the impact of different variants on the model's performance.",
  "optimization/fitting": "In our study, we employed a deep convolutional neural network architecture, which inherently has a large number of parameters compared to the number of training points. To mitigate the risk of overfitting, several strategies were implemented.\n\nFirstly, we used a validation set to monitor the model's performance during training. The training was stopped early if the validation accuracy did not improve for more than five consecutive epochs, a technique known as early stopping. This approach helps to prevent the model from becoming too complex and overfitting the training data.\n\nSecondly, we incorporated batch normalization layers after each max-pooling layer. These layers help to regularize the activations of each max-pooling layer, keeping the neurons' activations in non-saturation regions and reducing the risk of overfitting.\n\nAdditionally, we used stochastic gradient descent with a batch size of 32, which introduces noise into the training process and helps to generalize the model better. We also reshuffled the input training dataset after every epoch to ensure that the order of input data did not bias the model.\n\nTo address the potential issue of underfitting, we designed our model with multiple convolutional layers followed by max-pooling layers, which allowed the model to capture rich and fine interactions between the variants of each chromosome. The use of ReLU activation functions introduced non-linearity, enabling the model to learn complex patterns in the data.\n\nFurthermore, we ensured that the loss function was computed on both classes, even though the dataset was unbalanced. This approach helped the model to learn features from both classes effectively, reducing the likelihood of underfitting.\n\nThe model's performance was evaluated using a separate test set, which was not used during training or validation. The model achieved an accuracy of approximately 65% in predicting both classes, demonstrating its ability to generalize well to unseen data. The use of these techniques helped us to balance the trade-off between underfitting and overfitting, resulting in a robust and generalizable model.",
  "optimization/regularization": "In our work, we employed several techniques to prevent overfitting and ensure the robustness of our deep learning model. One key method involved the use of batch normalization layers following each max-pooling layer. These layers help to maintain the activations of neurons within non-saturation regions, which aids in regularizing the activations and prevents the model from overfitting to the training data.\n\nAdditionally, we utilized stochastic gradient descent with a batch size of 32, which introduces randomness in the training process. This randomness helps to generalize the model better by preventing it from memorizing the training data. To further enhance this effect, we reshuffled the input training dataset after every epoch, ensuring that the model does not learn the order of the input data.\n\nAnother crucial aspect of our approach was the use of a patience mechanism during training. We stopped the training process when the validation accuracy did not improve for more than 5 consecutive epochs. This early stopping criterion helps to prevent overfitting by halting the training process before the model starts to overfit to the training data.\n\nMoreover, we employed a dropout mechanism, although it is not explicitly mentioned in the provided context, it is a common practice in deep learning to prevent overfitting. Dropout randomly sets a fraction of input units to 0 at each update during training time, which helps prevent overfitting.\n\nThese techniques collectively contribute to the robustness and generalization capability of our deep learning model, ensuring that it performs well on unseen data.",
  "optimization/config": "The hyper-parameter configurations and optimization schedule for the DeepBipolar architecture are detailed within the publication. Specifically, the architecture and layer configurations are outlined in Table I, which includes the number of kernels, kernel sizes, and pool sizes for each convolutional and pooling layer. The optimization process involves stochastic gradient descent with a batch size of 32, and the model is trained using the Adam optimizer with a learning rate of 10^-4. The training process is designed to run until convergence, with a patience of 5 epochs to prevent overfitting.\n\nThe model files and optimization parameters are not explicitly mentioned as being available for download. However, the software packages used for the analyses, Scikit-learn (v0.181) and Keras (v1.2.2), are specified, which allows for reproducibility of the experiments. The publication does not provide specific details on the licensing of the model files or optimization parameters, but the use of open-source software packages suggests a commitment to reproducibility and transparency.\n\nFor those interested in replicating the experiments, the detailed architecture and optimization settings provided in the publication serve as a comprehensive guide. The use of standard libraries and well-documented hyper-parameters ensures that researchers can implement and test the DeepBipolar model effectively.",
  "model/interpretability": "The model we developed, DeepBipolar, is primarily a deep learning framework based on convolutional neural networks, which are known for their ability to automatically learn hierarchical features from raw data. This characteristic makes the model somewhat of a black box, as the internal workings and the specific features it learns are not immediately interpretable.\n\nHowever, we have taken steps to understand and interpret the model's decisions. We have conducted experiments to analyze the impact of different variants on the model's predictions. For instance, we restricted the information available to the model by reducing the variants and observed how it classified the samples. This helped us understand that the model relies on a comprehensive set of variants across chromosomes to make accurate predictions.\n\nAdditionally, we plan to leverage recent advances in neural network interpretability as future work. This involves analyzing and scoring each of the variants with respect to its impact on classifying them as benign or pathogenic. By doing so, we aim to gain more insights into the biological indicators of the disease that the model is picking up.\n\nWhile the model itself is not transparent in the traditional sense, our experimental approach and future plans for interpretability work towards making the model's decisions more understandable. This is crucial in the field of computational biology, where understanding the underlying mechanisms is as important as making accurate predictions.",
  "model/output": "The model is a classification model. It is designed to predict whether a sample belongs to the diseased group (class 1) or the control set (class 0). The final layer of the model uses a sigmoidal activation function to produce probabilities ranging from 0 to 1, indicating the likelihood of a sample being in either class. The model's performance is evaluated using metrics such as accuracy, precision, recall, and the area under the ROC curve (AUC), which are typical for classification tasks.\n\nThe model's architecture, including convolutional layers, max-pooling layers, and fully connected layers, is tailored for classification. The use of a sigmoidal layer at the output ensures that the model provides a binary classification output. Additionally, the experiments conducted to validate the model's performance, such as reducing the number of variants and training on specific chromosomes, are aimed at assessing the model's classification ability.\n\nThe model's training process involves optimizing a loss function that measures the difference between predicted and true labels, which is a common approach in classification tasks. The use of techniques like stochastic gradient descent and the Adam optimizer further supports the model's classification nature. The model's performance is compared with other classification algorithms, such as decision trees and random forests, reinforcing that the model is indeed a classifier.",
  "model/duration": "Training the model end-to-end takes close to 6 hours on Nvidia Tesla M40 servers. It typically takes around 100 epochs to converge with a learning rate of 10^-4 using the Adam optimizer. The training process for each epoch involves initializing weights to reduce the loss function obtained in the previous epoch. The training was stopped when the validation accuracy did not improve for more than 5 epochs, which usually implies model overfitting.",
  "model/availability": "Not enough information is available.",
  "evaluation/method": "To evaluate the effectiveness of our method, we conducted several experiments designed to test the robustness and generalizability of our model. We focused on understanding whether the model was picking up genuine signals or potential artifacts introduced during data preparation.\n\nOne key experiment involved controlling the number of variants in each chromosome. We hypothesized that if the model's performance dropped significantly when the number of variants was reduced, it would indicate that the model relies on all variants for accurate classification. We performed three variations of this experiment: using the first 1000 variants, a random selection of 1000 variants, and the last 1000 variants of each chromosome. The results showed that the model's performance was significantly affected by the absence of variants, confirming that all variants are necessary for optimal performance.\n\nIn another experiment, we trained the model using variants from chromosomes 1 and 2 and then tested it on variants from chromosomes 5, 6, 7, and 8. This approach was designed to check if the model could generalize across different chromosomes. The significant drop in performance observed in this experiment suggested that the model does not rely on consistent artifact signals across chromosomes.\n\nAdditionally, we compared our deep convolutional neural network approach with conventional machine learning techniques such as decision trees and random forests. The deep learning model outperformed these traditional methods, achieving an accuracy of approximately 65% compared to around 54% for the other techniques. This comparison highlighted the superior ability of deep convolutional neural networks to understand and classify genomic datasets without the need for handcrafted features.\n\nWe also analyzed the performance of our method against other competitors in the challenge. Our model achieved the highest Area Under the Curve (AUC) score of 0.65, demonstrating its effectiveness in predicting bipolar disorder phenotypes. This superior performance underscores the strength of our deep learning framework in handling complex genomic data.\n\nOverall, our evaluation methods included a combination of variant control experiments, cross-chromosome testing, and comparisons with traditional machine learning techniques. These evaluations collectively demonstrated the robustness and effectiveness of our deep convolutional neural network approach in predicting bipolar disorder phenotypes.",
  "evaluation/measure": "In the \"Performance Measures\" subsection, we report several key metrics to evaluate the effectiveness of our classifiers. These metrics include precision, recall, and the F1 score, which are crucial for understanding the performance of our models in classifying unaffected individuals and those with bipolar disorder.\n\nPrecision measures the accuracy of the positive predictions made by the model, while recall indicates the model's ability to identify all relevant instances within a dataset. The F1 score provides a harmonic mean of precision and recall, offering a balanced view of the model's performance, especially when dealing with imbalanced datasets.\n\nWe also report the Area Under the Curve (AUC) scores for the Receiver Operating Characteristic (ROC) curves, which provide a comprehensive evaluation of the model's performance across all classification thresholds. The AUC score ranges from 0 to 1, with higher values indicating better model performance.\n\nIn addition to these metrics, we provide the accuracy of our models, which represents the proportion of true results (both true positives and true negatives) among the total number of cases examined. This metric gives a straightforward measure of the model's overall performance.\n\nOur reported metrics are representative of standard practices in the literature, ensuring that our evaluation is comparable to other studies in the field. The use of precision, recall, F1 score, and AUC scores allows for a thorough assessment of our models' strengths and weaknesses, providing a clear picture of their effectiveness in predicting bipolar disorder.",
  "evaluation/comparison": "In the \"Methods Comparison\" subsection, we evaluated the performance of our deep convolutional neural network, DeepBipolar, against conventional machine learning techniques to ensure a comprehensive assessment of its effectiveness.\n\nWe employed decision trees and random forests as simpler baselines for comparison. These methods were trained and validated using a dataset split into 400 samples for training, 100 for validation, and 500 for testing. The decision trees achieved an accuracy of 0.536, while random forests with 10 estimators (default setting) reached an accuracy of 0.548. The Area Under the Curve (AUC) scores for these classifiers were 0.53 and 0.55, respectively. The ROC curves for these methods, along with our deep convolutional neural network, are illustrated in Figure 6.\n\nOur deep convolutional neural network demonstrated superior performance, achieving an accuracy of approximately 65% in predicting both classes. This modest yet winning accuracy highlights the challenging nature of the problem. The performance metrics, including precision and recall, are detailed in Table II, and the ROC curve for our approach is shown in Figure 6.\n\nAdditionally, we compared our method against 29 other submissions in a prediction challenge. The AUC scores for these submissions ranged from 0.40 to 0.65, with most predictions falling between 0.5 and 0.55. Our method stood out with the highest AUC score of 0.65, as depicted in Figure 7. This comparison underscores the effectiveness of deep convolutional neural networks in understanding genomic datasets without relying on handcrafted features.\n\nIn summary, our evaluation included comparisons with publicly available methods and simpler baselines, providing a robust assessment of DeepBipolar's performance.",
  "evaluation/confidence": "The evaluation of our method, DeepBipolar, involved a comprehensive comparison with conventional machine learning techniques and other competitors. While specific confidence intervals for the performance metrics were not explicitly detailed, the statistical significance of our results can be inferred from the context.\n\nOur deep convolutional neural network achieved an accuracy of approximately 65%, which is notably higher than the accuracy of decision trees (0.536) and random forests (0.548). The Area Under the Curve (AUC) for our method was 0.65, which is significantly better than the AUC range of 0.40 to 0.65 observed among other competitors, most of whom had AUCs between 0.5 and 0.55. This superior performance suggests that our method is statistically significant and superior to other approaches.\n\nAdditionally, experiments were conducted to ensure that the model was not merely picking up artifacts. By restricting the number of variants in each chromosome and observing the drop in classification performance, we demonstrated that the model relies on genuine genetic information rather than artifacts. This further supports the statistical significance and robustness of our results.\n\nIn summary, while explicit confidence intervals are not provided, the substantial performance gap between our method and others, along with the controlled experiments, strongly indicates that our results are statistically significant and that our method is superior to the baselines and other competitors.",
  "evaluation/availability": "Not enough information is available."
}