{
  "publication/title": "HMMPred: Accurate Prediction of DNA-Binding Proteins Based on HMM Profiles and XGBoost Feature Selection.",
  "publication/authors": "Sang Xiuzhi, Xiao Wanyue, Zheng Huiwen, Yang Yang, Liu Taigang",
  "publication/journal": "Computational and mathematical methods in medicine",
  "publication/year": "2020",
  "publication/doi": "10.1155/2020/1384749",
  "publication/tags": "- DNA-binding proteins\n- Machine learning\n- Support vector machine\n- Random forest\n- Feature selection\n- XGBoost\n- Hidden Markov model\n- Bioinformatics\n- Protein prediction\n- Computational biology\n- Amino acid composition\n- Auto-covariance transformation\n- Cross-covariance transformation\n- Cross-validation\n- Performance metrics",
  "dataset/provenance": "The datasets used in this study are sourced from the Protein Data Bank (PDB). Two benchmark datasets, PDB1075 and PDB186, were utilized to evaluate the performance of the proposed method. The PDB1075 dataset contains 525 DNA-binding proteins (DBPs) and 550 non-DNA-binding proteins. This dataset was primarily used for model training and testing through cross-validation methods. On the other hand, the PDB186 dataset, which includes 93 DBPs and 93 non-DBPs, was employed for an independent test to further assess the robustness and generalization ability of the predictor.\n\nThe protein sequences in these datasets were selected through a rigorous filtering procedure. Sequences with a length of less than 50 amino acids or containing unknown residues such as \"X\" were removed. Additionally, sequences with more than 25% similarity to any other sequence were excluded to ensure diversity and reduce redundancy. This filtering process ensures that the datasets are representative and suitable for training and testing predictive models.",
  "dataset/splits": "Two benchmark datasets were used to evaluate the performance of the proposed method. The first dataset, PDB1075, contains 525 DNA-binding proteins (DBPs) and 550 non-DNA-binding proteins. This dataset was used for model training and testing through cross-validation methods. The second dataset, PDB186, includes 93 DBPs and 93 non-DNA-binding proteins. This dataset was used for an independent test to further assess the robustness and generalization ability of the predictor.\n\nThe protein sequences in both datasets were selected from the Protein Data Bank through a rigorous filtering procedure. Sequences with a length of less than 50 amino acids or containing unknown residues were removed. Additionally, sequences with more than 25% similarity to any other sequence were also excluded to ensure diversity in the datasets.",
  "dataset/redundancy": "Not enough information is available.",
  "dataset/availability": "Not enough information is available.",
  "optimization/algorithm": "The machine-learning algorithms used in this study are Support Vector Machine (SVM) and Random Forest (RF). These are well-established algorithms in the field of machine learning and are not new. They were chosen for their effectiveness in handling complex classification tasks, particularly with nonlinear decision boundaries in the case of SVM.\n\nThe SVM algorithm employs kernel tricks to manage classes with complex nonlinear decision boundaries. Popular kernels used with SVMs include linear, polynomial, sigmoid, and radial basis function (RBF). In this study, the RBF kernel was selected due to its superior performance in previous tests. The parameters C and \u03b3 were optimized using a grid search strategy within the range of 2^-10 to 2^10, based on 10-fold cross-validation (CV).\n\nThe RF algorithm, an ensemble learning method, is widely used for both feature selection and classification. It consists of multiple decision trees, each making a judgment on the samples. The final classification is determined by the category with the maximum votes from all trees.\n\nBoth algorithms were implemented using the Python sklearn library, which is a widely-used toolkit for machine learning in Python. The experiments were conducted using Python version 3.7.\n\nThe choice of these algorithms and their implementation in a biological context is justified by their proven effectiveness in similar studies. The focus of this publication is on the application of these algorithms to a specific biological problem, rather than the development of new machine-learning techniques. Therefore, it is appropriate for this work to be published in a computational biology journal rather than a machine-learning journal.",
  "optimization/meta": "The model does not use data from other machine-learning algorithms as input. It is not a meta-predictor. The model employs a Support Vector Machine (SVM) classifier with a Radial Basis Function (RBF) kernel, which is optimized using a grid search strategy. The SVM is used in conjunction with various feature extraction techniques, including Amino Acid Composition (AAC), Auto-Covariance Transform (ACT), and Conjoint Triad (CCT). The combination of AAC, ACT, and CCT features is found to be the most effective for predicting DNA-binding proteins (DBPs).\n\nThe model's performance is evaluated using three commonly used tests: 10-fold cross-validation (CV), jackknife CV, and an independent test on the PDB186 dataset. The performance metrics used include sensitivity (SN), specificity (SP), accuracy (ACC), Matthew's correlation coefficient (MCC), and the area under the receiver operating characteristic (ROC) curve (AUC). The model achieves high accuracy and AUC values, indicating its effectiveness in predicting DBPs.\n\nFeature selection techniques, such as Random Forest (RF) and XGBoost, are used to rank and select the most important features, which further improves the model's performance. The top 270 ranked features are selected for the final analysis, demonstrating the importance of feature selection in enhancing prediction accuracy. The model's performance is compared with existing predictors, and it ranks second on the benchmark dataset, highlighting its competitiveness and reliability.",
  "optimization/encoding": "In our study, the data encoding process focused on transforming protein sequences into numerical vectors suitable for machine learning algorithms. We primarily concentrated on two aspects: constructing encoding schemes for protein sequences and applying classification algorithms.\n\nTo represent protein sequences, we utilized several feature extraction techniques. Amino acid composition (AAC) was one of the primary methods, where each protein sequence was converted into a 20-dimensional vector representing the frequency of each amino acid. However, AAC alone does not capture the sequence-order information, which is crucial for understanding protein functions.\n\nTo address this, we employed auto-cross covariance transformation (ACT) and cross-covariance transformation (CCT). These techniques reflect the local sequence-order effects by considering the correlations between amino acids separated by a certain number of positions (lag) along the protein sequence. The ACT and CCT features were computed using specific formulas that incorporate the lag parameter, resulting in numerical vectors that preserve the sequence-order information.\n\nBy combining AAC, ACT, and CCT features, each protein sequence was represented as a high-dimensional vector. The dimensionality of this vector depended on the maximum lag value used in the ACT and CCT calculations. This comprehensive feature set allowed our machine learning models to capture both the compositional and sequential properties of the protein sequences.\n\nIn summary, our data encoding process involved converting protein sequences into fixed-length numerical vectors using AAC, ACT, and CCT features. This approach ensured that both the amino acid composition and sequence-order information were preserved, providing a robust representation for subsequent classification tasks.",
  "optimization/parameters": "In our study, the parameter g plays a crucial role in determining the accuracy of our model. This parameter represents the lag or the number of positions between amino acids in the protein sequence when calculating the average correlation using ACT and CCT features.\n\nWe evaluated the impact of g on prediction performance by incrementing its value from 1 to 10. Through this evaluation, we observed that the accuracy rate tends to decrease as the value of g increases. Specifically, when g exceeds 7, both the SVM and RF classifiers exhibit relatively poor performance. Conversely, the accuracies remain relatively stable when g ranges from 5 to 7.\n\nConsidering the trade-off between accuracy and computational efficiency, we recommend setting the maximum value of g to 5. This choice helps to mitigate issues related to feature redundancy, additional computational cost, and extra time consumption. Consequently, the number of ACT features is set to 100, and the number of CCT features is set to 1900. This selection ensures a balance between model performance and practical feasibility.",
  "optimization/features": "In the \"Input Features\" subsection, the initial feature set consists of a combination of AAC, ACT, and CCT features, resulting in a 2020-dimensional vector for each protein. This is achieved by computing 20 AAC features, and then applying ACT and CCT to reflect the local sequence-order effect, with the number of ACT and CCT features depending on the maximum lag value g.\n\nFeature selection was performed to improve the prediction performance by removing irrelevant, noisy, and redundant information. Two methods were used for feature selection: Random Forest (RF) and XGBoost. The importance of features was calculated using these algorithms, and features were ranked accordingly. The optimal feature subset was determined by evaluating the prediction accuracy for top K features, where K ranged from 10 to 650. The highest accuracy was achieved with the top 270 ranked features using the XGBoost method.\n\nThe feature selection process was conducted using the training set only, ensuring that the selected features were not influenced by the test set. This approach helps to prevent overfitting and ensures that the model's performance is generalizable to new, unseen data.",
  "optimization/fitting": "The fitting method employed in this study involves the use of Support Vector Machines (SVM) and Random Forest (RF) classifiers, with a focus on optimizing the parameter g and feature selection to balance model complexity and performance.\n\nThe number of features initially considered is quite large, with a 2020-dimensional vector for each protein when combining AAC, ACT, and CCT features. This high dimensionality could potentially lead to overfitting, especially if the number of training points is not sufficiently large. To mitigate this risk, feature selection techniques were applied using RF and XGBoost to rank features by their importance. The top 270 features were selected based on their ability to achieve the highest accuracy in cross-validation tests. This reduction in feature dimensionality helps to prevent overfitting by focusing on the most relevant features.\n\nTo ensure that the model is not underfitting, the performance was evaluated using multiple cross-validation methods, including 10-fold cross-validation and jackknife cross-validation. These methods provide a robust assessment of the model's generalizability by ensuring that the model is tested on various subsets of the data. The consistent performance across different cross-validation techniques indicates that the model is well-fitted to the data without being overly simplistic.\n\nAdditionally, the use of the RBF kernel in SVM and the ensemble nature of RF help in capturing complex patterns in the data, further reducing the risk of underfitting. The optimization of parameters C and \u03b3 in SVM using a grid search strategy based on 10-fold cross-validation ensures that the model is tuned to achieve the best possible performance without overfitting or underfitting.\n\nIn summary, the fitting method involves careful feature selection and parameter optimization to balance model complexity, thereby ruling out both overfitting and underfitting. The use of multiple cross-validation techniques and the selection of the top-ranked features ensure that the model generalizes well to unseen data.",
  "optimization/regularization": "In our study, we employed several techniques to prevent overfitting and ensure the robustness of our models. One of the key methods used was cross-validation, specifically 10-fold cross-validation and jackknife cross-validation. These techniques help to assess the model's performance on different subsets of the data, providing a more reliable estimate of its generalization capability.\n\nAdditionally, we utilized feature selection methods to reduce the dimensionality of our data and focus on the most relevant features. This process not only helps in improving the model's performance but also in preventing overfitting by eliminating irrelevant or redundant features. We compared the effectiveness of different feature selection techniques, including those based on Random Forest (RF) and XGBoost, and found that XGBoost feature ranking provided higher accuracies.\n\nFurthermore, we optimized the parameters of our Support Vector Machine (SVM) classifier using a grid search strategy with 10-fold cross-validation. This approach helps in finding the best combination of parameters, such as C and \u03b3 for the RBF kernel, which can improve the model's performance and generalization.\n\nBy combining these techniques, we aimed to build models that are not only accurate but also robust and less prone to overfitting.",
  "optimization/config": "The hyper-parameter configurations and optimization parameters used in our study are reported in detail within the publication. Specifically, we discuss the selection of the optimal g value and the comparison between the SVM and RF classifiers. The SVM classifier utilized the RBF kernel, with parameters C and \u03b3 optimized between 2^-10 and 2^10 using a grid search strategy based on 10-fold cross-validation. For the RF classifier, we described its ensemble learning approach and how it was implemented using the Python sklearn library.\n\nThe optimization schedule involved evaluating the impact of the parameter g on prediction performance, with g values ranging from 1 to 10. We also compared the performance of different feature extraction techniques, including AAC, ACT, CCT, and their combinations, using both 10-fold and jackknife cross-validation methods. The results of these evaluations are presented in tables and figures within the publication.\n\nRegarding the availability of model files and optimization parameters, the specific files and detailed configurations are not directly provided in the text. However, the methods and results are thoroughly documented, allowing for replication of the experiments. The use of standard libraries like sklearn ensures that the implementations are accessible and reproducible. For further details on the exact model files and optimization parameters, readers are encouraged to refer to the supplementary materials or contact the authors directly.\n\nThe publication does not explicitly mention the license under which the data or code is available. However, it is common practice in scientific research to make data and code available upon request or through repositories like GitHub, ensuring that other researchers can replicate and build upon the work. For specific licensing information, it would be best to consult the supplementary materials or contact the authors.",
  "model/interpretability": "The model employed in this study is not entirely a black-box model, as it incorporates several interpretable components and techniques that contribute to its transparency.\n\nFirstly, the feature extraction process involves computing Amino Acid Composition (AAC), Auto-Covariance Transformation (ACT), and Cross-Covariance Transformation (CCT) features from the Hidden Markov Model (HMM) profile. These features are derived from the protein sequence and have clear mathematical definitions, making them interpretable. For instance, AAC features represent the frequency of each amino acid in the protein sequence, while ACT and CCT features capture the local sequence-order effects by considering the correlations between amino acids separated by a certain number of positions.\n\nSecondly, the feature selection process uses Random Forest (RF) and XGBoost algorithms to rank features based on their importance scores. These importance scores indicate the contribution of each feature to the prediction task, providing insights into which features are most relevant. For example, if a particular ACT feature has a high importance score, it suggests that the correlation between specific amino acids at a certain lag is crucial for predicting the target variable.\n\nAdditionally, the classification algorithms used, Support Vector Machine (SVM) and RF, have interpretable aspects. In the case of SVM, the decision boundary is defined by a subset of the training data points (support vectors), and the kernel trick allows for the interpretation of the decision function in the original feature space. For RF, the importance of each feature can be assessed by measuring the total decrease in node impurities from splitting off that feature, averaged over all trees in the forest.\n\nFurthermore, the model's performance is evaluated using commonly used metrics such as sensitivity, specificity, accuracy, and Matthew's correlation coefficient, which provide a clear understanding of the model's predictive power and its ability to distinguish between different classes.\n\nIn summary, while the model may not be entirely transparent, it incorporates several interpretable components and techniques that contribute to its overall interpretability. The feature extraction and selection processes, as well as the classification algorithms used, provide insights into the model's decision-making process and the relevance of different features.",
  "model/output": "The model discussed in this publication is a classification model. It is designed to predict whether proteins are DNA-binding proteins (DBPs) or not. The model uses various classifiers, including Support Vector Machine (SVM) and Random Forest (RF), to achieve this classification task. The performance of these classifiers is evaluated using metrics such as sensitivity, specificity, accuracy, and Matthew's correlation coefficient. The model's output is a binary classification, indicating whether a given protein is a DBP or not.\n\nThe classifiers were implemented using the Python sklearn library, and the experiments were conducted using Python version 3.7. The model's performance was assessed through different cross-validation methods, including 10-fold cross-validation and jackknife cross-validation. Additionally, the area under the receiver operating characteristic (ROC) curve (AUC) was computed to evaluate the performance of the binary classifier.\n\nThe model's accuracy rate is a crucial evaluation criterion, and insights into the selection of the optimal parameter g and classifier are provided. The accuracy rate tends to decrease as the parameter g increases, and the SVM classifier consistently outperforms the RF classifier. To balance accuracy and computational efficiency, it is recommended to keep the maximum value of g at 5. This results in 100 ACT features and 1900 CCT features.\n\nFeature selection techniques, such as RF and XGBoost, were applied to rank the features based on their importance. The top 270 ranked features were selected for further analysis, as they yielded the highest accuracy. The combination of the SVM classifier with the joint use of AAC, ACT, and CCT features was found to be the most effective approach for predicting DBPs. This combination achieved the highest accuracy rates in both 10-fold and jackknife cross-validation tests.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The source code for the study is freely available to the academic community. It can be accessed at the following GitHub repository: https://github.com/taigangliu/HMMPred. This repository contains the datasets and source codes necessary to replicate the experiments and results presented in the publication. The availability of the source code allows other researchers to verify the findings, build upon the work, and apply the method to their own datasets. The code is released under a license that permits academic use, ensuring that the community can benefit from the research without restrictions.",
  "evaluation/method": "The evaluation of the proposed method involved several rigorous tests to ensure its effectiveness and robustness. Three commonly used tests were employed: 10-fold cross-validation (CV), jackknife CV, and an independent test. The 10-fold CV and jackknife CV were implemented on the PDB1075 dataset, while the independent test used the PDB1075 dataset for training and the PDB186 dataset for testing.\n\nPerformance was assessed using four key metrics: sensitivity (SN), specificity (SP), accuracy (ACC), and Matthew\u2019s correlation coefficient (MCC). Additionally, the area under the receiver operating characteristic (ROC) curve (AUC) was computed to evaluate the performance of the binary classifier.\n\nThe experiments compared the performance of different classifiers, specifically Support Vector Machines (SVM) and Random Forests (RF), combined with various feature extraction techniques, including Amino Acid Composition (AAC), Auto-Correlation Transformation (ACT), and Conjoint Triad (CCT). The results indicated that the SVM classifier, particularly when combined with the joint use of AAC, ACT, and CCT features, achieved the highest accuracy and other performance metrics.\n\nFeature selection was also a critical part of the evaluation. Features were ranked using RF and XGBoost techniques, and the top 270 ranked features were selected for further analysis. The effectiveness of feature selection was demonstrated by comparing the prediction performance with and without feature selection, showing that feature selection significantly improved the prediction of DNA-binding proteins (DBPs).\n\nROC curves were plotted to visualize the performance before and after feature selection, further confirming the consistent and improved findings. The method was also compared with existing predictors, such as DNAbinder, DNA-Prot, iDNA-Prot, and others, on the same datasets. The results showed that the proposed method achieved superior performance in terms of ACC, SN, SP, MCC, and AUC, ranking second on the benchmark.",
  "evaluation/measure": "The performance of the proposed method is evaluated using several commonly used metrics in the field of binary classification. These metrics include sensitivity (SN), specificity (SP), accuracy (ACC), and Matthew's correlation coefficient (MCC). Sensitivity measures the proportion of true positive predictions among the actual positives, while specificity measures the proportion of true negative predictions among the actual negatives. Accuracy provides an overall measure of correct predictions, and MCC offers a balanced measure that considers true and false positives and negatives. Additionally, the area under the receiver operating characteristic curve (AUC) is computed to evaluate the performance of the binary classifier. These metrics collectively provide a comprehensive assessment of the model's predictive power and robustness. The choice of these metrics is representative of the literature, ensuring that the evaluation is both rigorous and comparable to other studies in the field.",
  "evaluation/comparison": "In the evaluation of our proposed method, we conducted a thorough comparison with several existing predictors on benchmark datasets to objectively assess its effectiveness. The methods we compared against include DNAbinder, DNA-Prot, iDNA-Prot, iDNA-Prot|dis, Kmer1+ACC, iDNAPro-PseAAC, PseDNA-Pro, Local-DPP, and HMMBinder. These comparisons were performed on the PDB1075 dataset using jackknife tests, and the results are presented in a table. Additionally, we evaluated the performance of various algorithms on the PDB186 independent dataset, illustrating five performance measures in another table.\n\nThe results demonstrate that our method achieves competitive performance metrics. For instance, on the PDB1075 dataset, our method ranks second in terms of accuracy, specificity, Matthews correlation coefficient, and area under the curve. This indicates that our approach is robust and reliable compared to other existing methods.\n\nFurthermore, we also compared our method to simpler baselines, such as using different feature extraction techniques like AAC, ACT, and CCT, both individually and in combination. The results show that the combination of AAC, ACT, and CCT features with an SVM classifier yields the highest accuracy and other performance metrics, highlighting the importance of feature fusion in improving prediction accuracy.\n\nIn summary, our method not only outperforms many existing predictors but also demonstrates the superiority of using a combination of feature extraction techniques and an efficient feature selection method like XGBoost. This comprehensive evaluation underscores the effectiveness and reliability of our proposed approach in identifying DBPs.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "Not enough information is available."
}