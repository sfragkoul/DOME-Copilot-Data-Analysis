{
  "publication/title": "From flamingo dance to (desirable) drug discovery: a nature-inspired approach.",
  "publication/authors": "S\u00e1nchez-Rodr\u00edguez Aminael, P\u00e9rez-Castillo Yunierkis, Sch\u00fcrer Stephan C, Nicolotti Orazio, Mangiatordi Giuseppe Felice, Borges Fernanda, Cordeiro M Natalia D S, Tejera Eduardo, Medina-Franco Jos\u00e9 L, Cruz-Monteagudo Maykel",
  "publication/journal": "Drug discovery today",
  "publication/year": "2017",
  "publication/doi": "10.1016/j.drudis.2017.05.008",
  "publication/tags": "- Drug Discovery\n- Multicriteria Decision-Making\n- Virtual Screening\n- Desirability Functions\n- Machine Learning\n- Ensemble Modeling\n- Chemogenomics\n- QSAR Modeling\n- Multitarget Ligands\n- Pharmacological Activity",
  "dataset/provenance": "The dataset used in our study comprises chemical compounds with known bioactivity values, categorized into active or inactive groups. For the antimalarial data set, we utilized 50 known antimalarial hits, while for the dual A2AAR/MAO-B ligands, we used eight known dual-target ligands. Decoy molecules for these datasets were generated using the DUD-E server and the DecoyFinder application. The structures of these compounds, along with their biological annotations, are provided in the supplemental information online.\n\nThe data preparation involved compiling, curating, and codifying these compounds through molecular descriptors using the ISIDA Fragmentor software. The top 250 most informative descriptors, selected based on higher relevance and lower redundancy using the mRMR algorithm, were used for modeling.\n\nThe datasets were divided into training, test, external, and virtual screening (VS) validation sets. The training set was used to build base models, while the test set evaluated their performance. The external set verified the predictive capability of the selected models, and the VS validation sets assessed the virtual screening performance. The composition of these sets is summarized in the supplemental information online.\n\nThe antimalarial dataset included compounds targeting the 3D7 and W2 strains, as well as a toxicity endpoint (Huh7). For the dual A2AAR/MAO-B ligands, the dataset focused on compounds targeting A2AAR and MAO-B. The performance of the base models varied, with better results observed for the toxicity endpoint in the antimalarial dataset and for MAO-B inhibitors in the dual-target dataset. This variation can be attributed to the structural diversity of the datasets, with the dual-target dataset being less diverse, making it easier to identify bioactivity rules.\n\nIn total, 1001 base models were trained for each endpoint in each dataset, with performance metrics summarized in the supplemental information. The best models were selected based on the maximum balanced classification rate (BCR) achieved for the test set. The external dataset was used solely for verification purposes and did not influence model selection.",
  "dataset/splits": "In our study, we utilized several data splits to ensure robust model training and validation. Specifically, we prepared training, test, external, and virtual screening (VS) validation sets for each endpoint. The supplemental information provides detailed SD files that include the compound structures and biological annotations for these sets. Additionally, Table S1 summarizes the composition of all these sets.\n\nFor the antimalarial data set, we included known antimalarial hits and a pool of decoys selected using the DUD-E server. Similarly, for the dual A2AAR/MAO-B ligands, DUD-E decoys were generated for known dual-target ligands to form the VS validation sets.\n\nThe external data set is used solely for verifying the predictive capability of the selected models and does not influence the model selection process. This ensures that the models are evaluated on unseen data, providing a reliable assessment of their generalizability.\n\nThe distribution of data points in each split is designed to cover a wide range of chemical space, ensuring that the models are trained on diverse and representative data. The exact number of data points in each split can be found in the supplemental information, which includes comprehensive details about the dataset composition.",
  "dataset/redundancy": "The datasets used in this study were split into several sets to ensure robust model training and validation. For each endpoint, the datasets were divided into training, test, external, and virtual screening (VS) validation sets. The training set was used to build the base models, while the test set was employed to evaluate their performance and select the best models. The external dataset was reserved solely for verifying the predictive capability of the selected models, ensuring that it did not influence the model selection process. This independence was crucial for assessing the generalizability of the models.\n\nTo enforce the independence of the training and test sets, careful curation and splitting strategies were employed. The datasets were designed to include a diverse range of compounds, ensuring that the models were not overfitted to specific subsets of data. The structural diversity of the datasets played a significant role in this process. For instance, the dual A2AAR/MAO-B ligands dataset was less structurally diverse compared to the antimalarial dataset, which affected the applicability domain of the models. This diversity influenced the ease of discovering bioactivity rules during the machine learning process.\n\nThe distribution of the datasets compares favorably with previously published machine learning datasets in the field. The use of ISIDA Fragments and the mRMR algorithm ensured that the most informative and non-redundant descriptors were selected, enhancing the quality of the models. The supplemental information provides detailed summaries of the composition of these sets, including the SD files with compound structures and biological annotations. This transparency allows for replication and further validation of the findings.\n\nIn summary, the datasets were meticulously split and curated to ensure independence and diversity, which are critical for building robust and generalizable machine learning models. The strategies employed align with best practices in the field, ensuring that the models' performance is reliable and reproducible.",
  "dataset/availability": "The data used in this study, including the data splits for training, test, external, and virtual screening (VS) validation sets, are provided in the supplemental information online. This includes the SD files containing compound structures and biological annotations for each set. Additionally, lists of the final subset of 250 ISIDA Fragments per endpoint are available. The composition of all these sets is summarized in Table S1 in the supplemental information.\n\nThe supplemental information also includes Table S2, which summarizes the performance metrics of the base classifiers. For the antimalarial compounds, models for the toxicity endpoint (Huh7) showed better average performances compared to those for antimalarial endpoints (3D7 and W2). In the case of dual A2AAR/MAO-B ligands, the best performance was achieved for MAO-B inhibitors. The performance of the base models was generally higher for the dual A2AAR/MAO-B ligands due to the lower structural diversity of this dataset, which made it easier to discover the rules guiding bioactivity.\n\nThe selection of the best models was based on the maximum value of the balanced classification rate (BCR) achieved for the test set. The external dataset was used solely for verifying the predictive capability of the selected models and did not influence the model selection process.\n\nDifferent strategies were employed for combining base models into ensembles for each endpoint. For antimalarial activity endpoints (3D7 and W2), the best-performing ensemble used a genetic algorithm (GA) to select base models and the scores vote (SV) aggregation strategy to maximize BCR. For the toxicity endpoint (Huh7), the best ensemble used majority vote (MV) aggregation and minimized the Akaike Information Criterion (AIC). For dual A2AAR/MAO-B ligands, the best ensembles used Borda vote (BV) and majority vote (MV) for A2AAR and MAO-B, respectively, to maximize BCR.\n\nThe obtained ensembles improved the average performance of the base models for all endpoints, as shown in Figure 4. The ensembles also demonstrated a better balance between sensitivity and specificity compared to the base models. The ensembles contained between 5 and 14 base models, representing approximately 1% of the total number of base models. This highlights the importance of combining a tailored subset of diverse base models rather than aggregating a large number of models.\n\nThe external dataset was used to assess the predictive potential of the ensembles, ensuring that the ensembles can generate trustworthy score values for compounds within their applicability domain. The final ensembles for all endpoints, except for MAO-B inhibitors, contained all compounds of the VS validation sets within their applicability domains. This illustrates the benefits of using the ensemble modeling strategy over individual models from the applicability domain perspective.",
  "optimization/algorithm": "The optimization algorithm employed in our work leverages ensemble modeling techniques, specifically utilizing Least Squares Support Vector Machines (LSSVM) as the base classification algorithm. LSSVM is a well-established machine-learning algorithm class within the realm of support vector machines, known for its efficiency in handling classification problems.\n\nThe approach is not entirely new but is innovative in its application to drug discovery. The novelty lies in the integration of LSSVM with a desirability-based method for multi-criteria virtual screening, which is tailored for drug discovery processes. This method involves transforming classification scores into desirability values, allowing for a more nuanced evaluation of compounds based on multiple criteria.\n\nThe reason this work was published in a drug discovery journal rather than a machine-learning journal is due to the specific focus on its application in pharmaceutical research. The primary contribution is the development of a nature-inspired multi-criteria optimization process for drug discovery, which includes the use of ensemble modeling and the applicability domain. The method's suitability is demonstrated through case studies in drug discovery, making it more relevant to the field of pharmaceutical research.\n\nThe ensemble models are constructed using diverse base models, selected through strategies like clustering and Genetic Algorithms (GA). The diversity of these base models is crucial for the performance of the ensemble, ensuring that the final model can handle a wide range of chemical spaces. The ensemble's applicability domain is defined as the union of the applicability domains of its constituent models, enhancing the model's reliability and performance in predicting new compounds.",
  "optimization/meta": "The model described in this publication employs an ensemble modeling approach, which can be considered a form of meta-predictor. This approach utilizes data from multiple base machine-learning algorithms as input. Specifically, a pool of diverse base classification models is trained for each endpoint using the Least Squares Support Vector Machines (LSSVM) classification algorithm. These base models are then aggregated into ensemble models using three different data fusion strategies: Major vote (MV), Borda vote (BV), and Scores vote (SV).\n\nThe diversity of the base models is ensured through a random features subset selection strategy, where each base model can contain several descriptors ranging from 5 to 25. The applicability domain of the base models is defined according to the molecular descriptors range method, ensuring that each feature included in the model is used to build a hyper-rectangle defined by the maximum and minimum values of the features on the training data.\n\nThe ensemble models are designed to improve the performance of the best base model for all endpoints and to provide a better balance between sensitivity and specificity. The selection of the best ensemble is based on the maximum value of the Balanced Classification Rate (BCR) achieved for the test set. The external data set is used only to assess the predictive potential of the models, ensuring that the training data is independent and that the models can generate trustworthy score values within their applicability domain.\n\nIn summary, the model is a meta-predictor that combines the outputs of multiple LSSVM base models using different aggregation strategies. The training data for the base models is independent, and the ensemble approach is designed to enhance the overall performance and applicability of the models.",
  "optimization/encoding": "In our methodology, data encoding and preprocessing were crucial steps to ensure the effectiveness of the machine-learning algorithms employed. Initially, a dataset of chemical compounds was compiled, curated, and codified using molecular descriptors. These descriptors were calculated using the ISIDA Fragmentor software, which is freely available. The top 250 most informative descriptors, those with higher relevance and lower redundancy, were selected using the minimum Redundancy Maximum Relevance (mRMR) algorithm. This selection process ensured that the descriptors used were both informative and non-redundant, providing a robust foundation for the subsequent modeling steps.\n\nThe molecular descriptors were then used to train a pool of diverse base classification models for each endpoint. To ensure diversity among the base models, a random features subset selection strategy was employed. Each base model could contain between 5 to 25 descriptors. The acceptability of a base model was determined by its accuracy in predicting the training and test sets, as well as in fivefold cross-validation experiments. A model was considered acceptable if it achieved an accuracy of at least 0.65. This rigorous selection process ensured that only high-performing models were included in the ensemble.\n\nThe applicability domain of the base models was defined using the molecular descriptors range method. This method involves creating a hyper-rectangle defined by the maximum and minimum values of the features in the training data. A sample was considered within the applicability domain if it fell within this hyper-rectangle. This approach ensured that predictions were made only for samples that were within the scope of the training data, enhancing the reliability of the model's predictions.\n\nIn summary, the data encoding and preprocessing involved the selection of informative molecular descriptors, the training of diverse base models, and the definition of an applicability domain to ensure reliable predictions. These steps were essential in preparing the data for the machine-learning algorithms and ensuring the robustness and accuracy of the models.",
  "optimization/parameters": "In our study, the number of parameters used in the model is not fixed but rather depends on the specific optimization problem and the data available. The parameters are the properties or endpoints that are considered for the optimization of compounds. These can include various molecular properties, biological activities, or other relevant descriptors.\n\nThe selection of parameters is guided by the goals of the project and the reliability of the measures. In practice, the number of parameters can vary, but it is important to note that as the number of properties being optimized increases, the number of optimal compounds also increases exponentially. This can become impractical when considering more than approximately four properties. Therefore, the selection of parameters is a crucial step that involves balancing the need for comprehensive optimization with the practical limitations of the method.\n\nIn some cases, ensemble modeling is used to handle a larger number of parameters effectively. This approach involves combining multiple base models to improve performance and robustness. The diversity of the base models is ensured through strategies such as clustering or genetic algorithms, which help in selecting a tailored subset of models that provide the best balance between sensitivity and specificity.\n\nThe applicability domain of the ensemble models is defined as the union of the applicability domains of the individual models, which increases the overall applicability domain. This ensures that the model can handle a wider range of compounds and provides more reliable predictions.\n\nIn summary, the number of parameters used in the model is flexible and depends on the specific optimization problem. The selection of parameters is carefully considered to balance the need for comprehensive optimization with practical limitations, and ensemble modeling is used to handle a larger number of parameters effectively.",
  "optimization/features": "The input features used in our methodology are molecular descriptors calculated using the ISIDA Fragmentor software. Feature selection was indeed performed to ensure that the most informative descriptors were used. The selection process involved using the minimum Redundancy Maximum Relevance (mRMR) algorithm to identify the top-250 descriptors that exhibited higher relevance and lower redundancy. This selection was conducted using the training set only, ensuring that the feature set was optimized for the specific endpoint being modeled. The use of these selected features helps in maintaining a balance between the relevance of the descriptors to the bioactivity and minimizing redundancy, thereby enhancing the performance of the models.",
  "optimization/fitting": "In our approach to drug discovery, we employed ensemble modeling, which inherently helps to mitigate both overfitting and underfitting issues. The ensembles we constructed comprised a tailored subset of base models, ensuring a certain level of diversity. This diversity is crucial because it allows the ensemble to capture a broader range of patterns in the data, reducing the risk of overfitting that can occur when a single model becomes too complex and fits the noise in the training data.\n\nTo rule out overfitting, we optimized the performance of our ensembles on a separate test set, ensuring that the improvements in performance were not merely due to memorizing the training data. Additionally, the ensembles showed a better balance between sensitivity and specificity compared to the base models, indicating that they generalize well to unseen data.\n\nThe ensembles also covered a significant portion of the chemical space, as evidenced by their applicability domain, which included nearly all samples in the validation sets. This extensive coverage suggests that the models are not underfitting, as they are capable of making predictions across a wide range of compounds.\n\nFurthermore, the use of desirability functions in our multi-criteria optimization process allowed us to handle missing values and data uncertainty effectively. This feature ensures that the models are robust and can provide reliable predictions even when some data points are incomplete or uncertain.\n\nIn summary, the combination of ensemble modeling, optimization on a test set, and the use of desirability functions helps to address both overfitting and underfitting, ensuring that our models are both complex enough to capture the underlying patterns in the data and generalizable to new, unseen compounds.",
  "optimization/regularization": "In our approach, we employed ensemble modeling as a key regularization method to prevent overfitting. This technique involves combining multiple base models to create a more robust and generalizable predictor. By aggregating the predictions of these diverse models, we achieved better performance than any single model could provide. This method not only improved the overall classification accuracy but also ensured a better balance between sensitivity and specificity.\n\nThe ensembles we developed were optimized on the test set, ensuring that the improvements in performance did not come at the expense of the training set statistics. This careful balancing act helped in maintaining the model's generalizability and preventing overfitting to the training data.\n\nAdditionally, we considered the applicability domain of the models, which is dynamically structured throughout the modeling process. This ensures that the models are reliable and trustworthy within the chemical space they are designed to cover. By focusing on a tailored subset of base models that encompass a certain level of diversity, we avoided the pitfalls of using an excessively large number of models, which could lead to overfitting.\n\nIn summary, our use of ensemble modeling and the careful consideration of the applicability domain served as effective regularization techniques, enhancing the robustness and reliability of our multicriteria virtual screening approach.",
  "optimization/config": "The hyper-parameter configurations, optimization schedule, and model files are not explicitly detailed in the publication. However, the supplemental information online provides extensive details that support the reproducibility of the experiments. This includes the composition of various datasets, performance metrics of base classifiers, and statistics for the best ensemble per endpoint.\n\nThe supplemental information also contains the SD files with the structures of the validation sets, which are crucial for verifying the predictive potential of the models. Additionally, the methods used for generating decoys and the criteria for selecting base models are described, ensuring that the optimization process can be replicated.\n\nWhile specific model files and exact optimization parameters are not directly provided, the comprehensive details in the supplemental information allow for the recreation of the experimental setup and the optimization process. This ensures that other researchers can follow the same procedures and achieve similar results. The supplemental information is available online, and there is no explicit mention of licensing restrictions, suggesting that it is accessible for research purposes.",
  "model/interpretability": "The models employed in our study are primarily ensemble models composed of base classifiers, which can be considered as a form of interpretable black-box models. While individual base models, such as Least Squares Support Vector Machines (LSSVM), may not be fully transparent, the ensemble approach provides several layers of interpretability.\n\nFirstly, the diversity of base models ensures that the ensemble captures a wide range of patterns in the data. This diversity is achieved through the use of different subsets of molecular descriptors and various aggregation strategies, such as Major Vote (MV), Borda Vote (BV), and Scores Vote (SV). The use of these strategies allows for a more robust and generalizable model, as the ensemble can leverage the strengths of individual models while mitigating their weaknesses.\n\nSecondly, the applicability domain of the ensemble models is defined as the union of the applicability domains of the individual base models. This means that the ensemble can provide predictions for a broader range of compounds, and the contribution of each base model to the final prediction is clearly defined. Only base models that include a sample within their applicability domain contribute to the aggregated decision, making the prediction process more transparent.\n\nAdditionally, the transformation of classification scores into desirability values adds another layer of interpretability. This transformation is based on the highest and lowest scores predicted by the ensemble across all training, test, and external sets. Compounds with higher scores are considered more desirable, and this desirability can be directly linked to the biological activity of the compounds.\n\nFurthermore, the use of Genetic Algorithms (GA) for selecting base models and optimizing their aggregation ensures that the ensemble is tailored to maximize performance metrics such as the Balanced Classification Rate (BCR). This optimization process is guided by clear fitness functions and distance metrics, providing a transparent framework for model selection and aggregation.\n\nIn summary, while the individual base models may not be fully transparent, the ensemble approach provides a structured and interpretable framework for model development and prediction. The use of diverse base models, clear applicability domains, and transparent score transformations ensures that the ensemble models are both robust and interpretable.",
  "model/output": "The model developed in our study is a classification model. It is designed to predict whether chemical compounds are active or inactive for specific endpoints, such as antimalarial activity or dual A2AAR/MAO-B inhibition. The model uses a pool of base classifiers, specifically Least Squares Support Vector Machines (LSSVM), to make these predictions. These base models are aggregated into ensemble models using different data fusion strategies, such as Major vote, Borda vote, and Scores vote. The final output of the model is a classification score that is transformed into a desirability value, indicating the likelihood of a compound being active or inactive.\n\nThe performance of the ensemble models is evaluated using metrics such as sensitivity, specificity, and the Balanced Classification Rate (BCR). These metrics help to assess the model's ability to correctly classify compounds as active or inactive. The ensemble models have shown improved performance compared to the average and best individual base models, demonstrating their effectiveness in classification tasks.\n\nThe applicability domain of the ensemble models is defined as the union of the applicability domains of the individual base models. This approach ensures that the ensemble model can make predictions for a wider range of compounds, increasing its practical utility. The model's predictions are considered reliable for compounds within its applicability domain, as validated by external data sets.\n\nIn summary, the model is a classification system that predicts the bioactivity of chemical compounds using ensemble learning techniques. It provides desirability values based on classification scores, helping to prioritize compounds for further investigation in drug discovery processes.",
  "model/duration": "Not enough information is available.",
  "model/availability": "The methodology described in our publication was implemented in MATLAB. However, the source code is not publicly released. The software is not available as an executable, web server, virtual machine, or container instance. The implementation details are provided in the supplemental information online, which offers a complete description of all the steps involved in the modeling workflow. This includes data preparation, training of base models, and aggregation of these models into an ensemble. The supplemental information can be accessed through the online version of the publication.",
  "evaluation/method": "The evaluation of the proposed methodology involved a comprehensive approach to ensure its robustness and suitability for virtual screening (VS) campaigns. Three distinct virtual screening validation sets (VSVS) were designed for this purpose. The first VSVS, referred to as VSVS-1, included known active compounds and decoys generated using the DUD-E server. This set was used to optimize the individual desirability weights, which were then aggregated into the final multicriteria VS tool.\n\nTo further validate the methodology, two additional VSVS were constructed: VSVS-2 and VSVS-3. These sets included a second subset of known active compounds and decoys generated using both the DUD-E server and the DecoyFinder application. The classification scores for these VSVS were computed and transformed into desirability values according to previously established transformations.\n\nThe evaluation focused on the initial enrichment of active compounds within the first 1% of screened data, which is crucial for the efficiency of VS campaigns. The results demonstrated a significant initial enrichment of active compounds, even at very low fractions of screened data. This observation was consistent across all experiments, including the worst-performing VS validation experiments.\n\nThe performance of the desirability-based methodology was compared to the aggregation of classification scores without transforming them into desirabilities. The desirability-based approach showed superior initial enrichment, highlighting its advantages for multicriteria VS. The optimization of weights for the aggregation of individual desirability functions provided only a slight improvement, indicating that weight optimization is not necessarily mandatory for obtaining effective VS tools.\n\nThe evaluation also included an analysis of the applicability domain of the ensemble models. The ensemble models covered a broader region of the chemical space compared to individual models, ensuring that the predictions are reliable for compounds within their applicability domain. This was particularly evident in the case of MAO-B inhibitors, where the ensemble model increased the coverage of the chemical space by approximately 13% relative to the individual model average.\n\nOverall, the evaluation methodology involved a rigorous assessment using multiple VSVS and a comparison with alternative approaches. The results strongly support the hypothesis that desirability functions can be effectively used for the development of high-performance multicriteria VS tools.",
  "evaluation/measure": "In our study, we primarily focused on the Balanced Classification Rate (BCR) as our key performance metric. BCR is defined as the average of sensitivity (Se) and specificity (Sp), providing a balanced measure of a model's performance, especially when dealing with imbalanced datasets. This metric is crucial because it ensures that models with a good balance between true positive and true negative rates are favored.\n\nIn addition to BCR, we also considered other performance metrics to comprehensively evaluate our models. These include sensitivity, specificity, and overall classification accuracy. Sensitivity measures the proportion of actual positives correctly identified by the model, while specificity measures the proportion of actual negatives correctly identified. Classification accuracy provides an overall measure of the model's correctness.\n\nThe use of BCR as our primary metric is representative of current practices in the field, as it addresses the common issue of imbalanced datasets in biological and chemical data. By focusing on BCR, we ensure that our models are robust and generalizable, providing reliable predictions across different datasets and endpoints.\n\nMoreover, we evaluated the performance of our ensemble models compared to individual base models. The ensemble models consistently showed improved performance metrics, indicating that the combination of diverse base models enhances predictive accuracy and reliability. This approach is in line with established methods in machine learning and cheminformatics, where ensemble techniques are widely used to improve model performance.\n\nIn summary, our choice of performance metrics is both comprehensive and representative of current standards in the field. By focusing on BCR and additional metrics like sensitivity, specificity, and accuracy, we ensure that our models are thoroughly evaluated and capable of providing reliable predictions for virtual screening and other applications.",
  "evaluation/comparison": "In our study, we did not perform a direct comparison to publicly available methods on benchmark datasets. Instead, our focus was on evaluating the performance of our ensemble modeling approach and the desirability-based methodology within the context of our specific datasets\u2014antimalarial compounds and dual A2AAR/MAO-B ligands.\n\nHowever, we did compare the performance of our ensemble models to simpler baselines, such as the average performance of the base models and the best individual base model. The ensemble models consistently showed better performance than these baselines across all endpoints. This improvement was evident in both the average performance metrics and the balance between sensitivity and specificity.\n\nAdditionally, we evaluated the virtual screening (VS) performance of our approach using three different VS Validation Sets (VSVS). These sets were designed to assess the ability of our models to retrieve known active compounds from a pool of decoys. The results demonstrated that our desirability-based methodology outperformed the simple aggregation of classification scores, particularly in the early fractions of screened data.\n\nWhile we did not compare our methods to other publicly available tools directly, the internal comparisons and the use of diverse validation sets provide strong evidence of the effectiveness of our approach. The ensemble modeling strategy and the desirability-based methodology showed significant improvements over simpler baselines, highlighting their potential for high-performance multicriteria virtual screening.",
  "evaluation/confidence": "Not enough information is available.",
  "evaluation/availability": "The raw evaluation files, including the structures and biological annotations of the compounds used in the training, test, external, and virtual screening (VS) validation sets, are available in the supplemental information online. These files are provided in SD format, which is a standard format for chemical structures and associated data. Additionally, lists of the final subset of 250 ISIDA Fragments per endpoint are included in the supplemental information. The composition of all these sets is summarized in Table S1.\n\nThe performance metrics of the base classifiers are detailed in Table S2, and the statistics for the best ensemble per endpoint are presented in Table S3. These tables provide a comprehensive overview of the model performance and the selection process.\n\nThe supplemental information also includes the structures of the VS Validation Sets (VSVS) in SD format. These sets were designed to evaluate the virtual screening performance of the approach. The first VSVS (VSVS-1) comprises known hits and decoys selected using the DUD-E server. Two additional VSVS (VSVS-2 and VSVS-3) were built using different decoy generation methods to further assess the performance.\n\nThe supplemental information is publicly available, and the files can be accessed and used according to the terms specified in the publication. This ensures that other researchers can replicate the results and further build upon the work presented."
}